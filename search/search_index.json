{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"OneFlow-YOLOV5-Document What is one-yolov5\ud83e\udd14\ufe0f\uff1f one-yolov5 : \u662f\u4ee5 OneFlow \u4e3a\u540e\u7aef\u7684YOLOv5\u76ee\u6807\u68c0\u6d4b\u9879\u76ee\u76f8\u6bd4pytorch\u540e\u7aef\u66f4\u6709\u6548\u7f29\u77ed\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\u3002 \u66f4\u591a\u8bf7\u53c2\u9605 one-yolov5\u7279\u70b9\u89e3\u6790 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \ud83c\udf89\u6587\u6863\u7f51\u7ad9\u5730\u5740\uff1a https://start.oneflow.org/oneflow-yolo-doc/index.html OneFlow \u5b89\u88c5\u65b9\u6cd5\uff1a https://github.com/Oneflow-Inc/oneflow#install-oneflow \u4e0d\u8fc7\u5373\u4f7f\u4f60\u5bf9 OneFlow \u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u4e0d\u592a\u611f\u5174\u8da3\uff0c\u6211\u4eec\u76f8\u4fe1 \u6587\u6863\u7f51\u7ad9 \u4e2d\u5bf9 YOLOv5 \u6559\u7a0b\u7684\u6c49\u5316\u4ee5\u53ca\u6e90\u7801\u5256\u6790\u4e5f\u4f1a\u662f\u4ece\u96f6\u5f00\u59cb\u6df1\u5165\u5b66\u4e60 YOLOv5 \u4e00\u4efd\u4e0d\u9519\u7684\u8d44\u6599\u3002\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 YOLOv5\u6559\u7a0b\u5bfc\u822a\ud83d\udcda \u5f15\u8a00: one-yolov5 \u7279\u70b9\u89e3\u6790 \u7b2c\u4e00\u7ae0 \u7f51\u7edc\u7ed3\u6784: 1.1. YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790 \u7b2c\u4e8c\u7ae0 \u8bad\u7ec3\u6a21\u578b\u7684\u6570\u636e\u96c6: 2.1. \u5982\u4f55\u51c6\u5907YOLOv5\u6a21\u578b\u8bad\u7ec3\u6570\u636e \u7b2c\u4e09\u7ae0 \u6a21\u578b\u8bad\u7ec3: 3.1. \u5feb\u901f\u5f00\u59cb 3.2. \u4eceOneFlow Hub \u52a0\u8f7dYOLOv5 3.3 \u6a21\u578b\u8bad\u7ec3 3.4 \u6d4b\u8bd5\u65f6\u589e\u5f3a (TTA) 3.5 \u6a21\u578b\u878d\u5408 (Model Ensembling) \u7b2c\u56db\u7ae0 \u6570\u636e\u7ec4\u7ec7\u4e0e\u5904\u7406\u89e3\u8bfb: 4.1 mosaic \u89e3\u8bfb \u7b2c\u4e94\u7ae0 YOLOv5\u4e2dIoU\u635f\u5931: 5.1 \u77e9\u5f62\u63a8\u7406 5.2 IoU\u6df1\u5165\u89e3\u6790 5.3 \u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30 \u7b2c\u516d\u7ae0 \u6a21\u578b\u5bfc\u51fa\u548c\u90e8\u7f72\u4ecb\u7ecd 6.1 \u6a21\u578b\u5bfc\u51fa \u7b2c\u4e03\u7ae0:\u7f51\u9875\u90e8\u7f72\u548capp\u3002 \u65bd\u5de5\u4e2d\u3002\u3002\u3002 \u7b2c\u516b\u7ae0\uff1a\u548ctvm\u7684\u4ea4\u4e92\uff0c\u57fa\u4e8etvm\u7684\u90e8\u7f72\u3002 \u65bd\u5de5\u4e2d\u3002\u3002\u3002 \u7b2c\u4e5d\u7ae0\uff1aYOLOv5\u4e2d\u7684\u53c2\u6570\u641c\u7d22 \u65bd\u5de5\u4e2d\u3002\u3002\u3002 \u7b2c\u5341\u7ae0: utils/\u6587\u4ef6\u5939\u63a2\u7d22 \u65bd\u5de5\u4e2d\u3002\u3002\u3002 \u8bba\u6587\u89e3\u8bfb\u5bfc\u822a\ud83d\udcda history YOLOv1 YOLOv2 YOLOv3 YOLOv4 YOLOv6 YOLOv5\u6e90\u7801\u8be6\u89e3\u5bfc\u822a\ud83d\udcda \u65bd\u5de5\u4e2d\u3002\u3002\u3002 FAQ \ud83d\udc98 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"\u9996\u9875\ud83c\udfe0"},{"location":"index.html#oneflow-yolov5-document","text":"","title":"OneFlow-YOLOV5-Document"},{"location":"index.html#what-is-one-yolov5","text":"one-yolov5 : \u662f\u4ee5 OneFlow \u4e3a\u540e\u7aef\u7684YOLOv5\u76ee\u6807\u68c0\u6d4b\u9879\u76ee\u76f8\u6bd4pytorch\u540e\u7aef\u66f4\u6709\u6548\u7f29\u77ed\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\u3002 \u66f4\u591a\u8bf7\u53c2\u9605 one-yolov5\u7279\u70b9\u89e3\u6790 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \ud83c\udf89\u6587\u6863\u7f51\u7ad9\u5730\u5740\uff1a https://start.oneflow.org/oneflow-yolo-doc/index.html OneFlow \u5b89\u88c5\u65b9\u6cd5\uff1a https://github.com/Oneflow-Inc/oneflow#install-oneflow \u4e0d\u8fc7\u5373\u4f7f\u4f60\u5bf9 OneFlow \u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u4e0d\u592a\u611f\u5174\u8da3\uff0c\u6211\u4eec\u76f8\u4fe1 \u6587\u6863\u7f51\u7ad9 \u4e2d\u5bf9 YOLOv5 \u6559\u7a0b\u7684\u6c49\u5316\u4ee5\u53ca\u6e90\u7801\u5256\u6790\u4e5f\u4f1a\u662f\u4ece\u96f6\u5f00\u59cb\u6df1\u5165\u5b66\u4e60 YOLOv5 \u4e00\u4efd\u4e0d\u9519\u7684\u8d44\u6599\u3002\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002","title":"What is one-yolov5\ud83e\udd14\ufe0f\uff1f"},{"location":"index.html#yolov5","text":"\u5f15\u8a00: one-yolov5 \u7279\u70b9\u89e3\u6790 \u7b2c\u4e00\u7ae0 \u7f51\u7edc\u7ed3\u6784: 1.1. YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790 \u7b2c\u4e8c\u7ae0 \u8bad\u7ec3\u6a21\u578b\u7684\u6570\u636e\u96c6: 2.1. \u5982\u4f55\u51c6\u5907YOLOv5\u6a21\u578b\u8bad\u7ec3\u6570\u636e \u7b2c\u4e09\u7ae0 \u6a21\u578b\u8bad\u7ec3: 3.1. \u5feb\u901f\u5f00\u59cb 3.2. \u4eceOneFlow Hub \u52a0\u8f7dYOLOv5 3.3 \u6a21\u578b\u8bad\u7ec3 3.4 \u6d4b\u8bd5\u65f6\u589e\u5f3a (TTA) 3.5 \u6a21\u578b\u878d\u5408 (Model Ensembling) \u7b2c\u56db\u7ae0 \u6570\u636e\u7ec4\u7ec7\u4e0e\u5904\u7406\u89e3\u8bfb: 4.1 mosaic \u89e3\u8bfb \u7b2c\u4e94\u7ae0 YOLOv5\u4e2dIoU\u635f\u5931: 5.1 \u77e9\u5f62\u63a8\u7406 5.2 IoU\u6df1\u5165\u89e3\u6790 5.3 \u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30 \u7b2c\u516d\u7ae0 \u6a21\u578b\u5bfc\u51fa\u548c\u90e8\u7f72\u4ecb\u7ecd 6.1 \u6a21\u578b\u5bfc\u51fa \u7b2c\u4e03\u7ae0:\u7f51\u9875\u90e8\u7f72\u548capp\u3002 \u65bd\u5de5\u4e2d\u3002\u3002\u3002 \u7b2c\u516b\u7ae0\uff1a\u548ctvm\u7684\u4ea4\u4e92\uff0c\u57fa\u4e8etvm\u7684\u90e8\u7f72\u3002 \u65bd\u5de5\u4e2d\u3002\u3002\u3002 \u7b2c\u4e5d\u7ae0\uff1aYOLOv5\u4e2d\u7684\u53c2\u6570\u641c\u7d22 \u65bd\u5de5\u4e2d\u3002\u3002\u3002 \u7b2c\u5341\u7ae0: utils/\u6587\u4ef6\u5939\u63a2\u7d22 \u65bd\u5de5\u4e2d\u3002\u3002\u3002","title":"YOLOv5\u6559\u7a0b\u5bfc\u822a\ud83d\udcda"},{"location":"index.html#_1","text":"history YOLOv1 YOLOv2 YOLOv3 YOLOv4 YOLOv6","title":"\u8bba\u6587\u89e3\u8bfb\u5bfc\u822a\ud83d\udcda"},{"location":"index.html#yolov5_1","text":"\u65bd\u5de5\u4e2d\u3002\u3002\u3002","title":"YOLOv5\u6e90\u7801\u8be6\u89e3\u5bfc\u822a\ud83d\udcda"},{"location":"index.html#faq","text":"\u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"FAQ \ud83d\udc98"},{"location":"source_code_interpretation/utils/augmentations_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/augmentations.py 1. random_perspective \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c \u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size\u3002 random_perspective\u51fd\u6570\u4ee3\u7801\uff1a def random_perspective ( img , targets = (), segments = (), degrees = 10 , translate = 0.1 , scale = 0.1 , shear = 10 , perspective = 0.0 , border = ( 0 , 0 ), ): \"\"\"\u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u4e8eload_mosaic\u4e2d\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e \u968f\u673a\u900f\u89c6\u53d8\u6362 \u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size :params img: mosaic\u6574\u5408\u540e\u7684\u56fe\u7247img4 [2*img_size, 2*img_size] \u5982\u679cmosaic\u540e\u7684\u56fe\u7247\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e segments\u4e3a\u7a7a \u5982\u679c\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e\u5219 segments\u4e0d\u4e3a\u7a7a\u3002 :params targets: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u6b63\u5e38label\u6807\u7b7elabels4(\u4e0d\u6b63\u5e38\u7684\u4f1a\u901a\u8fc7segments2boxes\u5c06\u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u6b63\u5e38\u6807\u7b7e) [N, cls+xyxy] :params segments: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u4e0d\u6b63\u5e38label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62\u4e5f\u5305\u542b\u6b63\u5e38gt) [m, x1y1....] :params degrees: \u65cb\u8f6c\u548c\u7f29\u653e\u77e9\u9635\u53c2\u6570 :params translate: \u5e73\u79fb\u77e9\u9635\u53c2\u6570 :params scale: \u7f29\u653e\u77e9\u9635\u53c2\u6570 :params shear: \u526a\u5207\u77e9\u9635\u53c2\u6570 :params perspective: \u900f\u89c6\u53d8\u6362\u53c2\u6570 :params border: \u7528\u4e8e\u786e\u5b9a\u6700\u540e\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f \u4e00\u822c\u7b49\u4e8e[-img_size//2, -img_size//2] \u90a3\u4e48\u6700\u540e\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f\u4e3a [img_size, img_size] :return img: \u901a\u8fc7\u900f\u89c6\u53d8\u6362/\u4eff\u5c04\u53d8\u6362\u540e\u7684img [img_size, img_size] :return targets: \u901a\u8fc7\u900f\u89c6\u53d8\u6362/\u4eff\u5c04\u53d8\u6362\u540e\u7684img\u5bf9\u5e94\u7684\u6807\u7b7e [n, cls+x1y1x2y2] (\u901a\u8fc7\u7b5b\u9009\u540e\u7684) \"\"\" # \u8bbe\u5b9a\u8f93\u51fa\u56fe\u7247\u7684 H W # border=-s // 2 \u6240\u4ee5\u6700\u540e\u56fe\u7247\u7684\u5927\u5c0f\u76f4\u63a5\u51cf\u534a [img_size, img_size, 3] height = img . shape [ 0 ] + border [ 0 ] * 2 # # \u6700\u7ec8\u8f93\u51fa\u56fe\u50cf\u7684H width = img . shape [ 1 ] + border [ 1 ] * 2 # \u6700\u7ec8\u8f93\u51fa\u56fe\u50cf\u7684W # ============================ \u5f00\u59cb\u53d8\u6362 ============================= # \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5176\u5b9eopencv\u662f\u5b9e\u73b0\u4e86\u4eff\u5c04\u53d8\u6362\u7684, \u4e0d\u8fc7\u6211\u4eec\u8981\u5148\u751f\u6210\u4eff\u5c04\u53d8\u6362\u77e9\u9635M # Center \u8bbe\u7f6e\u4e2d\u5fc3\u5e73\u79fb\u77e9\u9635 C = np . eye ( 3 ) C [ 0 , 2 ] = - img . shape [ 1 ] / 2 # x translation (pixels) C [ 1 , 2 ] = - img . shape [ 0 ] / 2 # y translation (pixels) # Perspective \u8bbe\u7f6e\u900f\u89c6\u53d8\u6362\u77e9\u9635 P = np . eye ( 3 ) P [ 2 , 0 ] = random . uniform ( - perspective , perspective ) # x perspective (about y) P [ 2 , 1 ] = random . uniform ( - perspective , perspective ) # y perspective (about x) # Rotation and Scale \u8bbe\u7f6e\u65cb\u8f6c\u548c\u7f29\u653e\u77e9\u9635 R = np . eye ( 3 ) # \u521d\u59cb\u5316R = [[1,0,0], [0,1,0], [0,0,1]] (3, 3) # a: \u968f\u673a\u751f\u6210\u65cb\u8f6c\u89d2\u5ea6 \u8303\u56f4\u5728(-degrees, degrees) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations a = random . uniform ( - degrees , degrees ) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations # s: \u968f\u673a\u751f\u6210\u65cb\u8f6c\u540e\u56fe\u50cf\u7684\u7f29\u653e\u6bd4\u4f8b \u8303\u56f4\u5728(1 - scale, 1 + scale) # s = 2 ** random.uniform(-scale, scale) s = random . uniform ( 1 - scale , 1 + scale ) # s = 2 ** random.uniform(-scale, scale) # cv2.getRotationMatrix2D: \u4e8c\u7ef4\u65cb\u8f6c\u7f29\u653e\u51fd\u6570 # \u53c2\u6570 angle:\u65cb\u8f6c\u89d2\u5ea6 center: \u65cb\u8f6c\u4e2d\u5fc3(\u9ed8\u8ba4\u5c31\u662f\u56fe\u50cf\u7684\u4e2d\u5fc3) scale: \u65cb\u8f6c\u540e\u56fe\u50cf\u7684\u7f29\u653e\u6bd4\u4f8b R [: 2 ] = cv2 . getRotationMatrix2D ( angle = a , center = ( 0 , 0 ), scale = s ) # Shear \u8bbe\u7f6e\u526a\u5207\u77e9\u9635 S = np . eye ( 3 ) # \u521d\u59cb\u5316T = [[1,0,0], [0,1,0], [0,0,1]] S [ 0 , 1 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # x shear (deg) S [ 1 , 0 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # y shear (deg) # Translation \u8bbe\u7f6e\u5e73\u79fb\u77e9\u9635 T = np . eye ( 3 ) # \u521d\u59cb\u5316T = [[1,0,0], [0,1,0], [0,0,1]] (3, 3) T [ 0 , 2 ] = ( random . uniform ( 0.5 - translate , 0.5 + translate ) * width ) # x translation (pixels) T [ 1 , 2 ] = ( random . uniform ( 0.5 - translate , 0.5 + translate ) * height ) # y translation (pixels) # Combined rotation matrix @ \u8868\u793a\u77e9\u9635\u4e58\u6cd5 \u751f\u6210\u4eff\u5c04\u53d8\u6362\u77e9\u9635M M = T @ S @ R @ P @ C # order of operations (right to left) is IMPORTANT # \u5c06\u4eff\u5c04\u53d8\u6362\u77e9\u9635M\u4f5c\u7528\u5728\u56fe\u7247\u4e0a if ( border [ 0 ] != 0 ) or ( border [ 1 ] != 0 ) or ( M != np . eye ( 3 )) . any (): # image changed if perspective : # \u900f\u89c6\u53d8\u6362\u51fd\u6570 \u5b9e\u73b0\u65cb\u8f6c\u5e73\u79fb\u7f29\u653e\u53d8\u6362\u540e\u7684\u5e73\u884c\u7ebf\u4e0d\u518d\u5e73\u884c # \u53c2\u6570\u548c\u4e0b\u9762warpAffine\u7c7b\u4f3c img = cv2 . warpPerspective ( img , M , dsize = ( width , height ), borderValue = ( 114 , 114 , 114 ) ) else : # \u4eff\u5c04\u53d8\u6362\u51fd\u6570 \u5b9e\u73b0\u65cb\u8f6c\u5e73\u79fb\u7f29\u653e\u53d8\u6362\u540e\u7684\u5e73\u884c\u7ebf\u4f9d\u65e7\u5e73\u884c # image changed img [1472, 1472, 3] => [736, 736, 3] # cv2.warpAffine: opencv\u5b9e\u73b0\u7684\u4eff\u5c04\u53d8\u6362\u51fd\u6570 # \u53c2\u6570\uff1a img: \u9700\u8981\u53d8\u5316\u7684\u56fe\u50cf M: \u53d8\u6362\u77e9\u9635 dsize: \u8f93\u51fa\u56fe\u50cf\u7684\u5927\u5c0f flags: \u63d2\u503c\u65b9\u6cd5\u7684\u7ec4\u5408\uff08int \u7c7b\u578b\uff01\uff09 # borderValue: \uff08\u91cd\u70b9\uff01\uff09\u8fb9\u754c\u586b\u5145\u503c \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5b83\u4e3a0\u3002 img = cv2 . warpAffine ( img , M [: 2 ], dsize = ( width , height ), borderValue = ( 114 , 114 , 114 ) ) # Visualize \u53ef\u89c6\u5316 # import matplotlib.pyplot as plt # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel() # ax[0].imshow(img[:, :, ::-1]) # base # ax[1].imshow(img2[:, :, ::-1]) # warped # Transform label coordinates # \u540c\u6837\u9700\u8981\u8c03\u6574\u6807\u7b7e\u4fe1\u606f n = len ( targets ) if n : # \u5224\u65ad\u662f\u5426\u53ef\u4ee5\u4f7f\u7528segment\u6807\u7b7e: \u53ea\u6709segments\u4e0d\u4e3a\u7a7a\u65f6\u5373\u6570\u636e\u96c6\u4e2d\u6709\u591a\u8fb9\u5f62gt\u4e5f\u6709\u6b63\u5e38gt\u65f6\u624d\u80fd\u4f7f\u7528segment\u6807\u7b7e use_segments=True # \u5426\u5219\u5982\u679c\u53ea\u6709\u6b63\u5e38gt\u65f6segments\u4e3a\u7a7a use_segments=False use_segments = any ( x . any () for x in segments ) new = np . zeros (( n , 4 )) # [n, 0+0+0+0] # \u5982\u679c\u4f7f\u7528\u7684\u662fsegments\u6807\u7b7e(\u6807\u7b7e\u4e2d\u542b\u6709\u591a\u8fb9\u5f62gt) if use_segments : # warp segments # \u5148\u5bf9segment\u6807\u7b7e\u8fdb\u884c\u91cd\u91c7\u6837 # \u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000) # [n, x1y2...x99y100] \u6269\u589e\u5750\u6807-> [n, 500, 2] # \u7531\u4e8e\u6709\u65cb\u8f6c\uff0c\u900f\u89c6\u53d8\u6362\u7b49\u64cd\u4f5c\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u591a\u8fb9\u5f62\u6240\u6709\u89d2\u70b9\u90fd\u8fdb\u884c\u53d8\u6362 segments = resample_segments ( segments ) for i , segment in enumerate ( segments ): # segment: [500, 2] \u591a\u8fb9\u5f62\u7684500\u4e2a\u70b9\u5750\u6807xy xy = np . ones (( len ( segment ), 3 )) # [1, 1+1+1] xy [:, : 2 ] = segment # [500, 2] # \u5bf9\u8be5\u6807\u7b7e\u591a\u8fb9\u5f62\u7684\u6240\u6709\u9876\u70b9\u5750\u6807\u8fdb\u884c\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362 xy = xy @ M . T # transform @\u8868\u793a\u77e9\u9635\u4e58\u6cd5\u8fd0\u7b97 xy = ( xy [:, : 2 ] / xy [:, 2 : 3 ] if perspective else xy [:, : 2 ] ) # perspective rescale or affine # \u6839\u636esegment\u7684\u5750\u6807\uff0c\u53d6xy\u5750\u6807\u7684\u6700\u5927\u6700\u5c0f\u503c\uff0c\u5f97\u5230\u8fb9\u6846\u7684\u5750\u6807 clip new [ i ] = segment2box ( xy , width , height ) # xy [500, 2] # \u4e0d\u4f7f\u7528segments\u6807\u7b7e \u4f7f\u7528\u6b63\u5e38\u7684\u77e9\u5f62\u7684\u6807\u7b7etargets else : # warp boxes # \u76f4\u63a5\u5bf9box\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362 # \u7531\u4e8e\u6709\u65cb\u8f6c\uff0c\u900f\u89c6\u53d8\u6362\u7b49\u64cd\u4f5c\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u56db\u4e2a\u89d2\u70b9\u90fd\u8fdb\u884c\u53d8\u6362 xy = np . ones (( n * 4 , 3 )) xy [:, : 2 ] = targets [:, [ 1 , 2 , 3 , 4 , 1 , 4 , 3 , 2 ]] . reshape ( n * 4 , 2 ) # x1y1, x2y2, x1y2, x2y1 xy = xy @ M . T # transform \u6bcf\u4e2a\u89d2\u70b9\u7684\u5750\u6807 xy = ( xy [:, : 2 ] / xy [:, 2 : 3 ] if perspective else xy [:, : 2 ]) . reshape ( n , 8 ) # perspective rescale or affine # create new boxes x = xy [:, [ 0 , 2 , 4 , 6 ]] y = xy [:, [ 1 , 3 , 5 , 7 ]] new = ( np . concatenate (( x . min ( 1 ), y . min ( 1 ), x . max ( 1 ), y . max ( 1 ))) . reshape ( 4 , n ) . T ) # clip \u53bb\u9664\u592a\u5c0f\u7684target(target\u5927\u90e8\u5206\u8dd1\u5230\u56fe\u5916\u53bb\u4e86) new [:, [ 0 , 2 ]] = new [:, [ 0 , 2 ]] . clip ( 0 , width ) new [:, [ 1 , 3 ]] = new [:, [ 1 , 3 ]] . clip ( 0 , height ) # filter candidates \u8fc7\u6ee4target \u7b5b\u9009box # \u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20 \u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236 # \u7b5b\u9009\u7ed3\u679c [n] \u5168\u662fTrue\u6216False \u4f7f\u7528\u6bd4\u5982: box1[i]\u5373\u53ef\u5f97\u5230i\u4e2d\u6240\u6709\u7b49\u4e8eTrue\u7684\u77e9\u5f62\u6846 False\u7684\u77e9\u5f62\u6846\u5168\u90e8\u5220\u9664 i = box_candidates ( box1 = targets [:, 1 : 5 ] . T * s , box2 = new . T , area_thr = 0.01 if use_segments else 0.10 , ) # \u5f97\u5230\u6240\u6709\u6ee1\u8db3\u6761\u4ef6\u7684targets targets = targets [ i ] targets [:, 1 : 5 ] = new [ i ] return img , targets \u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u4e8eload_mosaic\u4e2d\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e\u8fdb\u884c\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362\uff1a \u8fd9\u4e2a\u51fd\u6570\u7684\u53c2\u6570\u6765\u81eahyp\u4e2d\u76845\u4e2a\u53c2\u6570 2. box_candidates \u2003\u8fd9\u4e2a\u51fd\u6570\u7528\u5728random_perspective\u4e2d\uff0c\u662f\u5bf9\u900f\u89c6\u53d8\u6362\u540e\u7684\u56fe\u7247label\u8fdb\u884c\u7b5b\u9009\uff0c\u53bb\u9664\u88ab\u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u8fd8\u6709\u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20\uff0c\u4e14\u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236\u3002 box_candidates\u6a21\u5757\u4ee3\u7801\uff1a def box_candidates ( box1 , box2 , wh_thr = 2 , ar_thr = 20 , area_thr = 0.1 , eps = 1e-16 ): \"\"\"\u7528\u5728random_perspective\u4e2d \u5bf9\u900f\u89c6\u53d8\u6362\u540e\u7684\u56fe\u7247label\u8fdb\u884c\u7b5b\u9009 \u53bb\u9664\u88ab\u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u8fd8\u6709\u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20\uff0c\u4e14\u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236 Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio :params box1: [4, n] :params box2: [4, n] :params wh_thr: \u7b5b\u9009\u6761\u4ef6 \u5bbd\u9ad8\u9608\u503c :params ar_thr: \u7b5b\u9009\u6761\u4ef6 \u5bbd\u9ad8\u6bd4\u3001\u9ad8\u5bbd\u6bd4\u6700\u5927\u503c\u9608\u503c :params area_thr: \u7b5b\u9009\u6761\u4ef6 \u9762\u79ef\u9608\u503c :params eps: 1e-16 \u63a5\u8fd10\u7684\u6570 \u9632\u6b62\u5206\u6bcd\u4e3a0 :return i: \u7b5b\u9009\u7ed3\u679c [n] \u5168\u662fTrue\u6216False \u4f7f\u7528\u6bd4\u5982: box1[i]\u5373\u53ef\u5f97\u5230i\u4e2d\u6240\u6709\u7b49\u4e8eTrue\u7684\u77e9\u5f62\u6846 False\u7684\u77e9\u5f62\u6846\u5168\u90e8\u5220\u9664 \"\"\" w1 , h1 = box1 [ 2 ] - box1 [ 0 ], box1 [ 3 ] - box1 [ 1 ] # \u6c42\u51fa\u6240\u6709box1\u77e9\u5f62\u6846\u7684\u5bbd\u548c\u9ad8 [n] [n] w2 , h2 = box2 [ 2 ] - box2 [ 0 ], box2 [ 3 ] - box2 [ 1 ] # \u6c42\u51fa\u6240\u6709box2\u77e9\u5f62\u6846\u7684\u5bbd\u548c\u9ad8 [n] [n] ar = np . maximum ( w2 / ( h2 + eps ), h2 / ( w2 + eps )) # \u6c42\u51fa\u6240\u6709box2\u77e9\u5f62\u6846\u7684\u5bbd\u9ad8\u6bd4\u548c\u9ad8\u5bbd\u6bd4\u7684\u8f83\u5927\u8005 [n, 1] # \u7b5b\u9009\u6761\u4ef6: \u589e\u5f3a\u540ew\u3001h\u8981\u5927\u4e8e2 \u589e\u5f3a\u540e\u56fe\u50cf\u4e0e\u589e\u5f3a\u524d\u56fe\u50cf\u9762\u79ef\u6bd4\u503c\u5927\u4e8earea_thr \u5bbd\u9ad8\u6bd4\u5927\u4e8ear_thr return ( ( w2 > wh_thr ) & ( h2 > wh_thr ) & ( w2 * h2 / ( w1 * h1 + eps ) > area_thr ) & ( ar < ar_thr ) ) # candidates 3. replicate \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408\u3002\u53ef\u4ee5\u7528\u5728load_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d\uff0c \u4f5c\u8005\u9ed8\u8ba4\u662f\u5173\u95ed\u7684\uff0c \u81ea\u5df1\u53ef\u4ee5\u5b9e\u9a8c\u4e00\u4e0b\u6548\u679c\u3002 replicate\u6a21\u5757\u4ee3\u7801\uff1a def replicate ( img , labels ): \"\"\"\u53ef\u4ee5\u7528\u5728load_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d \u4f5c\u8005\u9ed8\u8ba4\u662f\u5173\u95ed\u7684 \u81ea\u5df1\u53ef\u4ee5\u5b9e\u9a8c\u4e00\u4e0b\u6548\u679c \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408 Replicate labels :params img: img4 \u56e0\u4e3a\u662f\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e \u6240\u4ee5size=[2*img_size, 2*img_size] :params labels: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u6b63\u5e38label\u6807\u7b7elabels4(\u4e0d\u6b63\u5e38\u7684\u4f1a\u901a\u8fc7segments2boxes\u5c06\u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u6b63\u5e38\u6807\u7b7e) [N, cls+xyxy] :return img: img4 size=[2*img_size, 2*img_size] \u4e0d\u8fc7\u56fe\u7247\u4e2d\u591a\u4e86\u4e00\u534a\u7684\u8f83\u5c0fgt\u4e2a\u6570 :params labels: labels4 \u4e0d\u8fc7\u53e6\u5916\u589e\u52a0\u4e86\u4e00\u534a\u7684\u8f83\u5c0flabel [3/2N, cls+xyxy] \"\"\" h , w = img . shape [: 2 ] # \u5f97\u5230\u56fe\u7247\u7684\u9ad8\u548c\u5bbd boxes = labels [:, 1 :] . astype ( int ) # \u5f97\u5230\u6240\u6709gt\u6846\u7684\u77e9\u5f62\u5750\u6807 xyxy [N, xyxy] x1 , y1 , x2 , y2 = boxes . T # \u5de6\u4e0a\u89d2: x1 y1 \u53f3\u4e0b\u89d2: x2 y2 [N] s = ( ( x2 - x1 ) + ( y2 - y1 ) ) / 2 # side length (pixels) [N] \u5f97\u5230N\u4e2agt\u7684 (w+h)/2 \u7528\u6765\u8861\u91cfgt\u6846\u7684\u5927\u5c0f # \u751f\u6210\u539f\u6807\u7b7e\u4e2a\u6570\u4e00\u534a\u7684\u65b0\u6807\u7b7e s.size\u8fd4\u56dendarray\u7684\u5143\u7d20\u6570\u91cf for i in s . argsort ()[: round ( s . size * 0.5 )]: # \u8fd4\u56de\u8f83\u5c0f(s\u8f83\u5c0f)\u7684\u4e00\u534agt\u6846\u7684index\u4fe1\u606f x1b , y1b , x2b , y2b = boxes [ i ] # \u5f97\u5230\u8fd9\u4e00\u534a\u8f83\u5c0fgt\u6846\u7684\u5750\u6807\u4fe1\u606f \u5de6\u4e0a\u89d2x1b y1b \u53f3\u4e0b\u89d2x2b y2b bh , bw = y2b - y1b , x2b - x1b # \u5f97\u5230\u8fd9\u4e00\u822c\u8f83\u5c0fgt\u6846\u7684\u9ad8\u5bbd\u4fe1\u606f # \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\u70b9 y\u8303\u56f4\u5728[0, \u56fe\u7247\u9ad8-gt\u6846\u9ad8] x\u8303\u56f4\u5728[0, \u56fe\u7247\u5bbd-gt\u6846\u5bbd] yc , xc = int ( random . uniform ( 0 , h - bh )), int ( random . uniform ( 0 , w - bw ) ) # offset x, y # \u91cd\u65b0\u751f\u6210\u8fd9\u4e00\u534a\u7684gt\u6846\u5750\u6807\u4fe1\u606f(\u504f\u79fb\u540e) x1a , y1a , x2a , y2a = [ xc , yc , xc + bw , yc + bh ] # \u5c06\u56fe\u7247\u4e2d\u771f\u5b9e\u7684gt\u6846\u504f\u79fb\u5230\u5bf9\u5e94\u751f\u6210\u7684\u5750\u6807(\u4e00\u534a\u8f83\u5c0f\u7684\u504f\u79fb \u8f83\u5927\u7684\u4e0d\u504f\u79fb) img [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] # append \u539f\u6765\u7684labels\u6807\u7b7e + \u504f\u79fb\u4e86\u7684\u6807\u7b7e labels = np . append ( labels , [[ labels [ i , 0 ], x1a , y1a , x2a , y2a ]], axis = 0 ) return img , labels \u4f1a\u7528\u5728load_mosaicload_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d\uff08\u4e00\u822c\u4f1a\u5173\u95ed \u5177\u4f53\u8fd8\u8981\u770b\u4e2a\u4eba\u5b9e\u9a8c\uff09 4. letterbox letterbox \u7684img\u8f6c\u6362\u90e8\u5206 \u2003\u6b64\u65f6\uff1aauto=False\uff08\u9700\u8981pad\uff09, scale_fill=False, scale_up=False\u3002 \u2003\u663e\u7136\uff0c\u8fd9\u90e8\u5206\u9700\u8981\u7f29\u653e\uff0c\u56e0\u4e3a\u5728\u8fd9\u4e4b\u524d\u7684load_image\u90e8\u5206\u5df2\u7ecf\u7f29\u653e\u8fc7\u4e86\uff08\u6700\u957f\u8fb9\u7b49\u4e8e\u6307\u5b9a\u5927\u5c0f\uff0c\u8f83\u77ed\u8fb9\u7b49\u6bd4\u4f8b\u7f29\u653e\uff09\uff0c \u90a3\u4e48\u5728letterbox\u53ea\u9700\u8981\u8ba1\u7b97\u51fa\u8f83\u5c0f\u8fb9\u9700\u8981\u586b\u5145\u7684pad, \u518d\u5c06\u8f83\u5c0f\u8fb9\u4e24\u8fb9pad\u5230\u76f8\u5e94\u5927\u5c0f\uff08\u6bcf\u4e2abatch\u9700\u8981\u6bcf\u5f20\u56fe\u7247\u7684\u5927\u5c0f\uff0c\u8fd9\u4e2a \u5927\u5c0f\u662f\u4e0d\u76f8\u540c\u7684\uff09\u5373\u53ef\u3002 \u4e5f\u53ef\u4ee5\u7ed3\u5408\u4e0b\u9762\u753b\u7684\u6d41\u7a0b\u56fe\u6765\u7406\u89e3\u4e0b\u9762\u7684letterbox\u4ee3\u7801\uff1a def letterbox ( img , new_shape = ( 640 , 640 ), color = ( 114 , 114 , 114 ), auto = True , scaleFill = False , scaleup = True , stride = 32 , ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u53ea\u5728val\u65f6\u624d\u4f1a\u4f7f\u7528 \u5c06\u56fe\u7247\u7f29\u653e\u8c03\u6574\u5230\u6307\u5b9a\u5927\u5c0f Resize and pad image while meeting stride-multiple constraints https://github.com/ultralytics/yolov3/issues/232 :param img: \u539f\u56fe hwc :param new_shape: \u7f29\u653e\u540e\u7684\u6700\u957f\u8fb9\u5927\u5c0f :param color: pad\u7684\u989c\u8272 :param auto: True \u4fdd\u8bc1\u7f29\u653e\u540e\u7684\u56fe\u7247\u4fdd\u6301\u539f\u56fe\u7684\u6bd4\u4f8b \u5373 \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e\uff08\u4e0d\u4f1a\u5931\u771f\uff09 False \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e,\u6700\u540e\u5c06\u8f83\u77ed\u8fb9\u4e24\u8fb9pad\u64cd\u4f5c\u7f29\u653e\u5230\u6700\u957f\u8fb9\u5927\u5c0f\uff08\u4e0d\u4f1a\u5931\u771f\uff09 :param scale_fill: True \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u539f\u56feresize\u5230\u6307\u5b9a\u7684\u5927\u5c0f \u76f8\u5f53\u4e8e\u5c31\u662fresize \u6ca1\u6709pad\u64cd\u4f5c\uff08\u5931\u771f\uff09 :param scale_up: True \u5bf9\u4e8e\u5c0f\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5927\u4e8e\u7684\u4e0d\u53d8 False \u5bf9\u4e8e\u5927\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8e\u7684\u4e0d\u53d8 :return: img: letterbox\u540e\u7684\u56fe\u7247 HWC ratio: wh ratios (dw, dh): w\u548ch\u7684pad \"\"\" shape = img . shape [: 2 ] # \u7b2c\u4e00\u5c42resize\u540e\u56fe\u7247\u5927\u5c0f[h, w] = [343, 512] if isinstance ( new_shape , int ): new_shape = ( new_shape , new_shape ) # (512, 512) # scale ratio (new / old) 1.024 new_shape=(384, 512) r = min ( new_shape [ 0 ] / shape [ 0 ], new_shape [ 1 ] / shape [ 1 ]) # r=1 # \u53ea\u8fdb\u884c\u4e0b\u91c7\u6837 \u56e0\u4e3a\u4e0a\u91c7\u6837\u4f1a\u8ba9\u56fe\u7247\u6a21\u7cca # (for better test mAP) scale_up = False \u5bf9\u4e8e\u5927\u4e8enew_shape\uff08r<1\uff09\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8enew_shape\uff08r>1\uff09\u7684\u4e0d\u53d8 if not scaleup : # only scale down, do not scale up (for better test mAP) r = min ( r , 1.0 ) # Compute padding ratio = r , r # width, height ratios (1, 1) new_unpad = int ( round ( shape [ 1 ] * r )), int ( round ( shape [ 0 ] * r ) ) # wh(512, 343) \u4fdd\u8bc1\u7f29\u653e\u540e\u56fe\u50cf\u6bd4\u4f8b\u4e0d\u53d8 dw , dh = ( new_shape [ 1 ] - new_unpad [ 0 ], new_shape [ 0 ] - new_unpad [ 1 ], ) # wh padding dw=0 dh=41 if auto : # minimum rectangle \u4fdd\u8bc1\u539f\u56fe\u6bd4\u4f8b\u4e0d\u53d8\uff0c\u5c06\u56fe\u50cf\u6700\u5927\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f # \u8fd9\u91cc\u7684\u53d6\u4f59\u64cd\u4f5c\u53ef\u4ee5\u4fdd\u8bc1padding\u540e\u7684\u56fe\u7247\u662f32\u7684\u6574\u6570\u500d(416x416)\uff0c\u5982\u679c\u662f(512x512)\u53ef\u4ee5\u4fdd\u8bc1\u662f64\u7684\u6574\u6570\u500d dw , dh = np . mod ( dw , stride ), np . mod ( dh , stride ) # wh padding dw=0 dh=0 elif scaleFill : # stretch \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u56fe\u7247\u7f29\u653e\u5230\u6307\u5b9a\u5c3a\u5bf8 dw , dh = 0.0 , 0.0 new_unpad = ( new_shape [ 1 ], new_shape [ 0 ]) ratio = new_shape [ 1 ] / shape [ 1 ], new_shape [ 0 ] / shape [ 0 ] # width, height ratios # \u5728\u8f83\u5c0f\u8fb9\u7684\u4e24\u4fa7\u8fdb\u884cpad, \u800c\u4e0d\u662f\u5728\u4e00\u4fa7pad dw /= 2 # divide padding into 2 sides \u5c06padding\u5206\u5230\u4e0a\u4e0b\uff0c\u5de6\u53f3\u4e24\u4fa7 dw=0 dh /= 2 # dh=20.5 # shape:[h, w] new_unpad:[w, h] if shape [:: - 1 ] != new_unpad : # resize \u5c06\u539f\u56feresize\u5230new_unpad\uff08\u957f\u8fb9\u76f8\u540c\uff0c\u6bd4\u4f8b\u76f8\u540c\u7684\u65b0\u56fe\uff09 img = cv2 . resize ( img , new_unpad , interpolation = cv2 . INTER_LINEAR ) top , bottom = int ( round ( dh - 0.1 )), int ( round ( dh + 0.1 ) ) # \u8ba1\u7b97\u4e0a\u4e0b\u4e24\u4fa7\u7684padding # top=20 bottom=21 left , right = int ( round ( dw - 0.1 )), int ( round ( dw + 0.1 ) ) # \u8ba1\u7b97\u5de6\u53f3\u4e24\u4fa7\u7684padding # left=0 right=0 # add border/pad img = cv2 . copyMakeBorder ( img , top , bottom , left , right , cv2 . BORDER_CONSTANT , value = color ) # add border # img: (384, 512, 3) ratio=(1.0,1.0) \u8fd9\u91cc\u6ca1\u6709\u7f29\u653e\u64cd\u4f5c (dw,dh)=(0.0, 20.5) return img , ratio , ( dw , dh ) \u603b\u7ed3\u4e0b\u5728val\u65f6\u8fd9\u91cc\u4e3b\u8981\u662f\u505a\u4e86\u4e09\u4ef6\u4e8b\uff1a load_image\u5c06\u56fe\u7247\u4ece\u6587\u4ef6\u4e2d\u52a0\u8f7d\u51fa\u6765\uff0c\u5e76resize\u5230\u76f8\u5e94\u7684\u5c3a\u5bf8\uff08\u6700\u957f\u8fb9\u7b49\u4e8e\u6211\u4eec\u9700\u8981\u7684\u5c3a\u5bf8\uff0c\u6700\u77ed\u8fb9\u7b49\u6bd4\u4f8b\u7f29\u653e\uff09\uff1b letterbox\u5c06\u4e4b\u524dresize\u540e\u7684\u56fe\u7247\u518dpad\u5230\u6211\u4eec\u6240\u9700\u8981\u7684\u653e\u5230dataloader\u4e2d\uff08collate_fn\u51fd\u6570\uff09\u7684\u5c3a\u5bf8\uff08\u77e9\u5f62\u8bad\u7ec3\u8981\u6c42\u540c\u4e00\u4e2a batch\u4e2d\u7684\u56fe\u7247\u7684\u5c3a\u5bf8\u5fc5\u987b\u4fdd\u6301\u4e00\u81f4\uff09\uff1b \u5c06label\u4ece\u76f8\u5bf9\u539f\u56fe\u5c3a\u5bf8\uff08\u539f\u6587\u4ef6\u4e2d\u56fe\u7247\u5c3a\u5bf8\uff09\u7f29\u653e\u5230\u76f8\u5bf9letterbox pad\u540e\u7684\u56fe\u7247\u5c3a\u5bf8\u3002\u56e0\u4e3a\u524d\u4e24\u90e8\u5206\u7684\u56fe\u7247\u5c3a\u5bf8\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u540c\u6837\u7684\u6211\u4eec\u7684label\u4e5f\u9700\u8981\u53d1\u751f\u76f8\u5e94\u7684\u53d8\u5316\u3002 5. cutout \u2003 cutout\u6570\u636e\u589e\u5f3a\uff0c\u7ed9\u56fe\u7247\u968f\u673a\u6dfb\u52a0\u968f\u673a\u5927\u5c0f\u7684\u65b9\u5757\u566a\u58f0 \uff0c\u76ee\u7684\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002\u6e90\u81ea\u8bba\u6587\uff1a Improved Regularization of Convolutional Neural Networks with Cutout \u3002 \u2003\u66f4\u591a\u539f\u7406\u7ec6\u8282\u8bf7\u53c2\u9605\uff1a mosaic \u89e3\u8bfb , \u3010YOLO v4\u3011\u3010trick 8\u3011Data augmentation: MixUp\u3001Random Erasing\u3001CutOut\u3001CutMix\u3001Mosic\u3002 \u2003 \u5177\u4f53\u8981\u4e0d\u8981\u4f7f\u7528\uff0c\u6982\u7387\u662f\u591a\u5c11\u53ef\u4ee5\u81ea\u5df1\u5b9e\u9a8c\u3002 cutout\u6a21\u5757\u4ee3\u7801\uff1a def cutout ( image , labels ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884ccutout\u589e\u5f3a v5\u6e90\u7801\u4f5c\u8005\u9ed8\u8ba4\u662f\u6ca1\u7528\u7528\u8fd9\u4e2a\u7684 \u611f\u5174\u8da3\u7684\u53ef\u4ee5\u6d4b\u8bd5\u4e00\u4e0b cutout\u6570\u636e\u589e\u5f3a, \u7ed9\u56fe\u7247\u968f\u673a\u6dfb\u52a0\u968f\u673a\u5927\u5c0f\u7684\u65b9\u5757\u566a\u58f0 \u76ee\u7684\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027 \u5b9e\u73b0\uff1a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u6b63\u65b9\u5f62\u533a\u57df\uff0c\u7136\u540e\u91c7\u7528\u51680\u586b\u5145\u5c31OK\u4e86\uff0c\u5f53\u7136\u4e3a\u4e86\u907f\u514d\u586b\u51450\u503c\u5bf9\u8bad\u7ec3\u7684\u5f71\u54cd\uff0c\u5e94\u8be5\u8981\u5bf9\u6570\u636e\u8fdb\u884c\u4e2d\u5fc3\u5f52\u4e00\u5316\u64cd\u4f5c\uff0cnorm\u52300\u3002 \u8bba\u6587: https://arxiv.org/abs/1708.04552 :params image: \u4e00\u5f20\u56fe\u7247 [640, 640, 3] numpy :params labels: \u8fd9\u5f20\u56fe\u7247\u7684\u6807\u7b7e [N, 5]=[N, cls+x1y1x2y2] :return labels: \u7b5b\u9009\u540e\u7684\u8fd9\u5f20\u56fe\u7247\u7684\u6807\u7b7e [M, 5]=[M, cls+x1y1x2y2] M<N \u7b5b\u9009: \u5982\u679c\u968f\u673a\u751f\u6210\u7684\u566a\u58f0\u548c\u539f\u59cbF\u7684gt\u6846\u76f8\u4ea4\u533a\u57df\u5360gt\u6846\u592a\u5927 \u5c31\u7b5b\u51fa\u8fd9\u4e2agt\u6846label \"\"\" h , w = image . shape [: 2 ] # \u83b7\u53d6\u56fe\u7247\u9ad8\u548c\u5bbd def bbox_ioa ( box1 , box2 ): \"\"\"\u7528\u5728cutout\u4e2d \u8ba1\u7b97box1\u548cbox2\u76f8\u4ea4\u9762\u79ef\u4e0ebox2\u9762\u79ef\u7684\u6bd4\u4f8b Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2 :params box1: \u4f20\u5165\u968f\u673a\u751f\u6210\u566a\u58f0 box [4] = [x1y1x2y2] :params box2: \u4f20\u5165\u56fe\u7247\u539f\u59cb\u7684label\u4fe1\u606f [n, 4] = [n, x1y1x2y2] :return [n, 1] \u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u7684\u566a\u58f0box\u4e0en\u4e2a\u539f\u59cblabel\u7684\u76f8\u4ea4\u9762\u79ef\u4e0eb\u539f\u59cblabel\u7684\u6bd4\u503c \"\"\" box2 = box2 . transpose () # Get the coordinates of bounding boxes b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 [ 0 ], box1 [ 1 ], box1 [ 2 ], box1 [ 3 ] b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 [ 0 ], box2 [ 1 ], box2 [ 2 ], box2 [ 3 ] # \u6c42box1\u548cbox2\u7684\u76f8\u4ea4\u9762\u79ef inter_area = ( np . minimum ( b1_x2 , b2_x2 ) - np . maximum ( b1_x1 , b2_x1 )) . clip ( 0 ) * \\ ( np . minimum ( b1_y2 , b2_y2 ) - np . maximum ( b1_y1 , b2_y1 )) . clip ( 0 ) # box\u9762\u79ef box2_area = ( b2_x2 - b2_x1 ) * ( b2_y2 - b2_y1 ) + 1e-16 # \u8fd4\u56debox1\u548cbox2\u76f8\u4ea4\u9762\u79ef \u4e0e box2\u9762\u79ef\u4e4b\u6bd4 return inter_area / box2_area # \u8bbe\u7f6ecutout\u6dfb\u52a0\u566a\u58f0\u7684scale create random masks scales = [ 0.5 ] * 1 + [ 0.25 ] * 2 + [ 0.125 ] * 4 + [ 0.0625 ] * 8 + [ 0.03125 ] * 16 # image size fraction for s in scales : # \u968f\u673a\u751f\u6210\u566a\u58f0 \u5bbd\u9ad8 mask_h = random . randint ( 1 , int ( h * s )) mask_w = random . randint ( 1 , int ( w * s )) # \u968f\u673a\u751f\u6210\u566a\u58f0 box xmin = max ( 0 , random . randint ( 0 , w ) - mask_w // 2 ) ymin = max ( 0 , random . randint ( 0 , h ) - mask_h // 2 ) xmax = min ( w , xmin + mask_w ) ymax = min ( h , ymin + mask_h ) # \u6dfb\u52a0\u968f\u673a\u989c\u8272\u7684\u566a\u58f0 apply random color mask image [ ymin : ymax , xmin : xmax ] = [ random . randint ( 64 , 191 ) for _ in range ( 3 )] # \u8fd4\u56de\u6ca1\u6709\u566a\u58f0\u7684label return unobscured labels if len ( labels ) and s > 0.03 : box = np . array ([ xmin , ymin , xmax , ymax ], dtype = np . float32 ) # \u968f\u673a\u751f\u6210\u7684\u566a\u58f0box # \u8ba1\u7b97\u751f\u6210\u7684\u4e00\u4e2a\u566a\u58f0box\u4e0e\u8fd9\u5f20\u56fe\u7247\u4e2d\u6240\u6709gt\u7684box\u505a\u8ba1\u7b97 inter_area/label_area [n, 1] ioa = bbox_ioa ( box , labels [:, 1 : 5 ]) # remove>60% obscured labels \u4e0d\u80fd\u5207\u7684\u592a\u5927 ioa < 0.60 \u4fdd\u7559cutout\u566a\u58f0\u906e\u6321\u5c0f\u4e8e60%\u7684\u6807\u7b7e labels = labels [ ioa < 0.60 ] return labels \u6ce8\u610f\uff1a 1. \u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884ccutout\u589e\u5f3a\uff1a mixup\u589e\u5f3a\u7531\u8d85\u53c2hyp[\u2018mixup\u2019]\u63a7\u5236\uff0c0\u5219\u5173\u95ed \u9ed8\u8ba4\u4e3a1\u5219100%\u6253\u5f00\uff08\u81ea\u5df1\u5b9e\u9a8c\u5224\u65ad\uff09\uff1a 6. mixup \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u8fdb\u884cmixup\u6570\u636e\u589e\u5f3a\uff1a\u6309\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247\u3002\u8bba\u6587\uff1a https://arxiv.org/pdf/1710.09412.pdf \u3002 \u2003\u66f4\u591a\u539f\u7406\u7ec6\u8282\u8bf7\u770b\u535a\u5ba2\uff1a \u3010YOLO v4\u3011\u3010trick 8\u3011Data augmentation: MixUp\u3001Random Erasing\u3001CutOut\u3001CutMix\u3001Mosic \u3002 \u2003\u5177\u4f53\u8981\u4e0d\u8981\u4f7f\u7528\uff0c\u6982\u7387\u662f\u591a\u5c11\u53ef\u4ee5\u81ea\u5df1\u5b9e\u9a8c\u3002 mixup\u6a21\u5757\u4ee3\u7801\uff1a def mixup ( im , labels , im2 , labels2 ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884cmixup\u589e\u5f3a mixup\u6570\u636e\u589e\u5f3a, \u6309\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247 Applies MixUp augmentation \u8bba\u6587: https://arxiv.org/pdf/1710.09412.pdf :params im:\u56fe\u72471 numpy (640, 640, 3) :params labels:[N, 5]=[N, cls+x1y1x2y2] :params im2:\u56fe\u72472 (640, 640, 3) :params labels2:[M, 5]=[M, cls+x1y1x2y2] :return img: \u4e24\u5f20\u56fe\u7247mixup\u589e\u5f3a\u540e\u7684\u56fe\u7247 (640, 640, 3) :return labels: \u4e24\u5f20\u56fe\u7247mixup\u589e\u5f3a\u540e\u7684label\u6807\u7b7e [M+N, cls+x1y1x2y2] \"\"\" # \u968f\u673a\u4ecebeta\u5206\u5e03\u4e2d\u83b7\u53d6\u6bd4\u4f8b,range[0, 1] r = np . random . beta ( 32.0 , 32.0 ) # mixup ratio, alpha=beta=32.0 # \u6309\u7167\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247 im = ( im * r + im2 * ( 1 - r )) . astype ( np . uint8 ) # \u5c06\u4e24\u5f20\u56fe\u7247\u6807\u7b7e\u62fc\u63a5\u5230\u4e00\u8d77 labels = np . concatenate (( labels , labels2 ), 0 ) return im , labels \u6ce8\u610f: - \u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884cmixup\u589e\u5f3a\uff1a - mixup\u589e\u5f3a\u7531\u8d85\u53c2hyp[\"mixup\"]\u63a7\u5236\uff0c0\u5219\u5173\u95ed \u9ed8\u8ba4\u4e3a1\u5219100%\u6253\u5f00\uff08\u81ea\u5df1\u5b9e\u9a8c\u5224\u65ad\uff09 7. hist_equalize \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u4e8e\u5bf9\u56fe\u7247\u8fdb\u884c\u76f4\u65b9\u56fe\u5747\u8861\u5316\u5904\u7406\uff0c\u4f46\u662f\u5728yolov5\u4e2d\u5e76\u6ca1\u6709\u7528\u5230\u6309\u8fd9\u4e2a\u51fd\u6570\uff0c\u5b66\u4e60\u4e86\u89e3\u4e0b\u5c31\u597d\uff0c\u4e0d\u662f\u91cd\u70b9\u3002 hist_equalize\u6a21\u5757\u4ee3\u7801: def hist_equalize ( img , clahe = True , bgr = False ): \"\"\"yolov5\u5e76\u6ca1\u6709\u4f7f\u7528\u76f4\u65b9\u56fe\u5747\u8861\u5316\u7684\u589e\u5f3a\u64cd\u4f5c \u53ef\u4ee5\u81ea\u5df1\u8bd5\u8bd5 \u76f4\u65b9\u56fe\u5747\u8861\u5316\u589e\u5f3a\u64cd\u4f5c Equalize histogram on BGR image 'img' with img.shape(n,m,3) and range 0-255 :params img: \u8981\u8fdb\u884c\u76f4\u65b9\u56fe\u5747\u8861\u5316\u7684\u539f\u56fe :params clahe: \u662f\u5426\u8981\u751f\u6210\u81ea\u9002\u5e94\u5747\u8861\u5316\u56fe\u7247 \u9ed8\u8ba4True \u5982\u679c\u662fFalse\u5c31\u751f\u6210\u5168\u5c40\u5747\u8861\u5316\u56fe\u7247 :params bgr: \u4f20\u5165\u7684img\u56fe\u50cf\u662f\u5426\u662fbgr\u56fe\u7247 \u9ed8\u8ba4False :return img: \u5747\u8861\u5316\u4e4b\u540e\u7684\u56fe\u7247 \u5927\u5c0f\u4e0d\u53d8 \u683c\u5f0fRGB \"\"\" # \u56fe\u7247BGR/RGB\u683c\u5f0f -> YUV\u683c\u5f0f yuv = cv2 . cvtColor ( img , cv2 . COLOR_BGR2YUV if bgr else cv2 . COLOR_RGB2YUV ) if clahe : # cv2.createCLAHE\u751f\u6210\u81ea\u9002\u5e94\u5747\u8861\u5316\u56fe\u50cf c = cv2 . createCLAHE ( clipLimit = 2.0 , tileGridSize = ( 8 , 8 )) yuv [:, :, 0 ] = c . apply ( yuv [:, :, 0 ]) else : # \u5168\u5c40\u5747\u8861\u5316 yuv [:, :, 0 ] = cv2 . equalizeHist ( yuv [:, :, 0 ]) # equalize Y channel histogram return cv2 . cvtColor ( yuv , cv2 . COLOR_YUV2BGR if bgr else cv2 . COLOR_YUV2RGB ) # convert YUV image to RGB Reference \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011 atasets.py","title":"augmentations_py"},{"location":"source_code_interpretation/utils/augmentations_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/augmentations.py","title":"\u524d\u8a00"},{"location":"source_code_interpretation/utils/augmentations_py.html#1-random_perspective","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c \u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size\u3002 random_perspective\u51fd\u6570\u4ee3\u7801\uff1a def random_perspective ( img , targets = (), segments = (), degrees = 10 , translate = 0.1 , scale = 0.1 , shear = 10 , perspective = 0.0 , border = ( 0 , 0 ), ): \"\"\"\u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u4e8eload_mosaic\u4e2d\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e \u968f\u673a\u900f\u89c6\u53d8\u6362 \u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size :params img: mosaic\u6574\u5408\u540e\u7684\u56fe\u7247img4 [2*img_size, 2*img_size] \u5982\u679cmosaic\u540e\u7684\u56fe\u7247\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e segments\u4e3a\u7a7a \u5982\u679c\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e\u5219 segments\u4e0d\u4e3a\u7a7a\u3002 :params targets: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u6b63\u5e38label\u6807\u7b7elabels4(\u4e0d\u6b63\u5e38\u7684\u4f1a\u901a\u8fc7segments2boxes\u5c06\u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u6b63\u5e38\u6807\u7b7e) [N, cls+xyxy] :params segments: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u4e0d\u6b63\u5e38label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62\u4e5f\u5305\u542b\u6b63\u5e38gt) [m, x1y1....] :params degrees: \u65cb\u8f6c\u548c\u7f29\u653e\u77e9\u9635\u53c2\u6570 :params translate: \u5e73\u79fb\u77e9\u9635\u53c2\u6570 :params scale: \u7f29\u653e\u77e9\u9635\u53c2\u6570 :params shear: \u526a\u5207\u77e9\u9635\u53c2\u6570 :params perspective: \u900f\u89c6\u53d8\u6362\u53c2\u6570 :params border: \u7528\u4e8e\u786e\u5b9a\u6700\u540e\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f \u4e00\u822c\u7b49\u4e8e[-img_size//2, -img_size//2] \u90a3\u4e48\u6700\u540e\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f\u4e3a [img_size, img_size] :return img: \u901a\u8fc7\u900f\u89c6\u53d8\u6362/\u4eff\u5c04\u53d8\u6362\u540e\u7684img [img_size, img_size] :return targets: \u901a\u8fc7\u900f\u89c6\u53d8\u6362/\u4eff\u5c04\u53d8\u6362\u540e\u7684img\u5bf9\u5e94\u7684\u6807\u7b7e [n, cls+x1y1x2y2] (\u901a\u8fc7\u7b5b\u9009\u540e\u7684) \"\"\" # \u8bbe\u5b9a\u8f93\u51fa\u56fe\u7247\u7684 H W # border=-s // 2 \u6240\u4ee5\u6700\u540e\u56fe\u7247\u7684\u5927\u5c0f\u76f4\u63a5\u51cf\u534a [img_size, img_size, 3] height = img . shape [ 0 ] + border [ 0 ] * 2 # # \u6700\u7ec8\u8f93\u51fa\u56fe\u50cf\u7684H width = img . shape [ 1 ] + border [ 1 ] * 2 # \u6700\u7ec8\u8f93\u51fa\u56fe\u50cf\u7684W # ============================ \u5f00\u59cb\u53d8\u6362 ============================= # \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5176\u5b9eopencv\u662f\u5b9e\u73b0\u4e86\u4eff\u5c04\u53d8\u6362\u7684, \u4e0d\u8fc7\u6211\u4eec\u8981\u5148\u751f\u6210\u4eff\u5c04\u53d8\u6362\u77e9\u9635M # Center \u8bbe\u7f6e\u4e2d\u5fc3\u5e73\u79fb\u77e9\u9635 C = np . eye ( 3 ) C [ 0 , 2 ] = - img . shape [ 1 ] / 2 # x translation (pixels) C [ 1 , 2 ] = - img . shape [ 0 ] / 2 # y translation (pixels) # Perspective \u8bbe\u7f6e\u900f\u89c6\u53d8\u6362\u77e9\u9635 P = np . eye ( 3 ) P [ 2 , 0 ] = random . uniform ( - perspective , perspective ) # x perspective (about y) P [ 2 , 1 ] = random . uniform ( - perspective , perspective ) # y perspective (about x) # Rotation and Scale \u8bbe\u7f6e\u65cb\u8f6c\u548c\u7f29\u653e\u77e9\u9635 R = np . eye ( 3 ) # \u521d\u59cb\u5316R = [[1,0,0], [0,1,0], [0,0,1]] (3, 3) # a: \u968f\u673a\u751f\u6210\u65cb\u8f6c\u89d2\u5ea6 \u8303\u56f4\u5728(-degrees, degrees) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations a = random . uniform ( - degrees , degrees ) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations # s: \u968f\u673a\u751f\u6210\u65cb\u8f6c\u540e\u56fe\u50cf\u7684\u7f29\u653e\u6bd4\u4f8b \u8303\u56f4\u5728(1 - scale, 1 + scale) # s = 2 ** random.uniform(-scale, scale) s = random . uniform ( 1 - scale , 1 + scale ) # s = 2 ** random.uniform(-scale, scale) # cv2.getRotationMatrix2D: \u4e8c\u7ef4\u65cb\u8f6c\u7f29\u653e\u51fd\u6570 # \u53c2\u6570 angle:\u65cb\u8f6c\u89d2\u5ea6 center: \u65cb\u8f6c\u4e2d\u5fc3(\u9ed8\u8ba4\u5c31\u662f\u56fe\u50cf\u7684\u4e2d\u5fc3) scale: \u65cb\u8f6c\u540e\u56fe\u50cf\u7684\u7f29\u653e\u6bd4\u4f8b R [: 2 ] = cv2 . getRotationMatrix2D ( angle = a , center = ( 0 , 0 ), scale = s ) # Shear \u8bbe\u7f6e\u526a\u5207\u77e9\u9635 S = np . eye ( 3 ) # \u521d\u59cb\u5316T = [[1,0,0], [0,1,0], [0,0,1]] S [ 0 , 1 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # x shear (deg) S [ 1 , 0 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # y shear (deg) # Translation \u8bbe\u7f6e\u5e73\u79fb\u77e9\u9635 T = np . eye ( 3 ) # \u521d\u59cb\u5316T = [[1,0,0], [0,1,0], [0,0,1]] (3, 3) T [ 0 , 2 ] = ( random . uniform ( 0.5 - translate , 0.5 + translate ) * width ) # x translation (pixels) T [ 1 , 2 ] = ( random . uniform ( 0.5 - translate , 0.5 + translate ) * height ) # y translation (pixels) # Combined rotation matrix @ \u8868\u793a\u77e9\u9635\u4e58\u6cd5 \u751f\u6210\u4eff\u5c04\u53d8\u6362\u77e9\u9635M M = T @ S @ R @ P @ C # order of operations (right to left) is IMPORTANT # \u5c06\u4eff\u5c04\u53d8\u6362\u77e9\u9635M\u4f5c\u7528\u5728\u56fe\u7247\u4e0a if ( border [ 0 ] != 0 ) or ( border [ 1 ] != 0 ) or ( M != np . eye ( 3 )) . any (): # image changed if perspective : # \u900f\u89c6\u53d8\u6362\u51fd\u6570 \u5b9e\u73b0\u65cb\u8f6c\u5e73\u79fb\u7f29\u653e\u53d8\u6362\u540e\u7684\u5e73\u884c\u7ebf\u4e0d\u518d\u5e73\u884c # \u53c2\u6570\u548c\u4e0b\u9762warpAffine\u7c7b\u4f3c img = cv2 . warpPerspective ( img , M , dsize = ( width , height ), borderValue = ( 114 , 114 , 114 ) ) else : # \u4eff\u5c04\u53d8\u6362\u51fd\u6570 \u5b9e\u73b0\u65cb\u8f6c\u5e73\u79fb\u7f29\u653e\u53d8\u6362\u540e\u7684\u5e73\u884c\u7ebf\u4f9d\u65e7\u5e73\u884c # image changed img [1472, 1472, 3] => [736, 736, 3] # cv2.warpAffine: opencv\u5b9e\u73b0\u7684\u4eff\u5c04\u53d8\u6362\u51fd\u6570 # \u53c2\u6570\uff1a img: \u9700\u8981\u53d8\u5316\u7684\u56fe\u50cf M: \u53d8\u6362\u77e9\u9635 dsize: \u8f93\u51fa\u56fe\u50cf\u7684\u5927\u5c0f flags: \u63d2\u503c\u65b9\u6cd5\u7684\u7ec4\u5408\uff08int \u7c7b\u578b\uff01\uff09 # borderValue: \uff08\u91cd\u70b9\uff01\uff09\u8fb9\u754c\u586b\u5145\u503c \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5b83\u4e3a0\u3002 img = cv2 . warpAffine ( img , M [: 2 ], dsize = ( width , height ), borderValue = ( 114 , 114 , 114 ) ) # Visualize \u53ef\u89c6\u5316 # import matplotlib.pyplot as plt # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel() # ax[0].imshow(img[:, :, ::-1]) # base # ax[1].imshow(img2[:, :, ::-1]) # warped # Transform label coordinates # \u540c\u6837\u9700\u8981\u8c03\u6574\u6807\u7b7e\u4fe1\u606f n = len ( targets ) if n : # \u5224\u65ad\u662f\u5426\u53ef\u4ee5\u4f7f\u7528segment\u6807\u7b7e: \u53ea\u6709segments\u4e0d\u4e3a\u7a7a\u65f6\u5373\u6570\u636e\u96c6\u4e2d\u6709\u591a\u8fb9\u5f62gt\u4e5f\u6709\u6b63\u5e38gt\u65f6\u624d\u80fd\u4f7f\u7528segment\u6807\u7b7e use_segments=True # \u5426\u5219\u5982\u679c\u53ea\u6709\u6b63\u5e38gt\u65f6segments\u4e3a\u7a7a use_segments=False use_segments = any ( x . any () for x in segments ) new = np . zeros (( n , 4 )) # [n, 0+0+0+0] # \u5982\u679c\u4f7f\u7528\u7684\u662fsegments\u6807\u7b7e(\u6807\u7b7e\u4e2d\u542b\u6709\u591a\u8fb9\u5f62gt) if use_segments : # warp segments # \u5148\u5bf9segment\u6807\u7b7e\u8fdb\u884c\u91cd\u91c7\u6837 # \u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000) # [n, x1y2...x99y100] \u6269\u589e\u5750\u6807-> [n, 500, 2] # \u7531\u4e8e\u6709\u65cb\u8f6c\uff0c\u900f\u89c6\u53d8\u6362\u7b49\u64cd\u4f5c\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u591a\u8fb9\u5f62\u6240\u6709\u89d2\u70b9\u90fd\u8fdb\u884c\u53d8\u6362 segments = resample_segments ( segments ) for i , segment in enumerate ( segments ): # segment: [500, 2] \u591a\u8fb9\u5f62\u7684500\u4e2a\u70b9\u5750\u6807xy xy = np . ones (( len ( segment ), 3 )) # [1, 1+1+1] xy [:, : 2 ] = segment # [500, 2] # \u5bf9\u8be5\u6807\u7b7e\u591a\u8fb9\u5f62\u7684\u6240\u6709\u9876\u70b9\u5750\u6807\u8fdb\u884c\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362 xy = xy @ M . T # transform @\u8868\u793a\u77e9\u9635\u4e58\u6cd5\u8fd0\u7b97 xy = ( xy [:, : 2 ] / xy [:, 2 : 3 ] if perspective else xy [:, : 2 ] ) # perspective rescale or affine # \u6839\u636esegment\u7684\u5750\u6807\uff0c\u53d6xy\u5750\u6807\u7684\u6700\u5927\u6700\u5c0f\u503c\uff0c\u5f97\u5230\u8fb9\u6846\u7684\u5750\u6807 clip new [ i ] = segment2box ( xy , width , height ) # xy [500, 2] # \u4e0d\u4f7f\u7528segments\u6807\u7b7e \u4f7f\u7528\u6b63\u5e38\u7684\u77e9\u5f62\u7684\u6807\u7b7etargets else : # warp boxes # \u76f4\u63a5\u5bf9box\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362 # \u7531\u4e8e\u6709\u65cb\u8f6c\uff0c\u900f\u89c6\u53d8\u6362\u7b49\u64cd\u4f5c\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u56db\u4e2a\u89d2\u70b9\u90fd\u8fdb\u884c\u53d8\u6362 xy = np . ones (( n * 4 , 3 )) xy [:, : 2 ] = targets [:, [ 1 , 2 , 3 , 4 , 1 , 4 , 3 , 2 ]] . reshape ( n * 4 , 2 ) # x1y1, x2y2, x1y2, x2y1 xy = xy @ M . T # transform \u6bcf\u4e2a\u89d2\u70b9\u7684\u5750\u6807 xy = ( xy [:, : 2 ] / xy [:, 2 : 3 ] if perspective else xy [:, : 2 ]) . reshape ( n , 8 ) # perspective rescale or affine # create new boxes x = xy [:, [ 0 , 2 , 4 , 6 ]] y = xy [:, [ 1 , 3 , 5 , 7 ]] new = ( np . concatenate (( x . min ( 1 ), y . min ( 1 ), x . max ( 1 ), y . max ( 1 ))) . reshape ( 4 , n ) . T ) # clip \u53bb\u9664\u592a\u5c0f\u7684target(target\u5927\u90e8\u5206\u8dd1\u5230\u56fe\u5916\u53bb\u4e86) new [:, [ 0 , 2 ]] = new [:, [ 0 , 2 ]] . clip ( 0 , width ) new [:, [ 1 , 3 ]] = new [:, [ 1 , 3 ]] . clip ( 0 , height ) # filter candidates \u8fc7\u6ee4target \u7b5b\u9009box # \u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20 \u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236 # \u7b5b\u9009\u7ed3\u679c [n] \u5168\u662fTrue\u6216False \u4f7f\u7528\u6bd4\u5982: box1[i]\u5373\u53ef\u5f97\u5230i\u4e2d\u6240\u6709\u7b49\u4e8eTrue\u7684\u77e9\u5f62\u6846 False\u7684\u77e9\u5f62\u6846\u5168\u90e8\u5220\u9664 i = box_candidates ( box1 = targets [:, 1 : 5 ] . T * s , box2 = new . T , area_thr = 0.01 if use_segments else 0.10 , ) # \u5f97\u5230\u6240\u6709\u6ee1\u8db3\u6761\u4ef6\u7684targets targets = targets [ i ] targets [:, 1 : 5 ] = new [ i ] return img , targets \u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u4e8eload_mosaic\u4e2d\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e\u8fdb\u884c\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362\uff1a \u8fd9\u4e2a\u51fd\u6570\u7684\u53c2\u6570\u6765\u81eahyp\u4e2d\u76845\u4e2a\u53c2\u6570","title":"1. random_perspective"},{"location":"source_code_interpretation/utils/augmentations_py.html#2-box_candidates","text":"\u8fd9\u4e2a\u51fd\u6570\u7528\u5728random_perspective\u4e2d\uff0c\u662f\u5bf9\u900f\u89c6\u53d8\u6362\u540e\u7684\u56fe\u7247label\u8fdb\u884c\u7b5b\u9009\uff0c\u53bb\u9664\u88ab\u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u8fd8\u6709\u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20\uff0c\u4e14\u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236\u3002 box_candidates\u6a21\u5757\u4ee3\u7801\uff1a def box_candidates ( box1 , box2 , wh_thr = 2 , ar_thr = 20 , area_thr = 0.1 , eps = 1e-16 ): \"\"\"\u7528\u5728random_perspective\u4e2d \u5bf9\u900f\u89c6\u53d8\u6362\u540e\u7684\u56fe\u7247label\u8fdb\u884c\u7b5b\u9009 \u53bb\u9664\u88ab\u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u8fd8\u6709\u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20\uff0c\u4e14\u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236 Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio :params box1: [4, n] :params box2: [4, n] :params wh_thr: \u7b5b\u9009\u6761\u4ef6 \u5bbd\u9ad8\u9608\u503c :params ar_thr: \u7b5b\u9009\u6761\u4ef6 \u5bbd\u9ad8\u6bd4\u3001\u9ad8\u5bbd\u6bd4\u6700\u5927\u503c\u9608\u503c :params area_thr: \u7b5b\u9009\u6761\u4ef6 \u9762\u79ef\u9608\u503c :params eps: 1e-16 \u63a5\u8fd10\u7684\u6570 \u9632\u6b62\u5206\u6bcd\u4e3a0 :return i: \u7b5b\u9009\u7ed3\u679c [n] \u5168\u662fTrue\u6216False \u4f7f\u7528\u6bd4\u5982: box1[i]\u5373\u53ef\u5f97\u5230i\u4e2d\u6240\u6709\u7b49\u4e8eTrue\u7684\u77e9\u5f62\u6846 False\u7684\u77e9\u5f62\u6846\u5168\u90e8\u5220\u9664 \"\"\" w1 , h1 = box1 [ 2 ] - box1 [ 0 ], box1 [ 3 ] - box1 [ 1 ] # \u6c42\u51fa\u6240\u6709box1\u77e9\u5f62\u6846\u7684\u5bbd\u548c\u9ad8 [n] [n] w2 , h2 = box2 [ 2 ] - box2 [ 0 ], box2 [ 3 ] - box2 [ 1 ] # \u6c42\u51fa\u6240\u6709box2\u77e9\u5f62\u6846\u7684\u5bbd\u548c\u9ad8 [n] [n] ar = np . maximum ( w2 / ( h2 + eps ), h2 / ( w2 + eps )) # \u6c42\u51fa\u6240\u6709box2\u77e9\u5f62\u6846\u7684\u5bbd\u9ad8\u6bd4\u548c\u9ad8\u5bbd\u6bd4\u7684\u8f83\u5927\u8005 [n, 1] # \u7b5b\u9009\u6761\u4ef6: \u589e\u5f3a\u540ew\u3001h\u8981\u5927\u4e8e2 \u589e\u5f3a\u540e\u56fe\u50cf\u4e0e\u589e\u5f3a\u524d\u56fe\u50cf\u9762\u79ef\u6bd4\u503c\u5927\u4e8earea_thr \u5bbd\u9ad8\u6bd4\u5927\u4e8ear_thr return ( ( w2 > wh_thr ) & ( h2 > wh_thr ) & ( w2 * h2 / ( w1 * h1 + eps ) > area_thr ) & ( ar < ar_thr ) ) # candidates","title":"2. box_candidates"},{"location":"source_code_interpretation/utils/augmentations_py.html#3-replicate","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408\u3002\u53ef\u4ee5\u7528\u5728load_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d\uff0c \u4f5c\u8005\u9ed8\u8ba4\u662f\u5173\u95ed\u7684\uff0c \u81ea\u5df1\u53ef\u4ee5\u5b9e\u9a8c\u4e00\u4e0b\u6548\u679c\u3002 replicate\u6a21\u5757\u4ee3\u7801\uff1a def replicate ( img , labels ): \"\"\"\u53ef\u4ee5\u7528\u5728load_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d \u4f5c\u8005\u9ed8\u8ba4\u662f\u5173\u95ed\u7684 \u81ea\u5df1\u53ef\u4ee5\u5b9e\u9a8c\u4e00\u4e0b\u6548\u679c \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408 Replicate labels :params img: img4 \u56e0\u4e3a\u662f\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e \u6240\u4ee5size=[2*img_size, 2*img_size] :params labels: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u6b63\u5e38label\u6807\u7b7elabels4(\u4e0d\u6b63\u5e38\u7684\u4f1a\u901a\u8fc7segments2boxes\u5c06\u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u6b63\u5e38\u6807\u7b7e) [N, cls+xyxy] :return img: img4 size=[2*img_size, 2*img_size] \u4e0d\u8fc7\u56fe\u7247\u4e2d\u591a\u4e86\u4e00\u534a\u7684\u8f83\u5c0fgt\u4e2a\u6570 :params labels: labels4 \u4e0d\u8fc7\u53e6\u5916\u589e\u52a0\u4e86\u4e00\u534a\u7684\u8f83\u5c0flabel [3/2N, cls+xyxy] \"\"\" h , w = img . shape [: 2 ] # \u5f97\u5230\u56fe\u7247\u7684\u9ad8\u548c\u5bbd boxes = labels [:, 1 :] . astype ( int ) # \u5f97\u5230\u6240\u6709gt\u6846\u7684\u77e9\u5f62\u5750\u6807 xyxy [N, xyxy] x1 , y1 , x2 , y2 = boxes . T # \u5de6\u4e0a\u89d2: x1 y1 \u53f3\u4e0b\u89d2: x2 y2 [N] s = ( ( x2 - x1 ) + ( y2 - y1 ) ) / 2 # side length (pixels) [N] \u5f97\u5230N\u4e2agt\u7684 (w+h)/2 \u7528\u6765\u8861\u91cfgt\u6846\u7684\u5927\u5c0f # \u751f\u6210\u539f\u6807\u7b7e\u4e2a\u6570\u4e00\u534a\u7684\u65b0\u6807\u7b7e s.size\u8fd4\u56dendarray\u7684\u5143\u7d20\u6570\u91cf for i in s . argsort ()[: round ( s . size * 0.5 )]: # \u8fd4\u56de\u8f83\u5c0f(s\u8f83\u5c0f)\u7684\u4e00\u534agt\u6846\u7684index\u4fe1\u606f x1b , y1b , x2b , y2b = boxes [ i ] # \u5f97\u5230\u8fd9\u4e00\u534a\u8f83\u5c0fgt\u6846\u7684\u5750\u6807\u4fe1\u606f \u5de6\u4e0a\u89d2x1b y1b \u53f3\u4e0b\u89d2x2b y2b bh , bw = y2b - y1b , x2b - x1b # \u5f97\u5230\u8fd9\u4e00\u822c\u8f83\u5c0fgt\u6846\u7684\u9ad8\u5bbd\u4fe1\u606f # \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\u70b9 y\u8303\u56f4\u5728[0, \u56fe\u7247\u9ad8-gt\u6846\u9ad8] x\u8303\u56f4\u5728[0, \u56fe\u7247\u5bbd-gt\u6846\u5bbd] yc , xc = int ( random . uniform ( 0 , h - bh )), int ( random . uniform ( 0 , w - bw ) ) # offset x, y # \u91cd\u65b0\u751f\u6210\u8fd9\u4e00\u534a\u7684gt\u6846\u5750\u6807\u4fe1\u606f(\u504f\u79fb\u540e) x1a , y1a , x2a , y2a = [ xc , yc , xc + bw , yc + bh ] # \u5c06\u56fe\u7247\u4e2d\u771f\u5b9e\u7684gt\u6846\u504f\u79fb\u5230\u5bf9\u5e94\u751f\u6210\u7684\u5750\u6807(\u4e00\u534a\u8f83\u5c0f\u7684\u504f\u79fb \u8f83\u5927\u7684\u4e0d\u504f\u79fb) img [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] # append \u539f\u6765\u7684labels\u6807\u7b7e + \u504f\u79fb\u4e86\u7684\u6807\u7b7e labels = np . append ( labels , [[ labels [ i , 0 ], x1a , y1a , x2a , y2a ]], axis = 0 ) return img , labels \u4f1a\u7528\u5728load_mosaicload_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d\uff08\u4e00\u822c\u4f1a\u5173\u95ed \u5177\u4f53\u8fd8\u8981\u770b\u4e2a\u4eba\u5b9e\u9a8c\uff09","title":"3. replicate"},{"location":"source_code_interpretation/utils/augmentations_py.html#4-letterbox","text":"letterbox \u7684img\u8f6c\u6362\u90e8\u5206 \u2003\u6b64\u65f6\uff1aauto=False\uff08\u9700\u8981pad\uff09, scale_fill=False, scale_up=False\u3002 \u2003\u663e\u7136\uff0c\u8fd9\u90e8\u5206\u9700\u8981\u7f29\u653e\uff0c\u56e0\u4e3a\u5728\u8fd9\u4e4b\u524d\u7684load_image\u90e8\u5206\u5df2\u7ecf\u7f29\u653e\u8fc7\u4e86\uff08\u6700\u957f\u8fb9\u7b49\u4e8e\u6307\u5b9a\u5927\u5c0f\uff0c\u8f83\u77ed\u8fb9\u7b49\u6bd4\u4f8b\u7f29\u653e\uff09\uff0c \u90a3\u4e48\u5728letterbox\u53ea\u9700\u8981\u8ba1\u7b97\u51fa\u8f83\u5c0f\u8fb9\u9700\u8981\u586b\u5145\u7684pad, \u518d\u5c06\u8f83\u5c0f\u8fb9\u4e24\u8fb9pad\u5230\u76f8\u5e94\u5927\u5c0f\uff08\u6bcf\u4e2abatch\u9700\u8981\u6bcf\u5f20\u56fe\u7247\u7684\u5927\u5c0f\uff0c\u8fd9\u4e2a \u5927\u5c0f\u662f\u4e0d\u76f8\u540c\u7684\uff09\u5373\u53ef\u3002 \u4e5f\u53ef\u4ee5\u7ed3\u5408\u4e0b\u9762\u753b\u7684\u6d41\u7a0b\u56fe\u6765\u7406\u89e3\u4e0b\u9762\u7684letterbox\u4ee3\u7801\uff1a def letterbox ( img , new_shape = ( 640 , 640 ), color = ( 114 , 114 , 114 ), auto = True , scaleFill = False , scaleup = True , stride = 32 , ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u53ea\u5728val\u65f6\u624d\u4f1a\u4f7f\u7528 \u5c06\u56fe\u7247\u7f29\u653e\u8c03\u6574\u5230\u6307\u5b9a\u5927\u5c0f Resize and pad image while meeting stride-multiple constraints https://github.com/ultralytics/yolov3/issues/232 :param img: \u539f\u56fe hwc :param new_shape: \u7f29\u653e\u540e\u7684\u6700\u957f\u8fb9\u5927\u5c0f :param color: pad\u7684\u989c\u8272 :param auto: True \u4fdd\u8bc1\u7f29\u653e\u540e\u7684\u56fe\u7247\u4fdd\u6301\u539f\u56fe\u7684\u6bd4\u4f8b \u5373 \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e\uff08\u4e0d\u4f1a\u5931\u771f\uff09 False \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e,\u6700\u540e\u5c06\u8f83\u77ed\u8fb9\u4e24\u8fb9pad\u64cd\u4f5c\u7f29\u653e\u5230\u6700\u957f\u8fb9\u5927\u5c0f\uff08\u4e0d\u4f1a\u5931\u771f\uff09 :param scale_fill: True \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u539f\u56feresize\u5230\u6307\u5b9a\u7684\u5927\u5c0f \u76f8\u5f53\u4e8e\u5c31\u662fresize \u6ca1\u6709pad\u64cd\u4f5c\uff08\u5931\u771f\uff09 :param scale_up: True \u5bf9\u4e8e\u5c0f\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5927\u4e8e\u7684\u4e0d\u53d8 False \u5bf9\u4e8e\u5927\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8e\u7684\u4e0d\u53d8 :return: img: letterbox\u540e\u7684\u56fe\u7247 HWC ratio: wh ratios (dw, dh): w\u548ch\u7684pad \"\"\" shape = img . shape [: 2 ] # \u7b2c\u4e00\u5c42resize\u540e\u56fe\u7247\u5927\u5c0f[h, w] = [343, 512] if isinstance ( new_shape , int ): new_shape = ( new_shape , new_shape ) # (512, 512) # scale ratio (new / old) 1.024 new_shape=(384, 512) r = min ( new_shape [ 0 ] / shape [ 0 ], new_shape [ 1 ] / shape [ 1 ]) # r=1 # \u53ea\u8fdb\u884c\u4e0b\u91c7\u6837 \u56e0\u4e3a\u4e0a\u91c7\u6837\u4f1a\u8ba9\u56fe\u7247\u6a21\u7cca # (for better test mAP) scale_up = False \u5bf9\u4e8e\u5927\u4e8enew_shape\uff08r<1\uff09\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8enew_shape\uff08r>1\uff09\u7684\u4e0d\u53d8 if not scaleup : # only scale down, do not scale up (for better test mAP) r = min ( r , 1.0 ) # Compute padding ratio = r , r # width, height ratios (1, 1) new_unpad = int ( round ( shape [ 1 ] * r )), int ( round ( shape [ 0 ] * r ) ) # wh(512, 343) \u4fdd\u8bc1\u7f29\u653e\u540e\u56fe\u50cf\u6bd4\u4f8b\u4e0d\u53d8 dw , dh = ( new_shape [ 1 ] - new_unpad [ 0 ], new_shape [ 0 ] - new_unpad [ 1 ], ) # wh padding dw=0 dh=41 if auto : # minimum rectangle \u4fdd\u8bc1\u539f\u56fe\u6bd4\u4f8b\u4e0d\u53d8\uff0c\u5c06\u56fe\u50cf\u6700\u5927\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f # \u8fd9\u91cc\u7684\u53d6\u4f59\u64cd\u4f5c\u53ef\u4ee5\u4fdd\u8bc1padding\u540e\u7684\u56fe\u7247\u662f32\u7684\u6574\u6570\u500d(416x416)\uff0c\u5982\u679c\u662f(512x512)\u53ef\u4ee5\u4fdd\u8bc1\u662f64\u7684\u6574\u6570\u500d dw , dh = np . mod ( dw , stride ), np . mod ( dh , stride ) # wh padding dw=0 dh=0 elif scaleFill : # stretch \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u56fe\u7247\u7f29\u653e\u5230\u6307\u5b9a\u5c3a\u5bf8 dw , dh = 0.0 , 0.0 new_unpad = ( new_shape [ 1 ], new_shape [ 0 ]) ratio = new_shape [ 1 ] / shape [ 1 ], new_shape [ 0 ] / shape [ 0 ] # width, height ratios # \u5728\u8f83\u5c0f\u8fb9\u7684\u4e24\u4fa7\u8fdb\u884cpad, \u800c\u4e0d\u662f\u5728\u4e00\u4fa7pad dw /= 2 # divide padding into 2 sides \u5c06padding\u5206\u5230\u4e0a\u4e0b\uff0c\u5de6\u53f3\u4e24\u4fa7 dw=0 dh /= 2 # dh=20.5 # shape:[h, w] new_unpad:[w, h] if shape [:: - 1 ] != new_unpad : # resize \u5c06\u539f\u56feresize\u5230new_unpad\uff08\u957f\u8fb9\u76f8\u540c\uff0c\u6bd4\u4f8b\u76f8\u540c\u7684\u65b0\u56fe\uff09 img = cv2 . resize ( img , new_unpad , interpolation = cv2 . INTER_LINEAR ) top , bottom = int ( round ( dh - 0.1 )), int ( round ( dh + 0.1 ) ) # \u8ba1\u7b97\u4e0a\u4e0b\u4e24\u4fa7\u7684padding # top=20 bottom=21 left , right = int ( round ( dw - 0.1 )), int ( round ( dw + 0.1 ) ) # \u8ba1\u7b97\u5de6\u53f3\u4e24\u4fa7\u7684padding # left=0 right=0 # add border/pad img = cv2 . copyMakeBorder ( img , top , bottom , left , right , cv2 . BORDER_CONSTANT , value = color ) # add border # img: (384, 512, 3) ratio=(1.0,1.0) \u8fd9\u91cc\u6ca1\u6709\u7f29\u653e\u64cd\u4f5c (dw,dh)=(0.0, 20.5) return img , ratio , ( dw , dh ) \u603b\u7ed3\u4e0b\u5728val\u65f6\u8fd9\u91cc\u4e3b\u8981\u662f\u505a\u4e86\u4e09\u4ef6\u4e8b\uff1a load_image\u5c06\u56fe\u7247\u4ece\u6587\u4ef6\u4e2d\u52a0\u8f7d\u51fa\u6765\uff0c\u5e76resize\u5230\u76f8\u5e94\u7684\u5c3a\u5bf8\uff08\u6700\u957f\u8fb9\u7b49\u4e8e\u6211\u4eec\u9700\u8981\u7684\u5c3a\u5bf8\uff0c\u6700\u77ed\u8fb9\u7b49\u6bd4\u4f8b\u7f29\u653e\uff09\uff1b letterbox\u5c06\u4e4b\u524dresize\u540e\u7684\u56fe\u7247\u518dpad\u5230\u6211\u4eec\u6240\u9700\u8981\u7684\u653e\u5230dataloader\u4e2d\uff08collate_fn\u51fd\u6570\uff09\u7684\u5c3a\u5bf8\uff08\u77e9\u5f62\u8bad\u7ec3\u8981\u6c42\u540c\u4e00\u4e2a batch\u4e2d\u7684\u56fe\u7247\u7684\u5c3a\u5bf8\u5fc5\u987b\u4fdd\u6301\u4e00\u81f4\uff09\uff1b \u5c06label\u4ece\u76f8\u5bf9\u539f\u56fe\u5c3a\u5bf8\uff08\u539f\u6587\u4ef6\u4e2d\u56fe\u7247\u5c3a\u5bf8\uff09\u7f29\u653e\u5230\u76f8\u5bf9letterbox pad\u540e\u7684\u56fe\u7247\u5c3a\u5bf8\u3002\u56e0\u4e3a\u524d\u4e24\u90e8\u5206\u7684\u56fe\u7247\u5c3a\u5bf8\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u540c\u6837\u7684\u6211\u4eec\u7684label\u4e5f\u9700\u8981\u53d1\u751f\u76f8\u5e94\u7684\u53d8\u5316\u3002","title":"4. letterbox"},{"location":"source_code_interpretation/utils/augmentations_py.html#5-cutout","text":"cutout\u6570\u636e\u589e\u5f3a\uff0c\u7ed9\u56fe\u7247\u968f\u673a\u6dfb\u52a0\u968f\u673a\u5927\u5c0f\u7684\u65b9\u5757\u566a\u58f0 \uff0c\u76ee\u7684\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002\u6e90\u81ea\u8bba\u6587\uff1a Improved Regularization of Convolutional Neural Networks with Cutout \u3002 \u2003\u66f4\u591a\u539f\u7406\u7ec6\u8282\u8bf7\u53c2\u9605\uff1a mosaic \u89e3\u8bfb , \u3010YOLO v4\u3011\u3010trick 8\u3011Data augmentation: MixUp\u3001Random Erasing\u3001CutOut\u3001CutMix\u3001Mosic\u3002 \u2003 \u5177\u4f53\u8981\u4e0d\u8981\u4f7f\u7528\uff0c\u6982\u7387\u662f\u591a\u5c11\u53ef\u4ee5\u81ea\u5df1\u5b9e\u9a8c\u3002 cutout\u6a21\u5757\u4ee3\u7801\uff1a def cutout ( image , labels ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884ccutout\u589e\u5f3a v5\u6e90\u7801\u4f5c\u8005\u9ed8\u8ba4\u662f\u6ca1\u7528\u7528\u8fd9\u4e2a\u7684 \u611f\u5174\u8da3\u7684\u53ef\u4ee5\u6d4b\u8bd5\u4e00\u4e0b cutout\u6570\u636e\u589e\u5f3a, \u7ed9\u56fe\u7247\u968f\u673a\u6dfb\u52a0\u968f\u673a\u5927\u5c0f\u7684\u65b9\u5757\u566a\u58f0 \u76ee\u7684\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027 \u5b9e\u73b0\uff1a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u6b63\u65b9\u5f62\u533a\u57df\uff0c\u7136\u540e\u91c7\u7528\u51680\u586b\u5145\u5c31OK\u4e86\uff0c\u5f53\u7136\u4e3a\u4e86\u907f\u514d\u586b\u51450\u503c\u5bf9\u8bad\u7ec3\u7684\u5f71\u54cd\uff0c\u5e94\u8be5\u8981\u5bf9\u6570\u636e\u8fdb\u884c\u4e2d\u5fc3\u5f52\u4e00\u5316\u64cd\u4f5c\uff0cnorm\u52300\u3002 \u8bba\u6587: https://arxiv.org/abs/1708.04552 :params image: \u4e00\u5f20\u56fe\u7247 [640, 640, 3] numpy :params labels: \u8fd9\u5f20\u56fe\u7247\u7684\u6807\u7b7e [N, 5]=[N, cls+x1y1x2y2] :return labels: \u7b5b\u9009\u540e\u7684\u8fd9\u5f20\u56fe\u7247\u7684\u6807\u7b7e [M, 5]=[M, cls+x1y1x2y2] M<N \u7b5b\u9009: \u5982\u679c\u968f\u673a\u751f\u6210\u7684\u566a\u58f0\u548c\u539f\u59cbF\u7684gt\u6846\u76f8\u4ea4\u533a\u57df\u5360gt\u6846\u592a\u5927 \u5c31\u7b5b\u51fa\u8fd9\u4e2agt\u6846label \"\"\" h , w = image . shape [: 2 ] # \u83b7\u53d6\u56fe\u7247\u9ad8\u548c\u5bbd def bbox_ioa ( box1 , box2 ): \"\"\"\u7528\u5728cutout\u4e2d \u8ba1\u7b97box1\u548cbox2\u76f8\u4ea4\u9762\u79ef\u4e0ebox2\u9762\u79ef\u7684\u6bd4\u4f8b Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2 :params box1: \u4f20\u5165\u968f\u673a\u751f\u6210\u566a\u58f0 box [4] = [x1y1x2y2] :params box2: \u4f20\u5165\u56fe\u7247\u539f\u59cb\u7684label\u4fe1\u606f [n, 4] = [n, x1y1x2y2] :return [n, 1] \u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u7684\u566a\u58f0box\u4e0en\u4e2a\u539f\u59cblabel\u7684\u76f8\u4ea4\u9762\u79ef\u4e0eb\u539f\u59cblabel\u7684\u6bd4\u503c \"\"\" box2 = box2 . transpose () # Get the coordinates of bounding boxes b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 [ 0 ], box1 [ 1 ], box1 [ 2 ], box1 [ 3 ] b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 [ 0 ], box2 [ 1 ], box2 [ 2 ], box2 [ 3 ] # \u6c42box1\u548cbox2\u7684\u76f8\u4ea4\u9762\u79ef inter_area = ( np . minimum ( b1_x2 , b2_x2 ) - np . maximum ( b1_x1 , b2_x1 )) . clip ( 0 ) * \\ ( np . minimum ( b1_y2 , b2_y2 ) - np . maximum ( b1_y1 , b2_y1 )) . clip ( 0 ) # box\u9762\u79ef box2_area = ( b2_x2 - b2_x1 ) * ( b2_y2 - b2_y1 ) + 1e-16 # \u8fd4\u56debox1\u548cbox2\u76f8\u4ea4\u9762\u79ef \u4e0e box2\u9762\u79ef\u4e4b\u6bd4 return inter_area / box2_area # \u8bbe\u7f6ecutout\u6dfb\u52a0\u566a\u58f0\u7684scale create random masks scales = [ 0.5 ] * 1 + [ 0.25 ] * 2 + [ 0.125 ] * 4 + [ 0.0625 ] * 8 + [ 0.03125 ] * 16 # image size fraction for s in scales : # \u968f\u673a\u751f\u6210\u566a\u58f0 \u5bbd\u9ad8 mask_h = random . randint ( 1 , int ( h * s )) mask_w = random . randint ( 1 , int ( w * s )) # \u968f\u673a\u751f\u6210\u566a\u58f0 box xmin = max ( 0 , random . randint ( 0 , w ) - mask_w // 2 ) ymin = max ( 0 , random . randint ( 0 , h ) - mask_h // 2 ) xmax = min ( w , xmin + mask_w ) ymax = min ( h , ymin + mask_h ) # \u6dfb\u52a0\u968f\u673a\u989c\u8272\u7684\u566a\u58f0 apply random color mask image [ ymin : ymax , xmin : xmax ] = [ random . randint ( 64 , 191 ) for _ in range ( 3 )] # \u8fd4\u56de\u6ca1\u6709\u566a\u58f0\u7684label return unobscured labels if len ( labels ) and s > 0.03 : box = np . array ([ xmin , ymin , xmax , ymax ], dtype = np . float32 ) # \u968f\u673a\u751f\u6210\u7684\u566a\u58f0box # \u8ba1\u7b97\u751f\u6210\u7684\u4e00\u4e2a\u566a\u58f0box\u4e0e\u8fd9\u5f20\u56fe\u7247\u4e2d\u6240\u6709gt\u7684box\u505a\u8ba1\u7b97 inter_area/label_area [n, 1] ioa = bbox_ioa ( box , labels [:, 1 : 5 ]) # remove>60% obscured labels \u4e0d\u80fd\u5207\u7684\u592a\u5927 ioa < 0.60 \u4fdd\u7559cutout\u566a\u58f0\u906e\u6321\u5c0f\u4e8e60%\u7684\u6807\u7b7e labels = labels [ ioa < 0.60 ] return labels \u6ce8\u610f\uff1a 1. \u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884ccutout\u589e\u5f3a\uff1a mixup\u589e\u5f3a\u7531\u8d85\u53c2hyp[\u2018mixup\u2019]\u63a7\u5236\uff0c0\u5219\u5173\u95ed \u9ed8\u8ba4\u4e3a1\u5219100%\u6253\u5f00\uff08\u81ea\u5df1\u5b9e\u9a8c\u5224\u65ad\uff09\uff1a","title":"5. cutout"},{"location":"source_code_interpretation/utils/augmentations_py.html#6-mixup","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u8fdb\u884cmixup\u6570\u636e\u589e\u5f3a\uff1a\u6309\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247\u3002\u8bba\u6587\uff1a https://arxiv.org/pdf/1710.09412.pdf \u3002 \u2003\u66f4\u591a\u539f\u7406\u7ec6\u8282\u8bf7\u770b\u535a\u5ba2\uff1a \u3010YOLO v4\u3011\u3010trick 8\u3011Data augmentation: MixUp\u3001Random Erasing\u3001CutOut\u3001CutMix\u3001Mosic \u3002 \u2003\u5177\u4f53\u8981\u4e0d\u8981\u4f7f\u7528\uff0c\u6982\u7387\u662f\u591a\u5c11\u53ef\u4ee5\u81ea\u5df1\u5b9e\u9a8c\u3002 mixup\u6a21\u5757\u4ee3\u7801\uff1a def mixup ( im , labels , im2 , labels2 ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884cmixup\u589e\u5f3a mixup\u6570\u636e\u589e\u5f3a, \u6309\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247 Applies MixUp augmentation \u8bba\u6587: https://arxiv.org/pdf/1710.09412.pdf :params im:\u56fe\u72471 numpy (640, 640, 3) :params labels:[N, 5]=[N, cls+x1y1x2y2] :params im2:\u56fe\u72472 (640, 640, 3) :params labels2:[M, 5]=[M, cls+x1y1x2y2] :return img: \u4e24\u5f20\u56fe\u7247mixup\u589e\u5f3a\u540e\u7684\u56fe\u7247 (640, 640, 3) :return labels: \u4e24\u5f20\u56fe\u7247mixup\u589e\u5f3a\u540e\u7684label\u6807\u7b7e [M+N, cls+x1y1x2y2] \"\"\" # \u968f\u673a\u4ecebeta\u5206\u5e03\u4e2d\u83b7\u53d6\u6bd4\u4f8b,range[0, 1] r = np . random . beta ( 32.0 , 32.0 ) # mixup ratio, alpha=beta=32.0 # \u6309\u7167\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247 im = ( im * r + im2 * ( 1 - r )) . astype ( np . uint8 ) # \u5c06\u4e24\u5f20\u56fe\u7247\u6807\u7b7e\u62fc\u63a5\u5230\u4e00\u8d77 labels = np . concatenate (( labels , labels2 ), 0 ) return im , labels \u6ce8\u610f: - \u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884cmixup\u589e\u5f3a\uff1a - mixup\u589e\u5f3a\u7531\u8d85\u53c2hyp[\"mixup\"]\u63a7\u5236\uff0c0\u5219\u5173\u95ed \u9ed8\u8ba4\u4e3a1\u5219100%\u6253\u5f00\uff08\u81ea\u5df1\u5b9e\u9a8c\u5224\u65ad\uff09","title":"6. mixup"},{"location":"source_code_interpretation/utils/augmentations_py.html#7-hist_equalize","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u4e8e\u5bf9\u56fe\u7247\u8fdb\u884c\u76f4\u65b9\u56fe\u5747\u8861\u5316\u5904\u7406\uff0c\u4f46\u662f\u5728yolov5\u4e2d\u5e76\u6ca1\u6709\u7528\u5230\u6309\u8fd9\u4e2a\u51fd\u6570\uff0c\u5b66\u4e60\u4e86\u89e3\u4e0b\u5c31\u597d\uff0c\u4e0d\u662f\u91cd\u70b9\u3002 hist_equalize\u6a21\u5757\u4ee3\u7801: def hist_equalize ( img , clahe = True , bgr = False ): \"\"\"yolov5\u5e76\u6ca1\u6709\u4f7f\u7528\u76f4\u65b9\u56fe\u5747\u8861\u5316\u7684\u589e\u5f3a\u64cd\u4f5c \u53ef\u4ee5\u81ea\u5df1\u8bd5\u8bd5 \u76f4\u65b9\u56fe\u5747\u8861\u5316\u589e\u5f3a\u64cd\u4f5c Equalize histogram on BGR image 'img' with img.shape(n,m,3) and range 0-255 :params img: \u8981\u8fdb\u884c\u76f4\u65b9\u56fe\u5747\u8861\u5316\u7684\u539f\u56fe :params clahe: \u662f\u5426\u8981\u751f\u6210\u81ea\u9002\u5e94\u5747\u8861\u5316\u56fe\u7247 \u9ed8\u8ba4True \u5982\u679c\u662fFalse\u5c31\u751f\u6210\u5168\u5c40\u5747\u8861\u5316\u56fe\u7247 :params bgr: \u4f20\u5165\u7684img\u56fe\u50cf\u662f\u5426\u662fbgr\u56fe\u7247 \u9ed8\u8ba4False :return img: \u5747\u8861\u5316\u4e4b\u540e\u7684\u56fe\u7247 \u5927\u5c0f\u4e0d\u53d8 \u683c\u5f0fRGB \"\"\" # \u56fe\u7247BGR/RGB\u683c\u5f0f -> YUV\u683c\u5f0f yuv = cv2 . cvtColor ( img , cv2 . COLOR_BGR2YUV if bgr else cv2 . COLOR_RGB2YUV ) if clahe : # cv2.createCLAHE\u751f\u6210\u81ea\u9002\u5e94\u5747\u8861\u5316\u56fe\u50cf c = cv2 . createCLAHE ( clipLimit = 2.0 , tileGridSize = ( 8 , 8 )) yuv [:, :, 0 ] = c . apply ( yuv [:, :, 0 ]) else : # \u5168\u5c40\u5747\u8861\u5316 yuv [:, :, 0 ] = cv2 . equalizeHist ( yuv [:, :, 0 ]) # equalize Y channel histogram return cv2 . cvtColor ( yuv , cv2 . COLOR_YUV2BGR if bgr else cv2 . COLOR_YUV2RGB ) # convert YUV image to RGB","title":"7. hist_equalize"},{"location":"source_code_interpretation/utils/augmentations_py.html#reference","text":"\u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011 atasets.py","title":"Reference"},{"location":"source_code_interpretation/utils/dataladers_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/dataloaders.py 1. \u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license \"\"\" Dataloaders and dataset utils \"\"\" import contextlib import glob # python\u81ea\u5df1\u5e26\u7684\u4e00\u4e2a\u6587\u4ef6\u64cd\u4f5c\u76f8\u5173\u6a21\u5757 \u67e5\u627e\u7b26\u5408\u81ea\u5df1\u76ee\u7684\u7684\u6587\u4ef6(\u5982\u6a21\u7cca\u5339\u914d) import hashlib # \u54c8\u5e0c\u6a21\u5757 \u63d0\u4f9b\u4e86\u591a\u79cd\u5b89\u5168\u65b9\u4fbf\u7684hash\u65b9\u6cd5 import json # json\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 import math # \u6570\u5b66\u516c\u5f0f\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 \u5305\u542b\u6587\u4ef6\u8def\u5f84\u64cd\u4f5c\u548c\u89e3\u6790 import random # \u751f\u6210\u968f\u673a\u6570\u6a21\u5757 import shutil # \u6587\u4ef6\u5939\u3001\u538b\u7f29\u5305\u5904\u7406\u6a21\u5757 import time # \u65f6\u95f4\u6a21\u5757 \u66f4\u5e95\u5c42 from itertools import repeat # \u590d\u5236\u6a21\u5757 from multiprocessing.pool import Pool , ThreadPool # \u591a\u7ebf\u7a0b\u6a21\u5757 \u7ebf\u7a0b\u6c60 from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 from threading import Thread # \u591a\u7ebf\u7a0b\u64cd\u4f5c\u6a21\u5757 from urllib.parse import urlparse from zipfile import ZipFile import numpy as np # numpy\u77e9\u9635\u64cd\u4f5c\u6a21\u5757 import oneflow as flow # OneFlow\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757 import oneflow.nn.functional as F # OneFlow\u51fd\u6570\u63a5\u53e3 \u5c01\u88c5\u4e86\u5f88\u591a\u5377\u79ef\u3001\u6c60\u5316\u7b49\u51fd\u6570 import yaml # yaml\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 from oneflow.utils.data import DataLoader , Dataset , dataloader , distributed from PIL import ExifTags , Image , ImageOps # \u56fe\u7247\u3001\u76f8\u673a\u64cd\u4f5c\u6a21\u5757 from tqdm import tqdm # \u8fdb\u5ea6\u6761\u6a21\u5757 # augmentations.py\u6e90\u7801\u89e3\u8bfb: https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/utils/augmentations_py.html from utils.augmentations import Albumentations , augment_hsv , copy_paste , letterbox , mixup , random_perspective from utils.general import ( DATASETS_DIR , LOGGER , NUM_THREADS , check_dataset , check_requirements , check_yaml , clean_str , cv2 , is_colab , is_kaggle , segments2boxes , xyn2xy , xywh2xyxy , xywhn2xyxy , xyxy2xywhn , ) # Parameters HELP_URL = \"https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\" IMG_FORMATS = ( \"bmp\" , \"dng\" , \"jpeg\" , \"jpg\" , \"mpo\" , \"png\" , \"tif\" , \"tiff\" , \"webp\" , ) # include image suffixes VID_FORMATS = ( \"asf\" , \"avi\" , \"gif\" , \"m4v\" , \"mkv\" , \"mov\" , \"mp4\" , \"mpeg\" , \"mpg\" , \"ts\" , \"wmv\" , ) # include video suffixes BAR_FORMAT = \" {l_bar}{bar:10}{r_bar}{bar:-10b} \" # tqdm bar format LOCAL_RANK = int ( os . getenv ( \"LOCAL_RANK\" , - 1 )) # https://oneflow.readthedocs.io/en/master/distributed.html?highlight=launch#launching-distributed-training RANK = int ( os . getenv ( \"RANK\" , - 1 )) 2. \u76f8\u673a\u8bbe\u7f6e \u2003\u8fd9\u90e8\u5206\u662f\u76f8\u673a\u76f8\u5173\u8bbe\u7f6e\uff0c\u5f53\u4f7f\u7528\u76f8\u673a\u91c7\u6837\u65f6\u624d\u4f1a\u4f7f\u7528\u3002 # \u76f8\u673a\u8bbe\u7f6e # Get orientation exif tag # \u4e13\u95e8\u4e3a\u6570\u7801\u76f8\u673a\u7684\u7167\u7247\u800c\u8bbe\u5b9a \u53ef\u4ee5\u8bb0\u5f55\u6570\u7801\u7167\u7247\u7684\u5c5e\u6027\u4fe1\u606f\u548c\u62cd\u6444\u6570\u636e for orientation in ExifTags . TAGS . keys (): if ExifTags . TAGS [ orientation ] == \"Orientation\" : break def get_hash ( paths ): # \u8fd4\u56de\u6587\u4ef6\u5217\u8868\u7684hash\u503c # Returns a single hash value of a list of paths (files or dirs) size = sum ( os . path . getsize ( p ) for p in paths if os . path . exists ( p )) # sizes h = hashlib . md5 ( str ( size ) . encode ()) # hash sizes h . update ( \"\" . join ( paths ) . encode ()) # hash paths return h . hexdigest () # return hash def exif_size ( img ): # \u83b7\u53d6\u6570\u7801\u76f8\u673a\u7684\u56fe\u7247\u5bbd\u9ad8\u4fe1\u606f \u5e76\u4e14\u5224\u65ad\u662f\u5426\u9700\u8981\u65cb\u8f6c\uff08\u6570\u7801\u76f8\u673a\u53ef\u4ee5\u591a\u89d2\u5ea6\u62cd\u6444\uff09 # Returns exif-corrected PIL size s = img . size # (width, height) with contextlib . suppress ( Exception ): rotation = dict ( img . _getexif () . items ())[ orientation ] if rotation in [ 6 , 8 ]: # rotation 270 or 90 s = ( s [ 1 ], s [ 0 ]) return s def exif_transpose ( image ): \"\"\" \u5982\u679c\u6709EXIF\u65b9\u5411\u6807\u8bb0\uff0c\u5219\u76f8\u5e94\u8c03\u6362PIL\u56fe\u50cf\u3002 Transpose a PIL image accordingly if it has an EXIF Orientation tag. Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose() :param image: The image to transpose. :return: An image. \"\"\" exif = image . getexif () orientation = exif . get ( 0x0112 , 1 ) # default 1 if orientation > 1 : method = { 2 : Image . FLIP_LEFT_RIGHT , 3 : Image . ROTATE_180 , 4 : Image . FLIP_TOP_BOTTOM , 5 : Image . TRANSPOSE , 6 : Image . ROTATE_270 , 7 : Image . TRANSVERSE , 8 : Image . ROTATE_90 , } . get ( orientation ) if method is not None : image = image . transpose ( method ) del exif [ 0x0112 ] image . info [ \"exif\" ] = exif . tobytes () return image def seed_worker ( worker_id ): # Set dataloader worker seed # https://oneflow.readthedocs.io/en/master/utils.data.html?highlight=randomness#platform-specific-behaviors worker_seed = flow . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) def create_dataloader ( path , # path: \u56fe\u7247\u6570\u636e\u52a0\u8f7d\u8def\u5f84 train/test \u5982: ../datasets/coco/images/train2017 imgsz , # train/test\u56fe\u7247\u5c3a\u5bf8\uff08\u6570\u636e\u589e\u5f3a\u540e\u5927\u5c0f\uff09 640 batch_size , # batch size \u5927\u5c0f 8/16/32 stride , # \u6a21\u578b\u6700\u5927stride=32 [32 16 8] single_cls = False , # \u6570\u636e\u96c6\u662f\u5426\u662f\u5355\u7c7b\u522b \u9ed8\u8ba4False hyp = None , # \u8d85\u53c2\u5217\u8868dict \u7f51\u7edc\u8bad\u7ec3\u65f6\u7684\u4e00\u4e9b\u8d85\u53c2\u6570\uff0c\u5305\u62ec\u5b66\u4e60\u7387\u7b49\uff0c\u8fd9\u91cc\u4e3b\u8981\u7528\u5230\u91cc\u9762\u4e00\u4e9b\u5173\u4e8e\u6570\u636e\u589e\u5f3a(\u65cb\u8f6c\u3001\u5e73\u79fb\u7b49)\u7684\u7cfb\u6570 augment = False , # \u662f\u5426\u8981\u8fdb\u884c\u6570\u636e\u589e\u5f3a True cache = False , # \u662f\u5426cache_images False pad = 0.0 , # \u8bbe\u7f6e\u77e9\u5f62\u8bad\u7ec3\u7684shape\u65f6\u8fdb\u884c\u7684\u586b\u5145 \u9ed8\u8ba40.0 rect = False , # \u662f\u5426\u5f00\u542f\u77e9\u5f62train/test \u9ed8\u8ba4\u8bad\u7ec3\u96c6\u5173\u95ed \u9a8c\u8bc1\u96c6\u5f00\u542f rank =- 1 , # \u591a\u5361\u8bad\u7ec3\u65f6\u7684\u8fdb\u7a0b\u7f16\u53f7 rank\u4e3a\u8fdb\u7a0b\u7f16\u53f7 -1\u4e14gpu=1\u65f6\u4e0d\u8fdb\u884c\u5206\u5e03\u5f0f -1\u4e14\u591a\u5757gpu\u4f7f\u7528DataParallel\u6a21\u5f0f \u9ed8\u8ba4-1 workers = 8 , # dataloader\u7684num_works \u52a0\u8f7d\u6570\u636e\u65f6\u7684cpu\u8fdb\u7a0b\u6570 image_weights = False , # \u8bad\u7ec3\u65f6\u662f\u5426\u6839\u636e\u56fe\u7247\u6837\u672c\u771f\u5b9e\u6846\u5206\u5e03\u6743\u91cd\u6765\u9009\u62e9\u56fe\u7247 \u9ed8\u8ba4False quad = False , # dataloader\u53d6\u6570\u636e\u65f6, \u662f\u5426\u4f7f\u7528collate_fn4\u4ee3\u66ffcollate_fn \u9ed8\u8ba4False prefix = \"\" , # \u663e\u793a\u4fe1\u606f \u4e00\u4e2a\u6807\u5fd7\uff0c\u591a\u4e3atrain/val\uff0c\u5904\u7406\u6807\u7b7e\u65f6\u4fdd\u5b58cache\u6587\u4ef6\u4f1a\u7528\u5230 shuffle = False , # \u5bf9\u8bad\u7ec3\u6570\u636e\u662f\u5426\u968f\u673a\u6253\u4e71\u3002 ): \"\"\"\u5728train.py\u4e2d\u88ab\u8c03\u7528\uff0c\u7528\u4e8e\u751f\u6210Trainloader, dataset\uff0ctestloader \u81ea\u5b9a\u4e49dataloader\u51fd\u6570: \u8c03\u7528LoadImagesAndLabels\u83b7\u53d6\u6570\u636e\u96c6(\u5305\u62ec\u6570\u636e\u589e\u5f3a) + \u8c03\u7528\u5206\u5e03\u5f0f\u91c7\u6837\u5668DistributedSampler + \u81ea\u5b9a\u4e49InfiniteDataLoader \u8fdb\u884c\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e \"\"\" if rect and shuffle : LOGGER . warning ( \"WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\" ) shuffle = False # \u8f7d\u5165\u6587\u4ef6\u6570\u636e(\u589e\u5f3a\u6570\u636e\u96c6) dataset = LoadImagesAndLabels ( path , imgsz , batch_size , augment = augment , # augmentation hyp = hyp , # hyperparameters rect = rect , # rectangular batches cache_images = cache , single_cls = single_cls , stride = int ( stride ), pad = pad , image_weights = image_weights , prefix = prefix , ) batch_size = min ( batch_size , len ( dataset )) nd = flow . cuda . device_count () # number of CUDA devices nw = min ([ os . cpu_count () // max ( nd , 1 ), batch_size if batch_size > 1 else 0 , workers ]) # number of workers # \u5206\u5e03\u5f0f\u91c7\u6837\u5668DistributedSampler sampler = None if rank == - 1 else distributed . DistributedSampler ( dataset , shuffle = shuffle ) # \u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u6765\u5bf9DataLoader\u8fdb\u884c\u5c01\u88c5, \u4ee3\u66ff\u539f\u5148\u7684DataLoader, \u80fd\u591f\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e loader = DataLoader if image_weights else InfiniteDataLoader # only DataLoader allows for attribute updates # \u968f\u673a\u6570\u751f\u6210\u5668 https://oneflow.readthedocs.io/en/master/generated/oneflow.randint.html?highlight=flow.Generator#oneflow.randint generator = flow . Generator () generator . manual_seed ( 6148914691236517205 + RANK ) return ( loader ( dataset , batch_size = batch_size , shuffle = shuffle and sampler is None , num_workers = nw , sampler = sampler , pin_memory = True , collate_fn = LoadImagesAndLabels . collate_fn4 if quad else LoadImagesAndLabels . collate_fn , worker_init_fn = seed_worker , generator = generator , ), dataset , ) 3.\u81ea\u5b9a\u4e49DataLoader \u2003\u5f53image_weights=False\u65f6\uff08\u4e0d\u6839\u636e\u56fe\u7247\u6837\u672c\u771f\u5b9e\u6846\u5206\u5e03\u6743\u91cd\u6765\u9009\u62e9\u56fe\u7247\uff09\u5c31\u4f1a\u8c03\u7528\u8fd9\u4e24\u4e2a\u51fd\u6570 \u8fdb\u884c\u81ea\u5b9a\u4e49DataLoader\uff0c\u8fdb\u884c\u6301\u7eed\u6027\u91c7\u6837\u3002\u5728\u4e0a\u9762\u7684create_dataloade\u51fd\u6570\u4e2d\u88ab\u8c03\u7528\u3002 class InfiniteDataLoader ( dataloader . DataLoader ): \"\"\"Dataloader that reuses workers \u5f53image_weights=False\u65f6\u5c31\u4f1a\u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u8fd9\u4e24\u4e2a\u7c7b\u5b9e\u73b0\u81ea\u5b9a\u4e49DataLoader \u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u6765\u5bf9DataLoader\u8fdb\u884c\u5c01\u88c5, \u4ee3\u66ff\u539f\u5148\u7684DataLoader, \u80fd\u591f\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e Uses same syntax as vanilla DataLoader \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) # \u8c03\u7528_RepeatSampler\u8fdb\u884c\u6301\u7eed\u91c7\u6837 object . __setattr__ ( self , \"batch_sampler\" , _RepeatSampler ( self . batch_sampler )) self . iterator = super () . __iter__ () def __len__ ( self ): return len ( self . batch_sampler . sampler ) def __iter__ ( self ): for _ in range ( len ( self )): yield next ( self . iterator ) class _RepeatSampler : \"\"\"Sampler that repeats forever \u8fd9\u90e8\u5206\u662f\u8fdb\u884c\u6301\u7eed\u91c7\u6837 Args: sampler (Sampler) \"\"\" def __init__ ( self , sampler ): self . sampler = sampler def __iter__ ( self ): while True : yield from iter ( self . sampler ) 4. LoadImagesAndLabels \u2003\u8fd9\u4e2a\u90e8\u5206\u662f\u6570\u636e\u8f7d\u5165\uff08\u6570\u636e\u589e\u5f3a\uff09\u90e8\u5206\uff0c \u4e5f\u5c31\u662f\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u90e8\u5206\uff0c\u7ee7\u627f\u81eaDataset\uff0c\u9700\u8981\u91cd\u5199__init__,__getitem()__\u7b49\u62bd\u8c61\u65b9\u6cd5\uff0c \u53e6\u5916\u76ee\u6807\u68c0\u6d4b\u4e00\u822c\u8fd8\u9700\u8981\u91cd\u5199collate_fn\u51fd\u6570\u3002\u6240\u4ee5\uff0c\u7406\u89e3\u8fd9\u4e09\u4e2a\u51fd\u6570\u662f\u7406\u89e3\u6570\u636e\u589e\u5f3a\uff08\u6570\u636e\u8f7d\u5165\uff09\u7684\u91cd\u4e2d\u4e4b\u91cd\u3002 4.1 init \u8fd9\u4e2a\u51fd\u6570\u7684\u5165\u53e3\u662f\u4e0a\u9762\u7684create_dataloader\u51fd\u6570\uff1a init \u4e3b\u8981\u5e72\u4e86\u4e00\u4e0b\u51e0\u4ef6\u4e8b\uff1a \u8d4b\u503c\u4e00\u4e9b\u57fa\u7840\u7684self\u53d8\u91cf \u7528\u4e8e\u540e\u9762\u5728__getitem__\u4e2d\u8c03\u7528 \u5f97\u5230path\u8def\u5f84\u4e0b\u7684\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84self.img_files \u6839\u636eimgs\u8def\u5f84\u627e\u5230labels\u7684\u8def\u5f84self.label_files cache label Read cache \u751f\u6210self.labels\u3001self.shapes\u3001self.img_files\u3001self.label_files\u3001self.batch\u3001self.n\u3001self.indices\u7b49\u53d8\u91cf \u4e3aRectangular Training\u4f5c\u51c6\u5907: \u751f\u6210self.batch_shapes \u662f\u5426\u9700\u8981cache image(\u4e00\u822c\u4e0d\u9700\u8981\uff0c\u592a\u5927\u4e86) __init__\u51fd\u6570\u4ee3\u7801\uff1a class LoadImagesAndLabels ( Dataset ): def __init__ ( self , path , img_size = 640 , batch_size = 16 , augment = False , hyp = None , rect = False , image_weights = False , cache_images = False , single_cls = False , stride = 32 , pad = 0.0 , prefix = \"\" , ): \"\"\" \u521d\u59cb\u5316\u8fc7\u7a0b\u5e76\u6ca1\u6709\u4ec0\u4e48\u5b9e\u8d28\u6027\u7684\u64cd\u4f5c,\u66f4\u591a\u662f\u4e00\u4e2a\u5b9a\u4e49\u53c2\u6570\u7684\u8fc7\u7a0b\uff08self\u53c2\u6570\uff09,\u4ee5\u4fbf\u5728__getitem()__\u4e2d\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u64cd\u4f5c,\u6240\u4ee5\u8fd9\u90e8\u5206\u4ee3\u7801\u53ea\u9700\u8981\u6293\u4f4fself\u4e2d\u7684\u5404\u4e2a\u53d8\u91cf\u7684\u542b\u4e49\u5c31\u7b97\u5dee\u4e0d\u591a\u4e86 self.img_files: {list: N} \u5b58\u653e\u7740\u6574\u4e2a\u6570\u636e\u96c6\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84 self.label_files: {list: N} \u5b58\u653e\u7740\u6574\u4e2a\u6570\u636e\u96c6\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84 cache label -> verify_image_label self.labels: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label labels\u5b58\u50a8\u7684label\u5c31\u90fd\u662f\u539f\u59cblabel(\u90fd\u662f\u6b63\u5e38\u7684\u77e9\u5f62label) \u5426\u5219\u5c06\u6240\u6709\u56fe\u7247\u6b63\u5e38gt\u7684label\u5b58\u5165labels \u4e0d\u6b63\u5e38gt(\u5b58\u5728\u4e00\u4e2a\u591a\u8fb9\u5f62)\u7ecf\u8fc7segments2boxes\u8f6c\u6362\u4e3a\u6b63\u5e38\u7684\u77e9\u5f62label self.shapes: \u6240\u6709\u56fe\u7247\u7684shape self.segments: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label self.segments=None \u5426\u5219\u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u6240\u6709\u5b58\u5728\u591a\u8fb9\u5f62gt\u7684\u56fe\u7247\u7684\u6240\u6709\u539f\u59cblabel(\u80af\u5b9a\u6709\u591a\u8fb9\u5f62label \u4e5f\u53ef\u80fd\u6709\u77e9\u5f62\u6b63\u5e38label \u672a\u77e5\u6570) self.batch: \u8bb0\u8f7d\u7740\u6bcf\u5f20\u56fe\u7247\u5c5e\u4e8e\u54ea\u4e2abatch self.n: \u6570\u636e\u96c6\u4e2d\u6240\u6709\u56fe\u7247\u7684\u6570\u91cf self.indices: \u8bb0\u8f7d\u7740\u6240\u6709\u56fe\u7247\u7684index self.rect=True\u65f6self.batch_shapes\u8bb0\u8f7d\u6bcf\u4e2abatch\u7684shape(\u540c\u4e00\u4e2abatch\u7684\u56fe\u7247shape\u76f8\u540c) \"\"\" # 1\u3001\u8d4b\u503c\u4e00\u4e9b\u57fa\u7840\u7684self\u53d8\u91cf \u7528\u4e8e\u540e\u9762\u5728__getitem__\u4e2d\u8c03\u7528 self . img_size = img_size # \u7ecf\u8fc7\u6570\u636e\u589e\u5f3a\u540e\u7684\u6570\u636e\u56fe\u7247\u7684\u5927\u5c0f self . augment = augment # \u662f\u5426\u542f\u52a8\u6570\u636e\u589e\u5f3a \u4e00\u822c\u8bad\u7ec3\u65f6\u6253\u5f00 \u9a8c\u8bc1\u65f6\u5173\u95ed self . hyp = hyp # \u8d85\u53c2\u5217\u8868 # \u56fe\u7247\u6309\u6743\u91cd\u91c7\u6837 True\u5c31\u53ef\u4ee5\u6839\u636e\u7c7b\u522b\u9891\u7387(\u9891\u7387\u9ad8\u7684\u6743\u91cd\u5c0f,\u53cd\u6b63\u5927)\u6765\u8fdb\u884c\u91c7\u6837 \u9ed8\u8ba4False: \u4e0d\u4f5c\u7c7b\u522b\u533a\u5206 self . image_weights = image_weights self . rect = False if image_weights else rect # \u662f\u5426\u542f\u52a8\u77e9\u5f62\u8bad\u7ec3 \u4e00\u822c\u8bad\u7ec3\u65f6\u5173\u95ed \u9a8c\u8bc1\u65f6\u6253\u5f00 \u53ef\u4ee5\u52a0\u901f self . mosaic = self . augment and not self . rect # load 4 images at a time into a mosaic (only during training) # mosaic\u589e\u5f3a\u7684\u8fb9\u754c\u503c [-320, -320] self . mosaic_border = [ - img_size // 2 , - img_size // 2 ] self . stride = stride # \u6700\u5927\u4e0b\u91c7\u6837\u7387 32 self . path = path # \u56fe\u7247\u8def\u5f84 self . albumentations = Albumentations () if augment else None # 2\u3001\u5f97\u5230path\u8def\u5f84\u4e0b\u7684\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84self.img_files \u8fd9\u91cc\u9700\u8981\u81ea\u5df1debug\u4e00\u4e0b \u4e0d\u4f1a\u592a\u96be try : f = [] # image files for p in path if isinstance ( path , list ) else [ path ]: # \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84path\uff0c\u5305\u542b\u56fe\u7247\u8def\u5f84\u7684txt\u6587\u4ef6\u6216\u8005\u5305\u542b\u56fe\u7247\u7684\u6587\u4ef6\u5939\u8def\u5f84 # \u4f7f\u7528pathlib.Path\u751f\u6210\u4e0e\u64cd\u4f5c\u7cfb\u7edf\u65e0\u5173\u7684\u8def\u5f84\uff0c\u56e0\u4e3a\u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf\u8def\u5f84\u7684\u2018/\u2019\u4f1a\u6709\u6240\u4e0d\u540c p = Path ( p ) # os-agnostic # \u5982\u679c\u8def\u5f84path\u4e3a\u5305\u542b\u56fe\u7247\u7684\u6587\u4ef6\u5939\u8def\u5f84 if p . is_dir (): # dir # glob.glab: \u8fd4\u56de\u6240\u6709\u5339\u914d\u7684\u6587\u4ef6\u8def\u5f84\u5217\u8868 \u9012\u5f52\u83b7\u53d6p\u8def\u5f84\u4e0b\u6240\u6709\u6587\u4ef6 f += glob . glob ( str ( p / '**' / '*.*' ), recursive = True ) # f = list(p.rglob('**/*.*')) # pathlib # \u5982\u679c\u8def\u5f84path\u4e3a\u5305\u542b\u56fe\u7247\u8def\u5f84\u7684txt\u6587\u4ef6 elif p . is_file (): # file with open ( p , 'r' ) as t : t = t . read () . strip () . splitlines () # \u83b7\u53d6\u56fe\u7247\u8def\u5f84\uff0c\u66f4\u6362\u76f8\u5bf9\u8def\u5f84 # \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84\u7684\u4e0a\u7ea7\u7236\u76ee\u5f55 os.sep\u4e3a\u8def\u5f84\u91cc\u7684\u5206\u9694\u7b26\uff08\u4e0d\u540c\u8def\u5f84\u7684\u5206\u9694\u7b26\u4e0d\u540c\uff0cos.sep\u53ef\u4ee5\u6839\u636e\u7cfb\u7edf\u81ea\u9002\u5e94\uff09 parent = str ( p . parent ) + os . sep f += [ x . replace ( './' , parent ) if x . startswith ( './' ) else x for x in t ] # local to global path # f += [p.parent / x.lstrip(os.sep) for x in t] # local to global path (pathlib) else : raise Exception ( f ' { prefix }{ p } does not exist' ) # \u7834\u6298\u53f7\u66ff\u6362\u4e3aos.sep\uff0cos.path.splitext(x)\u5c06\u6587\u4ef6\u540d\u4e0e\u6269\u5c55\u540d\u5206\u5f00\u5e76\u8fd4\u56de\u4e00\u4e2a\u5217\u8868 # \u7b5b\u9009f\u4e2d\u6240\u6709\u7684\u56fe\u7247\u6587\u4ef6 self . im_files = sorted ( x . replace ( \"/\" , os . sep ) for x in f if x . split ( \".\" )[ - 1 ] . lower () in IMG_FORMATS ) # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS]) # pathlib assert self . im_files , f \" { prefix } No images found\" except Exception as e : raise Exception ( f \" { prefix } Error loading data from { path } : { e } \\n See { HELP_URL } \" ) # Check cache 3\u6839\u636eimgs\u8def\u5f84\u627e\u5230labels\u7684\u8def\u5f84self.label_files self . label_files = img2label_paths ( self . im_files ) # labels # 4\u3001cache label \u4e0b\u6b21\u8fd0\u884c\u8fd9\u4e2a\u811a\u672c\u7684\u65f6\u5019\u76f4\u63a5\u4ececache\u4e2d\u53d6label\u800c\u4e0d\u662f\u53bb\u6587\u4ef6\u4e2d\u53d6label \u901f\u5ea6\u66f4\u5feb cache_path = ( p if p . is_file () else Path ( self . label_files [ 0 ]) . parent ) . with_suffix ( \".cache\" ) try : # \u5982\u679c\u6709cache\u6587\u4ef6\uff0c\u76f4\u63a5\u52a0\u8f7d exists=True: \u662f\u5426\u5df2\u4ececache\u6587\u4ef6\u4e2d\u8bfb\u51fa\u4e86nf, nm, ne, nc, n\u7b49\u4fe1\u606f cache , exists = np . load ( cache_path , allow_pickle = True ) . item (), True # load dict assert cache [ \"version\" ] == self . cache_version # matches current version assert cache [ \"hash\" ] == get_hash ( self . label_files + self . im_files ) # identical hash except Exception : # \u5982\u679c\u56fe\u7247\u7248\u672c\u4fe1\u606f\u6216\u8005\u6587\u4ef6\u5217\u8868\u7684hash\u503c\u5bf9\u4e0d\u4e0a\u53f7 \u8bf4\u660e\u672c\u5730\u6570\u636e\u96c6\u56fe\u7247\u548clabel\u53ef\u80fd\u53d1\u751f\u4e86\u53d8\u5316 \u5c31\u91cd\u65b0cache label\u6587\u4ef6 cache , exists = self . cache_labels ( cache_path , prefix ), False # run cache ops # Display cache # \u6253\u5370cache\u7684\u7ed3\u679c nf nm ne nc n = \u627e\u5230\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u6f0f\u6389\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u7a7a\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u635f\u574f\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u603b\u7684\u6807\u7b7e\u6570\u91cf nf , nm , ne , nc , n = cache . pop ( \"results\" ) # found, missing, empty, corrupt, total # \u5982\u679c\u5df2\u7ecf\u4ececache\u6587\u4ef6\u8bfb\u51fa\u4e86nf nm ne nc n\u7b49\u4fe1\u606f\uff0c\u76f4\u63a5\u663e\u793a\u6807\u7b7e\u4fe1\u606f msgs\u4fe1\u606f\u7b49 if exists and LOCAL_RANK in { - 1 , 0 }: d = f \"Scanning ' { cache_path } ' images and labels... { nf } found, { nm } missing, { ne } empty, { nc } corrupt\" tqdm ( None , desc = prefix + d , total = n , initial = n , bar_format = BAR_FORMAT ) # display cache results if cache [ \"msgs\" ]: LOGGER . info ( \" \\n \" . join ( cache [ \"msgs\" ])) # display warnings # \u6570\u636e\u96c6\u6ca1\u6709\u6807\u7b7e\u4fe1\u606f \u5c31\u53d1\u51fa\u8b66\u544a\u5e76\u663e\u793a\u6807\u7b7elabel\u4e0b\u8f7d\u5730\u5740help_url assert nf > 0 or not augment , f \" { prefix } No labels in { cache_path } . Can not train without labels. See { HELP_URL } \" # 5\u3001Read cache \u4ececache\u4e2d\u8bfb\u51fa\u6700\u65b0\u53d8\u91cf\u8d4b\u7ed9self \u65b9\u4fbf\u7ed9forward\u4e2d\u4f7f\u7528 # cache\u4e2d\u7684\u952e\u503c\u5bf9\u6700\u521d\u6709: cache[img_file]=[l, shape, segments] cache[hash] cache[results] cache[msg] cache[version] # \u5148\u4ececache\u4e2d\u53bb\u9664cache\u6587\u4ef6\u4e2d\u5176\u4ed6\u65e0\u5173\u952e\u503c\u5982:'hash', 'version', 'msgs'\u7b49\u90fd\u5220\u9664 [ cache . pop ( k ) for k in ( 'hash' , 'version' , 'msgs' )] # remove items # pop\u6389results\u3001hash\u3001version\u3001msgs\u540e\u53ea\u5269\u4e0bcache[img_file]=[l, shape, segments] # cache.values(): \u53d6cache\u4e2d\u6240\u6709\u503c \u5bf9\u5e94\u6240\u6709l, shape, segments # labels: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label labels\u5b58\u50a8\u7684label\u5c31\u90fd\u662f\u539f\u59cblabel(\u90fd\u662f\u6b63\u5e38\u7684\u77e9\u5f62label) # \u5426\u5219\u5c06\u6240\u6709\u56fe\u7247\u6b63\u5e38gt\u7684label\u5b58\u5165labels \u4e0d\u6b63\u5e38gt(\u5b58\u5728\u4e00\u4e2a\u591a\u8fb9\u5f62)\u7ecf\u8fc7segments2boxes\u8f6c\u6362\u4e3a\u6b63\u5e38\u7684\u77e9\u5f62label # shapes: \u6240\u6709\u56fe\u7247\u7684shape # self.segments: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label self.segments=None # \u5426\u5219\u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u6240\u6709\u5b58\u5728\u591a\u8fb9\u5f62gt\u7684\u56fe\u7247\u7684\u6240\u6709\u539f\u59cblabel(\u80af\u5b9a\u6709\u591a\u8fb9\u5f62label \u4e5f\u53ef\u80fd\u6709\u77e9\u5f62\u6b63\u5e38label \u672a\u77e5\u6570) # zip \u662f\u56e0\u4e3acache\u4e2d\u6240\u6709labels\u3001shapes\u3001segments\u4fe1\u606f\u90fd\u662f\u6309\u6bcf\u5f20img\u5206\u5f00\u5b58\u50a8\u7684, zip\u662f\u5c06\u6240\u6709\u56fe\u7247\u5bf9\u5e94\u7684\u4fe1\u606f\u53e0\u5728\u4e00\u8d77 labels , shapes , self . segments = zip ( * cache . values ()) # segments: \u90fd\u662f[] self . labels = list ( labels ) self . shapes = np . array ( shapes ) self . im_files = list ( cache . keys ()) # update self . label_files = img2label_paths ( cache . keys ()) # update \u66f4\u65b0\u6240\u6709\u56fe\u7247\u7684label_files\u4fe1\u606f(\u56e0\u4e3aimg_files\u4fe1\u606f\u53ef\u80fd\u53d1\u751f\u4e86\u53d8\u5316) n = len ( shapes ) # number of images bi = np . floor ( np . arange ( n ) / batch_size ) . astype ( np . int ) # batch index nb = bi [ - 1 ] + 1 # number of batches self . batch = bi # batch index of image \u6240\u6709\u56fe\u7247\u7684index self . n = n self . indices = range ( n ) # Update labels include_class = [] # filter labels to include only these classes (optional) include_class_array = np . array ( include_class ) . reshape ( 1 , - 1 ) for i , ( label , segment ) in enumerate ( zip ( self . labels , self . segments )): if include_class : j = ( label [:, 0 : 1 ] == include_class_array ) . any ( 1 ) self . labels [ i ] = label [ j ] if segment : self . segments [ i ] = segment [ j ] if single_cls : # single-class training, merge all classes into 0 self . labels [ i ][:, 0 ] = 0 if segment : self . segments [ i ][:, 0 ] = 0 # Rectangular Training # 6\u3001\u4e3aRectangular Training\u4f5c\u51c6\u5907 # \u8fd9\u91cc\u4e3b\u8981\u662f\u6ce8\u610fshapes\u7684\u751f\u6210 \u8fd9\u4e00\u6b65\u5f88\u91cd\u8981 \u56e0\u4e3a\u5982\u679c\u91c7\u6837\u77e9\u5f62\u8bad\u7ec3\u90a3\u4e48\u6574\u4e2abatch\u7684\u5f62\u72b6\u8981\u4e00\u6837 \u5c31\u8981\u8ba1\u7b97\u8fd9\u4e2a\u7b26\u5408\u6574\u4e2abatch\u7684shape # \u800c\u4e14\u8fd8\u8981\u5bf9\u6570\u636e\u96c6\u6309\u7167\u9ad8\u5bbd\u6bd4\u8fdb\u884c\u6392\u5e8f \u8fd9\u6837\u624d\u80fd\u4fdd\u8bc1\u540c\u4e00\u4e2abatch\u7684\u56fe\u7247\u7684\u5f62\u72b6\u5dee\u4e0d\u591a\u76f8\u540c \u518d\u9009\u5219\u4e00\u4e2a\u5171\u540c\u7684shape\u4ee3\u4ef7\u4e5f\u6bd4\u8f83\u5c0f if self . rect : # Sort by aspect ratio s = self . shapes # wh ar = s [:, 1 ] / s [:, 0 ] # aspect ratio irect = ar . argsort () # \u6839\u636e\u9ad8\u5bbd\u6bd4\u6392\u5e8f self . img_files = [ self . img_files [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684img_files self . label_files = [ self . label_files [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684label_files self . labels = [ self . labels [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684labels self . shapes = s [ irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684wh ar = ar [ irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684aspect ratio # \u8ba1\u7b97\u6bcf\u4e2abatch\u91c7\u7528\u7684\u7edf\u4e00\u5c3a\u5ea6 Set training image shapes shapes = [[ 1 , 1 ]] * nb # nb: number of batches for i in range ( nb ): ari = ar [ bi == i ] # bi: batch index mini , maxi = ari . min (), ari . max () # \u83b7\u53d6\u7b2ci\u4e2abatch\u4e2d\uff0c\u6700\u5c0f\u548c\u6700\u5927\u9ad8\u5bbd\u6bd4 # \u5982\u679c\u9ad8/\u5bbd\u5c0f\u4e8e1(w > h)\uff0c\u5c06w\u8bbe\u4e3aimg_size\uff08\u4fdd\u8bc1\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0d\u53d8\u8fdb\u884c\u7f29\u653e\uff09 if maxi < 1 : shapes [ i ] = [ maxi , 1 ] # maxi: h\u76f8\u5bf9\u6307\u5b9a\u5c3a\u5ea6\u7684\u6bd4\u4f8b 1: w\u76f8\u5bf9\u6307\u5b9a\u5c3a\u5ea6\u7684\u6bd4\u4f8b # \u5982\u679c\u9ad8/\u5bbd\u5927\u4e8e1(w < h)\uff0c\u5c06h\u8bbe\u7f6e\u4e3aimg_size\uff08\u4fdd\u8bc1\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0d\u53d8\u8fdb\u884c\u7f29\u653e\uff09 elif mini > 1 : shapes [ i ] = [ 1 , 1 / mini ] # \u8ba1\u7b97\u6bcf\u4e2abatch\u8f93\u5165\u7f51\u7edc\u7684shape\u503c(\u5411\u4e0a\u8bbe\u7f6e\u4e3a32\u7684\u6574\u6570\u500d) # \u8981\u6c42\u6bcf\u4e2abatch_shapes\u7684\u9ad8\u5bbd\u90fd\u662f32\u7684\u6574\u6570\u500d\uff0c\u6240\u4ee5\u8981\u5148\u9664\u4ee532\uff0c\u53d6\u6574\u518d\u4e58\u4ee532\uff08\u4e0d\u8fc7img_size\u5982\u679c\u662f32\u500d\u6570\u8fd9\u91cc\u5c31\u6ca1\u5fc5\u8981\u4e86\uff09 self . batch_shapes = np . ceil ( np . array ( shapes ) * img_size / stride + pad ) . astype ( np . int ) * stride # 7\u3001\u662f\u5426\u9700\u8981cache image \u4e00\u822c\u662fFalse \u56e0\u4e3aRAM\u4f1a\u4e0d\u8db3 cache label\u8fd8\u53ef\u4ee5 \u4f46\u662fcache image\u5c31\u592a\u5927\u4e86 \u6240\u4ee5\u4e00\u822c\u4e0d\u7528 # Cache images into RAM/disk for faster training (WARNING: large datasets may exceed system resources) self . ims = [ None ] * n self . npy_files = [ Path ( f ) . with_suffix ( \".npy\" ) for f in self . im_files ] if cache_images : gb = 0 # Gigabytes of cached images self . im_hw0 , self . im_hw = [ None ] * n , [ None ] * n fcn = self . cache_images_to_disk if cache_images == \"disk\" else self . load_image results = ThreadPool ( NUM_THREADS ) . imap ( fcn , range ( n )) pbar = tqdm ( enumerate ( results ), total = n , bar_format = BAR_FORMAT , disable = LOCAL_RANK > 0 ) for i , x in pbar : if cache_images == \"disk\" : gb += self . npy_files [ i ] . stat () . st_size else : # 'ram' ( self . ims [ i ], self . im_hw0 [ i ], self . im_hw [ i ], ) = x # im, hw_orig, hw_resized = load_image(self, i) gb += self . ims [ i ] . nbytes pbar . desc = f \" { prefix } Caching images ( { gb / 1E9 : .1f } GB { cache_images } )\" pbar . close () 4.2 cache_labels \u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u52a0\u8f7d\u6587\u4ef6\u8def\u5f84\u4e2d\u7684label\u4fe1\u606f\u751f\u6210cache\u6587\u4ef6\u3002cache\u6587\u4ef6\u4e2d\u5305\u62ec\u7684\u4fe1\u606f\u6709\uff1aim_file, l, shape, segments, hash, results, msgs, version\u7b49\uff0c\u5177\u4f53\u770b\u4ee3\u7801\u6ce8\u91ca\u3002 def cache_labels ( self , path = Path ( './labels.cache' ), prefix = '' ): \"\"\"\u7528\u5728__init__\u51fd\u6570\u4e2d cache\u6570\u636e\u96c6label \u52a0\u8f7dlabel\u4fe1\u606f\u751f\u6210cache\u6587\u4ef6 Cache dataset labels, check images and read shapes :params path: cache\u6587\u4ef6\u4fdd\u5b58\u5730\u5740 :params prefix: \u65e5\u5fd7\u5934\u90e8\u4fe1\u606f(\u5f69\u6253\u9ad8\u4eae\u90e8\u5206) :return x: cache\u4e2d\u4fdd\u5b58\u7684\u5b57\u5178 \u5305\u62ec\u7684\u4fe1\u606f\u6709: x[im_file] = [l, shape, segments] \u4e00\u5f20\u56fe\u7247\u4e00\u4e2alabel\u76f8\u5bf9\u5e94\u7684\u4fdd\u5b58\u5230x, \u6700\u7ec8x\u4f1a\u4fdd\u5b58\u6240\u6709\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84\u3001gt\u6846\u7684\u4fe1\u606f\u3001\u5f62\u72b6shape\u3001\u6240\u6709\u7684\u591a\u8fb9\u5f62gt\u4fe1\u606f im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 l: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, cls+xywh(normalized)] shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape segments: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u6240\u6709gt\u7684label\u4fe1\u606f(\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] hash: \u5f53\u524d\u56fe\u7247\u548clabel\u6587\u4ef6\u7684hash\u503c 1 results: \u627e\u5230\u7684label\u4e2a\u6570nf, \u4e22\u5931label\u4e2a\u6570nm, \u7a7alabel\u4e2a\u6570ne, \u7834\u635flabel\u4e2a\u6570nc, \u603bimg/label\u4e2a\u6570len(self.img_files) msgs: \u6240\u6709\u6570\u636e\u96c6\u7684msgs\u4fe1\u606f version: \u5f53\u524dcache version \"\"\" x = {} # \u521d\u59cb\u5316\u6700\u7ec8cache\u4e2d\u4fdd\u5b58\u7684\u5b57\u5178dict # \u521d\u59cb\u5316number missing, found, empty, corrupt, messages # \u521d\u59cb\u5316\u6574\u4e2a\u6570\u636e\u96c6: \u6f0f\u6389\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u627e\u5230\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u7a7a\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u9519\u8bef\u6807\u7b7e(label)\u603b\u6570\u91cf, \u6240\u6709\u9519\u8bef\u4fe1\u606f nm , nf , ne , nc , msgs = 0 , 0 , 0 , 0 , [] desc = f \" { prefix } Scanning ' { path . parent / path . stem } ' images and labels...\" # \u65e5\u5fd7 # \u591a\u8fdb\u7a0b\u8c03\u7528verify_image_label\u51fd\u6570 with Pool ( num_threads ) as pool : # \u5b9a\u4e49pbar\u8fdb\u5ea6\u6761 # pool.imap_unordered: \u5bf9\u5927\u91cf\u6570\u636e\u904d\u5386\u591a\u8fdb\u7a0b\u8ba1\u7b97 \u8fd4\u56de\u4e00\u4e2a\u8fed\u4ee3\u5668 # \u628aself.img_files, self.label_files, repeat(prefix) list\u4e2d\u7684\u503c\u4f5c\u4e3a\u53c2\u6570\u4f9d\u6b21\u9001\u5165(\u4e00\u6b21\u9001\u4e00\u4e2a)verify_image_label\u51fd\u6570 pbar = tqdm ( pool . imap_unordered ( verify_image_label , zip ( self . img_files , self . label_files , repeat ( prefix ))), desc = desc , total = len ( self . img_files )) # im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 # l: [gt_num, cls+xywh(normalized)] # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u539flabel(\u5168\u90e8\u662f\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e) # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u7ecf\u8fc7segments2boxes\u5904\u7406\u597d\u7684\u6807\u7b7e(\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e\u4e0d\u5904\u7406 \u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u77e9\u5f62\u6807\u7b7e) # shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape # segments: \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5b58\u50a8None # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5c31\u628a\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709label\u5b58\u50a8\u5230segments\u4e2d(\u82e5\u5e72\u4e2a\u6b63\u5e38gt \u82e5\u5e72\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] # nm_f(nm): number missing \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u4e22\u5931 \u4e22\u5931=1 \u5b58\u5728=0 # nf_f(nf): number found \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u5b58\u5728 \u5b58\u5728=1 \u4e22\u5931=0 # ne_f(ne): number empty \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u662f\u7a7a\u7684 \u7a7a\u7684=1 \u6ca1\u7a7a=0 # nc_f(nc): number corrupt \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u6587\u4ef6\u662f\u5426\u662f\u7834\u635f\u7684 \u7834\u635f\u7684=1 \u6ca1\u7834\u635f=0 # msg: \u8fd4\u56de\u7684msg\u4fe1\u606f label\u6587\u4ef6\u5b8c\u597d=\u2018\u2019 label\u6587\u4ef6\u7834\u635f=warning\u4fe1\u606f for im_file , l , shape , segments , nm_f , nf_f , ne_f , nc_f , msg in pbar : nm += nm_f # \u7d2f\u52a0\u603bnumber missing label nf += nf_f # \u7d2f\u52a0\u603bnumber found label ne += ne_f # \u7d2f\u52a0\u603bnumber empty label nc += nc_f # \u7d2f\u52a0\u603bnumber corrupt label if im_file : x [ im_file ] = [ l , shape , segments ] # \u4fe1\u606f\u5b58\u5165\u5b57\u5178 key=im_file value=[l, shape, segments] if msg : msgs . append ( msg ) # \u5c06msg\u52a0\u5165\u603bmsg pbar . desc = f \" { desc }{ nf } found, { nm } missing, { ne } empty, { nc } corrupted\" # \u65e5\u5fd7 pbar . close () # \u5173\u95ed\u8fdb\u5ea6\u6761 # \u65e5\u5fd7\u6253\u5370\u6240\u6709msg\u4fe1\u606f if msgs : logging . info ( ' \\n ' . join ( msgs )) # \u4e00\u5f20label\u90fd\u6ca1\u627e\u5230 \u65e5\u5fd7\u6253\u5370help_url\u4e0b\u8f7d\u5730\u5740 if nf == 0 : logging . info ( f ' { prefix } WARNING: No labels found in { path } . See { help_url } ' ) x [ 'hash' ] = get_hash ( self . label_files + self . img_files ) # \u5c06\u5f53\u524d\u56fe\u7247\u548clabel\u6587\u4ef6\u7684hash\u503c\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'results' ] = nf , nm , ne , nc , len ( self . img_files ) # \u5c06nf, nm, ne, nc, len(self.img_files)\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'msgs' ] = msgs # \u5c06\u6240\u6709\u6570\u636e\u96c6\u7684msgs\u4fe1\u606f\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'version' ] = 0.3 # \u5c06\u5f53\u524dcache version\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist try : torch . save ( x , path ) # save cache to path logging . info ( f ' { prefix } New cache created: { path } ' ) except Exception as e : logging . info ( f ' { prefix } WARNING: Cache directory { path . parent } is not writeable: { e } ' ) # path not writeable return x 4.3 getitem \u2003\u8fd9\u90e8\u5206\u662f\u6570\u636e\u589e\u5f3a\u51fd\u6570\uff0c\u4e00\u822c\u4e00\u6b21\u6027\u6267\u884cbatch_size\u6b21\u3002 def __getitem__ ( self , index ): \"\"\" \u8fd9\u90e8\u5206\u662f\u6570\u636e\u589e\u5f3a\u51fd\u6570\uff0c\u4e00\u822c\u4e00\u6b21\u6027\u6267\u884cbatch_size\u6b21\u3002 \u8bad\u7ec3 \u6570\u636e\u589e\u5f3a: mosaic(random_perspective) + hsv + \u4e0a\u4e0b\u5de6\u53f3\u7ffb\u8f6c \u6d4b\u8bd5 \u6570\u636e\u589e\u5f3a: letterbox :return torch.from_numpy(img): \u8fd9\u4e2aindex\u7684\u56fe\u7247\u6570\u636e(\u589e\u5f3a\u540e) [3, 640, 640] :return labels_out: \u8fd9\u4e2aindex\u56fe\u7247\u7684gt label [6, 6] = [gt_num, 0+class+xywh(normalized)] :return self.img_files[index]: \u8fd9\u4e2aindex\u56fe\u7247\u7684\u8def\u5f84\u5730\u5740 :return shapes: \u8fd9\u4e2abatch\u7684\u56fe\u7247\u7684shapes \u6d4b\u8bd5\u65f6(\u77e9\u5f62\u8bad\u7ec3)\u624d\u6709 \u9a8c\u8bc1\u65f6\u4e3aNone for COCO mAP rescaling \"\"\" # \u8fd9\u91cc\u53ef\u4ee5\u901a\u8fc7\u4e09\u79cd\u5f62\u5f0f\u83b7\u53d6\u8981\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u56fe\u7247index linear, shuffled, or image_weights index = self . indices [ index ] # linear, shuffled, or image_weights hyp = self . hyp # \u8d85\u53c2 \u5305\u542b\u4f17\u591a\u6570\u636e\u589e\u5f3a\u8d85\u53c2 mosaic = self . mosaic and random . random () < hyp [ \"mosaic\" ] # mosaic\u589e\u5f3a \u5bf9\u56fe\u50cf\u8fdb\u884c4\u5f20\u56fe\u62fc\u63a5\u8bad\u7ec3 \u4e00\u822c\u8bad\u7ec3\u65f6\u8fd0\u884c # mosaic + MixUp if mosaic : # Load mosaic img , labels = self . load_mosaic ( index ) shapes = None # MixUp augmentation if random . random () < hyp [ \"mixup\" ]: img , labels = mixup ( img , labels , * self . load_mosaic ( random . randint ( 0 , self . n - 1 ))) else : # Load image # \u8f7d\u5165\u56fe\u7247 \u8f7d\u5165\u56fe\u7247\u540e\u8fd8\u4f1a\u8fdb\u884c\u4e00\u6b21resize \u5c06\u5f53\u524d\u56fe\u7247\u7684\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u7684\u5927\u5c0f(512), \u8f83\u5c0f\u8fb9\u540c\u6bd4\u4f8b\u7f29\u653e # load image img=(343, 512, 3)=(h, w, c) (h0, w0)=(335, 500) numpy index=4 # img: resize\u540e\u7684\u56fe\u7247 (h0, w0): \u539f\u59cb\u56fe\u7247\u7684hw (h, w): resize\u540e\u7684\u56fe\u7247\u7684hw # \u8fd9\u4e00\u6b65\u662f\u5c06(335, 500, 3) resize-> (343, 512, 3) img , ( h0 , w0 ), ( h , w ) = self . load_image ( index ) # Letterbox # letterbox\u4e4b\u524d\u786e\u5b9a\u8fd9\u5f20\u5f53\u524d\u56fe\u7247letterbox\u4e4b\u540e\u7684shape # \u5982\u679c\u4e0d\u7528self.rect\u77e9\u5f62\u8bad\u7ec3shape\u5c31\u662fself.img_size # \u5982\u679c\u4f7f\u7528self.rect\u77e9\u5f62\u8bad\u7ec3shape\u5c31\u662f\u5f53\u524dbatch\u7684shape # \u56e0\u4e3a\u77e9\u5f62\u8bad\u7ec3\u7684\u8bdd\u6211\u4eec\u6574\u4e2abatch\u7684shape\u5fc5\u987b\u7edf\u4e00(\u5728__init__\u51fd\u6570\u7b2c6\u8282\u5185\u5bb9) shape = self . batch_shapes [ self . batch [ index ]] if self . rect else self . img_size # final letterboxed shape img , ratio , pad = letterbox ( img , shape , auto = False , scaleup = self . augment ) shapes = ( h0 , w0 ), (( h / h0 , w / w0 ), pad ) # for COCO mAP rescaling labels = self . labels [ index ] . copy () if labels . size : # normalized xywh to pixel xyxy format labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], ratio [ 0 ] * w , ratio [ 1 ] * h , padw = pad [ 0 ], padh = pad [ 1 ]) if self . augment : # random_perspective\u589e\u5f3a: \u968f\u673a\u5bf9\u56fe\u7247\u8fdb\u884c\u65cb\u8f6c\uff0c\u5e73\u79fb\uff0c\u7f29\u653e\uff0c\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362 img , labels = random_perspective ( img , labels , degrees = hyp [ \"degrees\" ], translate = hyp [ \"translate\" ], scale = hyp [ \"scale\" ], shear = hyp [ \"shear\" ], perspective = hyp [ \"perspective\" ], ) nl = len ( labels ) # number of labels if nl : labels [:, 1 : 5 ] = xyxy2xywhn ( labels [:, 1 : 5 ], w = img . shape [ 1 ], h = img . shape [ 0 ], clip = True , eps = 1e-3 ) if self . augment : # Albumentations img , labels = self . albumentations ( img , labels ) nl = len ( labels ) # update after albumentations # HSV color-space \u8272\u57df\u7a7a\u95f4\u589e\u5f3aAugment colorspace augment_hsv ( img , hgain = hyp [ \"hsv_h\" ], sgain = hyp [ \"hsv_s\" ], vgain = hyp [ \"hsv_v\" ]) # Flip up-down if random . random () < hyp [ \"flipud\" ]: img = np . flipud ( img ) if nl : labels [:, 2 ] = 1 - labels [:, 2 ] # Flip left-right \u968f\u673a\u5de6\u53f3\u7ffb\u8f6c if random . random () < hyp [ \"fliplr\" ]: img = np . fliplr ( img ) if nl : labels [:, 1 ] = 1 - labels [:, 1 ] # Cutouts # labels = cutout(img, labels, p=0.5) # nl = len(labels) # update after cutout # 6\u4e2a\u503c\u7684tensor \u521d\u59cb\u5316\u6807\u7b7e\u6846\u5bf9\u5e94\u7684\u56fe\u7247\u5e8f\u53f7, \u914d\u5408\u4e0b\u9762\u7684collate_fn\u4f7f\u7528 labels_out = flow . zeros (( nl , 6 )) if nl : labels_out [:, 1 :] = flow . from_numpy ( labels ) # Convert img = img . transpose (( 2 , 0 , 1 ))[:: - 1 ] # HWC to CHW, BGR to RGB img = np . ascontiguousarray ( img ) # img\u53d8\u6210\u5185\u5b58\u8fde\u7eed\u7684\u6570\u636e \u52a0\u5feb\u8fd0\u7b97 return flow . from_numpy ( img ), labels_out , self . im_files [ index ], shapes 4.4 collate_fn \u2003collate_fn \u4e00\u822c\u4e5f\u53ef\u4ee5\u53eb\u8c03\u6574\u51fd\u6570,\u5f88\u591a\u4eba\u4ee5\u4e3a\u5199\u5b8c init \u548c getitem \u51fd\u6570\u6570\u636e\u589e\u5f3a\u5c31\u505a\u5b8c\u4e86\uff0c\u6211\u4eec\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u786e\u5199\u5b8c\u8fd9\u4e24\u4e2a\u51fd\u6570\u5c31\u53ef\u4ee5\u4e86\uff0c\u56e0\u4e3a\u7cfb\u7edf\u4e2d\u662f\u7ed9\u6211\u4eec\u5199\u597d\u4e86\u4e00\u4e2acollate_fn\u51fd\u6570\u7684\uff0c\u4f46\u662f\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u6211\u4eec\u5374\u9700\u8981\u91cd\u5199collate_fn\u51fd\u6570\uff0c\u4e0b\u9762\u6211\u4f1a\u4ed4\u7ec6\u7684\u8bb2\u89e3\u8fd9\u6837\u505a\u7684\u539f\u56e0\uff08\u4ee3\u7801\u4e2d\u6ce8\u91ca\uff09\u3002 \u540c\u6837\u5728create_dataloader\u4e2d\u751f\u6210dataloader\u65f6\u8c03\u7528\uff1a @staticmethod def collate_fn4 ( batch ): \"\"\"\u540c\u6837\u5728create_dataloader\u4e2d\u751f\u6210dataloader\u65f6\u8c03\u7528\uff1a \u8fd9\u91cc\u662fyolo-v5\u4f5c\u8005\u5b9e\u9a8c\u6027\u7684\u4e00\u4e2a\u4ee3\u7801 quad-collate function \u5f53train.py\u7684opt\u53c2\u6570quad=True \u5219\u8c03\u7528collate_fn4\u4ee3\u66ffcollate_fn \u4f5c\u7528: \u5982\u4e4b\u524d\u7528collate_fn\u53ef\u4ee5\u8fd4\u56de\u56fe\u7247[16, 3, 640, 640] \u7ecf\u8fc7collate_fn4\u5219\u8fd4\u56de\u56fe\u7247[4, 3, 1280, 1280] \u5c064\u5f20mosaic\u56fe\u7247[1, 3, 640, 640]\u5408\u6210\u4e00\u5f20\u5927\u7684mosaic\u56fe\u7247[1, 3, 1280, 1280] \u5c06\u4e00\u4e2abatch\u7684\u56fe\u7247\u6bcf\u56db\u5f20\u5904\u7406, 0.5\u7684\u6982\u7387\u5c06\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5230\u4e00\u5f20\u5927\u56fe\u4e0a\u8bad\u7ec3, 0.5\u6982\u7387\u76f4\u63a5\u5c06\u67d0\u5f20\u56fe\u7247\u4e0a\u91c7\u6837\u4e24\u500d\u8bad\u7ec3 \"\"\" # img: \u6574\u4e2abatch\u7684\u56fe\u7247 [16, 3, 640, 640] # label: \u6574\u4e2abatch\u7684label\u6807\u7b7e [num_target, img_index+class_index+xywh(normalized)] # path: \u6574\u4e2abatch\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84 # shapes: (h0, w0), ((h / h0, w / w0), pad) for COCO mAP rescaling img , label , path , shapes = zip ( * batch ) # transposed n = len ( shapes ) // 4 # collate_fn4\u5904\u7406\u540e\u8fd9\u4e2abatch\u4e2d\u56fe\u7247\u7684\u4e2a\u6570 im4 , label4 , path4 , shapes4 = [], [], path [: n ], shapes [: n ] # \u521d\u59cb\u5316 ho = flow . tensor ([[ 0.0 , 0 , 0 , 1 , 0 , 0 ]]) wo = flow . tensor ([[ 0.0 , 0 , 1 , 0 , 0 , 0 ]]) s = flow . tensor ([[ 1 , 1 , 0.5 , 0.5 , 0.5 , 0.5 ]]) # scale for i in range ( n ): # zidane flow.zeros(16,3,720,1280) # BCHW i *= 4 # \u91c7\u6837 [0, 4, 8, 16] if random . random () < 0.5 : # \u968f\u673a\u6570\u5c0f\u4e8e0.5\u5c31\u76f4\u63a5\u5c06\u67d0\u5f20\u56fe\u7247\u4e0a\u91c7\u6837\u4e24\u500d\u8bad\u7ec3 im = F . interpolate ( img [ i ] . unsqueeze ( 0 ) . float (), scale_factor = 2.0 , mode = \"bilinear\" , align_corners = False ,)[ 0 ] . type ( img [ i ] . type ()) lb = label [ i ] else : # \u968f\u673a\u6570\u5927\u4e8e0.5\u5c31\u5c06\u56db\u5f20\u56fe\u7247(mosaic\u540e\u7684)\u62fc\u63a5\u5230\u4e00\u5f20\u5927\u56fe\u4e0a\u8bad\u7ec3 im = flow . cat ( ( flow . cat (( img [ i ], img [ i + 1 ]), 1 ), flow . cat (( img [ i + 2 ], img [ i + 3 ]), 1 ), ), 2 , ) lb = flow . cat (( label [ i ], label [ i + 1 ] + ho , label [ i + 2 ] + wo , label [ i + 3 ] + ho + wo ), 0 ) * s im4 . append ( im ) label4 . append ( lb ) # \u540e\u9762\u8fd4\u56de\u7684\u90e8\u5206\u548ccollate_fn\u5c31\u5dee\u4e0d\u591a\u4e86 \u539f\u56e0\u548c\u89e3\u91ca\u90fd\u5199\u5728\u4e0a\u4e00\u4e2a\u51fd\u6570\u4e86 \u81ea\u5df1debug\u770b\u4e00\u4e0b\u5427 for i , lb in enumerate ( label4 ): lb [:, 0 ] = i # add target image index for build_targets() return flow . stack ( im4 , 0 ), flow . cat ( label4 , 0 ), path4 , shapes4 5. img2label_paths \u2003\u8fd9\u4e2a\u6587\u4ef6\u662f\u6839\u636e\u6570\u636e\u96c6\u4e2d\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709labels\u5bf9\u5e94\u7684\u8def\u5f84\u3002 \u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__init__\u51fd\u6570\u4e2d\u3002 def img2label_paths ( img_paths ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__init__\u51fd\u6570\u4e2d \u6839\u636eimgs\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u5bf9\u5e94labels\u7684\u8def\u5f84 Define label paths as a function of image paths :params img_paths: {list: 50} \u6574\u4e2a\u6570\u636e\u96c6\u7684\u56fe\u7247\u76f8\u5bf9\u8def\u5f84 \u4f8b\u5982: '..\\\\datasets\\\\VOC\\\\images\\\\train2007\\\\000012.jpg' => '..\\\\datasets\\\\VOC\\\\labels\\\\train2007\\\\000012.jpg' \"\"\" # \u56e0\u4e3apython\u662f\u8de8\u5e73\u53f0\u7684,\u5728Windows\u4e0a,\u6587\u4ef6\u7684\u8def\u5f84\u5206\u9694\u7b26\u662f'\\',\u5728Linux\u4e0a\u662f'/' # \u4e3a\u4e86\u8ba9\u4ee3\u7801\u5728\u4e0d\u540c\u7684\u5e73\u53f0\u4e0a\u90fd\u80fd\u8fd0\u884c\uff0c\u90a3\u4e48\u8def\u5f84\u5e94\u8be5\u5199'\\'\u8fd8\u662f'/'\u5462\uff1f os.sep\u6839\u636e\u4f60\u6240\u5904\u7684\u5e73\u53f0, \u81ea\u52a8\u91c7\u7528\u76f8\u5e94\u7684\u5206\u9694\u7b26\u53f7 # sa: '\\\\images\\\\' sb: '\\\\labels\\\\' sa , sb = os . sep + 'images' + os . sep , os . sep + 'labels' + os . sep # /images/, /labels/ substrings # \u628aimg_paths\u4e2d\u6240\u4ee5\u56fe\u7247\u8def\u5f84\u4e2d\u7684images\u66ff\u6362\u4e3alabels return [ sb . join ( x . rsplit ( sa , 1 )) . rsplit ( '.' , 1 )[ 0 ] + '.txt' for x in img_paths ] 6. verify_image_label \u2003\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u68c0\u67e5\u6bcf\u4e00\u5f20\u56fe\u7247\u548c\u6bcf\u4e00\u5f20label\u6587\u4ef6\u662f\u5426\u5b8c\u597d\u3002 \u2003 \u56fe\u7247\u6587\u4ef6: \u68c0\u67e5\u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027 \u2003 label\u6587\u4ef6: \u68c0\u67e5\u6bcf\u4e2agt\u5fc5\u987b\u662f\u77e9\u5f62(\u6bcf\u884c\u90fd\u5f97\u662f5\u4e2a\u6570 class+xywh) + \u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 + \u6807\u7b7e\u5750\u6807xywh\u662f\u5426\u5f52\u4e00\u5316 + \u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 verify_image_label\u51fd\u6570\u4ee3\u7801\uff1a def verify_image_label ( args ): \"\"\"\u7528\u5728cache_labels\u51fd\u6570\u4e2d \u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u6bcf\u5f20\u56fe\u7247\u548c\u6bcf\u5f20laebl\u662f\u5426\u5b8c\u597d \u56fe\u7247\u6587\u4ef6: \u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027 label\u6587\u4ef6: \u6bcf\u4e2agt\u5fc5\u987b\u662f\u77e9\u5f62(\u6bcf\u884c\u90fd\u5f97\u662f5\u4e2a\u6570 class+xywh) + \u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 + \u6807\u7b7e\u5750\u6807xywh\u662f\u5426\u5f52\u4e00\u5316 + \u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 :params im_file: \u6570\u636e\u96c6\u4e2d\u4e00\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 :params lb_file: \u6570\u636e\u96c6\u4e2d\u4e00\u5f20\u56fe\u7247\u7684label\u76f8\u5bf9\u8def\u5f84 :params prefix: \u65e5\u5fd7\u5934\u90e8\u4fe1\u606f(\u5f69\u6253\u9ad8\u4eae\u90e8\u5206) :return im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 :return l: [gt_num, cls+xywh(normalized)] \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u539flabel(\u5168\u90e8\u662f\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e) \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u7ecf\u8fc7segments2boxes\u5904\u7406\u597d\u7684\u6807\u7b7e(\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e\u4e0d\u5904\u7406 \u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u77e9\u5f62\u6807\u7b7e) :return shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape :return segments: \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5b58\u50a8None \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5c31\u628a\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709label\u5b58\u50a8\u5230segments\u4e2d(\u82e5\u5e72\u4e2a\u6b63\u5e38gt \u82e5\u5e72\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] :return nm: number missing \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u4e22\u5931 \u4e22\u5931=1 \u5b58\u5728=0 :return nf: number found \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u5b58\u5728 \u5b58\u5728=1 \u4e22\u5931=0 :return ne: number empty \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u662f\u7a7a\u7684 \u7a7a\u7684=1 \u6ca1\u7a7a=0 :return nc: number corrupt \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u6587\u4ef6\u662f\u5426\u662f\u7834\u635f\u7684 \u7834\u635f\u7684=1 \u6ca1\u7834\u635f=0 :return msg: \u8fd4\u56de\u7684msg\u4fe1\u606f label\u6587\u4ef6\u5b8c\u597d=\u2018\u2019 label\u6587\u4ef6\u7834\u635f=warning\u4fe1\u606f \"\"\" # Verify one image-label pair im_file , lb_file , prefix = args nm , nf , ne , nc , msg , segments = ( 0 , 0 , 0 , 0 , \"\" , [], ) # number (missing, found, empty, corrupt), message, segments try : # verify images \u68c0\u67e5\u8fd9\u5f20\u56fe\u7247(\u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027) verify images im = Image . open ( im_file ) # \u6253\u5f00\u56fe\u7247\u6587\u4ef6 im . verify () # PIL verify \u68c0\u67e5\u56fe\u7247\u5185\u5bb9\u548c\u683c\u5f0f\u662f\u5426\u6b63\u5e38 shape = exif_size ( im ) # image size \u5f53\u524d\u56fe\u7247\u7684\u5927\u5c0f image size # \u56fe\u7247\u5927\u5c0f\u5fc5\u987b\u5927\u4e8e9\u4e2apixels assert ( shape [ 0 ] > 9 ) & ( shape [ 1 ] > 9 ), f \"image size { shape } <10 pixels\" # \u56fe\u7247\u683c\u5f0f\u5fc5\u987b\u5728img_format\u4e2d assert im . format . lower () in IMG_FORMATS , f \"invalid image format { im . format } \" if im . format . lower () in ( \"jpg\" , \"jpeg\" ): # \u68c0\u67e5jpg\u683c\u5f0f\u6587\u4ef6 with open ( im_file , \"rb\" ) as f : # f.seek: -2 \u504f\u79fb\u91cf \u5411\u6587\u4ef6\u5934\u65b9\u5411\u4e2d\u79fb\u52a8\u7684\u5b57\u8282\u6570 2 \u76f8\u5bf9\u4f4d\u7f6e \u4ece\u6587\u4ef6\u5c3e\u5f00\u59cb\u504f\u79fb f . seek ( - 2 , 2 ) # f.read(): \u8bfb\u53d6\u56fe\u7247\u6587\u4ef6 \u6307\u4ee4: \\xff\\xd9 \u68c0\u6d4b\u6574\u5f20\u56fe\u7247\u662f\u5426\u5b8c\u6574 \u5982\u679c\u4e0d\u5b8c\u6574\u5c31\u8fd4\u56decorrupted JPEG if f . read () != b \" \\xff\\xd9 \" : # corrupt JPEG ImageOps . exif_transpose ( Image . open ( im_file )) . save ( im_file , \"JPEG\" , subsampling = 0 , quality = 100 ) msg = f \" { prefix } WARNING: { im_file } : corrupt JPEG restored and saved\" # verify labels if os . path . isfile ( lb_file ): nf = 1 # label found with open ( lb_file ) as f : # \u8bfb\u53d6\u5f53\u524dlabel\u6587\u4ef6\u7684\u6bcf\u4e00\u884c: \u6bcf\u4e00\u884c\u90fd\u662f\u5f53\u524d\u56fe\u7247\u7684\u4e00\u4e2agt lb = [ x . split () for x in f . read () . strip () . splitlines () if len ( x )] # any() \u51fd\u6570\u7528\u4e8e\u5224\u65ad\u7ed9\u5b9a\u7684\u53ef\u8fed\u4ee3\u53c2\u6570 \u662f\u5426\u5168\u90e8\u4e3aFalse,\u5219\u8fd4\u56de False; \u5982\u679c\u6709\u4e00\u4e2a\u4e3a True,\u5219\u8fd4\u56deTrue # \u5982\u679c\u5f53\u524d\u56fe\u7247\u7684label\u6587\u4ef6\u67d0\u4e00\u5217\u6570\u5927\u4e8e8, \u5219\u8ba4\u4e3alabel\u662f\u5b58\u5728segment\u7684polygon\u70b9(\u591a\u8fb9\u5f62) # \u5c31\u4e0d\u662f\u77e9\u9635 \u5219\u5c06label\u4fe1\u606f\u5b58\u5165segment\u4e2d if any ( len ( x ) > 6 for x in lb ): # is segment # \u5f53\u524d\u56fe\u7247\u4e2d\u6240\u6709gt\u6846\u7684\u7c7b\u522b classes = np . array ([ x [ 0 ] for x in lb ], dtype = np . float32 ) # \u83b7\u5f97\u8fd9\u5f20\u56fe\u4e2d\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) # \u56e0\u4e3asegment\u6807\u7b7e\u53ef\u4ee5\u662f\u4e0d\u540c\u957f\u5ea6\uff0c\u6240\u4ee5\u8fd9\u91ccsegments\u662f\u4e00\u4e2a\u5217\u8868 [gt_num, xy1...(normalized)] segments = [ np . array ( x [ 1 :], dtype = np . float32 ) . reshape ( - 1 , 2 ) for x in lb ] # (cls, xy1...) # \u83b7\u5f97\u8fd9\u5f20\u56fe\u4e2d\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) # segments(\u591a\u8fb9\u5f62) -> bbox(\u6b63\u65b9\u5f62), \u5f97\u5230\u65b0\u6807\u7b7e [gt_num, cls+xywh(normalized)] lb = np . concatenate (( classes . reshape ( - 1 , 1 ), segments2boxes ( segments )), 1 ) # (cls, xywh) lb = np . array ( lb , dtype = np . float32 ) nl = len ( lb ) if nl : # \u5224\u65ad\u6807\u7b7e\u662f\u5426\u6709\u4e94\u5217 assert lb . shape [ 1 ] == 5 , f \"labels require 5 columns, { lb . shape [ 1 ] } columns detected\" # \u5224\u65ad\u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 assert ( lb >= 0 ) . all (), f \"negative label values { lb [ lb < 0 ] } \" # \u5224\u65ad\u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 assert ( lb [:, 1 :] <= 1 ) . all (), f \"non-normalized or out of bounds coordinates { lb [:, 1 :][ lb [:, 1 :] > 1 ] } \" _ , i = np . unique ( lb , axis = 0 , return_index = True ) if len ( i ) < nl : # duplicate row check lb = lb [ i ] # remove duplicates if segments : segments = segments [ i ] msg = f \" { prefix } WARNING: { im_file } : { nl - len ( i ) } duplicate labels removed\" else : ne = 1 # label empty l.shape[0] == 0\u5219\u4e3a\u7a7a\u7684\u6807\u7b7e\uff0cne=1 lb = np . zeros (( 0 , 5 ), dtype = np . float32 ) else : nm = 1 # label missing lb = np . zeros (( 0 , 5 ), dtype = np . float32 ) return im_file , lb , shape , segments , nm , nf , ne , nc , msg except Exception as e : nc = 1 msg = f \" { prefix } WARNING: { im_file } : ignoring corrupt image/label: { e } \" return [ None , None , None , None , nm , nf , ne , nc , msg ] 7. load_image \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u6839\u636e\u56fe\u7247index\uff0c\u4eceself\u6216\u8005\u4ece\u5bf9\u5e94\u56fe\u7247\u8def\u5f84\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247 \u5e76\u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55\u3002 \u4f1a\u88ab\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u548cload_mosaic\u6a21\u5757\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247\uff1a load_image\u51fd\u6570\u4ee3\u7801\uff1a def load_image ( self , i ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u548cload_mosaic\u6a21\u5757\u4e2d \u4eceself\u6216\u8005\u4ece\u5bf9\u5e94\u56fe\u7247\u8def\u5f84\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247 \u5e76\u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55 loads 1 image from dataset, returns img, original hw, resized hw :params self: \u4e00\u822c\u662f\u5bfc\u5165LoadImagesAndLabels\u4e2d\u7684self :param index: \u5f53\u524d\u56fe\u7247\u7684index :return: img: resize\u540e\u7684\u56fe\u7247 (h0, w0): hw_original \u539f\u56fe\u7684hw img.shape[:2]: hw_resized resize\u540e\u7684\u56fe\u7247hw(hw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55) \"\"\" im , f , fn = ( self . ims [ i ], self . im_files [ i ], self . npy_files [ i ], ) if im is None : # not cached in RAM if fn . exists (): # load npy im = np . load ( fn ) else : # read image im = cv2 . imread ( f ) # BGR assert im is not None , f \"Image Not Found { f } \" h0 , w0 = im . shape [: 2 ] # orig hw r = self . img_size / max ( h0 , w0 ) # ratio if r != 1 : # if sizes are not equal # cv2.INTER_AREA: \u57fa\u4e8e\u533a\u57df\u50cf\u7d20\u5173\u7cfb\u7684\u4e00\u79cd\u91cd\u91c7\u6837\u6216\u8005\u63d2\u503c\u65b9\u5f0f.\u8be5\u65b9\u6cd5\u662f\u56fe\u50cf\u62bd\u53d6\u7684\u9996\u9009\u65b9\u6cd5, \u5b83\u53ef\u4ee5\u4ea7\u751f\u66f4\u5c11\u7684\u6ce2\u7eb9 # cv2.INTER_LINEAR: \u53cc\u7ebf\u6027\u63d2\u503c,\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4f7f\u7528\u8be5\u65b9\u5f0f\u8fdb\u884c\u63d2\u503c \u6839\u636eratio\u9009\u62e9\u4e0d\u540c\u7684\u63d2\u503c\u65b9\u5f0f # \u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55 interp = cv2 . INTER_LINEAR if ( self . augment or r > 1 ) else cv2 . INTER_AREA im = cv2 . resize ( im , ( int ( w0 * r ), int ( h0 * r )), interpolation = interp ) return im , ( h0 , w0 ), im . shape [: 2 ] # im, hw_original, hw_resized return self . ims [ i ], self . im_hw0 [ i ], self . im_hw [ i ] # im, hw_original, hw_resized 8. augment_hsv \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u5173\u4e8e\u56fe\u7247\u7684\u8272\u57df\u589e\u5f3a\u6a21\u5757\uff0c\u56fe\u7247\u5e76\u4e0d\u53d1\u751f\u79fb\u52a8\uff0c\u6240\u6709\u4e0d\u9700\u8981\u6539\u53d8label\uff0c\u53ea\u9700\u8981 img \u589e\u5f3a\u5373\u53ef\u3002 augment_hsv\u6a21\u5757\u4ee3\u7801\uff1a def augment_hsv ( img , hgain = 0.5 , sgain = 0.5 , vgain = 0.5 ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 hsv\u8272\u57df\u589e\u5f3a \u5904\u7406\u56fe\u50cfhsv\uff0c\u4e0d\u5bf9label\u8fdb\u884c\u4efb\u4f55\u5904\u7406 :param img: \u5f85\u5904\u7406\u56fe\u7247 BGR [736, 736] :param hgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684h\u901a\u9053 :param sgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684s\u901a\u9053 :param vgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684v\u901a\u9053 :return: \u8fd4\u56dehsv\u589e\u5f3a\u540e\u7684\u56fe\u7247 img \"\"\" if hgain or sgain or vgain : # \u968f\u673a\u53d6-1\u52301\u4e09\u4e2a\u5b9e\u6570\uff0c\u4e58\u4ee5hyp\u4e2d\u7684hsv\u4e09\u901a\u9053\u7684\u7cfb\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684hsv\u901a\u9053 r = np . random . uniform ( - 1 , 1 , 3 ) * [ hgain , sgain , vgain ] + 1 # random gains hue , sat , val = cv2 . split ( cv2 . cvtColor ( img , cv2 . COLOR_BGR2HSV )) # \u56fe\u50cf\u7684\u901a\u9053\u62c6\u5206 h s v dtype = img . dtype # uint8 x = np . arange ( 0 , 256 , dtype = r . dtype ) lut_hue = (( x * r [ 0 ]) % 180 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684h\u901a\u9053 lut_sat = np . clip ( x * r [ 1 ], 0 , 255 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684s\u901a\u9053 lut_val = np . clip ( x * r [ 2 ], 0 , 255 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684v\u901a\u9053 # \u56fe\u50cf\u7684\u901a\u9053\u5408\u5e76 img_hsv=h+s+v \u968f\u673a\u8c03\u6574hsv\u4e4b\u540e\u91cd\u65b0\u7ec4\u5408hsv\u901a\u9053 # cv2.LUT(hue, lut_hue) \u901a\u9053\u8272\u57df\u53d8\u6362 \u8f93\u5165\u53d8\u6362\u524d\u901a\u9053hue \u548c\u53d8\u6362\u540e\u901a\u9053lut_hue img_hsv = cv2 . merge (( cv2 . LUT ( hue , lut_hue ), cv2 . LUT ( sat , lut_sat ), cv2 . LUT ( val , lut_val ))) # no return needed dst:\u8f93\u51fa\u56fe\u50cf cv2 . cvtColor ( img_hsv , cv2 . COLOR_HSV2BGR , dst = img ) # no return needed hsv->bgr \u8fd8\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e2ahsv\u589e\u5f3a\u662f\u968f\u673a\u751f\u6210\u5404\u4e2a\u8272\u57df\u53c2\u6570\u7684\uff0c\u6240\u4ee5\u6bcf\u6b21\u589e\u5f3a\u7684\u6548\u679c\u90fd\u662f\u4e0d\u540c\u7684\uff1a \u8fd9\u4e2a\u51fd\u6570\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u4e2d\uff1a \u53e6\u5916\uff0c\u8fd9\u91cc\u6d89\u53ca\u5230\u7684\u4e09\u4e2a\u53d8\u91cf\u6765\u81eahyp.yaml\u8d85\u53c2\u6587\u4ef6\uff1a 9. load_mosaic\u3001load_mosaic9 \u2003\u8fd9\u4e24\u4e2a\u51fd\u6570\u90fd\u662fmosaic\u6570\u636e\u589e\u5f3a\uff0c\u53ea\u4e0d\u8fc7load_mosaic\u51fd\u6570\u662f\u62fc\u63a5\u56db\u5f20\u56fe\uff0c\u800cload_mosaic9\u51fd\u6570\u662f\u62fc\u63a5\u4e5d\u5f20\u56fe\u3002 \u66f4\u591a\u8bf7\u53c2\u9605 \u300amosaic \u89e3\u8bfb\u300b 9.1 load_mosaic \u2003\u8fd9\u4e2a\u6a21\u5757\u5c31\u662f\u5f88\u6709\u540d\u7684mosaic\u589e\u5f3a\u6a21\u5757\uff0c\u51e0\u4e4e\u8bad\u7ec3\u7684\u65f6\u5019\u90fd\u4f1a\u7528\u5b83\uff0c\u53ef\u4ee5\u663e\u8457\u7684\u63d0\u9ad8\u5c0f\u6837\u672c\u7684mAP\u3002 \u4ee3\u7801\u662f\u6570\u636e\u589e\u5f3a\u91cc\u9762\u6700\u96be\u7684, \u4e5f\u662f\u6700\u6709\u4ef7\u503c\u7684\uff0cmosaic\u662f\u975e\u5e38\u975e\u5e38\u6709\u7528\u7684\u6570\u636e\u589e\u5f3atrick, \u4e00\u5b9a\u8981\u719f\u7ec3\u638c\u63e1\u3002 load_mosaic\u6a21\u5757\u4ee3\u7801\uff1a def load_mosaic ( self , index ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u8fdb\u884cmosaic\u6570\u636e\u589e\u5f3a \u5c06\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d loads images in a 4-mosaic :param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 :return: img4: mosaic\u548c\u968f\u673a\u900f\u89c6\u53d8\u6362\u540e\u7684\u4e00\u5f20\u56fe\u7247 numpy(640, 640, 3) labels4: img4\u5bf9\u5e94\u7684target [M, cls+x1y1x2y2] \"\"\" # labels4: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff084\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegments\u591a\u8fb9\u5f62) # segments4: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff084\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62) labels4 , segments4 = [], [] s = self . img_size # \u4e00\u822c\u7684\u56fe\u7247\u5927\u5c0f # \u968f\u673a\u521d\u59cb\u5316\u62fc\u63a5\u56fe\u50cf\u7684\u4e2d\u5fc3\u70b9\u5750\u6807 [0, s*2]\u4e4b\u95f4\u968f\u673a\u53d62\u4e2a\u6570\u4f5c\u4e3a\u62fc\u63a5\u56fe\u50cf\u7684\u4e2d\u5fc3\u5750\u6807 yc , xc = [ int ( random . uniform ( - x , 2 * s + x )) for x in self . mosaic_border ] # mosaic center x, y # \u4ecedataset\u4e2d\u968f\u673a\u5bfb\u627e\u989d\u5916\u7684\u4e09\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 [14, 26, 2, 16] \u518d\u968f\u673a\u9009\u4e09\u5f20\u56fe\u7247\u7684index indices = [ index ] + random . choices ( self . indices , k = 3 ) # 3 additional image indices # \u904d\u5386\u56db\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 4\u5f20\u4e0d\u540c\u5927\u5c0f\u7684\u56fe\u50cf => 1\u5f20[1472, 1472, 3]\u7684\u56fe\u50cf for i , index in enumerate ( indices ): # load image \u6bcf\u6b21\u62ff\u4e00\u5f20\u56fe\u7247 \u5e76\u5c06\u8fd9\u5f20\u56fe\u7247resize\u5230self.size(h,w) img , _ , ( h , w ) = load_image ( self , index ) # place img in img4 if i == 0 : # top left \u539f\u56fe[375, 500, 3] load_image->[552, 736, 3] hwc # \u521b\u5efa\u9a6c\u8d5b\u514b\u56fe\u50cf [1472, 1472, 3]=[h, w, c] img4 = np . full (( s * 2 , s * 2 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) w=736 h = 552 \u9a6c\u8d5b\u514b\u56fe\u50cf\uff1a(x1a,y1a)\u5de6\u4e0a\u89d2 (x2a,y2a)\u53f3\u4e0b\u89d2 x1a , y1a , x2a , y2a = max ( xc - w , 0 ), max ( yc - h , 0 ), xc , yc # xmin, ymin, xmax, ymax (large image) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e00\u5f20\u56fe\u50cf\u7684\u53f3\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) \u56fe\u50cf\uff1a(x1b,y1b)\u5de6\u4e0a\u89d2 (x2b,y2b)\u53f3\u4e0b\u89d2 x1b , y1b , x2b , y2b = w - ( x2a - x1a ), h - ( y2a - y1a ), w , h # xmin, ymin, xmax, ymax (small image) elif i == 1 : # top right # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = xc , max ( yc - h , 0 ), min ( xc + w , s * 2 ), yc # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e8c\u5f20\u56fe\u50cf\u7684\u5de6\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = 0 , h - ( y2a - y1a ), min ( w , x2a - x1a ), h elif i == 2 : # bottom left # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = max ( xc - w , 0 ), yc , xc , min ( s * 2 , yc + h ) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e09\u5f20\u56fe\u50cf\u7684\u53f3\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = w - ( x2a - x1a ), 0 , w , min ( y2a - y1a , h ) elif i == 3 : # bottom right # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = xc , yc , min ( xc + w , s * 2 ), min ( s * 2 , yc + h ) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u56db\u5f20\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = 0 , 0 , min ( w , x2a - x1a ), min ( y2a - y1a , h ) # \u5c06\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u7684\u76f8\u5e94\u4f4d\u7f6e img4[h, w, c] # \u5c06\u56fe\u50cfimg\u7684\u3010(x1b,y1b)\u5de6\u4e0a\u89d2 (x2b,y2b)\u53f3\u4e0b\u89d2\u3011\u533a\u57df\u622a\u53d6\u51fa\u6765\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u7684\u3010(x1a,y1a)\u5de6\u4e0a\u89d2 (x2a,y2a)\u53f3\u4e0b\u89d2\u3011\u533a\u57df img4 [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] # \u8ba1\u7b97pad(\u5f53\u524d\u56fe\u50cf\u8fb9\u754c\u4e0e\u9a6c\u8d5b\u514b\u8fb9\u754c\u7684\u8ddd\u79bb\uff0c\u8d8a\u754c\u7684\u60c5\u51b5padw/padh\u4e3a\u8d1f\u503c) \u7528\u4e8e\u540e\u9762\u7684label\u6620\u5c04 padw = x1a - x1b # \u5f53\u524d\u56fe\u50cf\u4e0e\u9a6c\u8d5b\u514b\u56fe\u50cf\u5728w\u7ef4\u5ea6\u4e0a\u76f8\u5dee\u591a\u5c11 padh = y1a - y1b # \u5f53\u524d\u56fe\u50cf\u4e0e\u9a6c\u8d5b\u514b\u56fe\u50cf\u5728h\u7ef4\u5ea6\u4e0a\u76f8\u5dee\u591a\u5c11 # labels: \u83b7\u53d6\u5bf9\u5e94\u62fc\u63a5\u56fe\u50cf\u7684\u6240\u6709\u6b63\u5e38label\u4fe1\u606f(\u5982\u679c\u6709segments\u591a\u8fb9\u5f62\u4f1a\u88ab\u8f6c\u5316\u4e3a\u77e9\u5f62label) # segments: \u83b7\u53d6\u5bf9\u5e94\u62fc\u63a5\u56fe\u50cf\u7684\u6240\u6709\u4e0d\u6b63\u5e38label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62\u4e5f\u5305\u542b\u6b63\u5e38gt) labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : # normalized xywh normalized to pixel xyxy format labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padw , padh ) segments = [ xyn2xy ( x , w , h , padw , padh ) for x in segments ] labels4 . append ( labels ) # \u66f4\u65b0labels4 segments4 . extend ( segments ) # \u66f4\u65b0segments4 # Concat/clip labels4 \u628alabels4\uff08[(2, 5), (1, 5), (3, 5), (1, 5)] => (7, 5)\uff09\u538b\u7f29\u5230\u4e00\u8d77 labels4 = np . concatenate ( labels4 , 0 ) # \u9632\u6b62\u8d8a\u754c label[:, 1:]\u4e2d\u7684\u6240\u6709\u5143\u7d20\u7684\u503c\uff08\u4f4d\u7f6e\u4fe1\u606f\uff09\u5fc5\u987b\u5728[0, 2*s]\u4e4b\u95f4,\u5c0f\u4e8e0\u5c31\u4ee4\u5176\u7b49\u4e8e0,\u5927\u4e8e2*s\u5c31\u7b49\u4e8e2*s out: \u8fd4\u56de for x in ( labels4 [:, 1 :], * segments4 ): np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5\u524d\u9762\u7684mosaic\u6548\u679c # cv2.imshow(\"mosaic\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (1280, 1280, 3) # \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408 replicate # img4, labels4 = replicate(img4, labels4) # # # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5replicate\u6548\u679c # cv2.imshow(\"replicate\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (1280, 1280, 3) # Augment # random_perspective Augment \u968f\u673a\u900f\u89c6\u53d8\u6362 [1280, 1280, 3] => [640, 640, 3] # \u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5mosaic + random_perspective\u968f\u673a\u4eff\u5c04\u53d8\u6362\u6548\u679c # cv2.imshow(\"random_perspective\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (640, 640, 3) return img4 , labels4 9.2 load_mosaic9 \u2003\u8fd9\u4e2a\u6a21\u5757\u662f\u4f5c\u8005\u7684\u5b9e\u9a8c\u6a21\u5757\uff0c\u5c06\u4e5d\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u3002\u603b\u4f53\u4ee3\u7801\u6d41\u7a0b\u548cload_mosaic4\u51e0\u4e4e\u4e00\u6837\uff0c\u770b\u61c2\u4e86load_mosaic4\u518d\u770b\u8fd9\u4e2a\u5c31\u5f88\u7b80\u5355\u4e86\u3001 load_mosaic9\u6a21\u5757\u4ee3\u7801\uff1a def load_mosaic9 ( self , index ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u66ff\u6362mosaic\u6570\u636e\u589e\u5f3a \u5c06\u4e5d\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d loads images in a 9-mosaic :param self: :param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 :return: img9: mosaic\u548c\u4eff\u5c04\u589e\u5f3a\u540e\u7684\u4e00\u5f20\u56fe\u7247 labels9: img9\u5bf9\u5e94\u7684target \"\"\" # labels9: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff089\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegments\u591a\u8fb9\u5f62) # segments9: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff089\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62) labels9 , segments9 = [], [] s = self . img_size # \u4e00\u822c\u7684\u56fe\u7247\u5927\u5c0f(\u4e5f\u662f\u6700\u7ec8\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f) # \u4ecedataset\u4e2d\u968f\u673a\u5bfb\u627e\u989d\u5916\u7684\u4e09\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 [14, 26, 2, 16] \u518d\u968f\u673a\u9009\u4e09\u5f20\u56fe\u7247\u7684index indices = [ index ] + random . choices ( self . indices , k = 8 ) # 8 additional image indices for i , index in enumerate ( indices ): # Load image \u6bcf\u6b21\u62ff\u4e00\u5f20\u56fe\u7247 \u5e76\u5c06\u8fd9\u5f20\u56fe\u7247resize\u5230self.size(h,w) img , _ , ( h , w ) = load_image ( self , index ) # \u8fd9\u91cc\u548c\u4e0a\u9762load_mosaic\u51fd\u6570\u7684\u64cd\u4f5c\u7c7b\u4f3c \u5c31\u662f\u5c06\u53d6\u51fa\u7684img\u56fe\u7247\u5d4c\u5230img9\u4e2d(\u4e0d\u662f\u771f\u7684\u5d4c\u5165 \u800c\u662f\u627e\u5230\u5bf9\u5e94\u7684\u4f4d\u7f6e) # place img in img9 if i == 0 : # center img9 = np . full (( s * 3 , s * 3 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles h0 , w0 = h , w c = s , s , s + w , s + h # xmin, ymin, xmax, ymax (base) coordinates elif i == 1 : # top c = s , s - h , s + w , s elif i == 2 : # top right c = s + wp , s - h , s + wp + w , s elif i == 3 : # right c = s + w0 , s , s + w0 + w , s + h elif i == 4 : # bottom right c = s + w0 , s + hp , s + w0 + w , s + hp + h elif i == 5 : # bottom c = s + w0 - w , s + h0 , s + w0 , s + h0 + h elif i == 6 : # bottom left c = s + w0 - wp - w , s + h0 , s + w0 - wp , s + h0 + h elif i == 7 : # left c = s - w , s + h0 - h , s , s + h0 elif i == 8 : # top left c = s - w , s + h0 - hp - h , s , s + h0 - hp padx , pady = c [: 2 ] x1 , y1 , x2 , y2 = [ max ( x , 0 ) for x in c ] # allocate coords # \u548c\u4e0a\u9762load_mosaic\u51fd\u6570\u7684\u64cd\u4f5c\u7c7b\u4f3c \u627e\u5230mosaic9\u589e\u5f3a\u540e\u7684labels9\u548csegments9 labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padx , pady ) # normalized xywh to pixel xyxy format segments = [ xyn2xy ( x , w , h , padx , pady ) for x in segments ] labels9 . append ( labels ) segments9 . extend ( segments ) # \u751f\u6210\u5bf9\u5e94\u7684img9\u56fe\u7247(\u5c06\u5bf9\u5e94\u4f4d\u7f6e\u7684\u56fe\u7247\u5d4c\u5165img9\u4e2d) img9 [ y1 : y2 , x1 : x2 ] = img [ y1 - pady :, x1 - padx :] # img9[ymin:ymax, xmin:xmax] hp , wp = h , w # height, width previous # Offset yc , xc = [ int ( random . uniform ( 0 , s )) for _ in self . mosaic_border ] # mosaic center x, y img9 = img9 [ yc : yc + 2 * s , xc : xc + 2 * s ] # Concat/clip labels labels9 = np . concatenate ( labels9 , 0 ) labels9 [:, [ 1 , 3 ]] -= xc labels9 [:, [ 2 , 4 ]] -= yc c = np . array ([ xc , yc ]) # centers segments9 = [ x - c for x in segments9 ] for x in ( labels9 [:, 1 :], * segments9 ): np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img9, labels9 = replicate(img9, labels9) # replicate # Augment \u540c\u6837\u8fdb\u884c \u968f\u673a\u900f\u89c6\u53d8\u6362 img9 , labels9 = random_perspective ( img9 , labels9 , segments9 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove return img9 , labels9 \u7528\u6cd5\u548cmosaic\u4e00\u6837\uff0c\u4f7f\u7528\u76f4\u63a5\u5c06class LoadImagesAndLabels(Dataset): \u4e2d getitem \u7684load_mosaic\u76f4\u63a5 \u76f4\u63a5\u66ff\u6362\u6210load_mosaic9\u5373\u53ef\uff1a 10. LoadImages & LoadStreams & LoadWebcam load \u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247/\u89c6\u9891 + \u7528\u5230\u5f88\u5c11 load web\u7f51\u9875\u4e2d\u7684\u6570\u636e\u3002 \u5168\u90e8\u4ee3\u7801\uff1a class LoadImages : # for inference \"\"\"\u5728detect.py\u4e2d\u4f7f\u7528 load \u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247/\u89c6\u9891 \u5b9a\u4e49\u8fed\u4ee3\u5668 \u7528\u4e8edetect.py \"\"\" def __init__ ( self , path , img_size = 640 , stride = 32 ): p = str ( Path ( path ) . absolute ()) # os-agnostic absolute path # glob.glab: \u8fd4\u56de\u6240\u6709\u5339\u914d\u7684\u6587\u4ef6\u8def\u5f84\u5217\u8868 files: \u63d0\u53d6\u56fe\u7247\u6240\u6709\u8def\u5f84 if \"*\" in p : # \u5982\u679cp\u662f\u91c7\u6837\u6b63\u5219\u5316\u8868\u8fbe\u5f0f\u63d0\u53d6\u56fe\u7247/\u89c6\u9891, \u53ef\u4ee5\u4f7f\u7528glob\u83b7\u53d6\u6587\u4ef6\u8def\u5f84 files = sorted ( glob . glob ( p , recursive = True )) # glob elif os . path . isdir ( p ): # \u5982\u679cp\u662f\u4e00\u4e2a\u6587\u4ef6\u5939\uff0c\u4f7f\u7528glob\u83b7\u53d6\u5168\u90e8\u6587\u4ef6\u8def\u5f84 files = sorted ( glob . glob ( os . path . join ( p , \"*.*\" ))) # dir elif os . path . isfile ( p ): # \u5982\u679cp\u662f\u6587\u4ef6\u5219\u76f4\u63a5\u83b7\u53d6 files = [ p ] # files else : raise Exception ( f \"ERROR: { p } does not exist\" ) # images: \u76ee\u5f55\u4e0b\u6240\u6709\u56fe\u7247\u7684\u56fe\u7247\u540d videos: \u76ee\u5f55\u4e0b\u6240\u6709\u89c6\u9891\u7684\u89c6\u9891\u540d images = [ x for x in files if x . split ( \".\" )[ - 1 ] . lower () in img_formats ] videos = [ x for x in files if x . split ( \".\" )[ - 1 ] . lower () in vid_formats ] # \u56fe\u7247\u4e0e\u89c6\u9891\u6570\u91cf ni , nv = len ( images ), len ( videos ) self . img_size = img_size self . stride = stride # \u6700\u5927\u7684\u4e0b\u91c7\u6837\u7387 self . files = images + videos # \u6574\u5408\u56fe\u7247\u548c\u89c6\u9891\u8def\u5f84\u5230\u4e00\u4e2a\u5217\u8868 self . nf = ni + nv # number of files self . video_flag = [ False ] * ni + [ True ] * nv # \u662f\u4e0d\u662fvideo self . mode = \"image\" # \u9ed8\u8ba4\u662f\u8bfbimage\u6a21\u5f0f if any ( videos ): # \u5224\u65ad\u6709\u6ca1\u6709video\u6587\u4ef6 \u5982\u679c\u5305\u542bvideo\u6587\u4ef6\uff0c\u5219\u521d\u59cb\u5316opencv\u4e2d\u7684\u89c6\u9891\u6a21\u5757\uff0ccap=cv2.VideoCapture\u7b49 self . new_video ( videos [ 0 ]) # new video else : self . cap = None assert self . nf > 0 , ( f \"No images or videos found in { p } . \" f \"Supported formats are: \\n images: { img_formats } \\n videos: { vid_formats } \" ) def __iter__ ( self ): \"\"\"\u8fed\u4ee3\u5668\"\"\" self . count = 0 return self def __next__ ( self ): \"\"\"\u4e0eiter\u4e00\u8d77\u7528\uff1f\"\"\" if self . count == self . nf : # \u6570\u636e\u8bfb\u5b8c\u4e86 raise StopIteration path = self . files [ self . count ] # \u8bfb\u53d6\u5f53\u524d\u6587\u4ef6\u8def\u5f84 if self . video_flag [ self . count ]: # \u5224\u65ad\u5f53\u524d\u6587\u4ef6\u662f\u5426\u662f\u89c6\u9891 # Read video self . mode = \"video\" # \u83b7\u53d6\u5f53\u524d\u5e27\u753b\u9762\uff0cret_val\u4e3a\u4e00\u4e2abool\u53d8\u91cf\uff0c\u76f4\u5230\u89c6\u9891\u8bfb\u53d6\u5b8c\u6bd5\u4e4b\u524d\u90fd\u4e3aTrue ret_val , img0 = self . cap . read () # \u5982\u679c\u5f53\u524d\u89c6\u9891\u8bfb\u53d6\u7ed3\u675f\uff0c\u5219\u8bfb\u53d6\u4e0b\u4e00\u4e2a\u89c6\u9891 if not ret_val : self . count += 1 self . cap . release () # self.count == self.nf\u8868\u793a\u89c6\u9891\u5df2\u7ecf\u8bfb\u53d6\u5b8c\u4e86 if self . count == self . nf : # last video raise StopIteration else : path = self . files [ self . count ] self . new_video ( path ) ret_val , img0 = self . cap . read () self . frame += 1 # \u5f53\u524d\u8bfb\u53d6\u89c6\u9891\u7684\u5e27\u6570 print ( f \"video { self . count + 1 } / { self . nf } ( { self . frame } / { self . frames } ) { path } : \" , end = \"\" , ) else : # Read image self . count += 1 img0 = cv2 . imread ( path ) # BGR assert img0 is not None , \"Image Not Found \" + path print ( f \"image { self . count } / { self . nf } { path } : \" , end = \"\" ) # Padded resize img = letterbox ( img0 , self . img_size , stride = self . stride )[ 0 ] # Convert img = img [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB and HWC to CHW img = np . ascontiguousarray ( img ) # \u8fd4\u56de\u8def\u5f84, resize+pad\u7684\u56fe\u7247, \u539f\u59cb\u56fe\u7247, \u89c6\u9891\u5bf9\u8c61 return path , img , img0 , self . cap def new_video ( self , path ): # \u8bb0\u5f55\u5e27\u6570 self . frame = 0 # \u521d\u59cb\u5316\u89c6\u9891\u5bf9\u8c61 self . cap = cv2 . VideoCapture ( path ) # \u5f97\u5230\u89c6\u9891\u6587\u4ef6\u4e2d\u7684\u603b\u5e27\u6570 self . frames = int ( self . cap . get ( cv2 . CAP_PROP_FRAME_COUNT )) def __len__ ( self ): return self . nf # number of files class LoadStreams : \"\"\" load \u6587\u4ef6\u5939\u4e2d\u89c6\u9891\u6d41 multiple IP or RTSP cameras \u5b9a\u4e49\u8fed\u4ee3\u5668 \u7528\u4e8edetect.py \"\"\" def __init__ ( self , sources = \"streams.txt\" , img_size = 640 , stride = 32 ): self . mode = \"stream\" # \u521d\u59cb\u5316mode\u4e3aimages self . img_size = img_size self . stride = stride # \u6700\u5927\u4e0b\u91c7\u6837\u6b65\u957f # \u5982\u679csources\u4e3a\u4e00\u4e2a\u4fdd\u5b58\u4e86\u591a\u4e2a\u89c6\u9891\u6d41\u7684\u6587\u4ef6 \u83b7\u53d6\u6bcf\u4e00\u4e2a\u89c6\u9891\u6d41\uff0c\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u5217\u8868 if os . path . isfile ( sources ): with open ( sources , \"r\" ) as f : sources = [ x . strip () for x in f . read () . strip () . splitlines () if len ( x . strip ()) ] else : # \u53cd\u4e4b\uff0c\u53ea\u6709\u4e00\u4e2a\u89c6\u9891\u6d41\u6587\u4ef6\u5c31\u76f4\u63a5\u4fdd\u5b58 sources = [ sources ] n = len ( sources ) # \u89c6\u9891\u6d41\u4e2a\u6570 # \u521d\u59cb\u5316\u56fe\u7247 fps \u603b\u5e27\u6570 \u7ebf\u7a0b\u6570 self . imgs , self . fps , self . frames , self . threads = ( [ None ] * n , [ 0 ] * n , [ 0 ] * n , [ None ] * n , ) self . sources = [ clean_str ( x ) for x in sources ] # clean source names for later # \u904d\u5386\u6bcf\u4e00\u4e2a\u89c6\u9891\u6d41 for i , s in enumerate ( sources ): # index, source # Start thread to read frames from video stream # \u6253\u5370\u5f53\u524d\u89c6\u9891index/\u603b\u89c6\u9891\u6570/\u89c6\u9891\u6d41\u5730\u5740 print ( f \" { i + 1 } / { n } : { s } ... \" , end = \"\" ) if \"youtube.com/\" in s or \"youtu.be/\" in s : # if source is YouTube video check_requirements (( \"pafy\" , \"youtube_dl\" )) import pafy s = pafy . new ( s ) . getbest ( preftype = \"mp4\" ) . url # YouTube URL s = eval ( s ) if s . isnumeric () else s # i.e. s = '0' local webcam \u672c\u5730\u6444\u50cf\u5934 # s='0'\u6253\u5f00\u672c\u5730\u6444\u50cf\u5934\uff0c\u5426\u5219\u6253\u5f00\u89c6\u9891\u6d41\u5730\u5740 cap = cv2 . VideoCapture ( s ) assert cap . isOpened (), f \"Failed to open { s } \" # \u83b7\u53d6\u89c6\u9891\u7684\u5bbd\u548c\u957f w = int ( cap . get ( cv2 . CAP_PROP_FRAME_WIDTH )) h = int ( cap . get ( cv2 . CAP_PROP_FRAME_HEIGHT )) # \u83b7\u53d6\u89c6\u9891\u7684\u5e27\u7387 self . fps [ i ] = ( max ( cap . get ( cv2 . CAP_PROP_FPS ) % 100 , 0 ) or 30.0 ) # 30 FPS fallback # \u5e27\u6570 self . frames [ i ] = max ( int ( cap . get ( cv2 . CAP_PROP_FRAME_COUNT )), 0 ) or float ( \"inf\" ) # infinite stream fallback # \u8bfb\u53d6\u5f53\u524d\u753b\u9762 _ , self . imgs [ i ] = cap . read () # guarantee first frame # \u521b\u5efa\u591a\u7ebf\u7a0b\u8bfb\u53d6\u89c6\u9891\u6d41\uff0cdaemon\u8868\u793a\u4e3b\u7ebf\u7a0b\u7ed3\u675f\u65f6\u5b50\u7ebf\u7a0b\u4e5f\u7ed3\u675f self . threads [ i ] = Thread ( target = self . update , args = ([ i , cap ]), daemon = True ) print ( f \" success ( { self . frames [ i ] } frames { w } x { h } at { self . fps [ i ] : .2f } FPS)\" ) self . threads [ i ] . start () print ( \"\" ) # newline # check for common shapes # \u83b7\u53d6\u8fdb\u884cresize+pad\u4e4b\u540e\u7684shape\uff0cletterbox\u51fd\u6570\u9ed8\u8ba4(\u53c2\u6570auto=True)\u662f\u6309\u7167\u77e9\u5f62\u63a8\u7406\u8fdb\u884c\u586b\u5145 s = np . stack ( [ letterbox ( x , self . img_size , stride = self . stride )[ 0 ] . shape for x in self . imgs ], 0 , ) # shapes self . rect = ( np . unique ( s , axis = 0 ) . shape [ 0 ] == 1 ) # rect inference if all shapes equal if not self . rect : print ( \"WARNING: Different stream shapes detected. For optimal performance supply similarly-shaped streams.\" ) def update ( self , i , cap ): # Read stream `i` frames in daemon thread n , f = 0 , self . frames [ i ] while cap . isOpened () and n < f : n += 1 # _, self.imgs[index] = cap.read() cap . grab () # \u6bcf4\u5e27\u8bfb\u53d6\u4e00\u6b21 if n % 4 : # read every 4th frame success , im = cap . retrieve () self . imgs [ i ] = im if success else self . imgs [ i ] * 0 time . sleep ( 1 / self . fps [ i ]) # wait time def __iter__ ( self ): self . count = - 1 return self def __next__ ( self ): self . count += 1 if not all ( x . is_alive () for x in self . threads ) or cv2 . waitKey ( 1 ) == ord ( \"q\" ): # q to quit cv2 . destroyAllWindows () raise StopIteration # Letterbox img0 = self . imgs . copy () img = [ letterbox ( x , self . img_size , auto = self . rect , stride = self . stride )[ 0 ] for x in img0 ] # Stack \u5c06\u8bfb\u53d6\u7684\u56fe\u7247\u62fc\u63a5\u5230\u4e00\u8d77 img = np . stack ( img , 0 ) # Convert img = img [:, :, :, :: - 1 ] . transpose ( 0 , 3 , 1 , 2 ) # BGR to RGB and BHWC to BCHW img = np . ascontiguousarray ( img ) return self . sources , img , img0 , None def __len__ ( self ): return 0 # 1E12 frames = 32 streams at 30 FPS for 30 years class LoadWebcam : # for inference \"\"\"\u7528\u5230\u5f88\u5c11 load web\u7f51\u9875\u4e2d\u7684\u6570\u636e\"\"\" def __init__ ( self , pipe = \"0\" , img_size = 640 , stride = 32 ): self . img_size = img_size self . stride = stride if pipe . isnumeric (): pipe = eval ( pipe ) # local camera # pipe = 'rtsp://192.168.1.64/1' # IP camera # pipe = 'rtsp://username:password@192.168.1.64/1' # IP camera with login # pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg' # IP golf camera self . pipe = pipe self . cap = cv2 . VideoCapture ( pipe ) # video capture object self . cap . set ( cv2 . CAP_PROP_BUFFERSIZE , 3 ) # set buffer size def __iter__ ( self ): self . count = - 1 return self def __next__ ( self ): self . count += 1 if cv2 . waitKey ( 1 ) == ord ( \"q\" ): # q to quit self . cap . release () cv2 . destroyAllWindows () raise StopIteration # Read frame if self . pipe == 0 : # local camera ret_val , img0 = self . cap . read () img0 = cv2 . flip ( img0 , 1 ) # flip left-right else : # IP camera n = 0 while True : n += 1 self . cap . grab () if n % 30 == 0 : # skip frames ret_val , img0 = self . cap . retrieve () if ret_val : break # Print assert ret_val , f \"Camera Error { self . pipe } \" img_path = \"webcam.jpg\" print ( f \"webcam { self . count } : \" , end = \"\" ) # Padded resize img = letterbox ( img0 , self . img_size , stride = self . stride )[ 0 ] # Convert img = img [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB and HWC to CHW img = np . ascontiguousarray ( img ) return img_path , img , img0 , None def __len__ ( self ): return 0 11. flatten_recursive \u8fd9\u4e2a\u6a21\u5757\u662f\u5c06\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u590d\u5236\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d \u5373\u5c06image\u6587\u4ef6\u548clabel\u6587\u4ef6\u653e\u5230\u4e00\u4e2a\u65b0\u6587\u4ef6\u5939\u4e2d\u3002 flatten_recursive\u6a21\u5757\u4ee3\u7801\uff1a def flatten_recursive ( path = DATASETS_DIR / \"coco128\" ): # \u5c06\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u590d\u5236\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d \u5373\u5c06image\u6587\u4ef6\u548clabel\u6587\u4ef6\u653e\u5230\u4e00\u4e2a\u65b0\u6587\u4ef6\u5939\u4e2d # Flatten a recursive directory by bringing all files to top level new_path = Path ( f \" { str ( path ) } _flat\" ) if os . path . exists ( new_path ): shutil . rmtree ( new_path ) # delete output folder os . makedirs ( new_path ) # make new output folder for file in tqdm ( glob . glob ( f \" { str ( Path ( path )) } /**/*.*\" , recursive = True )): # shutil.copyfile: \u590d\u5236\u6587\u4ef6\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d shutil . copyfile ( file , new_path / Path ( file ) . name ) 12.extract_boxes \u2003\u8fd9\u4e2a\u6a21\u5757\u662f\u5c06\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u5206\u7c7b\u6570\u636e\u96c6 \uff0c\u96c6\u4f53\u505a\u6cd5: \u628a\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2agt\u62c6\u89e3\u5f00 \u5206\u7c7b\u522b\u5b58\u50a8\u5230\u5bf9\u5e94\u7684\u6587\u4ef6\u5f53\u4e2d\u3002 def extract_boxes ( path = DATASETS_DIR / \"coco128\" , ): # from utils.dataloaders import *; extract_boxes() # Convert detection dataset into classification dataset, with one directory per class \"\"\"\u81ea\u884c\u4f7f\u7528 \u751f\u6210\u5206\u7c7b\u6570\u636e\u96c6 \u5c06\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u5206\u7c7b\u6570\u636e\u96c6 \u96c6\u4f53\u505a\u6cd5: \u628a\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2agt\u62c6\u89e3\u5f00 \u5206\u7c7b\u522b\u5b58\u50a8\u5230\u5bf9\u5e94\u7684\u6587\u4ef6\u5f53\u4e2d Convert detection dataset into classification dataset, with one directory per class \u4f7f\u7528: from utils.datasets import *; extract_boxes() :params path: \u6570\u636e\u96c6\u5730\u5740 \"\"\" path = Path ( path ) # images dir \u6570\u636e\u96c6\u6587\u4ef6\u76ee\u5f55 \u9ed8\u8ba4'..\\datasets\\coco128' shutil . rmtree ( path / \"classifier\" ) if ( path / \"classifier\" ) . is_dir () else None # remove existing files = list ( path . rglob ( \"*.*\" )) n = len ( files ) # number of files for im_file in tqdm ( files , total = n ): if im_file . suffix [ 1 :] in IMG_FORMATS : # \u5fc5\u987b\u5f97\u662f\u56fe\u7247\u6587\u4ef6 # image im = cv2 . imread ( str ( im_file ))[ ... , :: - 1 ] # BGR to RGB h , w = im . shape [: 2 ] # \u5f97\u5230\u8fd9\u5f20\u56fe\u7247h w # labels \u6839\u636e\u8fd9\u5f20\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u8fd9\u5f20\u56fe\u7247\u7684label\u8def\u5f84 lb_file = Path ( img2label_paths ([ str ( im_file )])[ 0 ]) if Path ( lb_file ) . exists (): with open ( lb_file ) as f : lb = np . array ([ x . split () for x in f . read () . strip () . splitlines ()], dtype = np . float32 ) # labels \u8bfb\u53d6label\u7684\u5404\u884c: \u5bf9\u5e94\u5404\u4e2agt\u5750\u6807 for j , x in enumerate ( lb ): # \u904d\u5386\u6bcf\u4e00\u4e2agt c = int ( x [ 0 ]) # class # \u751f\u6210\u65b0'file_name path\\classifier\\class_index\\image_name' # \u5982: 'F:\\yolo_v5\\datasets\\coco128\\images\\train2017\\classifier\\45\\train2017_000000000009_0.jpg' f = ( path / \"classifier\" ) / f \" { c } \" / f \" { path . stem } _ { im_file . stem } _ { j } .jpg\" # new filename if not f . parent . is_dir (): # \u6bcf\u4e00\u4e2a\u7c7b\u522b\u7684\u7b2c\u4e00\u5f20\u7167\u7247\u5b58\u8fdb\u53bb\u4e4b\u524d \u5148\u521b\u5efa\u5bf9\u5e94\u7c7b\u7684\u6587\u4ef6\u5939 f . parent . mkdir ( parents = True ) b = x [ 1 :] * [ w , h , w , h ] # box normalized to \u6b63\u5e38\u5927\u5c0f # b[2:] = b[2:].max() # rectangle to square b [ 2 :] = b [ 2 :] * 1.2 + 3 # pad b = xywh2xyxy ( b . reshape ( - 1 , 4 )) . ravel () . astype ( np . int ) b [[ 0 , 2 ]] = np . clip ( b [[ 0 , 2 ]], 0 , w ) # clip boxes outside of image \u9632\u6b62\u51fa\u754c b [[ 1 , 3 ]] = np . clip ( b [[ 1 , 3 ]], 0 , h ) assert cv2 . imwrite ( str ( f ), im [ b [ 1 ] : b [ 3 ], b [ 0 ] : b [ 2 ]]), f \"box failure in { f } \" 13. autosplit \u2003\u8fd9\u4e2a\u6a21\u5757\u662f\u8fdb\u884c\u81ea\u52a8\u5212\u5206\u6570\u636e\u96c6\u3002\u5f53\u4f7f\u7528\u81ea\u5df1\u6570\u636e\u96c6\u65f6\uff0c\u53ef\u4ee5\u7528\u8fd9\u4e2a\u6a21\u5757\u8fdb\u884c\u81ea\u884c\u5212\u5206\u6570\u636e\u96c6\u3002 autosplit\u6a21\u5757\u4ee3\u7801\uff1a def autosplit ( path = DATASETS_DIR / \"coco128/images\" , weights = ( 0.9 , 0.1 , 0.0 ), annotated_only = False ): \"\"\"Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files Usage: from utils.dataloaders import *; autosplit() Arguments path: Path to images directory weights: Train, val, test weights (list, tuple) annotated_only: Only use images with an annotated txt file \"\"\" path = Path ( path ) # images dir # \u83b7\u53d6images\u4e2d\u6240\u6709\u7684\u56fe\u7247 image files only files = sorted ( x for x in path . rglob ( \"*.*\" ) if x . suffix [ 1 :] . lower () in IMG_FORMATS ) # image files only n = len ( files ) # number of files # \u968f\u673a\u6570\u79cd\u5b50 random . seed ( 0 ) # for reproducibility # assign each image to a split \u6839\u636e(train, val, test)\u6743\u91cd\u5212\u5206\u539f\u59cb\u56fe\u7247\u6570\u636e\u96c6 # indices: [n] 0, 1, 2 \u5206\u522b\u8868\u793a\u6570\u636e\u96c6\u4e2d\u6bcf\u4e00\u5f20\u56fe\u7247\u5c5e\u4e8e\u54ea\u4e2a\u6570\u636e\u96c6 \u5206\u522b\u5bf9\u5e94\u7740(train, val, test) indices = random . choices ([ 0 , 1 , 2 ], weights = weights , k = n ) # assign each image to a split txt = [ \"autosplit_train.txt\" , \"autosplit_val.txt\" , \"autosplit_test.txt\" ] # 3 txt files [( path . parent / x ) . unlink ( missing_ok = True ) for x in txt ] # remove existing print ( f \"Autosplitting images from { path } \" + \", using *.txt labeled images only\" * annotated_only ) for i , img in tqdm ( zip ( indices , files ), total = n ): if not annotated_only or Path ( img2label_paths ([ str ( img )])[ 0 ]) . exists (): # check label with open ( path . parent / txt [ i ], \"a\" ) as f : f . write ( f \"./ { img . relative_to ( path . parent ) . as_posix () } \" + \" \\n \" ) # add image to txt file Reference \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011 atasets.py","title":"dataladers_py"},{"location":"source_code_interpretation/utils/dataladers_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/dataloaders.py","title":"\u524d\u8a00"},{"location":"source_code_interpretation/utils/dataladers_py.html#1","text":"# YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license \"\"\" Dataloaders and dataset utils \"\"\" import contextlib import glob # python\u81ea\u5df1\u5e26\u7684\u4e00\u4e2a\u6587\u4ef6\u64cd\u4f5c\u76f8\u5173\u6a21\u5757 \u67e5\u627e\u7b26\u5408\u81ea\u5df1\u76ee\u7684\u7684\u6587\u4ef6(\u5982\u6a21\u7cca\u5339\u914d) import hashlib # \u54c8\u5e0c\u6a21\u5757 \u63d0\u4f9b\u4e86\u591a\u79cd\u5b89\u5168\u65b9\u4fbf\u7684hash\u65b9\u6cd5 import json # json\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 import math # \u6570\u5b66\u516c\u5f0f\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 \u5305\u542b\u6587\u4ef6\u8def\u5f84\u64cd\u4f5c\u548c\u89e3\u6790 import random # \u751f\u6210\u968f\u673a\u6570\u6a21\u5757 import shutil # \u6587\u4ef6\u5939\u3001\u538b\u7f29\u5305\u5904\u7406\u6a21\u5757 import time # \u65f6\u95f4\u6a21\u5757 \u66f4\u5e95\u5c42 from itertools import repeat # \u590d\u5236\u6a21\u5757 from multiprocessing.pool import Pool , ThreadPool # \u591a\u7ebf\u7a0b\u6a21\u5757 \u7ebf\u7a0b\u6c60 from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 from threading import Thread # \u591a\u7ebf\u7a0b\u64cd\u4f5c\u6a21\u5757 from urllib.parse import urlparse from zipfile import ZipFile import numpy as np # numpy\u77e9\u9635\u64cd\u4f5c\u6a21\u5757 import oneflow as flow # OneFlow\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757 import oneflow.nn.functional as F # OneFlow\u51fd\u6570\u63a5\u53e3 \u5c01\u88c5\u4e86\u5f88\u591a\u5377\u79ef\u3001\u6c60\u5316\u7b49\u51fd\u6570 import yaml # yaml\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 from oneflow.utils.data import DataLoader , Dataset , dataloader , distributed from PIL import ExifTags , Image , ImageOps # \u56fe\u7247\u3001\u76f8\u673a\u64cd\u4f5c\u6a21\u5757 from tqdm import tqdm # \u8fdb\u5ea6\u6761\u6a21\u5757 # augmentations.py\u6e90\u7801\u89e3\u8bfb: https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/utils/augmentations_py.html from utils.augmentations import Albumentations , augment_hsv , copy_paste , letterbox , mixup , random_perspective from utils.general import ( DATASETS_DIR , LOGGER , NUM_THREADS , check_dataset , check_requirements , check_yaml , clean_str , cv2 , is_colab , is_kaggle , segments2boxes , xyn2xy , xywh2xyxy , xywhn2xyxy , xyxy2xywhn , ) # Parameters HELP_URL = \"https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\" IMG_FORMATS = ( \"bmp\" , \"dng\" , \"jpeg\" , \"jpg\" , \"mpo\" , \"png\" , \"tif\" , \"tiff\" , \"webp\" , ) # include image suffixes VID_FORMATS = ( \"asf\" , \"avi\" , \"gif\" , \"m4v\" , \"mkv\" , \"mov\" , \"mp4\" , \"mpeg\" , \"mpg\" , \"ts\" , \"wmv\" , ) # include video suffixes BAR_FORMAT = \" {l_bar}{bar:10}{r_bar}{bar:-10b} \" # tqdm bar format LOCAL_RANK = int ( os . getenv ( \"LOCAL_RANK\" , - 1 )) # https://oneflow.readthedocs.io/en/master/distributed.html?highlight=launch#launching-distributed-training RANK = int ( os . getenv ( \"RANK\" , - 1 ))","title":"1. \u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e"},{"location":"source_code_interpretation/utils/dataladers_py.html#2","text":"\u8fd9\u90e8\u5206\u662f\u76f8\u673a\u76f8\u5173\u8bbe\u7f6e\uff0c\u5f53\u4f7f\u7528\u76f8\u673a\u91c7\u6837\u65f6\u624d\u4f1a\u4f7f\u7528\u3002 # \u76f8\u673a\u8bbe\u7f6e # Get orientation exif tag # \u4e13\u95e8\u4e3a\u6570\u7801\u76f8\u673a\u7684\u7167\u7247\u800c\u8bbe\u5b9a \u53ef\u4ee5\u8bb0\u5f55\u6570\u7801\u7167\u7247\u7684\u5c5e\u6027\u4fe1\u606f\u548c\u62cd\u6444\u6570\u636e for orientation in ExifTags . TAGS . keys (): if ExifTags . TAGS [ orientation ] == \"Orientation\" : break def get_hash ( paths ): # \u8fd4\u56de\u6587\u4ef6\u5217\u8868\u7684hash\u503c # Returns a single hash value of a list of paths (files or dirs) size = sum ( os . path . getsize ( p ) for p in paths if os . path . exists ( p )) # sizes h = hashlib . md5 ( str ( size ) . encode ()) # hash sizes h . update ( \"\" . join ( paths ) . encode ()) # hash paths return h . hexdigest () # return hash def exif_size ( img ): # \u83b7\u53d6\u6570\u7801\u76f8\u673a\u7684\u56fe\u7247\u5bbd\u9ad8\u4fe1\u606f \u5e76\u4e14\u5224\u65ad\u662f\u5426\u9700\u8981\u65cb\u8f6c\uff08\u6570\u7801\u76f8\u673a\u53ef\u4ee5\u591a\u89d2\u5ea6\u62cd\u6444\uff09 # Returns exif-corrected PIL size s = img . size # (width, height) with contextlib . suppress ( Exception ): rotation = dict ( img . _getexif () . items ())[ orientation ] if rotation in [ 6 , 8 ]: # rotation 270 or 90 s = ( s [ 1 ], s [ 0 ]) return s def exif_transpose ( image ): \"\"\" \u5982\u679c\u6709EXIF\u65b9\u5411\u6807\u8bb0\uff0c\u5219\u76f8\u5e94\u8c03\u6362PIL\u56fe\u50cf\u3002 Transpose a PIL image accordingly if it has an EXIF Orientation tag. Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose() :param image: The image to transpose. :return: An image. \"\"\" exif = image . getexif () orientation = exif . get ( 0x0112 , 1 ) # default 1 if orientation > 1 : method = { 2 : Image . FLIP_LEFT_RIGHT , 3 : Image . ROTATE_180 , 4 : Image . FLIP_TOP_BOTTOM , 5 : Image . TRANSPOSE , 6 : Image . ROTATE_270 , 7 : Image . TRANSVERSE , 8 : Image . ROTATE_90 , } . get ( orientation ) if method is not None : image = image . transpose ( method ) del exif [ 0x0112 ] image . info [ \"exif\" ] = exif . tobytes () return image def seed_worker ( worker_id ): # Set dataloader worker seed # https://oneflow.readthedocs.io/en/master/utils.data.html?highlight=randomness#platform-specific-behaviors worker_seed = flow . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) def create_dataloader ( path , # path: \u56fe\u7247\u6570\u636e\u52a0\u8f7d\u8def\u5f84 train/test \u5982: ../datasets/coco/images/train2017 imgsz , # train/test\u56fe\u7247\u5c3a\u5bf8\uff08\u6570\u636e\u589e\u5f3a\u540e\u5927\u5c0f\uff09 640 batch_size , # batch size \u5927\u5c0f 8/16/32 stride , # \u6a21\u578b\u6700\u5927stride=32 [32 16 8] single_cls = False , # \u6570\u636e\u96c6\u662f\u5426\u662f\u5355\u7c7b\u522b \u9ed8\u8ba4False hyp = None , # \u8d85\u53c2\u5217\u8868dict \u7f51\u7edc\u8bad\u7ec3\u65f6\u7684\u4e00\u4e9b\u8d85\u53c2\u6570\uff0c\u5305\u62ec\u5b66\u4e60\u7387\u7b49\uff0c\u8fd9\u91cc\u4e3b\u8981\u7528\u5230\u91cc\u9762\u4e00\u4e9b\u5173\u4e8e\u6570\u636e\u589e\u5f3a(\u65cb\u8f6c\u3001\u5e73\u79fb\u7b49)\u7684\u7cfb\u6570 augment = False , # \u662f\u5426\u8981\u8fdb\u884c\u6570\u636e\u589e\u5f3a True cache = False , # \u662f\u5426cache_images False pad = 0.0 , # \u8bbe\u7f6e\u77e9\u5f62\u8bad\u7ec3\u7684shape\u65f6\u8fdb\u884c\u7684\u586b\u5145 \u9ed8\u8ba40.0 rect = False , # \u662f\u5426\u5f00\u542f\u77e9\u5f62train/test \u9ed8\u8ba4\u8bad\u7ec3\u96c6\u5173\u95ed \u9a8c\u8bc1\u96c6\u5f00\u542f rank =- 1 , # \u591a\u5361\u8bad\u7ec3\u65f6\u7684\u8fdb\u7a0b\u7f16\u53f7 rank\u4e3a\u8fdb\u7a0b\u7f16\u53f7 -1\u4e14gpu=1\u65f6\u4e0d\u8fdb\u884c\u5206\u5e03\u5f0f -1\u4e14\u591a\u5757gpu\u4f7f\u7528DataParallel\u6a21\u5f0f \u9ed8\u8ba4-1 workers = 8 , # dataloader\u7684num_works \u52a0\u8f7d\u6570\u636e\u65f6\u7684cpu\u8fdb\u7a0b\u6570 image_weights = False , # \u8bad\u7ec3\u65f6\u662f\u5426\u6839\u636e\u56fe\u7247\u6837\u672c\u771f\u5b9e\u6846\u5206\u5e03\u6743\u91cd\u6765\u9009\u62e9\u56fe\u7247 \u9ed8\u8ba4False quad = False , # dataloader\u53d6\u6570\u636e\u65f6, \u662f\u5426\u4f7f\u7528collate_fn4\u4ee3\u66ffcollate_fn \u9ed8\u8ba4False prefix = \"\" , # \u663e\u793a\u4fe1\u606f \u4e00\u4e2a\u6807\u5fd7\uff0c\u591a\u4e3atrain/val\uff0c\u5904\u7406\u6807\u7b7e\u65f6\u4fdd\u5b58cache\u6587\u4ef6\u4f1a\u7528\u5230 shuffle = False , # \u5bf9\u8bad\u7ec3\u6570\u636e\u662f\u5426\u968f\u673a\u6253\u4e71\u3002 ): \"\"\"\u5728train.py\u4e2d\u88ab\u8c03\u7528\uff0c\u7528\u4e8e\u751f\u6210Trainloader, dataset\uff0ctestloader \u81ea\u5b9a\u4e49dataloader\u51fd\u6570: \u8c03\u7528LoadImagesAndLabels\u83b7\u53d6\u6570\u636e\u96c6(\u5305\u62ec\u6570\u636e\u589e\u5f3a) + \u8c03\u7528\u5206\u5e03\u5f0f\u91c7\u6837\u5668DistributedSampler + \u81ea\u5b9a\u4e49InfiniteDataLoader \u8fdb\u884c\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e \"\"\" if rect and shuffle : LOGGER . warning ( \"WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\" ) shuffle = False # \u8f7d\u5165\u6587\u4ef6\u6570\u636e(\u589e\u5f3a\u6570\u636e\u96c6) dataset = LoadImagesAndLabels ( path , imgsz , batch_size , augment = augment , # augmentation hyp = hyp , # hyperparameters rect = rect , # rectangular batches cache_images = cache , single_cls = single_cls , stride = int ( stride ), pad = pad , image_weights = image_weights , prefix = prefix , ) batch_size = min ( batch_size , len ( dataset )) nd = flow . cuda . device_count () # number of CUDA devices nw = min ([ os . cpu_count () // max ( nd , 1 ), batch_size if batch_size > 1 else 0 , workers ]) # number of workers # \u5206\u5e03\u5f0f\u91c7\u6837\u5668DistributedSampler sampler = None if rank == - 1 else distributed . DistributedSampler ( dataset , shuffle = shuffle ) # \u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u6765\u5bf9DataLoader\u8fdb\u884c\u5c01\u88c5, \u4ee3\u66ff\u539f\u5148\u7684DataLoader, \u80fd\u591f\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e loader = DataLoader if image_weights else InfiniteDataLoader # only DataLoader allows for attribute updates # \u968f\u673a\u6570\u751f\u6210\u5668 https://oneflow.readthedocs.io/en/master/generated/oneflow.randint.html?highlight=flow.Generator#oneflow.randint generator = flow . Generator () generator . manual_seed ( 6148914691236517205 + RANK ) return ( loader ( dataset , batch_size = batch_size , shuffle = shuffle and sampler is None , num_workers = nw , sampler = sampler , pin_memory = True , collate_fn = LoadImagesAndLabels . collate_fn4 if quad else LoadImagesAndLabels . collate_fn , worker_init_fn = seed_worker , generator = generator , ), dataset , )","title":"2. \u76f8\u673a\u8bbe\u7f6e"},{"location":"source_code_interpretation/utils/dataladers_py.html#3dataloader","text":"\u5f53image_weights=False\u65f6\uff08\u4e0d\u6839\u636e\u56fe\u7247\u6837\u672c\u771f\u5b9e\u6846\u5206\u5e03\u6743\u91cd\u6765\u9009\u62e9\u56fe\u7247\uff09\u5c31\u4f1a\u8c03\u7528\u8fd9\u4e24\u4e2a\u51fd\u6570 \u8fdb\u884c\u81ea\u5b9a\u4e49DataLoader\uff0c\u8fdb\u884c\u6301\u7eed\u6027\u91c7\u6837\u3002\u5728\u4e0a\u9762\u7684create_dataloade\u51fd\u6570\u4e2d\u88ab\u8c03\u7528\u3002 class InfiniteDataLoader ( dataloader . DataLoader ): \"\"\"Dataloader that reuses workers \u5f53image_weights=False\u65f6\u5c31\u4f1a\u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u8fd9\u4e24\u4e2a\u7c7b\u5b9e\u73b0\u81ea\u5b9a\u4e49DataLoader \u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u6765\u5bf9DataLoader\u8fdb\u884c\u5c01\u88c5, \u4ee3\u66ff\u539f\u5148\u7684DataLoader, \u80fd\u591f\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e Uses same syntax as vanilla DataLoader \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) # \u8c03\u7528_RepeatSampler\u8fdb\u884c\u6301\u7eed\u91c7\u6837 object . __setattr__ ( self , \"batch_sampler\" , _RepeatSampler ( self . batch_sampler )) self . iterator = super () . __iter__ () def __len__ ( self ): return len ( self . batch_sampler . sampler ) def __iter__ ( self ): for _ in range ( len ( self )): yield next ( self . iterator ) class _RepeatSampler : \"\"\"Sampler that repeats forever \u8fd9\u90e8\u5206\u662f\u8fdb\u884c\u6301\u7eed\u91c7\u6837 Args: sampler (Sampler) \"\"\" def __init__ ( self , sampler ): self . sampler = sampler def __iter__ ( self ): while True : yield from iter ( self . sampler )","title":"3.\u81ea\u5b9a\u4e49DataLoader"},{"location":"source_code_interpretation/utils/dataladers_py.html#4-loadimagesandlabels","text":"\u8fd9\u4e2a\u90e8\u5206\u662f\u6570\u636e\u8f7d\u5165\uff08\u6570\u636e\u589e\u5f3a\uff09\u90e8\u5206\uff0c \u4e5f\u5c31\u662f\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u90e8\u5206\uff0c\u7ee7\u627f\u81eaDataset\uff0c\u9700\u8981\u91cd\u5199__init__,__getitem()__\u7b49\u62bd\u8c61\u65b9\u6cd5\uff0c \u53e6\u5916\u76ee\u6807\u68c0\u6d4b\u4e00\u822c\u8fd8\u9700\u8981\u91cd\u5199collate_fn\u51fd\u6570\u3002\u6240\u4ee5\uff0c\u7406\u89e3\u8fd9\u4e09\u4e2a\u51fd\u6570\u662f\u7406\u89e3\u6570\u636e\u589e\u5f3a\uff08\u6570\u636e\u8f7d\u5165\uff09\u7684\u91cd\u4e2d\u4e4b\u91cd\u3002","title":"4. LoadImagesAndLabels"},{"location":"source_code_interpretation/utils/dataladers_py.html#41-init","text":"\u8fd9\u4e2a\u51fd\u6570\u7684\u5165\u53e3\u662f\u4e0a\u9762\u7684create_dataloader\u51fd\u6570\uff1a init \u4e3b\u8981\u5e72\u4e86\u4e00\u4e0b\u51e0\u4ef6\u4e8b\uff1a \u8d4b\u503c\u4e00\u4e9b\u57fa\u7840\u7684self\u53d8\u91cf \u7528\u4e8e\u540e\u9762\u5728__getitem__\u4e2d\u8c03\u7528 \u5f97\u5230path\u8def\u5f84\u4e0b\u7684\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84self.img_files \u6839\u636eimgs\u8def\u5f84\u627e\u5230labels\u7684\u8def\u5f84self.label_files cache label Read cache \u751f\u6210self.labels\u3001self.shapes\u3001self.img_files\u3001self.label_files\u3001self.batch\u3001self.n\u3001self.indices\u7b49\u53d8\u91cf \u4e3aRectangular Training\u4f5c\u51c6\u5907: \u751f\u6210self.batch_shapes \u662f\u5426\u9700\u8981cache image(\u4e00\u822c\u4e0d\u9700\u8981\uff0c\u592a\u5927\u4e86) __init__\u51fd\u6570\u4ee3\u7801\uff1a class LoadImagesAndLabels ( Dataset ): def __init__ ( self , path , img_size = 640 , batch_size = 16 , augment = False , hyp = None , rect = False , image_weights = False , cache_images = False , single_cls = False , stride = 32 , pad = 0.0 , prefix = \"\" , ): \"\"\" \u521d\u59cb\u5316\u8fc7\u7a0b\u5e76\u6ca1\u6709\u4ec0\u4e48\u5b9e\u8d28\u6027\u7684\u64cd\u4f5c,\u66f4\u591a\u662f\u4e00\u4e2a\u5b9a\u4e49\u53c2\u6570\u7684\u8fc7\u7a0b\uff08self\u53c2\u6570\uff09,\u4ee5\u4fbf\u5728__getitem()__\u4e2d\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u64cd\u4f5c,\u6240\u4ee5\u8fd9\u90e8\u5206\u4ee3\u7801\u53ea\u9700\u8981\u6293\u4f4fself\u4e2d\u7684\u5404\u4e2a\u53d8\u91cf\u7684\u542b\u4e49\u5c31\u7b97\u5dee\u4e0d\u591a\u4e86 self.img_files: {list: N} \u5b58\u653e\u7740\u6574\u4e2a\u6570\u636e\u96c6\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84 self.label_files: {list: N} \u5b58\u653e\u7740\u6574\u4e2a\u6570\u636e\u96c6\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84 cache label -> verify_image_label self.labels: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label labels\u5b58\u50a8\u7684label\u5c31\u90fd\u662f\u539f\u59cblabel(\u90fd\u662f\u6b63\u5e38\u7684\u77e9\u5f62label) \u5426\u5219\u5c06\u6240\u6709\u56fe\u7247\u6b63\u5e38gt\u7684label\u5b58\u5165labels \u4e0d\u6b63\u5e38gt(\u5b58\u5728\u4e00\u4e2a\u591a\u8fb9\u5f62)\u7ecf\u8fc7segments2boxes\u8f6c\u6362\u4e3a\u6b63\u5e38\u7684\u77e9\u5f62label self.shapes: \u6240\u6709\u56fe\u7247\u7684shape self.segments: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label self.segments=None \u5426\u5219\u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u6240\u6709\u5b58\u5728\u591a\u8fb9\u5f62gt\u7684\u56fe\u7247\u7684\u6240\u6709\u539f\u59cblabel(\u80af\u5b9a\u6709\u591a\u8fb9\u5f62label \u4e5f\u53ef\u80fd\u6709\u77e9\u5f62\u6b63\u5e38label \u672a\u77e5\u6570) self.batch: \u8bb0\u8f7d\u7740\u6bcf\u5f20\u56fe\u7247\u5c5e\u4e8e\u54ea\u4e2abatch self.n: \u6570\u636e\u96c6\u4e2d\u6240\u6709\u56fe\u7247\u7684\u6570\u91cf self.indices: \u8bb0\u8f7d\u7740\u6240\u6709\u56fe\u7247\u7684index self.rect=True\u65f6self.batch_shapes\u8bb0\u8f7d\u6bcf\u4e2abatch\u7684shape(\u540c\u4e00\u4e2abatch\u7684\u56fe\u7247shape\u76f8\u540c) \"\"\" # 1\u3001\u8d4b\u503c\u4e00\u4e9b\u57fa\u7840\u7684self\u53d8\u91cf \u7528\u4e8e\u540e\u9762\u5728__getitem__\u4e2d\u8c03\u7528 self . img_size = img_size # \u7ecf\u8fc7\u6570\u636e\u589e\u5f3a\u540e\u7684\u6570\u636e\u56fe\u7247\u7684\u5927\u5c0f self . augment = augment # \u662f\u5426\u542f\u52a8\u6570\u636e\u589e\u5f3a \u4e00\u822c\u8bad\u7ec3\u65f6\u6253\u5f00 \u9a8c\u8bc1\u65f6\u5173\u95ed self . hyp = hyp # \u8d85\u53c2\u5217\u8868 # \u56fe\u7247\u6309\u6743\u91cd\u91c7\u6837 True\u5c31\u53ef\u4ee5\u6839\u636e\u7c7b\u522b\u9891\u7387(\u9891\u7387\u9ad8\u7684\u6743\u91cd\u5c0f,\u53cd\u6b63\u5927)\u6765\u8fdb\u884c\u91c7\u6837 \u9ed8\u8ba4False: \u4e0d\u4f5c\u7c7b\u522b\u533a\u5206 self . image_weights = image_weights self . rect = False if image_weights else rect # \u662f\u5426\u542f\u52a8\u77e9\u5f62\u8bad\u7ec3 \u4e00\u822c\u8bad\u7ec3\u65f6\u5173\u95ed \u9a8c\u8bc1\u65f6\u6253\u5f00 \u53ef\u4ee5\u52a0\u901f self . mosaic = self . augment and not self . rect # load 4 images at a time into a mosaic (only during training) # mosaic\u589e\u5f3a\u7684\u8fb9\u754c\u503c [-320, -320] self . mosaic_border = [ - img_size // 2 , - img_size // 2 ] self . stride = stride # \u6700\u5927\u4e0b\u91c7\u6837\u7387 32 self . path = path # \u56fe\u7247\u8def\u5f84 self . albumentations = Albumentations () if augment else None # 2\u3001\u5f97\u5230path\u8def\u5f84\u4e0b\u7684\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84self.img_files \u8fd9\u91cc\u9700\u8981\u81ea\u5df1debug\u4e00\u4e0b \u4e0d\u4f1a\u592a\u96be try : f = [] # image files for p in path if isinstance ( path , list ) else [ path ]: # \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84path\uff0c\u5305\u542b\u56fe\u7247\u8def\u5f84\u7684txt\u6587\u4ef6\u6216\u8005\u5305\u542b\u56fe\u7247\u7684\u6587\u4ef6\u5939\u8def\u5f84 # \u4f7f\u7528pathlib.Path\u751f\u6210\u4e0e\u64cd\u4f5c\u7cfb\u7edf\u65e0\u5173\u7684\u8def\u5f84\uff0c\u56e0\u4e3a\u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf\u8def\u5f84\u7684\u2018/\u2019\u4f1a\u6709\u6240\u4e0d\u540c p = Path ( p ) # os-agnostic # \u5982\u679c\u8def\u5f84path\u4e3a\u5305\u542b\u56fe\u7247\u7684\u6587\u4ef6\u5939\u8def\u5f84 if p . is_dir (): # dir # glob.glab: \u8fd4\u56de\u6240\u6709\u5339\u914d\u7684\u6587\u4ef6\u8def\u5f84\u5217\u8868 \u9012\u5f52\u83b7\u53d6p\u8def\u5f84\u4e0b\u6240\u6709\u6587\u4ef6 f += glob . glob ( str ( p / '**' / '*.*' ), recursive = True ) # f = list(p.rglob('**/*.*')) # pathlib # \u5982\u679c\u8def\u5f84path\u4e3a\u5305\u542b\u56fe\u7247\u8def\u5f84\u7684txt\u6587\u4ef6 elif p . is_file (): # file with open ( p , 'r' ) as t : t = t . read () . strip () . splitlines () # \u83b7\u53d6\u56fe\u7247\u8def\u5f84\uff0c\u66f4\u6362\u76f8\u5bf9\u8def\u5f84 # \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84\u7684\u4e0a\u7ea7\u7236\u76ee\u5f55 os.sep\u4e3a\u8def\u5f84\u91cc\u7684\u5206\u9694\u7b26\uff08\u4e0d\u540c\u8def\u5f84\u7684\u5206\u9694\u7b26\u4e0d\u540c\uff0cos.sep\u53ef\u4ee5\u6839\u636e\u7cfb\u7edf\u81ea\u9002\u5e94\uff09 parent = str ( p . parent ) + os . sep f += [ x . replace ( './' , parent ) if x . startswith ( './' ) else x for x in t ] # local to global path # f += [p.parent / x.lstrip(os.sep) for x in t] # local to global path (pathlib) else : raise Exception ( f ' { prefix }{ p } does not exist' ) # \u7834\u6298\u53f7\u66ff\u6362\u4e3aos.sep\uff0cos.path.splitext(x)\u5c06\u6587\u4ef6\u540d\u4e0e\u6269\u5c55\u540d\u5206\u5f00\u5e76\u8fd4\u56de\u4e00\u4e2a\u5217\u8868 # \u7b5b\u9009f\u4e2d\u6240\u6709\u7684\u56fe\u7247\u6587\u4ef6 self . im_files = sorted ( x . replace ( \"/\" , os . sep ) for x in f if x . split ( \".\" )[ - 1 ] . lower () in IMG_FORMATS ) # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS]) # pathlib assert self . im_files , f \" { prefix } No images found\" except Exception as e : raise Exception ( f \" { prefix } Error loading data from { path } : { e } \\n See { HELP_URL } \" ) # Check cache 3\u6839\u636eimgs\u8def\u5f84\u627e\u5230labels\u7684\u8def\u5f84self.label_files self . label_files = img2label_paths ( self . im_files ) # labels # 4\u3001cache label \u4e0b\u6b21\u8fd0\u884c\u8fd9\u4e2a\u811a\u672c\u7684\u65f6\u5019\u76f4\u63a5\u4ececache\u4e2d\u53d6label\u800c\u4e0d\u662f\u53bb\u6587\u4ef6\u4e2d\u53d6label \u901f\u5ea6\u66f4\u5feb cache_path = ( p if p . is_file () else Path ( self . label_files [ 0 ]) . parent ) . with_suffix ( \".cache\" ) try : # \u5982\u679c\u6709cache\u6587\u4ef6\uff0c\u76f4\u63a5\u52a0\u8f7d exists=True: \u662f\u5426\u5df2\u4ececache\u6587\u4ef6\u4e2d\u8bfb\u51fa\u4e86nf, nm, ne, nc, n\u7b49\u4fe1\u606f cache , exists = np . load ( cache_path , allow_pickle = True ) . item (), True # load dict assert cache [ \"version\" ] == self . cache_version # matches current version assert cache [ \"hash\" ] == get_hash ( self . label_files + self . im_files ) # identical hash except Exception : # \u5982\u679c\u56fe\u7247\u7248\u672c\u4fe1\u606f\u6216\u8005\u6587\u4ef6\u5217\u8868\u7684hash\u503c\u5bf9\u4e0d\u4e0a\u53f7 \u8bf4\u660e\u672c\u5730\u6570\u636e\u96c6\u56fe\u7247\u548clabel\u53ef\u80fd\u53d1\u751f\u4e86\u53d8\u5316 \u5c31\u91cd\u65b0cache label\u6587\u4ef6 cache , exists = self . cache_labels ( cache_path , prefix ), False # run cache ops # Display cache # \u6253\u5370cache\u7684\u7ed3\u679c nf nm ne nc n = \u627e\u5230\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u6f0f\u6389\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u7a7a\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u635f\u574f\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u603b\u7684\u6807\u7b7e\u6570\u91cf nf , nm , ne , nc , n = cache . pop ( \"results\" ) # found, missing, empty, corrupt, total # \u5982\u679c\u5df2\u7ecf\u4ececache\u6587\u4ef6\u8bfb\u51fa\u4e86nf nm ne nc n\u7b49\u4fe1\u606f\uff0c\u76f4\u63a5\u663e\u793a\u6807\u7b7e\u4fe1\u606f msgs\u4fe1\u606f\u7b49 if exists and LOCAL_RANK in { - 1 , 0 }: d = f \"Scanning ' { cache_path } ' images and labels... { nf } found, { nm } missing, { ne } empty, { nc } corrupt\" tqdm ( None , desc = prefix + d , total = n , initial = n , bar_format = BAR_FORMAT ) # display cache results if cache [ \"msgs\" ]: LOGGER . info ( \" \\n \" . join ( cache [ \"msgs\" ])) # display warnings # \u6570\u636e\u96c6\u6ca1\u6709\u6807\u7b7e\u4fe1\u606f \u5c31\u53d1\u51fa\u8b66\u544a\u5e76\u663e\u793a\u6807\u7b7elabel\u4e0b\u8f7d\u5730\u5740help_url assert nf > 0 or not augment , f \" { prefix } No labels in { cache_path } . Can not train without labels. See { HELP_URL } \" # 5\u3001Read cache \u4ececache\u4e2d\u8bfb\u51fa\u6700\u65b0\u53d8\u91cf\u8d4b\u7ed9self \u65b9\u4fbf\u7ed9forward\u4e2d\u4f7f\u7528 # cache\u4e2d\u7684\u952e\u503c\u5bf9\u6700\u521d\u6709: cache[img_file]=[l, shape, segments] cache[hash] cache[results] cache[msg] cache[version] # \u5148\u4ececache\u4e2d\u53bb\u9664cache\u6587\u4ef6\u4e2d\u5176\u4ed6\u65e0\u5173\u952e\u503c\u5982:'hash', 'version', 'msgs'\u7b49\u90fd\u5220\u9664 [ cache . pop ( k ) for k in ( 'hash' , 'version' , 'msgs' )] # remove items # pop\u6389results\u3001hash\u3001version\u3001msgs\u540e\u53ea\u5269\u4e0bcache[img_file]=[l, shape, segments] # cache.values(): \u53d6cache\u4e2d\u6240\u6709\u503c \u5bf9\u5e94\u6240\u6709l, shape, segments # labels: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label labels\u5b58\u50a8\u7684label\u5c31\u90fd\u662f\u539f\u59cblabel(\u90fd\u662f\u6b63\u5e38\u7684\u77e9\u5f62label) # \u5426\u5219\u5c06\u6240\u6709\u56fe\u7247\u6b63\u5e38gt\u7684label\u5b58\u5165labels \u4e0d\u6b63\u5e38gt(\u5b58\u5728\u4e00\u4e2a\u591a\u8fb9\u5f62)\u7ecf\u8fc7segments2boxes\u8f6c\u6362\u4e3a\u6b63\u5e38\u7684\u77e9\u5f62label # shapes: \u6240\u6709\u56fe\u7247\u7684shape # self.segments: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label self.segments=None # \u5426\u5219\u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u6240\u6709\u5b58\u5728\u591a\u8fb9\u5f62gt\u7684\u56fe\u7247\u7684\u6240\u6709\u539f\u59cblabel(\u80af\u5b9a\u6709\u591a\u8fb9\u5f62label \u4e5f\u53ef\u80fd\u6709\u77e9\u5f62\u6b63\u5e38label \u672a\u77e5\u6570) # zip \u662f\u56e0\u4e3acache\u4e2d\u6240\u6709labels\u3001shapes\u3001segments\u4fe1\u606f\u90fd\u662f\u6309\u6bcf\u5f20img\u5206\u5f00\u5b58\u50a8\u7684, zip\u662f\u5c06\u6240\u6709\u56fe\u7247\u5bf9\u5e94\u7684\u4fe1\u606f\u53e0\u5728\u4e00\u8d77 labels , shapes , self . segments = zip ( * cache . values ()) # segments: \u90fd\u662f[] self . labels = list ( labels ) self . shapes = np . array ( shapes ) self . im_files = list ( cache . keys ()) # update self . label_files = img2label_paths ( cache . keys ()) # update \u66f4\u65b0\u6240\u6709\u56fe\u7247\u7684label_files\u4fe1\u606f(\u56e0\u4e3aimg_files\u4fe1\u606f\u53ef\u80fd\u53d1\u751f\u4e86\u53d8\u5316) n = len ( shapes ) # number of images bi = np . floor ( np . arange ( n ) / batch_size ) . astype ( np . int ) # batch index nb = bi [ - 1 ] + 1 # number of batches self . batch = bi # batch index of image \u6240\u6709\u56fe\u7247\u7684index self . n = n self . indices = range ( n ) # Update labels include_class = [] # filter labels to include only these classes (optional) include_class_array = np . array ( include_class ) . reshape ( 1 , - 1 ) for i , ( label , segment ) in enumerate ( zip ( self . labels , self . segments )): if include_class : j = ( label [:, 0 : 1 ] == include_class_array ) . any ( 1 ) self . labels [ i ] = label [ j ] if segment : self . segments [ i ] = segment [ j ] if single_cls : # single-class training, merge all classes into 0 self . labels [ i ][:, 0 ] = 0 if segment : self . segments [ i ][:, 0 ] = 0 # Rectangular Training # 6\u3001\u4e3aRectangular Training\u4f5c\u51c6\u5907 # \u8fd9\u91cc\u4e3b\u8981\u662f\u6ce8\u610fshapes\u7684\u751f\u6210 \u8fd9\u4e00\u6b65\u5f88\u91cd\u8981 \u56e0\u4e3a\u5982\u679c\u91c7\u6837\u77e9\u5f62\u8bad\u7ec3\u90a3\u4e48\u6574\u4e2abatch\u7684\u5f62\u72b6\u8981\u4e00\u6837 \u5c31\u8981\u8ba1\u7b97\u8fd9\u4e2a\u7b26\u5408\u6574\u4e2abatch\u7684shape # \u800c\u4e14\u8fd8\u8981\u5bf9\u6570\u636e\u96c6\u6309\u7167\u9ad8\u5bbd\u6bd4\u8fdb\u884c\u6392\u5e8f \u8fd9\u6837\u624d\u80fd\u4fdd\u8bc1\u540c\u4e00\u4e2abatch\u7684\u56fe\u7247\u7684\u5f62\u72b6\u5dee\u4e0d\u591a\u76f8\u540c \u518d\u9009\u5219\u4e00\u4e2a\u5171\u540c\u7684shape\u4ee3\u4ef7\u4e5f\u6bd4\u8f83\u5c0f if self . rect : # Sort by aspect ratio s = self . shapes # wh ar = s [:, 1 ] / s [:, 0 ] # aspect ratio irect = ar . argsort () # \u6839\u636e\u9ad8\u5bbd\u6bd4\u6392\u5e8f self . img_files = [ self . img_files [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684img_files self . label_files = [ self . label_files [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684label_files self . labels = [ self . labels [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684labels self . shapes = s [ irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684wh ar = ar [ irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684aspect ratio # \u8ba1\u7b97\u6bcf\u4e2abatch\u91c7\u7528\u7684\u7edf\u4e00\u5c3a\u5ea6 Set training image shapes shapes = [[ 1 , 1 ]] * nb # nb: number of batches for i in range ( nb ): ari = ar [ bi == i ] # bi: batch index mini , maxi = ari . min (), ari . max () # \u83b7\u53d6\u7b2ci\u4e2abatch\u4e2d\uff0c\u6700\u5c0f\u548c\u6700\u5927\u9ad8\u5bbd\u6bd4 # \u5982\u679c\u9ad8/\u5bbd\u5c0f\u4e8e1(w > h)\uff0c\u5c06w\u8bbe\u4e3aimg_size\uff08\u4fdd\u8bc1\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0d\u53d8\u8fdb\u884c\u7f29\u653e\uff09 if maxi < 1 : shapes [ i ] = [ maxi , 1 ] # maxi: h\u76f8\u5bf9\u6307\u5b9a\u5c3a\u5ea6\u7684\u6bd4\u4f8b 1: w\u76f8\u5bf9\u6307\u5b9a\u5c3a\u5ea6\u7684\u6bd4\u4f8b # \u5982\u679c\u9ad8/\u5bbd\u5927\u4e8e1(w < h)\uff0c\u5c06h\u8bbe\u7f6e\u4e3aimg_size\uff08\u4fdd\u8bc1\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0d\u53d8\u8fdb\u884c\u7f29\u653e\uff09 elif mini > 1 : shapes [ i ] = [ 1 , 1 / mini ] # \u8ba1\u7b97\u6bcf\u4e2abatch\u8f93\u5165\u7f51\u7edc\u7684shape\u503c(\u5411\u4e0a\u8bbe\u7f6e\u4e3a32\u7684\u6574\u6570\u500d) # \u8981\u6c42\u6bcf\u4e2abatch_shapes\u7684\u9ad8\u5bbd\u90fd\u662f32\u7684\u6574\u6570\u500d\uff0c\u6240\u4ee5\u8981\u5148\u9664\u4ee532\uff0c\u53d6\u6574\u518d\u4e58\u4ee532\uff08\u4e0d\u8fc7img_size\u5982\u679c\u662f32\u500d\u6570\u8fd9\u91cc\u5c31\u6ca1\u5fc5\u8981\u4e86\uff09 self . batch_shapes = np . ceil ( np . array ( shapes ) * img_size / stride + pad ) . astype ( np . int ) * stride # 7\u3001\u662f\u5426\u9700\u8981cache image \u4e00\u822c\u662fFalse \u56e0\u4e3aRAM\u4f1a\u4e0d\u8db3 cache label\u8fd8\u53ef\u4ee5 \u4f46\u662fcache image\u5c31\u592a\u5927\u4e86 \u6240\u4ee5\u4e00\u822c\u4e0d\u7528 # Cache images into RAM/disk for faster training (WARNING: large datasets may exceed system resources) self . ims = [ None ] * n self . npy_files = [ Path ( f ) . with_suffix ( \".npy\" ) for f in self . im_files ] if cache_images : gb = 0 # Gigabytes of cached images self . im_hw0 , self . im_hw = [ None ] * n , [ None ] * n fcn = self . cache_images_to_disk if cache_images == \"disk\" else self . load_image results = ThreadPool ( NUM_THREADS ) . imap ( fcn , range ( n )) pbar = tqdm ( enumerate ( results ), total = n , bar_format = BAR_FORMAT , disable = LOCAL_RANK > 0 ) for i , x in pbar : if cache_images == \"disk\" : gb += self . npy_files [ i ] . stat () . st_size else : # 'ram' ( self . ims [ i ], self . im_hw0 [ i ], self . im_hw [ i ], ) = x # im, hw_orig, hw_resized = load_image(self, i) gb += self . ims [ i ] . nbytes pbar . desc = f \" { prefix } Caching images ( { gb / 1E9 : .1f } GB { cache_images } )\" pbar . close ()","title":"4.1 init"},{"location":"source_code_interpretation/utils/dataladers_py.html#42-cache_labels","text":"\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u52a0\u8f7d\u6587\u4ef6\u8def\u5f84\u4e2d\u7684label\u4fe1\u606f\u751f\u6210cache\u6587\u4ef6\u3002cache\u6587\u4ef6\u4e2d\u5305\u62ec\u7684\u4fe1\u606f\u6709\uff1aim_file, l, shape, segments, hash, results, msgs, version\u7b49\uff0c\u5177\u4f53\u770b\u4ee3\u7801\u6ce8\u91ca\u3002 def cache_labels ( self , path = Path ( './labels.cache' ), prefix = '' ): \"\"\"\u7528\u5728__init__\u51fd\u6570\u4e2d cache\u6570\u636e\u96c6label \u52a0\u8f7dlabel\u4fe1\u606f\u751f\u6210cache\u6587\u4ef6 Cache dataset labels, check images and read shapes :params path: cache\u6587\u4ef6\u4fdd\u5b58\u5730\u5740 :params prefix: \u65e5\u5fd7\u5934\u90e8\u4fe1\u606f(\u5f69\u6253\u9ad8\u4eae\u90e8\u5206) :return x: cache\u4e2d\u4fdd\u5b58\u7684\u5b57\u5178 \u5305\u62ec\u7684\u4fe1\u606f\u6709: x[im_file] = [l, shape, segments] \u4e00\u5f20\u56fe\u7247\u4e00\u4e2alabel\u76f8\u5bf9\u5e94\u7684\u4fdd\u5b58\u5230x, \u6700\u7ec8x\u4f1a\u4fdd\u5b58\u6240\u6709\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84\u3001gt\u6846\u7684\u4fe1\u606f\u3001\u5f62\u72b6shape\u3001\u6240\u6709\u7684\u591a\u8fb9\u5f62gt\u4fe1\u606f im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 l: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, cls+xywh(normalized)] shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape segments: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u6240\u6709gt\u7684label\u4fe1\u606f(\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] hash: \u5f53\u524d\u56fe\u7247\u548clabel\u6587\u4ef6\u7684hash\u503c 1 results: \u627e\u5230\u7684label\u4e2a\u6570nf, \u4e22\u5931label\u4e2a\u6570nm, \u7a7alabel\u4e2a\u6570ne, \u7834\u635flabel\u4e2a\u6570nc, \u603bimg/label\u4e2a\u6570len(self.img_files) msgs: \u6240\u6709\u6570\u636e\u96c6\u7684msgs\u4fe1\u606f version: \u5f53\u524dcache version \"\"\" x = {} # \u521d\u59cb\u5316\u6700\u7ec8cache\u4e2d\u4fdd\u5b58\u7684\u5b57\u5178dict # \u521d\u59cb\u5316number missing, found, empty, corrupt, messages # \u521d\u59cb\u5316\u6574\u4e2a\u6570\u636e\u96c6: \u6f0f\u6389\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u627e\u5230\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u7a7a\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u9519\u8bef\u6807\u7b7e(label)\u603b\u6570\u91cf, \u6240\u6709\u9519\u8bef\u4fe1\u606f nm , nf , ne , nc , msgs = 0 , 0 , 0 , 0 , [] desc = f \" { prefix } Scanning ' { path . parent / path . stem } ' images and labels...\" # \u65e5\u5fd7 # \u591a\u8fdb\u7a0b\u8c03\u7528verify_image_label\u51fd\u6570 with Pool ( num_threads ) as pool : # \u5b9a\u4e49pbar\u8fdb\u5ea6\u6761 # pool.imap_unordered: \u5bf9\u5927\u91cf\u6570\u636e\u904d\u5386\u591a\u8fdb\u7a0b\u8ba1\u7b97 \u8fd4\u56de\u4e00\u4e2a\u8fed\u4ee3\u5668 # \u628aself.img_files, self.label_files, repeat(prefix) list\u4e2d\u7684\u503c\u4f5c\u4e3a\u53c2\u6570\u4f9d\u6b21\u9001\u5165(\u4e00\u6b21\u9001\u4e00\u4e2a)verify_image_label\u51fd\u6570 pbar = tqdm ( pool . imap_unordered ( verify_image_label , zip ( self . img_files , self . label_files , repeat ( prefix ))), desc = desc , total = len ( self . img_files )) # im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 # l: [gt_num, cls+xywh(normalized)] # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u539flabel(\u5168\u90e8\u662f\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e) # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u7ecf\u8fc7segments2boxes\u5904\u7406\u597d\u7684\u6807\u7b7e(\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e\u4e0d\u5904\u7406 \u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u77e9\u5f62\u6807\u7b7e) # shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape # segments: \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5b58\u50a8None # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5c31\u628a\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709label\u5b58\u50a8\u5230segments\u4e2d(\u82e5\u5e72\u4e2a\u6b63\u5e38gt \u82e5\u5e72\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] # nm_f(nm): number missing \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u4e22\u5931 \u4e22\u5931=1 \u5b58\u5728=0 # nf_f(nf): number found \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u5b58\u5728 \u5b58\u5728=1 \u4e22\u5931=0 # ne_f(ne): number empty \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u662f\u7a7a\u7684 \u7a7a\u7684=1 \u6ca1\u7a7a=0 # nc_f(nc): number corrupt \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u6587\u4ef6\u662f\u5426\u662f\u7834\u635f\u7684 \u7834\u635f\u7684=1 \u6ca1\u7834\u635f=0 # msg: \u8fd4\u56de\u7684msg\u4fe1\u606f label\u6587\u4ef6\u5b8c\u597d=\u2018\u2019 label\u6587\u4ef6\u7834\u635f=warning\u4fe1\u606f for im_file , l , shape , segments , nm_f , nf_f , ne_f , nc_f , msg in pbar : nm += nm_f # \u7d2f\u52a0\u603bnumber missing label nf += nf_f # \u7d2f\u52a0\u603bnumber found label ne += ne_f # \u7d2f\u52a0\u603bnumber empty label nc += nc_f # \u7d2f\u52a0\u603bnumber corrupt label if im_file : x [ im_file ] = [ l , shape , segments ] # \u4fe1\u606f\u5b58\u5165\u5b57\u5178 key=im_file value=[l, shape, segments] if msg : msgs . append ( msg ) # \u5c06msg\u52a0\u5165\u603bmsg pbar . desc = f \" { desc }{ nf } found, { nm } missing, { ne } empty, { nc } corrupted\" # \u65e5\u5fd7 pbar . close () # \u5173\u95ed\u8fdb\u5ea6\u6761 # \u65e5\u5fd7\u6253\u5370\u6240\u6709msg\u4fe1\u606f if msgs : logging . info ( ' \\n ' . join ( msgs )) # \u4e00\u5f20label\u90fd\u6ca1\u627e\u5230 \u65e5\u5fd7\u6253\u5370help_url\u4e0b\u8f7d\u5730\u5740 if nf == 0 : logging . info ( f ' { prefix } WARNING: No labels found in { path } . See { help_url } ' ) x [ 'hash' ] = get_hash ( self . label_files + self . img_files ) # \u5c06\u5f53\u524d\u56fe\u7247\u548clabel\u6587\u4ef6\u7684hash\u503c\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'results' ] = nf , nm , ne , nc , len ( self . img_files ) # \u5c06nf, nm, ne, nc, len(self.img_files)\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'msgs' ] = msgs # \u5c06\u6240\u6709\u6570\u636e\u96c6\u7684msgs\u4fe1\u606f\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'version' ] = 0.3 # \u5c06\u5f53\u524dcache version\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist try : torch . save ( x , path ) # save cache to path logging . info ( f ' { prefix } New cache created: { path } ' ) except Exception as e : logging . info ( f ' { prefix } WARNING: Cache directory { path . parent } is not writeable: { e } ' ) # path not writeable return x","title":"4.2 cache_labels"},{"location":"source_code_interpretation/utils/dataladers_py.html#43-getitem","text":"\u8fd9\u90e8\u5206\u662f\u6570\u636e\u589e\u5f3a\u51fd\u6570\uff0c\u4e00\u822c\u4e00\u6b21\u6027\u6267\u884cbatch_size\u6b21\u3002 def __getitem__ ( self , index ): \"\"\" \u8fd9\u90e8\u5206\u662f\u6570\u636e\u589e\u5f3a\u51fd\u6570\uff0c\u4e00\u822c\u4e00\u6b21\u6027\u6267\u884cbatch_size\u6b21\u3002 \u8bad\u7ec3 \u6570\u636e\u589e\u5f3a: mosaic(random_perspective) + hsv + \u4e0a\u4e0b\u5de6\u53f3\u7ffb\u8f6c \u6d4b\u8bd5 \u6570\u636e\u589e\u5f3a: letterbox :return torch.from_numpy(img): \u8fd9\u4e2aindex\u7684\u56fe\u7247\u6570\u636e(\u589e\u5f3a\u540e) [3, 640, 640] :return labels_out: \u8fd9\u4e2aindex\u56fe\u7247\u7684gt label [6, 6] = [gt_num, 0+class+xywh(normalized)] :return self.img_files[index]: \u8fd9\u4e2aindex\u56fe\u7247\u7684\u8def\u5f84\u5730\u5740 :return shapes: \u8fd9\u4e2abatch\u7684\u56fe\u7247\u7684shapes \u6d4b\u8bd5\u65f6(\u77e9\u5f62\u8bad\u7ec3)\u624d\u6709 \u9a8c\u8bc1\u65f6\u4e3aNone for COCO mAP rescaling \"\"\" # \u8fd9\u91cc\u53ef\u4ee5\u901a\u8fc7\u4e09\u79cd\u5f62\u5f0f\u83b7\u53d6\u8981\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u56fe\u7247index linear, shuffled, or image_weights index = self . indices [ index ] # linear, shuffled, or image_weights hyp = self . hyp # \u8d85\u53c2 \u5305\u542b\u4f17\u591a\u6570\u636e\u589e\u5f3a\u8d85\u53c2 mosaic = self . mosaic and random . random () < hyp [ \"mosaic\" ] # mosaic\u589e\u5f3a \u5bf9\u56fe\u50cf\u8fdb\u884c4\u5f20\u56fe\u62fc\u63a5\u8bad\u7ec3 \u4e00\u822c\u8bad\u7ec3\u65f6\u8fd0\u884c # mosaic + MixUp if mosaic : # Load mosaic img , labels = self . load_mosaic ( index ) shapes = None # MixUp augmentation if random . random () < hyp [ \"mixup\" ]: img , labels = mixup ( img , labels , * self . load_mosaic ( random . randint ( 0 , self . n - 1 ))) else : # Load image # \u8f7d\u5165\u56fe\u7247 \u8f7d\u5165\u56fe\u7247\u540e\u8fd8\u4f1a\u8fdb\u884c\u4e00\u6b21resize \u5c06\u5f53\u524d\u56fe\u7247\u7684\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u7684\u5927\u5c0f(512), \u8f83\u5c0f\u8fb9\u540c\u6bd4\u4f8b\u7f29\u653e # load image img=(343, 512, 3)=(h, w, c) (h0, w0)=(335, 500) numpy index=4 # img: resize\u540e\u7684\u56fe\u7247 (h0, w0): \u539f\u59cb\u56fe\u7247\u7684hw (h, w): resize\u540e\u7684\u56fe\u7247\u7684hw # \u8fd9\u4e00\u6b65\u662f\u5c06(335, 500, 3) resize-> (343, 512, 3) img , ( h0 , w0 ), ( h , w ) = self . load_image ( index ) # Letterbox # letterbox\u4e4b\u524d\u786e\u5b9a\u8fd9\u5f20\u5f53\u524d\u56fe\u7247letterbox\u4e4b\u540e\u7684shape # \u5982\u679c\u4e0d\u7528self.rect\u77e9\u5f62\u8bad\u7ec3shape\u5c31\u662fself.img_size # \u5982\u679c\u4f7f\u7528self.rect\u77e9\u5f62\u8bad\u7ec3shape\u5c31\u662f\u5f53\u524dbatch\u7684shape # \u56e0\u4e3a\u77e9\u5f62\u8bad\u7ec3\u7684\u8bdd\u6211\u4eec\u6574\u4e2abatch\u7684shape\u5fc5\u987b\u7edf\u4e00(\u5728__init__\u51fd\u6570\u7b2c6\u8282\u5185\u5bb9) shape = self . batch_shapes [ self . batch [ index ]] if self . rect else self . img_size # final letterboxed shape img , ratio , pad = letterbox ( img , shape , auto = False , scaleup = self . augment ) shapes = ( h0 , w0 ), (( h / h0 , w / w0 ), pad ) # for COCO mAP rescaling labels = self . labels [ index ] . copy () if labels . size : # normalized xywh to pixel xyxy format labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], ratio [ 0 ] * w , ratio [ 1 ] * h , padw = pad [ 0 ], padh = pad [ 1 ]) if self . augment : # random_perspective\u589e\u5f3a: \u968f\u673a\u5bf9\u56fe\u7247\u8fdb\u884c\u65cb\u8f6c\uff0c\u5e73\u79fb\uff0c\u7f29\u653e\uff0c\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362 img , labels = random_perspective ( img , labels , degrees = hyp [ \"degrees\" ], translate = hyp [ \"translate\" ], scale = hyp [ \"scale\" ], shear = hyp [ \"shear\" ], perspective = hyp [ \"perspective\" ], ) nl = len ( labels ) # number of labels if nl : labels [:, 1 : 5 ] = xyxy2xywhn ( labels [:, 1 : 5 ], w = img . shape [ 1 ], h = img . shape [ 0 ], clip = True , eps = 1e-3 ) if self . augment : # Albumentations img , labels = self . albumentations ( img , labels ) nl = len ( labels ) # update after albumentations # HSV color-space \u8272\u57df\u7a7a\u95f4\u589e\u5f3aAugment colorspace augment_hsv ( img , hgain = hyp [ \"hsv_h\" ], sgain = hyp [ \"hsv_s\" ], vgain = hyp [ \"hsv_v\" ]) # Flip up-down if random . random () < hyp [ \"flipud\" ]: img = np . flipud ( img ) if nl : labels [:, 2 ] = 1 - labels [:, 2 ] # Flip left-right \u968f\u673a\u5de6\u53f3\u7ffb\u8f6c if random . random () < hyp [ \"fliplr\" ]: img = np . fliplr ( img ) if nl : labels [:, 1 ] = 1 - labels [:, 1 ] # Cutouts # labels = cutout(img, labels, p=0.5) # nl = len(labels) # update after cutout # 6\u4e2a\u503c\u7684tensor \u521d\u59cb\u5316\u6807\u7b7e\u6846\u5bf9\u5e94\u7684\u56fe\u7247\u5e8f\u53f7, \u914d\u5408\u4e0b\u9762\u7684collate_fn\u4f7f\u7528 labels_out = flow . zeros (( nl , 6 )) if nl : labels_out [:, 1 :] = flow . from_numpy ( labels ) # Convert img = img . transpose (( 2 , 0 , 1 ))[:: - 1 ] # HWC to CHW, BGR to RGB img = np . ascontiguousarray ( img ) # img\u53d8\u6210\u5185\u5b58\u8fde\u7eed\u7684\u6570\u636e \u52a0\u5feb\u8fd0\u7b97 return flow . from_numpy ( img ), labels_out , self . im_files [ index ], shapes","title":"4.3 getitem"},{"location":"source_code_interpretation/utils/dataladers_py.html#44-collate_fn","text":"collate_fn \u4e00\u822c\u4e5f\u53ef\u4ee5\u53eb\u8c03\u6574\u51fd\u6570,\u5f88\u591a\u4eba\u4ee5\u4e3a\u5199\u5b8c init \u548c getitem \u51fd\u6570\u6570\u636e\u589e\u5f3a\u5c31\u505a\u5b8c\u4e86\uff0c\u6211\u4eec\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u786e\u5199\u5b8c\u8fd9\u4e24\u4e2a\u51fd\u6570\u5c31\u53ef\u4ee5\u4e86\uff0c\u56e0\u4e3a\u7cfb\u7edf\u4e2d\u662f\u7ed9\u6211\u4eec\u5199\u597d\u4e86\u4e00\u4e2acollate_fn\u51fd\u6570\u7684\uff0c\u4f46\u662f\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u6211\u4eec\u5374\u9700\u8981\u91cd\u5199collate_fn\u51fd\u6570\uff0c\u4e0b\u9762\u6211\u4f1a\u4ed4\u7ec6\u7684\u8bb2\u89e3\u8fd9\u6837\u505a\u7684\u539f\u56e0\uff08\u4ee3\u7801\u4e2d\u6ce8\u91ca\uff09\u3002 \u540c\u6837\u5728create_dataloader\u4e2d\u751f\u6210dataloader\u65f6\u8c03\u7528\uff1a @staticmethod def collate_fn4 ( batch ): \"\"\"\u540c\u6837\u5728create_dataloader\u4e2d\u751f\u6210dataloader\u65f6\u8c03\u7528\uff1a \u8fd9\u91cc\u662fyolo-v5\u4f5c\u8005\u5b9e\u9a8c\u6027\u7684\u4e00\u4e2a\u4ee3\u7801 quad-collate function \u5f53train.py\u7684opt\u53c2\u6570quad=True \u5219\u8c03\u7528collate_fn4\u4ee3\u66ffcollate_fn \u4f5c\u7528: \u5982\u4e4b\u524d\u7528collate_fn\u53ef\u4ee5\u8fd4\u56de\u56fe\u7247[16, 3, 640, 640] \u7ecf\u8fc7collate_fn4\u5219\u8fd4\u56de\u56fe\u7247[4, 3, 1280, 1280] \u5c064\u5f20mosaic\u56fe\u7247[1, 3, 640, 640]\u5408\u6210\u4e00\u5f20\u5927\u7684mosaic\u56fe\u7247[1, 3, 1280, 1280] \u5c06\u4e00\u4e2abatch\u7684\u56fe\u7247\u6bcf\u56db\u5f20\u5904\u7406, 0.5\u7684\u6982\u7387\u5c06\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5230\u4e00\u5f20\u5927\u56fe\u4e0a\u8bad\u7ec3, 0.5\u6982\u7387\u76f4\u63a5\u5c06\u67d0\u5f20\u56fe\u7247\u4e0a\u91c7\u6837\u4e24\u500d\u8bad\u7ec3 \"\"\" # img: \u6574\u4e2abatch\u7684\u56fe\u7247 [16, 3, 640, 640] # label: \u6574\u4e2abatch\u7684label\u6807\u7b7e [num_target, img_index+class_index+xywh(normalized)] # path: \u6574\u4e2abatch\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84 # shapes: (h0, w0), ((h / h0, w / w0), pad) for COCO mAP rescaling img , label , path , shapes = zip ( * batch ) # transposed n = len ( shapes ) // 4 # collate_fn4\u5904\u7406\u540e\u8fd9\u4e2abatch\u4e2d\u56fe\u7247\u7684\u4e2a\u6570 im4 , label4 , path4 , shapes4 = [], [], path [: n ], shapes [: n ] # \u521d\u59cb\u5316 ho = flow . tensor ([[ 0.0 , 0 , 0 , 1 , 0 , 0 ]]) wo = flow . tensor ([[ 0.0 , 0 , 1 , 0 , 0 , 0 ]]) s = flow . tensor ([[ 1 , 1 , 0.5 , 0.5 , 0.5 , 0.5 ]]) # scale for i in range ( n ): # zidane flow.zeros(16,3,720,1280) # BCHW i *= 4 # \u91c7\u6837 [0, 4, 8, 16] if random . random () < 0.5 : # \u968f\u673a\u6570\u5c0f\u4e8e0.5\u5c31\u76f4\u63a5\u5c06\u67d0\u5f20\u56fe\u7247\u4e0a\u91c7\u6837\u4e24\u500d\u8bad\u7ec3 im = F . interpolate ( img [ i ] . unsqueeze ( 0 ) . float (), scale_factor = 2.0 , mode = \"bilinear\" , align_corners = False ,)[ 0 ] . type ( img [ i ] . type ()) lb = label [ i ] else : # \u968f\u673a\u6570\u5927\u4e8e0.5\u5c31\u5c06\u56db\u5f20\u56fe\u7247(mosaic\u540e\u7684)\u62fc\u63a5\u5230\u4e00\u5f20\u5927\u56fe\u4e0a\u8bad\u7ec3 im = flow . cat ( ( flow . cat (( img [ i ], img [ i + 1 ]), 1 ), flow . cat (( img [ i + 2 ], img [ i + 3 ]), 1 ), ), 2 , ) lb = flow . cat (( label [ i ], label [ i + 1 ] + ho , label [ i + 2 ] + wo , label [ i + 3 ] + ho + wo ), 0 ) * s im4 . append ( im ) label4 . append ( lb ) # \u540e\u9762\u8fd4\u56de\u7684\u90e8\u5206\u548ccollate_fn\u5c31\u5dee\u4e0d\u591a\u4e86 \u539f\u56e0\u548c\u89e3\u91ca\u90fd\u5199\u5728\u4e0a\u4e00\u4e2a\u51fd\u6570\u4e86 \u81ea\u5df1debug\u770b\u4e00\u4e0b\u5427 for i , lb in enumerate ( label4 ): lb [:, 0 ] = i # add target image index for build_targets() return flow . stack ( im4 , 0 ), flow . cat ( label4 , 0 ), path4 , shapes4","title":"4.4 collate_fn"},{"location":"source_code_interpretation/utils/dataladers_py.html#5-img2label_paths","text":"\u8fd9\u4e2a\u6587\u4ef6\u662f\u6839\u636e\u6570\u636e\u96c6\u4e2d\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709labels\u5bf9\u5e94\u7684\u8def\u5f84\u3002 \u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__init__\u51fd\u6570\u4e2d\u3002 def img2label_paths ( img_paths ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__init__\u51fd\u6570\u4e2d \u6839\u636eimgs\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u5bf9\u5e94labels\u7684\u8def\u5f84 Define label paths as a function of image paths :params img_paths: {list: 50} \u6574\u4e2a\u6570\u636e\u96c6\u7684\u56fe\u7247\u76f8\u5bf9\u8def\u5f84 \u4f8b\u5982: '..\\\\datasets\\\\VOC\\\\images\\\\train2007\\\\000012.jpg' => '..\\\\datasets\\\\VOC\\\\labels\\\\train2007\\\\000012.jpg' \"\"\" # \u56e0\u4e3apython\u662f\u8de8\u5e73\u53f0\u7684,\u5728Windows\u4e0a,\u6587\u4ef6\u7684\u8def\u5f84\u5206\u9694\u7b26\u662f'\\',\u5728Linux\u4e0a\u662f'/' # \u4e3a\u4e86\u8ba9\u4ee3\u7801\u5728\u4e0d\u540c\u7684\u5e73\u53f0\u4e0a\u90fd\u80fd\u8fd0\u884c\uff0c\u90a3\u4e48\u8def\u5f84\u5e94\u8be5\u5199'\\'\u8fd8\u662f'/'\u5462\uff1f os.sep\u6839\u636e\u4f60\u6240\u5904\u7684\u5e73\u53f0, \u81ea\u52a8\u91c7\u7528\u76f8\u5e94\u7684\u5206\u9694\u7b26\u53f7 # sa: '\\\\images\\\\' sb: '\\\\labels\\\\' sa , sb = os . sep + 'images' + os . sep , os . sep + 'labels' + os . sep # /images/, /labels/ substrings # \u628aimg_paths\u4e2d\u6240\u4ee5\u56fe\u7247\u8def\u5f84\u4e2d\u7684images\u66ff\u6362\u4e3alabels return [ sb . join ( x . rsplit ( sa , 1 )) . rsplit ( '.' , 1 )[ 0 ] + '.txt' for x in img_paths ]","title":"5. img2label_paths"},{"location":"source_code_interpretation/utils/dataladers_py.html#6-verify_image_label","text":"\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u68c0\u67e5\u6bcf\u4e00\u5f20\u56fe\u7247\u548c\u6bcf\u4e00\u5f20label\u6587\u4ef6\u662f\u5426\u5b8c\u597d\u3002 \u2003 \u56fe\u7247\u6587\u4ef6: \u68c0\u67e5\u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027 \u2003 label\u6587\u4ef6: \u68c0\u67e5\u6bcf\u4e2agt\u5fc5\u987b\u662f\u77e9\u5f62(\u6bcf\u884c\u90fd\u5f97\u662f5\u4e2a\u6570 class+xywh) + \u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 + \u6807\u7b7e\u5750\u6807xywh\u662f\u5426\u5f52\u4e00\u5316 + \u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 verify_image_label\u51fd\u6570\u4ee3\u7801\uff1a def verify_image_label ( args ): \"\"\"\u7528\u5728cache_labels\u51fd\u6570\u4e2d \u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u6bcf\u5f20\u56fe\u7247\u548c\u6bcf\u5f20laebl\u662f\u5426\u5b8c\u597d \u56fe\u7247\u6587\u4ef6: \u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027 label\u6587\u4ef6: \u6bcf\u4e2agt\u5fc5\u987b\u662f\u77e9\u5f62(\u6bcf\u884c\u90fd\u5f97\u662f5\u4e2a\u6570 class+xywh) + \u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 + \u6807\u7b7e\u5750\u6807xywh\u662f\u5426\u5f52\u4e00\u5316 + \u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 :params im_file: \u6570\u636e\u96c6\u4e2d\u4e00\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 :params lb_file: \u6570\u636e\u96c6\u4e2d\u4e00\u5f20\u56fe\u7247\u7684label\u76f8\u5bf9\u8def\u5f84 :params prefix: \u65e5\u5fd7\u5934\u90e8\u4fe1\u606f(\u5f69\u6253\u9ad8\u4eae\u90e8\u5206) :return im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 :return l: [gt_num, cls+xywh(normalized)] \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u539flabel(\u5168\u90e8\u662f\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e) \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u7ecf\u8fc7segments2boxes\u5904\u7406\u597d\u7684\u6807\u7b7e(\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e\u4e0d\u5904\u7406 \u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u77e9\u5f62\u6807\u7b7e) :return shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape :return segments: \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5b58\u50a8None \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5c31\u628a\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709label\u5b58\u50a8\u5230segments\u4e2d(\u82e5\u5e72\u4e2a\u6b63\u5e38gt \u82e5\u5e72\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] :return nm: number missing \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u4e22\u5931 \u4e22\u5931=1 \u5b58\u5728=0 :return nf: number found \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u5b58\u5728 \u5b58\u5728=1 \u4e22\u5931=0 :return ne: number empty \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u662f\u7a7a\u7684 \u7a7a\u7684=1 \u6ca1\u7a7a=0 :return nc: number corrupt \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u6587\u4ef6\u662f\u5426\u662f\u7834\u635f\u7684 \u7834\u635f\u7684=1 \u6ca1\u7834\u635f=0 :return msg: \u8fd4\u56de\u7684msg\u4fe1\u606f label\u6587\u4ef6\u5b8c\u597d=\u2018\u2019 label\u6587\u4ef6\u7834\u635f=warning\u4fe1\u606f \"\"\" # Verify one image-label pair im_file , lb_file , prefix = args nm , nf , ne , nc , msg , segments = ( 0 , 0 , 0 , 0 , \"\" , [], ) # number (missing, found, empty, corrupt), message, segments try : # verify images \u68c0\u67e5\u8fd9\u5f20\u56fe\u7247(\u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027) verify images im = Image . open ( im_file ) # \u6253\u5f00\u56fe\u7247\u6587\u4ef6 im . verify () # PIL verify \u68c0\u67e5\u56fe\u7247\u5185\u5bb9\u548c\u683c\u5f0f\u662f\u5426\u6b63\u5e38 shape = exif_size ( im ) # image size \u5f53\u524d\u56fe\u7247\u7684\u5927\u5c0f image size # \u56fe\u7247\u5927\u5c0f\u5fc5\u987b\u5927\u4e8e9\u4e2apixels assert ( shape [ 0 ] > 9 ) & ( shape [ 1 ] > 9 ), f \"image size { shape } <10 pixels\" # \u56fe\u7247\u683c\u5f0f\u5fc5\u987b\u5728img_format\u4e2d assert im . format . lower () in IMG_FORMATS , f \"invalid image format { im . format } \" if im . format . lower () in ( \"jpg\" , \"jpeg\" ): # \u68c0\u67e5jpg\u683c\u5f0f\u6587\u4ef6 with open ( im_file , \"rb\" ) as f : # f.seek: -2 \u504f\u79fb\u91cf \u5411\u6587\u4ef6\u5934\u65b9\u5411\u4e2d\u79fb\u52a8\u7684\u5b57\u8282\u6570 2 \u76f8\u5bf9\u4f4d\u7f6e \u4ece\u6587\u4ef6\u5c3e\u5f00\u59cb\u504f\u79fb f . seek ( - 2 , 2 ) # f.read(): \u8bfb\u53d6\u56fe\u7247\u6587\u4ef6 \u6307\u4ee4: \\xff\\xd9 \u68c0\u6d4b\u6574\u5f20\u56fe\u7247\u662f\u5426\u5b8c\u6574 \u5982\u679c\u4e0d\u5b8c\u6574\u5c31\u8fd4\u56decorrupted JPEG if f . read () != b \" \\xff\\xd9 \" : # corrupt JPEG ImageOps . exif_transpose ( Image . open ( im_file )) . save ( im_file , \"JPEG\" , subsampling = 0 , quality = 100 ) msg = f \" { prefix } WARNING: { im_file } : corrupt JPEG restored and saved\" # verify labels if os . path . isfile ( lb_file ): nf = 1 # label found with open ( lb_file ) as f : # \u8bfb\u53d6\u5f53\u524dlabel\u6587\u4ef6\u7684\u6bcf\u4e00\u884c: \u6bcf\u4e00\u884c\u90fd\u662f\u5f53\u524d\u56fe\u7247\u7684\u4e00\u4e2agt lb = [ x . split () for x in f . read () . strip () . splitlines () if len ( x )] # any() \u51fd\u6570\u7528\u4e8e\u5224\u65ad\u7ed9\u5b9a\u7684\u53ef\u8fed\u4ee3\u53c2\u6570 \u662f\u5426\u5168\u90e8\u4e3aFalse,\u5219\u8fd4\u56de False; \u5982\u679c\u6709\u4e00\u4e2a\u4e3a True,\u5219\u8fd4\u56deTrue # \u5982\u679c\u5f53\u524d\u56fe\u7247\u7684label\u6587\u4ef6\u67d0\u4e00\u5217\u6570\u5927\u4e8e8, \u5219\u8ba4\u4e3alabel\u662f\u5b58\u5728segment\u7684polygon\u70b9(\u591a\u8fb9\u5f62) # \u5c31\u4e0d\u662f\u77e9\u9635 \u5219\u5c06label\u4fe1\u606f\u5b58\u5165segment\u4e2d if any ( len ( x ) > 6 for x in lb ): # is segment # \u5f53\u524d\u56fe\u7247\u4e2d\u6240\u6709gt\u6846\u7684\u7c7b\u522b classes = np . array ([ x [ 0 ] for x in lb ], dtype = np . float32 ) # \u83b7\u5f97\u8fd9\u5f20\u56fe\u4e2d\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) # \u56e0\u4e3asegment\u6807\u7b7e\u53ef\u4ee5\u662f\u4e0d\u540c\u957f\u5ea6\uff0c\u6240\u4ee5\u8fd9\u91ccsegments\u662f\u4e00\u4e2a\u5217\u8868 [gt_num, xy1...(normalized)] segments = [ np . array ( x [ 1 :], dtype = np . float32 ) . reshape ( - 1 , 2 ) for x in lb ] # (cls, xy1...) # \u83b7\u5f97\u8fd9\u5f20\u56fe\u4e2d\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) # segments(\u591a\u8fb9\u5f62) -> bbox(\u6b63\u65b9\u5f62), \u5f97\u5230\u65b0\u6807\u7b7e [gt_num, cls+xywh(normalized)] lb = np . concatenate (( classes . reshape ( - 1 , 1 ), segments2boxes ( segments )), 1 ) # (cls, xywh) lb = np . array ( lb , dtype = np . float32 ) nl = len ( lb ) if nl : # \u5224\u65ad\u6807\u7b7e\u662f\u5426\u6709\u4e94\u5217 assert lb . shape [ 1 ] == 5 , f \"labels require 5 columns, { lb . shape [ 1 ] } columns detected\" # \u5224\u65ad\u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 assert ( lb >= 0 ) . all (), f \"negative label values { lb [ lb < 0 ] } \" # \u5224\u65ad\u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 assert ( lb [:, 1 :] <= 1 ) . all (), f \"non-normalized or out of bounds coordinates { lb [:, 1 :][ lb [:, 1 :] > 1 ] } \" _ , i = np . unique ( lb , axis = 0 , return_index = True ) if len ( i ) < nl : # duplicate row check lb = lb [ i ] # remove duplicates if segments : segments = segments [ i ] msg = f \" { prefix } WARNING: { im_file } : { nl - len ( i ) } duplicate labels removed\" else : ne = 1 # label empty l.shape[0] == 0\u5219\u4e3a\u7a7a\u7684\u6807\u7b7e\uff0cne=1 lb = np . zeros (( 0 , 5 ), dtype = np . float32 ) else : nm = 1 # label missing lb = np . zeros (( 0 , 5 ), dtype = np . float32 ) return im_file , lb , shape , segments , nm , nf , ne , nc , msg except Exception as e : nc = 1 msg = f \" { prefix } WARNING: { im_file } : ignoring corrupt image/label: { e } \" return [ None , None , None , None , nm , nf , ne , nc , msg ]","title":"6. verify_image_label"},{"location":"source_code_interpretation/utils/dataladers_py.html#7-load_image","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u6839\u636e\u56fe\u7247index\uff0c\u4eceself\u6216\u8005\u4ece\u5bf9\u5e94\u56fe\u7247\u8def\u5f84\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247 \u5e76\u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55\u3002 \u4f1a\u88ab\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u548cload_mosaic\u6a21\u5757\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247\uff1a load_image\u51fd\u6570\u4ee3\u7801\uff1a def load_image ( self , i ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u548cload_mosaic\u6a21\u5757\u4e2d \u4eceself\u6216\u8005\u4ece\u5bf9\u5e94\u56fe\u7247\u8def\u5f84\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247 \u5e76\u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55 loads 1 image from dataset, returns img, original hw, resized hw :params self: \u4e00\u822c\u662f\u5bfc\u5165LoadImagesAndLabels\u4e2d\u7684self :param index: \u5f53\u524d\u56fe\u7247\u7684index :return: img: resize\u540e\u7684\u56fe\u7247 (h0, w0): hw_original \u539f\u56fe\u7684hw img.shape[:2]: hw_resized resize\u540e\u7684\u56fe\u7247hw(hw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55) \"\"\" im , f , fn = ( self . ims [ i ], self . im_files [ i ], self . npy_files [ i ], ) if im is None : # not cached in RAM if fn . exists (): # load npy im = np . load ( fn ) else : # read image im = cv2 . imread ( f ) # BGR assert im is not None , f \"Image Not Found { f } \" h0 , w0 = im . shape [: 2 ] # orig hw r = self . img_size / max ( h0 , w0 ) # ratio if r != 1 : # if sizes are not equal # cv2.INTER_AREA: \u57fa\u4e8e\u533a\u57df\u50cf\u7d20\u5173\u7cfb\u7684\u4e00\u79cd\u91cd\u91c7\u6837\u6216\u8005\u63d2\u503c\u65b9\u5f0f.\u8be5\u65b9\u6cd5\u662f\u56fe\u50cf\u62bd\u53d6\u7684\u9996\u9009\u65b9\u6cd5, \u5b83\u53ef\u4ee5\u4ea7\u751f\u66f4\u5c11\u7684\u6ce2\u7eb9 # cv2.INTER_LINEAR: \u53cc\u7ebf\u6027\u63d2\u503c,\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4f7f\u7528\u8be5\u65b9\u5f0f\u8fdb\u884c\u63d2\u503c \u6839\u636eratio\u9009\u62e9\u4e0d\u540c\u7684\u63d2\u503c\u65b9\u5f0f # \u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55 interp = cv2 . INTER_LINEAR if ( self . augment or r > 1 ) else cv2 . INTER_AREA im = cv2 . resize ( im , ( int ( w0 * r ), int ( h0 * r )), interpolation = interp ) return im , ( h0 , w0 ), im . shape [: 2 ] # im, hw_original, hw_resized return self . ims [ i ], self . im_hw0 [ i ], self . im_hw [ i ] # im, hw_original, hw_resized","title":"7. load_image"},{"location":"source_code_interpretation/utils/dataladers_py.html#8-augment_hsv","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5173\u4e8e\u56fe\u7247\u7684\u8272\u57df\u589e\u5f3a\u6a21\u5757\uff0c\u56fe\u7247\u5e76\u4e0d\u53d1\u751f\u79fb\u52a8\uff0c\u6240\u6709\u4e0d\u9700\u8981\u6539\u53d8label\uff0c\u53ea\u9700\u8981 img \u589e\u5f3a\u5373\u53ef\u3002 augment_hsv\u6a21\u5757\u4ee3\u7801\uff1a def augment_hsv ( img , hgain = 0.5 , sgain = 0.5 , vgain = 0.5 ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 hsv\u8272\u57df\u589e\u5f3a \u5904\u7406\u56fe\u50cfhsv\uff0c\u4e0d\u5bf9label\u8fdb\u884c\u4efb\u4f55\u5904\u7406 :param img: \u5f85\u5904\u7406\u56fe\u7247 BGR [736, 736] :param hgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684h\u901a\u9053 :param sgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684s\u901a\u9053 :param vgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684v\u901a\u9053 :return: \u8fd4\u56dehsv\u589e\u5f3a\u540e\u7684\u56fe\u7247 img \"\"\" if hgain or sgain or vgain : # \u968f\u673a\u53d6-1\u52301\u4e09\u4e2a\u5b9e\u6570\uff0c\u4e58\u4ee5hyp\u4e2d\u7684hsv\u4e09\u901a\u9053\u7684\u7cfb\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684hsv\u901a\u9053 r = np . random . uniform ( - 1 , 1 , 3 ) * [ hgain , sgain , vgain ] + 1 # random gains hue , sat , val = cv2 . split ( cv2 . cvtColor ( img , cv2 . COLOR_BGR2HSV )) # \u56fe\u50cf\u7684\u901a\u9053\u62c6\u5206 h s v dtype = img . dtype # uint8 x = np . arange ( 0 , 256 , dtype = r . dtype ) lut_hue = (( x * r [ 0 ]) % 180 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684h\u901a\u9053 lut_sat = np . clip ( x * r [ 1 ], 0 , 255 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684s\u901a\u9053 lut_val = np . clip ( x * r [ 2 ], 0 , 255 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684v\u901a\u9053 # \u56fe\u50cf\u7684\u901a\u9053\u5408\u5e76 img_hsv=h+s+v \u968f\u673a\u8c03\u6574hsv\u4e4b\u540e\u91cd\u65b0\u7ec4\u5408hsv\u901a\u9053 # cv2.LUT(hue, lut_hue) \u901a\u9053\u8272\u57df\u53d8\u6362 \u8f93\u5165\u53d8\u6362\u524d\u901a\u9053hue \u548c\u53d8\u6362\u540e\u901a\u9053lut_hue img_hsv = cv2 . merge (( cv2 . LUT ( hue , lut_hue ), cv2 . LUT ( sat , lut_sat ), cv2 . LUT ( val , lut_val ))) # no return needed dst:\u8f93\u51fa\u56fe\u50cf cv2 . cvtColor ( img_hsv , cv2 . COLOR_HSV2BGR , dst = img ) # no return needed hsv->bgr \u8fd8\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e2ahsv\u589e\u5f3a\u662f\u968f\u673a\u751f\u6210\u5404\u4e2a\u8272\u57df\u53c2\u6570\u7684\uff0c\u6240\u4ee5\u6bcf\u6b21\u589e\u5f3a\u7684\u6548\u679c\u90fd\u662f\u4e0d\u540c\u7684\uff1a \u8fd9\u4e2a\u51fd\u6570\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u4e2d\uff1a \u53e6\u5916\uff0c\u8fd9\u91cc\u6d89\u53ca\u5230\u7684\u4e09\u4e2a\u53d8\u91cf\u6765\u81eahyp.yaml\u8d85\u53c2\u6587\u4ef6\uff1a","title":"8. augment_hsv"},{"location":"source_code_interpretation/utils/dataladers_py.html#9-load_mosaicload_mosaic9","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u90fd\u662fmosaic\u6570\u636e\u589e\u5f3a\uff0c\u53ea\u4e0d\u8fc7load_mosaic\u51fd\u6570\u662f\u62fc\u63a5\u56db\u5f20\u56fe\uff0c\u800cload_mosaic9\u51fd\u6570\u662f\u62fc\u63a5\u4e5d\u5f20\u56fe\u3002 \u66f4\u591a\u8bf7\u53c2\u9605 \u300amosaic \u89e3\u8bfb\u300b","title":"9. load_mosaic\u3001load_mosaic9"},{"location":"source_code_interpretation/utils/dataladers_py.html#91-load_mosaic","text":"\u8fd9\u4e2a\u6a21\u5757\u5c31\u662f\u5f88\u6709\u540d\u7684mosaic\u589e\u5f3a\u6a21\u5757\uff0c\u51e0\u4e4e\u8bad\u7ec3\u7684\u65f6\u5019\u90fd\u4f1a\u7528\u5b83\uff0c\u53ef\u4ee5\u663e\u8457\u7684\u63d0\u9ad8\u5c0f\u6837\u672c\u7684mAP\u3002 \u4ee3\u7801\u662f\u6570\u636e\u589e\u5f3a\u91cc\u9762\u6700\u96be\u7684, \u4e5f\u662f\u6700\u6709\u4ef7\u503c\u7684\uff0cmosaic\u662f\u975e\u5e38\u975e\u5e38\u6709\u7528\u7684\u6570\u636e\u589e\u5f3atrick, \u4e00\u5b9a\u8981\u719f\u7ec3\u638c\u63e1\u3002 load_mosaic\u6a21\u5757\u4ee3\u7801\uff1a def load_mosaic ( self , index ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u8fdb\u884cmosaic\u6570\u636e\u589e\u5f3a \u5c06\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d loads images in a 4-mosaic :param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 :return: img4: mosaic\u548c\u968f\u673a\u900f\u89c6\u53d8\u6362\u540e\u7684\u4e00\u5f20\u56fe\u7247 numpy(640, 640, 3) labels4: img4\u5bf9\u5e94\u7684target [M, cls+x1y1x2y2] \"\"\" # labels4: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff084\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegments\u591a\u8fb9\u5f62) # segments4: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff084\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62) labels4 , segments4 = [], [] s = self . img_size # \u4e00\u822c\u7684\u56fe\u7247\u5927\u5c0f # \u968f\u673a\u521d\u59cb\u5316\u62fc\u63a5\u56fe\u50cf\u7684\u4e2d\u5fc3\u70b9\u5750\u6807 [0, s*2]\u4e4b\u95f4\u968f\u673a\u53d62\u4e2a\u6570\u4f5c\u4e3a\u62fc\u63a5\u56fe\u50cf\u7684\u4e2d\u5fc3\u5750\u6807 yc , xc = [ int ( random . uniform ( - x , 2 * s + x )) for x in self . mosaic_border ] # mosaic center x, y # \u4ecedataset\u4e2d\u968f\u673a\u5bfb\u627e\u989d\u5916\u7684\u4e09\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 [14, 26, 2, 16] \u518d\u968f\u673a\u9009\u4e09\u5f20\u56fe\u7247\u7684index indices = [ index ] + random . choices ( self . indices , k = 3 ) # 3 additional image indices # \u904d\u5386\u56db\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 4\u5f20\u4e0d\u540c\u5927\u5c0f\u7684\u56fe\u50cf => 1\u5f20[1472, 1472, 3]\u7684\u56fe\u50cf for i , index in enumerate ( indices ): # load image \u6bcf\u6b21\u62ff\u4e00\u5f20\u56fe\u7247 \u5e76\u5c06\u8fd9\u5f20\u56fe\u7247resize\u5230self.size(h,w) img , _ , ( h , w ) = load_image ( self , index ) # place img in img4 if i == 0 : # top left \u539f\u56fe[375, 500, 3] load_image->[552, 736, 3] hwc # \u521b\u5efa\u9a6c\u8d5b\u514b\u56fe\u50cf [1472, 1472, 3]=[h, w, c] img4 = np . full (( s * 2 , s * 2 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) w=736 h = 552 \u9a6c\u8d5b\u514b\u56fe\u50cf\uff1a(x1a,y1a)\u5de6\u4e0a\u89d2 (x2a,y2a)\u53f3\u4e0b\u89d2 x1a , y1a , x2a , y2a = max ( xc - w , 0 ), max ( yc - h , 0 ), xc , yc # xmin, ymin, xmax, ymax (large image) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e00\u5f20\u56fe\u50cf\u7684\u53f3\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) \u56fe\u50cf\uff1a(x1b,y1b)\u5de6\u4e0a\u89d2 (x2b,y2b)\u53f3\u4e0b\u89d2 x1b , y1b , x2b , y2b = w - ( x2a - x1a ), h - ( y2a - y1a ), w , h # xmin, ymin, xmax, ymax (small image) elif i == 1 : # top right # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = xc , max ( yc - h , 0 ), min ( xc + w , s * 2 ), yc # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e8c\u5f20\u56fe\u50cf\u7684\u5de6\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = 0 , h - ( y2a - y1a ), min ( w , x2a - x1a ), h elif i == 2 : # bottom left # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = max ( xc - w , 0 ), yc , xc , min ( s * 2 , yc + h ) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e09\u5f20\u56fe\u50cf\u7684\u53f3\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = w - ( x2a - x1a ), 0 , w , min ( y2a - y1a , h ) elif i == 3 : # bottom right # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = xc , yc , min ( xc + w , s * 2 ), min ( s * 2 , yc + h ) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u56db\u5f20\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = 0 , 0 , min ( w , x2a - x1a ), min ( y2a - y1a , h ) # \u5c06\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u7684\u76f8\u5e94\u4f4d\u7f6e img4[h, w, c] # \u5c06\u56fe\u50cfimg\u7684\u3010(x1b,y1b)\u5de6\u4e0a\u89d2 (x2b,y2b)\u53f3\u4e0b\u89d2\u3011\u533a\u57df\u622a\u53d6\u51fa\u6765\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u7684\u3010(x1a,y1a)\u5de6\u4e0a\u89d2 (x2a,y2a)\u53f3\u4e0b\u89d2\u3011\u533a\u57df img4 [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] # \u8ba1\u7b97pad(\u5f53\u524d\u56fe\u50cf\u8fb9\u754c\u4e0e\u9a6c\u8d5b\u514b\u8fb9\u754c\u7684\u8ddd\u79bb\uff0c\u8d8a\u754c\u7684\u60c5\u51b5padw/padh\u4e3a\u8d1f\u503c) \u7528\u4e8e\u540e\u9762\u7684label\u6620\u5c04 padw = x1a - x1b # \u5f53\u524d\u56fe\u50cf\u4e0e\u9a6c\u8d5b\u514b\u56fe\u50cf\u5728w\u7ef4\u5ea6\u4e0a\u76f8\u5dee\u591a\u5c11 padh = y1a - y1b # \u5f53\u524d\u56fe\u50cf\u4e0e\u9a6c\u8d5b\u514b\u56fe\u50cf\u5728h\u7ef4\u5ea6\u4e0a\u76f8\u5dee\u591a\u5c11 # labels: \u83b7\u53d6\u5bf9\u5e94\u62fc\u63a5\u56fe\u50cf\u7684\u6240\u6709\u6b63\u5e38label\u4fe1\u606f(\u5982\u679c\u6709segments\u591a\u8fb9\u5f62\u4f1a\u88ab\u8f6c\u5316\u4e3a\u77e9\u5f62label) # segments: \u83b7\u53d6\u5bf9\u5e94\u62fc\u63a5\u56fe\u50cf\u7684\u6240\u6709\u4e0d\u6b63\u5e38label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62\u4e5f\u5305\u542b\u6b63\u5e38gt) labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : # normalized xywh normalized to pixel xyxy format labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padw , padh ) segments = [ xyn2xy ( x , w , h , padw , padh ) for x in segments ] labels4 . append ( labels ) # \u66f4\u65b0labels4 segments4 . extend ( segments ) # \u66f4\u65b0segments4 # Concat/clip labels4 \u628alabels4\uff08[(2, 5), (1, 5), (3, 5), (1, 5)] => (7, 5)\uff09\u538b\u7f29\u5230\u4e00\u8d77 labels4 = np . concatenate ( labels4 , 0 ) # \u9632\u6b62\u8d8a\u754c label[:, 1:]\u4e2d\u7684\u6240\u6709\u5143\u7d20\u7684\u503c\uff08\u4f4d\u7f6e\u4fe1\u606f\uff09\u5fc5\u987b\u5728[0, 2*s]\u4e4b\u95f4,\u5c0f\u4e8e0\u5c31\u4ee4\u5176\u7b49\u4e8e0,\u5927\u4e8e2*s\u5c31\u7b49\u4e8e2*s out: \u8fd4\u56de for x in ( labels4 [:, 1 :], * segments4 ): np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5\u524d\u9762\u7684mosaic\u6548\u679c # cv2.imshow(\"mosaic\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (1280, 1280, 3) # \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408 replicate # img4, labels4 = replicate(img4, labels4) # # # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5replicate\u6548\u679c # cv2.imshow(\"replicate\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (1280, 1280, 3) # Augment # random_perspective Augment \u968f\u673a\u900f\u89c6\u53d8\u6362 [1280, 1280, 3] => [640, 640, 3] # \u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5mosaic + random_perspective\u968f\u673a\u4eff\u5c04\u53d8\u6362\u6548\u679c # cv2.imshow(\"random_perspective\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (640, 640, 3) return img4 , labels4","title":"9.1 load_mosaic"},{"location":"source_code_interpretation/utils/dataladers_py.html#92-load_mosaic9","text":"\u8fd9\u4e2a\u6a21\u5757\u662f\u4f5c\u8005\u7684\u5b9e\u9a8c\u6a21\u5757\uff0c\u5c06\u4e5d\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u3002\u603b\u4f53\u4ee3\u7801\u6d41\u7a0b\u548cload_mosaic4\u51e0\u4e4e\u4e00\u6837\uff0c\u770b\u61c2\u4e86load_mosaic4\u518d\u770b\u8fd9\u4e2a\u5c31\u5f88\u7b80\u5355\u4e86\u3001 load_mosaic9\u6a21\u5757\u4ee3\u7801\uff1a def load_mosaic9 ( self , index ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u66ff\u6362mosaic\u6570\u636e\u589e\u5f3a \u5c06\u4e5d\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d loads images in a 9-mosaic :param self: :param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 :return: img9: mosaic\u548c\u4eff\u5c04\u589e\u5f3a\u540e\u7684\u4e00\u5f20\u56fe\u7247 labels9: img9\u5bf9\u5e94\u7684target \"\"\" # labels9: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff089\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegments\u591a\u8fb9\u5f62) # segments9: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff089\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62) labels9 , segments9 = [], [] s = self . img_size # \u4e00\u822c\u7684\u56fe\u7247\u5927\u5c0f(\u4e5f\u662f\u6700\u7ec8\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f) # \u4ecedataset\u4e2d\u968f\u673a\u5bfb\u627e\u989d\u5916\u7684\u4e09\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 [14, 26, 2, 16] \u518d\u968f\u673a\u9009\u4e09\u5f20\u56fe\u7247\u7684index indices = [ index ] + random . choices ( self . indices , k = 8 ) # 8 additional image indices for i , index in enumerate ( indices ): # Load image \u6bcf\u6b21\u62ff\u4e00\u5f20\u56fe\u7247 \u5e76\u5c06\u8fd9\u5f20\u56fe\u7247resize\u5230self.size(h,w) img , _ , ( h , w ) = load_image ( self , index ) # \u8fd9\u91cc\u548c\u4e0a\u9762load_mosaic\u51fd\u6570\u7684\u64cd\u4f5c\u7c7b\u4f3c \u5c31\u662f\u5c06\u53d6\u51fa\u7684img\u56fe\u7247\u5d4c\u5230img9\u4e2d(\u4e0d\u662f\u771f\u7684\u5d4c\u5165 \u800c\u662f\u627e\u5230\u5bf9\u5e94\u7684\u4f4d\u7f6e) # place img in img9 if i == 0 : # center img9 = np . full (( s * 3 , s * 3 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles h0 , w0 = h , w c = s , s , s + w , s + h # xmin, ymin, xmax, ymax (base) coordinates elif i == 1 : # top c = s , s - h , s + w , s elif i == 2 : # top right c = s + wp , s - h , s + wp + w , s elif i == 3 : # right c = s + w0 , s , s + w0 + w , s + h elif i == 4 : # bottom right c = s + w0 , s + hp , s + w0 + w , s + hp + h elif i == 5 : # bottom c = s + w0 - w , s + h0 , s + w0 , s + h0 + h elif i == 6 : # bottom left c = s + w0 - wp - w , s + h0 , s + w0 - wp , s + h0 + h elif i == 7 : # left c = s - w , s + h0 - h , s , s + h0 elif i == 8 : # top left c = s - w , s + h0 - hp - h , s , s + h0 - hp padx , pady = c [: 2 ] x1 , y1 , x2 , y2 = [ max ( x , 0 ) for x in c ] # allocate coords # \u548c\u4e0a\u9762load_mosaic\u51fd\u6570\u7684\u64cd\u4f5c\u7c7b\u4f3c \u627e\u5230mosaic9\u589e\u5f3a\u540e\u7684labels9\u548csegments9 labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padx , pady ) # normalized xywh to pixel xyxy format segments = [ xyn2xy ( x , w , h , padx , pady ) for x in segments ] labels9 . append ( labels ) segments9 . extend ( segments ) # \u751f\u6210\u5bf9\u5e94\u7684img9\u56fe\u7247(\u5c06\u5bf9\u5e94\u4f4d\u7f6e\u7684\u56fe\u7247\u5d4c\u5165img9\u4e2d) img9 [ y1 : y2 , x1 : x2 ] = img [ y1 - pady :, x1 - padx :] # img9[ymin:ymax, xmin:xmax] hp , wp = h , w # height, width previous # Offset yc , xc = [ int ( random . uniform ( 0 , s )) for _ in self . mosaic_border ] # mosaic center x, y img9 = img9 [ yc : yc + 2 * s , xc : xc + 2 * s ] # Concat/clip labels labels9 = np . concatenate ( labels9 , 0 ) labels9 [:, [ 1 , 3 ]] -= xc labels9 [:, [ 2 , 4 ]] -= yc c = np . array ([ xc , yc ]) # centers segments9 = [ x - c for x in segments9 ] for x in ( labels9 [:, 1 :], * segments9 ): np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img9, labels9 = replicate(img9, labels9) # replicate # Augment \u540c\u6837\u8fdb\u884c \u968f\u673a\u900f\u89c6\u53d8\u6362 img9 , labels9 = random_perspective ( img9 , labels9 , segments9 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove return img9 , labels9 \u7528\u6cd5\u548cmosaic\u4e00\u6837\uff0c\u4f7f\u7528\u76f4\u63a5\u5c06class LoadImagesAndLabels(Dataset): \u4e2d getitem \u7684load_mosaic\u76f4\u63a5 \u76f4\u63a5\u66ff\u6362\u6210load_mosaic9\u5373\u53ef\uff1a","title":"9.2 load_mosaic9"},{"location":"source_code_interpretation/utils/dataladers_py.html#10-loadimages-loadstreams-loadwebcam","text":"load \u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247/\u89c6\u9891 + \u7528\u5230\u5f88\u5c11 load web\u7f51\u9875\u4e2d\u7684\u6570\u636e\u3002 \u5168\u90e8\u4ee3\u7801\uff1a class LoadImages : # for inference \"\"\"\u5728detect.py\u4e2d\u4f7f\u7528 load \u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247/\u89c6\u9891 \u5b9a\u4e49\u8fed\u4ee3\u5668 \u7528\u4e8edetect.py \"\"\" def __init__ ( self , path , img_size = 640 , stride = 32 ): p = str ( Path ( path ) . absolute ()) # os-agnostic absolute path # glob.glab: \u8fd4\u56de\u6240\u6709\u5339\u914d\u7684\u6587\u4ef6\u8def\u5f84\u5217\u8868 files: \u63d0\u53d6\u56fe\u7247\u6240\u6709\u8def\u5f84 if \"*\" in p : # \u5982\u679cp\u662f\u91c7\u6837\u6b63\u5219\u5316\u8868\u8fbe\u5f0f\u63d0\u53d6\u56fe\u7247/\u89c6\u9891, \u53ef\u4ee5\u4f7f\u7528glob\u83b7\u53d6\u6587\u4ef6\u8def\u5f84 files = sorted ( glob . glob ( p , recursive = True )) # glob elif os . path . isdir ( p ): # \u5982\u679cp\u662f\u4e00\u4e2a\u6587\u4ef6\u5939\uff0c\u4f7f\u7528glob\u83b7\u53d6\u5168\u90e8\u6587\u4ef6\u8def\u5f84 files = sorted ( glob . glob ( os . path . join ( p , \"*.*\" ))) # dir elif os . path . isfile ( p ): # \u5982\u679cp\u662f\u6587\u4ef6\u5219\u76f4\u63a5\u83b7\u53d6 files = [ p ] # files else : raise Exception ( f \"ERROR: { p } does not exist\" ) # images: \u76ee\u5f55\u4e0b\u6240\u6709\u56fe\u7247\u7684\u56fe\u7247\u540d videos: \u76ee\u5f55\u4e0b\u6240\u6709\u89c6\u9891\u7684\u89c6\u9891\u540d images = [ x for x in files if x . split ( \".\" )[ - 1 ] . lower () in img_formats ] videos = [ x for x in files if x . split ( \".\" )[ - 1 ] . lower () in vid_formats ] # \u56fe\u7247\u4e0e\u89c6\u9891\u6570\u91cf ni , nv = len ( images ), len ( videos ) self . img_size = img_size self . stride = stride # \u6700\u5927\u7684\u4e0b\u91c7\u6837\u7387 self . files = images + videos # \u6574\u5408\u56fe\u7247\u548c\u89c6\u9891\u8def\u5f84\u5230\u4e00\u4e2a\u5217\u8868 self . nf = ni + nv # number of files self . video_flag = [ False ] * ni + [ True ] * nv # \u662f\u4e0d\u662fvideo self . mode = \"image\" # \u9ed8\u8ba4\u662f\u8bfbimage\u6a21\u5f0f if any ( videos ): # \u5224\u65ad\u6709\u6ca1\u6709video\u6587\u4ef6 \u5982\u679c\u5305\u542bvideo\u6587\u4ef6\uff0c\u5219\u521d\u59cb\u5316opencv\u4e2d\u7684\u89c6\u9891\u6a21\u5757\uff0ccap=cv2.VideoCapture\u7b49 self . new_video ( videos [ 0 ]) # new video else : self . cap = None assert self . nf > 0 , ( f \"No images or videos found in { p } . \" f \"Supported formats are: \\n images: { img_formats } \\n videos: { vid_formats } \" ) def __iter__ ( self ): \"\"\"\u8fed\u4ee3\u5668\"\"\" self . count = 0 return self def __next__ ( self ): \"\"\"\u4e0eiter\u4e00\u8d77\u7528\uff1f\"\"\" if self . count == self . nf : # \u6570\u636e\u8bfb\u5b8c\u4e86 raise StopIteration path = self . files [ self . count ] # \u8bfb\u53d6\u5f53\u524d\u6587\u4ef6\u8def\u5f84 if self . video_flag [ self . count ]: # \u5224\u65ad\u5f53\u524d\u6587\u4ef6\u662f\u5426\u662f\u89c6\u9891 # Read video self . mode = \"video\" # \u83b7\u53d6\u5f53\u524d\u5e27\u753b\u9762\uff0cret_val\u4e3a\u4e00\u4e2abool\u53d8\u91cf\uff0c\u76f4\u5230\u89c6\u9891\u8bfb\u53d6\u5b8c\u6bd5\u4e4b\u524d\u90fd\u4e3aTrue ret_val , img0 = self . cap . read () # \u5982\u679c\u5f53\u524d\u89c6\u9891\u8bfb\u53d6\u7ed3\u675f\uff0c\u5219\u8bfb\u53d6\u4e0b\u4e00\u4e2a\u89c6\u9891 if not ret_val : self . count += 1 self . cap . release () # self.count == self.nf\u8868\u793a\u89c6\u9891\u5df2\u7ecf\u8bfb\u53d6\u5b8c\u4e86 if self . count == self . nf : # last video raise StopIteration else : path = self . files [ self . count ] self . new_video ( path ) ret_val , img0 = self . cap . read () self . frame += 1 # \u5f53\u524d\u8bfb\u53d6\u89c6\u9891\u7684\u5e27\u6570 print ( f \"video { self . count + 1 } / { self . nf } ( { self . frame } / { self . frames } ) { path } : \" , end = \"\" , ) else : # Read image self . count += 1 img0 = cv2 . imread ( path ) # BGR assert img0 is not None , \"Image Not Found \" + path print ( f \"image { self . count } / { self . nf } { path } : \" , end = \"\" ) # Padded resize img = letterbox ( img0 , self . img_size , stride = self . stride )[ 0 ] # Convert img = img [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB and HWC to CHW img = np . ascontiguousarray ( img ) # \u8fd4\u56de\u8def\u5f84, resize+pad\u7684\u56fe\u7247, \u539f\u59cb\u56fe\u7247, \u89c6\u9891\u5bf9\u8c61 return path , img , img0 , self . cap def new_video ( self , path ): # \u8bb0\u5f55\u5e27\u6570 self . frame = 0 # \u521d\u59cb\u5316\u89c6\u9891\u5bf9\u8c61 self . cap = cv2 . VideoCapture ( path ) # \u5f97\u5230\u89c6\u9891\u6587\u4ef6\u4e2d\u7684\u603b\u5e27\u6570 self . frames = int ( self . cap . get ( cv2 . CAP_PROP_FRAME_COUNT )) def __len__ ( self ): return self . nf # number of files class LoadStreams : \"\"\" load \u6587\u4ef6\u5939\u4e2d\u89c6\u9891\u6d41 multiple IP or RTSP cameras \u5b9a\u4e49\u8fed\u4ee3\u5668 \u7528\u4e8edetect.py \"\"\" def __init__ ( self , sources = \"streams.txt\" , img_size = 640 , stride = 32 ): self . mode = \"stream\" # \u521d\u59cb\u5316mode\u4e3aimages self . img_size = img_size self . stride = stride # \u6700\u5927\u4e0b\u91c7\u6837\u6b65\u957f # \u5982\u679csources\u4e3a\u4e00\u4e2a\u4fdd\u5b58\u4e86\u591a\u4e2a\u89c6\u9891\u6d41\u7684\u6587\u4ef6 \u83b7\u53d6\u6bcf\u4e00\u4e2a\u89c6\u9891\u6d41\uff0c\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u5217\u8868 if os . path . isfile ( sources ): with open ( sources , \"r\" ) as f : sources = [ x . strip () for x in f . read () . strip () . splitlines () if len ( x . strip ()) ] else : # \u53cd\u4e4b\uff0c\u53ea\u6709\u4e00\u4e2a\u89c6\u9891\u6d41\u6587\u4ef6\u5c31\u76f4\u63a5\u4fdd\u5b58 sources = [ sources ] n = len ( sources ) # \u89c6\u9891\u6d41\u4e2a\u6570 # \u521d\u59cb\u5316\u56fe\u7247 fps \u603b\u5e27\u6570 \u7ebf\u7a0b\u6570 self . imgs , self . fps , self . frames , self . threads = ( [ None ] * n , [ 0 ] * n , [ 0 ] * n , [ None ] * n , ) self . sources = [ clean_str ( x ) for x in sources ] # clean source names for later # \u904d\u5386\u6bcf\u4e00\u4e2a\u89c6\u9891\u6d41 for i , s in enumerate ( sources ): # index, source # Start thread to read frames from video stream # \u6253\u5370\u5f53\u524d\u89c6\u9891index/\u603b\u89c6\u9891\u6570/\u89c6\u9891\u6d41\u5730\u5740 print ( f \" { i + 1 } / { n } : { s } ... \" , end = \"\" ) if \"youtube.com/\" in s or \"youtu.be/\" in s : # if source is YouTube video check_requirements (( \"pafy\" , \"youtube_dl\" )) import pafy s = pafy . new ( s ) . getbest ( preftype = \"mp4\" ) . url # YouTube URL s = eval ( s ) if s . isnumeric () else s # i.e. s = '0' local webcam \u672c\u5730\u6444\u50cf\u5934 # s='0'\u6253\u5f00\u672c\u5730\u6444\u50cf\u5934\uff0c\u5426\u5219\u6253\u5f00\u89c6\u9891\u6d41\u5730\u5740 cap = cv2 . VideoCapture ( s ) assert cap . isOpened (), f \"Failed to open { s } \" # \u83b7\u53d6\u89c6\u9891\u7684\u5bbd\u548c\u957f w = int ( cap . get ( cv2 . CAP_PROP_FRAME_WIDTH )) h = int ( cap . get ( cv2 . CAP_PROP_FRAME_HEIGHT )) # \u83b7\u53d6\u89c6\u9891\u7684\u5e27\u7387 self . fps [ i ] = ( max ( cap . get ( cv2 . CAP_PROP_FPS ) % 100 , 0 ) or 30.0 ) # 30 FPS fallback # \u5e27\u6570 self . frames [ i ] = max ( int ( cap . get ( cv2 . CAP_PROP_FRAME_COUNT )), 0 ) or float ( \"inf\" ) # infinite stream fallback # \u8bfb\u53d6\u5f53\u524d\u753b\u9762 _ , self . imgs [ i ] = cap . read () # guarantee first frame # \u521b\u5efa\u591a\u7ebf\u7a0b\u8bfb\u53d6\u89c6\u9891\u6d41\uff0cdaemon\u8868\u793a\u4e3b\u7ebf\u7a0b\u7ed3\u675f\u65f6\u5b50\u7ebf\u7a0b\u4e5f\u7ed3\u675f self . threads [ i ] = Thread ( target = self . update , args = ([ i , cap ]), daemon = True ) print ( f \" success ( { self . frames [ i ] } frames { w } x { h } at { self . fps [ i ] : .2f } FPS)\" ) self . threads [ i ] . start () print ( \"\" ) # newline # check for common shapes # \u83b7\u53d6\u8fdb\u884cresize+pad\u4e4b\u540e\u7684shape\uff0cletterbox\u51fd\u6570\u9ed8\u8ba4(\u53c2\u6570auto=True)\u662f\u6309\u7167\u77e9\u5f62\u63a8\u7406\u8fdb\u884c\u586b\u5145 s = np . stack ( [ letterbox ( x , self . img_size , stride = self . stride )[ 0 ] . shape for x in self . imgs ], 0 , ) # shapes self . rect = ( np . unique ( s , axis = 0 ) . shape [ 0 ] == 1 ) # rect inference if all shapes equal if not self . rect : print ( \"WARNING: Different stream shapes detected. For optimal performance supply similarly-shaped streams.\" ) def update ( self , i , cap ): # Read stream `i` frames in daemon thread n , f = 0 , self . frames [ i ] while cap . isOpened () and n < f : n += 1 # _, self.imgs[index] = cap.read() cap . grab () # \u6bcf4\u5e27\u8bfb\u53d6\u4e00\u6b21 if n % 4 : # read every 4th frame success , im = cap . retrieve () self . imgs [ i ] = im if success else self . imgs [ i ] * 0 time . sleep ( 1 / self . fps [ i ]) # wait time def __iter__ ( self ): self . count = - 1 return self def __next__ ( self ): self . count += 1 if not all ( x . is_alive () for x in self . threads ) or cv2 . waitKey ( 1 ) == ord ( \"q\" ): # q to quit cv2 . destroyAllWindows () raise StopIteration # Letterbox img0 = self . imgs . copy () img = [ letterbox ( x , self . img_size , auto = self . rect , stride = self . stride )[ 0 ] for x in img0 ] # Stack \u5c06\u8bfb\u53d6\u7684\u56fe\u7247\u62fc\u63a5\u5230\u4e00\u8d77 img = np . stack ( img , 0 ) # Convert img = img [:, :, :, :: - 1 ] . transpose ( 0 , 3 , 1 , 2 ) # BGR to RGB and BHWC to BCHW img = np . ascontiguousarray ( img ) return self . sources , img , img0 , None def __len__ ( self ): return 0 # 1E12 frames = 32 streams at 30 FPS for 30 years class LoadWebcam : # for inference \"\"\"\u7528\u5230\u5f88\u5c11 load web\u7f51\u9875\u4e2d\u7684\u6570\u636e\"\"\" def __init__ ( self , pipe = \"0\" , img_size = 640 , stride = 32 ): self . img_size = img_size self . stride = stride if pipe . isnumeric (): pipe = eval ( pipe ) # local camera # pipe = 'rtsp://192.168.1.64/1' # IP camera # pipe = 'rtsp://username:password@192.168.1.64/1' # IP camera with login # pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg' # IP golf camera self . pipe = pipe self . cap = cv2 . VideoCapture ( pipe ) # video capture object self . cap . set ( cv2 . CAP_PROP_BUFFERSIZE , 3 ) # set buffer size def __iter__ ( self ): self . count = - 1 return self def __next__ ( self ): self . count += 1 if cv2 . waitKey ( 1 ) == ord ( \"q\" ): # q to quit self . cap . release () cv2 . destroyAllWindows () raise StopIteration # Read frame if self . pipe == 0 : # local camera ret_val , img0 = self . cap . read () img0 = cv2 . flip ( img0 , 1 ) # flip left-right else : # IP camera n = 0 while True : n += 1 self . cap . grab () if n % 30 == 0 : # skip frames ret_val , img0 = self . cap . retrieve () if ret_val : break # Print assert ret_val , f \"Camera Error { self . pipe } \" img_path = \"webcam.jpg\" print ( f \"webcam { self . count } : \" , end = \"\" ) # Padded resize img = letterbox ( img0 , self . img_size , stride = self . stride )[ 0 ] # Convert img = img [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB and HWC to CHW img = np . ascontiguousarray ( img ) return img_path , img , img0 , None def __len__ ( self ): return 0","title":"10. LoadImages &amp; LoadStreams &amp; LoadWebcam"},{"location":"source_code_interpretation/utils/dataladers_py.html#11-flatten_recursive","text":"\u8fd9\u4e2a\u6a21\u5757\u662f\u5c06\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u590d\u5236\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d \u5373\u5c06image\u6587\u4ef6\u548clabel\u6587\u4ef6\u653e\u5230\u4e00\u4e2a\u65b0\u6587\u4ef6\u5939\u4e2d\u3002 flatten_recursive\u6a21\u5757\u4ee3\u7801\uff1a def flatten_recursive ( path = DATASETS_DIR / \"coco128\" ): # \u5c06\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u590d\u5236\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d \u5373\u5c06image\u6587\u4ef6\u548clabel\u6587\u4ef6\u653e\u5230\u4e00\u4e2a\u65b0\u6587\u4ef6\u5939\u4e2d # Flatten a recursive directory by bringing all files to top level new_path = Path ( f \" { str ( path ) } _flat\" ) if os . path . exists ( new_path ): shutil . rmtree ( new_path ) # delete output folder os . makedirs ( new_path ) # make new output folder for file in tqdm ( glob . glob ( f \" { str ( Path ( path )) } /**/*.*\" , recursive = True )): # shutil.copyfile: \u590d\u5236\u6587\u4ef6\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d shutil . copyfile ( file , new_path / Path ( file ) . name )","title":"11. flatten_recursive"},{"location":"source_code_interpretation/utils/dataladers_py.html#12extract_boxes","text":"\u8fd9\u4e2a\u6a21\u5757\u662f\u5c06\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u5206\u7c7b\u6570\u636e\u96c6 \uff0c\u96c6\u4f53\u505a\u6cd5: \u628a\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2agt\u62c6\u89e3\u5f00 \u5206\u7c7b\u522b\u5b58\u50a8\u5230\u5bf9\u5e94\u7684\u6587\u4ef6\u5f53\u4e2d\u3002 def extract_boxes ( path = DATASETS_DIR / \"coco128\" , ): # from utils.dataloaders import *; extract_boxes() # Convert detection dataset into classification dataset, with one directory per class \"\"\"\u81ea\u884c\u4f7f\u7528 \u751f\u6210\u5206\u7c7b\u6570\u636e\u96c6 \u5c06\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u5206\u7c7b\u6570\u636e\u96c6 \u96c6\u4f53\u505a\u6cd5: \u628a\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2agt\u62c6\u89e3\u5f00 \u5206\u7c7b\u522b\u5b58\u50a8\u5230\u5bf9\u5e94\u7684\u6587\u4ef6\u5f53\u4e2d Convert detection dataset into classification dataset, with one directory per class \u4f7f\u7528: from utils.datasets import *; extract_boxes() :params path: \u6570\u636e\u96c6\u5730\u5740 \"\"\" path = Path ( path ) # images dir \u6570\u636e\u96c6\u6587\u4ef6\u76ee\u5f55 \u9ed8\u8ba4'..\\datasets\\coco128' shutil . rmtree ( path / \"classifier\" ) if ( path / \"classifier\" ) . is_dir () else None # remove existing files = list ( path . rglob ( \"*.*\" )) n = len ( files ) # number of files for im_file in tqdm ( files , total = n ): if im_file . suffix [ 1 :] in IMG_FORMATS : # \u5fc5\u987b\u5f97\u662f\u56fe\u7247\u6587\u4ef6 # image im = cv2 . imread ( str ( im_file ))[ ... , :: - 1 ] # BGR to RGB h , w = im . shape [: 2 ] # \u5f97\u5230\u8fd9\u5f20\u56fe\u7247h w # labels \u6839\u636e\u8fd9\u5f20\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u8fd9\u5f20\u56fe\u7247\u7684label\u8def\u5f84 lb_file = Path ( img2label_paths ([ str ( im_file )])[ 0 ]) if Path ( lb_file ) . exists (): with open ( lb_file ) as f : lb = np . array ([ x . split () for x in f . read () . strip () . splitlines ()], dtype = np . float32 ) # labels \u8bfb\u53d6label\u7684\u5404\u884c: \u5bf9\u5e94\u5404\u4e2agt\u5750\u6807 for j , x in enumerate ( lb ): # \u904d\u5386\u6bcf\u4e00\u4e2agt c = int ( x [ 0 ]) # class # \u751f\u6210\u65b0'file_name path\\classifier\\class_index\\image_name' # \u5982: 'F:\\yolo_v5\\datasets\\coco128\\images\\train2017\\classifier\\45\\train2017_000000000009_0.jpg' f = ( path / \"classifier\" ) / f \" { c } \" / f \" { path . stem } _ { im_file . stem } _ { j } .jpg\" # new filename if not f . parent . is_dir (): # \u6bcf\u4e00\u4e2a\u7c7b\u522b\u7684\u7b2c\u4e00\u5f20\u7167\u7247\u5b58\u8fdb\u53bb\u4e4b\u524d \u5148\u521b\u5efa\u5bf9\u5e94\u7c7b\u7684\u6587\u4ef6\u5939 f . parent . mkdir ( parents = True ) b = x [ 1 :] * [ w , h , w , h ] # box normalized to \u6b63\u5e38\u5927\u5c0f # b[2:] = b[2:].max() # rectangle to square b [ 2 :] = b [ 2 :] * 1.2 + 3 # pad b = xywh2xyxy ( b . reshape ( - 1 , 4 )) . ravel () . astype ( np . int ) b [[ 0 , 2 ]] = np . clip ( b [[ 0 , 2 ]], 0 , w ) # clip boxes outside of image \u9632\u6b62\u51fa\u754c b [[ 1 , 3 ]] = np . clip ( b [[ 1 , 3 ]], 0 , h ) assert cv2 . imwrite ( str ( f ), im [ b [ 1 ] : b [ 3 ], b [ 0 ] : b [ 2 ]]), f \"box failure in { f } \"","title":"12.extract_boxes"},{"location":"source_code_interpretation/utils/dataladers_py.html#13-autosplit","text":"\u8fd9\u4e2a\u6a21\u5757\u662f\u8fdb\u884c\u81ea\u52a8\u5212\u5206\u6570\u636e\u96c6\u3002\u5f53\u4f7f\u7528\u81ea\u5df1\u6570\u636e\u96c6\u65f6\uff0c\u53ef\u4ee5\u7528\u8fd9\u4e2a\u6a21\u5757\u8fdb\u884c\u81ea\u884c\u5212\u5206\u6570\u636e\u96c6\u3002 autosplit\u6a21\u5757\u4ee3\u7801\uff1a def autosplit ( path = DATASETS_DIR / \"coco128/images\" , weights = ( 0.9 , 0.1 , 0.0 ), annotated_only = False ): \"\"\"Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files Usage: from utils.dataloaders import *; autosplit() Arguments path: Path to images directory weights: Train, val, test weights (list, tuple) annotated_only: Only use images with an annotated txt file \"\"\" path = Path ( path ) # images dir # \u83b7\u53d6images\u4e2d\u6240\u6709\u7684\u56fe\u7247 image files only files = sorted ( x for x in path . rglob ( \"*.*\" ) if x . suffix [ 1 :] . lower () in IMG_FORMATS ) # image files only n = len ( files ) # number of files # \u968f\u673a\u6570\u79cd\u5b50 random . seed ( 0 ) # for reproducibility # assign each image to a split \u6839\u636e(train, val, test)\u6743\u91cd\u5212\u5206\u539f\u59cb\u56fe\u7247\u6570\u636e\u96c6 # indices: [n] 0, 1, 2 \u5206\u522b\u8868\u793a\u6570\u636e\u96c6\u4e2d\u6bcf\u4e00\u5f20\u56fe\u7247\u5c5e\u4e8e\u54ea\u4e2a\u6570\u636e\u96c6 \u5206\u522b\u5bf9\u5e94\u7740(train, val, test) indices = random . choices ([ 0 , 1 , 2 ], weights = weights , k = n ) # assign each image to a split txt = [ \"autosplit_train.txt\" , \"autosplit_val.txt\" , \"autosplit_test.txt\" ] # 3 txt files [( path . parent / x ) . unlink ( missing_ok = True ) for x in txt ] # remove existing print ( f \"Autosplitting images from { path } \" + \", using *.txt labeled images only\" * annotated_only ) for i , img in tqdm ( zip ( indices , files ), total = n ): if not annotated_only or Path ( img2label_paths ([ str ( img )])[ 0 ]) . exists (): # check label with open ( path . parent / txt [ i ], \"a\" ) as f : f . write ( f \"./ { img . relative_to ( path . parent ) . as_posix () } \" + \" \\n \" ) # add image to txt file","title":"13. autosplit"},{"location":"source_code_interpretation/utils/dataladers_py.html#reference","text":"\u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011 atasets.py","title":"Reference"},{"location":"source_code_interpretation/utils/downloads_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/augmentations.py \u8fd9\u4e2a\u6587\u4ef6\u4e3b\u8981\u662f\u8d1f\u8d23\u4ecegithub/googleleaps/google drive \u7b49\u7f51\u7ad9\u6216\u8005 \u4e91\u670d\u52a1\u5668 \u4e0a\u4e0b\u8f7d\u6240\u9700\u7684\u4e00\u4e9b\u6587\u4ef6\u3002 \u662f\u4e00\u4e2a\u5de5\u5177\u7c7b\uff0c\u4ee3\u7801\u6bd4\u8f83\u7b80\u5355\uff0c\u51fd\u6570\u4e5f\u6bd4\u8f83\u5c11\uff0c\u4e3b\u8981\u96be\u70b9\u8fd8\u662f\u5728\u4e8e\u4e00\u4e9b\u5305\u53ef\u80fd\u5927\u5bb6\u4e0d\u662f\u5f88\u719f\u6089\uff0c\u4e0b\u9762\u4e00\u8d77\u6765\u5b66\u4e60\u4e0b\u3002 \u8fd9\u4e2a\u6587\u4ef6\u6bd4\u8f83\u91cd\u8981\u7684\u662f\u4e24\u4e2a\u51fd\u6570\uff1asafe_download\u548cattempt_download\u3002\u5728train.py\u6216\u8005yolo.py\u7b49\u6587\u4ef6\u4e2d\u90fd\u4f1a\u7528\u5230\u3002 1. \u5bfc\u5165\u9700\u8981\u7684\u5305 \"\"\" Download utils \"\"\" import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 import platform # \u63d0\u4f9b\u83b7\u53d6\u64cd\u4f5c\u7cfb\u7edf\u76f8\u5173\u4fe1\u606f\u7684\u6a21\u5757 import shutil import subprocess # \u5b50\u8fdb\u7a0b\u5b9a\u4e49\u53ca\u64cd\u4f5c\u7684\u6a21\u5757 import time import urllib # \u7528\u4e8e\u64cd\u4f5c\u7f51\u9875 URL\uff0c\u5e76\u5bf9\u7f51\u9875\u7684\u5185\u5bb9\u8fdb\u884c\u6293\u53d6\u5904\u7406 \u5982urllib.parse: \u89e3\u6790url from pathlib import Path from zipfile import ZipFile import oneflow as flow import requests # \u901a\u8fc7urllib3\u5b9e\u73b0\u81ea\u52a8\u53d1\u9001HTTP/1.1\u8bf7\u6c42\u7684\u7b2c\u4e09\u65b9\u6a21\u5757 2. gsutil_getsize \u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5url\u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f\u3002 def gsutil_getsize ( url = \"\" ): \"\"\"\u7528\u5728downloads.py\u7684print_mutation\u51fd\u6570\u5f53\u4e2d \u8ba1\u7b97\u67d0\u4e2aurl\u5bf9\u5e94\u7684\u6587\u4ef6\u5927\u5c0f \u7528\u4e8e\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5url\u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du \"\"\" # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u5728\u547d\u4ee4\u884c\u6267\u884c gsutil du url \u547d\u4ee4(\u8bbf\u95ee Cloud Storage) \u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u6587\u4ef6) # gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du s = subprocess . check_output ( f \"gsutil du { url } \" , shell = True ) . decode ( \"utf-8\" ) return eval ( s . split ( \" \" )[ 0 ]) if len ( s ) else 0 # bytes 3. safe_download\u3001attempt_download \u8fd9\u4e24\u4e2a\u51fd\u6570\u4e3b\u8981\u662f\u7528\u6765\u4ecegithub\u6216\u8005googleleaps\u4e91\u670d\u52a1\u5668\u4e2d\u4e0b\u8f7d\u6587\u4ef6\u7684\uff0c\u4e3b\u8981\u662f\u4e0b\u8f7d\u6743\u91cd\u6587\u4ef6\u3002 attempt_download\u51fd\u6570\u8c03\u7528safe_download\u51fd\u6570\u3002 3.1 safe_download \u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u4e0b\u8f7d url\uff08github\uff09 \u6216\u8005 url2\uff08\u8c37\u6b4c\u4e91\u670d\u52a1\u5668\uff09 \u8def\u5f84\u5bf9\u5e94\u7684\u7f51\u9875\u6587\u4ef6\uff0c \u901a\u5e38\u662f\u4e0b\u8f7d\u6743\u91cd\u6587\u4ef6\uff0c\u4f1a\u7528\u5728attempt_download\u51fd\u6570\u4e2d\u5982\uff1a def safe_download ( file , url , url2 = None , min_bytes = 1e0 , error_msg = \"\" ): \"\"\"\u7528\u5728attempt_download\u51fd\u6570\u4e2d \u4e0b\u8f7d url/url2 \u8def\u5f84\u5bf9\u5e94\u7684\u7f51\u9875\u6587\u4ef6 Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes @params file: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d @params url: \u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740 \u4e00\u822c\u662fgithub @params url2: \u7b2c\u4e8c\u4e2a\u4e0b\u8f7d\u5730\u5740(\u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740\u4e0b\u8f7d\u5931\u8d25\u540e\u4f7f\u7528) \u4e00\u822c\u662fgoogleleaps\u7b49\u4e91\u670d\u52a1\u5668 @params min_bytes: \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765 \u53ea\u6709\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes\u624d\u80fd\u5224\u65ad\u6587\u4ef6\u5df2\u7ecf\u4e0b\u8f7d\u4e0b\u6765\u4e86 @params error_msg: \u6587\u4ef6\u4e0b\u8f7d\u5931\u8d25\u7684\u663e\u793a\u4fe1\u606f \u521d\u59cb\u5316\u9ed8\u8ba4\u4e3a\u7a7a \"\"\" # Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes file = Path ( file ) assert_msg = f \"Downloaded file ' { file } ' does not exist or size is < min_bytes= { min_bytes } \" try : # url1 y: \u5c1d\u8bd5\u4eceurl\u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgithub print ( f \"Downloading { url } to { file } ...\" ) // \u4f7f\u7528 oneflow . hub . download_url_to_file \u4e0b\u8f7d url \u94fe\u63a5\u5bf9\u5e94\u7684\u6587\u4ef6 \uff0c // \u5173\u4e8eoneflow . hub\u6a21\u5757\u8bb2\u89e3\u53ef\u4ee5\u770b \uff1a https : // www . bilibili . com / video / BV1YG4y1B72u / ? spm_id_from = 333.999.0.0 flow . hub . download_url_to_file ( url , str ( file )) # \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765\u4e86(\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes) assert file . exists () and file . stat () . st_size > min_bytes , assert_msg # check except Exception as e : # url2 \u4e0d\u884c\u5c31\u5c1d\u8bd5\u4eceurl2\u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgoogleleaps(\u4e91\u670d\u52a1\u5668) # \u79fb\u9664\u4e4b\u524d\u4e0b\u8f7d\u5931\u8d25\u7684\u6587\u4ef6 file . unlink ( missing_ok = True ) # remove partial downloads print ( f \"ERROR: { e } \\n Re-attempting { url2 or url } to { file } ...\" ) os . system ( f \"curl -L ' { url2 or url } ' -o ' { file } ' --retry 3 -C -\" ) # curl download, retry and resume on fail finally : # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765\u4e86(\u662f\u5426\u5b58\u5728) \u6216 \u6587\u4ef6\u5927\u5c0f\u662f\u5426\u5c0f\u4e8emin_bytes if not file . exists () or file . stat () . st_size < min_bytes : # check # \u4e0b\u8f7d\u5931\u8d25 \u79fb\u9664\u4e0b\u8f7d\u5931\u8d25\u7684\u6587\u4ef6 remove partial downloads file . unlink ( missing_ok = True ) # remove partial downloads # \u6253\u5370\u9519\u8bef\u4fe1\u606f print ( f \"ERROR: { assert_msg } \\n { error_msg } \" ) print ( \"\" ) url = \"https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/model_comparison.png\" safe_download ( \"op.png\" , url ) Downloading https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/model_comparison.png to op.png... 0%| | 0.00/118k [00:00<?, ?B/s] from PIL import Image display ( Image . open ( \"op.png\" )) # \u663e\u793a\u4e0b\u8f7d\u7684\u56fe\u7247 3.2 attempt_download \u8fd9\u4e2a\u51fd\u6570\u662f\u5b9e\u73b0\u4ece\u51e0\u4e2a\u4e91\u5e73\u53f0(github/googleleaps\u4e91\u670d\u52a1\u5668)\u4e0b\u8f7d\u6587\u4ef6(\u9884\u8bad\u7ec3\u6a21\u578b)\uff0c \u4f1a\u8c03\u7528\u4e0a\u9762\u7684 safe_download \u51fd\u6570\u3002\u4f1a\u7528\u5728experimental.py\u4e2d\u7684attempt_load\u51fd\u6570\u548ctrain.py\u4e2d\uff0c\u90fd\u662f\u7528\u6765\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002\u4ee3\u7801\u8be6\u89e3\u5982\u4e0b\uff1a def attempt_download ( file , repo = \"Oneflow-Inc/one-yolov5\" ): # from utils.downloads import *; attempt_download() \"\"\"\u7528\u5728attempt_download\u51fd\u6570\u4e2d \u4e0b\u8f7d url/url2 \u8def\u5f84\u5bf9\u5e94\u7684\u7f51\u9875\u6587\u4ef6 Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes :params file: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d :params url: \u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740 \u4e00\u822c\u662fgithub :params url2: \u7b2c\u4e8c\u4e2a\u4e0b\u8f7d\u5730\u5740(\u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740\u4e0b\u8f7d\u5931\u8d25\u540e\u4f7f\u7528) \u4e00\u822c\u662fgoogleleaps\u7b49\u4e91\u670d\u52a1\u5668 :params min_bytes: \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765 \u53ea\u6709\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes\u624d\u80fd\u5224\u65ad\u6587\u4ef6\u5df2\u7ecf\u4e0b\u8f7d\u4e0b\u6765\u4e86 :params error_msg: \u6587\u4ef6\u4e0b\u8f7d\u5931\u8d25\u7684\u663e\u793a\u4fe1\u606f \u521d\u59cb\u5316\u9ed8\u8ba4\u2019\u2018 \"\"\" # Attempt file download if does not exist file = Path ( str ( file ) . strip () . replace ( \"'\" , \"\" )) if not file . exists (): # \u5c1d\u8bd5\u4eceurl\u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgithub # URL specified # urllib.parse: \u89e3\u6790url .unquote: \u5bf9url\u8fdb\u884c\u89e3\u7801 decode '%2F' to '/' etc. name = Path ( urllib . parse . unquote ( str ( file ))) . name # decode '%2F' to '/' etc. # \u5982\u679c\u89e3\u6790\u7684\u6587\u4ef6\u540d\u662fhttp:/ \u6216 https:/ \u5f00\u5934\u5c31\u76f4\u63a5\u4e0b\u8f7d if str ( file ) . startswith (( \"http:/\" , \"https:/\" )): # download # url: \u4e0b\u8f7d\u8def\u5f84 url url = str ( file ) . replace ( \":/\" , \"://\" ) # Pathlib turns :// -> :/ # name: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d file = name . split ( \"?\" )[ 0 ] # parse authentication https://url.com/file.txt?auth... if Path ( file ) . is_file (): print ( f \"Found { url } locally at { file } \" ) # file already exists else : safe_download ( file = file , url = url , min_bytes = 1e5 ) # \u4e0b\u8f7d\u6587\u4ef6 return file # GitHub assets file . parent . mkdir ( parents = True , exist_ok = True ) # make parent dir (if required) try : # \u5229\u7528github api \u83b7\u53d6\u6700\u65b0\u7684\u7248\u672c\u76f8\u5173\u4fe1\u606f \u8fd9\u91cc\u7684response\u662f\u4e00\u4e2a\u6253\u5b57\u5178 response = requests . get ( f \"https://api.github.com/repos/ { repo } /releases/latest\" ) . json () # github api assets = [ x [ \"name\" ] for x in response [ \"assets\" ]] # release assets, i.e. ['yolov5s', 'yolov5m', ...] tag = response [ \"tag_name\" ] # i.e. 'v1.0' except : # fallback plan \u83b7\u53d6\u5931\u8d25 \u5c31\u9000\u800c\u6c42\u5176\u6b21 \u76f4\u63a5\u5229\u7528git\u547d\u4ee4\u5f3a\u884c\u8865\u9f50\u7248\u672c\u4fe1\u606f assets = [ \"yolov5n.zip\" , \"yolov5s.zip\" , \"yolov5m.zip\" , \"yolov5l.zip\" , \"yolov5x.zip\" , \"yolov5n6.zip\" , \"yolov5s6.zip\" , \"yolov5m6.zip\" , \"yolov5l6.zip\" , \"yolov5x6.zip\" , ] try : # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u5728\u547d\u4ee4\u884c\u6267\u884c git tag \u547d\u4ee4(\u8fd4\u56de\u7248\u672c\u53f7 \u7248\u672c\u53f7\u4fe1\u606f\u4e00\u822c\u5728\u5b57\u5178\u6700\u540e -1) \u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u7248\u672c\u53f7tag) tag = subprocess . check_output ( \"git tag\" , shell = True , stderr = subprocess . STDOUT ) . decode () . split ()[ - 1 ] except : # \u5982\u679c\u8fd8\u662f\u5931\u8d25 \u5c31\u5f3a\u884c\u81ea\u5df1\u8865\u4e00\u4e2a\u7248\u672c\u53f7 tag='v5.0' tag = \"v1.0\" # current release if \".zip\" not in name : name = name + \".zip\" file = Path ( name ) if name in assets : safe_download ( file , url = f \"https://github.com/ { repo } /releases/download/ { tag } / { name } \" , # url2=f'https://storage.googleapis.com/{repo}/ckpt/{name}', # backup url (optional) min_bytes = 1e5 , error_msg = f \" { file } missing, try downloading from https://github.com/ { repo } /releases/\" , ) if \".zip\" in name : new_dir = Path ( name [: - 4 ]) else : new_dir = Path ( name ) if not os . path . exists ( new_dir ): # \u5224\u65ad\u6587\u4ef6\u5939\u662f\u5426\u5b58\u5728 os . mkdir ( new_dir ) # \u65b0\u5efa\u6587\u4ef6\u5939 if \".zip\" in name : print ( \"unzipping... \" , end = \"\" ) # ZipFile(new_file).extractall(path=file.parent) # unzip f = ZipFile ( file ) f . extractall ( new_dir ) os . remove ( file ) # remove zip tmp_dir = \"/tmp/oneyolov5\" if os . path . isdir ( tmp_dir ): shutil . rmtree ( tmp_dir ) if \".zip\" in name : path1 = os . path . join ( name [: - 4 ], name [: - 4 ]) else : path1 = os . path . join ( name , name ) shutil . copytree ( path1 , tmp_dir ) shutil . rmtree ( new_dir ) shutil . copytree ( tmp_dir , new_dir ) shutil . rmtree ( tmp_dir ) return str ( file ) attempt_download ( \"yolov5n\" ) Downloading https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/yolov5n.zip to yolov5n.zip... 0%| | 0.00/3.53M [00:00<?, ?B/s] unzipping... 'yolov5n.zip' 4. get_token & gdrive_download\uff08\u6ca1\u4f7f\u7528\uff09 \u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u5b9e\u73b0\u4ecegoogle drive\u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6\u3002\u4f46\u662f\u8fd9\u597d\u50cf\u5e76\u6ca1\u6709\u5728\u4ee3\u7801\u4e2d\u4f7f\u7528\uff0c\u6240\u4ee5\u8fd9\u4e24\u4e2a\u51fd\u6570\u53ef\u4ee5\u968f\u4fbf\u4e86\u89e3\u4e0b\u5c31\u597d\uff0c\u4e3b\u8981\u8fd8\u662f\u8981\u638c\u63e1\u4e0a\u9762\u7684\u4e24\u4e2a\u4e0b\u8f7d\u51fd\u6570\u7528\u7684\u6bd4\u8f83\u591a\u3002 4.1 get_token \u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4ececookie\u4e2d\u83b7\u53d6\u4ee4\u724ctoken\u3002\u4f1a\u5728gdrive_download\u4e2d\u88ab\u8c03\u7528\u3002 get_token\u51fd\u6570\u4ee3\u7801\uff1a def get_token ( cookie = \"./cookie\" ): \"\"\"\u5728gdrive_download\u4e2d\u4f7f\u7528 \u5b9e\u73b0\u4ececookie\u4e2d\u83b7\u53d6\u4ee4\u724ctoken \"\"\" with open ( cookie ) as f : for line in f : if \"download\" in line : return line . split ()[ - 1 ] return \"\" 4.2 gdrive_download \u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4ecegoogle drive\u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6\u3002\u8fd9\u4e2a\u51fd\u6570\u8c8c\u4f3c\u6ca1\u7528\u5230\uff0c\u968f\u4fbf\u770b\u4e0b\u5c31\u597d\u3002 gdrive_download\u51fd\u6570\u4ee3\u7801\uff1a def gdrive_download ( id = '16TiPfZj7htmTyhntwcZyEEAejOUxuT6m' , file = 'tmp.zip' ): \"\"\" \u5b9e\u73b0\u4ecegoogle drive\u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6 :params id: url ?\u540e\u9762\u7684id\u53c2\u6570\u7684\u53c2\u6570\u503c :params file: \u9700\u8981\u4e0b\u8f7d\u7684\u538b\u7f29\u6587\u4ef6\u540d \"\"\" t = time . time () # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 file = Path ( file ) # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 cookie = Path ( 'cookie' ) # gdrive cookie print ( f 'Downloading https://drive.google.com/uc?export=download&id= { id } as { file } ... ' , end = '' ) file . unlink ( missing_ok = True ) # \u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684\u6587\u4ef6(\u53ef\u80fd\u662f\u4e0b\u8f7d\u5931\u8d25/\u4e0b\u8f7d\u4e0d\u5b8c\u5168) cookie . unlink ( missing_ok = True ) # \u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684cookie # \u5c1d\u8bd5\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6 out = \"NUL\" if platform . system () == \"Windows\" else \"/dev/null\" # \u4f7f\u7528cmd\u547d\u4ee4\u4ecegoogle drive\u4e0a\u4e0b\u8f7d\u6587\u4ef6 os . system ( f 'curl -c ./cookie -s -L \"drive.google.com/uc?export=download&id= { id } \" > { out } ' ) if os . path . exists ( 'cookie' ): # \u5982\u679c\u6587\u4ef6\u8f83\u5927 \u5c31\u9700\u8981\u6709\u4ee4\u724cget_token(\u5b58\u5728cookie\u624d\u6709\u4ee4\u724c)\u7684\u6307\u4ee4s\u624d\u80fd\u4e0b\u8f7d # get_token()\u51fd\u6570\u5728\u4e0b\u9762\u5b9a\u4e49\u4e86 \u7528\u4e8e\u83b7\u53d6\u5f53\u524dcookie\u7684\u4ee4\u724ctoken s = f 'curl -Lb ./cookie \"drive.google.com/uc?export=download&confirm= { get_token () } &id= { id } \" -o { file } ' else : # \u5c0f\u6587\u4ef6\u5c31\u4e0d\u9700\u8981\u5e26\u4ee4\u724c\u7684\u6307\u4ee4s \u76f4\u63a5\u4e0b\u8f7d\u5c31\u884c s = f 'curl -s -L -o { file } \"drive.google.com/uc?export=download&id= { id } \"' # \u6267\u884c\u4e0b\u8f7d\u6307\u4ee4s \u5e76\u83b7\u5f97\u8fd4\u56de \u5982\u679ccmd\u547d\u4ee4\u6267\u884c\u6210\u529f \u5219os.system()\u547d\u4ee4\u4f1a\u8fd4\u56de0 r = os . system ( s ) cookie . unlink ( missing_ok = True ) # \u518d\u6b21\u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684cookie # \u4e0b\u8f7d\u9519\u8bef\u68c0\u6d4b \u5982\u679cr != 0 \u5219\u4e0b\u8f7d\u9519\u8bef if r != 0 : file . unlink ( missing_ok = True ) # \u4e0b\u8f7d\u9519\u8bef \u79fb\u9664\u4e0b\u8f7d\u7684\u6587\u4ef6(\u53ef\u80fd\u4e0d\u5b8c\u5168\u6216\u8005\u4e0b\u8f7d\u5931\u8d25) print ( 'Download error ' ) # raise Exception('Download error') return r # \u5982\u679c\u662f\u538b\u7f29\u6587\u4ef6 \u5c31\u89e3\u538b file.suffix\u65b9\u6cd5\u53ef\u4ee5\u83b7\u53d6file\u6587\u4ef6\u7684\u540e\u7f00 if file . suffix == '.zip' : print ( 'unzipping... ' , end = '' ) os . system ( f 'unzip -q { file } ' ) # cmd\u547d\u4ee4\u6267\u884c\u89e3\u538b\u547d\u4ee4 file . unlink () # \u79fb\u9664.zip\u538b\u7f29\u6587\u4ef6 print ( f 'Done ( { time . time () - t : .1f } s)' ) # \u6253\u5370\u4e0b\u8f7d + \u89e3\u538b\u8fc7\u7a0b\u6240\u9700\u8981\u7684\u65f6\u95f4 return r \u603b\u7ed3 \u8fd9\u4e2a\u6587\u4ef6\u7684\u4ee3\u7801\u6bd4\u8f83\u5c11\uff0c\u771f\u6b63\u6709\u7528\u7684\u51fd\u6570\u4e5f\u6bd4\u8f83\u5c11\uff0c \u4e5f\u5c31\u662fsafe_download\u548cattempt_download\u4e24\u4e2a\u51fd\u6570\u6bd4\u8f83\u91cd\u8981\uff0c\u5927\u5bb6\u91cd\u70b9\u638c\u63e1\u8fd9\u4e24\u4e2a\u51fd\u6570\u5373\u53ef\u3002 Reference \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011google_utils.py","title":"downloads_py"},{"location":"source_code_interpretation/utils/downloads_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/augmentations.py \u8fd9\u4e2a\u6587\u4ef6\u4e3b\u8981\u662f\u8d1f\u8d23\u4ecegithub/googleleaps/google drive \u7b49\u7f51\u7ad9\u6216\u8005 \u4e91\u670d\u52a1\u5668 \u4e0a\u4e0b\u8f7d\u6240\u9700\u7684\u4e00\u4e9b\u6587\u4ef6\u3002 \u662f\u4e00\u4e2a\u5de5\u5177\u7c7b\uff0c\u4ee3\u7801\u6bd4\u8f83\u7b80\u5355\uff0c\u51fd\u6570\u4e5f\u6bd4\u8f83\u5c11\uff0c\u4e3b\u8981\u96be\u70b9\u8fd8\u662f\u5728\u4e8e\u4e00\u4e9b\u5305\u53ef\u80fd\u5927\u5bb6\u4e0d\u662f\u5f88\u719f\u6089\uff0c\u4e0b\u9762\u4e00\u8d77\u6765\u5b66\u4e60\u4e0b\u3002 \u8fd9\u4e2a\u6587\u4ef6\u6bd4\u8f83\u91cd\u8981\u7684\u662f\u4e24\u4e2a\u51fd\u6570\uff1asafe_download\u548cattempt_download\u3002\u5728train.py\u6216\u8005yolo.py\u7b49\u6587\u4ef6\u4e2d\u90fd\u4f1a\u7528\u5230\u3002","title":"\u524d\u8a00"},{"location":"source_code_interpretation/utils/downloads_py.html#1","text":"\"\"\" Download utils \"\"\" import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 import platform # \u63d0\u4f9b\u83b7\u53d6\u64cd\u4f5c\u7cfb\u7edf\u76f8\u5173\u4fe1\u606f\u7684\u6a21\u5757 import shutil import subprocess # \u5b50\u8fdb\u7a0b\u5b9a\u4e49\u53ca\u64cd\u4f5c\u7684\u6a21\u5757 import time import urllib # \u7528\u4e8e\u64cd\u4f5c\u7f51\u9875 URL\uff0c\u5e76\u5bf9\u7f51\u9875\u7684\u5185\u5bb9\u8fdb\u884c\u6293\u53d6\u5904\u7406 \u5982urllib.parse: \u89e3\u6790url from pathlib import Path from zipfile import ZipFile import oneflow as flow import requests # \u901a\u8fc7urllib3\u5b9e\u73b0\u81ea\u52a8\u53d1\u9001HTTP/1.1\u8bf7\u6c42\u7684\u7b2c\u4e09\u65b9\u6a21\u5757","title":"1. \u5bfc\u5165\u9700\u8981\u7684\u5305"},{"location":"source_code_interpretation/utils/downloads_py.html#2-gsutil_getsize","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5url\u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f\u3002 def gsutil_getsize ( url = \"\" ): \"\"\"\u7528\u5728downloads.py\u7684print_mutation\u51fd\u6570\u5f53\u4e2d \u8ba1\u7b97\u67d0\u4e2aurl\u5bf9\u5e94\u7684\u6587\u4ef6\u5927\u5c0f \u7528\u4e8e\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5url\u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du \"\"\" # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u5728\u547d\u4ee4\u884c\u6267\u884c gsutil du url \u547d\u4ee4(\u8bbf\u95ee Cloud Storage) \u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u6587\u4ef6) # gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du s = subprocess . check_output ( f \"gsutil du { url } \" , shell = True ) . decode ( \"utf-8\" ) return eval ( s . split ( \" \" )[ 0 ]) if len ( s ) else 0 # bytes","title":"2. gsutil_getsize"},{"location":"source_code_interpretation/utils/downloads_py.html#3-safe_downloadattempt_download","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u4e3b\u8981\u662f\u7528\u6765\u4ecegithub\u6216\u8005googleleaps\u4e91\u670d\u52a1\u5668\u4e2d\u4e0b\u8f7d\u6587\u4ef6\u7684\uff0c\u4e3b\u8981\u662f\u4e0b\u8f7d\u6743\u91cd\u6587\u4ef6\u3002 attempt_download\u51fd\u6570\u8c03\u7528safe_download\u51fd\u6570\u3002","title":"3. safe_download\u3001attempt_download"},{"location":"source_code_interpretation/utils/downloads_py.html#31-safe_download","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u4e0b\u8f7d url\uff08github\uff09 \u6216\u8005 url2\uff08\u8c37\u6b4c\u4e91\u670d\u52a1\u5668\uff09 \u8def\u5f84\u5bf9\u5e94\u7684\u7f51\u9875\u6587\u4ef6\uff0c \u901a\u5e38\u662f\u4e0b\u8f7d\u6743\u91cd\u6587\u4ef6\uff0c\u4f1a\u7528\u5728attempt_download\u51fd\u6570\u4e2d\u5982\uff1a def safe_download ( file , url , url2 = None , min_bytes = 1e0 , error_msg = \"\" ): \"\"\"\u7528\u5728attempt_download\u51fd\u6570\u4e2d \u4e0b\u8f7d url/url2 \u8def\u5f84\u5bf9\u5e94\u7684\u7f51\u9875\u6587\u4ef6 Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes @params file: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d @params url: \u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740 \u4e00\u822c\u662fgithub @params url2: \u7b2c\u4e8c\u4e2a\u4e0b\u8f7d\u5730\u5740(\u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740\u4e0b\u8f7d\u5931\u8d25\u540e\u4f7f\u7528) \u4e00\u822c\u662fgoogleleaps\u7b49\u4e91\u670d\u52a1\u5668 @params min_bytes: \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765 \u53ea\u6709\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes\u624d\u80fd\u5224\u65ad\u6587\u4ef6\u5df2\u7ecf\u4e0b\u8f7d\u4e0b\u6765\u4e86 @params error_msg: \u6587\u4ef6\u4e0b\u8f7d\u5931\u8d25\u7684\u663e\u793a\u4fe1\u606f \u521d\u59cb\u5316\u9ed8\u8ba4\u4e3a\u7a7a \"\"\" # Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes file = Path ( file ) assert_msg = f \"Downloaded file ' { file } ' does not exist or size is < min_bytes= { min_bytes } \" try : # url1 y: \u5c1d\u8bd5\u4eceurl\u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgithub print ( f \"Downloading { url } to { file } ...\" ) // \u4f7f\u7528 oneflow . hub . download_url_to_file \u4e0b\u8f7d url \u94fe\u63a5\u5bf9\u5e94\u7684\u6587\u4ef6 \uff0c // \u5173\u4e8eoneflow . hub\u6a21\u5757\u8bb2\u89e3\u53ef\u4ee5\u770b \uff1a https : // www . bilibili . com / video / BV1YG4y1B72u / ? spm_id_from = 333.999.0.0 flow . hub . download_url_to_file ( url , str ( file )) # \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765\u4e86(\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes) assert file . exists () and file . stat () . st_size > min_bytes , assert_msg # check except Exception as e : # url2 \u4e0d\u884c\u5c31\u5c1d\u8bd5\u4eceurl2\u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgoogleleaps(\u4e91\u670d\u52a1\u5668) # \u79fb\u9664\u4e4b\u524d\u4e0b\u8f7d\u5931\u8d25\u7684\u6587\u4ef6 file . unlink ( missing_ok = True ) # remove partial downloads print ( f \"ERROR: { e } \\n Re-attempting { url2 or url } to { file } ...\" ) os . system ( f \"curl -L ' { url2 or url } ' -o ' { file } ' --retry 3 -C -\" ) # curl download, retry and resume on fail finally : # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765\u4e86(\u662f\u5426\u5b58\u5728) \u6216 \u6587\u4ef6\u5927\u5c0f\u662f\u5426\u5c0f\u4e8emin_bytes if not file . exists () or file . stat () . st_size < min_bytes : # check # \u4e0b\u8f7d\u5931\u8d25 \u79fb\u9664\u4e0b\u8f7d\u5931\u8d25\u7684\u6587\u4ef6 remove partial downloads file . unlink ( missing_ok = True ) # remove partial downloads # \u6253\u5370\u9519\u8bef\u4fe1\u606f print ( f \"ERROR: { assert_msg } \\n { error_msg } \" ) print ( \"\" ) url = \"https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/model_comparison.png\" safe_download ( \"op.png\" , url ) Downloading https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/model_comparison.png to op.png... 0%| | 0.00/118k [00:00<?, ?B/s] from PIL import Image display ( Image . open ( \"op.png\" )) # \u663e\u793a\u4e0b\u8f7d\u7684\u56fe\u7247","title":"3.1 safe_download"},{"location":"source_code_interpretation/utils/downloads_py.html#32-attempt_download","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5b9e\u73b0\u4ece\u51e0\u4e2a\u4e91\u5e73\u53f0(github/googleleaps\u4e91\u670d\u52a1\u5668)\u4e0b\u8f7d\u6587\u4ef6(\u9884\u8bad\u7ec3\u6a21\u578b)\uff0c \u4f1a\u8c03\u7528\u4e0a\u9762\u7684 safe_download \u51fd\u6570\u3002\u4f1a\u7528\u5728experimental.py\u4e2d\u7684attempt_load\u51fd\u6570\u548ctrain.py\u4e2d\uff0c\u90fd\u662f\u7528\u6765\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002\u4ee3\u7801\u8be6\u89e3\u5982\u4e0b\uff1a def attempt_download ( file , repo = \"Oneflow-Inc/one-yolov5\" ): # from utils.downloads import *; attempt_download() \"\"\"\u7528\u5728attempt_download\u51fd\u6570\u4e2d \u4e0b\u8f7d url/url2 \u8def\u5f84\u5bf9\u5e94\u7684\u7f51\u9875\u6587\u4ef6 Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes :params file: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d :params url: \u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740 \u4e00\u822c\u662fgithub :params url2: \u7b2c\u4e8c\u4e2a\u4e0b\u8f7d\u5730\u5740(\u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740\u4e0b\u8f7d\u5931\u8d25\u540e\u4f7f\u7528) \u4e00\u822c\u662fgoogleleaps\u7b49\u4e91\u670d\u52a1\u5668 :params min_bytes: \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765 \u53ea\u6709\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes\u624d\u80fd\u5224\u65ad\u6587\u4ef6\u5df2\u7ecf\u4e0b\u8f7d\u4e0b\u6765\u4e86 :params error_msg: \u6587\u4ef6\u4e0b\u8f7d\u5931\u8d25\u7684\u663e\u793a\u4fe1\u606f \u521d\u59cb\u5316\u9ed8\u8ba4\u2019\u2018 \"\"\" # Attempt file download if does not exist file = Path ( str ( file ) . strip () . replace ( \"'\" , \"\" )) if not file . exists (): # \u5c1d\u8bd5\u4eceurl\u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgithub # URL specified # urllib.parse: \u89e3\u6790url .unquote: \u5bf9url\u8fdb\u884c\u89e3\u7801 decode '%2F' to '/' etc. name = Path ( urllib . parse . unquote ( str ( file ))) . name # decode '%2F' to '/' etc. # \u5982\u679c\u89e3\u6790\u7684\u6587\u4ef6\u540d\u662fhttp:/ \u6216 https:/ \u5f00\u5934\u5c31\u76f4\u63a5\u4e0b\u8f7d if str ( file ) . startswith (( \"http:/\" , \"https:/\" )): # download # url: \u4e0b\u8f7d\u8def\u5f84 url url = str ( file ) . replace ( \":/\" , \"://\" ) # Pathlib turns :// -> :/ # name: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d file = name . split ( \"?\" )[ 0 ] # parse authentication https://url.com/file.txt?auth... if Path ( file ) . is_file (): print ( f \"Found { url } locally at { file } \" ) # file already exists else : safe_download ( file = file , url = url , min_bytes = 1e5 ) # \u4e0b\u8f7d\u6587\u4ef6 return file # GitHub assets file . parent . mkdir ( parents = True , exist_ok = True ) # make parent dir (if required) try : # \u5229\u7528github api \u83b7\u53d6\u6700\u65b0\u7684\u7248\u672c\u76f8\u5173\u4fe1\u606f \u8fd9\u91cc\u7684response\u662f\u4e00\u4e2a\u6253\u5b57\u5178 response = requests . get ( f \"https://api.github.com/repos/ { repo } /releases/latest\" ) . json () # github api assets = [ x [ \"name\" ] for x in response [ \"assets\" ]] # release assets, i.e. ['yolov5s', 'yolov5m', ...] tag = response [ \"tag_name\" ] # i.e. 'v1.0' except : # fallback plan \u83b7\u53d6\u5931\u8d25 \u5c31\u9000\u800c\u6c42\u5176\u6b21 \u76f4\u63a5\u5229\u7528git\u547d\u4ee4\u5f3a\u884c\u8865\u9f50\u7248\u672c\u4fe1\u606f assets = [ \"yolov5n.zip\" , \"yolov5s.zip\" , \"yolov5m.zip\" , \"yolov5l.zip\" , \"yolov5x.zip\" , \"yolov5n6.zip\" , \"yolov5s6.zip\" , \"yolov5m6.zip\" , \"yolov5l6.zip\" , \"yolov5x6.zip\" , ] try : # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u5728\u547d\u4ee4\u884c\u6267\u884c git tag \u547d\u4ee4(\u8fd4\u56de\u7248\u672c\u53f7 \u7248\u672c\u53f7\u4fe1\u606f\u4e00\u822c\u5728\u5b57\u5178\u6700\u540e -1) \u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u7248\u672c\u53f7tag) tag = subprocess . check_output ( \"git tag\" , shell = True , stderr = subprocess . STDOUT ) . decode () . split ()[ - 1 ] except : # \u5982\u679c\u8fd8\u662f\u5931\u8d25 \u5c31\u5f3a\u884c\u81ea\u5df1\u8865\u4e00\u4e2a\u7248\u672c\u53f7 tag='v5.0' tag = \"v1.0\" # current release if \".zip\" not in name : name = name + \".zip\" file = Path ( name ) if name in assets : safe_download ( file , url = f \"https://github.com/ { repo } /releases/download/ { tag } / { name } \" , # url2=f'https://storage.googleapis.com/{repo}/ckpt/{name}', # backup url (optional) min_bytes = 1e5 , error_msg = f \" { file } missing, try downloading from https://github.com/ { repo } /releases/\" , ) if \".zip\" in name : new_dir = Path ( name [: - 4 ]) else : new_dir = Path ( name ) if not os . path . exists ( new_dir ): # \u5224\u65ad\u6587\u4ef6\u5939\u662f\u5426\u5b58\u5728 os . mkdir ( new_dir ) # \u65b0\u5efa\u6587\u4ef6\u5939 if \".zip\" in name : print ( \"unzipping... \" , end = \"\" ) # ZipFile(new_file).extractall(path=file.parent) # unzip f = ZipFile ( file ) f . extractall ( new_dir ) os . remove ( file ) # remove zip tmp_dir = \"/tmp/oneyolov5\" if os . path . isdir ( tmp_dir ): shutil . rmtree ( tmp_dir ) if \".zip\" in name : path1 = os . path . join ( name [: - 4 ], name [: - 4 ]) else : path1 = os . path . join ( name , name ) shutil . copytree ( path1 , tmp_dir ) shutil . rmtree ( new_dir ) shutil . copytree ( tmp_dir , new_dir ) shutil . rmtree ( tmp_dir ) return str ( file ) attempt_download ( \"yolov5n\" ) Downloading https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/yolov5n.zip to yolov5n.zip... 0%| | 0.00/3.53M [00:00<?, ?B/s] unzipping... 'yolov5n.zip'","title":"3.2 attempt_download"},{"location":"source_code_interpretation/utils/downloads_py.html#4-get_token-gdrive_download","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u5b9e\u73b0\u4ecegoogle drive\u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6\u3002\u4f46\u662f\u8fd9\u597d\u50cf\u5e76\u6ca1\u6709\u5728\u4ee3\u7801\u4e2d\u4f7f\u7528\uff0c\u6240\u4ee5\u8fd9\u4e24\u4e2a\u51fd\u6570\u53ef\u4ee5\u968f\u4fbf\u4e86\u89e3\u4e0b\u5c31\u597d\uff0c\u4e3b\u8981\u8fd8\u662f\u8981\u638c\u63e1\u4e0a\u9762\u7684\u4e24\u4e2a\u4e0b\u8f7d\u51fd\u6570\u7528\u7684\u6bd4\u8f83\u591a\u3002","title":"4. get_token &amp; gdrive_download\uff08\u6ca1\u4f7f\u7528\uff09"},{"location":"source_code_interpretation/utils/downloads_py.html#41-get_token","text":"\u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4ececookie\u4e2d\u83b7\u53d6\u4ee4\u724ctoken\u3002\u4f1a\u5728gdrive_download\u4e2d\u88ab\u8c03\u7528\u3002 get_token\u51fd\u6570\u4ee3\u7801\uff1a def get_token ( cookie = \"./cookie\" ): \"\"\"\u5728gdrive_download\u4e2d\u4f7f\u7528 \u5b9e\u73b0\u4ececookie\u4e2d\u83b7\u53d6\u4ee4\u724ctoken \"\"\" with open ( cookie ) as f : for line in f : if \"download\" in line : return line . split ()[ - 1 ] return \"\"","title":"4.1 get_token"},{"location":"source_code_interpretation/utils/downloads_py.html#42-gdrive_download","text":"\u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4ecegoogle drive\u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6\u3002\u8fd9\u4e2a\u51fd\u6570\u8c8c\u4f3c\u6ca1\u7528\u5230\uff0c\u968f\u4fbf\u770b\u4e0b\u5c31\u597d\u3002 gdrive_download\u51fd\u6570\u4ee3\u7801\uff1a def gdrive_download ( id = '16TiPfZj7htmTyhntwcZyEEAejOUxuT6m' , file = 'tmp.zip' ): \"\"\" \u5b9e\u73b0\u4ecegoogle drive\u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6 :params id: url ?\u540e\u9762\u7684id\u53c2\u6570\u7684\u53c2\u6570\u503c :params file: \u9700\u8981\u4e0b\u8f7d\u7684\u538b\u7f29\u6587\u4ef6\u540d \"\"\" t = time . time () # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 file = Path ( file ) # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 cookie = Path ( 'cookie' ) # gdrive cookie print ( f 'Downloading https://drive.google.com/uc?export=download&id= { id } as { file } ... ' , end = '' ) file . unlink ( missing_ok = True ) # \u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684\u6587\u4ef6(\u53ef\u80fd\u662f\u4e0b\u8f7d\u5931\u8d25/\u4e0b\u8f7d\u4e0d\u5b8c\u5168) cookie . unlink ( missing_ok = True ) # \u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684cookie # \u5c1d\u8bd5\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6 out = \"NUL\" if platform . system () == \"Windows\" else \"/dev/null\" # \u4f7f\u7528cmd\u547d\u4ee4\u4ecegoogle drive\u4e0a\u4e0b\u8f7d\u6587\u4ef6 os . system ( f 'curl -c ./cookie -s -L \"drive.google.com/uc?export=download&id= { id } \" > { out } ' ) if os . path . exists ( 'cookie' ): # \u5982\u679c\u6587\u4ef6\u8f83\u5927 \u5c31\u9700\u8981\u6709\u4ee4\u724cget_token(\u5b58\u5728cookie\u624d\u6709\u4ee4\u724c)\u7684\u6307\u4ee4s\u624d\u80fd\u4e0b\u8f7d # get_token()\u51fd\u6570\u5728\u4e0b\u9762\u5b9a\u4e49\u4e86 \u7528\u4e8e\u83b7\u53d6\u5f53\u524dcookie\u7684\u4ee4\u724ctoken s = f 'curl -Lb ./cookie \"drive.google.com/uc?export=download&confirm= { get_token () } &id= { id } \" -o { file } ' else : # \u5c0f\u6587\u4ef6\u5c31\u4e0d\u9700\u8981\u5e26\u4ee4\u724c\u7684\u6307\u4ee4s \u76f4\u63a5\u4e0b\u8f7d\u5c31\u884c s = f 'curl -s -L -o { file } \"drive.google.com/uc?export=download&id= { id } \"' # \u6267\u884c\u4e0b\u8f7d\u6307\u4ee4s \u5e76\u83b7\u5f97\u8fd4\u56de \u5982\u679ccmd\u547d\u4ee4\u6267\u884c\u6210\u529f \u5219os.system()\u547d\u4ee4\u4f1a\u8fd4\u56de0 r = os . system ( s ) cookie . unlink ( missing_ok = True ) # \u518d\u6b21\u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684cookie # \u4e0b\u8f7d\u9519\u8bef\u68c0\u6d4b \u5982\u679cr != 0 \u5219\u4e0b\u8f7d\u9519\u8bef if r != 0 : file . unlink ( missing_ok = True ) # \u4e0b\u8f7d\u9519\u8bef \u79fb\u9664\u4e0b\u8f7d\u7684\u6587\u4ef6(\u53ef\u80fd\u4e0d\u5b8c\u5168\u6216\u8005\u4e0b\u8f7d\u5931\u8d25) print ( 'Download error ' ) # raise Exception('Download error') return r # \u5982\u679c\u662f\u538b\u7f29\u6587\u4ef6 \u5c31\u89e3\u538b file.suffix\u65b9\u6cd5\u53ef\u4ee5\u83b7\u53d6file\u6587\u4ef6\u7684\u540e\u7f00 if file . suffix == '.zip' : print ( 'unzipping... ' , end = '' ) os . system ( f 'unzip -q { file } ' ) # cmd\u547d\u4ee4\u6267\u884c\u89e3\u538b\u547d\u4ee4 file . unlink () # \u79fb\u9664.zip\u538b\u7f29\u6587\u4ef6 print ( f 'Done ( { time . time () - t : .1f } s)' ) # \u6253\u5370\u4e0b\u8f7d + \u89e3\u538b\u8fc7\u7a0b\u6240\u9700\u8981\u7684\u65f6\u95f4 return r","title":"4.2 gdrive_download"},{"location":"source_code_interpretation/utils/downloads_py.html#_2","text":"\u8fd9\u4e2a\u6587\u4ef6\u7684\u4ee3\u7801\u6bd4\u8f83\u5c11\uff0c\u771f\u6b63\u6709\u7528\u7684\u51fd\u6570\u4e5f\u6bd4\u8f83\u5c11\uff0c \u4e5f\u5c31\u662fsafe_download\u548cattempt_download\u4e24\u4e2a\u51fd\u6570\u6bd4\u8f83\u91cd\u8981\uff0c\u5927\u5bb6\u91cd\u70b9\u638c\u63e1\u8fd9\u4e24\u4e2a\u51fd\u6570\u5373\u53ef\u3002","title":"\u603b\u7ed3"},{"location":"source_code_interpretation/utils/downloads_py.html#reference","text":"\u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011google_utils.py","title":"Reference"},{"location":"thesis_interpretation/00_yolo_history.html","text":"\ud83c\udfc6\u4e00\u77a5\u4fbf\u662f\u60ca\u9e3f\uff0c\u82b3\u534e\u4e71\u4e86\u6d6e\u751f~ \u7531\u4e8e\u5176\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c \\(YOLO\\) \u6210\u4e3a\u4e16\u754c\u8457\u540d\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e4b\u4e00\u3002 YOLOv1\ud83c\udf89 \\(YOLO\\) \u662f \"You only look once\" \u7684\u7f29\u5199 , \u662f\u5c06\u56fe\u50cf\u5212\u5206\u4e3a\u7f51\u683c\u7cfb\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u3002( \ud83e\udd14\ufe0f\u7f51\u683c\u4e2d\u7684\u6bcf\u4e2a\u5355\u5143\u8d1f\u8d23\u68c0\u6d4b\u81ea\u8eab\u5185\u7684\u76ee\u6807 )\u3002 \u5b98\u65b9\u8bba\u6587: You Only Look Once: Unified, Real-Time Object Detection Author: Joseph Redmon YOLOv2\ud83c\udf1f \\(YOLOv2\\) \u662f \\(YOLO\\) \u7684\u539f\u4f5c\u8005Joseph Redmon \u548c Ali Farhadi \u7684\u5171\u540c\u4f5c\u54c1\u3002 \u4ed6\u4eec\u4e00\u8d77\u53d1\u8868\u4e86\uff1a YOLO9000:Better, Faster, Stronger Author: Joseph Redmon and Ali Farhadi Released: 25 Dec 2016 YOLOv3\ud83c\udf1f \\(YOLOv3\\) \u662f \\(YOLOv2\\) \u6539\u826f\u7248 \uff0c\u51fa\u81ea \\(YOLOv2\\) \u7684\u539f\u4f5c\u8005 (Joseph Redmon \u548c Ali Farhadi) , \u4e00\u8d77\u505a\u51fa\u6765\u8d21\u732e\u3002 \u4ed6\u4eec\u5171\u540c\u53d1\u8868\u4e86 YOLOv3: An Incremental Improvement \u6700\u521d\u7684\u7ea6\u6d1b\u8bba\u6587\u662f\u7531\u8c01\u63d0\u4f9b\u7684 here Author: Joseph Redmon and Ali Farhadi Released: 8 Apr 2018 YOLOv4\ud83c\udf70 \u968f\u7740\u539f\u4f5c\u8005 \\(YOLO\\) \u7684\u5de5\u4f5c\u9677\u5165\u50f5\u5c40, \\(YOLOv4\\) \u53d1\u8868\u7531 Alexey Bochoknovskiy, Chien-Yao Wang, \u548c Hong-Yuan Mark Liao. \u8bba\u6587\u540d\u4e3a YOLOv4: Optimal Speed and Accuracy of Object Detection YOLOV5 \ud83d\ude80 \\(YOLOv4\\) \u53d1\u5e03\u540e\u4e0d\u4e45\uff0cGlenn Jocher\u4f7f\u7528Pytorch\u6846\u67b6\u5f15\u5165\u4e86 \\(YOLOv5\\) \u6ca1\u6709\u53d1\u5e03\u8bba\u6587\u3002 \u4ee3\u7801\u94fe\u63a5: https://github.com/ultralytics/yolov5 YOLOv6\u26a1 \\(YOLOv6\\) \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u9762\u5411\u5404\u79cd\u5de5\u4e1a\u5e94\u7528\u573a\u666f\u7684\u6a21\u578b\uff0c\u5305\u62ec\u5fae\u5c0f\u7ea7(nano)\uff0c\u6781\u5c0f\u6781(tiny)\u3001\u5c0f(small)\uff0c\u4e2d(medium)\uff0c\u5927\u6a21\u578b(large)\u3002 \u5b98\u65b9\u8bba\u6587: YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications \u4ee3\u7801\u94fe\u63a5\uff1a https://github.com/meituan/YOLOv6 YOLOv7\ud83d\udc4d \u5b98\u65b9\u8bba\u6587: YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors \u4ee3\u7801\u94fe\u63a5\uff1a https://github.com/WongKinYiu/yolov7 \u5feb\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"history"},{"location":"thesis_interpretation/00_yolo_history.html#yolov1","text":"\\(YOLO\\) \u662f \"You only look once\" \u7684\u7f29\u5199 , \u662f\u5c06\u56fe\u50cf\u5212\u5206\u4e3a\u7f51\u683c\u7cfb\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u3002( \ud83e\udd14\ufe0f\u7f51\u683c\u4e2d\u7684\u6bcf\u4e2a\u5355\u5143\u8d1f\u8d23\u68c0\u6d4b\u81ea\u8eab\u5185\u7684\u76ee\u6807 )\u3002 \u5b98\u65b9\u8bba\u6587: You Only Look Once: Unified, Real-Time Object Detection Author: Joseph Redmon","title":"YOLOv1\ud83c\udf89"},{"location":"thesis_interpretation/00_yolo_history.html#yolov2","text":"\\(YOLOv2\\) \u662f \\(YOLO\\) \u7684\u539f\u4f5c\u8005Joseph Redmon \u548c Ali Farhadi \u7684\u5171\u540c\u4f5c\u54c1\u3002 \u4ed6\u4eec\u4e00\u8d77\u53d1\u8868\u4e86\uff1a YOLO9000:Better, Faster, Stronger Author: Joseph Redmon and Ali Farhadi Released: 25 Dec 2016","title":"YOLOv2\ud83c\udf1f"},{"location":"thesis_interpretation/00_yolo_history.html#yolov3","text":"\\(YOLOv3\\) \u662f \\(YOLOv2\\) \u6539\u826f\u7248 \uff0c\u51fa\u81ea \\(YOLOv2\\) \u7684\u539f\u4f5c\u8005 (Joseph Redmon \u548c Ali Farhadi) , \u4e00\u8d77\u505a\u51fa\u6765\u8d21\u732e\u3002 \u4ed6\u4eec\u5171\u540c\u53d1\u8868\u4e86 YOLOv3: An Incremental Improvement \u6700\u521d\u7684\u7ea6\u6d1b\u8bba\u6587\u662f\u7531\u8c01\u63d0\u4f9b\u7684 here Author: Joseph Redmon and Ali Farhadi Released: 8 Apr 2018","title":"YOLOv3\ud83c\udf1f"},{"location":"thesis_interpretation/00_yolo_history.html#yolov4","text":"\u968f\u7740\u539f\u4f5c\u8005 \\(YOLO\\) \u7684\u5de5\u4f5c\u9677\u5165\u50f5\u5c40, \\(YOLOv4\\) \u53d1\u8868\u7531 Alexey Bochoknovskiy, Chien-Yao Wang, \u548c Hong-Yuan Mark Liao. \u8bba\u6587\u540d\u4e3a YOLOv4: Optimal Speed and Accuracy of Object Detection","title":"YOLOv4\ud83c\udf70"},{"location":"thesis_interpretation/00_yolo_history.html#yolov5","text":"\\(YOLOv4\\) \u53d1\u5e03\u540e\u4e0d\u4e45\uff0cGlenn Jocher\u4f7f\u7528Pytorch\u6846\u67b6\u5f15\u5165\u4e86 \\(YOLOv5\\) \u6ca1\u6709\u53d1\u5e03\u8bba\u6587\u3002 \u4ee3\u7801\u94fe\u63a5: https://github.com/ultralytics/yolov5","title":"YOLOV5 \ud83d\ude80"},{"location":"thesis_interpretation/00_yolo_history.html#yolov6","text":"\\(YOLOv6\\) \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u9762\u5411\u5404\u79cd\u5de5\u4e1a\u5e94\u7528\u573a\u666f\u7684\u6a21\u578b\uff0c\u5305\u62ec\u5fae\u5c0f\u7ea7(nano)\uff0c\u6781\u5c0f\u6781(tiny)\u3001\u5c0f(small)\uff0c\u4e2d(medium)\uff0c\u5927\u6a21\u578b(large)\u3002 \u5b98\u65b9\u8bba\u6587: YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications \u4ee3\u7801\u94fe\u63a5\uff1a https://github.com/meituan/YOLOv6","title":"YOLOv6\u26a1"},{"location":"thesis_interpretation/00_yolo_history.html#yolov7","text":"\u5b98\u65b9\u8bba\u6587: YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors \u4ee3\u7801\u94fe\u63a5\uff1a https://github.com/WongKinYiu/yolov7 \u5feb\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"YOLOv7\ud83d\udc4d"},{"location":"thesis_interpretation/01_yolo.html","text":"\u539f\u6587\u5730\u5740: https://arxiv.org/pdf/1506.02640.pdf \u6458\u8981 \u2003\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5 \\(YOLO\\) \u3002\u4ee5\u524d\u7684\u76ee\u6807\u68c0\u6d4b\u5de5\u4f5c\u91cd\u65b0\u5229\u7528\u5206\u7c7b\u5668\u6765\u6267\u884c\u68c0\u6d4b\u3002\u76f8\u53cd\uff0c\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u6846\u67b6\u770b\u4f5c\u4ece\u7a7a\u95f4\u5206\u79bb\u7684\u8fb9\u754c\u6846\u548c\u76f8\u5173\u7c7b\u522b\u6982\u7387\u7684\u56de\u5f52\u95ee\u9898\u3002\u5728\u4e00\u6b21\u8bc4\u4f30\u4e2d\uff0c\u4e00\u4e2a\u5355\u4e00\u7684\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u4ece\u5b8c\u6574\u7684\u56fe\u50cf\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u3002\u7531\u4e8e\u6574\u4e2a\u68c0\u6d4b\u7ba1\u9053\u662f\u4e00\u4e2a\u5355\u4e00\u7684\u7f51\u7edc\uff0c\u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u5bf9\u68c0\u6d4b\u6027\u80fd\u8fdb\u884c\u7aef\u5230\u7aef( \u8bd1\u8005\u6ce8\uff1a\u7aef\u5bf9\u7aef\u6307\u7684\u662f\u8f93\u5165\u539f\u59cb\u6570\u636e\uff0c\u8f93\u51fa\u7684\u662f\u6700\u540e\u7ed3\u679c\uff0c\u5e94\u7528\u5728\u7279\u5f81\u5b66\u4e60\u878d\u5165\u7b97\u6cd5\uff0c\u65e0\u9700\u5355\u72ec\u5904\u7406 )\u4f18\u5316\u3002 \u2003 \u6211\u4eec\u7684\u7edf\u4e00\u67b6\u6784\u975e\u5e38\u5feb\u3002\u6211\u4eec\u7684\u57fa\u672c \\(YOLO\\) \u6a21\u578b\u4ee5\u6bcf\u79d245\u5e27\u7684\u901f\u5ea6\u5b9e\u65f6\u5904\u7406\u56fe\u50cf\u3002\u8be5\u7f51\u7edc\u7684\u4e00\u4e2a\u5c0f\u7248\u672c\uff1a \\(Fast \\ YOLO\\) \u662f \\(YOLO\\) \u7684\u4e00\u4e2a\u8f83\u5c0f\u7248\u672c\uff0c\u6bcf\u79d2\u80fd\u8fbe\u5230\u5904\u7406\u60ca\u4eba\u7684155\u5e27\u56fe\u50cf\uff0c\u540c\u65f6\u4ecd\u7136\u8fbe\u5230\u5176\u4ed6\u5b9e\u65f6\u63a2\u6d4b\u5668\u7684\u4e24\u500d \\(mAP\\) \u3002\u4e0e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\uff0c \\(YOLO\\) YOLO\u867d\u7136\u5b58\u5728\u8f83\u591a\u7684\u5b9a\u4f4d\u9519\u8bef\uff0c\u4f46\u5f88\u5c11\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u5047\u9633\u6027( \u8bd1\u8005\u6ce8\uff1a\u5176\u5b83\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u76ee\u6807\u7684\u6982\u7387\u8f83\u5927 )\u3002\u6700\u540e\uff0c \\(YOLO\\) \u80fd\u5b66\u4e60\u5230\u76ee\u6807\u7684\u975e\u5e38\u901a\u7528\u3002\u65e0\u8bba\u4ece\u81ea\u7136\u56fe\u50cf\u5230\u827a\u672f\u54c1\u7b49\u5176\u4ed6\u9886\u57df\u6cdb\u5316\u65f6\uff0c\u5b83\u90fd\u4f18\u4e8e\u5176\u4ed6\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6bd4\u5982 \\(DPM\\) \u548c \\(R-CNN\\) \u3002 1.\u4ecb\u7ecd \u2003\u4eba\u7c7b\u77a5\u4e00\u773c\u56fe\u50cf\uff0c\u5c31\u4f1a\u7acb\u5373\u77e5\u9053\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\u662f\u4ec0\u4e48\uff0c\u5b83\u4eec\u5728\u54ea\u91cc\uff0c\u4ee5\u53ca\u5b83\u4eec\u662f\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u7684\u3002\u4eba\u7c7b\u7684\u89c6\u89c9\u7cfb\u7edf\u5feb\u901f\u548c\u51c6\u786e\u7684\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u5728\u51e0\u4e4e\u6ca1\u6709\u610f\u8bc6\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u590d\u6742\u7684\u4efb\u52a1\uff0c\u5982\u9a7e\u9a76\u3002\u5feb\u901f\u3001\u51c6\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5c06\u5141\u8bb8\u8ba1\u7b97\u673a\u5728\u6ca1\u6709\u4e13\u7528\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u9a7e\u9a76\u6c7d\u8f66\uff0c\u4f7f\u8f85\u52a9\u8bbe\u5907\u80fd\u591f\u5411\u4eba\u7c7b\u7528\u6237\u4f20\u9001\u5b9e\u65f6\u573a\u666f\u4fe1\u606f\u5e76\u91ca\u653e\u901a\u7528\u3001\u54cd\u5e94\u7075\u654f\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6f5c\u529b\u3002\u5feb\u901f\u3001\u51c6\u786e\u7684\u7269\u4f53\u68c0\u6d4b\u7b97\u6cd5\u5c06\u5e2e\u52a9\u8ba1\u7b97\u673a\u5728\u6ca1\u6709\u4e13\u95e8\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u9a7e\u9a76\u6c7d\u8f66\uff0c\u8f85\u52a9\u8bbe\u5907\u80fd\u591f\u5c06\u5b9e\u65f6\u573a\u666f\u4fe1\u606f\u4f20\u8fbe\u7ed9\u7528\u6237\uff0c\u5e76\u663e\u793a\u901a\u7528\u3001\u54cd\u5e94\u5f0f\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6f5c\u529b\u3002 \u2003 \u76ee\u524d\u7684\u68c0\u6d4b\u7cfb\u7edf\u91cd\u590d\u5229\u7528\u5206\u7c7b\u5668\u6765\u6267\u884c\u68c0\u6d4b\u3002\u4e3a\u4e86\u68c0\u6d4b\u76ee\u6807\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u4e3a\u8be5\u76ee\u6807\u63d0\u4f9b\u4e00\u4e2a\u5206\u7c7b\u5668\uff0c\u5e76\u5728\u6d4b\u8bd5\u56fe\u50cf\u7684\u4e0d\u540c\u4f4d\u7f6e\u548c\u5c3a\u5ea6\u4e0a\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002\u4f8b\u5982\u50cf\u53ef\u53d8\u5f62\u90e8\u4ef6\u6a21\u578b \\((DPM)\\) \u8fd9\u6837\u7684\u7cfb\u7edf\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\uff0c\u5176\u4e2d\u5206\u7c7b\u5668\u5728\u6574\u4e2a\u56fe\u50cf\u4e0a\u5747\u5300\u95f4\u9694\u7684\u4f4d\u7f6e\u8fd0\u884c[10]\u3002 \u56fe1: YOLO\u68c0\u6d4b\u7cfb\u7edf\u3002 \u7528YOLO\u5904\u7406\u56fe\u50cf\u7b80\u5355\u800c\u76f4\u63a5\u3002\u5728\u6211\u4eec\u7684\u7cfb\u7edf\u4e2d: \u5c06\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u8c03\u6574\u4e3a448 \u00d7 448\u3002 \u5728\u56fe\u50cf\u4e0a\u8fd0\u884c\u4e00\u4e2a\u5377\u79ef\u7f51\u7edc\u3002 \u6839\u636e\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u5bf9\u7ed3\u679c\u68c0\u6d4b\u8fdb\u884c\u9608\u503c\u3002 \u2003\u6700\u8fd1\u7684\u65b9\u6cd5\uff0c\u5982R-CNN\u63d0\u51fa\u4f7f\u7528\u90e8\u5206\u533a\u57df\uff0c\u9996\u5148\u5728\u56fe\u50cf\u4e2d\u751f\u6210\u6f5c\u5728\u7684\u8fb9\u754c\u6846\uff0c\u7136\u540e\u5728\u8fd9\u4e9b\u6846\u4e0a\u8fd0\u884c\u5206\u7c7b\u5668\u3002\u5b8c\u6210\u5206\u7c7b\u540e\uff0c\u901a\u8fc7\u540e\u5904\u7406\u5728\u7ec6\u5316\u8fb9\u754c\u6846\uff0c\u6d88\u9664\u91cd\u590d\u68c0\u6d4b\uff0c\u5e76\u57fa\u4e8e\u573a\u666f\u4e2d\u7684\u5176\u4ed6\u76ee\u6807\u91cd\u65b0\u5b9a\u4f4d\u8fb9\u754c\u6846[13]\u3002\u8fd9\u4e9b\u590d\u6742\u7684\u6d41\u7a0b\u5f88\u6162\uff0c\u5f88\u96be\u4f18\u5316\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u5355\u72ec\u7684\u7ec4\u4ef6\u90fd\u5fc5\u987b\u5355\u72ec\u8bad\u7ec3\u3002 \u2003\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5355\u4e00\u7684\u56de\u5f52\u95ee\u9898\uff0c\u76f4\u63a5\u4ece\u56fe\u50cf\u50cf\u7d20\u5230\u8fb9\u754c\u6846\u5750\u6807\u548c\u7c7b\u522b\u6982\u7387\u3002\u4f7f\u7528\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u60a8\u53ea\u9700\u8981\u5728\u56fe\u50cf\u4e0a\u770b\u4e00\u6b21\uff08you only look once, \\(YOLO\\) \uff09\uff0c\u5c31\u4ee5\u9884\u6d4b\u4ec0\u4e48\u76ee\u6807\u51fa\u73b0\u548c\u5b83\u4eec\u5728\u54ea\u91cc\u3002 \u2003 \\(YOLO\\) \u65b0\u5947\u53c8\u5f88\u7b80\u5355\uff1a\u5982\u56fe1\u6240\u793a\u3002\u5355\u4e2a\u5377\u79ef\u7f51\u7edc\u540c\u65f6\u9884\u6d4b\u8fd9\u4e9b\u6846\u7684\u591a\u4e2a\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u503c\u3002YOLO\u5728\u5b8c\u6574\u56fe\u50cf\u4e0a\u8bad\u7ec3\uff0c\u5e76\u76f4\u63a5\u4f18\u5316\u68c0\u6d4b\u6027\u80fd\u3002\u4e0e\u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8fd9\u79cd\u7edf\u4e00\u7684\u6a21\u578b\u6709\u51e0\u4e2a\u4f18\u70b9\u3002 \u2003 \u9996\u5148\uff0c \\(YOLO\\) \u901f\u5ea6\u975e\u5e38\u5feb\u3002\u7531\u4e8e\u6211\u4eec\u5c06\u68c0\u6d4b\u89c6\u4e3a\u56de\u5f52\u95ee\u9898\uff0c\u6240\u4ee5\u6211\u4eec\u4e0d\u9700\u8981\u590d\u6742\u7684\u6d41\u7a0b\u3002\u6d4b\u8bd5\u65f6\u6211\u4eec\u5728\u4e00\u5f20\u65b0\u56fe\u50cf\u4e0a\u7b80\u5355\u7684\u8fd0\u884c\u6211\u4eec\u7684\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u68c0\u6d4b\u7684\u7ed3\u679c\u3002\u5728Titan X GPU\u4e0a\u6ca1\u6709\u6279\u5904\u7406\u4e2d\uff0c\u6211\u4eec\u7684\u57fa\u7840\u7f51\u7edc\u4ee5\u6bcf\u79d245\u5e27\u7684\u901f\u5ea6\u8fd0\u884c\u3002\u5feb\u901f\u7248\u672c\u8fd0\u884c\u901f\u5ea6\u8d85\u8fc7150fps\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u53ef\u4ee5\u5728\u4e0d\u523025\u6beb\u79d2\u7684\u5ef6\u8fdf\u5185\u5b9e\u65f6\u5904\u7406\u6d41\u5a92\u4f53\u89c6\u9891\u3002\u6b64\u5916\uff0c \\(YOLO\\) \u5b9e\u73b0\u4e86\u5176\u5b83\u5b9e\u65f6\u7cfb\u7edf\u4e24\u500d\u4ee5\u4e0a\u7684mAP\u3002\u5173\u4e8e\u6211\u4eec\u7684\u7cfb\u7edf\u5728\u7f51\u7edc\u6444\u50cf\u5934\u4e0a\u5b9e\u65f6\u8fd0\u884c\u7684\u6f14\u793a\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684\u9879\u76ee\u7f51\u9875\uff1ahttp://pjreddie.com/yolo/\u3002 \u2003 \u5176\u6b21\uff0c \\(YOLO\\) \u5728\u8fdb\u884c\u9884\u6d4b\u65f6\uff0c\u4f1a\u5bf9\u56fe\u50cf\u8fdb\u884c\u5168\u5c40\u5730\u63a8\u7406\u3002\u4e0e\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3( sliding window )\u548c\u57fa\u4e8e\u533a\u57df\u63d0\u8bae( region proposal )\u7684\u6280\u672f\u4e0d\u540c\uff0c \\(YOLO\\) \u5728\u8bad\u7ec3\u671f\u95f4\u548c\u6d4b\u8bd5\u65f6\u4f1a\u770b\u5230\u6574\u4e2a\u56fe\u50cf\uff0c\u56e0\u6b64\u5b83\u9690\u5f0f\u5730\u7f16\u7801\u5173\u4e8e\u7c7b\u53ca\u5176\u5916\u89c2\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002 \\(Fast \\ R-CNN\\) \u662f\u4e00\u79cd\u9876\u90e8\u7684\u68c0\u6d4b\u65b9\u6cd5[14]\uff0c\u4f46\u56e0\u4e3a\u5b83\u770b\u4e0d\u5230\u66f4\u5927\u7684\u4e0a\u4e0b\u6587\uff0c\u6240\u4ee5\u5728\u56fe\u50cf\u4e2d\u4f1a\u5c06\u80cc\u666f\u5757\u8bef\u68c0\u4e3a\u76ee\u6807\u3002\u4e0e \\(Fast R-CNN\\) \u76f8\u6bd4\uff0cYOLO\u7684\u80cc\u666f\u8bef\u68c0\u6570\u91cf\u5c11\u4e86\u4e00\u534a\u3002 \u2003 \u7b2c\u4e09\uff0c \\(YOLO\\) \u5b66\u4e60\u76ee\u6807\u53ef\u6cdb\u5316\u8868\u793a\u3002\u5f53\u5728\u81ea\u7136\u7684\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u5bf9\u827a\u672f\u4f5c\u54c1\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c \\(YOLO\\) \u5927\u5e45\u4f18\u4e8e \\(DPM\\) \u548c \\(R-CNN\\) \u7b49\u9876\u7ea7\u68c0\u6d4b\u65b9\u6cd5\u3002\u7531\u4e8e \\(YOLO\\) \u5177\u6709\u9ad8\u5ea6\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u5728\u5e94\u7528\u4e8e\u65b0\u9886\u57df\u6216\u78b0\u5230\u975e\u6b63\u5e38\u8f93\u5165\u65f6\u5f88\u5c11\u51fa\u6545\u969c\u3002 \u2003 \\(YOLO\\) \u5728\u51c6\u786e\u5ea6\u4e0a\u4ecd\u7136\u843d\u540e\u4e8e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002\u867d\u7136\u5b83\u53ef\u4ee5\u5feb\u901f\u8bc6\u522b\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff0c\u4f46\u5b83\u5f88\u96be\u7cbe\u786e\u5b9a\u4f4d\u4e00\u4e9b\u76ee\u6807\uff0c\u5c24\u5176\u662f\u4e00\u4e9b\u5c0f\u76ee\u6807\u3002\u6211\u4eec\u5728\u5b9e\u9a8c\u4e2d\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u8fd9\u4e9b\u6743\u8861\u3002 \u2003 \\(YOLO\\) \u6211\u4eec\u6240\u6709\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u90fd\u662f\u5f00\u6e90\u7684\u3002\u5404\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\u4e5f\u90fd\u53ef\u4ee5\u4e0b\u8f7d\u3002 2.\u7edf\u4e00\u7684\u68c0\u6d4b \u2003 \u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u7684\u5355\u72ec\u7ec4\u4ef6\u96c6\u6210\u5230\u5355\u4e2a\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002\u6211\u4eec\u7684\u7f51\u7edc\u5229\u7528\u6574\u4e2a\u56fe\u50cf\u7684\u7279\u5f81\u6765\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u3002\u5b83\u8fd8\u53ef\u4ee5\u540c\u65f6\u9884\u6d4b\u4e00\u5f20\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u7c7b\u522b\u7684\u6240\u6709\u8fb9\u754c\u6846\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u7f51\u7edc\u5bf9\u6574\u4e2a\u56fe\u50cf\u548c\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u5bf9\u8c61\u8fdb\u884c\u5168\u5c40\u63a8\u7406\u3002 \\(YOLO\\) \u8bbe\u8ba1\u53ef\u5b9e\u73b0\u7aef\u5230\u7aef\u8bad\u7ec3\u548c\u5b9e\u65f6\u7684\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u5e73\u5747\u7cbe\u5ea6( \u5373mAP\u503c )\u3002 \u2003 \u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u8f93\u5165\u56fe\u50cf\u5206\u6210 \\(S\u00d7S\\) \u7684\u7f51\u683c\u3002\u5982\u679c\u4e00\u4e2a\u76ee\u6807\u7684\u4e2d\u5fc3\u843d\u5165\u4e00\u4e2a\u7f51\u683c\u5355\u5143\u4e2d\uff0c\u8be5\u7f51\u683c\u5355\u5143\u8d1f\u8d23\u68c0\u6d4b\u8be5\u76ee\u6807\u3002 \u2003 \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u9884\u6d4b \\(B\\) \u4e2a\u8fb9\u754c\u6846\u548c\u7f6e\u4fe1\u5ea6\u5206\u6570\u5bf9\u4e8e\u90a3\u4e9b\u6846\u3002\u8fd9\u4e9b\u7f6e\u4fe1\u5ea6\u5206\u6570\u53cd\u6620\u4e86\u8be5\u6a21\u578b\u5bf9\u6846\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u7f6e\u4fe1\u5ea6\uff0c\u4ee5\u53ca\u5b83\u9884\u6d4b\u6846\u7684\u51c6\u786e\u5ea6\u3002\u5728\u5f62\u5f0f\u4e0a\uff0c\u6211\u4eec\u5c06\u7f6e\u4fe1\u5ea6\u5b9a\u4e49\u4e3a \\(Pr(Object)\u2217IOU^{truth}_{pred}\\) \u3002\u5982\u679c\u8be5\u5355\u5143\u683c\u4e2d\u4e0d\u5b58\u5728\u76ee\u6807\uff0c\u5219\u7f6e\u4fe1\u5ea6\u5206\u6570\u5e94\u4e3a \\(0\\) \u3002\u5426\u5219\uff0c\u6211\u4eec\u5e0c\u671b\u7f6e\u4fe1\u5ea6\u5206\u6570\u7b49\u4e8e\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u8054\u5408\u90e8\u5206\u7684\u4ea4\u96c6( \\(IOU\\) )\u3002 \u2003\u6bcf\u4e2a\u8fb9\u754c\u6846\u5305\u542b5\u4e2a\u9884\u503c\uff1a \\(x,y,w,h,confidence\\) \u3002 \\((x,y)\\) \u5750\u6807\u8868\u793a\u8fb9\u754c\u6846\u76f8\u5bf9\u4e8e\u7f51\u683c\u5355\u5143\u8fb9\u754c\u7684\u65b9\u6846\u4e2d\u5fc3\u3002\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u662f\u76f8\u5bf9\u4e8e\u6574\u5f20\u56fe\u50cf\u9884\u6d4b\u7684\u3002\u6700\u540e\uff0c\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u8868\u793a\u4e3a\u9884\u6d4b\u6846\u4e0e\u5b9e\u9645\u8fb9\u754c\u6846\u4e4b\u95f4\u7684 \\(IOU\\) \u3002 \u2003 \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u8fd8\u9884\u6d4b \\(C\\) \u4e2a\u6761\u4ef6\u7c7b\u522b\u6982\u7387 \\(Pr(Class_i|Object)\\) \u3002\u8fd9\u4e9b\u6982\u7387\u4ee5\u5305\u542b\u76ee\u6807\u7684\u7f51\u683c\u5355\u5143\u4e3a\u6761\u4ef6\u3002\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u6211\u4eec\u53ea\u9884\u6d4b\u7684\u4e00\u7ec4\u7c7b\u522b\u6982\u7387\uff0c\u800c\u4e0d\u7ba1\u8fb9\u754c\u6846\u7684\u7684\u6570\u91cf \\(B\\) \u662f\u591a\u5c11\u3002 \u2003\u5728\u6d4b\u8bd5\u65f6\uff0c\u6211\u4eec\u5c06\u6761\u4ef6\u7c7b\u6982\u7387\u548c\u5355\u4e2a\u6846\u7684\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u503c\u76f8\u4e58\uff1a \\(\\small{Pr(Class_i|Object) \u2217 Pr(Object) \u2217 IOU^{truth}_{pred} = Pr(Class_i) \u2217 IOU^{truth}_{pred}}\\) (1) \u5b83\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u6bcf\u4e2a\u6846\u7279\u5b9a\u7c7b\u522b\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\u3002\u8fd9\u4e9b\u5206\u6570\u7f16\u7801\u4e86\u8be5\u7c7b\u51fa\u73b0\u5728\u6846\u4e2d\u7684\u6982\u7387\u4ee5\u53ca\u9884\u6d4b\u6846\u62df\u5408\u76ee\u6807\u7684\u7a0b\u5ea6\u3002 \u56fe2\uff1a\u6a21\u578b\u3002 \u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u68c0\u6d4b\u5efa\u6a21\u4e3a\u4e00\u4e2a\u56de\u5f52\u95ee\u9898\u3002\u5b83\u5c06\u56fe\u50cf\u5212\u5206\u4e3a\u4e00\u4e2a \\(S \u00d7 S\\) \u7f51\u683c\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u9884\u6d4b \\(B\\) \u4e2a\u8fb9\u754c\u6846\u3001\u8fd9\u4e9b\u6846\u7684\u7f6e\u4fe1\u5ea6 \u548c \\(C\\) \u7c7b\u522b\u6982\u7387\u3002\u8fd9\u4e9b\u9884\u6d4b\u88ab\u7f16\u7801\u4e3a \\(S \u00d7 S \u00d7 (B * 5 + C)\\) \u7684\u5f20\u91cf \\(S\\times{S}\\) grid on input( \\(S\\times{S}\\) \u7684\u7f51\u683c\u5728\u8f93\u5165\u4e0a) Bounding boxes (\u8fb9\u754c\u6846) confidence (\u7f6e\u4fe1\u5ea6) Class probability map(\u7c7b\u522b\u6982\u7387\u5730\u56fe) Final detections (\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c) \u4e3a\u4e86\u5728 \\(Pascal \\ VOC\\) \u4e0a\u8bc4\u4f30 \\(YOLO\\) \uff0c\u6211\u4eec\u4f7f\u7528 \\(S=7\uff0cB=2\u3002Pascal VOC\\) \u6709 \\(20\\) \u4e2a\u6807\u6ce8\u7c7b\uff0c\u6240\u4ee5 \\(C=20\\) \u3002\u6211\u4eec\u6700\u7ec8\u7684\u9884\u6d4b\u662f \\(7\u00d77\u00d730\\) \u7684\u5f20\u91cf\u3002 \u6ce8\u610f\uff1a \u2003 \u2003 1.\u7531\u4e8e\u8f93\u51fa\u5c42\u4e3a\u5168\u8fde\u63a5\u5c42\uff0c\u56e0\u6b64\u5728\u68c0\u6d4b\u65f6\uff0cYOLO\u8bad\u7ec3\u6a21\u578b\u53ea\u652f\u6301\u4e0e\u8bad\u7ec3\u56fe\u50cf\u76f8\u540c\u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002 \u2003 \u2003 2.\u867d\u7136\u6bcf\u4e2a\u683c\u5b50\u53ef\u4ee5\u9884\u6d4bB\u4e2abounding box\uff0c\u4f46\u662f\u6700\u7ec8\u53ea\u9009\u62e9\u53ea\u9009\u62e9IOU\u6700\u9ad8\u7684bounding box\u4f5c\u4e3a\u7269\u4f53\u68c0\u6d4b\u8f93\u51fa\uff0c\u5373\u6bcf\u4e2a\u683c\u5b50\u6700\u591a\u53ea\u9884\u6d4b\u51fa\u4e00\u4e2a\u7269\u4f53\u3002\u5f53\u7269\u4f53\u5360\u753b\u9762\u6bd4\u4f8b\u8f83\u5c0f\uff0c\u5982\u56fe\u50cf\u4e2d\u5305\u542b\u755c\u7fa4\u6216\u9e1f\u7fa4\u65f6\uff0c\u6bcf\u4e2a\u683c\u5b50\u5305\u542b\u591a\u4e2a\u7269\u4f53\uff0c\u4f46\u5374\u53ea\u80fd\u68c0\u6d4b\u51fa\u5176\u4e2d\u4e00\u4e2a\u3002\u8fd9\u662fYOLO\u65b9\u6cd5\u7684\u4e00\u4e2a\u7f3a\u9677\u3002 2.1 \u7f51\u7edc\u8bbe\u8ba1 \u2003\u6211\u4eec\u5c06\u8be5\u6a21\u578b\u5b9e\u73b0\u4e3a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u5728 \\(PASCAL \\ VOC\\) \u68c0\u6d4b\u6570\u636e\u96c6[9]\u4e0a\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002\u7f51\u7edc\u7684\u521d\u59cb\u5377\u79ef\u5c42\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u800c\u5168\u8fde\u901a\u5c42\u9884\u6d4b\u8f93\u51fa\u6982\u7387\u548c\u5750\u6807\u3002 \u2003\u6211\u4eec\u7684\u7f51\u7edc\u67b6\u6784\u7684\u7075\u611f\u6765\u81ea\u4e8e\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b[34]\u7684 \\(GoogLeNet\\) \u6a21\u578b\u3002\u6211\u4eec\u7684\u7f51\u7edc\u6709 \\(24\\) \u4e2a\u5377\u79ef\u5c42\u548c \\(2\\) \u4e2a\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u7b80\u5355\u5730\u4f7f\u7528 \\(1 \u00d7 1\\) \u8fd8\u539f\u5c42\u548c \\(3 \u00d7 3\\) \u5377\u79ef\u5c42\uff0c\u7c7b\u4f3c \\(Lin\\) \u7b49[22]\u3002\u5b8c\u6574\u7684\u7f51\u7edc \\(\u5982\u56fe3\\) \u6240\u793a\u3002 \u56fe3 :\u4f53\u7cfb\u7ed3\u6784\u3002 \u6211\u4eec\u7684\u68c0\u6d4b\u7f51\u7edc\u6709 \\(24\\) \u4e2a\u5377\u79ef\u5c42\u548c \\(2\\) \u4e2a\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u4ea4\u66ff\u7684 \\(1 \u00d7 1\\) \u5377\u79ef\u5c42\u51cf\u5c11\u4e86\u524d\u4e00\u5c42\u7684\u7279\u5f81\u7a7a\u95f4\u3002\u6211\u4eec\u5728 \\(ImageNet\\) \u5206\u7c7b\u4efb\u52a1\u4e0a\u4ee5\u4e00\u534a\u5206\u8fa8\u7387( \\(224 \u00d7 224\\) \u8f93\u5165\u56fe\u50cf)\u5bf9\u5377\u79ef\u5c42\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5c06\u5206\u8fa8\u7387\u63d0\u9ad8\u4e00\u500d\u7528\u4e8e\u68c0\u6d4b\u3002 \u2003\u6211\u4eec\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5feb\u901f\u7248\u672c\u7684 \\(YOLO\\) \uff0c\u65e8\u5728\u63a8\u52a8\u5feb\u901f\u76ee\u6807\u68c0\u6d4b\u7684\u8fb9\u754c\u3002 \\(Fast \\ YOLO\\) \u4f7f\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u66f4\u5c11\u7684\u5377\u79ef\u5c42(9\u5c42\u800c\u4e0d\u662f24\u5c42)\uff0c\u8fd9\u4e9b\u5c42\u4e2d\u7684\u8fc7\u6ee4\u5668\u4e5f\u66f4\u5c11\u3002\u9664\u4e86\u7f51\u7edc\u7684\u89c4\u6a21\uff0c \\(YOLO\\) \u548c \\(Fast \\ YOLO\\) \u4e4b\u95f4\u7684\u6240\u6709\u8bad\u7ec3\u548c\u6d4b\u8bd5\u53c2\u6570\u90fd\u662f\u76f8\u540c\u7684\u3002 \u2003\u6211\u4eec\u7684\u7f51\u7edc\u7684\u6700\u7ec8\u8f93\u51fa\u662f \\(7 \u00d7 7 \u00d7 30\\) \u5f20\u91cf\u7684\u9884\u6d4b\u3002 2.2 \u8bad\u7ec3 \u2003 \u9884\u8bad\u7ec3\u5206\u7c7b\u7f51\u7edc\uff1a\u6211\u4eec\u5728ImageNet 1000\u7c7b\u7ade\u8d5b\u6570\u636e\u96c6[30]\u4e0a\u9884\u8bad\u7ec3\u5377\u79ef\u5c42\u3002\u5bf9\u4e8e\u9884\u8bad\u7ec3\uff0c\u6211\u4eec\u4f7f\u7528\u56fe3\u4e2d\u7684\u524d20\u4e2a\u5377\u79ef\u5c42\uff0c\u7136\u540e\u662f\u5e73\u5747\u6c60\u5316\u5c42\u548c\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u6211\u4eec\u5bf9\u8be5\u7f51\u7edc\u8fdb\u884c\u4e86\u5927\u7ea6\u4e00\u5468\u7684\u8bad\u7ec3\uff0c\u5e76\u5728ImageNet 2012\u9a8c\u8bc1\u96c6\u4e0a\u5b9e\u73b0\u4e8688%\u7684\u5355\u4e00\u4f5c\u7269\u524d5\u540d\u7684\u51c6\u786e\u6027\uff0c\u4e0eCaffe\u7684Model Zoo[24]\u4e2d\u7684GoogLeNet\u6a21\u578b\u76f8\u5f53\u3002\u6211\u4eec\u4f7f\u7528Darknet\u6846\u67b6\u8fdb\u884c\u6240\u6709\u7684\u8bad\u7ec3\u548c\u63a8\u7406[26]\u3002 \u2003 \u7136\u540e\u6211\u4eec\u5c06\u6a21\u578b\u8f6c\u6362\u4e3a\u6267\u884c\u68c0\u6d4b\u3002Ren\u7b49\u4eba\u8868\u660e\uff0c\u5728\u9884\u8bad\u7ec3\u7684\u7f51\u7edc\u4e2d\u540c\u65f6\u6dfb\u52a0\u5377\u79ef\u5c42\u548c\u8fde\u63a5\u5c42\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd[29]\u3002 \u6309\u7167\u4ed6\u4eec\u7684\u4f8b\u5b50\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u56db\u4e2a\u5377\u79ef\u5c42\u548c\u4e24\u4e2a\u5177\u6709\u968f\u673a\u521d\u59cb\u5316\u6743\u503c\u7684\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u68c0\u6d4b\u901a\u5e38\u9700\u8981\u7ec6\u7c92\u5ea6\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u56e0\u6b64\u6211\u4eec\u5c06\u7f51\u7edc\u7684\u8f93\u5165\u5206\u8fa8\u7387\u4ece \\(224 \u00d7 224\\) \u63d0\u9ad8\u5230 \\(448 \u00d7 448\\) \u3002 \u2003 \u6211\u4eec\u7684\u6700\u540e\u4e00\u5c42\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u548c\u8fb9\u754c\u6846\u5750\u6807\u3002\u6211\u4eec\u901a\u8fc7\u56fe\u50cf\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u6765\u5f52\u4e00\u5316\u8fb9\u754c\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u4f7f\u5b83\u4eec\u843d\u57280\u548c1\u4e4b\u95f4\u3002\u6211\u4eec\u5c06\u8fb9\u754c\u6846x\u548cy\u5750\u6807\u53c2\u6570\u5316\u4e3a\u7279\u5b9a\u7f51\u683c\u5355\u5143\u4f4d\u7f6e\u7684\u504f\u79fb\u91cf\uff0c\u56e0\u6b64\u5b83\u4eec\u8fb9\u754c\u4e5f\u57280\u548c1\u4e4b\u95f4\u3002 \u2003 \u6211\u4eec\u5bf9\u6700\u540e\u4e00\u5c42\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u6240\u6709\u5176\u5b83\u5c42\u4f7f\u7528\u4e0b\u9762\u7684leaky ReLU\u6fc0\u6d3b\u51fd\u6570: \\(\\phi(x)=\\left\\{\\begin{array}{ll} x, & \\text { if } x>0 \\\\ 0.1 x, & \\text { otherwise } \\end{array}\\right.\\) (2) \u6211\u4eec\u4f18\u5316\u4e86\u6a21\u578b\u8f93\u51fa\u7684\u5e73\u65b9\u548c\u8bef\u5dee\u3002\u6211\u4eec\u4f7f\u7528\u5e73\u65b9\u548c\u8bef\u5dee\u662f\u56e0\u4e3a\u5b83\u5f88\u5bb9\u6613\u8fdb\u884c\u4f18\u5316\uff0c\u4f46\u662f\u5b83\u5e76\u4e0d\u5b8c\u5168\u7b26\u5408\u6211\u4eec\u6700\u5927\u5316\u5e73\u5747\u7cbe\u5ea6\u7684\u76ee\u6807\u3002\u5206\u7c7b\u8bef\u5dee\u4e0e\u5b9a\u4f4d\u8bef\u5dee\u7684\u6743\u91cd\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u53ef\u80fd\u5e76\u4e0d\u7406\u60f3\u3002\u53e6\u5916\uff0c\u5728\u6bcf\u5f20\u56fe\u50cf\u4e2d\uff0c\u8bb8\u591a\u7f51\u683c\u5355\u5143\u4e0d\u5305\u542b\u4efb\u4f55\u5bf9\u8c61\u3002\u8fd9\u5c06\u5bfc\u81f4\u8fd9\u4e9b\u5355\u5143\u683c\u7684 \\(\"\u7f6e\u4fe1\u5ea6\"\\) \u5206\u6570\u4e3a\u96f6\uff0c\u901a\u5e38\u538b\u5012\u4e86\u5305\u542b\u76ee\u6807\u7684\u5355\u5143\u683c\u7684\u68af\u5ea6\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u4ece\u800c\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u65e9\u53d1\u6563\u3002 \u2003\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u589e\u52a0\u4e86\u8fb9\u754c\u6846\u5750\u6807\u9884\u6d4b\u7684\u635f\u5931\uff0c\u51cf\u5c11\u4e86\u4e0d\u5305\u542b\u76ee\u6807\u7684\u6846\u7684\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u7684\u635f\u5931\u3002\u6211\u4eec\u4f7f\u7528\u4e24\u4e2a\u53c2\u6570\uff0c \\(\\lambda_{coord}\\) \u548c \\(\\lambda{noobj}\\) \u6765\u5b8c\u6210\u8fd9\u4e2a\u4efb\u52a1\u3002\u6211\u4eec\u8bbe\u7f6e \\(\\lambda_{coord} = 5\\) , \\(\\lambda_{noobj} = 0.5\\) \u3002 \u2003 \u5e73\u65b9\u548c\u8bef\u5dee\u5728\u5927\u65b9\u6846\u548c\u5c0f\u65b9\u6846\u4e2d\u7684\u6743\u91cd\u76f8\u540c\u3002\u6211\u4eec\u7684\u8bef\u5dee\u5ea6\u91cf\u5e94\u8be5\u53cd\u6620\u5927\u65b9\u6846\u91cc\u7684\u5c0f\u504f\u5dee\u6bd4\u5c0f\u65b9\u6846\u91cc\u7684\u5f71\u54cd\u5c0f\u3002\u4e3a\u4e86\u90e8\u5206\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u9884\u6d4b\u8fb9\u754c\u6846\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5e73\u65b9\u6839\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u3002\u4e3a\u4e86\u7f13\u548c\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u9884\u6d4b\u8fb9\u754c\u6846\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5e73\u65b9\u6839\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u3002 \u2003 \\(YOLO\\) \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u6709\u9884\u6d4b\u591a\u4e2a\u8fb9\u754c\u6846\u3002\u5728\u8bad\u7ec3\u65f6\uff0c\u6bcf\u4e2a\u76ee\u6807\u6211\u4eec\u53ea\u9700\u8981\u4e00\u4e2a\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u6765\u8d1f\u8d23\u3002\u6211\u4eec\u6839\u636e\u54ea\u4e2a\u9884\u6d4b\u5668\u7684\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u5177\u6709\u5f53\u524d\u6700\u9ad8\u7684 \\(IOU\\) \u6765\u6307\u5b9a\u54ea\u4e2a\u9884\u6d4b\u5668 \u8d1f\u8d23 \u9884\u6d4b\u8be5\u76ee\u6807\u3002\u8fd9\u5bfc\u81f4\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u4e4b\u95f4\u7684\u4e13\u4e00\u5316\u3002\u6bcf\u4e2a\u9884\u6d4b\u5668\u53ef\u4ee5\u66f4\u597d\u5730\u9884\u6d4b\u7279\u5b9a\u5927\u5c0f\u3001\u957f\u5bbd\u6bd4\u6216\u76ee\u6807\u7684\u7c7b\u522b\uff0c\u4ece\u800c\u6539\u5584\u6574\u4f53\u53ec\u56de\u7387\u3002 \u2003\u5728\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u4f18\u5316\u4ee5\u4e0b\u7531\u591a\u90e8\u5206\u7ec4\u6210\u7684\u635f\u5931\u51fd\u6570\uff1a \\(\\begin{array}{c} \\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(x_{i}-\\hat{x}_{i}\\right)^{2}+\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\\right] \\\\ +\\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(\\sqrt{w_{i}}-\\sqrt{\\hat{w}_{i}}\\right)^{2}+\\left(\\sqrt{h_{i}}-\\sqrt{\\hat{h}_{i}}\\right)^{2}\\right] \\\\ +\\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ +\\lambda_{\\text {noobj }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {noobj }}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ +\\sum_{i=0}^{S^{2}} \\mathbb{1}_{i}^{\\text {obj }} \\sum_{c \\in \\text { classes }}\\left(p_{i}(c)-\\hat{p}_{i}(c)\\right)^{2} \\end{array}\\) (3) \u5176\u4e2d \\(\\mathbb{1}_{i}^{\\mathrm{obj}}\\) \u8868\u793a\u5982\u679c\u76ee\u6807\u51fa\u73b0\u5728\u5355\u5143\u683c \\(i\\) \u5e76\u4e14 \\(\\mathbb{1}_{i j}^{\\mathrm{obj}}\\) \u8868\u793a\u7b2c \\(j\\) \u4e2a\u8fb9\u754c\u6846\u8d1f\u8d23\u5728\u5355\u5143\u683c \\(i\\) \u9884\u6d4b \u3002 \u2003 \u6ce8\u610f\uff0c\u5982\u679c\u76ee\u6807\u5b58\u5728\u4e8e\u8be5\u7f51\u683c\u5355\u5143\u4e2d\uff08\u524d\u9762\u8ba8\u8bba\u7684\u6761\u4ef6\u7c7b\u522b\u6982\u7387\uff09\uff0c\u5219\u635f\u5931\u51fd\u6570\u60e9\u7f5a\u5206\u7c7b\u8bef\u5dee\u3002\u5982\u679c\u9884\u6d4b\u5668 \\(\"\u8d1f\u8d23\"\\) \u771f\u5b9e\u8fb9\u754c\u6846\uff08\u5373\u8be5\u7f51\u683c\u5355\u5143\u4e2d\u5177\u6709\u6700\u9ad8 \\(IOU\\) \u7684\u9884\u6d4b\u5668\uff09\uff0c\u5219\u5b83\u4e5f\u4ec5\u60e9\u7f5a\u8fb9\u754c\u6846\u5750\u6807\u8bef\u5dee\u3002 \u2003 \u6211\u4eec\u5728 \\(Pascal \\ VOC \\ 2007\\) \u548c \\(2012\\) \u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5927\u7ea6 \\(135\\) \u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u7f51\u7edc\u8bad\u7ec3\u3002 \u5728 \\(Pascal \\ VOC \\ 2012\\) \u4e0a\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c\u6211\u4eec\u7684\u8bad\u7ec3\u8fd8\u5305\u542b\u4e86 \\(P0ascal \\ VOC \\ 2007\\) \u7684\u6d4b\u8bd5\u6570\u636e\u3002\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e86batch-size = 64 ( \u6279\u5927\u5c0f )\uff0cmomentum = 0.9 ( \u52a8\u91cf )\u548c decay = 0.0005 ( \u8870\u51cf\u7387 )\u3002 \u2003 \u6211\u4eec\u7684\u5b66\u4e60\u7387\u65b9\u6848\u5982\u4e0b\uff1a\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u8fed\u4ee3\u5468\u671f\uff0c\u6211\u4eec\u6162\u6162\u5730\u5c06\u5b66\u4e60\u7387\u4ece \\(10^{-3}\\) \u63d0\u9ad8\u5230 \\(10^{-2}\\) \u3002\u5982\u679c\u6211\u4eec\u4ece\u9ad8\u5b66\u4e60\u7387\u5f00\u59cb\uff0c\u6211\u4eec\u7684\u6a21\u578b\u5f80\u5f80\u4f1a\u7531\u4e8e\u68af\u5ea6\u4e0d\u7a33\u5b9a\u800c\u53d1\u6563\u3002\u6211\u4eec\u7ee7\u7eed\u4ee5 \\(10^{-2}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 \\(75\\) \u4e2a epochs( \u5373\u8fed\u4ee3\u5468\u671f )\uff0c\u7136\u540e\u7528 \\(10^{-3}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 \\(30\\) \u4e2aepochs\uff0c\u6700\u540e\u7528 \\(10^{-4}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 30\u4e2aepochs\u3002 \u2003 \u4e3a\u4e86\u907f\u514d\u8fc7\u5ea6\u62df\u5408\uff0c\u6211\u4eec\u4f7f\u7528 \\(dropout\\) \u548c \u5e7f\u6cdb\u7684\u6570\u636e\u589e\u5f3a\u3002\u5728\u7b2c\u4e00\u4e2a\u8fde\u63a5\u5c42\u4e4b\u540e\u6211\u4eec\u4e22\u5f03\u5177\u6709\u901f\u7387=0.5\u7684\u5c42\uff0c\u9632\u6b62\u5c42\u4e4b\u95f4\u7684\uff08\u76f8\u4e92\u5f71\u54cd\uff09\u3002\u5bf9\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u6211\u4eec\u5f15\u5165\u968f\u673a\u7f29\u653e\u548c\u6700\u591a\u539f\u59cb\u56fe\u50cf\u5927\u5c0f\u768420%\u7684translations\u3002\u6211\u4eec\u8fd8\u968f\u673a\u8c03\u6574\u66dd\u5149\u548c\u9971\u548c\u5ea6\u7684\u56fe\u50cf\u591a\u8fbe1.5\u500d\u7684HSV\u989c\u8272\u7a7a\u95f4\u3002 \u2003\u5728\u7b2c\u4e00\u4e2a\u8fde\u63a5\u5c42\u4e4b\u540e\uff0c \\(dropout\\) \u5c42\u4f7f\u7528rate=0.5\u7684\u6bd4\u4f8b\uff0c\u9632\u6b62\u5c42\u4e4b\u95f4\u7684\u76f8\u4e92\u5f71\u54cd( co-adaptation )[18]\u3002\u5bf9\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u6211\u4eec\u5f15\u5165\u9ad8\u8fbe\u539f\u59cb\u56fe\u50cf20%\u5927\u5c0f\u7684\u968f\u673a\u7f29\u653e\u548c\u8f6c\u6362\u3002\u6211\u4eec\u8fd8\u5728HSV\u8272\u5f69\u7a7a\u95f4\u4e2d\u4f7f\u7528\u9ad8\u8fbe1.5\u7684\u56e0\u5b50\u6765\u968f\u673a\u8c03\u6574\u56fe\u50cf\u7684\u66dd\u5149\u548c\u9971\u548c\u5ea6\u3002 2.3 \u63a8\u7406 \u2003\u4e0e\u8bad\u7ec3\u65f6\u4e00\u6837\uff0c\u9884\u6d4b\u6d4b\u8bd5\u56fe\u50cf\u7684\u68c0\u6d4b\u53ea\u9700\u8981\u4e00\u6b21\u7f51\u7edc\u8bc4\u4f30\u3002\u5728 \\(Pascal \\ VOC\\) \u4e0a\uff0c\u6bcf\u5f20\u56fe\u50cf\u4e0a\u7f51\u7edc\u9884\u6d4b98\u4e2a\u8fb9\u754c\u6846\uff08 \u8bd1\u8005\u6ce8\uff1a\u6bcf\u5f20\u56fe\u50cf\u88ab\u5212\u5206\u62107 7\u7684\u683c\u5b50\uff0c\u6bcf\u4e2a\u683c\u5b50\u9884\u6d4b\u4e24\u4e2a\u8fb9\u754c\u6846\uff0c\u603b\u517198\u4e2a\u8fb9\u754c\u6846*\uff09\u548c\u6bcf\u4e2a\u6846\u7684\u7c7b\u522b\u6982\u7387\u3002\u4e0e\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c \\(YOLO\\) \u5728\u6d4b\u8bd5\u65f6\u975e\u5e38\u5feb\uff0c\u56e0\u4e3a\u5b83\u53ea\u9700\u8981\u8fd0\u884c\u4e00\u6b21\u7f51\u7edc\u8bc4\u4f30\u3002 \u2003\u7f51\u683c\u8bbe\u8ba1\u52a0\u5f3a\u4e86\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u7a7a\u95f4\u591a\u6837\u6027\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u76ee\u6807\u843d\u5728\u54ea\u4e2a\u7f51\u683c\u5355\u5143\u683c\u4e2d\u662f\u5f88\u6e05\u695a\u7684\uff0c\u7f51\u7edc\u9884\u6d4b\u7684\u6bcf\u4e2a\u76ee\u6807\u5bf9\u5e94\u4e00\u4e2a\u6846\u3002\u4e00\u4e9b\u5927\u7684\u76ee\u6807\u6216\u9760\u8fd1\u591a\u4e2a\u7f51\u683c\u5355\u5143\u8fb9\u754c\u7684\u76ee\u6807\u53ef\u4ee5\u88ab\u591a\u4e2a\u7f51\u683c\u5355\u5143\u5f88\u597d\u5730\u5b9a\u4f4d\u3002\u975e\u6781\u5927\u503c\u6291\u5236\uff08 \u5373NMS \uff09\u53ef\u4ee5\u7528\u6765\u4fee\u6b63\u8fd9\u4e9b\u591a\u91cd\u68c0\u6d4b\u3002\u867d\u7136\u4e0d\u50cf \\(R-CNN\\) \u6216 \\(DPM\\) \u90a3\u6837\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u975e\u6700\u5927\u6291\u5236\u589e\u52a0\u4e862~3%\u7684 \\(mAP\\) \u3002 2.4 YOLO\u7684\u5c40\u9650\u6027 \u2003YOLO\u5bf9\u8fb9\u754c\u6846\u9884\u6d4b\u65bd\u52a0\u4e86\u5f88\u5f3a\u7684\u7a7a\u95f4\u7ea6\u675f\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u683c\u53ea\u80fd\u9884\u6d4b\u4e24\u4e2a\u6846\uff0c\u5e76\u4e14\u53ea\u80fd\u6709\u4e00\u4e2a\u7c7b\u3002\u8fd9\u79cd\u7a7a\u95f4\u7ea6\u675f\u9650\u5236\u4e86\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u9884\u6d4b\u7684\u9644\u8fd1\u7269\u4f53\u7684\u6570\u91cf\u3002\u6211\u4eec\u7684\u6a21\u578b\u5f88\u96be\u5904\u7406\u6210\u7fa4\u51fa\u73b0\u7684\u5c0f\u7269\u4f53\uff0c\u6bd4\u5982\u9e1f\u7fa4\u3002 \u2003 \u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u5b66\u4e60\u4ece\u6570\u636e\u4e2d\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u56e0\u6b64\u5b83\u5f88\u96be\u6cdb\u5316\u5230\u65b0\u7684\u3001\u4e0d\u5e38\u89c1\u7684\u957f\u5bbd\u6bd4\u6216\u914d\u7f6e\u4e2d\u7684\u76ee\u6807\u3002\u6211\u4eec\u7684\u6a21\u578b\u4e5f\u4f7f\u7528\u76f8\u5bf9\u8f83\u7c97\u7cd9\u7684\u7279\u5f81\u6765\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u56e0\u4e3a\u6211\u4eec\u7684\u67b6\u6784\u5177\u6709\u6765\u81ea\u8f93\u5165\u56fe\u50cf\u7684\u591a\u4e2a\u4e0b\u91c7\u6837\u5c42\u3002 \u2003\u6700\u540e\uff0c\u5f53\u6211\u4eec\u8bad\u7ec3\u4e00\u4e2a\u8fd1\u4f3c\u68c0\u6d4b\u6027\u80fd\u7684\u635f\u5931\u51fd\u6570\u65f6\uff0c\u6211\u4eec\u7684\u635f\u5931\u51fd\u6570\u5bf9\u5f85\u5c0f\u8fb9\u754c\u6846\u4e0e\u5927\u8fb9\u754c\u6846\u7684\u4f1a\u6709\u540c\u6837\u7684\u8bef\u5dee\u3002\u5927\u8fb9\u754c\u6846\u7684\u5c0f\u8bef\u5dee\u901a\u5e38\u662f\u826f\u6027\u7684\uff0c\u4f46\u5c0f\u8fb9\u754c\u6846\u7684\u5c0f\u8bef\u5dee\u5bf9 \\(IOU\\) \u7684\u5f71\u54cd\u8981\u5927\u5f97\u591a\u3002\u6211\u4eec\u7684\u4e3b\u8981\u8bef\u5dee\u6765\u6e90\u662f\u5b9a\u4f4d\u8bef\u5dee\u3002 3. \u4e0e\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u7684\u6bd4\u8f83 \u2003\u76ee\u6807\u68c0\u6d4b\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u6838\u5fc3\u95ee\u9898\u3002\u68c0\u6d4b\u6d41\u7a0b\u901a\u5e38\u4ece\u8f93\u5165\u56fe\u50cf\u4e0a\u63d0\u53d6\u4e00\u7ec4\u5065\u58ee\u7684\u7279\u5f81\uff08 \\(Haar\\) [25]\uff0c \\(SIFT\\) [23]\uff0c \\(HOG\\) [4]\uff0c\u5377\u79ef\u7279\u5f81[6]\uff09\u5f00\u59cb\u3002\u7136\u540e\uff0c\u5206\u7c7b\u5668[36,21,13,10]\u6216\u5b9a\u4f4d\u5668[1,32]\u88ab\u7528\u6765\u8bc6\u522b\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u76ee\u6807\u3002 \u8fd9\u4e9b\u5206\u7c7b\u5668\u6216\u5b9a\u4f4d\u5668\u4ee5\u6ed1\u52a8\u7a97\u53e3\u7684\u65b9\u5f0f\u5728\u6574\u4e2a\u56fe\u50cf\u4e0a\u8fd0\u884c,\u6216\u8005\u5728\u56fe\u50cf\u4e2d\u7684\u4e00\u4e9b\u533a\u57df\u7684\u5b50\u96c6[35,15,39]\u4e0a\u3002 \u6211\u4eec\u5c06 \\(YOLO\\) \u68c0\u6d4b\u7cfb\u7edf\u4e0e\u51e0\u79cd\u9876\u7ea7\u68c0\u6d4b\u6846\u67b6\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u7a81\u51fa\u4e86\u4e3b\u8981\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\u3002 \u2003 \u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b \uff08 Deformable parts models \uff09\u3002\u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b\uff08 \\(DPM\\) \uff09\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b[10]\u3002DPM\u4f7f\u7528\u4e0d\u76f8\u4ea4\u7684\u6d41\u7a0b\u6765\u63d0\u53d6\u9759\u6001\u7279\u5f81\uff0c\u5bf9\u533a\u57df\u8fdb\u884c\u5206\u7c7b\uff0c\u9884\u6d4b\u9ad8\u8bc4\u5206\u533a\u57df\u7684\u8fb9\u754c\u6846\u7b49\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u7528\u5355\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u66ff\u6362\u6240\u6709\u8fd9\u4e9b\u4e0d\u540c\u7684\u90e8\u5206\u3002\u7f51\u7edc\u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3001\u8fb9\u754c\u6846\u9884\u6d4b\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u3002\u7f51\u7edc\u5185\u5d4c\u8bad\u7ec3\u7279\u5f81\u800c\u4e0d\u662f\u9759\u6001\u7279\u5f81\uff0c\u5e76\u4f18\u5316\u5b83\u4eec\u5b8c\u6210\u68c0\u6d4b\u4efb\u52a1\u3002\u6211\u4eec\u7684\u7edf\u4e00\u67b6\u6784\u83b7\u5f97\u4e86\u6bd4DPM\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u6a21\u578b\u3002 \u2003 \\(R-CNN\\) \u53ca\u5176\u53d8\u79cd\u4f7f\u7528 \\(region \\ proposals\\) \u800c\u4e0d\u662f\u6ed1\u52a8\u7a97\u53e3\u6765\u67e5\u627e\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u3002Selective Search[35]\u4ea7\u751f\u6f5c\u5728\u7684\u8fb9\u754c\u6846\u3001\u5377\u79ef\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\u3001 \\(SVM\\) \u5bf9\u8fb9\u754c\u6846\u8fdb\u884c\u8bc4\u5206\u3001\u7ebf\u6027\u6a21\u578b\u8c03\u6574\u8fb9\u754c\u6846\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u6d88\u9664\u91cd\u590d\u68c0\u6d4b\u3002\u8fd9\u4e2a\u590d\u6742\u6d41\u7a0b\u7684\u6bcf\u4e2a\u9636\u6bb5\u90fd\u5fc5\u987b\u72ec\u7acb\u5730\u8fdb\u884c\u7cbe\u786e\u8c03\u6574\uff0c\u6240\u5f97\u5230\u7684\u7cfb\u7edf\u975e\u5e38\u6162\uff0c\u6d4b\u8bd5\u65f6\u6bcf\u5f20\u56fe\u50cf\u9700\u8981\u8d85\u8fc740\u79d2[14]\u3002 \\(YOLO\\) \u4e0e $R-CNN $ \u6709\u4e00\u4e9b\u76f8\u4f3c\u4e4b\u5904\u3002\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u63d0\u51fa\u6f5c\u5728\u7684\u8fb9\u754c\u6846\u5e76\u4f7f\u7528\u5377\u79ef\u7279\u5f81\u5bf9\u8fd9\u4e9b\u6846\u8fdb\u884c\u8bc4\u5206\u3002\u4f46\u662f\u6211\u4eec\u7684\u7cfb\u7edf\u5bf9\u7f51\u683c\u5355\u5143\u63d0\u51fa\u8fdb\u884c\u4e86\u7a7a\u95f4\u9650\u5236\uff0c\u8fd9\u6709\u52a9\u4e8e\u7f13\u89e3\u5bf9\u540c\u4e00\u76ee\u6807\u7684\u591a\u6b21\u68c0\u6d4b\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u8fd8\u63d0\u51fa\u4e86\u66f4\u5c11\u7684\u8fb9\u754c\u6846\uff0c\u6bcf\u5f20\u56fe\u50cf\u53ea\u6709 \\(98\\) \u4e2a\uff0c\u800c \\(Selective Search\\) \u5219\u9700\u8981 \\(2000\\) \u4e2a\u5de6\u53f3\u3002\u6700\u540e\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u8fd9\u4e9b\u5355\u72ec\u7684\u7ec4\u4ef6\u7ec4\u5408\u6210\u4e00\u4e2a\u5355\u4e00\u7684\u3001\u5171\u540c\u4f18\u5316\u7684\u6a21\u578b\u3002 \u2003 \u5176\u5b83\u5feb\u901f\u68c0\u6d4b\u5668( Other Fast Detectors ) \u3002 \\(Fast\\) \u548c \\(Faster \\ R-CNN\\) \u901a\u8fc7\u5171\u4eab\u8ba1\u7b97\u548c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3 \\(Selective \\ Search\\) \u6765\u63d0\u51fa\u533a\u57df\u52a0\u901f \\(R-CNN\\) \u6846\u67b6[14][28]\u3002\u867d\u7136\u5b83\u4eec\u63d0\u4f9b\u4e86\u6bd4 \\(R-CNN\\) \u66f4\u5feb\u7684\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u5ea6\uff0c\u4f46\u4e24\u8005\u4ecd\u7136\u4e0d\u80fd\u8fbe\u5230\u5b9e\u65f6\u6027\u80fd\u3002 \u2003\u8bb8\u591a\u7814\u7a76\u5de5\u4f5c\u96c6\u4e2d\u5728\u52a0\u5feb \\(DPM\\) \u6d41\u7a0b\u4e0a[31][38][5]\u3002\u5b83\u4eec\u52a0\u901f \\(HOG\\) \u8ba1\u7b97\uff0c\u4f7f\u7528\u7ea7\u8054\uff0c\u5e76\u5c06\u8ba1\u7b97\u63a8\u52a8\u5230 \\(GPU\\) \u4e0a\u3002\u4f46\u662f\uff0c\u5b9e\u9645\u4e0a \\(DPM\\) [31]\u5b9e\u65f6\u8fd0\u884c\u53ea\u8fbe\u5230 \\(30Hz\\) \u3002 \u2003 \\(YOLO\\) \u4e0d\u662f\u8bd5\u56fe\u4f18\u5316\u5927\u578b\u68c0\u6d4b\u6d41\u7a0b\u7684\u5355\u4e2a\u7ec4\u4ef6\uff0c\u800c\u662f\u5b8c\u5168\u629b\u5f03\u6d41\u7a0b\uff0c\u4e3a\u63d0\u5347\u68c0\u6d4b\u901f\u5ea6\u800c\u91cd\u65b0\u8bbe\u8ba1\u3002 \u2003\u50cf\u4eba\u8138\u6216\u884c\u4eba\u7b49\u5355\u7c7b\u522b\u7684\u68c0\u6d4b\u5668\u53ef\u4ee5\u88ab\u9ad8\u5ea6\u4f18\u5316\uff0c\u56e0\u4e3a\u4ed6\u4eec\u53ea\u9700\u5904\u7406\u66f4\u5c11\u7684\u591a\u6837\u6027[37]\u3002 \\(YOLO\\) \u662f\u4e00\u79cd\u901a\u7528\u7684\u68c0\u6d4b\u5668\uff0c\u53ef\u4ee5\u5b66\u4e60\u540c\u65f6\u68c0\u6d4b\u5404\u79cd\u76ee\u6807\u3002 \u2003 Deep MultiBox :\u4e0eR-CNN\u4e0d\u540c\uff0cSzegedy\u7b49\u4eba\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u611f\u5174\u8da3\u533a\u57df\uff08 ROI \uff09[8]\uff0c\u800c\u4e0d\u662f\u4f7f\u7528 \\(Selective \\ Search\\) \u3002MultiBox\u8fd8\u53ef\u4ee5\u901a\u8fc7\u7528\u5355\u7c7b\u522b\u9884\u6d4b\u66ff\u6362\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u6765\u6267\u884c\u5355\u76ee\u6807\u68c0\u6d4b\u3002\u7136\u800c\uff0c \\(MultiBox\\) \u65e0\u6cd5\u6267\u884c\u901a\u7528\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u5e76\u4e14\u4ecd\u7136\u53ea\u662f\u4e00\u4e2a\u8f83\u5927\u7684\u68c0\u6d4b\u6d41\u7a0b\u4e2d\u7684\u4e00\u90e8\u5206\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u5bf9\u56fe\u50cf\u5757\u8fdb\u884c\u5206\u7c7b\u3002 \\(YOLO\\) \u548c \\(MultiBox\\) \u90fd\u4f7f\u7528\u5377\u79ef\u7f51\u7edc\u6765\u9884\u6d4b\u56fe\u50cf\u4e2d\u7684\u8fb9\u754c\u6846\uff0c\u4f46\u662f \\(YOLO\\) \u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002 \u2003 \\(OverFeat\\) :Sermanet\u7b49\u4eba\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u5b9a\u4f4d\u5de5\u4f5c\uff0c\u5e76\u4f7f\u8be5\u5b9a\u4f4d\u5668\u8fdb\u884c\u68c0\u6d4b[32]\u3002 \\(OverFeat\\) \u53ef\u4ee5\u9ad8\u6548\u5730\u6267\u884c\u6ed1\u52a8\u7a97\u53e3\u68c0\u6d4b\uff0c\u4f46\u5b83\u4ecd\u7136\u662f\u4e00\u4e2a\u4e0d\u8fde\u8d2f\u7684\u7cfb\u7edf\u3002 \\(OverFeat\\) \u4f18\u5316\u4e86\u5b9a\u4f4d\uff0c\u800c\u4e0d\u662f\u68c0\u6d4b\u6027\u80fd\u3002\u50cf \\(DPM\\) \u4e00\u6837\uff0c\u5b9a\u4f4d\u5668\u5728\u8fdb\u884c\u9884\u6d4b\u65f6\u53ea\u80fd\u770b\u5230\u5c40\u90e8\u4fe1\u606f\u3002 \\(OverFeat\\) \u4e0d\u80fd\u63a8\u7406\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u56e0\u6b64\u9700\u8981\u5927\u91cf\u7684\u540e\u5904\u7406\u6765\u4ea7\u751f\u4e00\u81f4\u7684\u68c0\u6d4b\u3002 \u2003 \\(MultiGrasp\\) : \u6211\u4eec\u7684\u5de5\u4f5c\u5728\u8bbe\u8ba1\u4e0a\u7c7b\u4f3c\u4e8e \\(Redmon\\) \u7b49[27]\u7684 \\(grasp\\) \u68c0\u6d4b\u3002\u6211\u4eec\u5bf9\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u7f51\u683c\u65b9\u6cd5\u662f\u57fa\u4e8e \\(MultiGrasp\\) \u7cfb\u7edf\u5bf9\u4e8e \\(grasp\u68c0\u6d4b\\) \u7684\u56de\u5f52\u5206\u6790\u3002\u7136\u800c\uff0c \\(grasp\\) \u68c0\u6d4b\u6bd4\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u8981\u7b80\u5355\u5f97\u591a\u3002 \\(MultiGrasp\\) \u53ea\u9700\u8981\u4e3a\u5305\u542b\u4e00\u4e2a\u76ee\u6807\u7684\u56fe\u50cf\u9884\u6d4b\u4e00\u4e2a\u53ef\u4ee5 \\(grasp\\) \u7684\u533a\u57df( \u5373\u9002\u5408\u6293\u53d6\u7684\u533a\u57df )\u3002\u4e0d\u5fc5\u4f30\u8ba1\u76ee\u6807\u7684\u5927\u5c0f\u3001\u4f4d\u7f6e\u6216\u76ee\u6807\u8fb9\u754c\u6216\u9884\u6d4b\u76ee\u6807\u7684\u7c7b\u522b\uff0c\u53ea\u9700\u8981\u627e\u5230\u9002\u5408\u6293\u53d6\u7684\u533a\u57df\u3002 \\(YOLO\\) \u53ef\u4ee5\u9884\u6d4b\u56fe\u50cf\u4e2d\u591a\u4e2a\u7c7b\u522b\u7684\u591a\u4e2a\u76ee\u6807\u7684\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u3002 4. \u6d4b\u8bd5\u5b9e\u9a8c \u9996\u5148\uff0c\u6211\u4eec\u5728 \\(PASCAL \\ VOC \\ 2007\\) \u4e0a\u6bd4\u8f83\u4e86 \\(YOLO\\) \u548c\u5176\u5b83\u7684\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf\u3002\u4e3a\u4e86\u7406\u89e3 \\(YOLO\\) \u548c \\(R-CNN\\) \u53d8\u79cd\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u63a2\u7d22\u4e86 \\(YOLO\\) \u548c \\(R-CNN\\) \u6027\u80fd\u6700\u9ad8\u7684\u7248\u672c\u4e4b\u4e00 \\(Fast\\ R-CNN\\) [14]\u5728 \\(VOC \\ 2007\\) \u4e0a\u9519\u8bef\u7387\u3002\u6839\u636e\u4e0d\u540c\u7684\u8bef\u5dee\u66f2\u7ebf\uff0c\u6211\u4eec\u7684\u7814\u7a76\u663e\u793a \\(YOLO\\) \u53ef\u4ee5\u7528\u6765\u91cd\u65b0\u8bc4\u4f30 \\(Fast \\ R-CNN\\) \u68c0\u6d4b\uff0c\u5e76\u51cf\u5c11\u80cc\u666f\u5047\u9633\u6027\u5e26\u6765\u7684\u8bef\u5dee\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u5728 \\(VOC \\ 2012\\) \u4e0a\u7684\u7ed3\u679c\uff0c\u5e76\u4e0e\u76ee\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u6bd4\u8f83\u4e86 \\(mAP\\) \u3002\u6700\u540e\uff0c\u5728\u4e24\u4e2a\u827a\u672f\u54c1\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86\u6211\u4eec \\(YOLO\\) \u6bd4\u5176\u4ed6\u68c0\u6d4b\u5668\u66f4\u80fd\u6cdb\u5316\u5230\u65b0\u7684\u9886\u57df\u3002 4.1 \u4e0e\u5176\u4ed6\u5b9e\u65f6\u7cfb\u7edf\u7684\u6bd4\u8f83 \u2003\u76ee\u6807\u68c0\u6d4b\u65b9\u9762\u7684\u8bb8\u591a\u7814\u7a76\u5de5\u4f5c\u90fd\u96c6\u4e2d\u5728\u5bf9\u6807\u51c6\u68c0\u6d4b\u6d41\u7a0b[5]\uff0c[38]\uff0c[31]\uff0c[14]\uff0c[17]\uff0c[28]\u63d0\u5347\u901f\u5ea6\u4e0a\u3002\u7136\u800c\uff0c\u53ea\u6709Sadeghi\u7b49\u771f\u6b63\u7814\u7a76\u51fa\u4e86\u4e00\u4e2a\u5b9e\u65f6\u8fd0\u884c\u7684\u68c0\u6d4b\u7cfb\u7edf\uff08\u6bcf\u79d230\u5e27\u6216\u66f4\u597d\uff09[31]\u3002\u6211\u4eec\u5c06YOLO\u4e0e\u4ed6\u4eecDPM\u7684GPU\u5b9e\u73b0\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5176\u572830Hz\u6216100Hz\u4e0b\u8fd0\u884c\u3002\u867d\u7136\u5176\u5b83\u7684\u7814\u7a76\u5de5\u4f5c\u6ca1\u6709\u8fbe\u5230\u5b9e\u65f6\u68c0\u6d4b\u7684\u6807\u51c6\uff0c\u6211\u4eec\u4e5f\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u76f8\u5bf9mAP\u548c\u901f\u5ea6\u6765\u68c0\u67e5\u76ee\u6807\u68c0\u6d4b\u7cfb\u7edf\u4e2d\u7cbe\u5ea6\u2014\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002 \u2003 \\(Fast \\ YOLO\\) \u662f \\(PASCAL\\) \u4e0a\u6700\u5feb\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5;\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u662f\u73b0\u5b58\u901f\u5ea6\u6700\u5feb\u7684\u7269\u4f53\u63a2\u6d4b\u5668\u3002 \\(mAP\\) \u7684\u51c6\u786e\u7387\u4e3a \\(52.7%\\) \uff0c\u662f\u4e4b\u524d\u5b9e\u65f6\u68c0\u6d4b\u5de5\u4f5c\u7684\u4e24\u500d\u591a\u3002 \\(YOLO\\) \u5c06 \\(mAP\\) \u63a8\u81f3 \\(63.4%\\) \uff0c\u540c\u65f6\u4ecd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002 \u2003\u6211\u4eec\u4e5f\u4f7f\u7528 \\(VGG-16\\) \u8bad\u7ec3\u4e86 \\(YOLO\\) \u3002\uff08 \u8bd1\u8005\u6ce8\uff1aYOLO\u4f7f\u7528\u4e86\u4f5c\u8005\u81ea\u5df1\u5f00\u53d1\u7684DarkNet\u6a21\u578b\u4e3abaseline \uff09\u8fd9\u4e2a\u6a21\u578b\u6bd4 \\(YOLO\\) \u66f4\u51c6\u786e\uff0c\u4f46\u901f\u5ea6\u6162\u5f97\u591a\u3002\u8fd9\u4e2a\u6a21\u578b\u53ef\u4ee5\u7528\u6765\u4e0e\u4f9d\u8d56\u4e8e \\(VGG-16\\) \u7684\u5176\u5b83\u68c0\u6d4b\u7cfb\u7edf\u4f5c\u6bd4\u8f83\uff0c\u4f46\u7531\u4e8e\u5b83\u6bd4\u5b9e\u65f6\u7684 \\(YOLO\\) \u66f4\u6162\uff0c\u672c\u6587\u7684\u5176\u4f59\u90e8\u5206\u4e3b\u8981\u5173\u6ce8\u6211\u4eec\u66f4\u5feb\u7684\u6a21\u578b\u3002 \u2003 \\(Fastest \\ DPM\\) \u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u592a\u591a \\(mAP\\) \u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5730\u52a0\u901f \\(DPM\\) \uff0c\u4f46\u5b83\u4ecd\u7136\u4f1a\u5c06\u5b9e\u65f6\u6027\u80fd\u964d\u4f4e2\u500d[38]\u3002\u4e0e\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u76f8\u6bd4\uff0c \\(DPM\\) \u76f8\u5bf9\u8f83\u4f4e\u7684\u68c0\u6d4b\u7cbe\u5ea6\u4e5f\u662f\u5176\u9650\u5236\u3002 \\(\\begin{array}{lrrr} \\text { Real-Time Detectors } & \\text { Train } & \\text { mAP } & \\text { FPS } \\\\ \\hline \\text { 100Hz DPM [31] } & 2007 & 16.0 & 100 \\\\ \\text { 30Hz DPM [31] } & 2007 & 26.1 & 30 \\\\ \\text { Fast YOLO } & 2007+2012 & 52.7 & \\mathbf{1 5 5} \\\\ \\text { YOLO } & 2007+2012 & \\mathbf{6 3 . 4} & 45 \\\\ \\hline \\hline \\text { Less Than Real-Time } & & & \\\\ \\hline \\text { Fastest DPM [38] } & 2007 & 30.4 & 15 \\\\ \\text { R-CNN Minus R [20] } & 2007 & 53.5 & 6 \\\\ \\text { Fast R-CNN [14] } & 2007+2012 & 70.0 & 0.5 \\\\ \\text { Faster R-CNN VGG-16[28] } & 2007+2012 & 73.2 & 7 \\\\ \\text { Faster R-CNN ZF [28] } & 2007+2012 & 62.1 & 18 \\\\ \\text { YOLO VGG-16 } & 2007+2012 & 66.4 & 21 \\end{array}\\) \u88681\uff1aPASCAL VOC 2007 \u7684\u5b9e\u65f6\u7cfb\u7edf \u6bd4\u8f83\u5feb\u901f\u63a2\u6d4b\u5668\u7684\u6027\u80fd\u548c\u901f\u5ea6\u3002 \\(Fast \\ YOLO\\) \u662f \\(PASCAL \\ VOC\\) \u68c0\u6d4b\u8bb0\u5f55\u4e2d\u6700\u5feb\u7684\u68c0\u6d4b\u5668\uff0c\u51c6\u786e\u6027\u4ecd\u7136\u662f\u4efb\u4f55\u5176\u4ed6\u5b9e\u65f6\u68c0\u6d4b\u5668\u7684\u4e24\u500d\u3002 \\(YOLO\\) \u6bd4\u5feb\u901f\u7248\u672c\u66f4\u7cbe\u786e \\(10mAP\\) \uff0c\u540c\u65f6\u5b9e\u65f6\u901f\u5ea6\u8fdc\u8fdc\u9ad8\u4e8e\u5176\u4ed6\u68c0\u6d4b\u5668\u3002 \u2003 \\(R-CNN \\ minnus \\ R\\) \u5c06\u9009\u62e9\u6027\u641c\u7d22\u66ff\u6362\u4e3a\u9759\u6001\u8fb9\u754c\u6846proposals [20]\u3002\u867d\u7136\u901f\u5ea6\u6bd4R-CNN\u66f4\u5feb\uff0c\u4f46\u4ecd\u7136\u8fbe\u4e0d\u5230\u5b9e\u65f6\uff0c\u5e76\u4e14\u7531\u4e8e\u6ca1\u6709\u597d\u7684\u8fb9\u754c\u6846proposals\uff0c\u51c6\u786e\u6027\u53d7\u5230\u4e86\u4e25\u91cd\u5f71\u54cd\u3002 \u2003 \\(Fast \\ R-CNN\\) \u52a0\u5feb\u4e86 \\(R-CNN\\) \u7684\u5206\u7c7b\u9636\u6bb5\uff0c\u4f46\u662f\u4ecd\u7136\u4f9d\u8d56selective search\uff0c\u6bcf\u5f20\u56fe\u50cf\u9700\u8981\u82b1\u8d39\u5927\u7ea62\u79d2\u6765\u751f\u6210\u8fb9\u754c\u6846proposals\u3002\u56e0\u6b64\uff0c\u5b83\u5177\u6709\u5f88\u9ad8\u7684mAP\uff0c\u4f46\u662f0.5 fps\u7684\u901f\u5ea6\u4ecd\u79bb\u5b9e\u65f6\u6027\u5f88\u8fdc\u3002 \u2003 \u6700\u8fd1 \\(Faster \\ R-CNN\\) \u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u4e86selective search\u6765\u63d0\u51fa\u8fb9\u754c\u6846\uff0c\u7c7b\u4f3c\u4e8eSzegedy\u7b49[8]\u3002\u5728\u6211\u4eec\u7684\u6d4b\u8bd5\u4e2d\uff0c\u4ed6\u4eec\u6700\u7cbe\u786e\u7684\u6a21\u578b\u8fbe\u5230\u4e867fps\uff0c\u800c\u8f83\u5c0f\u7684\u3001\u4e0d\u592a\u7cbe\u786e\u7684\u6a21\u578b\u8fd0\u884c\u901f\u5ea6\u8fbe\u523018fps\u3002 \\(VGG-16\\) \u7248\u672c\u7684 \\(Faster \\ R-CNN\\) \u8981\u9ad8\u51fa \\(10mAP\\) \uff0c\u4f46\u901f\u5ea6\u6bd4 \\(YOLO\\) \u6162 \\(6\\) \u500d\u3002ZeilerFergus\u7684 \\(Faster \\ R-CNN\\) \u53ea\u6bd4 \\(YOLO\\) \u6162\u4e862.5\u500d\uff0c\u4f46\u4e5f\u4e0d\u592a\u51c6\u786e\u3002 4.2 \u5728VOC 2007\u4e0a\u7684\u8bef\u5dee\u5206\u6790 \u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u68c0\u67e5 \\(YOLO\\) \u548c\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u8be6\u7ec6\u5206\u6790\u4e86 \\(VOC \\ 2007\\) \u7684\u7ed3\u679c\u3002\u6211\u4eec\u5c06 \\(YOLO\\) \u4e0e \\(Fast \\ R-CNN\\) \u8fdb\u884c\u6bd4\u8f83\uff0c\u56e0\u4e3a \\(Fast \\ R-CNN\\) \u662f \\(PASCAL\\) \u4e0a\u6027\u80fd\u6700\u9ad8\u7684\u68c0\u6d4b\u5668\u4e4b\u4e00\u5e76\u4e14\u5b83\u7684\u68c0\u6d4b\u4ee3\u7801\u662f\u53ef\u516c\u5f00\u5f97\u5230\u7684\u3002 \u2003\u6211\u4eec\u4f7f\u7528Hoiem\u7b49\u4eba[19]\u7684\u65b9\u6cd5\u548c\u5de5\u5177\u3002\u5bf9\u4e8e\u6d4b\u8bd5\u65f6\u7684\u6bcf\u4e2a\u7c7b\u522b\uff0c\u6211\u4eec\u53ea\u5173\u6ce8\u8fd9\u4e2a\u7c7b\u522b\u7684\u524dN\u4e2a\u9884\u6d4b\u3002\u6bcf\u4e2a\u9884\u6d4b\u8981\u4e48\u5f52\u4e3a\u6b63\u786e\uff0c\u8981\u4e48\u6839\u636e\u9519\u8bef\u7c7b\u578b\u8fdb\u884c\u5f52\u7c7b\uff1a Correct\uff1a\u5206\u7c7b\u6b63\u786e\u4e14 \\(IOU >0.5\\) \u3002 Localization\uff1a\u5206\u7c7b\u6b63\u786e\u4f46 \\(0.1<IOU<0.5\\) \u3002 Similar\uff1a\u5206\u7c7b\u7684\u7c7b\u522b\u76f8\u4f3c\u4e14 \\(IOU>0.1\\) \u3002 Other\uff1a\u7c7b\u522b\u9519\u8bef\uff0c \\(IOU>0.1\\) \u3002 Background\uff1a\u5206\u7c7b\u4e3a\u5176\u5b83\u4efb\u4f55\u76ee\u6807\uff0c \\(IOU<0.1\\) \u3002 \u56fe4\uff1a\u9519\u8bef\u5206\u6790: \\(Fast \\ R-CNN\\) vs. \\(YOLO\\) \u8fd9\u4e9b\u56fe\u8868\u663e\u793a\u4e86\u5404\u79cd\u7c7b\u522b\u7684\u524dN\u4e2a\u68c0\u6d4b\u4e2d\u5b9a\u4f4d\u548c\u80cc\u666f\u9519\u8bef\u7684\u767e\u5206\u6bd4(N = #\u8be5\u7c7b\u522b\u4e2d\u7684\u76ee\u6807\u6570) \u2003 \\(YOLO\\) \u5f88\u96be\u6b63\u786e\u6b63\u786e\u5b9a\u4f4d\u76ee\u6807\u3002\u5b9a\u4f4d\u8bef\u5dee\u6bd4\u5176\u5b83\u8bef\u5dee\u9519\u8bef\u6765\u6e90\u603b\u5408\u90fd\u591a\u3002 \\(Fast \\ R-CNN\\) \u5b9a\u4f4d\u8bef\u5dee\u5c11\u5f88\u591a\uff0c\u4f46\u80cc\u666f\u8bef\u5dee\u66f4\u591a\u3002\u5b83\u7684\u68c0\u6d4b\u7ed3\u679c\u4e2d \\(13.6%\\) \u662f\u4e0d\u5305\u542b\u4efb\u4f55\u76ee\u6807\u7684\u5047\u9633\u6027\u3002 \\(Fast \\ R-CNN\\) \u4e0e \\(YOLO\\) \u76f8\u6bd4\uff0c\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u76ee\u6807\u7684\u53ef\u80fd\u6027\u9ad8\u51fa\u8fd13\u500d\u3002\uff08 \u8bd1\u8005\u6ce8\uff1a\u6839\u636e\u56fe4\uff0c13.6/4.75=2.86 \uff09 4.3 \u7ed3\u5408 \\(Fast \\ R-CNN\\) \u548c \\(YOLO\\) \u2003 \\(YOLO\\) \u6bd4 \\(Fast \\ R-CNN\\) \u7684\u80cc\u666f\u8bef\u68c0\u8981\u5c11\u5f97\u591a\u3002\u901a\u8fc7\u4f7f\u7528 \\(YOLO\\) \u6d88\u9664 \\(Fast \\ R-CNN\\) \u7684\u80cc\u666f\u68c0\u6d4b\uff0c\u6211\u4eec\u83b7\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u5bf9\u4e8e \\(RCNN\\) \u9884\u6d4b\u7684\u6bcf\u4e2a\u8fb9\u754c\u6846\uff0c\u6211\u4eec\u68c0\u67e5 \\(YOLO\\) \u662f\u5426\u9884\u6d4b\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u7684\u6846\u3002\u5982\u679c\u662f\u8fd9\u6837\uff0c\u6211\u4eec\u6839\u636e \\(YOLO\\) \u9884\u6d4b\u7684\u6982\u7387\u548c\u4e24\u4e2a\u76d2\u5b50\u4e4b\u95f4\u7684\u91cd\u53e0\u6765\u5bf9\u8fd9\u4e2a\u9884\u6d4b\u8fdb\u884c\u6539\u8fdb\u3002 \u2003\u6700\u597d\u7684 \\(Fast \\ R-CNN\\) \u6a21\u578b\u5728 \\(VOC \\ 2007\\) \u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230\u4e86 71.8%\u7684 \\(mAP\\) \u3002\u5f53\u4e0e \\(YOLO\\) \u7ed3\u5408\u65f6\uff0c\u5176 \\(mAP\\) \u589e\u52a0\u4e86 3.2% \u8fbe\u5230\u4e86 75.0% \u3002\u6211\u4eec\u4e5f\u5c1d\u8bd5\u5c06\u6700\u597d\u7684 \\(Fast \\ R-CNN\\) \u6a21\u578b\u4e0e\u5176\u5b83\u51e0\u4e2a\u7248\u672c\u7684 \\(Fast \\ R-CNN\\) \u7ed3\u5408\u8d77\u6765\u3002\u8fd9\u4e9b\u6a21\u578b\u7ec4\u5408\u4ea7\u751f\u4e860.3-0.6%\u7684\u5c0f\u5e45\u589e\u52a0\uff0c\u8be6\u89c1\u88682\u3002 \\(\\begin{array}{lrrr} & \\text { mAP } & \\text { Combined } & \\text { Gain } \\\\ \\hline \\text { Fast R-CNN } & 71.8 & - & - \\\\ \\hline \\text { Fast R-CNN (2007 data) } & \\mathbf{6 6 . 9} & 72.4 & .6 \\\\ \\text { Fast R-CNN (VGG-M) } & 59.2 & 72.4 & .6 \\\\ \\text { Fast R-CNN (CaffeNet) } & 57.1 & 72.1 & .3 \\\\ \\text { YOLO } & 63.4 & \\mathbf{7 5 . 0} & \\mathbf{3 . 2} \\end{array}\\) \u88682:VOC 2007\u7684\u6a21\u578b\u7ec4\u5408\u8bd5\u9a8c\u3002\u6211\u4eec\u7528 \\(Fast \\ R-CNN\\) \u7684\u6700\u4f73\u7248\u672c\u6765\u68c0\u9a8c\u5404\u79cd\u6a21\u578b\u7684\u7ec4\u5408\u6548\u679c\u3002 \\(Fast \\ R-CNN\\) \u7684\u5176\u4ed6\u7248\u672c\u53ea\u6539\u5584\u4e86\u5f88\u5c0f\u7684\u6027\u80fd\uff0c\u800c \\(YOLO\\) \u63d0\u4f9b\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002 \u88683:PASCAL VOC 2012\u6392\u884c\u699c\u30022015\u5e7411\u67086\u65e5\uff0cYOLO\u4e0e\u5b8c\u6574comp4(\u5141\u8bb8\u5916\u90e8\u6570\u636e)\u516c\u5f00\u6392\u884c\u699c\u7684\u5bf9\u6bd4\u3002 \\(mAP\\) \u548c \u6bcf\u4e2a\u7c7bAP \u90fd\u663e\u793a\u5728\u5404\u79cd\u68c0\u6d4b\u65b9\u6cd5\u3002 \\(YOLO\\) \u662f\u552f\u4e00\u7684\u5b9e\u65f6\u68c0\u6d4b\u5668\u3002 \\(Fast \\ R-CNN + YOLO\\) \u662f\u7b2c\u56db\u9ad8\u7684\u5f97\u5206\u65b9\u6cd5\uff0c\u6bd4 \\(Fast \\ R-CNN\\) \u63d0\u9ad8\u4e862.3%\u7684 \\(mAP\\) \u3002 \u2003\u6765\u81eaYOLO\u7684\u63d0\u5347\u4e0d\u4ec5\u4ec5\u662f\u6a21\u578b\u96c6\u6210\u7684\u526f\u4ea7\u54c1\uff0c\u56e0\u4e3a\u7ec4\u5408\u4e0d\u540c\u7248\u672c\u7684Fast R-CNN\u51e0\u4e4e\u6ca1\u6709\u4ec0\u4e48\u6539\u8fdb\u3002\u76f8\u53cd\uff0c\u6b63\u662f\u56e0\u4e3a \\(YOLO\\) \u5728\u6d4b\u8bd5\u65f6\u51fa\u73b0\u4e86\u5404\u79cd\u5404\u6837\u7684\u8bef\u5dee\uff0c\u6240\u4ee5\u5728\u63d0\u9ad8 \\(Fast \\ R-CNN\\) \u7684\u6027\u80fd\u65b9\u9762\u975e\u5e38\u6709\u6548\u3002 \u2003\u9057\u61be\u7684\u662f\uff0c\u8fd9\u4e2a\u7ec4\u5408\u5e76\u6ca1\u6709\u4ece \\(YOLO\\) \u7684\u901f\u5ea6\u4e2d\u53d7\u76ca\uff0c\u56e0\u4e3a\u6211\u4eec\u5206\u522b\u8fd0\u884c\u6bcf\u4e2a\u6a21\u578b\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u7ec4\u5408\u8d77\u6765\u3002\u4f46\u662f\uff0c\u7531\u4e8e \\(YOLO\\) \u901f\u5ea6\u5982\u6b64\u4e4b\u5feb\uff0c\u4e0e \\(Fast \\ R-CNN\\) \u76f8\u6bd4\uff0c\u4e0d\u4f1a\u663e\u8457\u7684\u589e\u52a0\u4efb\u4f55\u8ba1\u7b97\u65f6\u95f4\u3002 4.4 VOC 2012\u6761\u7ed3\u679c \u2003\u5728 \\(VOC \\ 2012\\) \u6d4b\u8bd5\u96c6\u4e0a\uff0c \\(YOLO\\) \u83b7\u5f97\u4e8657.9% \u7684 \\(mAP\\) \u3002\u8fd9\u4f4e\u4e8e\u73b0\u6709\u7684\u6700\u597d\u6280\u672f\uff0c\u5982\u88683\u6240\u793a\u5176\u63a5\u8fd1\u4e8e\u4f7f\u7528VGG-16\u7684\u539f\u59cbR-CNN\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u4e0e\u5176\u6700\u63a5\u8fd1\u7684\u7ade\u4e89\u5bf9\u624b\u76f8\u6bd4\uff0c\u9700\u8981\u6539\u5584\u5728\u5c0f\u76ee\u6807\u4e0a\u7684\u68c0\u6d4b\u3002\u5728\u6c34\u74f6\u3001\u7ef5\u7f8a\u548c\u7535\u89c6/\u663e\u793a\u5668\u7b49\u7c7b\u522b\u4e0a\uff0cYOLO\u7684\u5f97\u5206\u6bd4R-CNN\u6216Feature Edit\u4f4e8\u221210%\u3002\u7136\u800c\uff0c\u5728\u732b\u548c\u706b\u8f66\u7b49\u5176\u5b83\u7c7b\u522b\u4e0aYOLO\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u3002 \u2003\u6211\u4eec\u8054\u5408\u7684 \\(Fast \\ R-CNN+YOLO\\) \u6a21\u578b\u662f\u6027\u80fd\u6700\u9ad8\u7684\u68c0\u6d4b\u65b9\u6cd5\u4e4b\u4e00\u3002 \\(Fast \\ R-CNN\\) \u548c \\(YOLO\\) \u7684\u7ec4\u5408\u4e2d\u83b7\u5f97\u4e862.3%\u7684\u63d0\u9ad8\uff0c\u5728\u516c\u5f00\u6392\u884c\u699c\u4e0a\u63d0\u5347\u4e865\u4e2a\u540d\u6b21\u3002 4.5 \u6cdb\u5316\u80fd\u529b\uff1a\u827a\u672f\u54c1\u4e2d\u7684\u4eba\u7269\u68c0\u6d4b \u2003\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u672f\u6570\u636e\u96c6\u4ee5\u76f8\u540c\u5206\u5e03\u83b7\u53d6\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u3002\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u4e2d\uff0c\u5f88\u96be\u9884\u6d4b\u6240\u6709\u53ef\u80fd\u7684\u6837\u672c\uff0c\u800c\u4e14\u6d4b\u8bd5\u6570\u636e\u53ef\u80fd\u4e0e\u7cfb\u7edf\u4e4b\u524d\u770b\u5230\u7684\u4e0d\u540c[3]\u3002( \u56e0\u4e3a\u6d4b\u8bd5\u6570\u636e\u4e0e\u6a21\u578b\u8bad\u7ec3\u7684\u6570\u636e\u53ef\u80fd\u5728\u98ce\u683c\u3001\u6a21\u5f0f\u3001\u76ee\u6807\u8868\u73b0\u5f62\u5f0f\u7b49\u65b9\u9762\u6709\u5f88\u5927\u7684\u533a\u522b\uff0c\u4f8b\u5982\u6a21\u578b\u8bad\u7ec3\u65f6\u7684\u6570\u636e\u662f\u7528\u76f8\u673a\u62cd\u6444\u7684\u56fe\u50cf\uff0c\u800c\u6d4b\u8bd5\u65f6\u7528\u6cb9\u753b\u4f5c\u54c1\u56fe\u50cf\uff0c\u6b64\u65f6\u7531\u4e8e\u6cb9\u753b\u4f5c\u54c1\u6bd4\u8f83\u62bd\u8c61\uff0c\u6a21\u578b\u5c31\u53ef\u80fd\u65e0\u6cd5\u5f88\u597d\u5730\u8bc6\u522b\u5176\u4e2d\u7684\u76ee\u6807 ) \u6211\u4eec\u5728 \\(Picasso\\) \u6570\u636e\u96c6\u4e0a[12]\u548c \\(People-Art\\) \u6570\u636e\u96c6[3]\u4e0a\u5c06 \\(YOLO\\) \u4e0e\u5176\u5b83\u7684\u68c0\u6d4b\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\uff0c\u4e24\u4e2a\u6570\u636e\u96c6\u7528\u4e8e\u827a\u672f\u54c1\u4e0a\u7684\u4eba\u7269\u68c0\u6d4b\u3002 \u2003\u56fe5\u6240\u793a\u4e3a \\(YOLO\\) \u548c\u5176\u5b83\u68c0\u6d4b\u65b9\u6cd5\u4e4b\u95f4\u6027\u80fd\u6bd4\u8f83\u7684\u7ed3\u679c\u3002\u4f5c\u4e3a\u53c2\u8003\uff0c\u6211\u4eec\u5728person\u4e0a\u63d0\u4f9b \\(VOC \\ 2007\\) \u7684\u68c0\u6d4b \\(AP\\) \uff0c\u5176\u4e2d\u6240\u6709\u6a21\u578b\u4ec5\u5728 \\(VOC \\ 2007\\) \u6570\u636e\u4e0a\u8bad\u7ec3\u3002\u5728Picasso\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u7684\u6a21\u578b\u4f7f\u7528 \\(VOC \\ 2012\\) \u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u800c \\(People-Art\\) \u6570\u636e\u96c6\u6d4b\u8bd5\u7684\u6a21\u578b\u4f7f\u7528 \\(VOC \\ 2010\\) \u8fdb\u884c\u4e86\u8bad\u7ec3\u3002 \u2003 \\(R-CNN\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u7684 \\(AP\\) \u5f88\u9ad8\u3002\u4f46\u662f\u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u7cbe\u5ea6\u4e0b\u964d\u4e86\u5f88\u591a\u3002 \\(R-CNN\\) \u4f7f\u7528Selective Search\u6765\u751f\u6210\u5019\u9009\u8fb9\u754c\u6846\uff0c\u73b0\u5728\u6362\u4e3a\u81ea\u7136\u56fe\u7247\u3002\u5728\u5206\u7c7b\u65f6\u53ea\u80fd\u770b\u5230\u56fe\u7247\u7684\u4e00\u4e2a\u5c0f\u533a\u57df\uff0c\u9700\u8981\u8d28\u91cf\u5f88\u9ad8\u7684\u5019\u9009\u624d\u53ef\u4ee5\u3002 \u2003 \\(DPM\\) \u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u540e \\(AP\\) \u8fd8\u4fdd\u6301\u7684\u4e0d\u9519\u3002\u4e4b\u524d\u7684\u5de5\u4f5c\u7406\u8bba \\(DPM\\) \u8868\u73b0\u4e0d\u9519\u7684\u539f\u56e0\u662f\u5b83\u5bf9\u4e8e\u7269\u4f53\u7684\u5f62\u72b6\u548c\u5e03\u5c40\u6709\u5f88\u5f3a\u7684\u7a7a\u95f4\u6a21\u578b\u3002\u867d\u7136 \\(DPM\\) \u6ca1\u6709\u50cf \\(R-CNN\\) \u90a3\u6837\u7cbe\u5ea6\u4e0b\u964d\u5f88\u591a\uff0c\u4f46\u662f\u5b83\u7684 \\(AP\\) \u672c\u6765\u5c31\u6bd4\u8f83\u4f4e\u3002 \u2003 \\(YOLO\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u7684\u8868\u73b0\u4e0d\u9519\uff0c\u5f53\u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u65f6\u6bd4\u5176\u4ed6\u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\u7684\u5c11\u3002\u4e0e \\(DPM\\) \u7c7b\u4f3c\uff0c \\(YOLO\\) \u5bf9\u7269\u4f53\u7684\u5927\u5c0f\u548c\u5f62\u72b6\u8fdb\u884c\u5efa\u6a21\uff0c\u8fd8\u6709\u7269\u4f53\u548c\u7269\u4f53\u901a\u5e38\u51fa\u73b0\u7684\u4f4d\u7f6e\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u827a\u672f\u54c1\u548c\u81ea\u7136\u56fe\u7247\u5728\u50cf\u7d20\u7ea7\u522b\u4e0a\u5dee\u5f02\u5f88\u5927\uff0c\u4f46\u662f\u7269\u4f53\u7684\u5927\u5c0f\u548c\u5f62\u72b6\u662f\u7c7b\u4f3c\u7684\uff0c\u56e0\u6b64 \\(YOLO\\) \u4ecd\u7136\u53ef\u4ee5\u5f88\u597d\u7684\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u68c0\u6d4b\u7269\u4f53\u3002 \u56fe5\uff1aPicasso \u548c People-Art \u6570\u636e\u96c6\u7efc\u5408\u7684\u7ed3\u679c\u3002 (a): \u5728Picasso\u6570\u636e\u96c6\u4e0a\u7684PR\u66f2\u7ebf\u3002 (b): \u5728 VOC 2007, Picasso, \u548c People-Art \u7684\u7ed3\u679c\u6570\u636e\u3002Picasso \u6570\u636e\u96c6\u8bc4\u4f30AP\u548c\u6700\u4f73 \\(F_1\\) \u5206\u6570\u3002 \u56fe6\uff1a\u68c0\u6d4b\u7684\u7ed3\u679c\u3002 \\(YOLO\\) \u8fd0\u884c\u7684\u6837\u672c\u827a\u672f\u4f5c\u54c1 \u548c \u6765\u81ea\u4e92\u8054\u7f51\u7684\u81ea\u7136\u56fe\u50cf\u3002\u867d\u7136\u5b83\u786e\u5b9e\u8ba4\u4e3a\u4e00\u4e2a\u4eba\u662f\u4e00\u67b6\u98de\u673a\uff0c\u4f46\u5b83\u57fa\u672c\u4e0a\u662f\u51c6\u786e\u7684\u3002 5.\u91ce\u5916\u5b9e\u65f6\u68c0\u6d4b \u2003 \\(YOLO\\) \u662f\u4e00\u79cd\u5feb\u901f\u3001\u7cbe\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u975e\u5e38\u9002\u5408\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u3002\u6211\u4eec\u5c06 \\(YOLO\\) \u8fde\u63a5\u5230\u7f51\u7edc\u6444\u50cf\u5934\uff0c\u5e76\u9a8c\u8bc1\u5b83\u662f\u5426\u80fd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\uff0c\u5305\u62ec\u4ece\u6444\u50cf\u5934\u83b7\u53d6\u56fe\u50cf\u5e76\u663e\u793a\u68c0\u6d4b\u7ed3\u679c\u7684\u65f6\u95f4\u3002 \u2003\u6700\u7ec8\u7684\u7cfb\u7edf\u662f\u4ea4\u4e92\u5f0f\u7684\u5e76\u4e14\u662f\u53c2\u4e0e\u5f0f\u7684\u3002\u867d\u7136 \\(YOLO\\) \u5355\u72ec\u5730\u5904\u7406\u56fe\u50cf\uff0c\u4f46\u5f53\u8fde\u63a5\u5230\u7f51\u7edc\u6444\u50cf\u5934\u65f6\uff0c\u5176\u529f\u80fd\u7c7b\u4f3c\u4e8e\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u53ef\u5728\u76ee\u6807\u79fb\u52a8\u548c\u5916\u89c2\u53d8\u5316\u65f6\u68c0\u6d4b\u76ee\u6807\u3002\u7cfb\u7edf\u6f14\u793a\u548c\u6e90\u4ee3\u7801\u53ef\u4ee5\u5728\u6211\u4eec\u7684\u9879\u76ee\u7f51\u7ad9\u4e0a\u627e\u5230\uff1ahttp://pjreddie.com/yolo/\u3002 6.\u603b\u7ed3 \u2003 \u6211\u4eec\u4ecb\u7ecd\u4e86 \\(YOLO\\) \uff0c\u4e00\u79cd\u7edf\u4e00\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u3002\u6211\u4eec\u7684\u6a21\u578b\u6784\u5efa\u7b80\u5355\uff0c\u53ef\u4ee5\u76f4\u63a5\u5728\u6574\u5f20\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u4e0e\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c \\(YOLO\\) \u76f4\u63a5\u5728\u5bf9\u5e94\u68c0\u6d4b\u6027\u80fd\u7684\u635f\u5931\u51fd\u6570\u4e0a\u8bad\u7ec3\uff0c\u5e76\u4e14\u6574\u4e2a\u6a21\u578b\u7edf\u4e00\u8bad\u7ec3\u3002 \\(Fast \\ YOLO\\) \u662f\u6587\u732e\u4e2d\u6700\u5feb\u7684\u901a\u7528\u76ee\u7684\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c \\(YOLO\\) \u63a8\u52a8\u4e86\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7684\u6700\u65b0\u6280\u672f\u3002 \\(YOLO\\) \u8fd8\u5f88\u597d\u5730\u6cdb\u5316\u5230\u65b0\u9886\u57df\uff0c\u4f7f\u5176\u6210\u4e3a\u8981\u6c42\u5feb\u901f\u3001\u5f3a\u5927\u76ee\u6807\u68c0\u6d4b\u5e94\u7528\u7684\u7406\u60f3\u9009\u62e9\u3002 Acknowledgements : This work is partially supported by ONR N00014-13-1-0720, NSF IIS-1338054, and The Allen Distinguished Investigator Award. References [1] M. B. Blaschko and C. H. Lampert. Learning to localize objects with structured output regression. In Computer Vision\u2013ECCV 2008, pages 2\u201315. Springer, 2008. 4 [2] L. Bourdev and J. Malik. Poselets: Body part detectors trained using 3d human pose annotations. In International Conference on Computer Vision (ICCV), 2009. 8 [3] H. Cai, Q. Wu, T. Corradi, and P. Hall. The cross-depiction problem: Computer vision algorithms for recognising objects in artwork and in photographs. arXiv preprint arXiv:1505.00110, 2015. 7 [4] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conferenceon, volume 1, pages 886\u2013893. IEEE, 2005. 4, 8 [5] T. Dean, M. Ruzon, M. Segal, J. Shlens, S. Vijayanarasimhan, J. Yagnik, et al. Fast, accurate detection of 100,000 object classes on a single machine. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pages 1814\u20131821. IEEE, 2013. 5 [6] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. arXiv preprint arXiv:1310.1531, 2013. 4 [7] J. Dong, Q. Chen, S. Yan, and A. Yuille. Towards unified object detection and semantic segmentation. In Computer Vision\u2013ECCV 2014, pages 299\u2013314. Springer, 2014. 7 [8] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov. Scalable object detection using deep neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2155\u20132162. IEEE, 2014. 5, 6 [9] M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The pascal visual object classes challenge: A retrospective. International Journal of Computer Vision, 111(1):98\u2013136, Jan. 2015. 2 [10] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9):1627\u20131645, 2010. 1, 4 [11] S. Gidaris and N. Komodakis. Object detection via a multiregion & semantic segmentation-aware CNN model. CoRR, abs/1505.01749, 2015. 7 [12] S. Ginosar, D. Haas, T. Brown, and J. Malik. Detecting people in cubist art. In Computer Vision-ECCV 2014 Workshops, pages 101\u2013116. Springer, 2014. 7 [13] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 580\u2013587. IEEE, 2014. 1, 4, 7 [14] R. B. Girshick. Fast R-CNN. CoRR, abs/1504.08083, 2015. 2, 5, 6, 7 [15] S. Gould, T. Gao, and D. Koller. Region-based segmentation and object detection. In Advances in neural information processing systems, pages 655\u2013663, 2009. 4 [16] B. Hariharan, P. Arbel\u00e1ez, R. Girshick, and J. Malik. Simultaneous detection and segmentation. In Computer Vision\u2013ECCV 2014, pages 297\u2013312. Springer, 2014. 7 [17] K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling in deep convolutional networks for visual recognition. arXiv preprint arXiv:1406.4729, 2014. 5 [18] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580, 2012. 4 [19] D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error in object detectors. In Computer Vision\u2013ECCV 2012, pages 340\u2013353. Springer, 2012. 6 [20] K. Lenc and A. Vedaldi. R-cnn minus r. arXiv preprint arXiv:1506.06981, 2015. 5, 6 [21] R. Lienhart and J. Maydt. An extended set of haar-like features for rapid object detection. In Image Processing. 2002. Proceedings. 2002 International Conference on, volume 1, pages I\u2013900. IEEE, 2002. 4 [22] M. Lin, Q. Chen, and S. Yan. Network in network. CoRR, abs/1312.4400, 2013. 2 [23] D. G. Lowe. Object recognition from local scale-invariant features. In Computer vision, 1999. The proceedings of the seventh IEEE international conference on, volume 2, pages 1150\u20131157. Ieee, 1999. 4 [24] D. Mishkin. Models accuracy on imagenet 2012 val. https://github.com/BVLC/caffe/wiki/Models-accuracy-on-ImageNet-2012-val. Ac-cessed: 2015-10-2. 3 [25] C. P. Papageorgiou, M. Oren, and T. Poggio. A general framework for object detection. In Computer vision, 1998. sixth international conference on, pages 555\u2013562. IEEE,1998. 4 [26] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 3 [27] J. Redmon and A. Angelova. Real-time grasp detection using convolutional neural networks. CoRR, abs/1412.3128, 2014.5 [28] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497, 2015. 5, 6, 7 [29] S. Ren, K. He, R. B. Girshick, X. Zhang, and J. Sun. Object detection networks on convolutional feature maps. CoRR, abs/1504.06066, 2015. 3, 7 [30] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. 3 [31] M. A. Sadeghi and D. Forsyth. 30hz object detection with dpm v5. In Computer Vision\u2013ECCV 2014, pages 65\u201379. Springer, 2014. 5, 6 [32] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. LeCun. Overfeat: Integrated recognition, localization and detection using convolutional networks. CoRR, abs/1312.6229, 2013. 4, 5- [33] Z. Shen and X. Xue. Do more dropouts in pool5 feature maps for better object detection. arXiv preprint arXiv:1409.6911, 2014. 7 [34] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. CoRR, abs/1409.4842, 2014. 2 [35] J. R. Uijlings, K. E. van de Sande, T. Gevers, and A. W. Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154\u2013171, 2013. 4, 5 [36] P. Viola and M. Jones. Robust real-time object detection. International Journal of Computer Vision, 4:34\u201347, 2001. 4 [37] P. Viola and M. J. Jones. Robust real-time face detection. International journal of computer vision, 57(2):137\u2013154, 2004. 5 [38] J. Yan, Z. Lei, L. Wen, and S. Z. Li. The fastest deformable part model for object detection. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2497\u20132504. IEEE, 2014. 5, 6 [39] C. L. Zitnick and P. Doll\u00e1r. Edge boxes: Locating object proposals from edges. In Computer Vision\u2013ECCV 2014, pages 391\u2013405. Springer, 2014. 4","title":"YOLOv1"},{"location":"thesis_interpretation/01_yolo.html#_1","text":"\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5 \\(YOLO\\) \u3002\u4ee5\u524d\u7684\u76ee\u6807\u68c0\u6d4b\u5de5\u4f5c\u91cd\u65b0\u5229\u7528\u5206\u7c7b\u5668\u6765\u6267\u884c\u68c0\u6d4b\u3002\u76f8\u53cd\uff0c\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u6846\u67b6\u770b\u4f5c\u4ece\u7a7a\u95f4\u5206\u79bb\u7684\u8fb9\u754c\u6846\u548c\u76f8\u5173\u7c7b\u522b\u6982\u7387\u7684\u56de\u5f52\u95ee\u9898\u3002\u5728\u4e00\u6b21\u8bc4\u4f30\u4e2d\uff0c\u4e00\u4e2a\u5355\u4e00\u7684\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u4ece\u5b8c\u6574\u7684\u56fe\u50cf\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u3002\u7531\u4e8e\u6574\u4e2a\u68c0\u6d4b\u7ba1\u9053\u662f\u4e00\u4e2a\u5355\u4e00\u7684\u7f51\u7edc\uff0c\u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u5bf9\u68c0\u6d4b\u6027\u80fd\u8fdb\u884c\u7aef\u5230\u7aef( \u8bd1\u8005\u6ce8\uff1a\u7aef\u5bf9\u7aef\u6307\u7684\u662f\u8f93\u5165\u539f\u59cb\u6570\u636e\uff0c\u8f93\u51fa\u7684\u662f\u6700\u540e\u7ed3\u679c\uff0c\u5e94\u7528\u5728\u7279\u5f81\u5b66\u4e60\u878d\u5165\u7b97\u6cd5\uff0c\u65e0\u9700\u5355\u72ec\u5904\u7406 )\u4f18\u5316\u3002 \u2003 \u6211\u4eec\u7684\u7edf\u4e00\u67b6\u6784\u975e\u5e38\u5feb\u3002\u6211\u4eec\u7684\u57fa\u672c \\(YOLO\\) \u6a21\u578b\u4ee5\u6bcf\u79d245\u5e27\u7684\u901f\u5ea6\u5b9e\u65f6\u5904\u7406\u56fe\u50cf\u3002\u8be5\u7f51\u7edc\u7684\u4e00\u4e2a\u5c0f\u7248\u672c\uff1a \\(Fast \\ YOLO\\) \u662f \\(YOLO\\) \u7684\u4e00\u4e2a\u8f83\u5c0f\u7248\u672c\uff0c\u6bcf\u79d2\u80fd\u8fbe\u5230\u5904\u7406\u60ca\u4eba\u7684155\u5e27\u56fe\u50cf\uff0c\u540c\u65f6\u4ecd\u7136\u8fbe\u5230\u5176\u4ed6\u5b9e\u65f6\u63a2\u6d4b\u5668\u7684\u4e24\u500d \\(mAP\\) \u3002\u4e0e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\uff0c \\(YOLO\\) YOLO\u867d\u7136\u5b58\u5728\u8f83\u591a\u7684\u5b9a\u4f4d\u9519\u8bef\uff0c\u4f46\u5f88\u5c11\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u5047\u9633\u6027( \u8bd1\u8005\u6ce8\uff1a\u5176\u5b83\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u76ee\u6807\u7684\u6982\u7387\u8f83\u5927 )\u3002\u6700\u540e\uff0c \\(YOLO\\) \u80fd\u5b66\u4e60\u5230\u76ee\u6807\u7684\u975e\u5e38\u901a\u7528\u3002\u65e0\u8bba\u4ece\u81ea\u7136\u56fe\u50cf\u5230\u827a\u672f\u54c1\u7b49\u5176\u4ed6\u9886\u57df\u6cdb\u5316\u65f6\uff0c\u5b83\u90fd\u4f18\u4e8e\u5176\u4ed6\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6bd4\u5982 \\(DPM\\) \u548c \\(R-CNN\\) \u3002","title":"\u6458\u8981"},{"location":"thesis_interpretation/01_yolo.html#1","text":"\u4eba\u7c7b\u77a5\u4e00\u773c\u56fe\u50cf\uff0c\u5c31\u4f1a\u7acb\u5373\u77e5\u9053\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\u662f\u4ec0\u4e48\uff0c\u5b83\u4eec\u5728\u54ea\u91cc\uff0c\u4ee5\u53ca\u5b83\u4eec\u662f\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u7684\u3002\u4eba\u7c7b\u7684\u89c6\u89c9\u7cfb\u7edf\u5feb\u901f\u548c\u51c6\u786e\u7684\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u5728\u51e0\u4e4e\u6ca1\u6709\u610f\u8bc6\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u590d\u6742\u7684\u4efb\u52a1\uff0c\u5982\u9a7e\u9a76\u3002\u5feb\u901f\u3001\u51c6\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5c06\u5141\u8bb8\u8ba1\u7b97\u673a\u5728\u6ca1\u6709\u4e13\u7528\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u9a7e\u9a76\u6c7d\u8f66\uff0c\u4f7f\u8f85\u52a9\u8bbe\u5907\u80fd\u591f\u5411\u4eba\u7c7b\u7528\u6237\u4f20\u9001\u5b9e\u65f6\u573a\u666f\u4fe1\u606f\u5e76\u91ca\u653e\u901a\u7528\u3001\u54cd\u5e94\u7075\u654f\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6f5c\u529b\u3002\u5feb\u901f\u3001\u51c6\u786e\u7684\u7269\u4f53\u68c0\u6d4b\u7b97\u6cd5\u5c06\u5e2e\u52a9\u8ba1\u7b97\u673a\u5728\u6ca1\u6709\u4e13\u95e8\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u9a7e\u9a76\u6c7d\u8f66\uff0c\u8f85\u52a9\u8bbe\u5907\u80fd\u591f\u5c06\u5b9e\u65f6\u573a\u666f\u4fe1\u606f\u4f20\u8fbe\u7ed9\u7528\u6237\uff0c\u5e76\u663e\u793a\u901a\u7528\u3001\u54cd\u5e94\u5f0f\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6f5c\u529b\u3002 \u2003 \u76ee\u524d\u7684\u68c0\u6d4b\u7cfb\u7edf\u91cd\u590d\u5229\u7528\u5206\u7c7b\u5668\u6765\u6267\u884c\u68c0\u6d4b\u3002\u4e3a\u4e86\u68c0\u6d4b\u76ee\u6807\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u4e3a\u8be5\u76ee\u6807\u63d0\u4f9b\u4e00\u4e2a\u5206\u7c7b\u5668\uff0c\u5e76\u5728\u6d4b\u8bd5\u56fe\u50cf\u7684\u4e0d\u540c\u4f4d\u7f6e\u548c\u5c3a\u5ea6\u4e0a\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002\u4f8b\u5982\u50cf\u53ef\u53d8\u5f62\u90e8\u4ef6\u6a21\u578b \\((DPM)\\) \u8fd9\u6837\u7684\u7cfb\u7edf\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\uff0c\u5176\u4e2d\u5206\u7c7b\u5668\u5728\u6574\u4e2a\u56fe\u50cf\u4e0a\u5747\u5300\u95f4\u9694\u7684\u4f4d\u7f6e\u8fd0\u884c[10]\u3002 \u56fe1: YOLO\u68c0\u6d4b\u7cfb\u7edf\u3002 \u7528YOLO\u5904\u7406\u56fe\u50cf\u7b80\u5355\u800c\u76f4\u63a5\u3002\u5728\u6211\u4eec\u7684\u7cfb\u7edf\u4e2d: \u5c06\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u8c03\u6574\u4e3a448 \u00d7 448\u3002 \u5728\u56fe\u50cf\u4e0a\u8fd0\u884c\u4e00\u4e2a\u5377\u79ef\u7f51\u7edc\u3002 \u6839\u636e\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u5bf9\u7ed3\u679c\u68c0\u6d4b\u8fdb\u884c\u9608\u503c\u3002 \u2003\u6700\u8fd1\u7684\u65b9\u6cd5\uff0c\u5982R-CNN\u63d0\u51fa\u4f7f\u7528\u90e8\u5206\u533a\u57df\uff0c\u9996\u5148\u5728\u56fe\u50cf\u4e2d\u751f\u6210\u6f5c\u5728\u7684\u8fb9\u754c\u6846\uff0c\u7136\u540e\u5728\u8fd9\u4e9b\u6846\u4e0a\u8fd0\u884c\u5206\u7c7b\u5668\u3002\u5b8c\u6210\u5206\u7c7b\u540e\uff0c\u901a\u8fc7\u540e\u5904\u7406\u5728\u7ec6\u5316\u8fb9\u754c\u6846\uff0c\u6d88\u9664\u91cd\u590d\u68c0\u6d4b\uff0c\u5e76\u57fa\u4e8e\u573a\u666f\u4e2d\u7684\u5176\u4ed6\u76ee\u6807\u91cd\u65b0\u5b9a\u4f4d\u8fb9\u754c\u6846[13]\u3002\u8fd9\u4e9b\u590d\u6742\u7684\u6d41\u7a0b\u5f88\u6162\uff0c\u5f88\u96be\u4f18\u5316\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u5355\u72ec\u7684\u7ec4\u4ef6\u90fd\u5fc5\u987b\u5355\u72ec\u8bad\u7ec3\u3002 \u2003\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5355\u4e00\u7684\u56de\u5f52\u95ee\u9898\uff0c\u76f4\u63a5\u4ece\u56fe\u50cf\u50cf\u7d20\u5230\u8fb9\u754c\u6846\u5750\u6807\u548c\u7c7b\u522b\u6982\u7387\u3002\u4f7f\u7528\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u60a8\u53ea\u9700\u8981\u5728\u56fe\u50cf\u4e0a\u770b\u4e00\u6b21\uff08you only look once, \\(YOLO\\) \uff09\uff0c\u5c31\u4ee5\u9884\u6d4b\u4ec0\u4e48\u76ee\u6807\u51fa\u73b0\u548c\u5b83\u4eec\u5728\u54ea\u91cc\u3002 \u2003 \\(YOLO\\) \u65b0\u5947\u53c8\u5f88\u7b80\u5355\uff1a\u5982\u56fe1\u6240\u793a\u3002\u5355\u4e2a\u5377\u79ef\u7f51\u7edc\u540c\u65f6\u9884\u6d4b\u8fd9\u4e9b\u6846\u7684\u591a\u4e2a\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u503c\u3002YOLO\u5728\u5b8c\u6574\u56fe\u50cf\u4e0a\u8bad\u7ec3\uff0c\u5e76\u76f4\u63a5\u4f18\u5316\u68c0\u6d4b\u6027\u80fd\u3002\u4e0e\u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8fd9\u79cd\u7edf\u4e00\u7684\u6a21\u578b\u6709\u51e0\u4e2a\u4f18\u70b9\u3002 \u2003 \u9996\u5148\uff0c \\(YOLO\\) \u901f\u5ea6\u975e\u5e38\u5feb\u3002\u7531\u4e8e\u6211\u4eec\u5c06\u68c0\u6d4b\u89c6\u4e3a\u56de\u5f52\u95ee\u9898\uff0c\u6240\u4ee5\u6211\u4eec\u4e0d\u9700\u8981\u590d\u6742\u7684\u6d41\u7a0b\u3002\u6d4b\u8bd5\u65f6\u6211\u4eec\u5728\u4e00\u5f20\u65b0\u56fe\u50cf\u4e0a\u7b80\u5355\u7684\u8fd0\u884c\u6211\u4eec\u7684\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u68c0\u6d4b\u7684\u7ed3\u679c\u3002\u5728Titan X GPU\u4e0a\u6ca1\u6709\u6279\u5904\u7406\u4e2d\uff0c\u6211\u4eec\u7684\u57fa\u7840\u7f51\u7edc\u4ee5\u6bcf\u79d245\u5e27\u7684\u901f\u5ea6\u8fd0\u884c\u3002\u5feb\u901f\u7248\u672c\u8fd0\u884c\u901f\u5ea6\u8d85\u8fc7150fps\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u53ef\u4ee5\u5728\u4e0d\u523025\u6beb\u79d2\u7684\u5ef6\u8fdf\u5185\u5b9e\u65f6\u5904\u7406\u6d41\u5a92\u4f53\u89c6\u9891\u3002\u6b64\u5916\uff0c \\(YOLO\\) \u5b9e\u73b0\u4e86\u5176\u5b83\u5b9e\u65f6\u7cfb\u7edf\u4e24\u500d\u4ee5\u4e0a\u7684mAP\u3002\u5173\u4e8e\u6211\u4eec\u7684\u7cfb\u7edf\u5728\u7f51\u7edc\u6444\u50cf\u5934\u4e0a\u5b9e\u65f6\u8fd0\u884c\u7684\u6f14\u793a\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684\u9879\u76ee\u7f51\u9875\uff1ahttp://pjreddie.com/yolo/\u3002 \u2003 \u5176\u6b21\uff0c \\(YOLO\\) \u5728\u8fdb\u884c\u9884\u6d4b\u65f6\uff0c\u4f1a\u5bf9\u56fe\u50cf\u8fdb\u884c\u5168\u5c40\u5730\u63a8\u7406\u3002\u4e0e\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3( sliding window )\u548c\u57fa\u4e8e\u533a\u57df\u63d0\u8bae( region proposal )\u7684\u6280\u672f\u4e0d\u540c\uff0c \\(YOLO\\) \u5728\u8bad\u7ec3\u671f\u95f4\u548c\u6d4b\u8bd5\u65f6\u4f1a\u770b\u5230\u6574\u4e2a\u56fe\u50cf\uff0c\u56e0\u6b64\u5b83\u9690\u5f0f\u5730\u7f16\u7801\u5173\u4e8e\u7c7b\u53ca\u5176\u5916\u89c2\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002 \\(Fast \\ R-CNN\\) \u662f\u4e00\u79cd\u9876\u90e8\u7684\u68c0\u6d4b\u65b9\u6cd5[14]\uff0c\u4f46\u56e0\u4e3a\u5b83\u770b\u4e0d\u5230\u66f4\u5927\u7684\u4e0a\u4e0b\u6587\uff0c\u6240\u4ee5\u5728\u56fe\u50cf\u4e2d\u4f1a\u5c06\u80cc\u666f\u5757\u8bef\u68c0\u4e3a\u76ee\u6807\u3002\u4e0e \\(Fast R-CNN\\) \u76f8\u6bd4\uff0cYOLO\u7684\u80cc\u666f\u8bef\u68c0\u6570\u91cf\u5c11\u4e86\u4e00\u534a\u3002 \u2003 \u7b2c\u4e09\uff0c \\(YOLO\\) \u5b66\u4e60\u76ee\u6807\u53ef\u6cdb\u5316\u8868\u793a\u3002\u5f53\u5728\u81ea\u7136\u7684\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u5bf9\u827a\u672f\u4f5c\u54c1\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c \\(YOLO\\) \u5927\u5e45\u4f18\u4e8e \\(DPM\\) \u548c \\(R-CNN\\) \u7b49\u9876\u7ea7\u68c0\u6d4b\u65b9\u6cd5\u3002\u7531\u4e8e \\(YOLO\\) \u5177\u6709\u9ad8\u5ea6\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u5728\u5e94\u7528\u4e8e\u65b0\u9886\u57df\u6216\u78b0\u5230\u975e\u6b63\u5e38\u8f93\u5165\u65f6\u5f88\u5c11\u51fa\u6545\u969c\u3002 \u2003 \\(YOLO\\) \u5728\u51c6\u786e\u5ea6\u4e0a\u4ecd\u7136\u843d\u540e\u4e8e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002\u867d\u7136\u5b83\u53ef\u4ee5\u5feb\u901f\u8bc6\u522b\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff0c\u4f46\u5b83\u5f88\u96be\u7cbe\u786e\u5b9a\u4f4d\u4e00\u4e9b\u76ee\u6807\uff0c\u5c24\u5176\u662f\u4e00\u4e9b\u5c0f\u76ee\u6807\u3002\u6211\u4eec\u5728\u5b9e\u9a8c\u4e2d\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u8fd9\u4e9b\u6743\u8861\u3002 \u2003 \\(YOLO\\) \u6211\u4eec\u6240\u6709\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u90fd\u662f\u5f00\u6e90\u7684\u3002\u5404\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\u4e5f\u90fd\u53ef\u4ee5\u4e0b\u8f7d\u3002","title":"1.\u4ecb\u7ecd"},{"location":"thesis_interpretation/01_yolo.html#2","text":"\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u7684\u5355\u72ec\u7ec4\u4ef6\u96c6\u6210\u5230\u5355\u4e2a\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002\u6211\u4eec\u7684\u7f51\u7edc\u5229\u7528\u6574\u4e2a\u56fe\u50cf\u7684\u7279\u5f81\u6765\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u3002\u5b83\u8fd8\u53ef\u4ee5\u540c\u65f6\u9884\u6d4b\u4e00\u5f20\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u7c7b\u522b\u7684\u6240\u6709\u8fb9\u754c\u6846\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u7f51\u7edc\u5bf9\u6574\u4e2a\u56fe\u50cf\u548c\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u5bf9\u8c61\u8fdb\u884c\u5168\u5c40\u63a8\u7406\u3002 \\(YOLO\\) \u8bbe\u8ba1\u53ef\u5b9e\u73b0\u7aef\u5230\u7aef\u8bad\u7ec3\u548c\u5b9e\u65f6\u7684\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u5e73\u5747\u7cbe\u5ea6( \u5373mAP\u503c )\u3002 \u2003 \u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u8f93\u5165\u56fe\u50cf\u5206\u6210 \\(S\u00d7S\\) \u7684\u7f51\u683c\u3002\u5982\u679c\u4e00\u4e2a\u76ee\u6807\u7684\u4e2d\u5fc3\u843d\u5165\u4e00\u4e2a\u7f51\u683c\u5355\u5143\u4e2d\uff0c\u8be5\u7f51\u683c\u5355\u5143\u8d1f\u8d23\u68c0\u6d4b\u8be5\u76ee\u6807\u3002 \u2003 \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u9884\u6d4b \\(B\\) \u4e2a\u8fb9\u754c\u6846\u548c\u7f6e\u4fe1\u5ea6\u5206\u6570\u5bf9\u4e8e\u90a3\u4e9b\u6846\u3002\u8fd9\u4e9b\u7f6e\u4fe1\u5ea6\u5206\u6570\u53cd\u6620\u4e86\u8be5\u6a21\u578b\u5bf9\u6846\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u7f6e\u4fe1\u5ea6\uff0c\u4ee5\u53ca\u5b83\u9884\u6d4b\u6846\u7684\u51c6\u786e\u5ea6\u3002\u5728\u5f62\u5f0f\u4e0a\uff0c\u6211\u4eec\u5c06\u7f6e\u4fe1\u5ea6\u5b9a\u4e49\u4e3a \\(Pr(Object)\u2217IOU^{truth}_{pred}\\) \u3002\u5982\u679c\u8be5\u5355\u5143\u683c\u4e2d\u4e0d\u5b58\u5728\u76ee\u6807\uff0c\u5219\u7f6e\u4fe1\u5ea6\u5206\u6570\u5e94\u4e3a \\(0\\) \u3002\u5426\u5219\uff0c\u6211\u4eec\u5e0c\u671b\u7f6e\u4fe1\u5ea6\u5206\u6570\u7b49\u4e8e\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u8054\u5408\u90e8\u5206\u7684\u4ea4\u96c6( \\(IOU\\) )\u3002 \u2003\u6bcf\u4e2a\u8fb9\u754c\u6846\u5305\u542b5\u4e2a\u9884\u503c\uff1a \\(x,y,w,h,confidence\\) \u3002 \\((x,y)\\) \u5750\u6807\u8868\u793a\u8fb9\u754c\u6846\u76f8\u5bf9\u4e8e\u7f51\u683c\u5355\u5143\u8fb9\u754c\u7684\u65b9\u6846\u4e2d\u5fc3\u3002\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u662f\u76f8\u5bf9\u4e8e\u6574\u5f20\u56fe\u50cf\u9884\u6d4b\u7684\u3002\u6700\u540e\uff0c\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u8868\u793a\u4e3a\u9884\u6d4b\u6846\u4e0e\u5b9e\u9645\u8fb9\u754c\u6846\u4e4b\u95f4\u7684 \\(IOU\\) \u3002 \u2003 \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u8fd8\u9884\u6d4b \\(C\\) \u4e2a\u6761\u4ef6\u7c7b\u522b\u6982\u7387 \\(Pr(Class_i|Object)\\) \u3002\u8fd9\u4e9b\u6982\u7387\u4ee5\u5305\u542b\u76ee\u6807\u7684\u7f51\u683c\u5355\u5143\u4e3a\u6761\u4ef6\u3002\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u6211\u4eec\u53ea\u9884\u6d4b\u7684\u4e00\u7ec4\u7c7b\u522b\u6982\u7387\uff0c\u800c\u4e0d\u7ba1\u8fb9\u754c\u6846\u7684\u7684\u6570\u91cf \\(B\\) \u662f\u591a\u5c11\u3002 \u2003\u5728\u6d4b\u8bd5\u65f6\uff0c\u6211\u4eec\u5c06\u6761\u4ef6\u7c7b\u6982\u7387\u548c\u5355\u4e2a\u6846\u7684\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u503c\u76f8\u4e58\uff1a \\(\\small{Pr(Class_i|Object) \u2217 Pr(Object) \u2217 IOU^{truth}_{pred} = Pr(Class_i) \u2217 IOU^{truth}_{pred}}\\) (1) \u5b83\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u6bcf\u4e2a\u6846\u7279\u5b9a\u7c7b\u522b\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\u3002\u8fd9\u4e9b\u5206\u6570\u7f16\u7801\u4e86\u8be5\u7c7b\u51fa\u73b0\u5728\u6846\u4e2d\u7684\u6982\u7387\u4ee5\u53ca\u9884\u6d4b\u6846\u62df\u5408\u76ee\u6807\u7684\u7a0b\u5ea6\u3002 \u56fe2\uff1a\u6a21\u578b\u3002 \u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u68c0\u6d4b\u5efa\u6a21\u4e3a\u4e00\u4e2a\u56de\u5f52\u95ee\u9898\u3002\u5b83\u5c06\u56fe\u50cf\u5212\u5206\u4e3a\u4e00\u4e2a \\(S \u00d7 S\\) \u7f51\u683c\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u9884\u6d4b \\(B\\) \u4e2a\u8fb9\u754c\u6846\u3001\u8fd9\u4e9b\u6846\u7684\u7f6e\u4fe1\u5ea6 \u548c \\(C\\) \u7c7b\u522b\u6982\u7387\u3002\u8fd9\u4e9b\u9884\u6d4b\u88ab\u7f16\u7801\u4e3a \\(S \u00d7 S \u00d7 (B * 5 + C)\\) \u7684\u5f20\u91cf \\(S\\times{S}\\) grid on input( \\(S\\times{S}\\) \u7684\u7f51\u683c\u5728\u8f93\u5165\u4e0a) Bounding boxes (\u8fb9\u754c\u6846) confidence (\u7f6e\u4fe1\u5ea6) Class probability map(\u7c7b\u522b\u6982\u7387\u5730\u56fe) Final detections (\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c) \u4e3a\u4e86\u5728 \\(Pascal \\ VOC\\) \u4e0a\u8bc4\u4f30 \\(YOLO\\) \uff0c\u6211\u4eec\u4f7f\u7528 \\(S=7\uff0cB=2\u3002Pascal VOC\\) \u6709 \\(20\\) \u4e2a\u6807\u6ce8\u7c7b\uff0c\u6240\u4ee5 \\(C=20\\) \u3002\u6211\u4eec\u6700\u7ec8\u7684\u9884\u6d4b\u662f \\(7\u00d77\u00d730\\) \u7684\u5f20\u91cf\u3002 \u6ce8\u610f\uff1a \u2003 \u2003 1.\u7531\u4e8e\u8f93\u51fa\u5c42\u4e3a\u5168\u8fde\u63a5\u5c42\uff0c\u56e0\u6b64\u5728\u68c0\u6d4b\u65f6\uff0cYOLO\u8bad\u7ec3\u6a21\u578b\u53ea\u652f\u6301\u4e0e\u8bad\u7ec3\u56fe\u50cf\u76f8\u540c\u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002 \u2003 \u2003 2.\u867d\u7136\u6bcf\u4e2a\u683c\u5b50\u53ef\u4ee5\u9884\u6d4bB\u4e2abounding box\uff0c\u4f46\u662f\u6700\u7ec8\u53ea\u9009\u62e9\u53ea\u9009\u62e9IOU\u6700\u9ad8\u7684bounding box\u4f5c\u4e3a\u7269\u4f53\u68c0\u6d4b\u8f93\u51fa\uff0c\u5373\u6bcf\u4e2a\u683c\u5b50\u6700\u591a\u53ea\u9884\u6d4b\u51fa\u4e00\u4e2a\u7269\u4f53\u3002\u5f53\u7269\u4f53\u5360\u753b\u9762\u6bd4\u4f8b\u8f83\u5c0f\uff0c\u5982\u56fe\u50cf\u4e2d\u5305\u542b\u755c\u7fa4\u6216\u9e1f\u7fa4\u65f6\uff0c\u6bcf\u4e2a\u683c\u5b50\u5305\u542b\u591a\u4e2a\u7269\u4f53\uff0c\u4f46\u5374\u53ea\u80fd\u68c0\u6d4b\u51fa\u5176\u4e2d\u4e00\u4e2a\u3002\u8fd9\u662fYOLO\u65b9\u6cd5\u7684\u4e00\u4e2a\u7f3a\u9677\u3002","title":"2.\u7edf\u4e00\u7684\u68c0\u6d4b"},{"location":"thesis_interpretation/01_yolo.html#21","text":"\u6211\u4eec\u5c06\u8be5\u6a21\u578b\u5b9e\u73b0\u4e3a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u5728 \\(PASCAL \\ VOC\\) \u68c0\u6d4b\u6570\u636e\u96c6[9]\u4e0a\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002\u7f51\u7edc\u7684\u521d\u59cb\u5377\u79ef\u5c42\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u800c\u5168\u8fde\u901a\u5c42\u9884\u6d4b\u8f93\u51fa\u6982\u7387\u548c\u5750\u6807\u3002 \u2003\u6211\u4eec\u7684\u7f51\u7edc\u67b6\u6784\u7684\u7075\u611f\u6765\u81ea\u4e8e\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b[34]\u7684 \\(GoogLeNet\\) \u6a21\u578b\u3002\u6211\u4eec\u7684\u7f51\u7edc\u6709 \\(24\\) \u4e2a\u5377\u79ef\u5c42\u548c \\(2\\) \u4e2a\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u7b80\u5355\u5730\u4f7f\u7528 \\(1 \u00d7 1\\) \u8fd8\u539f\u5c42\u548c \\(3 \u00d7 3\\) \u5377\u79ef\u5c42\uff0c\u7c7b\u4f3c \\(Lin\\) \u7b49[22]\u3002\u5b8c\u6574\u7684\u7f51\u7edc \\(\u5982\u56fe3\\) \u6240\u793a\u3002 \u56fe3 :\u4f53\u7cfb\u7ed3\u6784\u3002 \u6211\u4eec\u7684\u68c0\u6d4b\u7f51\u7edc\u6709 \\(24\\) \u4e2a\u5377\u79ef\u5c42\u548c \\(2\\) \u4e2a\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u4ea4\u66ff\u7684 \\(1 \u00d7 1\\) \u5377\u79ef\u5c42\u51cf\u5c11\u4e86\u524d\u4e00\u5c42\u7684\u7279\u5f81\u7a7a\u95f4\u3002\u6211\u4eec\u5728 \\(ImageNet\\) \u5206\u7c7b\u4efb\u52a1\u4e0a\u4ee5\u4e00\u534a\u5206\u8fa8\u7387( \\(224 \u00d7 224\\) \u8f93\u5165\u56fe\u50cf)\u5bf9\u5377\u79ef\u5c42\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5c06\u5206\u8fa8\u7387\u63d0\u9ad8\u4e00\u500d\u7528\u4e8e\u68c0\u6d4b\u3002 \u2003\u6211\u4eec\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5feb\u901f\u7248\u672c\u7684 \\(YOLO\\) \uff0c\u65e8\u5728\u63a8\u52a8\u5feb\u901f\u76ee\u6807\u68c0\u6d4b\u7684\u8fb9\u754c\u3002 \\(Fast \\ YOLO\\) \u4f7f\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u66f4\u5c11\u7684\u5377\u79ef\u5c42(9\u5c42\u800c\u4e0d\u662f24\u5c42)\uff0c\u8fd9\u4e9b\u5c42\u4e2d\u7684\u8fc7\u6ee4\u5668\u4e5f\u66f4\u5c11\u3002\u9664\u4e86\u7f51\u7edc\u7684\u89c4\u6a21\uff0c \\(YOLO\\) \u548c \\(Fast \\ YOLO\\) \u4e4b\u95f4\u7684\u6240\u6709\u8bad\u7ec3\u548c\u6d4b\u8bd5\u53c2\u6570\u90fd\u662f\u76f8\u540c\u7684\u3002 \u2003\u6211\u4eec\u7684\u7f51\u7edc\u7684\u6700\u7ec8\u8f93\u51fa\u662f \\(7 \u00d7 7 \u00d7 30\\) \u5f20\u91cf\u7684\u9884\u6d4b\u3002","title":"2.1 \u7f51\u7edc\u8bbe\u8ba1"},{"location":"thesis_interpretation/01_yolo.html#22","text":"\u9884\u8bad\u7ec3\u5206\u7c7b\u7f51\u7edc\uff1a\u6211\u4eec\u5728ImageNet 1000\u7c7b\u7ade\u8d5b\u6570\u636e\u96c6[30]\u4e0a\u9884\u8bad\u7ec3\u5377\u79ef\u5c42\u3002\u5bf9\u4e8e\u9884\u8bad\u7ec3\uff0c\u6211\u4eec\u4f7f\u7528\u56fe3\u4e2d\u7684\u524d20\u4e2a\u5377\u79ef\u5c42\uff0c\u7136\u540e\u662f\u5e73\u5747\u6c60\u5316\u5c42\u548c\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u6211\u4eec\u5bf9\u8be5\u7f51\u7edc\u8fdb\u884c\u4e86\u5927\u7ea6\u4e00\u5468\u7684\u8bad\u7ec3\uff0c\u5e76\u5728ImageNet 2012\u9a8c\u8bc1\u96c6\u4e0a\u5b9e\u73b0\u4e8688%\u7684\u5355\u4e00\u4f5c\u7269\u524d5\u540d\u7684\u51c6\u786e\u6027\uff0c\u4e0eCaffe\u7684Model Zoo[24]\u4e2d\u7684GoogLeNet\u6a21\u578b\u76f8\u5f53\u3002\u6211\u4eec\u4f7f\u7528Darknet\u6846\u67b6\u8fdb\u884c\u6240\u6709\u7684\u8bad\u7ec3\u548c\u63a8\u7406[26]\u3002 \u2003 \u7136\u540e\u6211\u4eec\u5c06\u6a21\u578b\u8f6c\u6362\u4e3a\u6267\u884c\u68c0\u6d4b\u3002Ren\u7b49\u4eba\u8868\u660e\uff0c\u5728\u9884\u8bad\u7ec3\u7684\u7f51\u7edc\u4e2d\u540c\u65f6\u6dfb\u52a0\u5377\u79ef\u5c42\u548c\u8fde\u63a5\u5c42\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd[29]\u3002 \u6309\u7167\u4ed6\u4eec\u7684\u4f8b\u5b50\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u56db\u4e2a\u5377\u79ef\u5c42\u548c\u4e24\u4e2a\u5177\u6709\u968f\u673a\u521d\u59cb\u5316\u6743\u503c\u7684\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u68c0\u6d4b\u901a\u5e38\u9700\u8981\u7ec6\u7c92\u5ea6\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u56e0\u6b64\u6211\u4eec\u5c06\u7f51\u7edc\u7684\u8f93\u5165\u5206\u8fa8\u7387\u4ece \\(224 \u00d7 224\\) \u63d0\u9ad8\u5230 \\(448 \u00d7 448\\) \u3002 \u2003 \u6211\u4eec\u7684\u6700\u540e\u4e00\u5c42\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u548c\u8fb9\u754c\u6846\u5750\u6807\u3002\u6211\u4eec\u901a\u8fc7\u56fe\u50cf\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u6765\u5f52\u4e00\u5316\u8fb9\u754c\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u4f7f\u5b83\u4eec\u843d\u57280\u548c1\u4e4b\u95f4\u3002\u6211\u4eec\u5c06\u8fb9\u754c\u6846x\u548cy\u5750\u6807\u53c2\u6570\u5316\u4e3a\u7279\u5b9a\u7f51\u683c\u5355\u5143\u4f4d\u7f6e\u7684\u504f\u79fb\u91cf\uff0c\u56e0\u6b64\u5b83\u4eec\u8fb9\u754c\u4e5f\u57280\u548c1\u4e4b\u95f4\u3002 \u2003 \u6211\u4eec\u5bf9\u6700\u540e\u4e00\u5c42\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u6240\u6709\u5176\u5b83\u5c42\u4f7f\u7528\u4e0b\u9762\u7684leaky ReLU\u6fc0\u6d3b\u51fd\u6570: \\(\\phi(x)=\\left\\{\\begin{array}{ll} x, & \\text { if } x>0 \\\\ 0.1 x, & \\text { otherwise } \\end{array}\\right.\\) (2) \u6211\u4eec\u4f18\u5316\u4e86\u6a21\u578b\u8f93\u51fa\u7684\u5e73\u65b9\u548c\u8bef\u5dee\u3002\u6211\u4eec\u4f7f\u7528\u5e73\u65b9\u548c\u8bef\u5dee\u662f\u56e0\u4e3a\u5b83\u5f88\u5bb9\u6613\u8fdb\u884c\u4f18\u5316\uff0c\u4f46\u662f\u5b83\u5e76\u4e0d\u5b8c\u5168\u7b26\u5408\u6211\u4eec\u6700\u5927\u5316\u5e73\u5747\u7cbe\u5ea6\u7684\u76ee\u6807\u3002\u5206\u7c7b\u8bef\u5dee\u4e0e\u5b9a\u4f4d\u8bef\u5dee\u7684\u6743\u91cd\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u53ef\u80fd\u5e76\u4e0d\u7406\u60f3\u3002\u53e6\u5916\uff0c\u5728\u6bcf\u5f20\u56fe\u50cf\u4e2d\uff0c\u8bb8\u591a\u7f51\u683c\u5355\u5143\u4e0d\u5305\u542b\u4efb\u4f55\u5bf9\u8c61\u3002\u8fd9\u5c06\u5bfc\u81f4\u8fd9\u4e9b\u5355\u5143\u683c\u7684 \\(\"\u7f6e\u4fe1\u5ea6\"\\) \u5206\u6570\u4e3a\u96f6\uff0c\u901a\u5e38\u538b\u5012\u4e86\u5305\u542b\u76ee\u6807\u7684\u5355\u5143\u683c\u7684\u68af\u5ea6\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u4ece\u800c\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u65e9\u53d1\u6563\u3002 \u2003\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u589e\u52a0\u4e86\u8fb9\u754c\u6846\u5750\u6807\u9884\u6d4b\u7684\u635f\u5931\uff0c\u51cf\u5c11\u4e86\u4e0d\u5305\u542b\u76ee\u6807\u7684\u6846\u7684\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u7684\u635f\u5931\u3002\u6211\u4eec\u4f7f\u7528\u4e24\u4e2a\u53c2\u6570\uff0c \\(\\lambda_{coord}\\) \u548c \\(\\lambda{noobj}\\) \u6765\u5b8c\u6210\u8fd9\u4e2a\u4efb\u52a1\u3002\u6211\u4eec\u8bbe\u7f6e \\(\\lambda_{coord} = 5\\) , \\(\\lambda_{noobj} = 0.5\\) \u3002 \u2003 \u5e73\u65b9\u548c\u8bef\u5dee\u5728\u5927\u65b9\u6846\u548c\u5c0f\u65b9\u6846\u4e2d\u7684\u6743\u91cd\u76f8\u540c\u3002\u6211\u4eec\u7684\u8bef\u5dee\u5ea6\u91cf\u5e94\u8be5\u53cd\u6620\u5927\u65b9\u6846\u91cc\u7684\u5c0f\u504f\u5dee\u6bd4\u5c0f\u65b9\u6846\u91cc\u7684\u5f71\u54cd\u5c0f\u3002\u4e3a\u4e86\u90e8\u5206\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u9884\u6d4b\u8fb9\u754c\u6846\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5e73\u65b9\u6839\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u3002\u4e3a\u4e86\u7f13\u548c\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u9884\u6d4b\u8fb9\u754c\u6846\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5e73\u65b9\u6839\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u3002 \u2003 \\(YOLO\\) \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u6709\u9884\u6d4b\u591a\u4e2a\u8fb9\u754c\u6846\u3002\u5728\u8bad\u7ec3\u65f6\uff0c\u6bcf\u4e2a\u76ee\u6807\u6211\u4eec\u53ea\u9700\u8981\u4e00\u4e2a\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u6765\u8d1f\u8d23\u3002\u6211\u4eec\u6839\u636e\u54ea\u4e2a\u9884\u6d4b\u5668\u7684\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u5177\u6709\u5f53\u524d\u6700\u9ad8\u7684 \\(IOU\\) \u6765\u6307\u5b9a\u54ea\u4e2a\u9884\u6d4b\u5668 \u8d1f\u8d23 \u9884\u6d4b\u8be5\u76ee\u6807\u3002\u8fd9\u5bfc\u81f4\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u4e4b\u95f4\u7684\u4e13\u4e00\u5316\u3002\u6bcf\u4e2a\u9884\u6d4b\u5668\u53ef\u4ee5\u66f4\u597d\u5730\u9884\u6d4b\u7279\u5b9a\u5927\u5c0f\u3001\u957f\u5bbd\u6bd4\u6216\u76ee\u6807\u7684\u7c7b\u522b\uff0c\u4ece\u800c\u6539\u5584\u6574\u4f53\u53ec\u56de\u7387\u3002 \u2003\u5728\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u4f18\u5316\u4ee5\u4e0b\u7531\u591a\u90e8\u5206\u7ec4\u6210\u7684\u635f\u5931\u51fd\u6570\uff1a \\(\\begin{array}{c} \\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(x_{i}-\\hat{x}_{i}\\right)^{2}+\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\\right] \\\\ +\\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(\\sqrt{w_{i}}-\\sqrt{\\hat{w}_{i}}\\right)^{2}+\\left(\\sqrt{h_{i}}-\\sqrt{\\hat{h}_{i}}\\right)^{2}\\right] \\\\ +\\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ +\\lambda_{\\text {noobj }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {noobj }}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ +\\sum_{i=0}^{S^{2}} \\mathbb{1}_{i}^{\\text {obj }} \\sum_{c \\in \\text { classes }}\\left(p_{i}(c)-\\hat{p}_{i}(c)\\right)^{2} \\end{array}\\) (3) \u5176\u4e2d \\(\\mathbb{1}_{i}^{\\mathrm{obj}}\\) \u8868\u793a\u5982\u679c\u76ee\u6807\u51fa\u73b0\u5728\u5355\u5143\u683c \\(i\\) \u5e76\u4e14 \\(\\mathbb{1}_{i j}^{\\mathrm{obj}}\\) \u8868\u793a\u7b2c \\(j\\) \u4e2a\u8fb9\u754c\u6846\u8d1f\u8d23\u5728\u5355\u5143\u683c \\(i\\) \u9884\u6d4b \u3002 \u2003 \u6ce8\u610f\uff0c\u5982\u679c\u76ee\u6807\u5b58\u5728\u4e8e\u8be5\u7f51\u683c\u5355\u5143\u4e2d\uff08\u524d\u9762\u8ba8\u8bba\u7684\u6761\u4ef6\u7c7b\u522b\u6982\u7387\uff09\uff0c\u5219\u635f\u5931\u51fd\u6570\u60e9\u7f5a\u5206\u7c7b\u8bef\u5dee\u3002\u5982\u679c\u9884\u6d4b\u5668 \\(\"\u8d1f\u8d23\"\\) \u771f\u5b9e\u8fb9\u754c\u6846\uff08\u5373\u8be5\u7f51\u683c\u5355\u5143\u4e2d\u5177\u6709\u6700\u9ad8 \\(IOU\\) \u7684\u9884\u6d4b\u5668\uff09\uff0c\u5219\u5b83\u4e5f\u4ec5\u60e9\u7f5a\u8fb9\u754c\u6846\u5750\u6807\u8bef\u5dee\u3002 \u2003 \u6211\u4eec\u5728 \\(Pascal \\ VOC \\ 2007\\) \u548c \\(2012\\) \u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5927\u7ea6 \\(135\\) \u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u7f51\u7edc\u8bad\u7ec3\u3002 \u5728 \\(Pascal \\ VOC \\ 2012\\) \u4e0a\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c\u6211\u4eec\u7684\u8bad\u7ec3\u8fd8\u5305\u542b\u4e86 \\(P0ascal \\ VOC \\ 2007\\) \u7684\u6d4b\u8bd5\u6570\u636e\u3002\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e86batch-size = 64 ( \u6279\u5927\u5c0f )\uff0cmomentum = 0.9 ( \u52a8\u91cf )\u548c decay = 0.0005 ( \u8870\u51cf\u7387 )\u3002 \u2003 \u6211\u4eec\u7684\u5b66\u4e60\u7387\u65b9\u6848\u5982\u4e0b\uff1a\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u8fed\u4ee3\u5468\u671f\uff0c\u6211\u4eec\u6162\u6162\u5730\u5c06\u5b66\u4e60\u7387\u4ece \\(10^{-3}\\) \u63d0\u9ad8\u5230 \\(10^{-2}\\) \u3002\u5982\u679c\u6211\u4eec\u4ece\u9ad8\u5b66\u4e60\u7387\u5f00\u59cb\uff0c\u6211\u4eec\u7684\u6a21\u578b\u5f80\u5f80\u4f1a\u7531\u4e8e\u68af\u5ea6\u4e0d\u7a33\u5b9a\u800c\u53d1\u6563\u3002\u6211\u4eec\u7ee7\u7eed\u4ee5 \\(10^{-2}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 \\(75\\) \u4e2a epochs( \u5373\u8fed\u4ee3\u5468\u671f )\uff0c\u7136\u540e\u7528 \\(10^{-3}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 \\(30\\) \u4e2aepochs\uff0c\u6700\u540e\u7528 \\(10^{-4}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 30\u4e2aepochs\u3002 \u2003 \u4e3a\u4e86\u907f\u514d\u8fc7\u5ea6\u62df\u5408\uff0c\u6211\u4eec\u4f7f\u7528 \\(dropout\\) \u548c \u5e7f\u6cdb\u7684\u6570\u636e\u589e\u5f3a\u3002\u5728\u7b2c\u4e00\u4e2a\u8fde\u63a5\u5c42\u4e4b\u540e\u6211\u4eec\u4e22\u5f03\u5177\u6709\u901f\u7387=0.5\u7684\u5c42\uff0c\u9632\u6b62\u5c42\u4e4b\u95f4\u7684\uff08\u76f8\u4e92\u5f71\u54cd\uff09\u3002\u5bf9\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u6211\u4eec\u5f15\u5165\u968f\u673a\u7f29\u653e\u548c\u6700\u591a\u539f\u59cb\u56fe\u50cf\u5927\u5c0f\u768420%\u7684translations\u3002\u6211\u4eec\u8fd8\u968f\u673a\u8c03\u6574\u66dd\u5149\u548c\u9971\u548c\u5ea6\u7684\u56fe\u50cf\u591a\u8fbe1.5\u500d\u7684HSV\u989c\u8272\u7a7a\u95f4\u3002 \u2003\u5728\u7b2c\u4e00\u4e2a\u8fde\u63a5\u5c42\u4e4b\u540e\uff0c \\(dropout\\) \u5c42\u4f7f\u7528rate=0.5\u7684\u6bd4\u4f8b\uff0c\u9632\u6b62\u5c42\u4e4b\u95f4\u7684\u76f8\u4e92\u5f71\u54cd( co-adaptation )[18]\u3002\u5bf9\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u6211\u4eec\u5f15\u5165\u9ad8\u8fbe\u539f\u59cb\u56fe\u50cf20%\u5927\u5c0f\u7684\u968f\u673a\u7f29\u653e\u548c\u8f6c\u6362\u3002\u6211\u4eec\u8fd8\u5728HSV\u8272\u5f69\u7a7a\u95f4\u4e2d\u4f7f\u7528\u9ad8\u8fbe1.5\u7684\u56e0\u5b50\u6765\u968f\u673a\u8c03\u6574\u56fe\u50cf\u7684\u66dd\u5149\u548c\u9971\u548c\u5ea6\u3002","title":"2.2 \u8bad\u7ec3"},{"location":"thesis_interpretation/01_yolo.html#23","text":"\u4e0e\u8bad\u7ec3\u65f6\u4e00\u6837\uff0c\u9884\u6d4b\u6d4b\u8bd5\u56fe\u50cf\u7684\u68c0\u6d4b\u53ea\u9700\u8981\u4e00\u6b21\u7f51\u7edc\u8bc4\u4f30\u3002\u5728 \\(Pascal \\ VOC\\) \u4e0a\uff0c\u6bcf\u5f20\u56fe\u50cf\u4e0a\u7f51\u7edc\u9884\u6d4b98\u4e2a\u8fb9\u754c\u6846\uff08 \u8bd1\u8005\u6ce8\uff1a\u6bcf\u5f20\u56fe\u50cf\u88ab\u5212\u5206\u62107 7\u7684\u683c\u5b50\uff0c\u6bcf\u4e2a\u683c\u5b50\u9884\u6d4b\u4e24\u4e2a\u8fb9\u754c\u6846\uff0c\u603b\u517198\u4e2a\u8fb9\u754c\u6846*\uff09\u548c\u6bcf\u4e2a\u6846\u7684\u7c7b\u522b\u6982\u7387\u3002\u4e0e\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c \\(YOLO\\) \u5728\u6d4b\u8bd5\u65f6\u975e\u5e38\u5feb\uff0c\u56e0\u4e3a\u5b83\u53ea\u9700\u8981\u8fd0\u884c\u4e00\u6b21\u7f51\u7edc\u8bc4\u4f30\u3002 \u2003\u7f51\u683c\u8bbe\u8ba1\u52a0\u5f3a\u4e86\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u7a7a\u95f4\u591a\u6837\u6027\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u76ee\u6807\u843d\u5728\u54ea\u4e2a\u7f51\u683c\u5355\u5143\u683c\u4e2d\u662f\u5f88\u6e05\u695a\u7684\uff0c\u7f51\u7edc\u9884\u6d4b\u7684\u6bcf\u4e2a\u76ee\u6807\u5bf9\u5e94\u4e00\u4e2a\u6846\u3002\u4e00\u4e9b\u5927\u7684\u76ee\u6807\u6216\u9760\u8fd1\u591a\u4e2a\u7f51\u683c\u5355\u5143\u8fb9\u754c\u7684\u76ee\u6807\u53ef\u4ee5\u88ab\u591a\u4e2a\u7f51\u683c\u5355\u5143\u5f88\u597d\u5730\u5b9a\u4f4d\u3002\u975e\u6781\u5927\u503c\u6291\u5236\uff08 \u5373NMS \uff09\u53ef\u4ee5\u7528\u6765\u4fee\u6b63\u8fd9\u4e9b\u591a\u91cd\u68c0\u6d4b\u3002\u867d\u7136\u4e0d\u50cf \\(R-CNN\\) \u6216 \\(DPM\\) \u90a3\u6837\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u975e\u6700\u5927\u6291\u5236\u589e\u52a0\u4e862~3%\u7684 \\(mAP\\) \u3002","title":"2.3 \u63a8\u7406"},{"location":"thesis_interpretation/01_yolo.html#24-yolo","text":"YOLO\u5bf9\u8fb9\u754c\u6846\u9884\u6d4b\u65bd\u52a0\u4e86\u5f88\u5f3a\u7684\u7a7a\u95f4\u7ea6\u675f\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u683c\u53ea\u80fd\u9884\u6d4b\u4e24\u4e2a\u6846\uff0c\u5e76\u4e14\u53ea\u80fd\u6709\u4e00\u4e2a\u7c7b\u3002\u8fd9\u79cd\u7a7a\u95f4\u7ea6\u675f\u9650\u5236\u4e86\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u9884\u6d4b\u7684\u9644\u8fd1\u7269\u4f53\u7684\u6570\u91cf\u3002\u6211\u4eec\u7684\u6a21\u578b\u5f88\u96be\u5904\u7406\u6210\u7fa4\u51fa\u73b0\u7684\u5c0f\u7269\u4f53\uff0c\u6bd4\u5982\u9e1f\u7fa4\u3002 \u2003 \u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u5b66\u4e60\u4ece\u6570\u636e\u4e2d\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u56e0\u6b64\u5b83\u5f88\u96be\u6cdb\u5316\u5230\u65b0\u7684\u3001\u4e0d\u5e38\u89c1\u7684\u957f\u5bbd\u6bd4\u6216\u914d\u7f6e\u4e2d\u7684\u76ee\u6807\u3002\u6211\u4eec\u7684\u6a21\u578b\u4e5f\u4f7f\u7528\u76f8\u5bf9\u8f83\u7c97\u7cd9\u7684\u7279\u5f81\u6765\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u56e0\u4e3a\u6211\u4eec\u7684\u67b6\u6784\u5177\u6709\u6765\u81ea\u8f93\u5165\u56fe\u50cf\u7684\u591a\u4e2a\u4e0b\u91c7\u6837\u5c42\u3002 \u2003\u6700\u540e\uff0c\u5f53\u6211\u4eec\u8bad\u7ec3\u4e00\u4e2a\u8fd1\u4f3c\u68c0\u6d4b\u6027\u80fd\u7684\u635f\u5931\u51fd\u6570\u65f6\uff0c\u6211\u4eec\u7684\u635f\u5931\u51fd\u6570\u5bf9\u5f85\u5c0f\u8fb9\u754c\u6846\u4e0e\u5927\u8fb9\u754c\u6846\u7684\u4f1a\u6709\u540c\u6837\u7684\u8bef\u5dee\u3002\u5927\u8fb9\u754c\u6846\u7684\u5c0f\u8bef\u5dee\u901a\u5e38\u662f\u826f\u6027\u7684\uff0c\u4f46\u5c0f\u8fb9\u754c\u6846\u7684\u5c0f\u8bef\u5dee\u5bf9 \\(IOU\\) \u7684\u5f71\u54cd\u8981\u5927\u5f97\u591a\u3002\u6211\u4eec\u7684\u4e3b\u8981\u8bef\u5dee\u6765\u6e90\u662f\u5b9a\u4f4d\u8bef\u5dee\u3002","title":"2.4 YOLO\u7684\u5c40\u9650\u6027"},{"location":"thesis_interpretation/01_yolo.html#3","text":"\u76ee\u6807\u68c0\u6d4b\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u6838\u5fc3\u95ee\u9898\u3002\u68c0\u6d4b\u6d41\u7a0b\u901a\u5e38\u4ece\u8f93\u5165\u56fe\u50cf\u4e0a\u63d0\u53d6\u4e00\u7ec4\u5065\u58ee\u7684\u7279\u5f81\uff08 \\(Haar\\) [25]\uff0c \\(SIFT\\) [23]\uff0c \\(HOG\\) [4]\uff0c\u5377\u79ef\u7279\u5f81[6]\uff09\u5f00\u59cb\u3002\u7136\u540e\uff0c\u5206\u7c7b\u5668[36,21,13,10]\u6216\u5b9a\u4f4d\u5668[1,32]\u88ab\u7528\u6765\u8bc6\u522b\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u76ee\u6807\u3002 \u8fd9\u4e9b\u5206\u7c7b\u5668\u6216\u5b9a\u4f4d\u5668\u4ee5\u6ed1\u52a8\u7a97\u53e3\u7684\u65b9\u5f0f\u5728\u6574\u4e2a\u56fe\u50cf\u4e0a\u8fd0\u884c,\u6216\u8005\u5728\u56fe\u50cf\u4e2d\u7684\u4e00\u4e9b\u533a\u57df\u7684\u5b50\u96c6[35,15,39]\u4e0a\u3002 \u6211\u4eec\u5c06 \\(YOLO\\) \u68c0\u6d4b\u7cfb\u7edf\u4e0e\u51e0\u79cd\u9876\u7ea7\u68c0\u6d4b\u6846\u67b6\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u7a81\u51fa\u4e86\u4e3b\u8981\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\u3002 \u2003 \u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b \uff08 Deformable parts models \uff09\u3002\u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b\uff08 \\(DPM\\) \uff09\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b[10]\u3002DPM\u4f7f\u7528\u4e0d\u76f8\u4ea4\u7684\u6d41\u7a0b\u6765\u63d0\u53d6\u9759\u6001\u7279\u5f81\uff0c\u5bf9\u533a\u57df\u8fdb\u884c\u5206\u7c7b\uff0c\u9884\u6d4b\u9ad8\u8bc4\u5206\u533a\u57df\u7684\u8fb9\u754c\u6846\u7b49\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u7528\u5355\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u66ff\u6362\u6240\u6709\u8fd9\u4e9b\u4e0d\u540c\u7684\u90e8\u5206\u3002\u7f51\u7edc\u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3001\u8fb9\u754c\u6846\u9884\u6d4b\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u3002\u7f51\u7edc\u5185\u5d4c\u8bad\u7ec3\u7279\u5f81\u800c\u4e0d\u662f\u9759\u6001\u7279\u5f81\uff0c\u5e76\u4f18\u5316\u5b83\u4eec\u5b8c\u6210\u68c0\u6d4b\u4efb\u52a1\u3002\u6211\u4eec\u7684\u7edf\u4e00\u67b6\u6784\u83b7\u5f97\u4e86\u6bd4DPM\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u6a21\u578b\u3002 \u2003 \\(R-CNN\\) \u53ca\u5176\u53d8\u79cd\u4f7f\u7528 \\(region \\ proposals\\) \u800c\u4e0d\u662f\u6ed1\u52a8\u7a97\u53e3\u6765\u67e5\u627e\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u3002Selective Search[35]\u4ea7\u751f\u6f5c\u5728\u7684\u8fb9\u754c\u6846\u3001\u5377\u79ef\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\u3001 \\(SVM\\) \u5bf9\u8fb9\u754c\u6846\u8fdb\u884c\u8bc4\u5206\u3001\u7ebf\u6027\u6a21\u578b\u8c03\u6574\u8fb9\u754c\u6846\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u6d88\u9664\u91cd\u590d\u68c0\u6d4b\u3002\u8fd9\u4e2a\u590d\u6742\u6d41\u7a0b\u7684\u6bcf\u4e2a\u9636\u6bb5\u90fd\u5fc5\u987b\u72ec\u7acb\u5730\u8fdb\u884c\u7cbe\u786e\u8c03\u6574\uff0c\u6240\u5f97\u5230\u7684\u7cfb\u7edf\u975e\u5e38\u6162\uff0c\u6d4b\u8bd5\u65f6\u6bcf\u5f20\u56fe\u50cf\u9700\u8981\u8d85\u8fc740\u79d2[14]\u3002 \\(YOLO\\) \u4e0e $R-CNN $ \u6709\u4e00\u4e9b\u76f8\u4f3c\u4e4b\u5904\u3002\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u63d0\u51fa\u6f5c\u5728\u7684\u8fb9\u754c\u6846\u5e76\u4f7f\u7528\u5377\u79ef\u7279\u5f81\u5bf9\u8fd9\u4e9b\u6846\u8fdb\u884c\u8bc4\u5206\u3002\u4f46\u662f\u6211\u4eec\u7684\u7cfb\u7edf\u5bf9\u7f51\u683c\u5355\u5143\u63d0\u51fa\u8fdb\u884c\u4e86\u7a7a\u95f4\u9650\u5236\uff0c\u8fd9\u6709\u52a9\u4e8e\u7f13\u89e3\u5bf9\u540c\u4e00\u76ee\u6807\u7684\u591a\u6b21\u68c0\u6d4b\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u8fd8\u63d0\u51fa\u4e86\u66f4\u5c11\u7684\u8fb9\u754c\u6846\uff0c\u6bcf\u5f20\u56fe\u50cf\u53ea\u6709 \\(98\\) \u4e2a\uff0c\u800c \\(Selective Search\\) \u5219\u9700\u8981 \\(2000\\) \u4e2a\u5de6\u53f3\u3002\u6700\u540e\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u8fd9\u4e9b\u5355\u72ec\u7684\u7ec4\u4ef6\u7ec4\u5408\u6210\u4e00\u4e2a\u5355\u4e00\u7684\u3001\u5171\u540c\u4f18\u5316\u7684\u6a21\u578b\u3002 \u2003 \u5176\u5b83\u5feb\u901f\u68c0\u6d4b\u5668( Other Fast Detectors ) \u3002 \\(Fast\\) \u548c \\(Faster \\ R-CNN\\) \u901a\u8fc7\u5171\u4eab\u8ba1\u7b97\u548c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3 \\(Selective \\ Search\\) \u6765\u63d0\u51fa\u533a\u57df\u52a0\u901f \\(R-CNN\\) \u6846\u67b6[14][28]\u3002\u867d\u7136\u5b83\u4eec\u63d0\u4f9b\u4e86\u6bd4 \\(R-CNN\\) \u66f4\u5feb\u7684\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u5ea6\uff0c\u4f46\u4e24\u8005\u4ecd\u7136\u4e0d\u80fd\u8fbe\u5230\u5b9e\u65f6\u6027\u80fd\u3002 \u2003\u8bb8\u591a\u7814\u7a76\u5de5\u4f5c\u96c6\u4e2d\u5728\u52a0\u5feb \\(DPM\\) \u6d41\u7a0b\u4e0a[31][38][5]\u3002\u5b83\u4eec\u52a0\u901f \\(HOG\\) \u8ba1\u7b97\uff0c\u4f7f\u7528\u7ea7\u8054\uff0c\u5e76\u5c06\u8ba1\u7b97\u63a8\u52a8\u5230 \\(GPU\\) \u4e0a\u3002\u4f46\u662f\uff0c\u5b9e\u9645\u4e0a \\(DPM\\) [31]\u5b9e\u65f6\u8fd0\u884c\u53ea\u8fbe\u5230 \\(30Hz\\) \u3002 \u2003 \\(YOLO\\) \u4e0d\u662f\u8bd5\u56fe\u4f18\u5316\u5927\u578b\u68c0\u6d4b\u6d41\u7a0b\u7684\u5355\u4e2a\u7ec4\u4ef6\uff0c\u800c\u662f\u5b8c\u5168\u629b\u5f03\u6d41\u7a0b\uff0c\u4e3a\u63d0\u5347\u68c0\u6d4b\u901f\u5ea6\u800c\u91cd\u65b0\u8bbe\u8ba1\u3002 \u2003\u50cf\u4eba\u8138\u6216\u884c\u4eba\u7b49\u5355\u7c7b\u522b\u7684\u68c0\u6d4b\u5668\u53ef\u4ee5\u88ab\u9ad8\u5ea6\u4f18\u5316\uff0c\u56e0\u4e3a\u4ed6\u4eec\u53ea\u9700\u5904\u7406\u66f4\u5c11\u7684\u591a\u6837\u6027[37]\u3002 \\(YOLO\\) \u662f\u4e00\u79cd\u901a\u7528\u7684\u68c0\u6d4b\u5668\uff0c\u53ef\u4ee5\u5b66\u4e60\u540c\u65f6\u68c0\u6d4b\u5404\u79cd\u76ee\u6807\u3002 \u2003 Deep MultiBox :\u4e0eR-CNN\u4e0d\u540c\uff0cSzegedy\u7b49\u4eba\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u611f\u5174\u8da3\u533a\u57df\uff08 ROI \uff09[8]\uff0c\u800c\u4e0d\u662f\u4f7f\u7528 \\(Selective \\ Search\\) \u3002MultiBox\u8fd8\u53ef\u4ee5\u901a\u8fc7\u7528\u5355\u7c7b\u522b\u9884\u6d4b\u66ff\u6362\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u6765\u6267\u884c\u5355\u76ee\u6807\u68c0\u6d4b\u3002\u7136\u800c\uff0c \\(MultiBox\\) \u65e0\u6cd5\u6267\u884c\u901a\u7528\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u5e76\u4e14\u4ecd\u7136\u53ea\u662f\u4e00\u4e2a\u8f83\u5927\u7684\u68c0\u6d4b\u6d41\u7a0b\u4e2d\u7684\u4e00\u90e8\u5206\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u5bf9\u56fe\u50cf\u5757\u8fdb\u884c\u5206\u7c7b\u3002 \\(YOLO\\) \u548c \\(MultiBox\\) \u90fd\u4f7f\u7528\u5377\u79ef\u7f51\u7edc\u6765\u9884\u6d4b\u56fe\u50cf\u4e2d\u7684\u8fb9\u754c\u6846\uff0c\u4f46\u662f \\(YOLO\\) \u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002 \u2003 \\(OverFeat\\) :Sermanet\u7b49\u4eba\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u5b9a\u4f4d\u5de5\u4f5c\uff0c\u5e76\u4f7f\u8be5\u5b9a\u4f4d\u5668\u8fdb\u884c\u68c0\u6d4b[32]\u3002 \\(OverFeat\\) \u53ef\u4ee5\u9ad8\u6548\u5730\u6267\u884c\u6ed1\u52a8\u7a97\u53e3\u68c0\u6d4b\uff0c\u4f46\u5b83\u4ecd\u7136\u662f\u4e00\u4e2a\u4e0d\u8fde\u8d2f\u7684\u7cfb\u7edf\u3002 \\(OverFeat\\) \u4f18\u5316\u4e86\u5b9a\u4f4d\uff0c\u800c\u4e0d\u662f\u68c0\u6d4b\u6027\u80fd\u3002\u50cf \\(DPM\\) \u4e00\u6837\uff0c\u5b9a\u4f4d\u5668\u5728\u8fdb\u884c\u9884\u6d4b\u65f6\u53ea\u80fd\u770b\u5230\u5c40\u90e8\u4fe1\u606f\u3002 \\(OverFeat\\) \u4e0d\u80fd\u63a8\u7406\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u56e0\u6b64\u9700\u8981\u5927\u91cf\u7684\u540e\u5904\u7406\u6765\u4ea7\u751f\u4e00\u81f4\u7684\u68c0\u6d4b\u3002 \u2003 \\(MultiGrasp\\) : \u6211\u4eec\u7684\u5de5\u4f5c\u5728\u8bbe\u8ba1\u4e0a\u7c7b\u4f3c\u4e8e \\(Redmon\\) \u7b49[27]\u7684 \\(grasp\\) \u68c0\u6d4b\u3002\u6211\u4eec\u5bf9\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u7f51\u683c\u65b9\u6cd5\u662f\u57fa\u4e8e \\(MultiGrasp\\) \u7cfb\u7edf\u5bf9\u4e8e \\(grasp\u68c0\u6d4b\\) \u7684\u56de\u5f52\u5206\u6790\u3002\u7136\u800c\uff0c \\(grasp\\) \u68c0\u6d4b\u6bd4\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u8981\u7b80\u5355\u5f97\u591a\u3002 \\(MultiGrasp\\) \u53ea\u9700\u8981\u4e3a\u5305\u542b\u4e00\u4e2a\u76ee\u6807\u7684\u56fe\u50cf\u9884\u6d4b\u4e00\u4e2a\u53ef\u4ee5 \\(grasp\\) \u7684\u533a\u57df( \u5373\u9002\u5408\u6293\u53d6\u7684\u533a\u57df )\u3002\u4e0d\u5fc5\u4f30\u8ba1\u76ee\u6807\u7684\u5927\u5c0f\u3001\u4f4d\u7f6e\u6216\u76ee\u6807\u8fb9\u754c\u6216\u9884\u6d4b\u76ee\u6807\u7684\u7c7b\u522b\uff0c\u53ea\u9700\u8981\u627e\u5230\u9002\u5408\u6293\u53d6\u7684\u533a\u57df\u3002 \\(YOLO\\) \u53ef\u4ee5\u9884\u6d4b\u56fe\u50cf\u4e2d\u591a\u4e2a\u7c7b\u522b\u7684\u591a\u4e2a\u76ee\u6807\u7684\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u3002","title":"3. \u4e0e\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u7684\u6bd4\u8f83"},{"location":"thesis_interpretation/01_yolo.html#4","text":"\u9996\u5148\uff0c\u6211\u4eec\u5728 \\(PASCAL \\ VOC \\ 2007\\) \u4e0a\u6bd4\u8f83\u4e86 \\(YOLO\\) \u548c\u5176\u5b83\u7684\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf\u3002\u4e3a\u4e86\u7406\u89e3 \\(YOLO\\) \u548c \\(R-CNN\\) \u53d8\u79cd\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u63a2\u7d22\u4e86 \\(YOLO\\) \u548c \\(R-CNN\\) \u6027\u80fd\u6700\u9ad8\u7684\u7248\u672c\u4e4b\u4e00 \\(Fast\\ R-CNN\\) [14]\u5728 \\(VOC \\ 2007\\) \u4e0a\u9519\u8bef\u7387\u3002\u6839\u636e\u4e0d\u540c\u7684\u8bef\u5dee\u66f2\u7ebf\uff0c\u6211\u4eec\u7684\u7814\u7a76\u663e\u793a \\(YOLO\\) \u53ef\u4ee5\u7528\u6765\u91cd\u65b0\u8bc4\u4f30 \\(Fast \\ R-CNN\\) \u68c0\u6d4b\uff0c\u5e76\u51cf\u5c11\u80cc\u666f\u5047\u9633\u6027\u5e26\u6765\u7684\u8bef\u5dee\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u5728 \\(VOC \\ 2012\\) \u4e0a\u7684\u7ed3\u679c\uff0c\u5e76\u4e0e\u76ee\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u6bd4\u8f83\u4e86 \\(mAP\\) \u3002\u6700\u540e\uff0c\u5728\u4e24\u4e2a\u827a\u672f\u54c1\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86\u6211\u4eec \\(YOLO\\) \u6bd4\u5176\u4ed6\u68c0\u6d4b\u5668\u66f4\u80fd\u6cdb\u5316\u5230\u65b0\u7684\u9886\u57df\u3002","title":"4. \u6d4b\u8bd5\u5b9e\u9a8c"},{"location":"thesis_interpretation/01_yolo.html#41","text":"\u76ee\u6807\u68c0\u6d4b\u65b9\u9762\u7684\u8bb8\u591a\u7814\u7a76\u5de5\u4f5c\u90fd\u96c6\u4e2d\u5728\u5bf9\u6807\u51c6\u68c0\u6d4b\u6d41\u7a0b[5]\uff0c[38]\uff0c[31]\uff0c[14]\uff0c[17]\uff0c[28]\u63d0\u5347\u901f\u5ea6\u4e0a\u3002\u7136\u800c\uff0c\u53ea\u6709Sadeghi\u7b49\u771f\u6b63\u7814\u7a76\u51fa\u4e86\u4e00\u4e2a\u5b9e\u65f6\u8fd0\u884c\u7684\u68c0\u6d4b\u7cfb\u7edf\uff08\u6bcf\u79d230\u5e27\u6216\u66f4\u597d\uff09[31]\u3002\u6211\u4eec\u5c06YOLO\u4e0e\u4ed6\u4eecDPM\u7684GPU\u5b9e\u73b0\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5176\u572830Hz\u6216100Hz\u4e0b\u8fd0\u884c\u3002\u867d\u7136\u5176\u5b83\u7684\u7814\u7a76\u5de5\u4f5c\u6ca1\u6709\u8fbe\u5230\u5b9e\u65f6\u68c0\u6d4b\u7684\u6807\u51c6\uff0c\u6211\u4eec\u4e5f\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u76f8\u5bf9mAP\u548c\u901f\u5ea6\u6765\u68c0\u67e5\u76ee\u6807\u68c0\u6d4b\u7cfb\u7edf\u4e2d\u7cbe\u5ea6\u2014\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002 \u2003 \\(Fast \\ YOLO\\) \u662f \\(PASCAL\\) \u4e0a\u6700\u5feb\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5;\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u662f\u73b0\u5b58\u901f\u5ea6\u6700\u5feb\u7684\u7269\u4f53\u63a2\u6d4b\u5668\u3002 \\(mAP\\) \u7684\u51c6\u786e\u7387\u4e3a \\(52.7%\\) \uff0c\u662f\u4e4b\u524d\u5b9e\u65f6\u68c0\u6d4b\u5de5\u4f5c\u7684\u4e24\u500d\u591a\u3002 \\(YOLO\\) \u5c06 \\(mAP\\) \u63a8\u81f3 \\(63.4%\\) \uff0c\u540c\u65f6\u4ecd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002 \u2003\u6211\u4eec\u4e5f\u4f7f\u7528 \\(VGG-16\\) \u8bad\u7ec3\u4e86 \\(YOLO\\) \u3002\uff08 \u8bd1\u8005\u6ce8\uff1aYOLO\u4f7f\u7528\u4e86\u4f5c\u8005\u81ea\u5df1\u5f00\u53d1\u7684DarkNet\u6a21\u578b\u4e3abaseline \uff09\u8fd9\u4e2a\u6a21\u578b\u6bd4 \\(YOLO\\) \u66f4\u51c6\u786e\uff0c\u4f46\u901f\u5ea6\u6162\u5f97\u591a\u3002\u8fd9\u4e2a\u6a21\u578b\u53ef\u4ee5\u7528\u6765\u4e0e\u4f9d\u8d56\u4e8e \\(VGG-16\\) \u7684\u5176\u5b83\u68c0\u6d4b\u7cfb\u7edf\u4f5c\u6bd4\u8f83\uff0c\u4f46\u7531\u4e8e\u5b83\u6bd4\u5b9e\u65f6\u7684 \\(YOLO\\) \u66f4\u6162\uff0c\u672c\u6587\u7684\u5176\u4f59\u90e8\u5206\u4e3b\u8981\u5173\u6ce8\u6211\u4eec\u66f4\u5feb\u7684\u6a21\u578b\u3002 \u2003 \\(Fastest \\ DPM\\) \u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u592a\u591a \\(mAP\\) \u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5730\u52a0\u901f \\(DPM\\) \uff0c\u4f46\u5b83\u4ecd\u7136\u4f1a\u5c06\u5b9e\u65f6\u6027\u80fd\u964d\u4f4e2\u500d[38]\u3002\u4e0e\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u76f8\u6bd4\uff0c \\(DPM\\) \u76f8\u5bf9\u8f83\u4f4e\u7684\u68c0\u6d4b\u7cbe\u5ea6\u4e5f\u662f\u5176\u9650\u5236\u3002 \\(\\begin{array}{lrrr} \\text { Real-Time Detectors } & \\text { Train } & \\text { mAP } & \\text { FPS } \\\\ \\hline \\text { 100Hz DPM [31] } & 2007 & 16.0 & 100 \\\\ \\text { 30Hz DPM [31] } & 2007 & 26.1 & 30 \\\\ \\text { Fast YOLO } & 2007+2012 & 52.7 & \\mathbf{1 5 5} \\\\ \\text { YOLO } & 2007+2012 & \\mathbf{6 3 . 4} & 45 \\\\ \\hline \\hline \\text { Less Than Real-Time } & & & \\\\ \\hline \\text { Fastest DPM [38] } & 2007 & 30.4 & 15 \\\\ \\text { R-CNN Minus R [20] } & 2007 & 53.5 & 6 \\\\ \\text { Fast R-CNN [14] } & 2007+2012 & 70.0 & 0.5 \\\\ \\text { Faster R-CNN VGG-16[28] } & 2007+2012 & 73.2 & 7 \\\\ \\text { Faster R-CNN ZF [28] } & 2007+2012 & 62.1 & 18 \\\\ \\text { YOLO VGG-16 } & 2007+2012 & 66.4 & 21 \\end{array}\\) \u88681\uff1aPASCAL VOC 2007 \u7684\u5b9e\u65f6\u7cfb\u7edf \u6bd4\u8f83\u5feb\u901f\u63a2\u6d4b\u5668\u7684\u6027\u80fd\u548c\u901f\u5ea6\u3002 \\(Fast \\ YOLO\\) \u662f \\(PASCAL \\ VOC\\) \u68c0\u6d4b\u8bb0\u5f55\u4e2d\u6700\u5feb\u7684\u68c0\u6d4b\u5668\uff0c\u51c6\u786e\u6027\u4ecd\u7136\u662f\u4efb\u4f55\u5176\u4ed6\u5b9e\u65f6\u68c0\u6d4b\u5668\u7684\u4e24\u500d\u3002 \\(YOLO\\) \u6bd4\u5feb\u901f\u7248\u672c\u66f4\u7cbe\u786e \\(10mAP\\) \uff0c\u540c\u65f6\u5b9e\u65f6\u901f\u5ea6\u8fdc\u8fdc\u9ad8\u4e8e\u5176\u4ed6\u68c0\u6d4b\u5668\u3002 \u2003 \\(R-CNN \\ minnus \\ R\\) \u5c06\u9009\u62e9\u6027\u641c\u7d22\u66ff\u6362\u4e3a\u9759\u6001\u8fb9\u754c\u6846proposals [20]\u3002\u867d\u7136\u901f\u5ea6\u6bd4R-CNN\u66f4\u5feb\uff0c\u4f46\u4ecd\u7136\u8fbe\u4e0d\u5230\u5b9e\u65f6\uff0c\u5e76\u4e14\u7531\u4e8e\u6ca1\u6709\u597d\u7684\u8fb9\u754c\u6846proposals\uff0c\u51c6\u786e\u6027\u53d7\u5230\u4e86\u4e25\u91cd\u5f71\u54cd\u3002 \u2003 \\(Fast \\ R-CNN\\) \u52a0\u5feb\u4e86 \\(R-CNN\\) \u7684\u5206\u7c7b\u9636\u6bb5\uff0c\u4f46\u662f\u4ecd\u7136\u4f9d\u8d56selective search\uff0c\u6bcf\u5f20\u56fe\u50cf\u9700\u8981\u82b1\u8d39\u5927\u7ea62\u79d2\u6765\u751f\u6210\u8fb9\u754c\u6846proposals\u3002\u56e0\u6b64\uff0c\u5b83\u5177\u6709\u5f88\u9ad8\u7684mAP\uff0c\u4f46\u662f0.5 fps\u7684\u901f\u5ea6\u4ecd\u79bb\u5b9e\u65f6\u6027\u5f88\u8fdc\u3002 \u2003 \u6700\u8fd1 \\(Faster \\ R-CNN\\) \u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u4e86selective search\u6765\u63d0\u51fa\u8fb9\u754c\u6846\uff0c\u7c7b\u4f3c\u4e8eSzegedy\u7b49[8]\u3002\u5728\u6211\u4eec\u7684\u6d4b\u8bd5\u4e2d\uff0c\u4ed6\u4eec\u6700\u7cbe\u786e\u7684\u6a21\u578b\u8fbe\u5230\u4e867fps\uff0c\u800c\u8f83\u5c0f\u7684\u3001\u4e0d\u592a\u7cbe\u786e\u7684\u6a21\u578b\u8fd0\u884c\u901f\u5ea6\u8fbe\u523018fps\u3002 \\(VGG-16\\) \u7248\u672c\u7684 \\(Faster \\ R-CNN\\) \u8981\u9ad8\u51fa \\(10mAP\\) \uff0c\u4f46\u901f\u5ea6\u6bd4 \\(YOLO\\) \u6162 \\(6\\) \u500d\u3002ZeilerFergus\u7684 \\(Faster \\ R-CNN\\) \u53ea\u6bd4 \\(YOLO\\) \u6162\u4e862.5\u500d\uff0c\u4f46\u4e5f\u4e0d\u592a\u51c6\u786e\u3002","title":"4.1 \u4e0e\u5176\u4ed6\u5b9e\u65f6\u7cfb\u7edf\u7684\u6bd4\u8f83"},{"location":"thesis_interpretation/01_yolo.html#42-voc-2007","text":"\u4e3a\u4e86\u8fdb\u4e00\u6b65\u68c0\u67e5 \\(YOLO\\) \u548c\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u8be6\u7ec6\u5206\u6790\u4e86 \\(VOC \\ 2007\\) \u7684\u7ed3\u679c\u3002\u6211\u4eec\u5c06 \\(YOLO\\) \u4e0e \\(Fast \\ R-CNN\\) \u8fdb\u884c\u6bd4\u8f83\uff0c\u56e0\u4e3a \\(Fast \\ R-CNN\\) \u662f \\(PASCAL\\) \u4e0a\u6027\u80fd\u6700\u9ad8\u7684\u68c0\u6d4b\u5668\u4e4b\u4e00\u5e76\u4e14\u5b83\u7684\u68c0\u6d4b\u4ee3\u7801\u662f\u53ef\u516c\u5f00\u5f97\u5230\u7684\u3002 \u2003\u6211\u4eec\u4f7f\u7528Hoiem\u7b49\u4eba[19]\u7684\u65b9\u6cd5\u548c\u5de5\u5177\u3002\u5bf9\u4e8e\u6d4b\u8bd5\u65f6\u7684\u6bcf\u4e2a\u7c7b\u522b\uff0c\u6211\u4eec\u53ea\u5173\u6ce8\u8fd9\u4e2a\u7c7b\u522b\u7684\u524dN\u4e2a\u9884\u6d4b\u3002\u6bcf\u4e2a\u9884\u6d4b\u8981\u4e48\u5f52\u4e3a\u6b63\u786e\uff0c\u8981\u4e48\u6839\u636e\u9519\u8bef\u7c7b\u578b\u8fdb\u884c\u5f52\u7c7b\uff1a Correct\uff1a\u5206\u7c7b\u6b63\u786e\u4e14 \\(IOU >0.5\\) \u3002 Localization\uff1a\u5206\u7c7b\u6b63\u786e\u4f46 \\(0.1<IOU<0.5\\) \u3002 Similar\uff1a\u5206\u7c7b\u7684\u7c7b\u522b\u76f8\u4f3c\u4e14 \\(IOU>0.1\\) \u3002 Other\uff1a\u7c7b\u522b\u9519\u8bef\uff0c \\(IOU>0.1\\) \u3002 Background\uff1a\u5206\u7c7b\u4e3a\u5176\u5b83\u4efb\u4f55\u76ee\u6807\uff0c \\(IOU<0.1\\) \u3002 \u56fe4\uff1a\u9519\u8bef\u5206\u6790: \\(Fast \\ R-CNN\\) vs. \\(YOLO\\) \u8fd9\u4e9b\u56fe\u8868\u663e\u793a\u4e86\u5404\u79cd\u7c7b\u522b\u7684\u524dN\u4e2a\u68c0\u6d4b\u4e2d\u5b9a\u4f4d\u548c\u80cc\u666f\u9519\u8bef\u7684\u767e\u5206\u6bd4(N = #\u8be5\u7c7b\u522b\u4e2d\u7684\u76ee\u6807\u6570) \u2003 \\(YOLO\\) \u5f88\u96be\u6b63\u786e\u6b63\u786e\u5b9a\u4f4d\u76ee\u6807\u3002\u5b9a\u4f4d\u8bef\u5dee\u6bd4\u5176\u5b83\u8bef\u5dee\u9519\u8bef\u6765\u6e90\u603b\u5408\u90fd\u591a\u3002 \\(Fast \\ R-CNN\\) \u5b9a\u4f4d\u8bef\u5dee\u5c11\u5f88\u591a\uff0c\u4f46\u80cc\u666f\u8bef\u5dee\u66f4\u591a\u3002\u5b83\u7684\u68c0\u6d4b\u7ed3\u679c\u4e2d \\(13.6%\\) \u662f\u4e0d\u5305\u542b\u4efb\u4f55\u76ee\u6807\u7684\u5047\u9633\u6027\u3002 \\(Fast \\ R-CNN\\) \u4e0e \\(YOLO\\) \u76f8\u6bd4\uff0c\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u76ee\u6807\u7684\u53ef\u80fd\u6027\u9ad8\u51fa\u8fd13\u500d\u3002\uff08 \u8bd1\u8005\u6ce8\uff1a\u6839\u636e\u56fe4\uff0c13.6/4.75=2.86 \uff09","title":"4.2 \u5728VOC 2007\u4e0a\u7684\u8bef\u5dee\u5206\u6790"},{"location":"thesis_interpretation/01_yolo.html#43-fast-r-cnn-yolo","text":"\\(YOLO\\) \u6bd4 \\(Fast \\ R-CNN\\) \u7684\u80cc\u666f\u8bef\u68c0\u8981\u5c11\u5f97\u591a\u3002\u901a\u8fc7\u4f7f\u7528 \\(YOLO\\) \u6d88\u9664 \\(Fast \\ R-CNN\\) \u7684\u80cc\u666f\u68c0\u6d4b\uff0c\u6211\u4eec\u83b7\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u5bf9\u4e8e \\(RCNN\\) \u9884\u6d4b\u7684\u6bcf\u4e2a\u8fb9\u754c\u6846\uff0c\u6211\u4eec\u68c0\u67e5 \\(YOLO\\) \u662f\u5426\u9884\u6d4b\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u7684\u6846\u3002\u5982\u679c\u662f\u8fd9\u6837\uff0c\u6211\u4eec\u6839\u636e \\(YOLO\\) \u9884\u6d4b\u7684\u6982\u7387\u548c\u4e24\u4e2a\u76d2\u5b50\u4e4b\u95f4\u7684\u91cd\u53e0\u6765\u5bf9\u8fd9\u4e2a\u9884\u6d4b\u8fdb\u884c\u6539\u8fdb\u3002 \u2003\u6700\u597d\u7684 \\(Fast \\ R-CNN\\) \u6a21\u578b\u5728 \\(VOC \\ 2007\\) \u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230\u4e86 71.8%\u7684 \\(mAP\\) \u3002\u5f53\u4e0e \\(YOLO\\) \u7ed3\u5408\u65f6\uff0c\u5176 \\(mAP\\) \u589e\u52a0\u4e86 3.2% \u8fbe\u5230\u4e86 75.0% \u3002\u6211\u4eec\u4e5f\u5c1d\u8bd5\u5c06\u6700\u597d\u7684 \\(Fast \\ R-CNN\\) \u6a21\u578b\u4e0e\u5176\u5b83\u51e0\u4e2a\u7248\u672c\u7684 \\(Fast \\ R-CNN\\) \u7ed3\u5408\u8d77\u6765\u3002\u8fd9\u4e9b\u6a21\u578b\u7ec4\u5408\u4ea7\u751f\u4e860.3-0.6%\u7684\u5c0f\u5e45\u589e\u52a0\uff0c\u8be6\u89c1\u88682\u3002 \\(\\begin{array}{lrrr} & \\text { mAP } & \\text { Combined } & \\text { Gain } \\\\ \\hline \\text { Fast R-CNN } & 71.8 & - & - \\\\ \\hline \\text { Fast R-CNN (2007 data) } & \\mathbf{6 6 . 9} & 72.4 & .6 \\\\ \\text { Fast R-CNN (VGG-M) } & 59.2 & 72.4 & .6 \\\\ \\text { Fast R-CNN (CaffeNet) } & 57.1 & 72.1 & .3 \\\\ \\text { YOLO } & 63.4 & \\mathbf{7 5 . 0} & \\mathbf{3 . 2} \\end{array}\\) \u88682:VOC 2007\u7684\u6a21\u578b\u7ec4\u5408\u8bd5\u9a8c\u3002\u6211\u4eec\u7528 \\(Fast \\ R-CNN\\) \u7684\u6700\u4f73\u7248\u672c\u6765\u68c0\u9a8c\u5404\u79cd\u6a21\u578b\u7684\u7ec4\u5408\u6548\u679c\u3002 \\(Fast \\ R-CNN\\) \u7684\u5176\u4ed6\u7248\u672c\u53ea\u6539\u5584\u4e86\u5f88\u5c0f\u7684\u6027\u80fd\uff0c\u800c \\(YOLO\\) \u63d0\u4f9b\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002 \u88683:PASCAL VOC 2012\u6392\u884c\u699c\u30022015\u5e7411\u67086\u65e5\uff0cYOLO\u4e0e\u5b8c\u6574comp4(\u5141\u8bb8\u5916\u90e8\u6570\u636e)\u516c\u5f00\u6392\u884c\u699c\u7684\u5bf9\u6bd4\u3002 \\(mAP\\) \u548c \u6bcf\u4e2a\u7c7bAP \u90fd\u663e\u793a\u5728\u5404\u79cd\u68c0\u6d4b\u65b9\u6cd5\u3002 \\(YOLO\\) \u662f\u552f\u4e00\u7684\u5b9e\u65f6\u68c0\u6d4b\u5668\u3002 \\(Fast \\ R-CNN + YOLO\\) \u662f\u7b2c\u56db\u9ad8\u7684\u5f97\u5206\u65b9\u6cd5\uff0c\u6bd4 \\(Fast \\ R-CNN\\) \u63d0\u9ad8\u4e862.3%\u7684 \\(mAP\\) \u3002 \u2003\u6765\u81eaYOLO\u7684\u63d0\u5347\u4e0d\u4ec5\u4ec5\u662f\u6a21\u578b\u96c6\u6210\u7684\u526f\u4ea7\u54c1\uff0c\u56e0\u4e3a\u7ec4\u5408\u4e0d\u540c\u7248\u672c\u7684Fast R-CNN\u51e0\u4e4e\u6ca1\u6709\u4ec0\u4e48\u6539\u8fdb\u3002\u76f8\u53cd\uff0c\u6b63\u662f\u56e0\u4e3a \\(YOLO\\) \u5728\u6d4b\u8bd5\u65f6\u51fa\u73b0\u4e86\u5404\u79cd\u5404\u6837\u7684\u8bef\u5dee\uff0c\u6240\u4ee5\u5728\u63d0\u9ad8 \\(Fast \\ R-CNN\\) \u7684\u6027\u80fd\u65b9\u9762\u975e\u5e38\u6709\u6548\u3002 \u2003\u9057\u61be\u7684\u662f\uff0c\u8fd9\u4e2a\u7ec4\u5408\u5e76\u6ca1\u6709\u4ece \\(YOLO\\) \u7684\u901f\u5ea6\u4e2d\u53d7\u76ca\uff0c\u56e0\u4e3a\u6211\u4eec\u5206\u522b\u8fd0\u884c\u6bcf\u4e2a\u6a21\u578b\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u7ec4\u5408\u8d77\u6765\u3002\u4f46\u662f\uff0c\u7531\u4e8e \\(YOLO\\) \u901f\u5ea6\u5982\u6b64\u4e4b\u5feb\uff0c\u4e0e \\(Fast \\ R-CNN\\) \u76f8\u6bd4\uff0c\u4e0d\u4f1a\u663e\u8457\u7684\u589e\u52a0\u4efb\u4f55\u8ba1\u7b97\u65f6\u95f4\u3002","title":"4.3 \u7ed3\u5408 \\(Fast \\ R-CNN\\) \u548c \\(YOLO\\)"},{"location":"thesis_interpretation/01_yolo.html#44-voc-2012","text":"\u5728 \\(VOC \\ 2012\\) \u6d4b\u8bd5\u96c6\u4e0a\uff0c \\(YOLO\\) \u83b7\u5f97\u4e8657.9% \u7684 \\(mAP\\) \u3002\u8fd9\u4f4e\u4e8e\u73b0\u6709\u7684\u6700\u597d\u6280\u672f\uff0c\u5982\u88683\u6240\u793a\u5176\u63a5\u8fd1\u4e8e\u4f7f\u7528VGG-16\u7684\u539f\u59cbR-CNN\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u4e0e\u5176\u6700\u63a5\u8fd1\u7684\u7ade\u4e89\u5bf9\u624b\u76f8\u6bd4\uff0c\u9700\u8981\u6539\u5584\u5728\u5c0f\u76ee\u6807\u4e0a\u7684\u68c0\u6d4b\u3002\u5728\u6c34\u74f6\u3001\u7ef5\u7f8a\u548c\u7535\u89c6/\u663e\u793a\u5668\u7b49\u7c7b\u522b\u4e0a\uff0cYOLO\u7684\u5f97\u5206\u6bd4R-CNN\u6216Feature Edit\u4f4e8\u221210%\u3002\u7136\u800c\uff0c\u5728\u732b\u548c\u706b\u8f66\u7b49\u5176\u5b83\u7c7b\u522b\u4e0aYOLO\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u3002 \u2003\u6211\u4eec\u8054\u5408\u7684 \\(Fast \\ R-CNN+YOLO\\) \u6a21\u578b\u662f\u6027\u80fd\u6700\u9ad8\u7684\u68c0\u6d4b\u65b9\u6cd5\u4e4b\u4e00\u3002 \\(Fast \\ R-CNN\\) \u548c \\(YOLO\\) \u7684\u7ec4\u5408\u4e2d\u83b7\u5f97\u4e862.3%\u7684\u63d0\u9ad8\uff0c\u5728\u516c\u5f00\u6392\u884c\u699c\u4e0a\u63d0\u5347\u4e865\u4e2a\u540d\u6b21\u3002","title":"4.4 VOC 2012\u6761\u7ed3\u679c"},{"location":"thesis_interpretation/01_yolo.html#45","text":"\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u672f\u6570\u636e\u96c6\u4ee5\u76f8\u540c\u5206\u5e03\u83b7\u53d6\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u3002\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u4e2d\uff0c\u5f88\u96be\u9884\u6d4b\u6240\u6709\u53ef\u80fd\u7684\u6837\u672c\uff0c\u800c\u4e14\u6d4b\u8bd5\u6570\u636e\u53ef\u80fd\u4e0e\u7cfb\u7edf\u4e4b\u524d\u770b\u5230\u7684\u4e0d\u540c[3]\u3002( \u56e0\u4e3a\u6d4b\u8bd5\u6570\u636e\u4e0e\u6a21\u578b\u8bad\u7ec3\u7684\u6570\u636e\u53ef\u80fd\u5728\u98ce\u683c\u3001\u6a21\u5f0f\u3001\u76ee\u6807\u8868\u73b0\u5f62\u5f0f\u7b49\u65b9\u9762\u6709\u5f88\u5927\u7684\u533a\u522b\uff0c\u4f8b\u5982\u6a21\u578b\u8bad\u7ec3\u65f6\u7684\u6570\u636e\u662f\u7528\u76f8\u673a\u62cd\u6444\u7684\u56fe\u50cf\uff0c\u800c\u6d4b\u8bd5\u65f6\u7528\u6cb9\u753b\u4f5c\u54c1\u56fe\u50cf\uff0c\u6b64\u65f6\u7531\u4e8e\u6cb9\u753b\u4f5c\u54c1\u6bd4\u8f83\u62bd\u8c61\uff0c\u6a21\u578b\u5c31\u53ef\u80fd\u65e0\u6cd5\u5f88\u597d\u5730\u8bc6\u522b\u5176\u4e2d\u7684\u76ee\u6807 ) \u6211\u4eec\u5728 \\(Picasso\\) \u6570\u636e\u96c6\u4e0a[12]\u548c \\(People-Art\\) \u6570\u636e\u96c6[3]\u4e0a\u5c06 \\(YOLO\\) \u4e0e\u5176\u5b83\u7684\u68c0\u6d4b\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\uff0c\u4e24\u4e2a\u6570\u636e\u96c6\u7528\u4e8e\u827a\u672f\u54c1\u4e0a\u7684\u4eba\u7269\u68c0\u6d4b\u3002 \u2003\u56fe5\u6240\u793a\u4e3a \\(YOLO\\) \u548c\u5176\u5b83\u68c0\u6d4b\u65b9\u6cd5\u4e4b\u95f4\u6027\u80fd\u6bd4\u8f83\u7684\u7ed3\u679c\u3002\u4f5c\u4e3a\u53c2\u8003\uff0c\u6211\u4eec\u5728person\u4e0a\u63d0\u4f9b \\(VOC \\ 2007\\) \u7684\u68c0\u6d4b \\(AP\\) \uff0c\u5176\u4e2d\u6240\u6709\u6a21\u578b\u4ec5\u5728 \\(VOC \\ 2007\\) \u6570\u636e\u4e0a\u8bad\u7ec3\u3002\u5728Picasso\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u7684\u6a21\u578b\u4f7f\u7528 \\(VOC \\ 2012\\) \u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u800c \\(People-Art\\) \u6570\u636e\u96c6\u6d4b\u8bd5\u7684\u6a21\u578b\u4f7f\u7528 \\(VOC \\ 2010\\) \u8fdb\u884c\u4e86\u8bad\u7ec3\u3002 \u2003 \\(R-CNN\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u7684 \\(AP\\) \u5f88\u9ad8\u3002\u4f46\u662f\u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u7cbe\u5ea6\u4e0b\u964d\u4e86\u5f88\u591a\u3002 \\(R-CNN\\) \u4f7f\u7528Selective Search\u6765\u751f\u6210\u5019\u9009\u8fb9\u754c\u6846\uff0c\u73b0\u5728\u6362\u4e3a\u81ea\u7136\u56fe\u7247\u3002\u5728\u5206\u7c7b\u65f6\u53ea\u80fd\u770b\u5230\u56fe\u7247\u7684\u4e00\u4e2a\u5c0f\u533a\u57df\uff0c\u9700\u8981\u8d28\u91cf\u5f88\u9ad8\u7684\u5019\u9009\u624d\u53ef\u4ee5\u3002 \u2003 \\(DPM\\) \u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u540e \\(AP\\) \u8fd8\u4fdd\u6301\u7684\u4e0d\u9519\u3002\u4e4b\u524d\u7684\u5de5\u4f5c\u7406\u8bba \\(DPM\\) \u8868\u73b0\u4e0d\u9519\u7684\u539f\u56e0\u662f\u5b83\u5bf9\u4e8e\u7269\u4f53\u7684\u5f62\u72b6\u548c\u5e03\u5c40\u6709\u5f88\u5f3a\u7684\u7a7a\u95f4\u6a21\u578b\u3002\u867d\u7136 \\(DPM\\) \u6ca1\u6709\u50cf \\(R-CNN\\) \u90a3\u6837\u7cbe\u5ea6\u4e0b\u964d\u5f88\u591a\uff0c\u4f46\u662f\u5b83\u7684 \\(AP\\) \u672c\u6765\u5c31\u6bd4\u8f83\u4f4e\u3002 \u2003 \\(YOLO\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u7684\u8868\u73b0\u4e0d\u9519\uff0c\u5f53\u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u65f6\u6bd4\u5176\u4ed6\u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\u7684\u5c11\u3002\u4e0e \\(DPM\\) \u7c7b\u4f3c\uff0c \\(YOLO\\) \u5bf9\u7269\u4f53\u7684\u5927\u5c0f\u548c\u5f62\u72b6\u8fdb\u884c\u5efa\u6a21\uff0c\u8fd8\u6709\u7269\u4f53\u548c\u7269\u4f53\u901a\u5e38\u51fa\u73b0\u7684\u4f4d\u7f6e\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u827a\u672f\u54c1\u548c\u81ea\u7136\u56fe\u7247\u5728\u50cf\u7d20\u7ea7\u522b\u4e0a\u5dee\u5f02\u5f88\u5927\uff0c\u4f46\u662f\u7269\u4f53\u7684\u5927\u5c0f\u548c\u5f62\u72b6\u662f\u7c7b\u4f3c\u7684\uff0c\u56e0\u6b64 \\(YOLO\\) \u4ecd\u7136\u53ef\u4ee5\u5f88\u597d\u7684\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u68c0\u6d4b\u7269\u4f53\u3002 \u56fe5\uff1aPicasso \u548c People-Art \u6570\u636e\u96c6\u7efc\u5408\u7684\u7ed3\u679c\u3002 (a): \u5728Picasso\u6570\u636e\u96c6\u4e0a\u7684PR\u66f2\u7ebf\u3002 (b): \u5728 VOC 2007, Picasso, \u548c People-Art \u7684\u7ed3\u679c\u6570\u636e\u3002Picasso \u6570\u636e\u96c6\u8bc4\u4f30AP\u548c\u6700\u4f73 \\(F_1\\) \u5206\u6570\u3002 \u56fe6\uff1a\u68c0\u6d4b\u7684\u7ed3\u679c\u3002 \\(YOLO\\) \u8fd0\u884c\u7684\u6837\u672c\u827a\u672f\u4f5c\u54c1 \u548c \u6765\u81ea\u4e92\u8054\u7f51\u7684\u81ea\u7136\u56fe\u50cf\u3002\u867d\u7136\u5b83\u786e\u5b9e\u8ba4\u4e3a\u4e00\u4e2a\u4eba\u662f\u4e00\u67b6\u98de\u673a\uff0c\u4f46\u5b83\u57fa\u672c\u4e0a\u662f\u51c6\u786e\u7684\u3002","title":"4.5 \u6cdb\u5316\u80fd\u529b\uff1a\u827a\u672f\u54c1\u4e2d\u7684\u4eba\u7269\u68c0\u6d4b"},{"location":"thesis_interpretation/01_yolo.html#5","text":"\\(YOLO\\) \u662f\u4e00\u79cd\u5feb\u901f\u3001\u7cbe\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u975e\u5e38\u9002\u5408\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u3002\u6211\u4eec\u5c06 \\(YOLO\\) \u8fde\u63a5\u5230\u7f51\u7edc\u6444\u50cf\u5934\uff0c\u5e76\u9a8c\u8bc1\u5b83\u662f\u5426\u80fd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\uff0c\u5305\u62ec\u4ece\u6444\u50cf\u5934\u83b7\u53d6\u56fe\u50cf\u5e76\u663e\u793a\u68c0\u6d4b\u7ed3\u679c\u7684\u65f6\u95f4\u3002 \u2003\u6700\u7ec8\u7684\u7cfb\u7edf\u662f\u4ea4\u4e92\u5f0f\u7684\u5e76\u4e14\u662f\u53c2\u4e0e\u5f0f\u7684\u3002\u867d\u7136 \\(YOLO\\) \u5355\u72ec\u5730\u5904\u7406\u56fe\u50cf\uff0c\u4f46\u5f53\u8fde\u63a5\u5230\u7f51\u7edc\u6444\u50cf\u5934\u65f6\uff0c\u5176\u529f\u80fd\u7c7b\u4f3c\u4e8e\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u53ef\u5728\u76ee\u6807\u79fb\u52a8\u548c\u5916\u89c2\u53d8\u5316\u65f6\u68c0\u6d4b\u76ee\u6807\u3002\u7cfb\u7edf\u6f14\u793a\u548c\u6e90\u4ee3\u7801\u53ef\u4ee5\u5728\u6211\u4eec\u7684\u9879\u76ee\u7f51\u7ad9\u4e0a\u627e\u5230\uff1ahttp://pjreddie.com/yolo/\u3002","title":"5.\u91ce\u5916\u5b9e\u65f6\u68c0\u6d4b"},{"location":"thesis_interpretation/01_yolo.html#6","text":"\u6211\u4eec\u4ecb\u7ecd\u4e86 \\(YOLO\\) \uff0c\u4e00\u79cd\u7edf\u4e00\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u3002\u6211\u4eec\u7684\u6a21\u578b\u6784\u5efa\u7b80\u5355\uff0c\u53ef\u4ee5\u76f4\u63a5\u5728\u6574\u5f20\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u4e0e\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c \\(YOLO\\) \u76f4\u63a5\u5728\u5bf9\u5e94\u68c0\u6d4b\u6027\u80fd\u7684\u635f\u5931\u51fd\u6570\u4e0a\u8bad\u7ec3\uff0c\u5e76\u4e14\u6574\u4e2a\u6a21\u578b\u7edf\u4e00\u8bad\u7ec3\u3002 \\(Fast \\ YOLO\\) \u662f\u6587\u732e\u4e2d\u6700\u5feb\u7684\u901a\u7528\u76ee\u7684\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c \\(YOLO\\) \u63a8\u52a8\u4e86\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7684\u6700\u65b0\u6280\u672f\u3002 \\(YOLO\\) \u8fd8\u5f88\u597d\u5730\u6cdb\u5316\u5230\u65b0\u9886\u57df\uff0c\u4f7f\u5176\u6210\u4e3a\u8981\u6c42\u5feb\u901f\u3001\u5f3a\u5927\u76ee\u6807\u68c0\u6d4b\u5e94\u7528\u7684\u7406\u60f3\u9009\u62e9\u3002 Acknowledgements : This work is partially supported by ONR N00014-13-1-0720, NSF IIS-1338054, and The Allen Distinguished Investigator Award.","title":"6.\u603b\u7ed3"},{"location":"thesis_interpretation/01_yolo.html#references","text":"[1] M. B. Blaschko and C. H. Lampert. Learning to localize objects with structured output regression. In Computer Vision\u2013ECCV 2008, pages 2\u201315. Springer, 2008. 4 [2] L. Bourdev and J. Malik. Poselets: Body part detectors trained using 3d human pose annotations. In International Conference on Computer Vision (ICCV), 2009. 8 [3] H. Cai, Q. Wu, T. Corradi, and P. Hall. The cross-depiction problem: Computer vision algorithms for recognising objects in artwork and in photographs. arXiv preprint arXiv:1505.00110, 2015. 7 [4] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conferenceon, volume 1, pages 886\u2013893. IEEE, 2005. 4, 8 [5] T. Dean, M. Ruzon, M. Segal, J. Shlens, S. Vijayanarasimhan, J. Yagnik, et al. Fast, accurate detection of 100,000 object classes on a single machine. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pages 1814\u20131821. IEEE, 2013. 5 [6] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. arXiv preprint arXiv:1310.1531, 2013. 4 [7] J. Dong, Q. Chen, S. Yan, and A. Yuille. Towards unified object detection and semantic segmentation. In Computer Vision\u2013ECCV 2014, pages 299\u2013314. Springer, 2014. 7 [8] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov. Scalable object detection using deep neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2155\u20132162. IEEE, 2014. 5, 6 [9] M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The pascal visual object classes challenge: A retrospective. International Journal of Computer Vision, 111(1):98\u2013136, Jan. 2015. 2 [10] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9):1627\u20131645, 2010. 1, 4 [11] S. Gidaris and N. Komodakis. Object detection via a multiregion & semantic segmentation-aware CNN model. CoRR, abs/1505.01749, 2015. 7 [12] S. Ginosar, D. Haas, T. Brown, and J. Malik. Detecting people in cubist art. In Computer Vision-ECCV 2014 Workshops, pages 101\u2013116. Springer, 2014. 7 [13] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 580\u2013587. IEEE, 2014. 1, 4, 7 [14] R. B. Girshick. Fast R-CNN. CoRR, abs/1504.08083, 2015. 2, 5, 6, 7 [15] S. Gould, T. Gao, and D. Koller. Region-based segmentation and object detection. In Advances in neural information processing systems, pages 655\u2013663, 2009. 4 [16] B. Hariharan, P. Arbel\u00e1ez, R. Girshick, and J. Malik. Simultaneous detection and segmentation. In Computer Vision\u2013ECCV 2014, pages 297\u2013312. Springer, 2014. 7 [17] K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling in deep convolutional networks for visual recognition. arXiv preprint arXiv:1406.4729, 2014. 5 [18] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580, 2012. 4 [19] D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error in object detectors. In Computer Vision\u2013ECCV 2012, pages 340\u2013353. Springer, 2012. 6 [20] K. Lenc and A. Vedaldi. R-cnn minus r. arXiv preprint arXiv:1506.06981, 2015. 5, 6 [21] R. Lienhart and J. Maydt. An extended set of haar-like features for rapid object detection. In Image Processing. 2002. Proceedings. 2002 International Conference on, volume 1, pages I\u2013900. IEEE, 2002. 4 [22] M. Lin, Q. Chen, and S. Yan. Network in network. CoRR, abs/1312.4400, 2013. 2 [23] D. G. Lowe. Object recognition from local scale-invariant features. In Computer vision, 1999. The proceedings of the seventh IEEE international conference on, volume 2, pages 1150\u20131157. Ieee, 1999. 4 [24] D. Mishkin. Models accuracy on imagenet 2012 val. https://github.com/BVLC/caffe/wiki/Models-accuracy-on-ImageNet-2012-val. Ac-cessed: 2015-10-2. 3 [25] C. P. Papageorgiou, M. Oren, and T. Poggio. A general framework for object detection. In Computer vision, 1998. sixth international conference on, pages 555\u2013562. IEEE,1998. 4 [26] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 3 [27] J. Redmon and A. Angelova. Real-time grasp detection using convolutional neural networks. CoRR, abs/1412.3128, 2014.5 [28] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497, 2015. 5, 6, 7 [29] S. Ren, K. He, R. B. Girshick, X. Zhang, and J. Sun. Object detection networks on convolutional feature maps. CoRR, abs/1504.06066, 2015. 3, 7 [30] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. 3 [31] M. A. Sadeghi and D. Forsyth. 30hz object detection with dpm v5. In Computer Vision\u2013ECCV 2014, pages 65\u201379. Springer, 2014. 5, 6 [32] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. LeCun. Overfeat: Integrated recognition, localization and detection using convolutional networks. CoRR, abs/1312.6229, 2013. 4, 5- [33] Z. Shen and X. Xue. Do more dropouts in pool5 feature maps for better object detection. arXiv preprint arXiv:1409.6911, 2014. 7 [34] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. CoRR, abs/1409.4842, 2014. 2 [35] J. R. Uijlings, K. E. van de Sande, T. Gevers, and A. W. Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154\u2013171, 2013. 4, 5 [36] P. Viola and M. Jones. Robust real-time object detection. International Journal of Computer Vision, 4:34\u201347, 2001. 4 [37] P. Viola and M. J. Jones. Robust real-time face detection. International journal of computer vision, 57(2):137\u2013154, 2004. 5 [38] J. Yan, Z. Lei, L. Wen, and S. Z. Li. The fastest deformable part model for object detection. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2497\u20132504. IEEE, 2014. 5, 6 [39] C. L. Zitnick and P. Doll\u00e1r. Edge boxes: Locating object proposals from edges. In Computer Vision\u2013ECCV 2014, pages 391\u2013405. Springer, 2014. 4","title":"References"},{"location":"thesis_interpretation/02_yolo.html","text":"\u672c\u6587\u7ffb\u8bd1\u81ea: https://arxiv.org/pdf/1612.08242.pdf \\(YOLO9000\\) : Better, Faster, Stronger Joseph Redmon\u2217\u2020, Ali Farhadi\u2217\u2020 University of Washington\u2217, Allen Institute for AI\u2020 http://pjreddie.com/yolo9000/ \u6458\u8981 \u2003\u6211\u4eec\u63a8\u51fa\u7684 \\(YOLO9000\\) \u662f\u4e00\u6b3e\u5148\u8fdb\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7cfb\u7edf\uff0c\u53ef\u68c0\u6d4b9000\u591a\u79cd\u76ee\u6807\u7c7b\u522b\u3002\u9996\u5148\uff0c\u6211\u4eec\u63d0\u51fa\u5bf9 \\(YOLO\\) \u68c0\u6d4b\u65b9\u6cd5\u7684\u5404\u79cd\u6539\u8fdb\uff0c\u8fd9\u4e9b\u6539\u8fdb\u6709\u72ec\u521b\u7684\uff0c\u4e5f\u6709\u7684\u662f\u6765\u6e90\u4e8e\u4ee5\u524d\u7684\u7814\u7a76\u3002\u6539\u8fdb\u540e\u7684\u6a21\u578b \\(YOLOv2\\) \u5728 \\(PASCAL VOC\\) \u548c \\(COCO\\) \u7b49\u6807\u51c6\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5904\u4e8e\u6280\u672f\u9886\u5148\u5730\u4f4d\u3002\u901a\u8fc7\u4f7f\u7528\u4e00\u79cd\u65b0\u9896\u7684\u591a\u5c3a\u5ea6\u8bad\u7ec3\u65b9\u6cd5\uff0c\u540c\u6837\u7684 \\(YOLOv2\\) \u6a21\u578b\u53ef\u4ee5\u4ee5\u4e0d\u540c\u7684\u5c3a\u5bf8\u8fd0\u884c\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u6298\u8877\u3002\u5728 \\(67 FPS\\) \u65f6\uff0c \\(YOLOv2\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u83b7\u5f97\u4e8676.8 \\(mAP\\) \u3002\u5728 \\(40FPS\\) \u65f6\uff0c \\(YOLOv2\\) \u83b7\u5f97\u4e8678.6 \\(mAP\\) \uff0c\u8d85\u8d8a\u4e86\u91c7\u7528 \\(ResNet\\) \u548c \\(SSD\u7684Faster \\ R-CNN\\) \u7b49\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u8fd0\u884c\u901f\u5ea6\u4ecd\u7136\u66f4\u5feb\u3002\u6700\u540e\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u8054\u5408\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u548c\u5206\u7c7b\u7684\u65b9\u6cd5\u3002\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u5728 \\(COCO\\) \u68c0\u6d4b\u6570\u636e\u96c6\u548c \\(ImageNet\\) \u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u540c\u65f6\u8bad\u7ec3 \\(YOLO9000\\) \u3002\u6211\u4eec\u7684\u8054\u5408\u8bad\u7ec3\u4f7f \\(YOLO9000\\) \u80fd\u591f\u9884\u6d4b\u672a\u6807\u6ce8\u68c0\u6d4b\u6570\u636e\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u5e76\u4e14\u6211\u4eec\u5728 \\(ImageNet\\) \u68c0\u6d4b\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u3002 \\(YOLO9000\\) \u5728 \\(ImageNet\\) \u68c0\u6d4b\u9a8c\u8bc1\u96c6\u4e0a\u83b7\u5f9719.7 \\(mAP\\) \uff0c\u5c3d\u7ba1200\u4e2a\u7c7b\u4e2d\u53ea\u670944\u4e2a\u5177\u6709\u68c0\u6d4b\u6570\u636e\u3002\u5728 \\(COCO\\) \u4e0a\u6ca1\u6709\u7684156\u79cd\u7c7b\u4e0a\uff0c \\(YOLO9000\\) \u5f97\u5230 16.0 \\(mAP\\) \uff0c\u4f46\u662f \\(YOLO\\) \u53ef\u4ee5\u68c0\u6d4b\u8d85\u8fc7200\u4e2a\u79cd\u7c7b;\u5b83\u9884\u6d4b\u8d85\u8fc79000 \u591a\u79cd\u4e0d\u540c\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u800c\u4e14\u5b83\u4ecd\u7136\u662f\u5b9e\u65f6\u8fd0\u884c\u7684\u3002 \u56fe1: \\(YOLO9000\\) \u3002 \\(YOLO9000\\) \u53ef\u4ee5\u5b9e\u65f6\u68c0\u6d4b\u5404\u79cd\u5404\u6837\u7684\u76ee\u6807\u7c7b\u522b\u3002 1.\u5f15\u8a00 \u2003\u901a\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u5e94\u8be5\u5feb\u901f\uff0c\u51c6\u786e\uff0c\u5e76\u4e14\u80fd\u591f\u8bc6\u522b\u5404\u79cd\u5404\u6837\u7684\u76ee\u6807\u3002\u81ea\u4ece\u5f15\u5165\u795e\u7ecf\u7f51\u7edc\uff0c\u68c0\u6d4b\u6846\u67b6\u53d8\u5f97\u8d8a\u6765\u8d8a\u5feb\u901f\u548c\u51c6\u786e\u3002\u4f46\u662f\uff0c\u5927\u591a\u6570\u68c0\u6d4b\u65b9\u6cd5\u4ec5\u9650\u4e8e\u68c0\u6d4b\u4e00\u5c0f\u90e8\u5206\u76ee\u6807\u3002 \u2003\u4e0e\u5206\u7c7b\u548c\u6807\u8bb0\u7b49\u5176\u4ed6\u4efb\u52a1\u7684\u6570\u636e\u96c6\u76f8\u6bd4\uff0c\u76ee\u524d\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u662f\u6709\u9650\u7684\u3002\u6700\u5e38\u89c1\u7684\u68c0\u6d4b\u6570\u636e\u96c6\u5305\u542b\u6210\u5343\u4e0a\u4e07\u5230\u6570\u5341\u4e07\u5f20\u5177\u6709\u6210\u767e\u4e0a\u5343\u4e2a\u6807\u7b7e\u7684\u56fe\u50cf[3][10][2]\u3002\u800c\u5206\u7c7b\u6570\u636e\u96c6\u6709\u6570\u4ee5\u767e\u4e07\u8ba1\u7684\u56fe\u50cf\uff0c\u6570\u5341\u6216\u6570\u767e\u4e07\u4e2a\u7c7b\u522b[20][2]\u3002 \u2003\u6211\u4eec\u5e0c\u671b\u68c0\u6d4b\u7684\u7c7b\u522b\u80fd\u591f\u6269\u5c55\u5230\u76ee\u6807\u5206\u7c7b\u7684\u7ea7\u522b\u3002\u4f46\u662f\uff0c\u6807\u6ce8\u68c0\u6d4b\u56fe\u50cf\u8981\u6bd4\u6807\u6ce8\u5206\u7c7b\u6216\u8d34\u6807\u7b7e\u8981\u6602\u8d35\u5f97\u591a\uff08 \u6807\u7b7e\u901a\u5e38\u662f\u7528\u6237\u514d\u8d39\u63d0\u4f9b ) \u3002\u56e0\u6b64\uff0c\u6211\u4eec\u4e0d\u592a\u53ef\u80fd\u5728\u8fd1\u671f\u5185\u770b\u5230\u4e0e\u5206\u7c7b\u6570\u636e\u96c6\u76f8\u540c\u89c4\u6a21\u7684\u68c0\u6d4b\u6570\u636e\u96c6\u3002 \u2003\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u2014\u2014\u901a\u8fc7\u5229\u7528\u6211\u4eec\u5df2\u6709\u7684\u5927\u91cf\u5206\u7c7b\u6570\u636e\u6765\u6269\u5927\u5f53\u524d\u68c0\u6d4b\u7cfb\u7edf\u7684\u8303\u56f4\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u76ee\u6807\u5206\u7c7b\u7684\u5206\u5c42\u89c6\u56fe\uff0c\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u5c06\u4e0d\u540c\u7684\u6570\u636e\u96c6\u7ec4\u5408\u5728\u4e00\u8d77\u3002 \u2003\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5b83\u5141\u8bb8\u6211\u4eec\u5728\u68c0\u6d4b\u548c\u5206\u7c7b\u6570\u636e\u4e0a\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u5668\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u6807\u8bb0\u68c0\u6d4b\u56fe\u50cf\u6765\u5b66\u4e60\u7cbe\u786e\u5b9a\u4f4d\u76ee\u6807\uff0c\u540c\u65f6\u4f7f\u7528\u5206\u7c7b\u56fe\u50cf\u6765\u589e\u52a0\u8bcd\u6c47\u91cf\u548c\u9c81\u68d2\u6027\u3002 \u2003\u6211\u4eec\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8bad\u7ec3 \\(YOLO9000\\) b\u4e00\u79cd\u53ef\u4ee5\u68c0\u6d4b\u8d85\u8fc79000\u79cd\u4e0d\u540c\u7684\u76ee\u6807\u7c7b\u522b\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u3002 \u9996\u5148\uff0c\u6211\u4eec\u6539\u8fdbYOLO\u57fa\u7840\u68c0\u6d4b\u7cfb\u7edf\uff0c\u751f\u6210\u6700\u5148\u8fdb\u7684\u5b9e\u65f6\u68c0\u6d4b\u5668 \\(YOLOv2\\) \u3002 \u7136\u540e\uff0c\u91c7\u7528\u6211\u4eec\u7684\u6570\u636e\u96c6\u7ec4\u5408\u65b9\u6cd5\u548c\u8054\u5408\u8bad\u7ec3\u7b97\u6cd5\uff0c\u4f7f\u7528\u6765\u81ea \\(ImageNet\\) \u76849000\u591a\u4e2a\u7c7b\u4ee5\u53ca \\(COCO\\) \u7684\u68c0\u6d4b\u6570\u636e\u6765\u8bad\u7ec3\u6a21\u578b\u3002 \u6211\u4eec\u6240\u6709\u4ee3\u7801\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u90fd\u53ef\u5728\u7ebf\u83b7\u5f97\uff1ahttp://pjreddie.com/yolo9000/\u3002 2.\u66f4\u597d \u2003\u4e0e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\uff0c \\(YOLO\\) \u5b58\u5728\u5404\u79cd\u7f3a\u70b9\u3002 \\(YOLO\\) \u4e0e \\(Fast \\ R-CNN\\) \u7684\u8bef\u5dee\u6bd4\u8f83\u5206\u6790\u8868\u660e\uff0c \\(YOLO\\) \u4ea7\u751f\u4e86\u5927\u91cf\u7684\u5b9a\u4f4d\u9519\u8bef\u3002\u6b64\u5916\uff0c\u4e0e\u751f\u6210\u5019\u9009\u533a\u57df\u65b9\u6cd5\u76f8\u6bd4\uff0c \\(YOLO\\) \u53ec\u56de\u7387( recall )\u76f8\u5bf9\u8f83\u4f4e\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u4e3b\u8981\u5173\u6ce8\u6539\u5584\u53ec\u56de\u7387\u548c\u5b9a\u4f4d\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u7c7b\u51c6\u786e\u6027\u3002 \u2003\u8ba1\u7b97\u673a\u89c6\u89c9\u901a\u5e38\u8d8b\u5411\u4e8e\u66f4\u5927\u66f4\u6df1\u7684\u7f51\u7edc[6] [18] [17]\u3002 \u66f4\u597d\u7684\u6027\u80fd\u901a\u5e38\u53d6\u51b3\u4e8e\u8bad\u7ec3\u66f4\u5927\u7684\u7f51\u7edc\u6216\u5c06\u591a\u4e2a\u6a21\u578b\u7ec4\u5408\u5728\u4e00\u8d77\u3002 \u4f46\u662f\uff0c\u5bf9\u4e8e \\(YOLOv2\\) \uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u66f4\u7cbe\u786e\u7684\u68c0\u6d4b\u5668\uff0c\u800c\u4e14\u4fdd\u6301\u5f88\u5feb\u7684\u901f\u5ea6\u3002 \u6211\u4eec\u4e0d\u662f\u8981\u6269\u5927\u7f51\u7edc\uff0c\u800c\u662f\u7b80\u5316\u7f51\u7edc\uff0c\u7136\u540e\u8ba9\u8868\u5f81( \u5373\u76ee\u6807\u7279\u5f81 )\u66f4\u6613\u4e8e\u5b66\u4e60\u3002 \u6211\u4eec\u5c06\u4ee5\u5f80\u5de5\u4f5c\u4e2d\u7684\u5404\u79cd\u521b\u610f\u4e0e\u6211\u4eec\u81ea\u5df1\u65b0\u9896\u7684\u65b9\u6cd5\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u63d0\u9ad8 \\(YOLO\\) \u7684\u6027\u80fd\u3002 \u7ed3\u679c\u6c47\u603b\u89c1 \u88682\u3002 \u2003 \u6279\u91cf\u6807\u51c6\u5316 \uff08Batch Normalization\uff09\u3002\u6279\u91cf\u6807\u51c6\u5316\u53ef\u4ee5\u663e\u7740\u6539\u5584\u6536\u655b\u6027\uff0c\u800c\u4e14\u4e0d\u518d\u9700\u8981\u5176\u4ed6\u5f62\u5f0f\u7684\u6b63\u5219\u5316[7]\u3002 \u901a\u8fc7\u5728 \\(YOLO\\) \u4e2d\u7684\u6240\u6709\u5377\u79ef\u5c42\u4e0a\u6dfb\u52a0\u6279\u91cf\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u5728 \\(mAP\\) \u4e2d\u83b7\u5f97 2\uff05\u4ee5\u4e0a\u7684\u6539\u8fdb\u3002 \u6279\u91cf\u6807\u51c6\u5316\u4e5f\u6709\u52a9\u4e8e\u89c4\u8303\u6a21\u578b\u3002 \u901a\u8fc7\u6279\u91cf\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u4ece\u6a21\u578b\u4e2d\u5220\u9664 \\(dropout\\) \u800c\u4e0d\u4f1a\u53d1\u751f\u8fc7\u62df\u5408\u3002 \u2003 \u9ad8\u5206\u8fa8\u7387\u5206\u7c7b\u5668 \uff08High Resolution Classifier\uff09\u3002\u6240\u6709\u7684\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u65b9\u6cd5\u90fd\u4f7f\u7528\u5728 \\(ImageNet\\) \u4e0a\u9884\u5148\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668[16]\u3002 \u4eceAlexNet\u5f00\u59cb\uff0c\u5927\u591a\u6570\u5206\u7c7b\u5668\u7528\u5c0f\u4e8e \\(256\u00d7256\\) \u7684\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165[8]\u3002 \u6700\u521d\u7684 \\(YOLO\\) \u4ee5 \\(224\u00d7224\\) \u7684\u56fe\u50cf\u8bad\u7ec3\u5206\u7c7b\u5668\u7f51\u7edc\uff0c\u5e76\u5c06\u5206\u8fa8\u7387\u63d0\u9ad8\u5230 \\(448\\) \u4ee5\u8fdb\u884c\u68c0\u6d4b\u8bad\u7ec3\u3002 \u8fd9\u610f\u5473\u7740\u7f51\u7edc\u5fc5\u987b\u5207\u6362\u5230\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u4e60\uff0c\u540c\u65f6\u80fd\u8c03\u6574\u5230\u65b0\u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002 \u2003\u5bf9\u4e8e \\(YOLOv2\\) \uff0c\u6211\u4eec\u9996\u5148\u4ee5 \\(448\u00d7448\\) \u7684\u5168\u5206\u8fa8\u7387\u5728 \\(ImageNet\\) \u4e0a\u8fdb\u884c \\(10\\) \u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u5fae\u8c03\u3002\u8fd9\u7ed9\u4e88\u7f51\u7edc\u4e00\u4e9b\u65f6\u95f4\uff0c\u4ee5\u8c03\u6574\u5176\u6ee4\u6ce2\u5668\u6765\u66f4\u597d\u5730\u5904\u7406\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8f93\u5165\u3002\u7136\u540e\uff0c\u6211\u4eec\u518d\u5bf9\u8be5\u68c0\u6d4b\u7f51\u7edc\u8fdb\u884c\u5fae\u8c03\u3002 \u8fd9\u4e2a\u9ad8\u5206\u8fa8\u7387\u7684\u5206\u7c7b\u7f51\u7edc\u4f7f \\(mAP\\) \u589e\u52a0\u4e86\u8fd14\uff05\u3002 \u2003 \u5377\u79ef\u4e0e\u951a\u6846 \u3002 \\(YOLO\\) \u76f4\u63a5\u4f7f\u7528\u5377\u79ef\u7279\u5f81\u63d0\u53d6\u5668\u9876\u90e8\u7684\u5168\u8fde\u63a5\u5c42\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u7684\u5750\u6807\u3002\u800c \\(Fast \\ R-CNN\\) \u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5750\u6807\uff0c\u662f\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684\u5148\u9a8c\u6765\u9884\u6d4b\u8fb9\u754c\u6846[15]\u3002\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5750\u6807 \\(Fast \\ R-CNN\\) \u9884\u6d4b\u8fb9\u754c\u6846\u4f7f\u7528\u624b\u5de5\u6311\u9009\u7684\u5148\u9a8c\u533a\u57df[15]\u3002 Faster R-CNN\u4e2d\u7684\u5019\u9009\u533a\u57df\u751f\u6210\u7f51\u7edc\uff08RPN\uff09\u4ec5\u4f7f\u7528\u5377\u79ef\u5c42\u6765\u9884\u6d4b\u951a\u6846\u7684\u504f\u79fb\u548c\u7f6e\u4fe1\u5ea6\u3002\u7531\u4e8e\u9884\u6d4b\u5c42\u662f\u5377\u79ef\u7684\uff0c\u6240\u4ee5RPN\u53ef\u4ee5\u5728\u7279\u5f81\u56fe\u4e2d\u7684\u6bcf\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u8fd9\u4e9b\u504f\u79fb\u3002\u4f7f\u7528\u9884\u6d4b\u504f\u79fb\u4ee3\u66ff\u5750\u6807\uff0c\u53ef\u4ee5\u7b80\u5316\u95ee\u9898\u5e76\u4f7f\u7f51\u7edc\u66f4\u6613\u4e8e\u5b66\u4e60\u3002 \u2003\u6211\u4eec\u4ece \\(YOLO\\) \u4e2d\u79fb\u9664\u5168\u8fde\u63a5\u5c42\uff0c\u5e76\u4f7f\u7528\u951a\u6846\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u3002 \u9996\u5148\u6211\u4eec\u6d88\u9664\u4e00\u4e2a\u6c60\u5316\u5c42\uff0c\u4ee5\u4f7f\u7f51\u7edc\u5377\u79ef\u5c42\u7684\u8f93\u51fa\u5177\u6709\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u3002 \u6211\u4eec\u8fd8\u7f29\u5c0f\u7f51\u7edc\uff0c\u4f7f\u5176\u5728\u5206\u8fa8\u7387\u4e3a \\(416X416\\) \u7684\u8f93\u5165\u56fe\u50cf\u4e0a\u8fd0\u884c\uff0c\u800c\u4e0d\u662f \\(448\u00d7448\\) \u3002\u6211\u4eec\u8fd9\u6837\u505a\u662f\u56e0\u4e3a\u6211\u4eec\u60f3\u8981\u5728\u7279\u5f81\u56fe\u4e2d\u6709\u5947\u6570\u4e2a\u4f4d\u7f6e\uff0c\u4ece\u800c\u6709\u4e00\u4e2a\u5355\u4e00\u7684\u4e2d\u5fc3\u5355\u5143\u683c\u3002\u76ee\u6807\uff0c\u5c24\u5176\u662f\u5927\u7684\u76ee\u6807\uff0c\u5f80\u5f80\u5360\u636e\u56fe\u50cf\u7684\u4e2d\u5fc3\uff0c\u6240\u4ee5\u6700\u597d\u5728\u6b63\u4e2d\u5fc3\u62e5\u6709\u5355\u72ec\u4e00\u4e2a\u4f4d\u7f6e\u6765\u9884\u6d4b\u8fd9\u4e9b\u76ee\u6807\uff0c\u800c\u4e0d\u662f\u5728\u4e2d\u5fc3\u9644\u8fd1\u7684\u56db\u4e2a\u4f4d\u7f6e\u3002 \\(YOLO\\) \u7684\u5377\u79ef\u5c42\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e86 \\(32\\) \u500d\u7684\u91c7\u6837\uff0c\u6240\u4ee5\u901a\u8fc7\u4f7f\u7528 \\(416\\) \u7684\u8f93\u5165\u56fe\u50cf\uff0c\u6211\u4eec\u5f97\u5230 \\(13\u00d713\\) \u7684\u8f93\u51fa\u7279\u5f81\u56fe\u3002 \u2003\u5f53\u6211\u4eec\u79fb\u52a8\u5230\u951a\u6846\u65f6\uff0c\u6211\u4eec\u5c06\u7c7b\u9884\u6d4b\u673a\u5236\u4e0e\u7a7a\u95f4\u4f4d\u7f6e\u5206\u5f00\u5904\u7406\uff0c\u5355\u72ec\u9884\u6d4b\u6bcf\u4e2a\u951a\u6846\u7684\u7c7b\u53ca\u5176\u76ee\u6807\u3002 \u9075\u5faa\u539f\u6765\u7684 \\(YOLO\\) \u7684\u505a\u6cd5\uff0c\u76ee\u6807\u9884\u6d4b\u4f9d\u7136\u9884\u6d4b\u4e86\u771f\u5b9e\u6807\u7b7e\u6846\uff08ground truth box\uff09\u548c\u5019\u9009\u6846\u7684 \\(IOU\\) \uff0c\u800c\u7c7b\u522b\u9884\u6d4b\u4e5f\u662f\u9884\u6d4b\u4e86\u5f53\u6709\u76ee\u6807\u5b58\u5728\u65f6\uff0c\u8be5\u7c7b\u522b\u7684\u6761\u4ef6\u6982\u7387\u3002 \u2003\u4f7f\u7528\u951a\u6846\uff0c\u7cbe\u5ea6\u503c\u4f1a\u5c0f\u5e45\u4e0b\u964d\u3002\u56e0\u4e3a\u539f\u59cb\u7684 \\(YOLO\\) \u4ec5\u4e3a\u6bcf\u4e2a\u56fe\u7247\u9884\u6d4b98\u4e2a\u6846\uff0c\u4f46\u4f7f\u7528\u951a\u6846\u540e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u9884\u6d4b\u7684\u6846\u6570\u8d85\u8fc7 1000 \u4e2a\u3002 \u5728\u6ca1\u6709\u951a\u6846\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u7684\u4e2d\u7b49\u6a21\u578b\u5c06\u83b7\u5f97 69.5 \u7684 \\(mAP\\) \uff0c\u53ec\u56de\u7387\u4e3a81\uff05\u3002 \u4f7f\u7528\u951a\u6846\u540e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u83b7\u5f97\u4e86 \\(69.2\\) \u7684 \\(mAP\\) \uff0c\u53ec\u56de\u7387\u4e3a88\uff05\u3002\u5c3d\u7ba1 \\(mAP\\) \u51cf\u5c11\uff0c\u4f46\u53ec\u56de\u7387\u7684\u589e\u52a0\u610f\u5473\u7740\u6211\u4eec\u7684\u6a21\u578b\u6709\u66f4\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002 \u56fe2\uff1a \\(VOC\\) \u548c \\(COCO\\) \u4e0a\u7684\u805a\u7c7b\u6846\u5c3a\u5bf8\u3002\u6211\u4eec\u5728\u8fb9\u754c\u6846\u7684\u7ef4\u4e0a\u8fd0\u884c \\(k-means\\) \u805a\u7c7b\uff0c\u4ee5\u83b7\u5f97\u6211\u4eec\u6a21\u578b\u7684\u826f\u597d\u5148\u9a8c\u3002\u5de6\u56fe\u663e\u793a\u4e86\u6211\u4eec\u901a\u8fc7k\u7684\u5404\u79cd\u9009\u62e9\u83b7\u5f97\u7684\u5e73\u5747 \\(IOU\\) \u3002\u6211\u4eec\u53d1\u73b0 \\(k = 5\\) \u4e3a\u53ec\u56de\u4e0e\u6a21\u578b\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6298\u4e2d\u3002\u53f3\u56fe\u663e\u793a\u4e86 \\(VOC\\) \u548c \\(COCO\\) \u7684\u76f8\u5bf9\u8d28\u5fc3\u3002\u8fd9\u4e24\u79cd\u65b9\u6848\u90fd\u559c\u6b22\u66f4\u8584\uff0c\u66f4\u9ad8\u7684\u6846\uff0c\u5e76\u4e14 \\(COCO\\) \u7684\u5c3a\u5bf8\u7684\u53d8\u5316\u6bd4 \\(VOC\\) \u66f4\u5927\u3002 \\(k-means\\) \u7b97\u6cd5: \\(K-means\\) \u7b97\u6cd5\u662f\u5f88\u5178\u578b\u7684\u57fa\u4e8e\u8ddd\u79bb\u7684\u805a\u7c7b\u7b97\u6cd5\uff0c\u91c7\u7528\u8ddd\u79bb\u4f5c\u4e3a\u76f8\u4f3c\u6027\u7684\u8bc4\u4ef7\u6307\u6807\uff0c\u5373\u8ba4\u4e3a\u4e24\u4e2a\u5bf9\u8c61\u7684\u8ddd\u79bb\u8d8a\u8fd1\uff0c\u5176\u76f8\u4f3c\u5ea6\u5c31\u8d8a\u5927\u3002\u8be5\u7b97\u6cd5\u8ba4\u4e3a\u7c07\u662f\u7531\u8ddd\u79bb\u9760\u8fd1\u7684\u5bf9\u8c61\u7ec4\u6210\u7684\uff0c\u56e0\u6b64\u628a\u5f97\u5230\u7d27\u51d1\u4e14\u72ec\u7acb\u7684\u7c07\u4f5c\u4e3a\u6700\u7ec8\u76ee\u6807\u3002 \u2003 \u7ef4\u5ea6\u805a\u7c7b \uff08Dimension Clusters\uff09\u3002\u5f53\u628a\u951a\u6846\u4e0eYOLO\u4e00\u8d77\u4f7f\u7528\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u4e24\u4e2a\u95ee\u9898\u3002 \u9996\u5148\u662f\u6846\u7684\u5c3a\u5bf8\u662f\u624b\u5de5\u6311\u9009\u7684\u3002\u867d\u7136\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u9002\u5f53\u5730\u8c03\u6574\u65b9\u6846\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u4ece\u4e00\u5f00\u59cb\u5c31\u4e3a\u7f51\u7edc\u9009\u62e9\u66f4\u597d\u7684\u5148\u9a8c\u6846\uff0c\u5c31\u53ef\u4ee5\u8ba9\u7f51\u7edc\u66f4\u5bb9\u6613\u5b66\u4e60\u5230\u66f4\u597d\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u2003\u6211\u4eec\u4e0d\u7528\u624b\u5de5\u9009\u62e9\u5148\u9a8c\u6846\uff0c\u800c\u662f\u5728\u8bad\u7ec3\u96c6\u7684\u8fb9\u754c\u6846\u4e0a\u8fd0\u884ck-means\u805a\u7c7b\uff0c\u81ea\u52a8\u627e\u5230\u826f\u597d\u7684\u5148\u9a8c\u6846\u3002 \u5982\u679c\u6211\u4eec\u4f7f\u7528\u5177\u6709\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u6807\u51c6 \\(k-means\\) \uff0c\u90a3\u4e48\u8f83\u5927\u7684\u6846\u6bd4\u8f83\u5c0f\u7684\u6846\u4ea7\u751f\u66f4\u591a\u7684\u8bef\u5dee\u3002 \u7136\u800c\uff0c\u6211\u4eec\u771f\u6b63\u60f3\u8981\u7684\u662f\u72ec\u7acb\u4e8e\u6846\u7684\u5927\u5c0f\u7684\uff0c\u80fd\u83b7\u5f97\u826f\u597d\u7684 \\(IOU\\) \u5206\u6570\u7684\u5148\u9a8c\u6846\u3002 \u56e0\u6b64\u5bf9\u4e8e\u8ddd\u79bb\u5ea6\u91cf\u6211\u4eec\u4f7f\u7528: \\(d(\\text { box, centroid }) = 1-\\operatorname{IOU}(\\text { box }, \\text { centroid })\\) \u2003\u6211\u4eec\u7528\u4e0d\u540c\u7684 \\(k\\) \u503c\u8fd0\u884c \\(k-means\\) \uff0c\u5e76\u7ed8\u5236\u6700\u63a5\u8fd1\u8d28\u5fc3\u7684\u5e73\u5747 \\(IOU\\) \uff08\u89c1\u56fe2\uff09\u3002\u4e3a\u4e86\u5728\u6a21\u578b\u590d\u6742\u5ea6\u548c\u9ad8\u53ec\u56de\u7387\u4e4b\u95f4\u7684\u826f\u597d\u6298\u8877\uff0c\u6211\u4eec\u9009\u62e9 \\(k = 5\\) \u3002\u805a\u7c7b\u7684\u8d28\u5fc3\u4e0e\u624b\u5de5\u9009\u53d6\u7684\u951a\u6846\u663e\u7740\u4e0d\u540c\uff0c\u5b83\u6709\u66f4\u5c11\u7684\u77ed\u4e14\u5bbd\u7684\u6846\uff0c\u800c\u4e14\u6709\u66f4\u591a\u65e2\u957f\u53c8\u7a84\u7684\u6846\u3002 \u2003\u88681\u4e2d\uff0c\u6211\u4eec\u5c06\u805a\u7c7b\u7b56\u7565\u7684\u5148\u9a8c\u6846\u4e2d\u5fc3\u6570\u548c\u624b\u5de5\u9009\u53d6\u7684\u951a\u6846\u6570\u5728\u6700\u63a5\u8fd1\u7684\u5e73\u5747 \\(IOU\\) \u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002\u4ec55\u4e2a\u5148\u9a8c\u6846\u4e2d\u5fc3\u7684\u5e73\u5747 \\(IOU\\) \u4e3a61.0\uff0c\u5176\u6027\u80fd\u7c7b\u4f3c\u4e8e9\u4e2a\u951a\u6846\u768460.9\u3002 \u4f7f\u75289\u4e2a\u8d28\u5fc3\u4f1a\u5f97\u5230\u66f4\u9ad8\u7684\u5e73\u5747 \\(IOU\\) \u3002\u8fd9\u8868\u660e\u4f7f\u7528 \\(k-means\\) \u751f\u6210\u8fb9\u754c\u6846\u53ef\u4ee5\u66f4\u597d\u5730\u8868\u793a\u6a21\u578b\u5e76\u4f7f\u5176\u66f4\u5bb9\u6613\u5b66\u4e60\u3002 \\(\\begin{array}{lcc} \\text { Box Generation } & \\# & \\text { Avg IOU } \\\\ \\hline \\text { Cluster SSE } & 5 & 58.7 \\\\ \\text { Cluster IOU } & 5 & 61.0 \\\\ \\text { Anchor Boxes [15] } & 9 & 60.9 \\\\ \\text { Cluster IOU } & 9 & 67.2 \\end{array}\\) \u88681\uff1a \\(VOC \\ 2007\\) \u6700\u63a5\u8fd1\u5148\u9a8c\u7684\u6846\u7684\u5e73\u5747 \\(IOU\\) \u3002 \\(VOC \\ 2007\\) \u4e0a\u7684\u76ee\u6807\u7684\u5e73\u5747IOU\u4e0e\u5176\u6700\u63a5\u8fd1\u7684\uff0c\u672a\u7ecf\u4fee\u6539\u7684\u4f7f\u7528\u4e0d\u540c\u751f\u6210\u65b9\u6cd5\u7684\u76ee\u6807\u4e4b\u95f4\u7684\u5e73\u5747 \\(IOU\\) \u3002\u805a\u7c7b\u5f97\u7ed3\u679c\u6bd4\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684\u5148\u9a8c\u6846\u7ed3\u679c\u8981\u597d\u5f97\u591a\u3002 \u2003 \u76f4\u63a5\u4f4d\u7f6e\u9884\u6d4b \uff08Direct location prediction\uff09\u3002\u5f53\u5728 \\(YOLO\\) \u4e2d\u4f7f\u7528\u951a\u6846\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff1a\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u5c24\u5176\u662f\u5728\u65e9\u671f\u8fed\u4ee3\u7684\u8fc7\u7a0b\u4e2d\u3002 \u5927\u591a\u6570\u4e0d\u7a33\u5b9a\u6765\u81ea\u4e8e\u9884\u6d4b\u6846\u7684 \\((x,y)\\) \u4f4d\u7f6e\u3002 \u5728\u5019\u9009\u533a\u57df\u7f51\u7edc\u4e2d\uff0c\u7f51\u7edc\u9884\u6d4b\u7684 \\(t_x,t_y\\) \uff0c\u548c\u4e2d\u5fc3\u5750\u6807 \\((x,y)\\) \u8ba1\u7b97\u5982\u4e0b\uff1a \\(\\huge\\begin{array}{l} x=\\left(t_{x} * w_{a}\\right)-x_{a} \\\\ y=\\left(t_{y} * h_{a}\\right)-y_{a} \\end{array}\\) \u2003\u4f8b\u5982\uff0c\u9884\u6d4b \\(t_x = 1\\) \u4f1a\u4f7f\u8be5\u6846\u5411\u53f3\u79fb\u52a8\u951a\u6846\u7684\u5bbd\u5ea6\uff0c\u800c\u9884\u6d4b \\(t_x = -1\\) \u4f1a\u5c06\u5176\u5411\u5de6\u79fb\u52a8\u76f8\u540c\u7684\u5bbd\u5ea6\u3002 \u2003\u8fd9\u4e2a\u516c\u5f0f\u662f\u4e0d\u53d7\u7ea6\u675f\u7684\uff0c\u6240\u4ee5\u4efb\u4f55\u951a\u6846\u90fd\u53ef\u4ee5\u5728\u56fe\u50cf\u4e2d\u7684\u4efb\u4f55\u4e00\u70b9\u7ed3\u675f\uff0c\u800c\u4e0d\u7ba1\u951a\u6846\u662f\u5728\u54ea\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u7684\u3002\u968f\u673a\u521d\u59cb\u5316\u6a21\u578b\u9700\u8981\u5f88\u957f\u65f6\u95f4\u624d\u80fd\u7a33\u5b9a\u5230\u9884\u6d4b\u5408\u7406\u7684\u504f\u79fb\u91cf\u3002 \u2003\u6211\u4eec\u6ca1\u6709\u9884\u6d4b\u504f\u79fb\uff0c\u800c\u662f\u9075\u5faa \\(YOLO\\) \u7684\u65b9\u6cd5\uff0c\u9884\u6d4b\u76f8\u5bf9\u4e8e\u7f51\u683c\u5355\u5143\u4f4d\u7f6e\u7684\u4f4d\u7f6e\u5750\u6807\u3002\u8fd9\u4f7f\u5f97\u771f\u5b9e\u503c\u7684\u754c\u9650\u57280\u52301\u4e4b\u95f4\u3002\u6211\u4eec\u4f7f\u7528\u903b\u8f91\u6fc0\u6d3b\u6765\u9650\u5236\u7f51\u7edc\u7684\u9884\u6d4b\u843d\u5728\u8fd9\u4e2a\u8303\u56f4\u5185\u3002 \u2003\u7f51\u7edc\u4e3a\u7279\u5f81\u56fe\u7684\u8f93\u51fa\u7684\u6bcf\u4e2a\u5355\u5143\u9884\u6d4b5\u4e2a\u8fb9\u754c\u6846\u3002\u7f51\u7edc\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u76845\u4e2a\u5750\u6807 \\(t_x,t_y,t_w,t_h\u548ct_o\\) \u3002\u5982\u679c\u5355\u5143\u683c\u4ece\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u504f\u79fb\u4e86,\u5e76\u4e14\u4e4b\u524d\u7684\u8fb9\u754c\u6846\u5177\u6709\u5bbd\u5ea6\u548c\u9ad8\u5ea6 \\(p_w,p_h\\) \u5219\u9884\u6d4b\u5bf9\u5e94\u4e8e\uff1a \\(\\begin{aligned} b_{x} &=\\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} &=\\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} &=p_{w} e^{t_{w}} \\\\ b_{h} &=p_{h} e^{t_{h}} \\\\ \\operatorname{Pr}(\\text { object }) * \\operatorname{IOU}(b, \\text { object }) &=\\sigma\\left(t_{o}\\right) \\end{aligned}\\) \u2003\u7531\u4e8e\u6211\u4eec\u9650\u5236\u4e86\u4f4d\u7f6e\u9884\u6d4b\uff0c\u4f7f\u5f97\u53c2\u6570\u5316\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u66f4\u52a0\u7a33\u5b9a\u3002\u4f7f\u7528\u7ef4\u5ea6\u96c6\u7fa4\u4ee5\u53ca\u76f4\u63a5\u9884\u6d4b\u8fb9\u754c\u6846\u4e2d\u5fc3\u4f4d\u7f6e\uff0c\u53ef\u4ee5\u4f7f \\(YOLO\\) \u6bd4\u951a\u6846\u7684\u7248\u672c\u63d0\u9ad8\u8fd15\uff05\u3002 \u56fe3\uff1a\u5177\u6709\u7ef4\u5ea6\u5148\u9a8c\u548c\u4f4d\u7f6e\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u3002\u6211\u4eec\u9884\u6d4b\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4f5c\u4e3a\u805a\u7c7b\u8d28\u5fc3\u7684\u504f\u79fb\u91cf\u3002\u6211\u4eec\u4f7f\u7528sigmoid\u51fd\u6570\u9884\u6d4b\u76f8\u5bf9\u4e8e\u6ee4\u6ce2\u5668\u5e94\u7528\u4f4d\u7f6e\u7684\u6846\u7684\u4e2d\u5fc3\u5750\u6807\u3002 \u2003 \u7ec6\u7c92\u5ea6\u529f\u80fd \uff08Fine-Grained Features\uff09\u3002\u4fee\u6539\u540e\u7684YOLO\u5728 \\(13\u00d713\\) \u7279\u5f81\u56fe\u4e0a\u9884\u6d4b\u68c0\u6d4b\u7ed3\u679c\u3002 \u867d\u7136\u8fd9\u5bf9\u4e8e\u5927\u578b\u7269\u4f53\u662f\u8db3\u591f\u7684\uff0c\u4f46\u4f7f\u7528\u66f4\u7ec6\u7c92\u5ea6\u7279\u5f81\u5bf9\u5b9a\u4f4d\u8f83\u5c0f\u7269\u4f53\u6709\u597d\u5904\u3002Faster R-CNN\u548cSSD\u90fd\u5728\u7f51\u7edc\u4e2d\u7684\u5404\u79cd\u7279\u5f81\u56fe\u4e0a\u8fd0\u884c\u7f51\u7edc\uff0c\u4ee5\u83b7\u5f97\u591a\u4e2a\u5206\u8fa8\u7387\u3002 \u6211\u4eec\u91c7\u53d6\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u53ea\u9700\u6dfb\u52a0\u4e00\u4e2a\u76f4\u901a\u5c42\uff0c\u4ee5 \\(26\u00d726\\) \u7684\u5206\u8fa8\u7387\u4ece\u8f83\u65e9\u7684\u5c42\u4e2d\u63d0\u53d6\u7279\u5f81\u3002 \u2003\u76f4\u901a\u5c42\u5c06\u9ad8\u5206\u8fa8\u7387\u7279\u5f81\u4e0e\u4f4e\u5206\u8fa8\u7387\u7279\u5f81\u8fde\u63a5\u8d77\u6765\uff0c\u5c06\u76f8\u90bb\u7279\u5f81\u53e0\u52a0\u5230\u4e0d\u540c\u7684\u901a\u9053\u4e2d\uff0c\u800c\u4e0d\u662f\u7a7a\u95f4\u4f4d\u7f6e\u4e0a\uff0c\u7c7b\u4f3c\u4e8e \\(ResNet\\) \u4e2d\u7684\u6052\u7b49\u6620\u5c04\u3002\u5c06 \\(26\u00d726\u00d7512\\) \u7684\u7279\u5f81\u56fe\u53d8\u4e3a \\(13\u00d713\u00d72048\\) \u7684\u7279\u5f81\u56fe\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u4e0e\u539f\u6765\u7684\u7279\u5f81\u8fde\u63a5\u3002\u6211\u4eec\u7684\u68c0\u6d4b\u5668\u8fd0\u884c\u5728\u8fd9\u5f20\u6269\u5c55\u7684\u7279\u5f81\u56fe\u7684\u9876\u90e8\uff0c\u4ee5\u4fbf\u5b83\u53ef\u4ee5\u8bbf\u95ee\u7ec6\u7c92\u5ea6\u7684\u529f\u80fd\u3002\u8fd9\u4f7f\u6027\u80fd\u63d0\u9ad8\u4e861\uff05\u3002 \u2003 \u591a\u5c3a\u5ea6\u8bad\u7ec3 \uff08Multi-Scale Training\uff09\u3002\u539f\u6765\u7684 \\(YOLO\\) \u4f7f\u7528 \\(448\u00d7448\\) \u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002\u901a\u8fc7\u6dfb\u52a0\u951a\u6846\uff0c\u6211\u4eec\u5c06\u5206\u8fa8\u7387\u66f4\u6539\u4e3a \\(416\u00d7416\\) \u3002\u4f46\u662f\uff0c\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u4ec5\u4f7f\u7528\u5377\u79ef\u5c42\u548c\u6c60\u5316\u5c42\uff0c\u56e0\u6b64\u53ef\u4ee5\u5b9e\u65f6\u8c03\u6574\u5927\u5c0f\u3002\u6211\u4eec\u5e0c\u671b \\(YOLOv2\\) \u80fd\u591f\u5728\u4e0d\u540c\u5c3a\u5bf8\u7684\u56fe\u50cf\u4e0a\u8fd0\u884c\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u591a\u5c3a\u5ea6\u8bad\u7ec3\u5e94\u5230\u6a21\u578b\u4e2d\u3002 \u2003\u6211\u4eec\u4e0d\u9700\u8981\u4fee\u6539\u8f93\u5165\u56fe\u50cf\u5927\u5c0f\uff0c\u800c\u662f\u6bcf\u9694\u51e0\u6b21\u8fed\u4ee3\u5c31\u6539\u53d8\u4e00\u6b21\u7f51\u7edc\u3002\u6bcf \\(10\\) \u4e2a\u6279\u6b21\u6211\u4eec\u7684\u7f51\u7edc\u4f1a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u65b0\u7684\u56fe\u50cf\u5c3a\u5bf8\u5927\u5c0f\u3002\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u7f29\u51cf\u4e86 \\(32\\) \u500d\uff0c\u6240\u4ee5\u6211\u4eec\u4ece \\(32\\) \u7684\u500d\u6570\u4e2d\u62bd\u53d6\uff1a \\({320,352\uff0c\u2026\uff0c608}\\) \u3002\u56e0\u6b64\uff0c\u6700\u5c0f\u7684\u9009\u9879\u662f \\(320\u00d7320\\) \uff0c\u6700\u5927\u7684\u662f \\(608\u00d7608\\) \u3002\u6211\u4eec\u8c03\u6574\u7f51\u7edc\u7684\u5c3a\u5bf8\u5230\u90a3\u4e2a\u7ef4\u5ea6\u5e76\u7ee7\u7eed\u8bad\u7ec3\u3002 \u2003\u8fd9\u4e2a\u673a\u5236\u8feb\u4f7f\u7f51\u7edc\u5b66\u4e60\u5982\u4f55\u5728\u5404\u79cd\u8f93\u5165\u7ef4\u5ea6\u4e0a\u505a\u597d\u9884\u6d4b\u3002\u8fd9\u610f\u5473\u7740\u540c\u4e00\u4e2a\u7f51\u7edc\u53ef\u4ee5\u9884\u6d4b\u4e0d\u540c\u5206\u8fa8\u7387\u4e0b\u7684\u68c0\u6d4b\u7ed3\u679c\u3002\u7f51\u7edc\u5728\u8f83\u5c0f\u7684\u5c3a\u5bf8\u4e0b\u8fd0\u884c\u901f\u5ea6\u66f4\u5feb\uff0c\u56e0\u6b64 \\(YOLOv2\\) \u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u677e\u7684\u6298\u4e2d\u3002 \u2003 \u5728\u4f4e\u5206\u8fa8\u7387\u4e0b\uff0c \\(YOLOv2\\) \u4f5c\u4e3a\u4e00\u79cd\u4fbf\u5b9c\u4f46\u76f8\u5f53\u51c6\u786e\u7684\u68c0\u6d4b\u5668\u5de5\u4f5c\u3002 \u5728 \\(288\u00d7288\\) \u60c5\u51b5\u4e0b\uff0c\u5b83\u7684\u8fd0\u884c\u901f\u5ea6\u8d85\u8fc7 90 FPS\uff0c\u800c \\(mAP\\) \u51e0\u4e4e\u4e0e \\(Fast \\ R-CNN\\) \u4e00\u6837\u597d\u3002\u8fd9\u4f7f\u5176\u6210\u4e3a\u5c0f\u578b \\(GPU\\) \uff0c\u9ad8\u5e27\u7387\u89c6\u9891\u6216\u591a\u89c6\u9891\u6d41\u7684\u7406\u60f3\u9009\u62e9\u3002 \u2003\u5728\u9ad8\u5206\u8fa8\u7387\u4e0b\uff0c \\(YOLOv2\\) \u662f\u4e00\u6b3e\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5728VOC2007\u4e0a\u83b7\u5f97\u4e8678.6\u7684 \\(mAP\\) \uff0c\u540c\u65f6\u4ecd\u4ee5\u9ad8\u4e8e\u5b9e\u65f6\u901f\u5ea6\u8fd0\u884c\u3002\u8bf7\u53c2\u9605\u88683\uff0c\u4e86\u89e3 \\(YOLOv2\\) \u4e0e\u5176\u4ed6\u6846\u67b6\u5728 \\(VOC \\ 2007\\) \u4e0a\u7684\u6bd4\u8f83 \u56fe4\u3002 \u56fe4\uff1a \\(VOC \\ 2007\\) \u4e0a\u7684\u7cbe\u5ea6\u548c\u901f\u5ea6 \u2003 \u8fdb\u4e00\u6b65\u7684\u5b9e\u9a8c \uff08Further Experiments\uff09\u3002 \u6211\u4eec\u5728 \\(VOC \\ 2012\\) \u4e0a\u8bad\u7ec3\u4e86 \\(YOLOv2\\) \u8fdb\u884c\u68c0\u6d4b\u3002\u88684 \u663e\u793a\u4e86 \\(YOLOv2\\) \u4e0e\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u7684\u6027\u80fd\u6bd4\u8f83\u3002 \\(YOLOv2\\) \u8fd0\u884c\u901f\u5ea6\u8fdc\u9ad8\u4e8e\u5bf9\u624b\uff0c\u4e14\u7cbe\u5ea6\u8fbe\u5230 73.4 \\(mAP\\) \u3002 \u6211\u4eec\u8fd8\u5728 \\(COCO\\) \u4e0a\u8bad\u7ec3\uff0c\u5e76\u4e0e\u88685\u4e2d\u7684\u5176\u4ed6\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002\u4f7f\u7528 \\(VOC\\) \u5ea6\u91cf\uff08 \\(IOU = 0.5\\) \uff09\uff0c \\(YOLOv2\\) \u83b7\u5f9744.0 \\(mAP\\) \uff0c\u4e0e \\(SSD\\) \u548c \\(Faster \\ R-CNN\\) \u76f8\u5f53\u3002 \\(\\begin{array}{lrrr} \\text { Detection Frameworks } & \\text { Train } & \\text { mAP } & \\text { FPS } \\\\ \\hline \\text { Fast R-CNN [5] } & 2007+2012 & 70.0 & 0.5 \\\\ \\text { Faster R-CNN VGG-16[15] } & 2007+2012 & 73.2 & 7 \\\\ \\text { Faster R-CNN ResNet[6] } & 2007+2012 & 76.4 & 5 \\\\ \\text { YOLO [14] } & 2007+2012 & 63.4 & 45 \\\\ \\text { SSD300 [11] } & 2007+2012 & 74.3 & 46 \\\\ \\text { SSD500 [11] } & 2007+2012 & 76.8 & 19 \\\\ \\hline \\text { YOLOv2 288 } \\times 288 & 2007+2012 & 69.0 & 91 \\\\ \\text { YOLOv2 352 } \\times 352 & 2007+2012 & 73.7 & 81 \\\\ \\text { YOLOv2 416 } \\times 416 & 2007+2012 & 76.8 & 67 \\\\ \\text { YOLOv2 480 } \\times 480 & 2007+2012 & 77.8 & 59 \\\\ \\text { YOLOv2 } 544 \\times 544 & 2007+2012 & \\mathbf{7 8 . 6} & 40 \\end{array}\\) \u88683\uff1a \\(PA S C A L \\ VOC \\ 2007\\) \u7684\u68c0\u6d4b\u6846\u67b6\u3002 \\(YOLOv2\\) \u6bd4\u4ee5\u524d\u7684\u68c0\u6d4b\u65b9\u6cd5\u66f4\u5feb\uff0c\u66f4\u51c6\u786e\u3002\u5b83\u4e5f\u53ef\u4ee5\u4ee5\u4e0d\u540c\u7684\u5206\u8fa8\u7387\u8fd0\u884c\uff0c\u4ee5\u4fbf\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u8f7b\u677e\u6298\u8877\u3002\u6bcf\u4e2a \\(YOLOv2\\) \u9879\u5b9e\u9645\u4e0a\u90fd\u662f\u5177\u6709\u76f8\u540c\u6743\u91cd\u7684\u76f8\u540c\u8bad\u7ec3\u6a21\u578b\uff0c\u53ea\u662f\u4ee5\u4e0d\u540c\u7684\u5927\u5c0f\u8fdb\u884c\u8bc4\u4f30\u3002\u6240\u6709\u7684\u65f6\u95f4\u7684\u6d4b\u8bd5\u90fd\u8fd0\u884c\u5728Geforce GTX Titan X\uff08\u539f\u59cb\u7684\uff0c\u800c\u4e0d\u662fPascal\u6a21\u578b\uff09 3.\u66f4\u5feb \u2003\u6211\u4eec\u5e0c\u671b\u68c0\u6d4b\u7ed3\u679c\u51c6\u786e\uff0c\u4f46\u6211\u4eec\u4e5f\u5e0c\u671b\u68c0\u6d4b\u901f\u5ea6\u66f4\u5feb\u3002 \u5927\u591a\u6570\u7528\u4e8e\u68c0\u6d4b\u7684\u5e94\u7528\u7a0b\u5e8f\uff08\u5982\u673a\u5668\u4eba\u6216\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff09\u90fd\u4f9d\u8d56\u4e8e\u4f4e\u5ef6\u8fdf\u9884\u6d4b\u3002 \u4e3a\u4e86\u6700\u5927\u9650\u5ea6\u5730\u63d0\u9ad8\u6027\u80fd\uff0c\u6211\u4eec\u5c06 \\(YOLOv2\\) \u8bbe\u8ba1\u4ece\u5934\u5230\u5c3e\u90fd\u975e\u5e38\u5feb \u3002 \u88682\uff1a\u4ece \\(YOLO\\) \u5230 \\(YOLOv2\\) \u7684\u8def\u5f84\u3002\u5927\u591a\u6570\u5217\u51fa\u7684\u8bbe\u8ba1\u51b3\u7b56\u90fd\u4f1a\u5bfc\u81f4 \\(MAP\\) \u663e\u7740\u589e\u52a0\u3002\u6709\u4e24\u4e2a\u4f8b\u5916\u60c5\u51b5\u662f\uff1a\u5207\u6362\u5230\u5e26\u6709\u951a\u6846\u7684\u5168\u5377\u79ef\u7f51\u7edc\u548c\u4f7f\u7528\u65b0\u7f51\u7edc\u3002\u5207\u6362\u5230\u951a\u6846\u65b9\u6cd5\u589e\u52a0\u53ec\u56de\u7387\uff0c\u800c\u4e0d\u6539\u53d8 \\(mAP\\) \uff0c\u800c\u4f7f\u7528\u65b0\u7f51\u7edc\u524a\u51cf33\uff05\u7684\u8ba1\u7b97\u3002 \u88684\uff1aPASCAL VOC2012\u6d4b\u8bd5\u68c0\u6d4b\u7ed3\u679c\u3002 \\(YOLOv2\\) \u4e0e\u91c7\u7528ResNet\u548cSSD512\u7684Faster R-CNN\u7b49\u5148\u8fdb\u68c0\u6d4b\u5668\u6027\u80fd\u76f8\u5f53\uff0c\u901f\u5ea6\u63d0\u9ad82\u81f310\u500d\u3002 \u2003\u5927\u591a\u6570\u68c0\u6d4b\u6846\u67b6\u4f9d\u8d56\u4e8eVGG-16\u4f5c\u4e3a\u57fa\u672c\u7279\u5f81\u63d0\u53d6\u5668[17]\u3002 \\(VGG-16\\) \u662f\u4e00\u4e2a\u529f\u80fd\u5f3a\u5927\uff0c\u51c6\u786e\u7684\u5206\u7c7b\u7f51\u7edc\uff0c\u4f46\u5b83\u6709\u4e0d\u5fc5\u8981\u7684\u590d\u6742\u5ea6\u3002 \\(VGG-16\\) \u7684\u5377\u79ef\u5c42\u5728\u4e00\u4e2a \\(224\u00d7224\\) \u5206\u8fa8\u7387\u5355\u4e2a\u56fe\u50cf\u4e0a\u8fd0\u884c\u4e00\u6b21\u9700\u8981 \\(306.90\\) \u4ebf\u6d6e\u70b9\u8fd0\u7b97\u3002 \u2003 \\(YOLO\\) \u6846\u67b6\u4f7f\u7528\u57fa\u4e8e \\(Googlenet\\) \u67b6\u6784\u7684\u81ea\u5b9a\u4e49\u7f51\u7edc[19]\u3002\u8fd9\u4e2a\u7f51\u7edc\u6bd4 \\(VGG-16\\) \u66f4\u5feb\uff0c\u4e00\u6b21\u524d\u5411\u4f20\u64ad\u53ea\u8981 \\(85.2\\) \u4ebf\u6b21\u8fd0\u884c\u3002\u7136\u800c\uff0c\u5b83\u7684\u51c6\u786e\u6027\u7565\u4f4e\u4e8e \\(VGG-16\\) \u3002\u5728 \\(ImageNet\\) \u4e0a\uff0c\u7528 \\(224\u00d7224\\) \u7684\u5355\u5f20\u88c1\u526a\u56fe\u50cf\uff0c \\(YOLO\\) \u7684\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u7cbe\u5ea6\u4e3a88.0\uff05\u800c \\(VGG-16\\) \u5219\u4e3a90.0\uff05\u3002 \u2003 \\(Darknet-19\\) \u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5206\u7c7b\u6a21\u578b\u4f5c\u4e3a \\(YOLOv2\\) \u7684\u57fa\u7840\u3002\u6211\u4eec\u7684\u6a21\u578b\u5efa\u7acb\u5728\u7f51\u7edc\u8bbe\u8ba1\u7684\u5148\u524d\u5de5\u4f5c\u4ee5\u53ca\u8be5\u9886\u57df\u7684\u5e38\u8bc6\u4e0a\u3002\u4e0e \\(VGG\\) \u6a21\u578b\u7c7b\u4f3c\uff0c\u6211\u4eec\u5927\u591a\u4f7f\u7528 \\(3\u00d73\\) \u6ee4\u6ce2\u5668\uff0c\u5e76\u4e14\u5728\u6c60\u5316\u5c42\u6b65\u9aa4\u540e\u4f7f\u7528\u4e24\u500d\u7684\u901a\u9053\u6570[17]\u3002\u6309\u7167Network in Network\uff08NIN\uff09\u7684\u65b9\u6cd5\uff0c\u6211\u4eec\u4f7f\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u6765\u505a\u9884\u6d4b\uff0c\u5e76\u4f7f\u75281\u00d71\u6ee4\u6ce2\u5668\u6765\u538b\u7f293\u00d73\u5377\u79ef\u7684\u7279\u5f81\u8868\u793a[9]\u3002\u6211\u4eec\u4f7f\u7528\u6279\u91cf\u5f52\u4e00\u5316\u6765\u7a33\u5b9a\u8bad\u7ec3\uff0c\u52a0\u901f\u6536\u655b\uff0c\u5e76\u89c4\u8303\u6a21\u578b[7]\u3002 \u2003\u6700\u7ec8\u7684\u6a21\u578b\u53eb\u505aDarknet-19\uff0c\u5b83\u670919\u4e2a\u5377\u79ef\u5c42\u548c5\u4e2aMaxpool\u5c42\u3002 \\(Darknet-19\\) \u53ea\u9700\u898155.8\u4ebf\u6b21\u64cd\u4f5c\u6765\u5904\u7406\u56fe\u50cf\uff0c\u4f46\u5728 \\(ImageNet\\) \u4e0a\u5b9e\u73b0\u4e8672.9\uff05\u7684top-1\u7cbe\u5ea6\u548c91.2\uff05\u7684top-5\u7cbe\u5ea6\u3002 \u2003 \u5206\u7c7b\u8bad\u7ec3 \uff08Training for classification\uff09\u3002\u6211\u4eec\u4f7f\u7528 \\(DarkNet\\) \u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u4f7f\u7528\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0c\u521d\u59cb\u5b66\u4e60\u7387\u4e3a0.1\uff0c\u591a\u9879\u5f0f\u901f\u7387\u8870\u51cf\u4e3a4\uff0c\u6743\u91cd\u8870\u51cf\u4e3a0.0005\uff0c\u52a8\u91cf\u4e3a0.9\uff0c\u5728\u6807\u51c6 \\(ImageNet\\) 1000\u7c7b\u522b\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u5bf9\u7f51\u7edc\u8fdb\u884c160\u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u8bad\u7ec3[13]\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u6807\u51c6\u6570\u636e\u589e\u5f3a\u6280\u5de7\uff0c\u5305\u62ec\u968f\u673a\u622a\u53d6\uff0c\u65cb\u8f6c\u548c\u6539\u53d8\u8272\u76f8\uff0c\u9971\u548c\u5ea6\u548c\u66dd\u5149\u3002 \u2003 \u5982\u4e0a\u6240\u8ff0\uff0c\u5728\u6211\u4eec\u5bf9 \\(224\u00d7224\\) \u56fe\u50cf\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3\u4e4b\u540e\uff0c\u6211\u4eec\u7528\u66f4\u5927\u7684\u5206\u8fa8\u7387448\u5bf9\u7f51\u7edc\u8fdb\u884c\u4e86\u5fae\u8c03\u3002\u5fae\u8c03\u65f6\uff0c\u6211\u4eec\u4f7f\u7528\u4e0a\u8ff0\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u4ec5\u752810\u4e2a\u5468\u671f\uff0c\u5e76\u4e14\u5f00\u59cb\u65f6\u7684\u5b66\u4e60\u7387\u4e3a10-3\u3002\u5728\u8fd9\u4e2a\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u4e0b\uff0c\u6211\u4eec\u7684\u7f51\u7edc\u5b9e\u73b0\u4e8676.5\uff05\u7684 \\(top-1\\) \u7cbe\u5ea6\u548c93.3\uff05\u7684 \\(top-5\\) \u7cbe\u5ea6\u3002 \u2003 \u68c0\u6d4b\u8bad\u7ec3 \uff08Training for detection\uff09\u3002\u6211\u4eec\u8fd9\u6837\u4fee\u6539\u7f51\u7edc\uff1a\u53bb\u9664\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u53d6\u800c\u4ee3\u4e4b\u7684\u662f\u6dfb\u52a0\u4e09\u4e2a \\(3 \u00d7 3\\) \u7684\u5377\u79ef\u5c42\uff0c\u6bcf\u4e2a\u5c42\u6709 \\(1024\\) \u4e2a\u8fc7\u6ee4\u5668\uff0c\u7136\u540e\u5728\u6700\u540e\u6dfb\u52a0 \\(1\u00d71\\) \u5377\u79ef\u5c42\uff0c\u8be5\u5c42\u7684\u6ee4\u6ce2\u5668\u6570\u91cf\u662f\u68c0\u6d4b\u9700\u8981\u7684\u8f93\u51fa\u6570\u91cf\u3002 \u5bf9\u4e8e \\(VOC\\) \uff0c\u6211\u4eec\u9884\u6d4b \\(05\\) \u4e2a\u8fb9\u754c\u6846\uff0c\u6bcf\u4e2a\u8fb9\u754c\u6846\u6709 5\u4e2a\u5750\u6807\u548c20\u4e2a\u7c7b\u522b\uff0c\u6240\u4ee5\u6709125\u4e2a\u6ee4\u6ce2\u5668\u3002\u6211\u4eec\u8fd8\u6dfb\u52a0\u4e86\u4ece\u6700\u540e\u7684 \\(3\u00d73\u00d7512\\) \u5c42\u5230\u5012\u6570\u7b2c\u4e8c\u5c42\u5377\u79ef\u5c42\u7684\u76f4\u901a\u5c42\uff0c\u4ee5\u4fbf\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u4f7f\u7528\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002 \u2003\u6211\u4eec\u8bad\u7ec3\u7f51\u7edc160\u4e2a\u8fed\u4ee3\u5468\u671f\uff0c\u521d\u59cb\u5b66\u4e60\u7387\u4e3a \\(10^{-3}\\) \uff0c\u572860\u548c90\u5468\u671f\u540c\u65f6\u9664\u4ee510\u3002\u6211\u4eec\u4f7f\u7528 \\(0.0005\\) \u7684\u6743\u503c\u8870\u51cf\u548c 0.9 \u7684\u52a8\u91cf( momentum )\u3002\u6211\u4eec\u5bf9 \\(YOLO\\) \u548c \\(SSD\\) \u8fdb\u884c\u7c7b\u4f3c\u7684\u6570\u636e\u589e\u5f3a\uff0c\u968f\u673a\u88c1\u526a\uff0c\u8272\u5f69\u4fee\u6539\u7b49\u3002\u6211\u4eec\u5728 \\(COCO\\) \u548c \\(VOC\\) \u4f7f\u7528\u76f8\u540c\u7684\u8bad\u7ec3\u7b56\u7565\u3002 \\(\\begin{array}{l|c|cccc|ccc|ccc|ccc} & & 0.5: 0.95 & 0.5 & 0.75 & \\mathrm{~S} & \\mathrm{M} & \\mathrm{L} & 1 & 10 & 100 & \\mathrm{~S} & \\mathrm{M} & \\mathrm{L} \\\\ \\hline \\text { Fast R-CNN [5] } & \\text { train } & 19.7 & 35.9 & - & - & - & - & - & - & - & - & - & - \\\\ \\text { Fast R-CNN[1] } & \\text { train } & 20.5 & 39.9 & 19.4 & 4.1 & 20.0 & 35.8 & 21.3 & 29.5 & 30.1 & 7.3 & 32.1 & 52 .0 \\\\ \\text { Faster R-CNN[15] } & \\text { trainval } & 21.9 & 42.7 & - & - & - & - & - & - & - & - & - & - \\\\ \\text { ION [1] } & \\text { train } & 23.6 & 43.2 & 23.6 & 6.4 & 24.1 & 38.3 & 23.2 & 32.7 & 33.5 & 10.1 & 37.7 & 53.6 \\\\ \\text { Faster R-CNN[10] } & \\text { trainval } & 24.2 & 45.3 & 23.5 & 7.7 & 26.4 & 37.1 & 23.8 & 34.0 & 34.6 & 12.0 & 38.5 & 54.4 \\\\ \\text { SSD300 [11] } & \\text { trainval35k } & 23.2 & 41.2 & 23.4 & 5.3 & 23.2 & 39.6 & 22.5 & 33.2 & 35.3 & 9.6 & 37.6 & 56.5 \\\\ \\text { SSD512 [11] } & \\text { trainval35k } & \\mathbf{26.8} & \\mathbf{4 6 . 5} & \\mathbf{2 7 . 8} & \\mathbf{9 . 0} & \\mathbf{2 8 . 9} & 41.9 & \\mathbf{2 4 . 8} & 37.5 & \\mathbf{3 9 . 8} & \\mathbf{1 4 . 0} & 43.5 & 59.0 \\\\ \\hline \\text { YOLOv2 [11] } & \\text { trainval35k } & 21.6 & 44.0 & 19.2 & 5.0 & 22.4 & 35.5 & 20.7 & 31.6 & 33.3 & 9.8 & 36.5 & 54 .4 \\end{array}\\) \u88685\uff1a \\(COCO\\) test-dev\u96c6\u4e0a\u7684\u7ed3\u679c\uff0c\u6765\u6e90\u4e8e\u8bba\u6587[11] 4.\u66f4\u5f3a \u2003\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u5408\u8bad\u7ec3\u5206\u7c7b\u548c\u68c0\u6d4b\u6570\u636e\u7684\u673a\u5236\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u4e86\u7528\u4e8e\u68c0\u6d4b\u7684\u56fe\u50cf\u6765\u5b66\u4e60\u68c0\u6d4b\u7279\u5b9a\u4fe1\u606f\uff0c\u5982\u8fb9\u754c\u6846\u5750\u6807\u9884\u6d4b\u548c\u76ee\u6807\u4ee5\u53ca\u5982\u4f55\u5bf9\u5e38\u89c1\u76ee\u6807\u8fdb\u884c\u5206\u7c7b\u3002\u901a\u8fc7\u4f7f\u7528\u4ec5\u5177\u6709\u7c7b\u6807\u7b7e\u7684\u56fe\u50cf\u6765\u6269\u5c55\u5176\u53ef\u68c0\u6d4b\u7c7b\u522b\u7684\u6570\u91cf\u3002 \u2003\u5728\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u6df7\u5408\u6765\u81ea\u68c0\u6d4b\u548c\u5206\u7c7b\u6570\u636e\u96c6\u7684\u56fe\u50cf\u3002 \u5f53\u6211\u4eec\u7684\u7f51\u7edc\u770b\u5230\u6807\u8bb0\u4e3a\u68c0\u6d4b\u7684\u56fe\u50cf\u65f6\uff0c\u53ef\u4ee5\u6839\u636e\u5b8c\u6574\u7684 \\(YOLOv2\\) \u635f\u5931\u51fd\u6570\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3002 \u5f53\u5b83\u770b\u5230\u5206\u7c7b\u56fe\u50cf\u65f6\uff0c\u53ea\u4f1a\u53cd\u5411\u4f20\u64ad\u5206\u7c7b\u90e8\u5206\u7684\u635f\u5931\u3002 \\(\\begin{array}{l|c|c|c} \\text { Type } & \\text { Filters } & \\text { Size/Stride } & \\text { Output } \\\\ \\hline \\text { Convolutional } & 32 & 3 \\times 3 & 224 \\times 224 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 112 \\times 112 \\\\ \\text { Convolutional } & 64 & 3 \\times 3 & 112 \\times 112 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 56 \\times 56 \\\\ \\text { Convolutional } & 128 & 3 \\times 3 & 56 \\times 56 \\\\ \\text { Convolutional } & 64 & 1 \\times 1 & 56 \\times 56 \\\\ \\text { Convolutional } & 128 & 3 \\times 3 & 56 \\times 56 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 28 \\times 28 \\\\ \\text { Convolutional } & 256 & 3 \\times 3 & 28 \\times 28 \\\\ \\text { Convolutional } & 128 & 1 \\times 1 & 28 \\times 28 \\\\ \\text { Convolutional } & 256 & 3 \\times 3 & 28 \\times 28 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Convolutional } & 256 & 1 \\times 1 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Convolutional } & 256 & 1 \\times 1 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\text { Convolutional } & 512 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\text { Convolutional } & 512 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\hline \\hline \\text { Convolutional } & 1000 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Avgpool } & & \\text { Global } & 1000 \\\\ \\text { Softmax } & & & \\end{array}\\) \u88686\uff1aDarknet-19 \u2003\u8fd9\u79cd\u65b9\u6cd5\u5e26\u6765\u4e86\u4e00\u4e9b\u96be\u9898\u3002\u68c0\u6d4b\u6570\u636e\u96c6\u53ea\u6709\u5e38\u7528\u7684\u76ee\u6807\u548c\u901a\u7528\u7684\u6807\u7b7e\uff0c\u5982\u201c\u72d7\u201d\u6216\u201c\u8239\u201d\u3002\u5206\u7c7b\u6570\u636e\u96c6\u5177\u6709\u66f4\u5e7f\u6cdb\u548c\u66f4\u6df1\u5165\u7684\u6807\u7b7e\u8303\u56f4\u3002 \\(ImageNet\\) \u62e5\u6709\u591a\u79cd\u72ac\u79cd\uff0c\u5305\u62ecNorfolk terrier\uff0cYorkshire terrier\u548cBedlington terrier\u3002\u5982\u679c\u6211\u4eec\u60f3\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5219\u9700\u8981\u91c7\u7528\u4e00\u81f4\u7684\u65b9\u5f0f\u6765\u5408\u5e76\u8fd9\u4e9b\u6807\u7b7e\u3002 \u2003\u5927\u591a\u6570\u5206\u7c7b\u65b9\u6cd5\u4f7f\u7528\u6db5\u76d6\u6240\u6709\u53ef\u80fd\u7c7b\u522b\u7684 \\(softmax\\) \u5c42\u6765\u8ba1\u7b97\u6700\u7ec8\u6982\u7387\u5206\u5e03\u3002\u4f7f\u7528 \\(softmax\\) \uff0c\u610f\u5473\u7740\u7c7b\u662f\u76f8\u4e92\u6392\u65a5\u7684\u3002\u8fd9\u7ed9\u7ec4\u5408\u6570\u636e\u96c6\u5e26\u6765\u4e86\u95ee\u9898\uff0c\u4f8b\u5982\uff0c\u4f60\u4e0d\u80fd\u7528\u8fd9\u4e2a\u6a21\u578b\u6765\u7ec4\u5408 \\(ImageNet\\) \u548c \\(COCO\\) \uff0c\u56e0\u4e3a\u7c7b\u522b \\(Norfolk \\ terrier\u548cdog\\) \u4e0d\u662f\u4e92\u65a5\u7684\u3002 \u2003\u76f8\u53cd\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u591a\u6807\u7b7e\u6a21\u578b\u6765\u7ec4\u5408\u4e0d\u4f1a\u4e92\u76f8\u6392\u65a5\u7684\u6570\u636e\u96c6\u3002\u8fd9\u4e2a\u65b9\u6cd5\u5ffd\u7565\u4e86\u6211\u4eec\u6240\u77e5\u9053\u7684\u5173\u4e8e\u6570\u636e\u7684\u6240\u6709\u7ed3\u6784\uff0c\u4f8b\u5982\u6240\u6709\u7684 \\(COCO\\) \u7c7b\u90fd\u662f\u76f8\u4e92\u72ec\u7acb\u7684\u3002 \u2003 \u5206\u5c42\u5206\u7c7b \uff08Hierarchical classification\uff09\u3002 \\(ImageNet\\) \u6807\u7b7e\u662f\u4ece \\(WordNet\\) \u4e2d\u63d0\u53d6\u7684\uff0c \\(WordNet\\) \u662f\u4e00\u4e2a\u6784\u5efa\u6982\u5ff5\u53ca\u5176\u76f8\u4e92\u5173\u7cfb\u7684\u8bed\u8a00\u6570\u636e\u5e93[12]\u3002 Norfolk terrier\u548cYorkshire terrier\u90fd\u662fterrier\u7684\u4e0b\u4e49\u8bcd\uff0cterrier\u662f\u4e00\u79cdhunting dog\uff0chunting dog\u662fdog\uff0cdog\u662fcanine\u7b49\u3002\u5927\u591a\u6570\u5206\u7c7b\u7684\u65b9\u6cd5\u5047\u8bbe\u6807\u7b7e\u662f\u4e00\u4e2a\u6241\u5e73\u7ed3\u6784\uff0c\u4f46\u662f\u5bf9\u4e8e\u7ec4\u5408\u6570\u636e\u96c6\uff0c\u7ed3\u6784\u6b63\u662f\u6211\u4eec\u6240\u9700\u8981\u7684\u3002 \u2003 \\(WordNet\\) \u7684\u7ed3\u6784\u662f\u6709\u5411\u56fe\uff0c\u800c\u4e0d\u662f\u6811\uff0c\u56e0\u4e3a\u8bed\u8a00\u5f88\u590d\u6742\u3002 \u4f8b\u5982\uff0c\u201c\u72d7\u201d\u65e2\u662f\u4e00\u79cd\u201c\u72ac\u201d\u53c8\u662f\u4e00\u79cd\u201c\u5bb6\u517b\u52a8\u7269\u201d\uff0c\u5b83\u4eec\u90fd\u662f \\(WordNet\\) \u4e2d\u7684\u540c\u4e49\u8bcd\u3002 \u6211\u4eec\u4e0d\u4f7f\u7528\u5b8c\u6574\u7684\u56fe\u7ed3\u6784\uff0c\u800c\u662f\u901a\u8fc7\u4ece \\(ImageNet\\) \u4e2d\u7684\u6982\u5ff5\u6784\u5efa\u5206\u5c42\u6811\u6765\u7b80\u5316\u95ee\u9898\u3002 \u2003WordNet\u7684\u7ed3\u6784\u662f\u6709\u5411\u56fe\uff0c\u800c\u4e0d\u662f\u6811\uff0c\u56e0\u4e3a\u8bed\u8a00\u5f88\u590d\u6742\u3002\u4f8b\u5982\uff0c\u4e00\u53ea\u72d7\u65e2\u662f\u4e00\u79cd\u72ac\u79d1\u52a8\u7269\uff0c\u53c8\u662f\u4e00\u79cd\u5bb6\u517b\u52a8\u7269\uff0c\u5b83\u4eec\u90fd\u662fWordNet\u4e2d\u7684\u540c\u79cd\u52a8\u7269\u3002\u6211\u4eec\u6ca1\u6709\u4f7f\u7528\u5b8c\u6574\u7684\u56fe\u7ed3\u6784\uff0c\u800c\u662f\u901a\u8fc7\u4ece \\(ImageNet\\) \u4e2d\u7684\u6982\u5ff5\u6784\u5efa\u5206\u5c42\u6811\u6765\u7b80\u5316\u95ee\u9898\u3002 \u2003\u4e3a\u4e86\u6784\u5efa\u8fd9\u68f5\u6811\uff0c\u6211\u4eec\u68c0\u67e5 \\(ImageNet\\) \u4e2d\u7684\u89c6\u89c9\u540d\u8bcd\uff0c\u5e76\u67e5\u770b\u5b83\u4eec\u901a\u8fc7 \\(WordNet\\) \u56fe\u5230\u6839\u8282\u70b9\u7684\u8def\u5f84\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u662f\u201c\u7269\u7406\u76ee\u6807\u201d\u3002 \u8bb8\u591a\u540c\u4e49\u8bcd\u53ea\u6709\u5728\u56fe\u4e0a\u4e00\u6761\u8def\u5f84\uff0c\u6240\u4ee5\u9996\u5148\u6211\u4eec\u5c06\u6240\u6709\u8fd9\u4e9b\u8def\u5f84\u6dfb\u52a0\u5230\u6211\u4eec\u7684\u6811\u4e2d\u3002 \u7136\u540e\uff0c\u6211\u4eec\u53cd\u590d\u68c0\u67e5\u6211\u4eec\u7559\u4e0b\u7684\u6982\u5ff5\uff0c\u5e76\u5c3d\u53ef\u80fd\u5c11\u5730\u6dfb\u52a0\u751f\u6210\u6811\u7684\u8def\u5f84\u3002 \u6240\u4ee5\u5982\u679c\u4e00\u4e2a\u6982\u5ff5\u6709\u4e24\u6761\u901a\u5411\u6839\u7684\u8def\u5f84\uff0c\u4e00\u6761\u8def\u5f84\u4f1a\u4e3a\u6211\u4eec\u7684\u6811\u589e\u52a0\u4e09\u6761\u8fb9\uff0c\u53e6\u4e00\u6761\u8def\u53ea\u589e\u52a0\u4e00\u6761\u8fb9\uff0c\u6211\u4eec\u9009\u62e9\u8f83\u77ed\u7684\u8def\u5f84\u3002 \u2003 \u6700\u7ec8\u7684\u7ed3\u679c\u662f \\(WordTree\\) \uff0c\u4e00\u4e2a\u89c6\u89c9\u6982\u5ff5\u7684\u5206\u5c42\u6a21\u578b\u3002\u4e3a\u4e86\u4f7f\u7528 \\(WordTree\\) \u8fdb\u884c\u5206\u7c7b\uff0c\u6211\u4eec\u9884\u6d4b\u6bcf\u4e2a\u8282\u70b9\u7684\u6761\u4ef6\u6982\u7387\uff0c\u4ee5\u5f97\u5230\u540c\u4e49\u8bcd\u96c6\u5408\u4e2d\u6bcf\u4e2a\u540c\u4e49\u8bcd\u4e0b\u4e49\u8bcd\u7684\u6982\u7387\u3002\u4f8b\u5982\uff0c\u5728terrier\u8282\u70b9\u6211\u4eec\u9884\u6d4b\uff1a \\(\\large\\operatorname{Pr} (Norfolk \\ terrier|terrier) \\\\ \\operatorname{Pr} (Yorkshire \\ terrier|terrier) \\\\ \\operatorname{Pr}( Bedlington \\ terrier|terrier )\\) \u2003\u5982\u679c\u6211\u4eec\u60f3\u8981\u8ba1\u7b97\u4e00\u4e2a\u7279\u5b9a\u8282\u70b9\u7684\u7edd\u5bf9\u6982\u7387\uff0c\u6211\u4eec\u53ea\u9700\u6cbf\u7740\u901a\u8fc7\u6811\u5230\u8fbe\u6839\u8282\u70b9\u7684\u8def\u5f84\uff0c\u518d\u4e58\u4ee5\u6761\u4ef6\u6982\u7387\u3002\u6240\u4ee5\u5982\u679c\u6211\u4eec\u60f3\u77e5\u9053\u4e00\u5f20\u56fe\u7247\u662f\u5426\u662fNorfolk terrier\uff0c\u6211\u4eec\u8ba1\u7b97\uff1a \\(\\operatorname{Pr}(\\text { Norfolk terrier }) = \\operatorname{Pr}(\\text { Norfolk terrier } \\mid \\text { terrier })\\) \\(\\quad * \\operatorname{Pr}(\\text { terrier } \\mid \\text { hunting dog })\\) \\(* \\ldots * \\\\\\) \\(* \\operatorname{Pr}(\\text { mammal } \\mid \\operatorname{Pr}(\\text { animal })\\) \\(* \\operatorname{Pr}(\\text { animal } \\mid \\text { physical object })\\) \u2003\u4e3a\u4e86\u5b9e\u73b0\u5206\u7c7b\uff0c\u6211\u4eec\u5047\u5b9a\u56fe\u50cf\u5305\u542b\u4e00\u4e2a\u76ee\u6807\uff1a \\(P r(physical object) = 1\\) \u3002 \u2003\u4e3a\u4e86\u9a8c\u8bc1\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u5728\u4f7f\u75281000\u7c7b \\(ImageNet\\) \u6784\u5efa\u7684 \\(WordTree\\) \u4e0a\u8bad\u7ec3 \\(Darknet-19\\) \u6a21\u578b\u3002 \u4e3a\u4e86\u6784\u5efa \\(WordTree1k\\) \uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u6240\u6709\u4e2d\u95f4\u8282\u70b9\uff0c\u5c06\u6807\u7b7e\u7a7a\u95f4\u4ece \\(1000\\) \u6269\u5c55\u5230 \\(1369\\) \u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u6211\u4eec\u5c06\u771f\u5b9e\u6807\u7b7e\u5411\u6811\u4e0a\u9762\u4f20\u64ad\uff0c\u4ee5\u4fbf\u5982\u679c\u56fe\u50cf\u88ab\u6807\u8bb0\u4e3aNorfolk terrier\uff0c\u5219\u5b83\u4e5f\u88ab\u6807\u8bb0\u4e3adog\u548cmamal\u7b49\u3002\u4e3a\u4e86\u8ba1\u7b97\u6761\u4ef6\u6982\u7387\uff0c\u6211\u4eec\u7684\u6a21\u578b\u9884\u6d4b\u4e861369\u4e2a\u503c\u7684\u5411\u91cf\uff0c\u5e76\u4e14\u6211\u4eec\u8ba1\u7b97\u4e86\u76f8\u540c\u6982\u5ff5\u7684\u4e0b\u4e49\u8bcd\u5728\u6240\u6709\u540c\u4e49\u8bcd\u96c6\u4e0a\u7684softmax\uff0c\u89c1\u56fe5\u3002 \u2003\u4f7f\u7528\u4e0e\u4ee5\u524d\u76f8\u540c\u7684\u8bad\u7ec3\u53c2\u6570\uff0c\u6211\u4eec\u7684\u5206\u5c42Darknet-19\u8fbe\u5230\u4e8671.9\uff05\u7684 \\(top-1\\) \u7cbe\u5ea6\u548c90.4\uff05\u7684 \\(top-5\\) \u7cbe\u5ea6\u3002 \u5c3d\u7ba1\u589e\u52a0\u4e86369\u4e2a\u9644\u52a0\u6982\u5ff5\uff0c\u5e76\u4e14\u8ba9\u6211\u4eec\u7684\u7f51\u7edc\u9884\u6d4b\u4e86\u6811\u72b6\u7ed3\u6784\uff0c\u4f46\u6211\u4eec\u7684\u7cbe\u5ea6\u4ec5\u7565\u6709\u4e0b\u964d\u3002 \u4ee5\u8fd9\u79cd\u65b9\u5f0f\u8fdb\u884c\u5206\u7c7b\u4e5f\u6709\u82e5\u5e72\u597d\u5904\u3002 \u5728\u65b0\u7684\u6216\u672a\u77e5\u7684\u76ee\u6807\u7c7b\u522b\u4e0a\uff0c\u6027\u80fd\u4f1a\u4f18\u96c5\u4f4e\u964d\u4f4e\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u7f51\u7edc\u770b\u5230\u4e00\u5f20\u72d7\u7684\u7167\u7247\uff0c\u4f46\u4e0d\u786e\u5b9a\u5b83\u662f\u4ec0\u4e48\u7c7b\u578b\u7684\u72d7\uff0c\u5b83\u4ecd\u7136\u4f1a\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u201cdog\u201d\uff0c\u53ea\u662f\u5728\u4e0b\u4e49\u8bcd\u4f1a\u6709\u8f83\u4f4e\u7684\u7f6e\u4fe1\u5ea6\u3002 \u2003\u8be5\u65b9\u6cd5\u4e5f\u9002\u7528\u4e8e\u68c0\u6d4b\u3002\u73b0\u5728\uff0c\u6211\u4eec\u4e0d\u7528\u5047\u5b9a\u6bcf\u4e2a\u56fe\u50cf\u90fd\u6709\u4e00\u4e2a\u76ee\u6807\u7269\u4f53\uff0c\u800c\u662f\u4f7f\u7528 \\(YOLOv2\\) \u7684\u76ee\u6807\u9884\u6d4b\u5668\u7ed9\u51faP r\uff08\u76ee\u6807\u7269\u4f53\uff09\u7684\u503c\u3002\u68c0\u6d4b\u5668\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u6982\u7387\u6811\u3002\u6211\u4eec\u904d\u5386\u6811\uff0c\u5728\u6bcf\u6b21\u5206\u5272\u4e2d\u9009\u53d6\u5177\u6709\u6700\u9ad8\u7684\u7f6e\u4fe1\u5ea6\u7684\u8def\u5f84\uff0c\u76f4\u5230\u8fbe\u5230\u67d0\u4e2a\u9608\u503c\uff0c\u7136\u540e\u6211\u4eec\u5f97\u5230\u8be5\u76ee\u6807\u7684\u7c7b\u522b\u3002 \u2003 \u6570\u636e\u96c6\u4e0e \\(WordTree\\) \u7684\u7ec4\u5408 (Dataset combination with WordTree)\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \\(WordTree\\) \u4ee5\u53ef\u884c\u7684\u65b9\u5f0f\u5c06\u591a\u4e2a\u6570\u636e\u96c6\u7ec4\u5408\u5728\u4e00\u8d77\u3002\u6211\u4eec\u53ea\u9700\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u6620\u5c04\u5230\u6811\u4e2d\u7684synsets\u5373\u53ef\u3002\u56fe6\u663e\u793a\u4e86\u4e00\u4e2a\u4f7f\u7528 \\(WordTree\\) \u7ec4\u5408\u6765\u81ea \\(ImageNet\\) \u548c \\(COCO\\) \u7684\u6807\u7b7e\u7684\u793a\u4f8b\u3002 WordNet\u975e\u5e38\u591a\u6837\u5316\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u8fd9\u79cd\u6280\u672f\u7528\u4e8e\u5927\u591a\u6570\u6570\u636e\u96c6\u3002 \u56fe5\uff1a\u5bf9 \\(ImageNet\\) \u4e0e \\(WordTree\\) \u7684\u9884\u6d4b\u3002\u5927\u591a\u6570ImaNet\u6a21\u578b\u4f7f\u7528\u4e00\u4e2a\u5927\u7684softmax\u6765\u9884\u6d4b\u6982\u7387\u5206\u5e03\u3002\u4f7f\u7528 \\(WordTree\\) \uff0c\u6211\u4eec\u901a\u8fc7\u5171\u540c\u7684\u4e0b\u4f4d\u8bcd\u6267\u884c\u591a\u4e2asoftmax\u64cd\u4f5c\u3002 \u2003 \u8054\u5408\u5206\u7c7b\u548c\u68c0\u6d4b (Joint classification and detection)\u3002\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \\(WordTree\\) \u7ec4\u5408\u6570\u636e\u96c6\uff0c\u5728\u5206\u7c7b\u548c\u68c0\u6d4b\u4e0a\u8bad\u7ec3\u8054\u5408\u6a21\u578b\u3002\u6211\u4eec\u60f3\u8981\u8bad\u7ec3\u4e00\u4e2a\u975e\u5e38\u5927\u89c4\u6a21\u7684\u68c0\u6d4b\u5668\uff0c\u6240\u4ee5\u4f7f\u7528 \\(COCO\\) \u68c0\u6d4b\u6570\u636e\u96c6\u548c\u5b8c\u6574 \\(ImageNet\\) \u7248\u672c\u4e2d\u7684\u524d9000\u7c7b\u521b\u5efa\u6211\u4eec\u7684\u7ec4\u5408\u6570\u636e\u96c6\u3002\u6211\u4eec\u8fd8\u9700\u8981\u8bc4\u4f30\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u4ee5\u4fbf\u4ece \\(ImageNet\\) \u68c0\u6d4b\u6311\u6218\u4e2d\u6dfb\u52a0\u4efb\u4f55\u5c1a\u672a\u5305\u542b\u7684\u7c7b\u3002\u8be5\u6570\u636e\u96c6\u7684\u76f8\u5e94 \\(WordTree\\) \u5177\u67099418\u4e2a\u7c7b\u3002 \\(ImageNet\\) \u6709\u66f4\u5927\u7684\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u901a\u8fc7\u5bf9 \\(COCO\\) \u8fdb\u884c\u8fc7\u91c7\u6837\u6765\u5e73\u8861\u6570\u636e\u96c6\uff0c\u4f7f\u5f97 \\(ImageNet\\) \u4e0e \\(COCO\\) \u7684\u6bd4\u4f8b\u7565\u5927\u4e8e \\(4:1\\) \u3002 \u2003\u6211\u4eec\u4f7f\u7528\u4e0a\u8ff0\u7684\u6570\u636e\u96c6\u8bad\u7ec3 \\(YOLO9000\\) \u3002 \u6211\u4eec\u4f7f\u7528\u57fa\u672c\u7684 \\(YOLOv2\\) \u67b6\u6784\uff0c\u4f46\u53ea\u67093\u4e2a\u5148\u9a8c\u6846\u800c\u4e0d\u662f5\u4e2a\u6765\u9650\u5236\u8f93\u51fa\u5927\u5c0f\u3002\u5f53\u6211\u4eec\u7684\u7f51\u7edc\u5904\u7406\u68c0\u6d4b\u56fe\u50cf\u65f6\uff0c\u6211\u4eec\u4f1a\u50cf\u5e73\u5e38\u4e00\u6837\u53cd\u5411\u4f20\u64ad\u635f\u5931\u3002\u5bf9\u4e8e\u5206\u7c7b\u635f\u5931\uff0c\u6211\u4eec\u53ea\u662f\u5c06\u635f\u5931\u53cd\u5411\u4f20\u64ad\u5230\u6807\u7b7e\u76f8\u5e94\u7ea7\u522b\u6216\u66f4\u9ad8\u7684\u7ea7\u522b\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u6807\u7b7e\u662f\u72d7\uff0c\u6211\u4eec\u4e0d\u4f1a\u5c06\u4efb\u4f55\u9519\u8bef\u7ed9\u6811\u505a\u8fdb\u4e00\u6b65\u9884\u6d4b\uff0c\u5982\u5fb7\u56fd\u7267\u7f8a\u72ac\u4e0e\u9ec4\u91d1\u730e\u72ac\uff0c\u56e0\u4e3a\u6211\u4eec\u6ca1\u6709\u8fd9\u4e9b\u4fe1\u606f\u3002 \u56fe6\uff1a\u4f7f\u7528 \\(WordTree\\) \u5c42\u6b21\u7ed3\u6784\u7ec4\u5408\u6570\u636e\u96c6\u3002\u4f7f\u7528WordNet\u6982\u5ff5\u56fe\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u89c6\u89c9\u6982\u5ff5\u7684\u5206\u5c42\u6811\u3002\u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u6620\u5c04\u5230\u6811\u4e2d\u7684synsets\u6765\u5408\u5e76\u6570\u636e\u96c6\u3002\u51fa\u4e8e\u8bf4\u660e\u76ee\u7684\uff0c\u8fd9\u662f \\(WordTree\\) \u7684\u7b80\u5316\u89c6\u56fe\u3002 \u2003\u5f53\u7f51\u7edc\u5904\u7406\u5206\u7c7b\u56fe\u50cf\u65f6\uff0c\u6211\u4eec\u53ea\u662f\u53cd\u5411\u4f20\u64ad\u5206\u7c7b\u635f\u5931\u3002\u8981\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ea\u9700\u627e\u5230\u9884\u6d4b\u8be5\u7c7b\u522b\u6700\u9ad8\u6982\u7387\u7684\u8fb9\u754c\u6846\uff0c\u7136\u540e\u5728\u9884\u6d4b\u7684\u6811\u4e0a\u8ba1\u7b97\u635f\u5931\u3002\u6211\u4eec\u8fd8\u5047\u8bbe\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u7684 \\(IOU\\) \u81f3\u5c11\u4e3a0.3\uff0c\u5e76\u4e14\u57fa\u4e8e\u8fd9\u4e2a\u5047\u8bbe\u6211\u4eec\u53cd\u5411\u4f20\u64ad\u76ee\u6807\u635f\u5931\u3002 \u2003\u901a\u8fc7\u8fd9\u79cd\u8054\u5408\u8bad\u7ec3\uff0c \\(YOLO9000\\) \u5b66\u4e60\u4f7f\u7528 \\(COCO\\) \u4e2d\u7684\u68c0\u6d4b\u6570\u636e\u6765\u67e5\u627e\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff0c\u5e76\u5b66\u4e60\u4f7f\u7528\u6765\u81ea \\(ImageNet\\) \u7684\u6570\u636e\u5bf9\u5404\u79cd\u8fd9\u4e9b\u76ee\u6807\u8fdb\u884c\u5206\u7c7b\u3002 \u2003\u6211\u4eec\u5728 \\(ImageNet\\) \u68c0\u6d4b\u4efb\u52a1\u4e0a\u8bc4\u4f30 \\(YOLO9000\\) \u3002 \\(ImageNet\\) \u7684\u68c0\u6d4b\u4efb\u52a1\u4e0e \\(COCO\\) \u5171\u4eab44\u4e2a\u76ee\u6807\u7c7b\u522b\uff0c\u8fd9\u610f\u5473\u7740 \\(YOLO9000\\) \u770b\u5230\u7684\u6d4b\u8bd5\u56fe\u50cf\u5927\u591a\u6570\u662f\u5206\u7c7b\u6570\u636e\uff0c\u800c\u4e0d\u662f\u68c0\u6d4b\u6570\u636e\u3002 \\(YOLO9000\\) \u7684\u603b \\(mAP\\) \u662f19.7 \\(mAP\\) \uff0c\u5176\u4e2d\u5728\u4e0d\u76f8\u4ea4\u7684156\u4e2a\u76ee\u6807\u7c7b\u4e0a\uff0c \\(YOLO9000\\) \u4ece\u672a\u89c1\u8fc7\u8fd9\u4e9b\u7c7b\u7684\u4efb\u4f55\u68c0\u6d4b\u6570\u636e\u7684\u6807\u7b7e\uff0c\u4ecd\u83b7\u5f97\u4e8616.0 \\(mAP\\) \u3002\u8fd9\u4e2a \\(mAP\\) \u9ad8\u4e8eDPM\u7684\u7ed3\u679c\uff0c\u4f46 \\(YOLO9000\\) \u662f\u5728\u90e8\u5206\u76d1\u7763[4]\u7684\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u3002\u800c\u4e14\u5b83\u80fd\u540c\u65f6\u68c0\u6d4b9000\u4e2a\u5176\u4ed6\u76ee\u6807\u7c7b\u522b\uff0c\u6240\u6709\u7684\u68c0\u6d4b\u90fd\u662f\u5b9e\u65f6\u7684\u3002 \u2003\u5728\u5206\u6790 \\(YOLO9000\\) \u5728 \\(ImageNet\\) \u4e0a\u7684\u8868\u73b0\u65f6\uff0c\u6211\u4eec\u53d1\u73b0\u5b83\u5f88\u597d\u5730\u5b66\u4e60\u4e86\u65b0\u7684\u52a8\u7269\u79cd\u7c7b\uff0c\u4f46\u662f\u5728\u50cf\u670d\u88c5\u548c\u8bbe\u5907\u8fd9\u6837\u7684\u5b66\u4e60\u7c7b\u522b\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u65b0\u52a8\u7269\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u56e0\u4e3a\u76ee\u6807\u9884\u6d4b\u53ef\u4ee5\u4ece \\(COCO\\) \u4e2d\u7684\u52a8\u7269\u6cdb\u5316\u7684\u5f88\u597d\u3002\u76f8\u53cd\uff0c \\(COCO\\) \u6ca1\u6709\u4efb\u4f55\u7c7b\u578b\u7684\u8863\u670d\u7684\u8fb9\u754c\u6846\u6807\u7b7e\uff0c\u53ea\u9488\u5bf9\u4eba\uff0c\u56e0\u6b64 \\(YOLO9000\\) \u5728\u5206\u7c7b\u201c\u58a8\u955c\u201d\u6216\u201c\u6cf3\u88e4\u201d\u7b49\u7c7b\u522b\u4e0a\u5b58\u5728\u56f0\u96be\u3002 \\(\\begin{array}{ll} \\text { diaper } & 0.0 \\\\ \\text { horizontal bar } & 0.0 \\\\ \\text { rubber eraser } & 0.0 \\\\ \\text { sunglasses } & 0.0 \\\\ \\text { swimming trunks } & 0.0 \\\\ \\ldots & \\\\ \\text { red panda } & 50.7 \\\\ \\text { fox } & 52.1 \\\\ \\text { koala bear } & 54.3 \\\\ \\text { tiger } & 61.0 \\\\ \\text { armadillo } & 61.7 \\end{array}\\) \u88687\uff1a \\(ImageNet\\) \u4e0a\u7684 \\(YOLO9000\\) \u6700\u4f73\u548c\u6700\u5dee\u7c7b\u522b\u3002 156\u4e2a\u5f31\u76d1\u7763\u7c7b\u7684AP\u6700\u9ad8\u548c\u6700\u4f4e\u7684\u7c7b\u3002 \\(YOLO9000\\) \u6a21\u578b\u5f88\u597d\u5730\u9884\u6d4b\u5404\u79cd\u5404\u6837\u7684\u52a8\u7269\uff0c\u4f46\u4e0d\u64c5\u957f\u9884\u6d4b\u8bf8\u5982\u670d\u88c5\u6216\u8bbe\u5907\u7b49\u7684\u65b0\u7c7b\u3002 5.\u603b\u7ed3 \u2003\u6211\u4eec\u4ecb\u7ecd\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf \\(YOLOv2\\) \u548c \\(YOLO9000\\) \u3002 \\(YOLOv2\\) \u5728\u5404\u79cd\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u90fd\u662f\u6700\u5148\u8fdb\u7684\uff0c\u5e76\u4e14\u6bd4\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u66f4\u5feb\u3002\u6b64\u5916\uff0c\u5b83\u53ef\u4ee5\u5728\u5404\u79cd\u56fe\u50cf\u5c3a\u5bf8\u4e0b\u8fd0\u884c\uff0c\u4ee5\u63d0\u4f9b\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5e73\u6ed1\u6298\u4e2d\u3002 \u2003 \\(YOLO9000\\) \u662f\u4e00\u4e2a\u901a\u8fc7\u8054\u5408\u4f18\u5316\u68c0\u6d4b\u548c\u5206\u7c7b\u6765\u68c0\u6d4b\u8d85\u8fc79000\u4e2a\u76ee\u6807\u7c7b\u522b\u7684\u5b9e\u65f6\u6846\u67b6\u3002\u6211\u4eec\u4f7f\u7528 \\(WordTree\\) \u5c06\u5404\u79cd\u6765\u6e90\u7684\u6570\u636e\u548c\u6211\u4eec\u7684\u8054\u5408\u4f18\u5316\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u5728 \\(ImageNet\\) \u548c \\(COCO\\) \u4e0a\u540c\u65f6\u8fdb\u884c\u8bad\u7ec3\u3002 \\(YOLO9000\\) \u5411\u7f29\u5c0f\u68c0\u6d4b\u548c\u5206\u7c7b\u4e4b\u95f4\u7684\u6570\u636e\u96c6\u5927\u5c0f\u7684\u5dee\u8ddd\u8fc8\u51fa\u4e86\u575a\u5b9e\u7684\u4e00\u6b65\u3002 \u2003\u6211\u4eec\u7684\u8bb8\u591a\u6280\u672f\u90fd\u662f\u6cdb\u5316\u5230\u76ee\u6807\u68c0\u6d4b\u4e4b\u5916\u7684\u9886\u57df\u3002 \\(ImageNet\\) \u7684 \\(WordTree\\) \u8868\u793a\u65b9\u6cd5\u4e3a\u56fe\u50cf\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\uff0c\u66f4\u8be6\u7ec6\u7684\u8f93\u51fa\u7a7a\u95f4\u3002\u4f7f\u7528\u5206\u5c42\u5206\u7c7b\u7684\u6570\u636e\u96c6\u7ec4\u5408\u5728\u5206\u7c7b\u548c\u5206\u5272\u9886\u57df\u5c06\u4f1a\u5f88\u6709\u7528\u3002\u50cf\u591a\u5c3a\u5ea6\u8bad\u7ec3\u8fd9\u6837\u7684\u8bad\u7ec3\u6280\u672f\u53ef\u4ee5\u4e3a\u5404\u79cd\u89c6\u89c9\u4efb\u52a1\u63d0\u4f9b\u5e2e\u52a9\u3002 \u2003\u5bf9\u4e8e\u672a\u6765\u7684\u5de5\u4f5c\uff0c\u6211\u4eec\u5e0c\u671b\u4f7f\u7528\u7c7b\u4f3c\u7684\u6280\u672f\u8fdb\u884c\u5f31\u76d1\u7763\u56fe\u50cf\u5206\u5272\u3002\u6211\u4eec\u8fd8\u8ba1\u5212\u4f7f\u7528\u66f4\u5f3a\u5927\u7684\u5339\u914d\u7b56\u7565\u6765\u6539\u5584\u6211\u4eec\u7684\u68c0\u6d4b\u7ed3\u679c\uff0c\u4ee5\u5728\u8bad\u7ec3\u671f\u95f4\u5c06\u5f31\u6807\u7b7e\u5206\u914d\u7ed9\u5206\u7c7b\u6570\u636e\u3002\u8ba1\u7b97\u673a\u89c6\u89c9\u62e5\u6709\u5927\u91cf\u7684\u6807\u8bb0\u6570\u636e\u3002\u6211\u4eec\u5c06\u7ee7\u7eed\u5bfb\u627e\u65b9\u6cd5\uff0c\u5c06\u4e0d\u540c\u7684\u6570\u636e\u6765\u6e90\u548c\u6570\u636e\u7ed3\u6784\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u5f62\u6210\u66f4\u5f3a\u5927\u7684\u89c6\u89c9\u4e16\u754c\u6a21\u578b\u3002 References [1] S. Bell, C. L. Zitnick, K. Bala, and R. Girshick. Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks. arXiv preprint arXiv:1512.04143, 2015. 6 [2] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 248\u2013255. IEEE, 2009. 1 [3] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) chal-lenge. International journal of computer vision, 88(2):303\u2013338, 2010. 1 [4] P. F. Felzenszwalb, R. B. Girshick, and D. McAllester. Discriminatively trained deformable part models, release 4. http://people.cs.uchicago.edu/ pff/latent-release4/. 8 [5] R. B. Girshick. Fast R-CNN. CoRR, abs/1504.08083, 2015. 4, 5, 6 [6] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learn-ing for image recognition. arXiv preprint arXiv:1512.03385, 2015. 2, 4, 5 [7] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015. 2, 5 [8] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097\u20131105, 2012. 2 [9] M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.4400, 2013. 5 [10] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ra-manan, P. Doll\u00b4ar, and C. L. Zitnick. Microsoft coco: Com-mon objects in context. In European Conference on Com-puter Vision, pages 740\u2013755. Springer, 2014. 1, 6 [11] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, and S. E. Reed. SSD: single shot multibox detector. CoRR, abs/1512.02325, 2015. 4, 5, 6 [12] G. A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. J. Miller. Introduction to wordnet: An on-line lexical database. International journal of lexicography, 3(4):235\u2013244, 1990. 6 [13] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 5 [14] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. arXiv preprint arXiv:1506.02640, 2015. 4, 5 [15] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: To-wards real-time object detection with region proposal net-works. arXiv preprint arXiv:1506.01497, 2015. 2, 3, 4, 5, 6 [16] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. 2 [17] K. Simonyan and A. Zisserman. V ery deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. 2, 5 [18] C. Szegedy, S. Ioffe, and V . V anhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR, abs/1602.07261, 2016. 2 [19] C. Szegedy, W. Liu, Y . Jia, P . Sermanet, S. Reed, D. Anguelov, D. Erhan, V . V anhoucke, and A. Rabinovich.Going deeper with convolutions. CoRR, abs/1409.4842, 2014. 5 [20] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):64\u201373, 2016. 1","title":"YOLOv2"},{"location":"thesis_interpretation/02_yolo.html#_1","text":"\u6211\u4eec\u63a8\u51fa\u7684 \\(YOLO9000\\) \u662f\u4e00\u6b3e\u5148\u8fdb\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7cfb\u7edf\uff0c\u53ef\u68c0\u6d4b9000\u591a\u79cd\u76ee\u6807\u7c7b\u522b\u3002\u9996\u5148\uff0c\u6211\u4eec\u63d0\u51fa\u5bf9 \\(YOLO\\) \u68c0\u6d4b\u65b9\u6cd5\u7684\u5404\u79cd\u6539\u8fdb\uff0c\u8fd9\u4e9b\u6539\u8fdb\u6709\u72ec\u521b\u7684\uff0c\u4e5f\u6709\u7684\u662f\u6765\u6e90\u4e8e\u4ee5\u524d\u7684\u7814\u7a76\u3002\u6539\u8fdb\u540e\u7684\u6a21\u578b \\(YOLOv2\\) \u5728 \\(PASCAL VOC\\) \u548c \\(COCO\\) \u7b49\u6807\u51c6\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5904\u4e8e\u6280\u672f\u9886\u5148\u5730\u4f4d\u3002\u901a\u8fc7\u4f7f\u7528\u4e00\u79cd\u65b0\u9896\u7684\u591a\u5c3a\u5ea6\u8bad\u7ec3\u65b9\u6cd5\uff0c\u540c\u6837\u7684 \\(YOLOv2\\) \u6a21\u578b\u53ef\u4ee5\u4ee5\u4e0d\u540c\u7684\u5c3a\u5bf8\u8fd0\u884c\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u6298\u8877\u3002\u5728 \\(67 FPS\\) \u65f6\uff0c \\(YOLOv2\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u83b7\u5f97\u4e8676.8 \\(mAP\\) \u3002\u5728 \\(40FPS\\) \u65f6\uff0c \\(YOLOv2\\) \u83b7\u5f97\u4e8678.6 \\(mAP\\) \uff0c\u8d85\u8d8a\u4e86\u91c7\u7528 \\(ResNet\\) \u548c \\(SSD\u7684Faster \\ R-CNN\\) \u7b49\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u8fd0\u884c\u901f\u5ea6\u4ecd\u7136\u66f4\u5feb\u3002\u6700\u540e\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u8054\u5408\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u548c\u5206\u7c7b\u7684\u65b9\u6cd5\u3002\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u5728 \\(COCO\\) \u68c0\u6d4b\u6570\u636e\u96c6\u548c \\(ImageNet\\) \u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u540c\u65f6\u8bad\u7ec3 \\(YOLO9000\\) \u3002\u6211\u4eec\u7684\u8054\u5408\u8bad\u7ec3\u4f7f \\(YOLO9000\\) \u80fd\u591f\u9884\u6d4b\u672a\u6807\u6ce8\u68c0\u6d4b\u6570\u636e\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u5e76\u4e14\u6211\u4eec\u5728 \\(ImageNet\\) \u68c0\u6d4b\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u3002 \\(YOLO9000\\) \u5728 \\(ImageNet\\) \u68c0\u6d4b\u9a8c\u8bc1\u96c6\u4e0a\u83b7\u5f9719.7 \\(mAP\\) \uff0c\u5c3d\u7ba1200\u4e2a\u7c7b\u4e2d\u53ea\u670944\u4e2a\u5177\u6709\u68c0\u6d4b\u6570\u636e\u3002\u5728 \\(COCO\\) \u4e0a\u6ca1\u6709\u7684156\u79cd\u7c7b\u4e0a\uff0c \\(YOLO9000\\) \u5f97\u5230 16.0 \\(mAP\\) \uff0c\u4f46\u662f \\(YOLO\\) \u53ef\u4ee5\u68c0\u6d4b\u8d85\u8fc7200\u4e2a\u79cd\u7c7b;\u5b83\u9884\u6d4b\u8d85\u8fc79000 \u591a\u79cd\u4e0d\u540c\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u800c\u4e14\u5b83\u4ecd\u7136\u662f\u5b9e\u65f6\u8fd0\u884c\u7684\u3002 \u56fe1: \\(YOLO9000\\) \u3002 \\(YOLO9000\\) \u53ef\u4ee5\u5b9e\u65f6\u68c0\u6d4b\u5404\u79cd\u5404\u6837\u7684\u76ee\u6807\u7c7b\u522b\u3002","title":"\u6458\u8981"},{"location":"thesis_interpretation/02_yolo.html#1","text":"\u901a\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u5e94\u8be5\u5feb\u901f\uff0c\u51c6\u786e\uff0c\u5e76\u4e14\u80fd\u591f\u8bc6\u522b\u5404\u79cd\u5404\u6837\u7684\u76ee\u6807\u3002\u81ea\u4ece\u5f15\u5165\u795e\u7ecf\u7f51\u7edc\uff0c\u68c0\u6d4b\u6846\u67b6\u53d8\u5f97\u8d8a\u6765\u8d8a\u5feb\u901f\u548c\u51c6\u786e\u3002\u4f46\u662f\uff0c\u5927\u591a\u6570\u68c0\u6d4b\u65b9\u6cd5\u4ec5\u9650\u4e8e\u68c0\u6d4b\u4e00\u5c0f\u90e8\u5206\u76ee\u6807\u3002 \u2003\u4e0e\u5206\u7c7b\u548c\u6807\u8bb0\u7b49\u5176\u4ed6\u4efb\u52a1\u7684\u6570\u636e\u96c6\u76f8\u6bd4\uff0c\u76ee\u524d\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u662f\u6709\u9650\u7684\u3002\u6700\u5e38\u89c1\u7684\u68c0\u6d4b\u6570\u636e\u96c6\u5305\u542b\u6210\u5343\u4e0a\u4e07\u5230\u6570\u5341\u4e07\u5f20\u5177\u6709\u6210\u767e\u4e0a\u5343\u4e2a\u6807\u7b7e\u7684\u56fe\u50cf[3][10][2]\u3002\u800c\u5206\u7c7b\u6570\u636e\u96c6\u6709\u6570\u4ee5\u767e\u4e07\u8ba1\u7684\u56fe\u50cf\uff0c\u6570\u5341\u6216\u6570\u767e\u4e07\u4e2a\u7c7b\u522b[20][2]\u3002 \u2003\u6211\u4eec\u5e0c\u671b\u68c0\u6d4b\u7684\u7c7b\u522b\u80fd\u591f\u6269\u5c55\u5230\u76ee\u6807\u5206\u7c7b\u7684\u7ea7\u522b\u3002\u4f46\u662f\uff0c\u6807\u6ce8\u68c0\u6d4b\u56fe\u50cf\u8981\u6bd4\u6807\u6ce8\u5206\u7c7b\u6216\u8d34\u6807\u7b7e\u8981\u6602\u8d35\u5f97\u591a\uff08 \u6807\u7b7e\u901a\u5e38\u662f\u7528\u6237\u514d\u8d39\u63d0\u4f9b ) \u3002\u56e0\u6b64\uff0c\u6211\u4eec\u4e0d\u592a\u53ef\u80fd\u5728\u8fd1\u671f\u5185\u770b\u5230\u4e0e\u5206\u7c7b\u6570\u636e\u96c6\u76f8\u540c\u89c4\u6a21\u7684\u68c0\u6d4b\u6570\u636e\u96c6\u3002 \u2003\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u2014\u2014\u901a\u8fc7\u5229\u7528\u6211\u4eec\u5df2\u6709\u7684\u5927\u91cf\u5206\u7c7b\u6570\u636e\u6765\u6269\u5927\u5f53\u524d\u68c0\u6d4b\u7cfb\u7edf\u7684\u8303\u56f4\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u76ee\u6807\u5206\u7c7b\u7684\u5206\u5c42\u89c6\u56fe\uff0c\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u5c06\u4e0d\u540c\u7684\u6570\u636e\u96c6\u7ec4\u5408\u5728\u4e00\u8d77\u3002 \u2003\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5b83\u5141\u8bb8\u6211\u4eec\u5728\u68c0\u6d4b\u548c\u5206\u7c7b\u6570\u636e\u4e0a\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u5668\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u6807\u8bb0\u68c0\u6d4b\u56fe\u50cf\u6765\u5b66\u4e60\u7cbe\u786e\u5b9a\u4f4d\u76ee\u6807\uff0c\u540c\u65f6\u4f7f\u7528\u5206\u7c7b\u56fe\u50cf\u6765\u589e\u52a0\u8bcd\u6c47\u91cf\u548c\u9c81\u68d2\u6027\u3002 \u2003\u6211\u4eec\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8bad\u7ec3 \\(YOLO9000\\) b\u4e00\u79cd\u53ef\u4ee5\u68c0\u6d4b\u8d85\u8fc79000\u79cd\u4e0d\u540c\u7684\u76ee\u6807\u7c7b\u522b\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u3002 \u9996\u5148\uff0c\u6211\u4eec\u6539\u8fdbYOLO\u57fa\u7840\u68c0\u6d4b\u7cfb\u7edf\uff0c\u751f\u6210\u6700\u5148\u8fdb\u7684\u5b9e\u65f6\u68c0\u6d4b\u5668 \\(YOLOv2\\) \u3002 \u7136\u540e\uff0c\u91c7\u7528\u6211\u4eec\u7684\u6570\u636e\u96c6\u7ec4\u5408\u65b9\u6cd5\u548c\u8054\u5408\u8bad\u7ec3\u7b97\u6cd5\uff0c\u4f7f\u7528\u6765\u81ea \\(ImageNet\\) \u76849000\u591a\u4e2a\u7c7b\u4ee5\u53ca \\(COCO\\) \u7684\u68c0\u6d4b\u6570\u636e\u6765\u8bad\u7ec3\u6a21\u578b\u3002 \u6211\u4eec\u6240\u6709\u4ee3\u7801\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u90fd\u53ef\u5728\u7ebf\u83b7\u5f97\uff1ahttp://pjreddie.com/yolo9000/\u3002","title":"1.\u5f15\u8a00"},{"location":"thesis_interpretation/02_yolo.html#2","text":"\u4e0e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\uff0c \\(YOLO\\) \u5b58\u5728\u5404\u79cd\u7f3a\u70b9\u3002 \\(YOLO\\) \u4e0e \\(Fast \\ R-CNN\\) \u7684\u8bef\u5dee\u6bd4\u8f83\u5206\u6790\u8868\u660e\uff0c \\(YOLO\\) \u4ea7\u751f\u4e86\u5927\u91cf\u7684\u5b9a\u4f4d\u9519\u8bef\u3002\u6b64\u5916\uff0c\u4e0e\u751f\u6210\u5019\u9009\u533a\u57df\u65b9\u6cd5\u76f8\u6bd4\uff0c \\(YOLO\\) \u53ec\u56de\u7387( recall )\u76f8\u5bf9\u8f83\u4f4e\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u4e3b\u8981\u5173\u6ce8\u6539\u5584\u53ec\u56de\u7387\u548c\u5b9a\u4f4d\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u7c7b\u51c6\u786e\u6027\u3002 \u2003\u8ba1\u7b97\u673a\u89c6\u89c9\u901a\u5e38\u8d8b\u5411\u4e8e\u66f4\u5927\u66f4\u6df1\u7684\u7f51\u7edc[6] [18] [17]\u3002 \u66f4\u597d\u7684\u6027\u80fd\u901a\u5e38\u53d6\u51b3\u4e8e\u8bad\u7ec3\u66f4\u5927\u7684\u7f51\u7edc\u6216\u5c06\u591a\u4e2a\u6a21\u578b\u7ec4\u5408\u5728\u4e00\u8d77\u3002 \u4f46\u662f\uff0c\u5bf9\u4e8e \\(YOLOv2\\) \uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u66f4\u7cbe\u786e\u7684\u68c0\u6d4b\u5668\uff0c\u800c\u4e14\u4fdd\u6301\u5f88\u5feb\u7684\u901f\u5ea6\u3002 \u6211\u4eec\u4e0d\u662f\u8981\u6269\u5927\u7f51\u7edc\uff0c\u800c\u662f\u7b80\u5316\u7f51\u7edc\uff0c\u7136\u540e\u8ba9\u8868\u5f81( \u5373\u76ee\u6807\u7279\u5f81 )\u66f4\u6613\u4e8e\u5b66\u4e60\u3002 \u6211\u4eec\u5c06\u4ee5\u5f80\u5de5\u4f5c\u4e2d\u7684\u5404\u79cd\u521b\u610f\u4e0e\u6211\u4eec\u81ea\u5df1\u65b0\u9896\u7684\u65b9\u6cd5\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u63d0\u9ad8 \\(YOLO\\) \u7684\u6027\u80fd\u3002 \u7ed3\u679c\u6c47\u603b\u89c1 \u88682\u3002 \u2003 \u6279\u91cf\u6807\u51c6\u5316 \uff08Batch Normalization\uff09\u3002\u6279\u91cf\u6807\u51c6\u5316\u53ef\u4ee5\u663e\u7740\u6539\u5584\u6536\u655b\u6027\uff0c\u800c\u4e14\u4e0d\u518d\u9700\u8981\u5176\u4ed6\u5f62\u5f0f\u7684\u6b63\u5219\u5316[7]\u3002 \u901a\u8fc7\u5728 \\(YOLO\\) \u4e2d\u7684\u6240\u6709\u5377\u79ef\u5c42\u4e0a\u6dfb\u52a0\u6279\u91cf\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u5728 \\(mAP\\) \u4e2d\u83b7\u5f97 2\uff05\u4ee5\u4e0a\u7684\u6539\u8fdb\u3002 \u6279\u91cf\u6807\u51c6\u5316\u4e5f\u6709\u52a9\u4e8e\u89c4\u8303\u6a21\u578b\u3002 \u901a\u8fc7\u6279\u91cf\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u4ece\u6a21\u578b\u4e2d\u5220\u9664 \\(dropout\\) \u800c\u4e0d\u4f1a\u53d1\u751f\u8fc7\u62df\u5408\u3002 \u2003 \u9ad8\u5206\u8fa8\u7387\u5206\u7c7b\u5668 \uff08High Resolution Classifier\uff09\u3002\u6240\u6709\u7684\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u65b9\u6cd5\u90fd\u4f7f\u7528\u5728 \\(ImageNet\\) \u4e0a\u9884\u5148\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668[16]\u3002 \u4eceAlexNet\u5f00\u59cb\uff0c\u5927\u591a\u6570\u5206\u7c7b\u5668\u7528\u5c0f\u4e8e \\(256\u00d7256\\) \u7684\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165[8]\u3002 \u6700\u521d\u7684 \\(YOLO\\) \u4ee5 \\(224\u00d7224\\) \u7684\u56fe\u50cf\u8bad\u7ec3\u5206\u7c7b\u5668\u7f51\u7edc\uff0c\u5e76\u5c06\u5206\u8fa8\u7387\u63d0\u9ad8\u5230 \\(448\\) \u4ee5\u8fdb\u884c\u68c0\u6d4b\u8bad\u7ec3\u3002 \u8fd9\u610f\u5473\u7740\u7f51\u7edc\u5fc5\u987b\u5207\u6362\u5230\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u4e60\uff0c\u540c\u65f6\u80fd\u8c03\u6574\u5230\u65b0\u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002 \u2003\u5bf9\u4e8e \\(YOLOv2\\) \uff0c\u6211\u4eec\u9996\u5148\u4ee5 \\(448\u00d7448\\) \u7684\u5168\u5206\u8fa8\u7387\u5728 \\(ImageNet\\) \u4e0a\u8fdb\u884c \\(10\\) \u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u5fae\u8c03\u3002\u8fd9\u7ed9\u4e88\u7f51\u7edc\u4e00\u4e9b\u65f6\u95f4\uff0c\u4ee5\u8c03\u6574\u5176\u6ee4\u6ce2\u5668\u6765\u66f4\u597d\u5730\u5904\u7406\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8f93\u5165\u3002\u7136\u540e\uff0c\u6211\u4eec\u518d\u5bf9\u8be5\u68c0\u6d4b\u7f51\u7edc\u8fdb\u884c\u5fae\u8c03\u3002 \u8fd9\u4e2a\u9ad8\u5206\u8fa8\u7387\u7684\u5206\u7c7b\u7f51\u7edc\u4f7f \\(mAP\\) \u589e\u52a0\u4e86\u8fd14\uff05\u3002 \u2003 \u5377\u79ef\u4e0e\u951a\u6846 \u3002 \\(YOLO\\) \u76f4\u63a5\u4f7f\u7528\u5377\u79ef\u7279\u5f81\u63d0\u53d6\u5668\u9876\u90e8\u7684\u5168\u8fde\u63a5\u5c42\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u7684\u5750\u6807\u3002\u800c \\(Fast \\ R-CNN\\) \u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5750\u6807\uff0c\u662f\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684\u5148\u9a8c\u6765\u9884\u6d4b\u8fb9\u754c\u6846[15]\u3002\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5750\u6807 \\(Fast \\ R-CNN\\) \u9884\u6d4b\u8fb9\u754c\u6846\u4f7f\u7528\u624b\u5de5\u6311\u9009\u7684\u5148\u9a8c\u533a\u57df[15]\u3002 Faster R-CNN\u4e2d\u7684\u5019\u9009\u533a\u57df\u751f\u6210\u7f51\u7edc\uff08RPN\uff09\u4ec5\u4f7f\u7528\u5377\u79ef\u5c42\u6765\u9884\u6d4b\u951a\u6846\u7684\u504f\u79fb\u548c\u7f6e\u4fe1\u5ea6\u3002\u7531\u4e8e\u9884\u6d4b\u5c42\u662f\u5377\u79ef\u7684\uff0c\u6240\u4ee5RPN\u53ef\u4ee5\u5728\u7279\u5f81\u56fe\u4e2d\u7684\u6bcf\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u8fd9\u4e9b\u504f\u79fb\u3002\u4f7f\u7528\u9884\u6d4b\u504f\u79fb\u4ee3\u66ff\u5750\u6807\uff0c\u53ef\u4ee5\u7b80\u5316\u95ee\u9898\u5e76\u4f7f\u7f51\u7edc\u66f4\u6613\u4e8e\u5b66\u4e60\u3002 \u2003\u6211\u4eec\u4ece \\(YOLO\\) \u4e2d\u79fb\u9664\u5168\u8fde\u63a5\u5c42\uff0c\u5e76\u4f7f\u7528\u951a\u6846\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u3002 \u9996\u5148\u6211\u4eec\u6d88\u9664\u4e00\u4e2a\u6c60\u5316\u5c42\uff0c\u4ee5\u4f7f\u7f51\u7edc\u5377\u79ef\u5c42\u7684\u8f93\u51fa\u5177\u6709\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u3002 \u6211\u4eec\u8fd8\u7f29\u5c0f\u7f51\u7edc\uff0c\u4f7f\u5176\u5728\u5206\u8fa8\u7387\u4e3a \\(416X416\\) \u7684\u8f93\u5165\u56fe\u50cf\u4e0a\u8fd0\u884c\uff0c\u800c\u4e0d\u662f \\(448\u00d7448\\) \u3002\u6211\u4eec\u8fd9\u6837\u505a\u662f\u56e0\u4e3a\u6211\u4eec\u60f3\u8981\u5728\u7279\u5f81\u56fe\u4e2d\u6709\u5947\u6570\u4e2a\u4f4d\u7f6e\uff0c\u4ece\u800c\u6709\u4e00\u4e2a\u5355\u4e00\u7684\u4e2d\u5fc3\u5355\u5143\u683c\u3002\u76ee\u6807\uff0c\u5c24\u5176\u662f\u5927\u7684\u76ee\u6807\uff0c\u5f80\u5f80\u5360\u636e\u56fe\u50cf\u7684\u4e2d\u5fc3\uff0c\u6240\u4ee5\u6700\u597d\u5728\u6b63\u4e2d\u5fc3\u62e5\u6709\u5355\u72ec\u4e00\u4e2a\u4f4d\u7f6e\u6765\u9884\u6d4b\u8fd9\u4e9b\u76ee\u6807\uff0c\u800c\u4e0d\u662f\u5728\u4e2d\u5fc3\u9644\u8fd1\u7684\u56db\u4e2a\u4f4d\u7f6e\u3002 \\(YOLO\\) \u7684\u5377\u79ef\u5c42\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e86 \\(32\\) \u500d\u7684\u91c7\u6837\uff0c\u6240\u4ee5\u901a\u8fc7\u4f7f\u7528 \\(416\\) \u7684\u8f93\u5165\u56fe\u50cf\uff0c\u6211\u4eec\u5f97\u5230 \\(13\u00d713\\) \u7684\u8f93\u51fa\u7279\u5f81\u56fe\u3002 \u2003\u5f53\u6211\u4eec\u79fb\u52a8\u5230\u951a\u6846\u65f6\uff0c\u6211\u4eec\u5c06\u7c7b\u9884\u6d4b\u673a\u5236\u4e0e\u7a7a\u95f4\u4f4d\u7f6e\u5206\u5f00\u5904\u7406\uff0c\u5355\u72ec\u9884\u6d4b\u6bcf\u4e2a\u951a\u6846\u7684\u7c7b\u53ca\u5176\u76ee\u6807\u3002 \u9075\u5faa\u539f\u6765\u7684 \\(YOLO\\) \u7684\u505a\u6cd5\uff0c\u76ee\u6807\u9884\u6d4b\u4f9d\u7136\u9884\u6d4b\u4e86\u771f\u5b9e\u6807\u7b7e\u6846\uff08ground truth box\uff09\u548c\u5019\u9009\u6846\u7684 \\(IOU\\) \uff0c\u800c\u7c7b\u522b\u9884\u6d4b\u4e5f\u662f\u9884\u6d4b\u4e86\u5f53\u6709\u76ee\u6807\u5b58\u5728\u65f6\uff0c\u8be5\u7c7b\u522b\u7684\u6761\u4ef6\u6982\u7387\u3002 \u2003\u4f7f\u7528\u951a\u6846\uff0c\u7cbe\u5ea6\u503c\u4f1a\u5c0f\u5e45\u4e0b\u964d\u3002\u56e0\u4e3a\u539f\u59cb\u7684 \\(YOLO\\) \u4ec5\u4e3a\u6bcf\u4e2a\u56fe\u7247\u9884\u6d4b98\u4e2a\u6846\uff0c\u4f46\u4f7f\u7528\u951a\u6846\u540e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u9884\u6d4b\u7684\u6846\u6570\u8d85\u8fc7 1000 \u4e2a\u3002 \u5728\u6ca1\u6709\u951a\u6846\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u7684\u4e2d\u7b49\u6a21\u578b\u5c06\u83b7\u5f97 69.5 \u7684 \\(mAP\\) \uff0c\u53ec\u56de\u7387\u4e3a81\uff05\u3002 \u4f7f\u7528\u951a\u6846\u540e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u83b7\u5f97\u4e86 \\(69.2\\) \u7684 \\(mAP\\) \uff0c\u53ec\u56de\u7387\u4e3a88\uff05\u3002\u5c3d\u7ba1 \\(mAP\\) \u51cf\u5c11\uff0c\u4f46\u53ec\u56de\u7387\u7684\u589e\u52a0\u610f\u5473\u7740\u6211\u4eec\u7684\u6a21\u578b\u6709\u66f4\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002 \u56fe2\uff1a \\(VOC\\) \u548c \\(COCO\\) \u4e0a\u7684\u805a\u7c7b\u6846\u5c3a\u5bf8\u3002\u6211\u4eec\u5728\u8fb9\u754c\u6846\u7684\u7ef4\u4e0a\u8fd0\u884c \\(k-means\\) \u805a\u7c7b\uff0c\u4ee5\u83b7\u5f97\u6211\u4eec\u6a21\u578b\u7684\u826f\u597d\u5148\u9a8c\u3002\u5de6\u56fe\u663e\u793a\u4e86\u6211\u4eec\u901a\u8fc7k\u7684\u5404\u79cd\u9009\u62e9\u83b7\u5f97\u7684\u5e73\u5747 \\(IOU\\) \u3002\u6211\u4eec\u53d1\u73b0 \\(k = 5\\) \u4e3a\u53ec\u56de\u4e0e\u6a21\u578b\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6298\u4e2d\u3002\u53f3\u56fe\u663e\u793a\u4e86 \\(VOC\\) \u548c \\(COCO\\) \u7684\u76f8\u5bf9\u8d28\u5fc3\u3002\u8fd9\u4e24\u79cd\u65b9\u6848\u90fd\u559c\u6b22\u66f4\u8584\uff0c\u66f4\u9ad8\u7684\u6846\uff0c\u5e76\u4e14 \\(COCO\\) \u7684\u5c3a\u5bf8\u7684\u53d8\u5316\u6bd4 \\(VOC\\) \u66f4\u5927\u3002 \\(k-means\\) \u7b97\u6cd5: \\(K-means\\) \u7b97\u6cd5\u662f\u5f88\u5178\u578b\u7684\u57fa\u4e8e\u8ddd\u79bb\u7684\u805a\u7c7b\u7b97\u6cd5\uff0c\u91c7\u7528\u8ddd\u79bb\u4f5c\u4e3a\u76f8\u4f3c\u6027\u7684\u8bc4\u4ef7\u6307\u6807\uff0c\u5373\u8ba4\u4e3a\u4e24\u4e2a\u5bf9\u8c61\u7684\u8ddd\u79bb\u8d8a\u8fd1\uff0c\u5176\u76f8\u4f3c\u5ea6\u5c31\u8d8a\u5927\u3002\u8be5\u7b97\u6cd5\u8ba4\u4e3a\u7c07\u662f\u7531\u8ddd\u79bb\u9760\u8fd1\u7684\u5bf9\u8c61\u7ec4\u6210\u7684\uff0c\u56e0\u6b64\u628a\u5f97\u5230\u7d27\u51d1\u4e14\u72ec\u7acb\u7684\u7c07\u4f5c\u4e3a\u6700\u7ec8\u76ee\u6807\u3002 \u2003 \u7ef4\u5ea6\u805a\u7c7b \uff08Dimension Clusters\uff09\u3002\u5f53\u628a\u951a\u6846\u4e0eYOLO\u4e00\u8d77\u4f7f\u7528\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u4e24\u4e2a\u95ee\u9898\u3002 \u9996\u5148\u662f\u6846\u7684\u5c3a\u5bf8\u662f\u624b\u5de5\u6311\u9009\u7684\u3002\u867d\u7136\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u9002\u5f53\u5730\u8c03\u6574\u65b9\u6846\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u4ece\u4e00\u5f00\u59cb\u5c31\u4e3a\u7f51\u7edc\u9009\u62e9\u66f4\u597d\u7684\u5148\u9a8c\u6846\uff0c\u5c31\u53ef\u4ee5\u8ba9\u7f51\u7edc\u66f4\u5bb9\u6613\u5b66\u4e60\u5230\u66f4\u597d\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u2003\u6211\u4eec\u4e0d\u7528\u624b\u5de5\u9009\u62e9\u5148\u9a8c\u6846\uff0c\u800c\u662f\u5728\u8bad\u7ec3\u96c6\u7684\u8fb9\u754c\u6846\u4e0a\u8fd0\u884ck-means\u805a\u7c7b\uff0c\u81ea\u52a8\u627e\u5230\u826f\u597d\u7684\u5148\u9a8c\u6846\u3002 \u5982\u679c\u6211\u4eec\u4f7f\u7528\u5177\u6709\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u6807\u51c6 \\(k-means\\) \uff0c\u90a3\u4e48\u8f83\u5927\u7684\u6846\u6bd4\u8f83\u5c0f\u7684\u6846\u4ea7\u751f\u66f4\u591a\u7684\u8bef\u5dee\u3002 \u7136\u800c\uff0c\u6211\u4eec\u771f\u6b63\u60f3\u8981\u7684\u662f\u72ec\u7acb\u4e8e\u6846\u7684\u5927\u5c0f\u7684\uff0c\u80fd\u83b7\u5f97\u826f\u597d\u7684 \\(IOU\\) \u5206\u6570\u7684\u5148\u9a8c\u6846\u3002 \u56e0\u6b64\u5bf9\u4e8e\u8ddd\u79bb\u5ea6\u91cf\u6211\u4eec\u4f7f\u7528: \\(d(\\text { box, centroid }) = 1-\\operatorname{IOU}(\\text { box }, \\text { centroid })\\) \u2003\u6211\u4eec\u7528\u4e0d\u540c\u7684 \\(k\\) \u503c\u8fd0\u884c \\(k-means\\) \uff0c\u5e76\u7ed8\u5236\u6700\u63a5\u8fd1\u8d28\u5fc3\u7684\u5e73\u5747 \\(IOU\\) \uff08\u89c1\u56fe2\uff09\u3002\u4e3a\u4e86\u5728\u6a21\u578b\u590d\u6742\u5ea6\u548c\u9ad8\u53ec\u56de\u7387\u4e4b\u95f4\u7684\u826f\u597d\u6298\u8877\uff0c\u6211\u4eec\u9009\u62e9 \\(k = 5\\) \u3002\u805a\u7c7b\u7684\u8d28\u5fc3\u4e0e\u624b\u5de5\u9009\u53d6\u7684\u951a\u6846\u663e\u7740\u4e0d\u540c\uff0c\u5b83\u6709\u66f4\u5c11\u7684\u77ed\u4e14\u5bbd\u7684\u6846\uff0c\u800c\u4e14\u6709\u66f4\u591a\u65e2\u957f\u53c8\u7a84\u7684\u6846\u3002 \u2003\u88681\u4e2d\uff0c\u6211\u4eec\u5c06\u805a\u7c7b\u7b56\u7565\u7684\u5148\u9a8c\u6846\u4e2d\u5fc3\u6570\u548c\u624b\u5de5\u9009\u53d6\u7684\u951a\u6846\u6570\u5728\u6700\u63a5\u8fd1\u7684\u5e73\u5747 \\(IOU\\) \u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002\u4ec55\u4e2a\u5148\u9a8c\u6846\u4e2d\u5fc3\u7684\u5e73\u5747 \\(IOU\\) \u4e3a61.0\uff0c\u5176\u6027\u80fd\u7c7b\u4f3c\u4e8e9\u4e2a\u951a\u6846\u768460.9\u3002 \u4f7f\u75289\u4e2a\u8d28\u5fc3\u4f1a\u5f97\u5230\u66f4\u9ad8\u7684\u5e73\u5747 \\(IOU\\) \u3002\u8fd9\u8868\u660e\u4f7f\u7528 \\(k-means\\) \u751f\u6210\u8fb9\u754c\u6846\u53ef\u4ee5\u66f4\u597d\u5730\u8868\u793a\u6a21\u578b\u5e76\u4f7f\u5176\u66f4\u5bb9\u6613\u5b66\u4e60\u3002 \\(\\begin{array}{lcc} \\text { Box Generation } & \\# & \\text { Avg IOU } \\\\ \\hline \\text { Cluster SSE } & 5 & 58.7 \\\\ \\text { Cluster IOU } & 5 & 61.0 \\\\ \\text { Anchor Boxes [15] } & 9 & 60.9 \\\\ \\text { Cluster IOU } & 9 & 67.2 \\end{array}\\) \u88681\uff1a \\(VOC \\ 2007\\) \u6700\u63a5\u8fd1\u5148\u9a8c\u7684\u6846\u7684\u5e73\u5747 \\(IOU\\) \u3002 \\(VOC \\ 2007\\) \u4e0a\u7684\u76ee\u6807\u7684\u5e73\u5747IOU\u4e0e\u5176\u6700\u63a5\u8fd1\u7684\uff0c\u672a\u7ecf\u4fee\u6539\u7684\u4f7f\u7528\u4e0d\u540c\u751f\u6210\u65b9\u6cd5\u7684\u76ee\u6807\u4e4b\u95f4\u7684\u5e73\u5747 \\(IOU\\) \u3002\u805a\u7c7b\u5f97\u7ed3\u679c\u6bd4\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684\u5148\u9a8c\u6846\u7ed3\u679c\u8981\u597d\u5f97\u591a\u3002 \u2003 \u76f4\u63a5\u4f4d\u7f6e\u9884\u6d4b \uff08Direct location prediction\uff09\u3002\u5f53\u5728 \\(YOLO\\) \u4e2d\u4f7f\u7528\u951a\u6846\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff1a\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u5c24\u5176\u662f\u5728\u65e9\u671f\u8fed\u4ee3\u7684\u8fc7\u7a0b\u4e2d\u3002 \u5927\u591a\u6570\u4e0d\u7a33\u5b9a\u6765\u81ea\u4e8e\u9884\u6d4b\u6846\u7684 \\((x,y)\\) \u4f4d\u7f6e\u3002 \u5728\u5019\u9009\u533a\u57df\u7f51\u7edc\u4e2d\uff0c\u7f51\u7edc\u9884\u6d4b\u7684 \\(t_x,t_y\\) \uff0c\u548c\u4e2d\u5fc3\u5750\u6807 \\((x,y)\\) \u8ba1\u7b97\u5982\u4e0b\uff1a \\(\\huge\\begin{array}{l} x=\\left(t_{x} * w_{a}\\right)-x_{a} \\\\ y=\\left(t_{y} * h_{a}\\right)-y_{a} \\end{array}\\) \u2003\u4f8b\u5982\uff0c\u9884\u6d4b \\(t_x = 1\\) \u4f1a\u4f7f\u8be5\u6846\u5411\u53f3\u79fb\u52a8\u951a\u6846\u7684\u5bbd\u5ea6\uff0c\u800c\u9884\u6d4b \\(t_x = -1\\) \u4f1a\u5c06\u5176\u5411\u5de6\u79fb\u52a8\u76f8\u540c\u7684\u5bbd\u5ea6\u3002 \u2003\u8fd9\u4e2a\u516c\u5f0f\u662f\u4e0d\u53d7\u7ea6\u675f\u7684\uff0c\u6240\u4ee5\u4efb\u4f55\u951a\u6846\u90fd\u53ef\u4ee5\u5728\u56fe\u50cf\u4e2d\u7684\u4efb\u4f55\u4e00\u70b9\u7ed3\u675f\uff0c\u800c\u4e0d\u7ba1\u951a\u6846\u662f\u5728\u54ea\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u7684\u3002\u968f\u673a\u521d\u59cb\u5316\u6a21\u578b\u9700\u8981\u5f88\u957f\u65f6\u95f4\u624d\u80fd\u7a33\u5b9a\u5230\u9884\u6d4b\u5408\u7406\u7684\u504f\u79fb\u91cf\u3002 \u2003\u6211\u4eec\u6ca1\u6709\u9884\u6d4b\u504f\u79fb\uff0c\u800c\u662f\u9075\u5faa \\(YOLO\\) \u7684\u65b9\u6cd5\uff0c\u9884\u6d4b\u76f8\u5bf9\u4e8e\u7f51\u683c\u5355\u5143\u4f4d\u7f6e\u7684\u4f4d\u7f6e\u5750\u6807\u3002\u8fd9\u4f7f\u5f97\u771f\u5b9e\u503c\u7684\u754c\u9650\u57280\u52301\u4e4b\u95f4\u3002\u6211\u4eec\u4f7f\u7528\u903b\u8f91\u6fc0\u6d3b\u6765\u9650\u5236\u7f51\u7edc\u7684\u9884\u6d4b\u843d\u5728\u8fd9\u4e2a\u8303\u56f4\u5185\u3002 \u2003\u7f51\u7edc\u4e3a\u7279\u5f81\u56fe\u7684\u8f93\u51fa\u7684\u6bcf\u4e2a\u5355\u5143\u9884\u6d4b5\u4e2a\u8fb9\u754c\u6846\u3002\u7f51\u7edc\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u76845\u4e2a\u5750\u6807 \\(t_x,t_y,t_w,t_h\u548ct_o\\) \u3002\u5982\u679c\u5355\u5143\u683c\u4ece\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u504f\u79fb\u4e86,\u5e76\u4e14\u4e4b\u524d\u7684\u8fb9\u754c\u6846\u5177\u6709\u5bbd\u5ea6\u548c\u9ad8\u5ea6 \\(p_w,p_h\\) \u5219\u9884\u6d4b\u5bf9\u5e94\u4e8e\uff1a \\(\\begin{aligned} b_{x} &=\\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} &=\\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} &=p_{w} e^{t_{w}} \\\\ b_{h} &=p_{h} e^{t_{h}} \\\\ \\operatorname{Pr}(\\text { object }) * \\operatorname{IOU}(b, \\text { object }) &=\\sigma\\left(t_{o}\\right) \\end{aligned}\\) \u2003\u7531\u4e8e\u6211\u4eec\u9650\u5236\u4e86\u4f4d\u7f6e\u9884\u6d4b\uff0c\u4f7f\u5f97\u53c2\u6570\u5316\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u66f4\u52a0\u7a33\u5b9a\u3002\u4f7f\u7528\u7ef4\u5ea6\u96c6\u7fa4\u4ee5\u53ca\u76f4\u63a5\u9884\u6d4b\u8fb9\u754c\u6846\u4e2d\u5fc3\u4f4d\u7f6e\uff0c\u53ef\u4ee5\u4f7f \\(YOLO\\) \u6bd4\u951a\u6846\u7684\u7248\u672c\u63d0\u9ad8\u8fd15\uff05\u3002 \u56fe3\uff1a\u5177\u6709\u7ef4\u5ea6\u5148\u9a8c\u548c\u4f4d\u7f6e\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u3002\u6211\u4eec\u9884\u6d4b\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4f5c\u4e3a\u805a\u7c7b\u8d28\u5fc3\u7684\u504f\u79fb\u91cf\u3002\u6211\u4eec\u4f7f\u7528sigmoid\u51fd\u6570\u9884\u6d4b\u76f8\u5bf9\u4e8e\u6ee4\u6ce2\u5668\u5e94\u7528\u4f4d\u7f6e\u7684\u6846\u7684\u4e2d\u5fc3\u5750\u6807\u3002 \u2003 \u7ec6\u7c92\u5ea6\u529f\u80fd \uff08Fine-Grained Features\uff09\u3002\u4fee\u6539\u540e\u7684YOLO\u5728 \\(13\u00d713\\) \u7279\u5f81\u56fe\u4e0a\u9884\u6d4b\u68c0\u6d4b\u7ed3\u679c\u3002 \u867d\u7136\u8fd9\u5bf9\u4e8e\u5927\u578b\u7269\u4f53\u662f\u8db3\u591f\u7684\uff0c\u4f46\u4f7f\u7528\u66f4\u7ec6\u7c92\u5ea6\u7279\u5f81\u5bf9\u5b9a\u4f4d\u8f83\u5c0f\u7269\u4f53\u6709\u597d\u5904\u3002Faster R-CNN\u548cSSD\u90fd\u5728\u7f51\u7edc\u4e2d\u7684\u5404\u79cd\u7279\u5f81\u56fe\u4e0a\u8fd0\u884c\u7f51\u7edc\uff0c\u4ee5\u83b7\u5f97\u591a\u4e2a\u5206\u8fa8\u7387\u3002 \u6211\u4eec\u91c7\u53d6\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u53ea\u9700\u6dfb\u52a0\u4e00\u4e2a\u76f4\u901a\u5c42\uff0c\u4ee5 \\(26\u00d726\\) \u7684\u5206\u8fa8\u7387\u4ece\u8f83\u65e9\u7684\u5c42\u4e2d\u63d0\u53d6\u7279\u5f81\u3002 \u2003\u76f4\u901a\u5c42\u5c06\u9ad8\u5206\u8fa8\u7387\u7279\u5f81\u4e0e\u4f4e\u5206\u8fa8\u7387\u7279\u5f81\u8fde\u63a5\u8d77\u6765\uff0c\u5c06\u76f8\u90bb\u7279\u5f81\u53e0\u52a0\u5230\u4e0d\u540c\u7684\u901a\u9053\u4e2d\uff0c\u800c\u4e0d\u662f\u7a7a\u95f4\u4f4d\u7f6e\u4e0a\uff0c\u7c7b\u4f3c\u4e8e \\(ResNet\\) \u4e2d\u7684\u6052\u7b49\u6620\u5c04\u3002\u5c06 \\(26\u00d726\u00d7512\\) \u7684\u7279\u5f81\u56fe\u53d8\u4e3a \\(13\u00d713\u00d72048\\) \u7684\u7279\u5f81\u56fe\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u4e0e\u539f\u6765\u7684\u7279\u5f81\u8fde\u63a5\u3002\u6211\u4eec\u7684\u68c0\u6d4b\u5668\u8fd0\u884c\u5728\u8fd9\u5f20\u6269\u5c55\u7684\u7279\u5f81\u56fe\u7684\u9876\u90e8\uff0c\u4ee5\u4fbf\u5b83\u53ef\u4ee5\u8bbf\u95ee\u7ec6\u7c92\u5ea6\u7684\u529f\u80fd\u3002\u8fd9\u4f7f\u6027\u80fd\u63d0\u9ad8\u4e861\uff05\u3002 \u2003 \u591a\u5c3a\u5ea6\u8bad\u7ec3 \uff08Multi-Scale Training\uff09\u3002\u539f\u6765\u7684 \\(YOLO\\) \u4f7f\u7528 \\(448\u00d7448\\) \u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002\u901a\u8fc7\u6dfb\u52a0\u951a\u6846\uff0c\u6211\u4eec\u5c06\u5206\u8fa8\u7387\u66f4\u6539\u4e3a \\(416\u00d7416\\) \u3002\u4f46\u662f\uff0c\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u4ec5\u4f7f\u7528\u5377\u79ef\u5c42\u548c\u6c60\u5316\u5c42\uff0c\u56e0\u6b64\u53ef\u4ee5\u5b9e\u65f6\u8c03\u6574\u5927\u5c0f\u3002\u6211\u4eec\u5e0c\u671b \\(YOLOv2\\) \u80fd\u591f\u5728\u4e0d\u540c\u5c3a\u5bf8\u7684\u56fe\u50cf\u4e0a\u8fd0\u884c\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u591a\u5c3a\u5ea6\u8bad\u7ec3\u5e94\u5230\u6a21\u578b\u4e2d\u3002 \u2003\u6211\u4eec\u4e0d\u9700\u8981\u4fee\u6539\u8f93\u5165\u56fe\u50cf\u5927\u5c0f\uff0c\u800c\u662f\u6bcf\u9694\u51e0\u6b21\u8fed\u4ee3\u5c31\u6539\u53d8\u4e00\u6b21\u7f51\u7edc\u3002\u6bcf \\(10\\) \u4e2a\u6279\u6b21\u6211\u4eec\u7684\u7f51\u7edc\u4f1a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u65b0\u7684\u56fe\u50cf\u5c3a\u5bf8\u5927\u5c0f\u3002\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u7f29\u51cf\u4e86 \\(32\\) \u500d\uff0c\u6240\u4ee5\u6211\u4eec\u4ece \\(32\\) \u7684\u500d\u6570\u4e2d\u62bd\u53d6\uff1a \\({320,352\uff0c\u2026\uff0c608}\\) \u3002\u56e0\u6b64\uff0c\u6700\u5c0f\u7684\u9009\u9879\u662f \\(320\u00d7320\\) \uff0c\u6700\u5927\u7684\u662f \\(608\u00d7608\\) \u3002\u6211\u4eec\u8c03\u6574\u7f51\u7edc\u7684\u5c3a\u5bf8\u5230\u90a3\u4e2a\u7ef4\u5ea6\u5e76\u7ee7\u7eed\u8bad\u7ec3\u3002 \u2003\u8fd9\u4e2a\u673a\u5236\u8feb\u4f7f\u7f51\u7edc\u5b66\u4e60\u5982\u4f55\u5728\u5404\u79cd\u8f93\u5165\u7ef4\u5ea6\u4e0a\u505a\u597d\u9884\u6d4b\u3002\u8fd9\u610f\u5473\u7740\u540c\u4e00\u4e2a\u7f51\u7edc\u53ef\u4ee5\u9884\u6d4b\u4e0d\u540c\u5206\u8fa8\u7387\u4e0b\u7684\u68c0\u6d4b\u7ed3\u679c\u3002\u7f51\u7edc\u5728\u8f83\u5c0f\u7684\u5c3a\u5bf8\u4e0b\u8fd0\u884c\u901f\u5ea6\u66f4\u5feb\uff0c\u56e0\u6b64 \\(YOLOv2\\) \u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u677e\u7684\u6298\u4e2d\u3002 \u2003 \u5728\u4f4e\u5206\u8fa8\u7387\u4e0b\uff0c \\(YOLOv2\\) \u4f5c\u4e3a\u4e00\u79cd\u4fbf\u5b9c\u4f46\u76f8\u5f53\u51c6\u786e\u7684\u68c0\u6d4b\u5668\u5de5\u4f5c\u3002 \u5728 \\(288\u00d7288\\) \u60c5\u51b5\u4e0b\uff0c\u5b83\u7684\u8fd0\u884c\u901f\u5ea6\u8d85\u8fc7 90 FPS\uff0c\u800c \\(mAP\\) \u51e0\u4e4e\u4e0e \\(Fast \\ R-CNN\\) \u4e00\u6837\u597d\u3002\u8fd9\u4f7f\u5176\u6210\u4e3a\u5c0f\u578b \\(GPU\\) \uff0c\u9ad8\u5e27\u7387\u89c6\u9891\u6216\u591a\u89c6\u9891\u6d41\u7684\u7406\u60f3\u9009\u62e9\u3002 \u2003\u5728\u9ad8\u5206\u8fa8\u7387\u4e0b\uff0c \\(YOLOv2\\) \u662f\u4e00\u6b3e\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5728VOC2007\u4e0a\u83b7\u5f97\u4e8678.6\u7684 \\(mAP\\) \uff0c\u540c\u65f6\u4ecd\u4ee5\u9ad8\u4e8e\u5b9e\u65f6\u901f\u5ea6\u8fd0\u884c\u3002\u8bf7\u53c2\u9605\u88683\uff0c\u4e86\u89e3 \\(YOLOv2\\) \u4e0e\u5176\u4ed6\u6846\u67b6\u5728 \\(VOC \\ 2007\\) \u4e0a\u7684\u6bd4\u8f83 \u56fe4\u3002 \u56fe4\uff1a \\(VOC \\ 2007\\) \u4e0a\u7684\u7cbe\u5ea6\u548c\u901f\u5ea6 \u2003 \u8fdb\u4e00\u6b65\u7684\u5b9e\u9a8c \uff08Further Experiments\uff09\u3002 \u6211\u4eec\u5728 \\(VOC \\ 2012\\) \u4e0a\u8bad\u7ec3\u4e86 \\(YOLOv2\\) \u8fdb\u884c\u68c0\u6d4b\u3002\u88684 \u663e\u793a\u4e86 \\(YOLOv2\\) \u4e0e\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u7684\u6027\u80fd\u6bd4\u8f83\u3002 \\(YOLOv2\\) \u8fd0\u884c\u901f\u5ea6\u8fdc\u9ad8\u4e8e\u5bf9\u624b\uff0c\u4e14\u7cbe\u5ea6\u8fbe\u5230 73.4 \\(mAP\\) \u3002 \u6211\u4eec\u8fd8\u5728 \\(COCO\\) \u4e0a\u8bad\u7ec3\uff0c\u5e76\u4e0e\u88685\u4e2d\u7684\u5176\u4ed6\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002\u4f7f\u7528 \\(VOC\\) \u5ea6\u91cf\uff08 \\(IOU = 0.5\\) \uff09\uff0c \\(YOLOv2\\) \u83b7\u5f9744.0 \\(mAP\\) \uff0c\u4e0e \\(SSD\\) \u548c \\(Faster \\ R-CNN\\) \u76f8\u5f53\u3002 \\(\\begin{array}{lrrr} \\text { Detection Frameworks } & \\text { Train } & \\text { mAP } & \\text { FPS } \\\\ \\hline \\text { Fast R-CNN [5] } & 2007+2012 & 70.0 & 0.5 \\\\ \\text { Faster R-CNN VGG-16[15] } & 2007+2012 & 73.2 & 7 \\\\ \\text { Faster R-CNN ResNet[6] } & 2007+2012 & 76.4 & 5 \\\\ \\text { YOLO [14] } & 2007+2012 & 63.4 & 45 \\\\ \\text { SSD300 [11] } & 2007+2012 & 74.3 & 46 \\\\ \\text { SSD500 [11] } & 2007+2012 & 76.8 & 19 \\\\ \\hline \\text { YOLOv2 288 } \\times 288 & 2007+2012 & 69.0 & 91 \\\\ \\text { YOLOv2 352 } \\times 352 & 2007+2012 & 73.7 & 81 \\\\ \\text { YOLOv2 416 } \\times 416 & 2007+2012 & 76.8 & 67 \\\\ \\text { YOLOv2 480 } \\times 480 & 2007+2012 & 77.8 & 59 \\\\ \\text { YOLOv2 } 544 \\times 544 & 2007+2012 & \\mathbf{7 8 . 6} & 40 \\end{array}\\) \u88683\uff1a \\(PA S C A L \\ VOC \\ 2007\\) \u7684\u68c0\u6d4b\u6846\u67b6\u3002 \\(YOLOv2\\) \u6bd4\u4ee5\u524d\u7684\u68c0\u6d4b\u65b9\u6cd5\u66f4\u5feb\uff0c\u66f4\u51c6\u786e\u3002\u5b83\u4e5f\u53ef\u4ee5\u4ee5\u4e0d\u540c\u7684\u5206\u8fa8\u7387\u8fd0\u884c\uff0c\u4ee5\u4fbf\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u8f7b\u677e\u6298\u8877\u3002\u6bcf\u4e2a \\(YOLOv2\\) \u9879\u5b9e\u9645\u4e0a\u90fd\u662f\u5177\u6709\u76f8\u540c\u6743\u91cd\u7684\u76f8\u540c\u8bad\u7ec3\u6a21\u578b\uff0c\u53ea\u662f\u4ee5\u4e0d\u540c\u7684\u5927\u5c0f\u8fdb\u884c\u8bc4\u4f30\u3002\u6240\u6709\u7684\u65f6\u95f4\u7684\u6d4b\u8bd5\u90fd\u8fd0\u884c\u5728Geforce GTX Titan X\uff08\u539f\u59cb\u7684\uff0c\u800c\u4e0d\u662fPascal\u6a21\u578b\uff09","title":"2.\u66f4\u597d"},{"location":"thesis_interpretation/02_yolo.html#3","text":"\u6211\u4eec\u5e0c\u671b\u68c0\u6d4b\u7ed3\u679c\u51c6\u786e\uff0c\u4f46\u6211\u4eec\u4e5f\u5e0c\u671b\u68c0\u6d4b\u901f\u5ea6\u66f4\u5feb\u3002 \u5927\u591a\u6570\u7528\u4e8e\u68c0\u6d4b\u7684\u5e94\u7528\u7a0b\u5e8f\uff08\u5982\u673a\u5668\u4eba\u6216\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff09\u90fd\u4f9d\u8d56\u4e8e\u4f4e\u5ef6\u8fdf\u9884\u6d4b\u3002 \u4e3a\u4e86\u6700\u5927\u9650\u5ea6\u5730\u63d0\u9ad8\u6027\u80fd\uff0c\u6211\u4eec\u5c06 \\(YOLOv2\\) \u8bbe\u8ba1\u4ece\u5934\u5230\u5c3e\u90fd\u975e\u5e38\u5feb \u3002 \u88682\uff1a\u4ece \\(YOLO\\) \u5230 \\(YOLOv2\\) \u7684\u8def\u5f84\u3002\u5927\u591a\u6570\u5217\u51fa\u7684\u8bbe\u8ba1\u51b3\u7b56\u90fd\u4f1a\u5bfc\u81f4 \\(MAP\\) \u663e\u7740\u589e\u52a0\u3002\u6709\u4e24\u4e2a\u4f8b\u5916\u60c5\u51b5\u662f\uff1a\u5207\u6362\u5230\u5e26\u6709\u951a\u6846\u7684\u5168\u5377\u79ef\u7f51\u7edc\u548c\u4f7f\u7528\u65b0\u7f51\u7edc\u3002\u5207\u6362\u5230\u951a\u6846\u65b9\u6cd5\u589e\u52a0\u53ec\u56de\u7387\uff0c\u800c\u4e0d\u6539\u53d8 \\(mAP\\) \uff0c\u800c\u4f7f\u7528\u65b0\u7f51\u7edc\u524a\u51cf33\uff05\u7684\u8ba1\u7b97\u3002 \u88684\uff1aPASCAL VOC2012\u6d4b\u8bd5\u68c0\u6d4b\u7ed3\u679c\u3002 \\(YOLOv2\\) \u4e0e\u91c7\u7528ResNet\u548cSSD512\u7684Faster R-CNN\u7b49\u5148\u8fdb\u68c0\u6d4b\u5668\u6027\u80fd\u76f8\u5f53\uff0c\u901f\u5ea6\u63d0\u9ad82\u81f310\u500d\u3002 \u2003\u5927\u591a\u6570\u68c0\u6d4b\u6846\u67b6\u4f9d\u8d56\u4e8eVGG-16\u4f5c\u4e3a\u57fa\u672c\u7279\u5f81\u63d0\u53d6\u5668[17]\u3002 \\(VGG-16\\) \u662f\u4e00\u4e2a\u529f\u80fd\u5f3a\u5927\uff0c\u51c6\u786e\u7684\u5206\u7c7b\u7f51\u7edc\uff0c\u4f46\u5b83\u6709\u4e0d\u5fc5\u8981\u7684\u590d\u6742\u5ea6\u3002 \\(VGG-16\\) \u7684\u5377\u79ef\u5c42\u5728\u4e00\u4e2a \\(224\u00d7224\\) \u5206\u8fa8\u7387\u5355\u4e2a\u56fe\u50cf\u4e0a\u8fd0\u884c\u4e00\u6b21\u9700\u8981 \\(306.90\\) \u4ebf\u6d6e\u70b9\u8fd0\u7b97\u3002 \u2003 \\(YOLO\\) \u6846\u67b6\u4f7f\u7528\u57fa\u4e8e \\(Googlenet\\) \u67b6\u6784\u7684\u81ea\u5b9a\u4e49\u7f51\u7edc[19]\u3002\u8fd9\u4e2a\u7f51\u7edc\u6bd4 \\(VGG-16\\) \u66f4\u5feb\uff0c\u4e00\u6b21\u524d\u5411\u4f20\u64ad\u53ea\u8981 \\(85.2\\) \u4ebf\u6b21\u8fd0\u884c\u3002\u7136\u800c\uff0c\u5b83\u7684\u51c6\u786e\u6027\u7565\u4f4e\u4e8e \\(VGG-16\\) \u3002\u5728 \\(ImageNet\\) \u4e0a\uff0c\u7528 \\(224\u00d7224\\) \u7684\u5355\u5f20\u88c1\u526a\u56fe\u50cf\uff0c \\(YOLO\\) \u7684\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u7cbe\u5ea6\u4e3a88.0\uff05\u800c \\(VGG-16\\) \u5219\u4e3a90.0\uff05\u3002 \u2003 \\(Darknet-19\\) \u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5206\u7c7b\u6a21\u578b\u4f5c\u4e3a \\(YOLOv2\\) \u7684\u57fa\u7840\u3002\u6211\u4eec\u7684\u6a21\u578b\u5efa\u7acb\u5728\u7f51\u7edc\u8bbe\u8ba1\u7684\u5148\u524d\u5de5\u4f5c\u4ee5\u53ca\u8be5\u9886\u57df\u7684\u5e38\u8bc6\u4e0a\u3002\u4e0e \\(VGG\\) \u6a21\u578b\u7c7b\u4f3c\uff0c\u6211\u4eec\u5927\u591a\u4f7f\u7528 \\(3\u00d73\\) \u6ee4\u6ce2\u5668\uff0c\u5e76\u4e14\u5728\u6c60\u5316\u5c42\u6b65\u9aa4\u540e\u4f7f\u7528\u4e24\u500d\u7684\u901a\u9053\u6570[17]\u3002\u6309\u7167Network in Network\uff08NIN\uff09\u7684\u65b9\u6cd5\uff0c\u6211\u4eec\u4f7f\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u6765\u505a\u9884\u6d4b\uff0c\u5e76\u4f7f\u75281\u00d71\u6ee4\u6ce2\u5668\u6765\u538b\u7f293\u00d73\u5377\u79ef\u7684\u7279\u5f81\u8868\u793a[9]\u3002\u6211\u4eec\u4f7f\u7528\u6279\u91cf\u5f52\u4e00\u5316\u6765\u7a33\u5b9a\u8bad\u7ec3\uff0c\u52a0\u901f\u6536\u655b\uff0c\u5e76\u89c4\u8303\u6a21\u578b[7]\u3002 \u2003\u6700\u7ec8\u7684\u6a21\u578b\u53eb\u505aDarknet-19\uff0c\u5b83\u670919\u4e2a\u5377\u79ef\u5c42\u548c5\u4e2aMaxpool\u5c42\u3002 \\(Darknet-19\\) \u53ea\u9700\u898155.8\u4ebf\u6b21\u64cd\u4f5c\u6765\u5904\u7406\u56fe\u50cf\uff0c\u4f46\u5728 \\(ImageNet\\) \u4e0a\u5b9e\u73b0\u4e8672.9\uff05\u7684top-1\u7cbe\u5ea6\u548c91.2\uff05\u7684top-5\u7cbe\u5ea6\u3002 \u2003 \u5206\u7c7b\u8bad\u7ec3 \uff08Training for classification\uff09\u3002\u6211\u4eec\u4f7f\u7528 \\(DarkNet\\) \u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u4f7f\u7528\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0c\u521d\u59cb\u5b66\u4e60\u7387\u4e3a0.1\uff0c\u591a\u9879\u5f0f\u901f\u7387\u8870\u51cf\u4e3a4\uff0c\u6743\u91cd\u8870\u51cf\u4e3a0.0005\uff0c\u52a8\u91cf\u4e3a0.9\uff0c\u5728\u6807\u51c6 \\(ImageNet\\) 1000\u7c7b\u522b\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u5bf9\u7f51\u7edc\u8fdb\u884c160\u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u8bad\u7ec3[13]\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u6807\u51c6\u6570\u636e\u589e\u5f3a\u6280\u5de7\uff0c\u5305\u62ec\u968f\u673a\u622a\u53d6\uff0c\u65cb\u8f6c\u548c\u6539\u53d8\u8272\u76f8\uff0c\u9971\u548c\u5ea6\u548c\u66dd\u5149\u3002 \u2003 \u5982\u4e0a\u6240\u8ff0\uff0c\u5728\u6211\u4eec\u5bf9 \\(224\u00d7224\\) \u56fe\u50cf\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3\u4e4b\u540e\uff0c\u6211\u4eec\u7528\u66f4\u5927\u7684\u5206\u8fa8\u7387448\u5bf9\u7f51\u7edc\u8fdb\u884c\u4e86\u5fae\u8c03\u3002\u5fae\u8c03\u65f6\uff0c\u6211\u4eec\u4f7f\u7528\u4e0a\u8ff0\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u4ec5\u752810\u4e2a\u5468\u671f\uff0c\u5e76\u4e14\u5f00\u59cb\u65f6\u7684\u5b66\u4e60\u7387\u4e3a10-3\u3002\u5728\u8fd9\u4e2a\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u4e0b\uff0c\u6211\u4eec\u7684\u7f51\u7edc\u5b9e\u73b0\u4e8676.5\uff05\u7684 \\(top-1\\) \u7cbe\u5ea6\u548c93.3\uff05\u7684 \\(top-5\\) \u7cbe\u5ea6\u3002 \u2003 \u68c0\u6d4b\u8bad\u7ec3 \uff08Training for detection\uff09\u3002\u6211\u4eec\u8fd9\u6837\u4fee\u6539\u7f51\u7edc\uff1a\u53bb\u9664\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u53d6\u800c\u4ee3\u4e4b\u7684\u662f\u6dfb\u52a0\u4e09\u4e2a \\(3 \u00d7 3\\) \u7684\u5377\u79ef\u5c42\uff0c\u6bcf\u4e2a\u5c42\u6709 \\(1024\\) \u4e2a\u8fc7\u6ee4\u5668\uff0c\u7136\u540e\u5728\u6700\u540e\u6dfb\u52a0 \\(1\u00d71\\) \u5377\u79ef\u5c42\uff0c\u8be5\u5c42\u7684\u6ee4\u6ce2\u5668\u6570\u91cf\u662f\u68c0\u6d4b\u9700\u8981\u7684\u8f93\u51fa\u6570\u91cf\u3002 \u5bf9\u4e8e \\(VOC\\) \uff0c\u6211\u4eec\u9884\u6d4b \\(05\\) \u4e2a\u8fb9\u754c\u6846\uff0c\u6bcf\u4e2a\u8fb9\u754c\u6846\u6709 5\u4e2a\u5750\u6807\u548c20\u4e2a\u7c7b\u522b\uff0c\u6240\u4ee5\u6709125\u4e2a\u6ee4\u6ce2\u5668\u3002\u6211\u4eec\u8fd8\u6dfb\u52a0\u4e86\u4ece\u6700\u540e\u7684 \\(3\u00d73\u00d7512\\) \u5c42\u5230\u5012\u6570\u7b2c\u4e8c\u5c42\u5377\u79ef\u5c42\u7684\u76f4\u901a\u5c42\uff0c\u4ee5\u4fbf\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u4f7f\u7528\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002 \u2003\u6211\u4eec\u8bad\u7ec3\u7f51\u7edc160\u4e2a\u8fed\u4ee3\u5468\u671f\uff0c\u521d\u59cb\u5b66\u4e60\u7387\u4e3a \\(10^{-3}\\) \uff0c\u572860\u548c90\u5468\u671f\u540c\u65f6\u9664\u4ee510\u3002\u6211\u4eec\u4f7f\u7528 \\(0.0005\\) \u7684\u6743\u503c\u8870\u51cf\u548c 0.9 \u7684\u52a8\u91cf( momentum )\u3002\u6211\u4eec\u5bf9 \\(YOLO\\) \u548c \\(SSD\\) \u8fdb\u884c\u7c7b\u4f3c\u7684\u6570\u636e\u589e\u5f3a\uff0c\u968f\u673a\u88c1\u526a\uff0c\u8272\u5f69\u4fee\u6539\u7b49\u3002\u6211\u4eec\u5728 \\(COCO\\) \u548c \\(VOC\\) \u4f7f\u7528\u76f8\u540c\u7684\u8bad\u7ec3\u7b56\u7565\u3002 \\(\\begin{array}{l|c|cccc|ccc|ccc|ccc} & & 0.5: 0.95 & 0.5 & 0.75 & \\mathrm{~S} & \\mathrm{M} & \\mathrm{L} & 1 & 10 & 100 & \\mathrm{~S} & \\mathrm{M} & \\mathrm{L} \\\\ \\hline \\text { Fast R-CNN [5] } & \\text { train } & 19.7 & 35.9 & - & - & - & - & - & - & - & - & - & - \\\\ \\text { Fast R-CNN[1] } & \\text { train } & 20.5 & 39.9 & 19.4 & 4.1 & 20.0 & 35.8 & 21.3 & 29.5 & 30.1 & 7.3 & 32.1 & 52 .0 \\\\ \\text { Faster R-CNN[15] } & \\text { trainval } & 21.9 & 42.7 & - & - & - & - & - & - & - & - & - & - \\\\ \\text { ION [1] } & \\text { train } & 23.6 & 43.2 & 23.6 & 6.4 & 24.1 & 38.3 & 23.2 & 32.7 & 33.5 & 10.1 & 37.7 & 53.6 \\\\ \\text { Faster R-CNN[10] } & \\text { trainval } & 24.2 & 45.3 & 23.5 & 7.7 & 26.4 & 37.1 & 23.8 & 34.0 & 34.6 & 12.0 & 38.5 & 54.4 \\\\ \\text { SSD300 [11] } & \\text { trainval35k } & 23.2 & 41.2 & 23.4 & 5.3 & 23.2 & 39.6 & 22.5 & 33.2 & 35.3 & 9.6 & 37.6 & 56.5 \\\\ \\text { SSD512 [11] } & \\text { trainval35k } & \\mathbf{26.8} & \\mathbf{4 6 . 5} & \\mathbf{2 7 . 8} & \\mathbf{9 . 0} & \\mathbf{2 8 . 9} & 41.9 & \\mathbf{2 4 . 8} & 37.5 & \\mathbf{3 9 . 8} & \\mathbf{1 4 . 0} & 43.5 & 59.0 \\\\ \\hline \\text { YOLOv2 [11] } & \\text { trainval35k } & 21.6 & 44.0 & 19.2 & 5.0 & 22.4 & 35.5 & 20.7 & 31.6 & 33.3 & 9.8 & 36.5 & 54 .4 \\end{array}\\) \u88685\uff1a \\(COCO\\) test-dev\u96c6\u4e0a\u7684\u7ed3\u679c\uff0c\u6765\u6e90\u4e8e\u8bba\u6587[11]","title":"3.\u66f4\u5feb"},{"location":"thesis_interpretation/02_yolo.html#4","text":"\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u5408\u8bad\u7ec3\u5206\u7c7b\u548c\u68c0\u6d4b\u6570\u636e\u7684\u673a\u5236\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u4e86\u7528\u4e8e\u68c0\u6d4b\u7684\u56fe\u50cf\u6765\u5b66\u4e60\u68c0\u6d4b\u7279\u5b9a\u4fe1\u606f\uff0c\u5982\u8fb9\u754c\u6846\u5750\u6807\u9884\u6d4b\u548c\u76ee\u6807\u4ee5\u53ca\u5982\u4f55\u5bf9\u5e38\u89c1\u76ee\u6807\u8fdb\u884c\u5206\u7c7b\u3002\u901a\u8fc7\u4f7f\u7528\u4ec5\u5177\u6709\u7c7b\u6807\u7b7e\u7684\u56fe\u50cf\u6765\u6269\u5c55\u5176\u53ef\u68c0\u6d4b\u7c7b\u522b\u7684\u6570\u91cf\u3002 \u2003\u5728\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u6df7\u5408\u6765\u81ea\u68c0\u6d4b\u548c\u5206\u7c7b\u6570\u636e\u96c6\u7684\u56fe\u50cf\u3002 \u5f53\u6211\u4eec\u7684\u7f51\u7edc\u770b\u5230\u6807\u8bb0\u4e3a\u68c0\u6d4b\u7684\u56fe\u50cf\u65f6\uff0c\u53ef\u4ee5\u6839\u636e\u5b8c\u6574\u7684 \\(YOLOv2\\) \u635f\u5931\u51fd\u6570\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3002 \u5f53\u5b83\u770b\u5230\u5206\u7c7b\u56fe\u50cf\u65f6\uff0c\u53ea\u4f1a\u53cd\u5411\u4f20\u64ad\u5206\u7c7b\u90e8\u5206\u7684\u635f\u5931\u3002 \\(\\begin{array}{l|c|c|c} \\text { Type } & \\text { Filters } & \\text { Size/Stride } & \\text { Output } \\\\ \\hline \\text { Convolutional } & 32 & 3 \\times 3 & 224 \\times 224 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 112 \\times 112 \\\\ \\text { Convolutional } & 64 & 3 \\times 3 & 112 \\times 112 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 56 \\times 56 \\\\ \\text { Convolutional } & 128 & 3 \\times 3 & 56 \\times 56 \\\\ \\text { Convolutional } & 64 & 1 \\times 1 & 56 \\times 56 \\\\ \\text { Convolutional } & 128 & 3 \\times 3 & 56 \\times 56 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 28 \\times 28 \\\\ \\text { Convolutional } & 256 & 3 \\times 3 & 28 \\times 28 \\\\ \\text { Convolutional } & 128 & 1 \\times 1 & 28 \\times 28 \\\\ \\text { Convolutional } & 256 & 3 \\times 3 & 28 \\times 28 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Convolutional } & 256 & 1 \\times 1 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Convolutional } & 256 & 1 \\times 1 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\text { Convolutional } & 512 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\text { Convolutional } & 512 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\hline \\hline \\text { Convolutional } & 1000 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Avgpool } & & \\text { Global } & 1000 \\\\ \\text { Softmax } & & & \\end{array}\\) \u88686\uff1aDarknet-19 \u2003\u8fd9\u79cd\u65b9\u6cd5\u5e26\u6765\u4e86\u4e00\u4e9b\u96be\u9898\u3002\u68c0\u6d4b\u6570\u636e\u96c6\u53ea\u6709\u5e38\u7528\u7684\u76ee\u6807\u548c\u901a\u7528\u7684\u6807\u7b7e\uff0c\u5982\u201c\u72d7\u201d\u6216\u201c\u8239\u201d\u3002\u5206\u7c7b\u6570\u636e\u96c6\u5177\u6709\u66f4\u5e7f\u6cdb\u548c\u66f4\u6df1\u5165\u7684\u6807\u7b7e\u8303\u56f4\u3002 \\(ImageNet\\) \u62e5\u6709\u591a\u79cd\u72ac\u79cd\uff0c\u5305\u62ecNorfolk terrier\uff0cYorkshire terrier\u548cBedlington terrier\u3002\u5982\u679c\u6211\u4eec\u60f3\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5219\u9700\u8981\u91c7\u7528\u4e00\u81f4\u7684\u65b9\u5f0f\u6765\u5408\u5e76\u8fd9\u4e9b\u6807\u7b7e\u3002 \u2003\u5927\u591a\u6570\u5206\u7c7b\u65b9\u6cd5\u4f7f\u7528\u6db5\u76d6\u6240\u6709\u53ef\u80fd\u7c7b\u522b\u7684 \\(softmax\\) \u5c42\u6765\u8ba1\u7b97\u6700\u7ec8\u6982\u7387\u5206\u5e03\u3002\u4f7f\u7528 \\(softmax\\) \uff0c\u610f\u5473\u7740\u7c7b\u662f\u76f8\u4e92\u6392\u65a5\u7684\u3002\u8fd9\u7ed9\u7ec4\u5408\u6570\u636e\u96c6\u5e26\u6765\u4e86\u95ee\u9898\uff0c\u4f8b\u5982\uff0c\u4f60\u4e0d\u80fd\u7528\u8fd9\u4e2a\u6a21\u578b\u6765\u7ec4\u5408 \\(ImageNet\\) \u548c \\(COCO\\) \uff0c\u56e0\u4e3a\u7c7b\u522b \\(Norfolk \\ terrier\u548cdog\\) \u4e0d\u662f\u4e92\u65a5\u7684\u3002 \u2003\u76f8\u53cd\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u591a\u6807\u7b7e\u6a21\u578b\u6765\u7ec4\u5408\u4e0d\u4f1a\u4e92\u76f8\u6392\u65a5\u7684\u6570\u636e\u96c6\u3002\u8fd9\u4e2a\u65b9\u6cd5\u5ffd\u7565\u4e86\u6211\u4eec\u6240\u77e5\u9053\u7684\u5173\u4e8e\u6570\u636e\u7684\u6240\u6709\u7ed3\u6784\uff0c\u4f8b\u5982\u6240\u6709\u7684 \\(COCO\\) \u7c7b\u90fd\u662f\u76f8\u4e92\u72ec\u7acb\u7684\u3002 \u2003 \u5206\u5c42\u5206\u7c7b \uff08Hierarchical classification\uff09\u3002 \\(ImageNet\\) \u6807\u7b7e\u662f\u4ece \\(WordNet\\) \u4e2d\u63d0\u53d6\u7684\uff0c \\(WordNet\\) \u662f\u4e00\u4e2a\u6784\u5efa\u6982\u5ff5\u53ca\u5176\u76f8\u4e92\u5173\u7cfb\u7684\u8bed\u8a00\u6570\u636e\u5e93[12]\u3002 Norfolk terrier\u548cYorkshire terrier\u90fd\u662fterrier\u7684\u4e0b\u4e49\u8bcd\uff0cterrier\u662f\u4e00\u79cdhunting dog\uff0chunting dog\u662fdog\uff0cdog\u662fcanine\u7b49\u3002\u5927\u591a\u6570\u5206\u7c7b\u7684\u65b9\u6cd5\u5047\u8bbe\u6807\u7b7e\u662f\u4e00\u4e2a\u6241\u5e73\u7ed3\u6784\uff0c\u4f46\u662f\u5bf9\u4e8e\u7ec4\u5408\u6570\u636e\u96c6\uff0c\u7ed3\u6784\u6b63\u662f\u6211\u4eec\u6240\u9700\u8981\u7684\u3002 \u2003 \\(WordNet\\) \u7684\u7ed3\u6784\u662f\u6709\u5411\u56fe\uff0c\u800c\u4e0d\u662f\u6811\uff0c\u56e0\u4e3a\u8bed\u8a00\u5f88\u590d\u6742\u3002 \u4f8b\u5982\uff0c\u201c\u72d7\u201d\u65e2\u662f\u4e00\u79cd\u201c\u72ac\u201d\u53c8\u662f\u4e00\u79cd\u201c\u5bb6\u517b\u52a8\u7269\u201d\uff0c\u5b83\u4eec\u90fd\u662f \\(WordNet\\) \u4e2d\u7684\u540c\u4e49\u8bcd\u3002 \u6211\u4eec\u4e0d\u4f7f\u7528\u5b8c\u6574\u7684\u56fe\u7ed3\u6784\uff0c\u800c\u662f\u901a\u8fc7\u4ece \\(ImageNet\\) \u4e2d\u7684\u6982\u5ff5\u6784\u5efa\u5206\u5c42\u6811\u6765\u7b80\u5316\u95ee\u9898\u3002 \u2003WordNet\u7684\u7ed3\u6784\u662f\u6709\u5411\u56fe\uff0c\u800c\u4e0d\u662f\u6811\uff0c\u56e0\u4e3a\u8bed\u8a00\u5f88\u590d\u6742\u3002\u4f8b\u5982\uff0c\u4e00\u53ea\u72d7\u65e2\u662f\u4e00\u79cd\u72ac\u79d1\u52a8\u7269\uff0c\u53c8\u662f\u4e00\u79cd\u5bb6\u517b\u52a8\u7269\uff0c\u5b83\u4eec\u90fd\u662fWordNet\u4e2d\u7684\u540c\u79cd\u52a8\u7269\u3002\u6211\u4eec\u6ca1\u6709\u4f7f\u7528\u5b8c\u6574\u7684\u56fe\u7ed3\u6784\uff0c\u800c\u662f\u901a\u8fc7\u4ece \\(ImageNet\\) \u4e2d\u7684\u6982\u5ff5\u6784\u5efa\u5206\u5c42\u6811\u6765\u7b80\u5316\u95ee\u9898\u3002 \u2003\u4e3a\u4e86\u6784\u5efa\u8fd9\u68f5\u6811\uff0c\u6211\u4eec\u68c0\u67e5 \\(ImageNet\\) \u4e2d\u7684\u89c6\u89c9\u540d\u8bcd\uff0c\u5e76\u67e5\u770b\u5b83\u4eec\u901a\u8fc7 \\(WordNet\\) \u56fe\u5230\u6839\u8282\u70b9\u7684\u8def\u5f84\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u662f\u201c\u7269\u7406\u76ee\u6807\u201d\u3002 \u8bb8\u591a\u540c\u4e49\u8bcd\u53ea\u6709\u5728\u56fe\u4e0a\u4e00\u6761\u8def\u5f84\uff0c\u6240\u4ee5\u9996\u5148\u6211\u4eec\u5c06\u6240\u6709\u8fd9\u4e9b\u8def\u5f84\u6dfb\u52a0\u5230\u6211\u4eec\u7684\u6811\u4e2d\u3002 \u7136\u540e\uff0c\u6211\u4eec\u53cd\u590d\u68c0\u67e5\u6211\u4eec\u7559\u4e0b\u7684\u6982\u5ff5\uff0c\u5e76\u5c3d\u53ef\u80fd\u5c11\u5730\u6dfb\u52a0\u751f\u6210\u6811\u7684\u8def\u5f84\u3002 \u6240\u4ee5\u5982\u679c\u4e00\u4e2a\u6982\u5ff5\u6709\u4e24\u6761\u901a\u5411\u6839\u7684\u8def\u5f84\uff0c\u4e00\u6761\u8def\u5f84\u4f1a\u4e3a\u6211\u4eec\u7684\u6811\u589e\u52a0\u4e09\u6761\u8fb9\uff0c\u53e6\u4e00\u6761\u8def\u53ea\u589e\u52a0\u4e00\u6761\u8fb9\uff0c\u6211\u4eec\u9009\u62e9\u8f83\u77ed\u7684\u8def\u5f84\u3002 \u2003 \u6700\u7ec8\u7684\u7ed3\u679c\u662f \\(WordTree\\) \uff0c\u4e00\u4e2a\u89c6\u89c9\u6982\u5ff5\u7684\u5206\u5c42\u6a21\u578b\u3002\u4e3a\u4e86\u4f7f\u7528 \\(WordTree\\) \u8fdb\u884c\u5206\u7c7b\uff0c\u6211\u4eec\u9884\u6d4b\u6bcf\u4e2a\u8282\u70b9\u7684\u6761\u4ef6\u6982\u7387\uff0c\u4ee5\u5f97\u5230\u540c\u4e49\u8bcd\u96c6\u5408\u4e2d\u6bcf\u4e2a\u540c\u4e49\u8bcd\u4e0b\u4e49\u8bcd\u7684\u6982\u7387\u3002\u4f8b\u5982\uff0c\u5728terrier\u8282\u70b9\u6211\u4eec\u9884\u6d4b\uff1a \\(\\large\\operatorname{Pr} (Norfolk \\ terrier|terrier) \\\\ \\operatorname{Pr} (Yorkshire \\ terrier|terrier) \\\\ \\operatorname{Pr}( Bedlington \\ terrier|terrier )\\) \u2003\u5982\u679c\u6211\u4eec\u60f3\u8981\u8ba1\u7b97\u4e00\u4e2a\u7279\u5b9a\u8282\u70b9\u7684\u7edd\u5bf9\u6982\u7387\uff0c\u6211\u4eec\u53ea\u9700\u6cbf\u7740\u901a\u8fc7\u6811\u5230\u8fbe\u6839\u8282\u70b9\u7684\u8def\u5f84\uff0c\u518d\u4e58\u4ee5\u6761\u4ef6\u6982\u7387\u3002\u6240\u4ee5\u5982\u679c\u6211\u4eec\u60f3\u77e5\u9053\u4e00\u5f20\u56fe\u7247\u662f\u5426\u662fNorfolk terrier\uff0c\u6211\u4eec\u8ba1\u7b97\uff1a \\(\\operatorname{Pr}(\\text { Norfolk terrier }) = \\operatorname{Pr}(\\text { Norfolk terrier } \\mid \\text { terrier })\\) \\(\\quad * \\operatorname{Pr}(\\text { terrier } \\mid \\text { hunting dog })\\) \\(* \\ldots * \\\\\\) \\(* \\operatorname{Pr}(\\text { mammal } \\mid \\operatorname{Pr}(\\text { animal })\\) \\(* \\operatorname{Pr}(\\text { animal } \\mid \\text { physical object })\\) \u2003\u4e3a\u4e86\u5b9e\u73b0\u5206\u7c7b\uff0c\u6211\u4eec\u5047\u5b9a\u56fe\u50cf\u5305\u542b\u4e00\u4e2a\u76ee\u6807\uff1a \\(P r(physical object) = 1\\) \u3002 \u2003\u4e3a\u4e86\u9a8c\u8bc1\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u5728\u4f7f\u75281000\u7c7b \\(ImageNet\\) \u6784\u5efa\u7684 \\(WordTree\\) \u4e0a\u8bad\u7ec3 \\(Darknet-19\\) \u6a21\u578b\u3002 \u4e3a\u4e86\u6784\u5efa \\(WordTree1k\\) \uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u6240\u6709\u4e2d\u95f4\u8282\u70b9\uff0c\u5c06\u6807\u7b7e\u7a7a\u95f4\u4ece \\(1000\\) \u6269\u5c55\u5230 \\(1369\\) \u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u6211\u4eec\u5c06\u771f\u5b9e\u6807\u7b7e\u5411\u6811\u4e0a\u9762\u4f20\u64ad\uff0c\u4ee5\u4fbf\u5982\u679c\u56fe\u50cf\u88ab\u6807\u8bb0\u4e3aNorfolk terrier\uff0c\u5219\u5b83\u4e5f\u88ab\u6807\u8bb0\u4e3adog\u548cmamal\u7b49\u3002\u4e3a\u4e86\u8ba1\u7b97\u6761\u4ef6\u6982\u7387\uff0c\u6211\u4eec\u7684\u6a21\u578b\u9884\u6d4b\u4e861369\u4e2a\u503c\u7684\u5411\u91cf\uff0c\u5e76\u4e14\u6211\u4eec\u8ba1\u7b97\u4e86\u76f8\u540c\u6982\u5ff5\u7684\u4e0b\u4e49\u8bcd\u5728\u6240\u6709\u540c\u4e49\u8bcd\u96c6\u4e0a\u7684softmax\uff0c\u89c1\u56fe5\u3002 \u2003\u4f7f\u7528\u4e0e\u4ee5\u524d\u76f8\u540c\u7684\u8bad\u7ec3\u53c2\u6570\uff0c\u6211\u4eec\u7684\u5206\u5c42Darknet-19\u8fbe\u5230\u4e8671.9\uff05\u7684 \\(top-1\\) \u7cbe\u5ea6\u548c90.4\uff05\u7684 \\(top-5\\) \u7cbe\u5ea6\u3002 \u5c3d\u7ba1\u589e\u52a0\u4e86369\u4e2a\u9644\u52a0\u6982\u5ff5\uff0c\u5e76\u4e14\u8ba9\u6211\u4eec\u7684\u7f51\u7edc\u9884\u6d4b\u4e86\u6811\u72b6\u7ed3\u6784\uff0c\u4f46\u6211\u4eec\u7684\u7cbe\u5ea6\u4ec5\u7565\u6709\u4e0b\u964d\u3002 \u4ee5\u8fd9\u79cd\u65b9\u5f0f\u8fdb\u884c\u5206\u7c7b\u4e5f\u6709\u82e5\u5e72\u597d\u5904\u3002 \u5728\u65b0\u7684\u6216\u672a\u77e5\u7684\u76ee\u6807\u7c7b\u522b\u4e0a\uff0c\u6027\u80fd\u4f1a\u4f18\u96c5\u4f4e\u964d\u4f4e\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u7f51\u7edc\u770b\u5230\u4e00\u5f20\u72d7\u7684\u7167\u7247\uff0c\u4f46\u4e0d\u786e\u5b9a\u5b83\u662f\u4ec0\u4e48\u7c7b\u578b\u7684\u72d7\uff0c\u5b83\u4ecd\u7136\u4f1a\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u201cdog\u201d\uff0c\u53ea\u662f\u5728\u4e0b\u4e49\u8bcd\u4f1a\u6709\u8f83\u4f4e\u7684\u7f6e\u4fe1\u5ea6\u3002 \u2003\u8be5\u65b9\u6cd5\u4e5f\u9002\u7528\u4e8e\u68c0\u6d4b\u3002\u73b0\u5728\uff0c\u6211\u4eec\u4e0d\u7528\u5047\u5b9a\u6bcf\u4e2a\u56fe\u50cf\u90fd\u6709\u4e00\u4e2a\u76ee\u6807\u7269\u4f53\uff0c\u800c\u662f\u4f7f\u7528 \\(YOLOv2\\) \u7684\u76ee\u6807\u9884\u6d4b\u5668\u7ed9\u51faP r\uff08\u76ee\u6807\u7269\u4f53\uff09\u7684\u503c\u3002\u68c0\u6d4b\u5668\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u6982\u7387\u6811\u3002\u6211\u4eec\u904d\u5386\u6811\uff0c\u5728\u6bcf\u6b21\u5206\u5272\u4e2d\u9009\u53d6\u5177\u6709\u6700\u9ad8\u7684\u7f6e\u4fe1\u5ea6\u7684\u8def\u5f84\uff0c\u76f4\u5230\u8fbe\u5230\u67d0\u4e2a\u9608\u503c\uff0c\u7136\u540e\u6211\u4eec\u5f97\u5230\u8be5\u76ee\u6807\u7684\u7c7b\u522b\u3002 \u2003 \u6570\u636e\u96c6\u4e0e \\(WordTree\\) \u7684\u7ec4\u5408 (Dataset combination with WordTree)\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \\(WordTree\\) \u4ee5\u53ef\u884c\u7684\u65b9\u5f0f\u5c06\u591a\u4e2a\u6570\u636e\u96c6\u7ec4\u5408\u5728\u4e00\u8d77\u3002\u6211\u4eec\u53ea\u9700\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u6620\u5c04\u5230\u6811\u4e2d\u7684synsets\u5373\u53ef\u3002\u56fe6\u663e\u793a\u4e86\u4e00\u4e2a\u4f7f\u7528 \\(WordTree\\) \u7ec4\u5408\u6765\u81ea \\(ImageNet\\) \u548c \\(COCO\\) \u7684\u6807\u7b7e\u7684\u793a\u4f8b\u3002 WordNet\u975e\u5e38\u591a\u6837\u5316\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u8fd9\u79cd\u6280\u672f\u7528\u4e8e\u5927\u591a\u6570\u6570\u636e\u96c6\u3002 \u56fe5\uff1a\u5bf9 \\(ImageNet\\) \u4e0e \\(WordTree\\) \u7684\u9884\u6d4b\u3002\u5927\u591a\u6570ImaNet\u6a21\u578b\u4f7f\u7528\u4e00\u4e2a\u5927\u7684softmax\u6765\u9884\u6d4b\u6982\u7387\u5206\u5e03\u3002\u4f7f\u7528 \\(WordTree\\) \uff0c\u6211\u4eec\u901a\u8fc7\u5171\u540c\u7684\u4e0b\u4f4d\u8bcd\u6267\u884c\u591a\u4e2asoftmax\u64cd\u4f5c\u3002 \u2003 \u8054\u5408\u5206\u7c7b\u548c\u68c0\u6d4b (Joint classification and detection)\u3002\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \\(WordTree\\) \u7ec4\u5408\u6570\u636e\u96c6\uff0c\u5728\u5206\u7c7b\u548c\u68c0\u6d4b\u4e0a\u8bad\u7ec3\u8054\u5408\u6a21\u578b\u3002\u6211\u4eec\u60f3\u8981\u8bad\u7ec3\u4e00\u4e2a\u975e\u5e38\u5927\u89c4\u6a21\u7684\u68c0\u6d4b\u5668\uff0c\u6240\u4ee5\u4f7f\u7528 \\(COCO\\) \u68c0\u6d4b\u6570\u636e\u96c6\u548c\u5b8c\u6574 \\(ImageNet\\) \u7248\u672c\u4e2d\u7684\u524d9000\u7c7b\u521b\u5efa\u6211\u4eec\u7684\u7ec4\u5408\u6570\u636e\u96c6\u3002\u6211\u4eec\u8fd8\u9700\u8981\u8bc4\u4f30\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u4ee5\u4fbf\u4ece \\(ImageNet\\) \u68c0\u6d4b\u6311\u6218\u4e2d\u6dfb\u52a0\u4efb\u4f55\u5c1a\u672a\u5305\u542b\u7684\u7c7b\u3002\u8be5\u6570\u636e\u96c6\u7684\u76f8\u5e94 \\(WordTree\\) \u5177\u67099418\u4e2a\u7c7b\u3002 \\(ImageNet\\) \u6709\u66f4\u5927\u7684\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u901a\u8fc7\u5bf9 \\(COCO\\) \u8fdb\u884c\u8fc7\u91c7\u6837\u6765\u5e73\u8861\u6570\u636e\u96c6\uff0c\u4f7f\u5f97 \\(ImageNet\\) \u4e0e \\(COCO\\) \u7684\u6bd4\u4f8b\u7565\u5927\u4e8e \\(4:1\\) \u3002 \u2003\u6211\u4eec\u4f7f\u7528\u4e0a\u8ff0\u7684\u6570\u636e\u96c6\u8bad\u7ec3 \\(YOLO9000\\) \u3002 \u6211\u4eec\u4f7f\u7528\u57fa\u672c\u7684 \\(YOLOv2\\) \u67b6\u6784\uff0c\u4f46\u53ea\u67093\u4e2a\u5148\u9a8c\u6846\u800c\u4e0d\u662f5\u4e2a\u6765\u9650\u5236\u8f93\u51fa\u5927\u5c0f\u3002\u5f53\u6211\u4eec\u7684\u7f51\u7edc\u5904\u7406\u68c0\u6d4b\u56fe\u50cf\u65f6\uff0c\u6211\u4eec\u4f1a\u50cf\u5e73\u5e38\u4e00\u6837\u53cd\u5411\u4f20\u64ad\u635f\u5931\u3002\u5bf9\u4e8e\u5206\u7c7b\u635f\u5931\uff0c\u6211\u4eec\u53ea\u662f\u5c06\u635f\u5931\u53cd\u5411\u4f20\u64ad\u5230\u6807\u7b7e\u76f8\u5e94\u7ea7\u522b\u6216\u66f4\u9ad8\u7684\u7ea7\u522b\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u6807\u7b7e\u662f\u72d7\uff0c\u6211\u4eec\u4e0d\u4f1a\u5c06\u4efb\u4f55\u9519\u8bef\u7ed9\u6811\u505a\u8fdb\u4e00\u6b65\u9884\u6d4b\uff0c\u5982\u5fb7\u56fd\u7267\u7f8a\u72ac\u4e0e\u9ec4\u91d1\u730e\u72ac\uff0c\u56e0\u4e3a\u6211\u4eec\u6ca1\u6709\u8fd9\u4e9b\u4fe1\u606f\u3002 \u56fe6\uff1a\u4f7f\u7528 \\(WordTree\\) \u5c42\u6b21\u7ed3\u6784\u7ec4\u5408\u6570\u636e\u96c6\u3002\u4f7f\u7528WordNet\u6982\u5ff5\u56fe\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u89c6\u89c9\u6982\u5ff5\u7684\u5206\u5c42\u6811\u3002\u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u6620\u5c04\u5230\u6811\u4e2d\u7684synsets\u6765\u5408\u5e76\u6570\u636e\u96c6\u3002\u51fa\u4e8e\u8bf4\u660e\u76ee\u7684\uff0c\u8fd9\u662f \\(WordTree\\) \u7684\u7b80\u5316\u89c6\u56fe\u3002 \u2003\u5f53\u7f51\u7edc\u5904\u7406\u5206\u7c7b\u56fe\u50cf\u65f6\uff0c\u6211\u4eec\u53ea\u662f\u53cd\u5411\u4f20\u64ad\u5206\u7c7b\u635f\u5931\u3002\u8981\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ea\u9700\u627e\u5230\u9884\u6d4b\u8be5\u7c7b\u522b\u6700\u9ad8\u6982\u7387\u7684\u8fb9\u754c\u6846\uff0c\u7136\u540e\u5728\u9884\u6d4b\u7684\u6811\u4e0a\u8ba1\u7b97\u635f\u5931\u3002\u6211\u4eec\u8fd8\u5047\u8bbe\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u7684 \\(IOU\\) \u81f3\u5c11\u4e3a0.3\uff0c\u5e76\u4e14\u57fa\u4e8e\u8fd9\u4e2a\u5047\u8bbe\u6211\u4eec\u53cd\u5411\u4f20\u64ad\u76ee\u6807\u635f\u5931\u3002 \u2003\u901a\u8fc7\u8fd9\u79cd\u8054\u5408\u8bad\u7ec3\uff0c \\(YOLO9000\\) \u5b66\u4e60\u4f7f\u7528 \\(COCO\\) \u4e2d\u7684\u68c0\u6d4b\u6570\u636e\u6765\u67e5\u627e\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff0c\u5e76\u5b66\u4e60\u4f7f\u7528\u6765\u81ea \\(ImageNet\\) \u7684\u6570\u636e\u5bf9\u5404\u79cd\u8fd9\u4e9b\u76ee\u6807\u8fdb\u884c\u5206\u7c7b\u3002 \u2003\u6211\u4eec\u5728 \\(ImageNet\\) \u68c0\u6d4b\u4efb\u52a1\u4e0a\u8bc4\u4f30 \\(YOLO9000\\) \u3002 \\(ImageNet\\) \u7684\u68c0\u6d4b\u4efb\u52a1\u4e0e \\(COCO\\) \u5171\u4eab44\u4e2a\u76ee\u6807\u7c7b\u522b\uff0c\u8fd9\u610f\u5473\u7740 \\(YOLO9000\\) \u770b\u5230\u7684\u6d4b\u8bd5\u56fe\u50cf\u5927\u591a\u6570\u662f\u5206\u7c7b\u6570\u636e\uff0c\u800c\u4e0d\u662f\u68c0\u6d4b\u6570\u636e\u3002 \\(YOLO9000\\) \u7684\u603b \\(mAP\\) \u662f19.7 \\(mAP\\) \uff0c\u5176\u4e2d\u5728\u4e0d\u76f8\u4ea4\u7684156\u4e2a\u76ee\u6807\u7c7b\u4e0a\uff0c \\(YOLO9000\\) \u4ece\u672a\u89c1\u8fc7\u8fd9\u4e9b\u7c7b\u7684\u4efb\u4f55\u68c0\u6d4b\u6570\u636e\u7684\u6807\u7b7e\uff0c\u4ecd\u83b7\u5f97\u4e8616.0 \\(mAP\\) \u3002\u8fd9\u4e2a \\(mAP\\) \u9ad8\u4e8eDPM\u7684\u7ed3\u679c\uff0c\u4f46 \\(YOLO9000\\) \u662f\u5728\u90e8\u5206\u76d1\u7763[4]\u7684\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u3002\u800c\u4e14\u5b83\u80fd\u540c\u65f6\u68c0\u6d4b9000\u4e2a\u5176\u4ed6\u76ee\u6807\u7c7b\u522b\uff0c\u6240\u6709\u7684\u68c0\u6d4b\u90fd\u662f\u5b9e\u65f6\u7684\u3002 \u2003\u5728\u5206\u6790 \\(YOLO9000\\) \u5728 \\(ImageNet\\) \u4e0a\u7684\u8868\u73b0\u65f6\uff0c\u6211\u4eec\u53d1\u73b0\u5b83\u5f88\u597d\u5730\u5b66\u4e60\u4e86\u65b0\u7684\u52a8\u7269\u79cd\u7c7b\uff0c\u4f46\u662f\u5728\u50cf\u670d\u88c5\u548c\u8bbe\u5907\u8fd9\u6837\u7684\u5b66\u4e60\u7c7b\u522b\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u65b0\u52a8\u7269\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u56e0\u4e3a\u76ee\u6807\u9884\u6d4b\u53ef\u4ee5\u4ece \\(COCO\\) \u4e2d\u7684\u52a8\u7269\u6cdb\u5316\u7684\u5f88\u597d\u3002\u76f8\u53cd\uff0c \\(COCO\\) \u6ca1\u6709\u4efb\u4f55\u7c7b\u578b\u7684\u8863\u670d\u7684\u8fb9\u754c\u6846\u6807\u7b7e\uff0c\u53ea\u9488\u5bf9\u4eba\uff0c\u56e0\u6b64 \\(YOLO9000\\) \u5728\u5206\u7c7b\u201c\u58a8\u955c\u201d\u6216\u201c\u6cf3\u88e4\u201d\u7b49\u7c7b\u522b\u4e0a\u5b58\u5728\u56f0\u96be\u3002 \\(\\begin{array}{ll} \\text { diaper } & 0.0 \\\\ \\text { horizontal bar } & 0.0 \\\\ \\text { rubber eraser } & 0.0 \\\\ \\text { sunglasses } & 0.0 \\\\ \\text { swimming trunks } & 0.0 \\\\ \\ldots & \\\\ \\text { red panda } & 50.7 \\\\ \\text { fox } & 52.1 \\\\ \\text { koala bear } & 54.3 \\\\ \\text { tiger } & 61.0 \\\\ \\text { armadillo } & 61.7 \\end{array}\\) \u88687\uff1a \\(ImageNet\\) \u4e0a\u7684 \\(YOLO9000\\) \u6700\u4f73\u548c\u6700\u5dee\u7c7b\u522b\u3002 156\u4e2a\u5f31\u76d1\u7763\u7c7b\u7684AP\u6700\u9ad8\u548c\u6700\u4f4e\u7684\u7c7b\u3002 \\(YOLO9000\\) \u6a21\u578b\u5f88\u597d\u5730\u9884\u6d4b\u5404\u79cd\u5404\u6837\u7684\u52a8\u7269\uff0c\u4f46\u4e0d\u64c5\u957f\u9884\u6d4b\u8bf8\u5982\u670d\u88c5\u6216\u8bbe\u5907\u7b49\u7684\u65b0\u7c7b\u3002","title":"4.\u66f4\u5f3a"},{"location":"thesis_interpretation/02_yolo.html#5","text":"\u6211\u4eec\u4ecb\u7ecd\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf \\(YOLOv2\\) \u548c \\(YOLO9000\\) \u3002 \\(YOLOv2\\) \u5728\u5404\u79cd\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u90fd\u662f\u6700\u5148\u8fdb\u7684\uff0c\u5e76\u4e14\u6bd4\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u66f4\u5feb\u3002\u6b64\u5916\uff0c\u5b83\u53ef\u4ee5\u5728\u5404\u79cd\u56fe\u50cf\u5c3a\u5bf8\u4e0b\u8fd0\u884c\uff0c\u4ee5\u63d0\u4f9b\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5e73\u6ed1\u6298\u4e2d\u3002 \u2003 \\(YOLO9000\\) \u662f\u4e00\u4e2a\u901a\u8fc7\u8054\u5408\u4f18\u5316\u68c0\u6d4b\u548c\u5206\u7c7b\u6765\u68c0\u6d4b\u8d85\u8fc79000\u4e2a\u76ee\u6807\u7c7b\u522b\u7684\u5b9e\u65f6\u6846\u67b6\u3002\u6211\u4eec\u4f7f\u7528 \\(WordTree\\) \u5c06\u5404\u79cd\u6765\u6e90\u7684\u6570\u636e\u548c\u6211\u4eec\u7684\u8054\u5408\u4f18\u5316\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u5728 \\(ImageNet\\) \u548c \\(COCO\\) \u4e0a\u540c\u65f6\u8fdb\u884c\u8bad\u7ec3\u3002 \\(YOLO9000\\) \u5411\u7f29\u5c0f\u68c0\u6d4b\u548c\u5206\u7c7b\u4e4b\u95f4\u7684\u6570\u636e\u96c6\u5927\u5c0f\u7684\u5dee\u8ddd\u8fc8\u51fa\u4e86\u575a\u5b9e\u7684\u4e00\u6b65\u3002 \u2003\u6211\u4eec\u7684\u8bb8\u591a\u6280\u672f\u90fd\u662f\u6cdb\u5316\u5230\u76ee\u6807\u68c0\u6d4b\u4e4b\u5916\u7684\u9886\u57df\u3002 \\(ImageNet\\) \u7684 \\(WordTree\\) \u8868\u793a\u65b9\u6cd5\u4e3a\u56fe\u50cf\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\uff0c\u66f4\u8be6\u7ec6\u7684\u8f93\u51fa\u7a7a\u95f4\u3002\u4f7f\u7528\u5206\u5c42\u5206\u7c7b\u7684\u6570\u636e\u96c6\u7ec4\u5408\u5728\u5206\u7c7b\u548c\u5206\u5272\u9886\u57df\u5c06\u4f1a\u5f88\u6709\u7528\u3002\u50cf\u591a\u5c3a\u5ea6\u8bad\u7ec3\u8fd9\u6837\u7684\u8bad\u7ec3\u6280\u672f\u53ef\u4ee5\u4e3a\u5404\u79cd\u89c6\u89c9\u4efb\u52a1\u63d0\u4f9b\u5e2e\u52a9\u3002 \u2003\u5bf9\u4e8e\u672a\u6765\u7684\u5de5\u4f5c\uff0c\u6211\u4eec\u5e0c\u671b\u4f7f\u7528\u7c7b\u4f3c\u7684\u6280\u672f\u8fdb\u884c\u5f31\u76d1\u7763\u56fe\u50cf\u5206\u5272\u3002\u6211\u4eec\u8fd8\u8ba1\u5212\u4f7f\u7528\u66f4\u5f3a\u5927\u7684\u5339\u914d\u7b56\u7565\u6765\u6539\u5584\u6211\u4eec\u7684\u68c0\u6d4b\u7ed3\u679c\uff0c\u4ee5\u5728\u8bad\u7ec3\u671f\u95f4\u5c06\u5f31\u6807\u7b7e\u5206\u914d\u7ed9\u5206\u7c7b\u6570\u636e\u3002\u8ba1\u7b97\u673a\u89c6\u89c9\u62e5\u6709\u5927\u91cf\u7684\u6807\u8bb0\u6570\u636e\u3002\u6211\u4eec\u5c06\u7ee7\u7eed\u5bfb\u627e\u65b9\u6cd5\uff0c\u5c06\u4e0d\u540c\u7684\u6570\u636e\u6765\u6e90\u548c\u6570\u636e\u7ed3\u6784\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u5f62\u6210\u66f4\u5f3a\u5927\u7684\u89c6\u89c9\u4e16\u754c\u6a21\u578b\u3002","title":"5.\u603b\u7ed3"},{"location":"thesis_interpretation/02_yolo.html#references","text":"[1] S. Bell, C. L. Zitnick, K. Bala, and R. Girshick. Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks. arXiv preprint arXiv:1512.04143, 2015. 6 [2] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 248\u2013255. IEEE, 2009. 1 [3] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) chal-lenge. International journal of computer vision, 88(2):303\u2013338, 2010. 1 [4] P. F. Felzenszwalb, R. B. Girshick, and D. McAllester. Discriminatively trained deformable part models, release 4. http://people.cs.uchicago.edu/ pff/latent-release4/. 8 [5] R. B. Girshick. Fast R-CNN. CoRR, abs/1504.08083, 2015. 4, 5, 6 [6] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learn-ing for image recognition. arXiv preprint arXiv:1512.03385, 2015. 2, 4, 5 [7] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015. 2, 5 [8] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097\u20131105, 2012. 2 [9] M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.4400, 2013. 5 [10] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ra-manan, P. Doll\u00b4ar, and C. L. Zitnick. Microsoft coco: Com-mon objects in context. In European Conference on Com-puter Vision, pages 740\u2013755. Springer, 2014. 1, 6 [11] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, and S. E. Reed. SSD: single shot multibox detector. CoRR, abs/1512.02325, 2015. 4, 5, 6 [12] G. A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. J. Miller. Introduction to wordnet: An on-line lexical database. International journal of lexicography, 3(4):235\u2013244, 1990. 6 [13] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 5 [14] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. arXiv preprint arXiv:1506.02640, 2015. 4, 5 [15] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: To-wards real-time object detection with region proposal net-works. arXiv preprint arXiv:1506.01497, 2015. 2, 3, 4, 5, 6 [16] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. 2 [17] K. Simonyan and A. Zisserman. V ery deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. 2, 5 [18] C. Szegedy, S. Ioffe, and V . V anhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR, abs/1602.07261, 2016. 2 [19] C. Szegedy, W. Liu, Y . Jia, P . Sermanet, S. Reed, D. Anguelov, D. Erhan, V . V anhoucke, and A. Rabinovich.Going deeper with convolutions. CoRR, abs/1409.4842, 2014. 5 [20] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):64\u201373, 2016. 1","title":"References"},{"location":"thesis_interpretation/03_yolo.html","text":"\u539f\u6587\u5730\u5740 : https://arxiv.org/pdf/1804.02767v1.pdf \\(YOLOv3\\) : An Incremental Improvement \\(YOLOv3\\) \uff1a\u589e\u91cf\u5f0f\u7684\u6539\u8fdb Joseph Redmon Ali Farhadi University of Washington \u6458\u8981 \u6211\u4eec\u5bf9YOLO\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u66f4\u65b0\uff01\u5b83\u5305\u542b\u4e00\u5806\u5c0f\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u4f7f\u7cfb\u7edf\u7684\u6027\u80fd\u5f97\u5230\u66f4\u65b0\u3002\u6211\u4eec\u4e5f\u8bad\u7ec3\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u6bd4\u8f83\u5927\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u867d\u7136\u6bd4\u4e0a\u4e00\u7248\u66f4\u5927\u4e00\u4e9b\uff0c\u4f46\u662f\u7cbe\u5ea6\u4e5f\u63d0\u9ad8\u4e86\u3002\u4e0d\u7528\u62c5\u5fc3\uff0c\u5b83\u7684\u901f\u5ea6\u4f9d\u7136\u5f88\u5feb\u3002 \\(YOLOv3\\) \u5728 \\(320\u00d7320\\) \u8f93\u5165\u56fe\u50cf\u4e0a\u8fd0\u884c\u65f6\u53ea\u9700 \\(22ms\\) \uff0c\u5e76\u80fd\u8fbe\u5230 \\(28.2mAP\\) \uff0c\u5176\u7cbe\u5ea6\u548c \\(SSD\\) \u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u8981\u5feb\u4e0a \\(3\\) \u500d\u3002\u4f7f\u7528\u4e4b\u524d \\(0.5 \\ IOU \\ mAP\\) \u7684\u68c0\u6d4b\u6307\u6807\uff0c \\(YOLOv3\\) \u7684\u6548\u679c\u662f\u76f8\u5f53\u4e0d\u9519\u3002 \\(YOLOv3\\) \u4f7f\u7528Titan X GPU\uff0c\u5b83\u5728 \\(51ms\\) \u68c0\u6d4b\u7cbe\u5ea6\u8fbe\u5230 \\(57.9 \\ AP50\\) \uff0c\u7136\u800c\u4e0e \\(RetinaNet\\) \u76f8\u6bd4 \uff0c\u5176\u7cbe\u5ea6\u53ea\u6709 \\(57.5 \\ AP50\\) \uff0c\u4f46\u5374\u8017\u65f6 \\(198ms\\) \uff0c\u76f8\u540c\u6027\u80fd\u7684\u60c5\u51b5\u4e0b \\(YOLOv3\\) \u901f\u5ea6\u6bd4 \\(RetinaNet\\) \u5feb \\(3.8\\) \u500d\u3002\u4e0e\u4e4b\u524d\u4e00\u6837\uff0c\u6240\u6709\u4ee3\u7801\u5728\u7f51\u5740\uff1ahttps://pjreddie.com/yolo/\u3002 1.\u5f15\u8a00 \u2003\u6709\u65f6\u5019\uff0c\u4e00\u5e74\u5185\u4f60\u4e3b\u8981\u90fd\u5728\u73a9\u624b\u673a\uff0c\u4f60\u77e5\u9053\u5417\uff1f\u4eca\u5e74\u6211\u6ca1\u6709\u505a\u5f88\u591a\u7814\u7a76\u3002\u6211\u5728 \\(Twitter\\) \u4e0a\u82b1\u4e86\u5f88\u591a\u65f6\u95f4,\u5728GANs\u4e0a\u73a9\u4e86\u70b9\u5c0f\u6e38\u620f\u3002\u53bb\u5e74\u6211\u7559\u4e0b\u4e86\u4e00\u70b9\u70b9\u7684\u7cbe\u529b [12] [1]\uff1b\u6211\u8bbe\u6cd5\u5bf9 \\(YOLO\\) \u8fdb\u884c\u4e86\u4e00\u4e9b\u6539\u8fdb\u3002\u4f46\u662f\uff0c\u5b9e\u8bdd\u5b9e\u8bf4\uff0c\u4ec5\u4ec5\u4e00\u4e9b\u5c0f\u7684\u6539\u53d8\u4f7f\u5f97\u5b83\u53d8\u5f97\u66f4\u597d\uff0c\u6ca1\u6709\u4ec0\u4e48\u8d85\u7ea7\u6709\u8da3\u7684\u4e8b\u60c5\u3002\u6211\u4e5f\u7a0d\u5fae\u5e2e\u52a9\u4e86\u5176\u4ed6\u4eba\u7684\u4e00\u4e9b\u7814\u7a76\u3002 \u2003\u4e8b\u5b9e\u4e0a\uff0c\u8fd9\u5c31\u662f\u6211\u4eec\u4eca\u5929\u6765\u8fd9\u91cc\u7684\u539f\u56e0\u3002\u6211\u4eec\u6709\u4e00\u7bc7\u8bba\u6587\u5feb\u622a\u7a3f\u4e86\uff0c\u5e76\u4e14\u6211\u4eec\u8fd8\u7f3a\u4e00\u7bc7\u5173\u4e8e \\(YOLO\\) \u66f4\u65b0\u5185\u5bb9\u7684\u6587\u7ae0\u4f5c\u4e3a\u5f15\u7528\uff0c\u4f46\u662f\u6211\u4eec\u6ca1\u6709\u5f15\u7528\u6765\u6e90\u3002\u6240\u4ee5\uff0c\u51c6\u5907\u597d\u8fce\u63a5\u79d1\u6280\u62a5\u9053\u5427! \u2003\u6280\u672f\u62a5\u544a\u6700\u68d2\u7684\u4e00\u70b9\u5c31\u662f\u4ed6\u4eec\u4e0d\u9700\u8981\u4ecb\u7ecd\uff0c\u4f60\u4eec\u90fd\u77e5\u9053\u6211\u4eec\u4e3a\u4ec0\u4e48\u5728\u8fd9\u91cc\u3002\u56e0\u6b64\uff0c\u8fd9\u7bc7\u4ecb\u7ecd\u7684\u7ed3\u5c3e\u5c06\u4e3a\u672c\u6587\u7684\u5176\u4f59\u90e8\u5206\u6307\u660e\u65b9\u5411\u3002\u9996\u5148\u6211\u4eec\u4f1a\u544a\u8bc9\u4f60 \\(YOLOv3\\) \u7684\u65b9\u6848\u3002\u5176\u6b21\u6211\u4eec\u4f1a\u544a\u8bc9\u4f60\u6211\u4eec\u662f\u5982\u4f55\u5b9e\u73b0\u7684\u3002\u6211\u4eec\u4e5f\u4f1a\u544a\u8bc9\u4f60\u6211\u4eec\u5c1d\u8bd5\u8fc7\u4f46\u5e76\u4e0d\u594f\u6548\u7684\u4e00\u4e9b\u4e8b\u60c5\u3002\u6700\u540e\u6211\u4eec\u5c06\u63a2\u8ba8\u8fd9\u4e9b\u7684\u610f\u4e49\u3002 2.\u65b9\u6848 \u2003\u8fd9\u8282\u4e3b\u8981\u4ecb\u7ecd \\(YOLOv3\\) \u7684\u66f4\u65b0\u65b9\u6848\uff1a\u6211\u4eec\u4e3b\u8981\u4ece\u5176\u4ed6\u4eba\u7684\u7814\u7a76\u5de5\u4f5c\u91cc\u83b7\u5f97\u4e86\u4e00\u4e9b\u597d\u601d\u8def\u3001\u597d\u60f3\u6cd5\u3002\u6211\u4eec\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u6bd4\u5176\u4ed6\u7f51\u7edc\u66f4\u597d\u7684\u5206\u7c7b\u7f51\u7edc\u3002\u4e3a\u4e86\u65b9\u4fbf\u7406\u89e3\uff0c\u8ba9\u6211\u4eec\u4ece\u5934\u5f00\u59cb\u6162\u6162\u4ecb\u7ecd\u6574\u4e2a\u6a21\u578b\u7cfb\u7edf\u3002 \u56fe1. \u6e90\u81ea \\(Focal \\ Loss\\) \u8bba\u6587[9]\u3002 \\(YOLOv3\\) \u7684\u8fd0\u884c\u901f\u5ea6\u660e\u663e\u5feb\u4e8e\u5176\u4ed6\u6027\u80fd\u76f8\u5f53\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002\u68c0\u6d4b\u65f6\u95f4\u57fa\u4e8e \\(M40\\) \u6216 \\(Titan \\ X\\) \uff08 \u5176\u4e2d \\(M40,Titan X\\) \u662f\u76f8\u4f3c\u7684\u4e24\u79cd \\(GPU\\) \uff09\u3002 2.1 \u8fb9\u754c\u6846\u9884\u6d4b \u2003\u548c \\(YOLO9000\\) \u4e00\u6837\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u4e5f\u4f7f\u7528\u7ef4\u5ea6\u805a\u7c7b\u7b97\u6cd5\u751f\u6210\u7684\u951a\u6846\uff08 anchor boxes \uff09[15] \u6765\u9884\u6d4b\u8fb9\u754c\u6846\u3002\u7f51\u7edc\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u76844\u4e2a\u5750\u6807\uff1a \\(t_x\u3001t_y\u3001t_w\u3001t_h\\) \u3002\u5047\u8bbe\u683c\u5b50\u8ddd\u79bb\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u504f\u79fb\u91cf\u4e3a \\((c_x\uff0cc_y)\\) \uff0c\u4e14\u4e4b\u524d\u7684\u8fb9\u754c\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e3a \\(p_w, p_h\\) \uff0c\u5219\u9884\u6d4b\u7ed3\u679c: \\[ {\\large \\begin{align} b_{x} & = \\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} & = \\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} & = p_{w} e^{t_{w}} \\\\ b_{h} & = p_{h} e^{t_{h}} \\end{align}} \\] \u2003\u5728\u8bad\u7ec3\u4e2d\u6211\u4eec\u4f7f\u7528\u8bef\u5dee\u5e73\u65b9\u548c\u635f\u5931\u8ba1\u7b97\u3002\u5982\u679c\u67d0\u4e2a\u9884\u6d4b\u5750\u6807\u7684 \\(ground \\ truth\\) \u662f \\(\\hat{t}_*\\) \uff0c\u90a3\u4e48\u5bf9\u5e94\u7684\u68af\u5ea6\u5c31\u662f \\(ground \\ truth \\ value\\) \uff08\u7531 \\(ground \\ truth \\ box\\) \u8ba1\u7b97\u800c\u5f97\uff09\u548c\u9884\u6d4b\u503c\u4e4b\u5dee\uff1a \\(\\hat{t}_* - t_*\\) \u3002\u901a\u8fc7\u53d8\u6362\u4e0a\u8ff0\u516c\u5f0f\u8ba1\u7b97,\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5f97\u5230 \\(ground \\ truth \\ value\\) \u3002 \u56fe2\uff1a \u7ef4\u5ea6\u5148\u9a8c\u548c\u4f4d\u7f6e\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u3002 \\(\\large{\\sigma(t_x)}\\) , \\(\\large{\\sigma(t_y)}\\) \u662f\u57fa\u4e8e\u77e9\u5f62\u6846\u4e2d\u5fc3\u70b9\u5de6\u4e0a\u89d2\u683c\u70b9\u5750\u6807\u7684\u504f\u79fb\u91cf\uff0c \\(\\large{\\sigma}\\) \u662f\u6fc0\u6d3b\u51fd\u6570\uff0c\u8bba\u6587\u4e2d\u4f5c\u8005\u4f7f\u7528 sigmoid [15]\u3002 \\(\\large{P_w,P_h}\\) \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u3001\u9ad8\uff0c\u901a\u8fc7\u4e0a\u8ff0\u516c\u5f0f\uff0c\u8ba1\u7b97\u51fa\u5b9e\u9645\u9884\u6d4b\u6846\u7684\u5bbd\u9ad8 \u3002 \u2003 \\(YOLOv3\\) \u4f7f\u7528\u903b\u8f91\u56de\u5f52\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u662f\u76ee\u6807\u7684\u5206\u6570\u3002\u5982\u679c\u771f\u5b9e\u6807\u7b7e\u6846\u4e0e\u67d0\u4e2a\u8fb9\u754c\u6846\u91cd\u53e0\u7684\u9762\u79ef\u6bd4\u4e0e\u5176\u4ed6\u4efb\u4f55\u8fb9\u754c\u6846\u90fd\u5927\uff0c\u90a3\u4e48\u8fd9\u4e2a\u5148\u9a8c\u8fb9\u754c\u6846\u5f97\u5206\u4e3a1\u3002\u6309\u7167[17]\u7684\u505a\u6cd5\uff0c\u5982\u679c\u5148\u9a8c\u8fb9\u754c\u6846\u4e0d\u662f\u6700\u597d\u7684\uff0c\u4f46\u662f\u786e\u5b9e\u4e0e\u76ee\u6807\u7684\u771f\u5b9e\u6807\u7b7e\u6846\u91cd\u53e0\u7684\u9762\u79ef\u5927\u4e8e\u9608\u503c\uff0c\u6211\u4eec\u4e5f\u4f1a\u5ffd\u7565\u8fd9\u4e2a\u9884\u6d4b\u3002\u6211\u4eec\u4f7f\u7528\u9608\u503c\u4e3a0.5\u3002\u4e0e[17]\u4e0d\u540c\u7684\u662f\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u53ea\u4e3a\u6bcf\u4e2a\u771f\u5b9e\u76ee\u6807\u5206\u914d\u4e00\u4e2a\u8fb9\u754c\u6846\u3002\u5982\u679c\u5148\u9a8c\u8fb9\u754c\u6846\u672a\u5206\u914d\u5230\u771f\u5b9e\u76ee\u6807\uff0c\u5219\u4e0d\u4f1a\u4ea7\u751f\u5750\u6807\u6216\u7c7b\u522b\u9884\u6d4b\u7684\u635f\u5931\uff0c\u53ea\u4f1a\u4ea7\u751f\u662f\u5426\u662f\u76ee\u6807\u7684\u635f\u5931\u3002 2.2 \u5206\u7c7b\u9884\u6d4b \u2003\u6bcf\u4e2a\u8fb9\u754c\u6846\u90fd\u4f1a\u4f7f\u7528\u591a\u6807\u7b7e\u5206\u7c7b\u6765\u9884\u6d4b\u6846\u4e2d\u53ef\u80fd\u5305\u542b\u7684\u7c7b\u3002\u6211\u4eec\u4e0d\u7528 \\(softmax\\) \uff0c\u800c\u662f\u7528\u5355\u72ec\u7684\u903b\u8f91\u5206\u7c7b\u5668\uff0c\u56e0\u4e3a\u6211\u4eec\u53d1\u73b0\u524d\u8005\u5bf9\u4e8e\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u6ca1\u4ec0\u4e48\u4f5c\u7528\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u7528binary cross-entropy\uff08\u4e8c\u5143\u4ea4\u53c9\u71b5\uff09\u635f\u5931\u6765\u9884\u6d4b\u7c7b\u522b\u3002 \u2003\u5f53\u6211\u4eec\u8f6c\u5411\u66f4\u590d\u6742\u7684\u9886\u57df\uff0c\u4f8b\u5982 \\(Open \\ Images \\ Dataset\\) [7]\uff0c\u4e0a\u9762\u7684\u8fd9\u79cd\u6539\u53d8\u5c06\u53d8\u5f97\u5f88\u6709\u7528\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u4e2d\u6709\u8bb8\u591a\u91cd\u53e0\u7684\u6807\u7b7e\uff08\u4f8b\u5982\u5973\u6027\u548c\u4eba\uff09\u3002\u4f7f\u7528 \\(softmax\\) \u4f1a\u5047\u5b9a\u6bcf\u4e2a\u6846\u53ea\u5305\u542b\u4e00\u4e2a\u7c7b\uff0c\u4f46\u901a\u5e38\u60c5\u51b5\u5e76\u975e\u5982\u6b64\u3002\u591a\u6807\u7b7e\u7684\u65b9\u5f0f\u53ef\u4ee5\u66f4\u597d\u5730\u5bf9\u6570\u636e\u8fdb\u884c\u5efa\u6a21\u3002 2.3 \u8de8\u5c3a\u5ea6\u9884\u6d4b \u2003 \\(YOLOv3\\) \u5728 3 \u79cd\u4e0d\u540c\u5c3a\u5ea6\u4e0a\u9884\u6d4b\u6846\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u4f7f\u7528\u7c7b\u4f3c\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc\u7684\u76f8\u4f3c\u6982\u5ff5( \u8be6\u7ec6\u53ef\u89c1\u8bba\u6587\uff1ahttps://arxiv.org/pdf/1612.03144.pdf )\uff0c\u5e76\u4ece\u8fd9\u4e9b\u5c3a\u5ea6\u4e2d\u63d0\u53d6\u7279\u5f81[8]\u3002\u6211\u4eec\u5728\u57fa\u7840\u7279\u5f81\u63d0\u53d6\u5668\u4e0a\u6dfb\u52a0\u4e86\u51e0\u4e2a\u5377\u79ef\u5c42\u3002\u5176\u4e2d\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42 \u9884\u6d4b\u4e86\u4e00\u4e2a\u7f16\u7801\u8fb9\u754c\u6846\u3001\u662f\u5426\u662f\u76ee\u6807\u548c\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c \u7684\u4e09\u7ef4\u5f20\u91cf\u3002\u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c[8]\u4e2d\uff0c\u6211\u4eec\u4e3a\u6bcf\u4e2a\u5c3a\u5ea6\u9884\u6d4b3\u4e2a\u6846\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u8fb9\u754c\u6846\u6709 4\u4e2a\u504f\u79fb\u91cf\u30011\u4e2a\u76ee\u6807\u9884\u6d4b\u548c80\u4e2a\u7c7b\u522b\u9884\u6d4b\uff0c\u6700\u7ec8\u7684\u5f20\u91cf\u5927\u5c0f\u4e3a \\(N\u00d7N\u00d7[3\u00d7(4+1+80)]\\) \u3002 \u2003\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4ece\u524d\u9762\u76842\u4e2a\u5c42\u4e2d\u63d0\u53d6\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u5176\u4e0a\u91c7\u68372\u500d\u3002\u6211\u4eec\u8fd8\u4ece\u7f51\u7edc\u4e2d\u7684\u8f83\u524d\u7684\u5c42\u4e2d\u83b7\u53d6\u4e00\u4e2a\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u5176\u4e0e\u6211\u4eec\u7684\u4e0a\u91c7\u6837\u7279\u5f81\u56fe\u8fdb\u884c\u62fc\u63a5\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u6211\u4eec\u80fd\u591f\u4ece\u4e0a\u91c7\u6837\u7684\u7279\u5f81\u56fe\u4e2d\u83b7\u5f97\u66f4\u6709\u610f\u4e49\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u540c\u65f6\u53ef\u4ee5\u4ece\u66f4\u524d\u7684\u5c42\u4e2d\u83b7\u53d6\u66f4\u7ec6\u7c92\u5ea6\u7684\u4fe1\u606f\u3002\u7136\u540e\uff0c\u6211\u4eec\u6dfb\u52a0\u51e0\u4e2a\u5377\u79ef\u5c42\u6765\u5904\u7406\u8fd9\u4e2a\u7279\u5f81\u6620\u5c04\u7ec4\u5408\uff0c\u5e76\u6700\u7ec8\u9884\u6d4b\u51fa\u4e00\u4e2a\u76f8\u4f3c\u7684\u3001\u5927\u5c0f\u662f\u539f\u5148\u4e24\u500d\u7684\u5f20\u91cf\u3002 \u2003\u6211\u4eec\u518d\u6b21\u4f7f\u7528\u76f8\u540c\u7684\u8bbe\u8ba1\u6765\u9884\u6d4b\u6700\u7ec8\u5c3a\u5bf8\u7684\u8fb9\u754c\u6846\u3002\u56e0\u6b64\uff0c\u7b2c\u4e09\u4e2a\u5c3a\u5bf8\u7684\u9884\u6d4b\u5c06\u65e2\u80fd\u4ece\u6240\u6709\u5148\u524d\u7684\u8ba1\u7b97\uff0c\u53c8\u80fd\u4ece\u7f51\u7edc\u524d\u9762\u7684\u5c42\u4e2d\u7684\u7ec6\u7c92\u5ea6\u7684\u7279\u5f81\u4e2d\u83b7\u76ca\u3002 \u2003\u6211\u4eec\u4ecd\u7136\u4f7f\u7528k-means\u805a\u7c7b\u7b97\u6cd5\u6765\u786e\u5b9a\u6211\u4eec\u7684\u5148\u9a8c\u8fb9\u754c\u6846\u3002\u6211\u4eec\u53ea\u662f\u9009\u62e9\u4e869\u4e2a\u805a\u7c7b( clusters )\u548c3\u4e2a\u4efb\u610f\u7684\u5c3a\u5ea6( scales arbitrarily )\uff0c \u7136\u540e\u5728\u5c3a\u5ea6\u4e0a\u5c06\u805a\u7c7b\u5747\u5300\u5730\u5212\u5206\u805a\u7c7b\u3002 \u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\uff0c9\u4e2a\u805a\u7c7b\u5206\u522b \u4e3a \\((10\u00d713)\u3001(16\u00d730)\u3001(33\u00d723)\u3001(30\u00d761)\u3001(62\u00d745)\u3001(59\u00d7119)\u3001(116 \u00d7 90)\u3001(156 \u00d7 198)\u3001(373 \u00d7 326)\\) \u3002 2.4 \u7279\u5f81\u63d0\u53d6\u5668 \u2003\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u65b0\u7684\u7f51\u7edc\u6765\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002\u6211\u4eec\u7684\u65b0\u7f51\u7edc\u878d\u5408\u4e86 \\(YOLOv2\u3001Darknet-19\\) \u548c\u65b0\u53d1\u660e\u7684\u6b8b\u5dee\u7f51\u7edc\u7684\u601d\u60f3\u3002\u6211\u4eec\u7684\u7f51\u7edc\u4f7f\u7528\u8fde\u7eed\u7684 \\(3\u00d73\\) \u548c \\(1\u00d71\\) \u5377\u79ef\u5c42\u548c\u6dfb\u52a0\u4e86\u4e00\u4e9b\u5feb\u6377\u8fde\u63a5\uff08shortcut connetction\uff09\uff0c\u4ece\u800c\u89c4\u6a21\u66f4\u5927\uff0c\u76ee\u524d\u5b83\u670953\u4e2a\u5377\u79ef\u5c42\uff0c\u6240\u4ee5\u6211\u4eec\u79f0\u4e4b\u4e3a... \\(Darknet-53!\\) \u88681. Darknet-53. \u6211\u4eec\u7684\u7f51\u7edc\u5728\u6027\u80fd\u4e0a\u8fdc\u8d85Darknet-19\uff0c\u5728\u6548\u7387\u4e0a\u4e5f\u4f18\u4e8eResNet-101\u548cResNet-152\u3002\u8fd9\u91cc\u662f\u4e00\u4e9b\u7f51\u7edc\u5728ImageNet\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\uff1a \\[ \\begin{eqnarray} \\text { Backbone } & \\text { Top-1 } & \\text { Top-5 } & \\text { Bn Ops } & \\text { BFLOP/s } & \\text { FPS } \\\\ \\hline \\text { Darknet-19[15] } & 74.1 & 91.8 & 7.29 & 1246 & \\mathbf{1 7 1} \\\\ \\text { ResNet-101[5] } & 77.1 & 93.7 & 19.7 & 1039 & 53 \\\\ \\text { ResNet-152[5] } & \\mathbf{7 7 . 6} & \\mathbf{9 3 . 8} & 29.4 & 1090 & 37 \\\\ \\text { Darknet-53 } & 77.2 & \\mathbf{9 3 . 8} & 18.7 & \\mathbf{1 4 5 7} & 78 \\end{eqnarray} \\] \u88682.\u7f51\u7edc\u7684\u6bd4\u8f83\u3002\u4e0d\u540cbackbones\u7684\u5404\u79cd\u7f51\u7edc\u5728\u51c6\u786e\u5ea6\u3001Bn Ops\uff08\u5341\u4ebf\u64cd\u4f5c\u6570\uff09\u3001BFLOP/s\uff08\u6bcf\u79d2\u5341\u4ebf\u6d6e\u70b9\u64cd\u4f5c\uff09\u548cFPS\u4e0a\u7684\u6bd4\u8f83\u3002 \u2003\u6bcf\u4e2a\u7f51\u7edc\u90fd\u5728\u76f8\u540c\u7684\u914d\u7f6e\u4e0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5747\u7528 \\(256 \u00d7256\\) \u7684\u56fe\u7247\u4e0a\u8fdb\u884c\u5355\u7cbe\u5ea6\u6d4b\u8bd5\u3002\u8fd0\u884c\u65f6\u95f4\u901a\u8fc7\u5728 \\(Titan \\ X\\) \u4e0a\u5904\u7406 \\(256 \u00d7 256\\) \u56fe\u7247\u6d4b\u51fa\u3002\u4ece\u88682\u53ef\u4ee5\u770b\u51fa\uff0c \\(Darknet-53\\) \u4e0d\u4ec5\u7cbe\u5ea6\u53ef\u4ee5\u5ab2\u7f8e\u6700\u5148\u8fdb\u7684\u5206\u7c7b\u5668\uff0c\u800c\u4e14\u5b83\u6709\u8f83\u5c11\u6d6e\u70b9\u8fd0\u7b97\u64cd\u4f5c\uff0c\u66f4\u5feb\u7684\u901f\u5ea6\u3002 \\(Darknet-53\\) \u6bd4 \\(ResNet-101\\) \u6027\u80fd\u66f4\u597d\u800c\u4e14\u8981\u5feb1.5\u500d\u3002 \\(Darknet-53\\) \u6027\u80fd\u4e0e \\(ResNet-152\\) \u76f8\u8fd1\uff0c\u4f46\u662f\u8981\u6bd4\u5b83\u5feb2\u500d\u3002 \u2003 \\(Darknet-53\\) \u4e5f\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u6bcf\u79d2\u6d6e\u70b9\u8fd0\u7b97\u6d4b\u91cf\u3002\u8fd9\u610f\u5473\u7740\u7f51\u7edc\u7ed3\u6784\u53ef\u4ee5\u66f4\u597d\u5730\u5229\u7528GPU\uff0c\u4f7f\u5176\u9884\u6d4b\u6548\u7387\u66f4\u9ad8\uff0c\u901f\u5ea6\u66f4\u5feb\u3002ResNets\u66f4\u6162\uff0c\u5927\u62b5\u662f\u56e0\u4e3a\u5176\u5c42\u6570\u592a\u591a\uff0c\u6240\u4ee5\u4e0d\u662f\u90a3\u4e48\u6709\u6548\u7387\u3002 2.5 \u8bad\u7ec3 \u2003\u6211\u4eec\u4f9d\u65e7\u53ea\u662f\u8bad\u7ec3\u5b8c\u6574\u7684\u56fe\u50cf\uff0c\u6ca1\u6709\u5c06\u96be\u4ee5\u6b63\u786e\u5206\u7c7b\u7684\u6837\u672c\u53cd\u590d\u8bad\u7ec3\uff0c\u4e5f\u6ca1\u6709\u8fdb\u884c\u5176\u4ed6\u4efb\u4f55\u64cd\u4f5c\u3002\u6211\u4eec\u4f7f\u7528\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u4f7f\u7528\u5927\u91cf\u7684\u6570\u636e\u589e\u5f3a\u3001\u6279\u91cf\u6807\u51c6\u5316\u7b49\u6807\u51c6\u7684\u64cd\u4f5c\u3002\u6211\u4eec\u4f7f\u7528 \\(Darknet\\) \u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5[12]\u3002 \\(YOLOv3\\) is pretty good! See table 3. In terms of COCOs weird average mean AP metric it is on par with the SSD variants but is 3\u00d7 faster. It is still quite a bit behind other models like RetinaNet in this metric though. Table 3. I\u2019m seriously just stealing all these tables from [9] they take soooo long to make from scratch. Ok, \\(YOLOv3\\) is doing alright. Keep in mind that RetinaNet has like 3.8\u00d7 longer to process an image. \\(YOLOv3\\) is much better than SSD variants and comparable to state-of-the-art models on the AP50 metric. 3 \u6211\u4eec\u662f\u5982\u4f55\u505a\u7684 \\(YOLOv3\\) \u8868\u73b0\u975e\u5e38\u597d\uff01\u8bf7\u770b\u88683\u3002\u5c31COCO\u7684\u5e73\u5747AP\u6307\u6807\u800c\u8a00\uff0c\u5b83\u4e0eSSD\u7c7b\u7684\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u63d0\u9ad8\u4e863\u500d\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u5b83\u4ecd\u7136\u5728\u8fd9\u4e2a\u6307\u6807\u4e0a\u6bd4\u50cfRetinaNet\u8fd9\u6837\u7684\u5176\u4ed6\u6a21\u578b\u5dee\u4e9b\u3002 \u88683.\u6211\u5f88\u8ba4\u771f\u5730\u4ece[9]\u4e2d \\(\u201c\u7a83\u53d6\u201d\\) \u4e86\u4ed6\u4eec\u82b1\u4e86\u5f88\u957f\u65f6\u95f4\u624d\u4ece\u5934\u5f00\u59cb\u5236\u4f5c\u8fd9\u4e9b\u8868\u683c\u3002\u597d\u7684\uff0c \\(YOLOv3\\) \u6ca1\u95ee\u9898\u3002\u8bf7\u8bb0\u4f4f\uff0c \\(RetinaNet\\) \u5904\u7406\u4e00\u5f20\u56fe\u50cf\u7684\u65f6\u95f4\u662f \\(YOLOv3\\) \u7684 \\(3.8\\) \u500d\u3002 \\(YOLOv3\\) \u6bd4 \\(SSD\\) \u8981\u597d\u5f97\u591a\uff0c\u5e76\u4e14\u5728 \\(AP50\\) \u6807\u51c6\u4e0b\u53ef\u4ee5\u4e0e\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5ab2\u7f8e\uff01 \u2003\u7136\u800c\uff0c\u5f53\u6211\u4eec\u4f7f\u7528 \\(\u201c\u65e7\u7684\u201d\\) \u68c0\u6d4b\u6307\u6807\u2014\u2014\u5728 \\(IOU=0.5\u7684mAP\\) \uff08\u6216\u56fe\u8868\u4e2d\u7684 \\(AP50\\) \uff09\u65f6\uff0c \\(YOLOv3\\) \u975e\u5e38\u5f3a\u5927\u3002\u5176\u6027\u80fd\u51e0\u4e4e\u4e0eRetinaNet\u76f8\u5f53\uff0c\u5e76\u4e14\u8fdc\u5f3a\u4e8e \\(SSD\\) \u3002\u8fd9\u8868\u660e \\(YOLOv3\\) \u662f\u4e00\u4e2a\u975e\u5e38\u5f3a\u5927\u7684\u68c0\u6d4b\u5668\uff0c\u64c5\u957f\u4e3a\u76ee\u6807\u751f\u6210\u6070\u5f53\u7684\u6846\u3002\u7136\u800c\uff0c\u968f\u7740 \\(IOU\\) \u9608\u503c\u589e\u52a0\uff0c\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8fd9\u8868\u660e \\(YOLOv3\\) \u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4e0e\u76ee\u6807\u4e0d\u80fd\u5b8c\u7f8e\u5bf9\u9f50\u3002 Figure 3. Again adapted from the [9], this time displaying speed/accuracy tradeoff on the mAP at .5 IOU metric. You can tell \\(YOLOv3\\) is good because it\u2019s very high and far to the left. Can you cite your own paper? Guess who\u2019s going to try, this guy ! [16]. Oh, I forgot, we also fix a data loading bug in YOLOv2, that helped by like 2 mAP. Just sneaking this in here to not throw off layout. \u56fe3. \u518d\u6b21\u6539\u7f16\u81ea[9]\uff0c\u8fd9\u6b21\u663e\u793a\u7684\u662f\u5728 \\(0.5 \\ IOU\\) \u6307\u6807\u4e0a\u901f\u5ea6/\u51c6\u786e\u5ea6\u7684\u6743\u8861\u3002\u4f60\u53ef\u4ee5\u8bf4 \\(YOLOv3\\) \u662f\u597d\u7684\uff0c\u56e0\u4e3a\u5b83\u975e\u5e38\u9ad8\u5e76\u4e14\u5728\u5de6\u8fb9\u5f88\u8fdc\u3002 \u4f60\u80fd\u5f15\u7528\u4f60\u81ea\u5df1\u7684\u8bba\u6587\u5417\uff1f\u731c\u731c\u8c01\u4f1a\u53bb\u5c1d\u8bd5\uff0c\u8fd9\u4e2a\u4eba\u2192[16]\u3002\u54e6\uff0c\u6211\u5fd8\u4e86\uff0c\u6211\u4eec\u8fd8\u4fee\u590d\u4e86YOLOv2\u4e2d\u7684\u6570\u636e\u52a0\u8f7dbug\uff0c\u8be5bug\u7684\u4fee\u590d\u63d0\u5347\u4e862 mAP, \u53ea\u662f\u5728\u8fd9\u91cc\u5077\u5077\u63d0\u4e00\u4e0b\uff0c\u8fd9\u4e0d\u662f\u91cd\u70b9\u3002 \u2003\u5728\u4e4b\u524d\u7684 \\(YOLO\\) \u4e0d\u64c5\u957f\u68c0\u6d4b\u5c0f\u7269\u4f53\u3002\u4f46\u662f\uff0c\u73b0\u5728\u6211\u4eec\u770b\u5230\u4e86\u8fd9\u79cd\u8d8b\u52bf\u7684\u9006\u8f6c\u3002\u968f\u7740\u65b0\u7684\u591a\u5c3a\u5ea6\u9884\u6d4b\uff0c\u6211\u4eec\u770b\u5230 \\(YOLOv3\\) \u5177\u6709\u76f8\u5bf9\u8f83\u9ad8\u7684 \\(APS\\) \u6027\u80fd\u3002\u4f46\u662f\uff0c\u5b83\u5728\u4e2d\u578b\u548c\u5927\u578b\u7269\u4f53\u68c0\u6d4b\u4e0a\u7684\u6027\u80fd\u8fd8\u76f8\u5bf9\u8f83\u5dee\u3002\u8fd9\u53ef\u80fd\u9700\u8981\u66f4\u591a\u7684\u8c03\u7814\u548c\u5b9e\u9a8c\u624d\u80fd\u77e5\u9053\u5982\u4f55\u53bb\u6539\u8fdb\u8fd9\u4e00\u70b9\u3002 \u2003\u5f53\u6211\u4eec\u5728 \\(AP50\\) \u6307\u6807\u4e0a\u7ed8\u5236\u51c6\u786e\u5ea6\u548c\u901f\u5ea6\u5173\u7cfb\u56fe\u65f6\uff08\u8bf7\u89c1\u56fe3\uff09\uff0c\u6211\u4eec\u770b\u5230 \\(YOLOv3\\) \u4e0e\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\u5177\u6709\u663e\u7740\u7684\u4f18\u52bf\u3002\u4e5f\u5c31\u662f\u8bf4 \\(YOLOv3\\) \uff0c\u901f\u5ea6\u66f4\u5feb\u3001\u6027\u80fd\u66f4\u597d\u3002 4 \u5931\u8d25\u7684\u5c1d\u8bd5 \u2003\u6211\u4eec\u5728\u5b9e\u73b0 \\(YOLOv3\\) \u7684\u8fc7\u7a0b\u4e2d\u5c1d\u8bd5\u4e86\u5f88\u591a\u4e1c\u897f\uff0c\u4f46\u662f\u5f88\u591a\u90fd\u5931\u8d25\u4e86\uff0c\u4ee5\u4e0b\u662f\u6211\u4eec\u8fd8\u8bb0\u5f97\u7684\u4e00\u4e9b\u5931\u8d25\u7684\u5c1d\u8bd5\u3002 \u2003 Anchor\u6846\u7684x\u3001y\u504f\u79fb\u9884\u6d4b \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528\u5e38\u89c4\u7684Anchor\u6846\u9884\u6d4b\u673a\u5236\uff0c\u6bd4\u5982\u5229\u7528\u7ebf\u6027\u6fc0\u6d3b\u5c06\u5750\u6807x\u3001y\u7684\u504f\u79fb\u7a0b\u5ea6\u9884\u6d4b\u4e3a\u8fb9\u754c\u6846\u5bbd\u5ea6\u6216\u9ad8\u5ea6\u7684\u500d\u6570\u3002\u4f46\u6211\u4eec\u53d1\u73b0\u8fd9\u79cd\u65b9\u6cd5\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u4e14\u6548\u679c\u4e0d\u4f73\u3002 \u2003 \u7528\u7ebf\u6027\u6fc0\u6d3b\u4ee3\u66ff\u903b\u8f91\u6fc0\u6d3b\u51fd\u6570\u8fdb\u884cx\u3001y\u9884\u6d4b \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u4ee3\u66ff\u903b\u8f91\u6fc0\u6d3b\u6765\u76f4\u63a5\u9884\u6d4bx\u3001y\u504f\u79fb\u3002\u8fd9\u4e2a\u6539\u53d8\u5bfc\u81f4mAP\u4e0b\u964d\u4e86\u51e0\u4e2a\u70b9\u3002 \u2003 focal loss \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528focal loss\u3002\u5b83\u4f7f\u5f97mAP\u4e0b\u964d2\u4e2a\u70b9\u3002 \\(YOLOv3\\) \u53ef\u80fd\u5df2\u7ecf\u5bf9focal loss \u8bd5\u56fe\u89e3\u51b3\u7684\u95ee\u9898\u5177\u6709\u76f8\u5f53\u7684\u9c81\u68d2\u6027\uff0c\u56e0\u4e3a\u5b83\u5177\u6709\u5355\u72ec\u7684\u76ee\u6807\u9884\u6d4b\u548c\u6761\u4ef6\u7c7b\u522b\u9884\u6d4b\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u5927\u591a\u6570\u6837\u672c\u6765\u8bf4\uff0c\u7c7b\u522b\u9884\u6d4b\u6ca1\u6709\u635f\u5931\uff1f\u6216\u8005\u6709\u4e00\u4e9b\uff1f\u6211\u4eec\u5e76\u4e0d\u5b8c\u5168\u786e\u5b9a\u3002 \u2003 \u53ccIOU\u9608\u503c\u548c\u771f\u503c\u5206\u914d \u3002 \\(Faster \\ R-CNN\\) \u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528\u4e24\u4e2a \\(IOU\\) \u9608\u503c\u3002\u5982\u679c\u4e00\u4e2a\u9884\u6d4b\u4e0e\u771f\u5b9e\u6807\u7b7e\u6846\u91cd\u53e0\u8d85\u8fc7 \\(0.7\\) \uff0c\u5b83\u5c31\u662f\u4e00\u4e2a\u6b63\u6837\u672c\uff0c\u82e5\u91cd\u53e0\u5728 \\([0.3\uff0c0.7]\\) \u4e4b\u95f4\uff0c\u90a3\u4e48\u5b83\u4f1a\u88ab\u5ffd\u7565\uff0c\u82e5\u5b83\u4e0e\u6240\u6709\u7684\u771f\u5b9e\u6807\u7b7e\u6846\u7684 \\(IOU\\) \u5c0f\u4e8e0.3\uff0c\u90a3\u4e48\u5c31\u4f1a\u88ab\u5224\u5b9a\u4e3a\u4e00\u4e2a\u8d1f\u6837\u672c\u3002\u6211\u4eec\u5c1d\u8bd5\u4e86\u7c7b\u4f3c\u7684\u7b56\u7565\uff0c\u4f46\u6700\u7ec8\u7684\u6548\u679c\u5e76\u4e0d\u597d\u3002 \u2003\u6211\u4eec\u975e\u5e38\u559c\u6b22\u76ee\u524d\u7684\u6a21\u578b\uff0c\u5b83\u81f3\u5c11\u5728\u5c40\u90e8\u8fbe\u5230\u4e86\u6700\u4f73\u3002\u4e0a\u8ff0\u7684\u6709\u4e9b\u6280\u672f\u53ef\u80fd\u4f1a\u4f7f\u6211\u4eec\u7684\u6a21\u578b\u66f4\u597d\uff0c\u4f46\u6211\u4eec\u53ef\u80fd\u8fd8\u9700\u8981\u5bf9\u4ed6\u4eec\u505a\u4e00\u4e9b\u8c03\u6574\u3002 5 \u8fd9\u4e00\u5207\u610f\u5473\u7740\u4ec0\u4e48 \u2003 \\(YOLOv3\\) \u662f\u4e00\u4e2a\u5f88\u68d2\u7684\u68c0\u6d4b\u5668\uff0c\u5b83\u7531\u51c6\u53c8\u5feb\u3002\u867d\u7136\u5b83\u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\uff0c0.3\u548c0.95 IOU \u4e0b\u7684\u5e73\u5747AP\u5e76\u4e0d\u597d\uff0c\u4f46\u5728\u65e7\u7684 0.5 IOU\u7684\u68c0\u6d4b\u6307\u6807\u4e0b\uff0c\u5b83\u8fd8\u662f\u975e\u5e38\u4e0d\u9519\u7684\u3002 \u2003 \u4e3a\u4ec0\u4e48\u6211\u4eec\u8981\u6539\u53d8\u6307\u6807\uff1f \\(COCO\\) \u7684\u539f\u8bba\u6587\u6709\u8fd9\u6837\u4e00\u53e5\u542b\u7cca\u4e0d\u6e05\u7684\u53e5\u5b50\uff1a \\(\u201cA \\ full \\ discussion \\ of \\ evaluation \\ metrics \\ will \\ be \\ added \\ once \\ the \\ evaluation \\ server \\ is \\ complete\u201d\\) \u3002Russakovsky\u7b49\u4eba\u7684\u62a5\u544a\u4e2d\u8bf4\uff0c\u4eba\u4eec\u5f88\u96be\u533a\u52060.3\u548c0.5\u7684IOU\u3002\u201c\u8bad\u7ec3\u4eba\u7c7b\u7528\u89c6\u89c9\u68c0\u67e50.3 IOU\u7684\u8fb9\u754c\u6846\uff0c\u5e76\u4e14\u4e0e0.5 IOU\u7684\u6846\u533a\u522b\u5f00\u6765\u662f\u975e\u5e38\u56f0\u96be\u7684\u3002\u201c[16]\u5982\u679c\u4eba\u7c7b\u5f88\u96be\u8bf4\u51fa\u5dee\u5f02\uff0c\u90a3\u4e48\u5b83\u4e5f\u6ca1\u6709\u591a\u91cd\u8981\u5427\uff1f \u2003\u4e5f\u8bb8\u6709\u4e2a\u66f4\u597d\u7684\u95ee\u9898\u503c\u5f97\u6211\u4eec\u63a2\u8ba8\u201c\u6211\u4eec\u7528\u5b83\u6765\u5e72\u4ec0\u4e48\u201d\u8bb8\u591a\u4ece\u4e8b\u8fd9\u9879\u7814\u7a76\u7684\u4eba\u90fd\u5728Google\u548cFacebook\uff0c\u6211\u60f3\u81f3\u5c11\u6211\u4eec\u77e5\u9053\u8fd9\u4e2a\u6280\u672f\u662f\u638c\u63e1\u5728\u597d\u4eba\u624b\u91cc\uff0c\u7edd\u5bf9\u4e0d\u4f1a\u628a\u5b83\u7528\u6765\u6536\u96c6\u4f60\u7684\u4e2a\u4eba\u4fe1\u606f\u7136\u540e\u5356\u7ed9\u2026\u2026\u7b49\u7b49\uff0c\u4f60\u7a76\u7adf\u60f3\u7528\u5b83\u6765\u5e72\u561b\uff01\uff01\u5662\u3002 \u2003\u5176\u4ed6\u82b1\u5927\u94b1\u8d44\u52a9\u89c6\u89c9\u7814\u7a76\u7684\u4eba\u8fd8\u6709\u519b\u65b9\uff0c\u4ed6\u4eec\u4ece\u6765\u6ca1\u6709\u505a\u8fc7\u4efb\u4f55\u53ef\u6015\u7684\u4e8b\u60c5\uff0c\u4f8b\u5982\u7528\u65b0\u6280\u672f\u6740\u6b7b\u5f88\u591a\u4eba\uff0c\u7b49\u7b49..... \u6211\u5f3a\u70c8\u5730\u5e0c\u671b\uff0c\u5927\u591a\u6570\u4f7f\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u4eba\u90fd\u7528\u5b83\u6765\u505a\u4e00\u4e9b\u5feb\u4e50\u4e14\u6709\u76ca\u7684\u4e8b\u60c5\uff0c\u6bd4\u5982\u8ba1\u7b97\u4e00\u4e2a\u56fd\u5bb6\u516c\u56ed\u91cc\u6591\u9a6c\u7684\u6570\u91cf[13]\uff0c\u6216\u8005\u8ffd\u8e2a\u5728\u9644\u8fd1\u5f98\u5f8a\u7684\u732b[19]\u3002\u4f46\u8ba1\u7b97\u673a\u89c6\u89c9\u5df2\u7ecf\u88ab\u7528\u4e8e\u503c\u5f97\u6000\u7591\u7684\u7528\u9014\uff0c\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\uff0c\u6211\u4eec\u6709\u8d23\u4efb\u8003\u8651\u6211\u4eec\u7684\u5de5\u4f5c\u53ef\u80fd\u9020\u6210\u7684\u635f\u5bb3\uff0c\u5e76\u601d\u8003\u5982\u4f55\u51cf\u8f7b\u5b83\u7684\u5f71\u54cd\u3002\u6211\u4eec\u6b20\u8fd9\u4e2a\u4e16\u754c\u592a\u591a\u3002 \u6700\u540e\uff0c\u4e0d\u8981\u518d@\u6211\u4e86\u3002\uff08\u56e0\u4e3a\u6211\u5df2\u7ecf\u9000\u51faTwitter\u8fd9\u4e2a\u662f\u975e\u4e4b\u5730\u4e86\uff09\u3002 In closing, do not@me. (Because I finally quit Twitter). References [1] Analogy. Wikipedia, Mar 2018. 1 [2] M. Everingham, L. V an Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) challenge. International journal of computer vision, 88(2):303\u2013 338, 2010. 6 [3] C.-Y . Fu, W. Liu, A. Ranga, A. Tyagi, and A. C. Berg. Dssd: Deconvolutional single shot detector. arXiv preprint arXiv:1701.06659, 2017. 3 [4] D. Gordon, A. Kembhavi, M. Rastegari, J. Redmon, D. Fox, and A. Farhadi. Iqa: Visual question answering in interactive environments. arXiv preprint arXiv:1712.03316, 2017. 1 [5] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016. 3 [6] J. Huang, V . Rathod, C. Sun, M. Zhu, A. Korattikara, A. Fathi, I. Fischer, Z. Wojna, Y . Song, S. Guadarrama, et al Speed/accuracy trade-offs for modern convolutional object detectors. 3 [7] I. Krasin, T. Duerig, N. Alldrin, V . Ferrari, S. Abu-El-Haija, A. Kuznetsova, H. Rom, J. Uijlings, S. Popov, A. V eit, S. Belongie, V . Gomes, A. Gupta, C. Sun, G. Chechik, D. Cai, Z. Feng, D. Narayanan, and K. Murphy. Openimages: A public dataset for large-scale multi-label and multi-class image classification. Dataset available from https://github.com/openimages, 2017. 2 [8] T.-Y . Lin, P . Dollar, R. Girshick, K. He, B. Hariharan, and S. Belongie. Feature pyramid networks for object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2117\u20132125, 2017. 2, 3 [9] T.-Y . Lin, P . Goyal, R. Girshick, K. He, and P . Doll\u00e1r. Focal loss for dense object detection. arXiv preprint arXiv:1708.02002, 2017. 1, 3, 4 [10] T.-Y . Lin, M. Maire, S. Belongie, J. Hays, P . Perona, D. Ramanan, P . Doll\u00e1r, and C. L. Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision, pages 740\u2013755. Springer, 2014. 2 [11] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.Y . Fu, and A. C. Berg. Ssd: Single shot multibox detector. In European conference on computer vision, pages 21\u201337. Springer, 2016. 3 [12] I. Newton. Philosophiae naturalis principia mathematica. William Dawson & Sons Ltd., London, 1687. 1 [13] J. Parham, J. Crall, C. Stewart, T. Berger-Wolf, and D. Rubenstein. Animal population censusing at scale with citizen science and photographic identification. 2017. 4 [14] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 3 [15] J. Redmon and A. Farhadi. Y olo9000: Better, faster, stronger. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pages 6517\u20136525. IEEE, 2017. 1, 2, 3 [16] J. Redmon and A. Farhadi. Y olov3: An incremental improvement. arXiv, 2018. 4 [17] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497, 2015. 2 [18] O. Russakovsky, L.-J. Li, and L. Fei-Fei. Best of both worlds: human-machine collaboration for object annotation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2121\u20132131, 2015. 4 [19] M. Scott. Smart camera gimbal bot scanlime:027, Dec 2017. 4 [20] A. Shrivastava, R. Sukthankar, J. Malik, and A. Gupta. Be- yond skip connections: Top-down modulation for object de- tection. arXiv preprint arXiv:1612.06851, 2016. 3 [21] C. Szegedy, S. Ioffe, V . V anhoucke, and A. A. Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. 2017. 3","title":"YOLOv3"},{"location":"thesis_interpretation/03_yolo.html#_1","text":"\u6211\u4eec\u5bf9YOLO\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u66f4\u65b0\uff01\u5b83\u5305\u542b\u4e00\u5806\u5c0f\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u4f7f\u7cfb\u7edf\u7684\u6027\u80fd\u5f97\u5230\u66f4\u65b0\u3002\u6211\u4eec\u4e5f\u8bad\u7ec3\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u6bd4\u8f83\u5927\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u867d\u7136\u6bd4\u4e0a\u4e00\u7248\u66f4\u5927\u4e00\u4e9b\uff0c\u4f46\u662f\u7cbe\u5ea6\u4e5f\u63d0\u9ad8\u4e86\u3002\u4e0d\u7528\u62c5\u5fc3\uff0c\u5b83\u7684\u901f\u5ea6\u4f9d\u7136\u5f88\u5feb\u3002 \\(YOLOv3\\) \u5728 \\(320\u00d7320\\) \u8f93\u5165\u56fe\u50cf\u4e0a\u8fd0\u884c\u65f6\u53ea\u9700 \\(22ms\\) \uff0c\u5e76\u80fd\u8fbe\u5230 \\(28.2mAP\\) \uff0c\u5176\u7cbe\u5ea6\u548c \\(SSD\\) \u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u8981\u5feb\u4e0a \\(3\\) \u500d\u3002\u4f7f\u7528\u4e4b\u524d \\(0.5 \\ IOU \\ mAP\\) \u7684\u68c0\u6d4b\u6307\u6807\uff0c \\(YOLOv3\\) \u7684\u6548\u679c\u662f\u76f8\u5f53\u4e0d\u9519\u3002 \\(YOLOv3\\) \u4f7f\u7528Titan X GPU\uff0c\u5b83\u5728 \\(51ms\\) \u68c0\u6d4b\u7cbe\u5ea6\u8fbe\u5230 \\(57.9 \\ AP50\\) \uff0c\u7136\u800c\u4e0e \\(RetinaNet\\) \u76f8\u6bd4 \uff0c\u5176\u7cbe\u5ea6\u53ea\u6709 \\(57.5 \\ AP50\\) \uff0c\u4f46\u5374\u8017\u65f6 \\(198ms\\) \uff0c\u76f8\u540c\u6027\u80fd\u7684\u60c5\u51b5\u4e0b \\(YOLOv3\\) \u901f\u5ea6\u6bd4 \\(RetinaNet\\) \u5feb \\(3.8\\) \u500d\u3002\u4e0e\u4e4b\u524d\u4e00\u6837\uff0c\u6240\u6709\u4ee3\u7801\u5728\u7f51\u5740\uff1ahttps://pjreddie.com/yolo/\u3002","title":"\u6458\u8981"},{"location":"thesis_interpretation/03_yolo.html#1","text":"\u6709\u65f6\u5019\uff0c\u4e00\u5e74\u5185\u4f60\u4e3b\u8981\u90fd\u5728\u73a9\u624b\u673a\uff0c\u4f60\u77e5\u9053\u5417\uff1f\u4eca\u5e74\u6211\u6ca1\u6709\u505a\u5f88\u591a\u7814\u7a76\u3002\u6211\u5728 \\(Twitter\\) \u4e0a\u82b1\u4e86\u5f88\u591a\u65f6\u95f4,\u5728GANs\u4e0a\u73a9\u4e86\u70b9\u5c0f\u6e38\u620f\u3002\u53bb\u5e74\u6211\u7559\u4e0b\u4e86\u4e00\u70b9\u70b9\u7684\u7cbe\u529b [12] [1]\uff1b\u6211\u8bbe\u6cd5\u5bf9 \\(YOLO\\) \u8fdb\u884c\u4e86\u4e00\u4e9b\u6539\u8fdb\u3002\u4f46\u662f\uff0c\u5b9e\u8bdd\u5b9e\u8bf4\uff0c\u4ec5\u4ec5\u4e00\u4e9b\u5c0f\u7684\u6539\u53d8\u4f7f\u5f97\u5b83\u53d8\u5f97\u66f4\u597d\uff0c\u6ca1\u6709\u4ec0\u4e48\u8d85\u7ea7\u6709\u8da3\u7684\u4e8b\u60c5\u3002\u6211\u4e5f\u7a0d\u5fae\u5e2e\u52a9\u4e86\u5176\u4ed6\u4eba\u7684\u4e00\u4e9b\u7814\u7a76\u3002 \u2003\u4e8b\u5b9e\u4e0a\uff0c\u8fd9\u5c31\u662f\u6211\u4eec\u4eca\u5929\u6765\u8fd9\u91cc\u7684\u539f\u56e0\u3002\u6211\u4eec\u6709\u4e00\u7bc7\u8bba\u6587\u5feb\u622a\u7a3f\u4e86\uff0c\u5e76\u4e14\u6211\u4eec\u8fd8\u7f3a\u4e00\u7bc7\u5173\u4e8e \\(YOLO\\) \u66f4\u65b0\u5185\u5bb9\u7684\u6587\u7ae0\u4f5c\u4e3a\u5f15\u7528\uff0c\u4f46\u662f\u6211\u4eec\u6ca1\u6709\u5f15\u7528\u6765\u6e90\u3002\u6240\u4ee5\uff0c\u51c6\u5907\u597d\u8fce\u63a5\u79d1\u6280\u62a5\u9053\u5427! \u2003\u6280\u672f\u62a5\u544a\u6700\u68d2\u7684\u4e00\u70b9\u5c31\u662f\u4ed6\u4eec\u4e0d\u9700\u8981\u4ecb\u7ecd\uff0c\u4f60\u4eec\u90fd\u77e5\u9053\u6211\u4eec\u4e3a\u4ec0\u4e48\u5728\u8fd9\u91cc\u3002\u56e0\u6b64\uff0c\u8fd9\u7bc7\u4ecb\u7ecd\u7684\u7ed3\u5c3e\u5c06\u4e3a\u672c\u6587\u7684\u5176\u4f59\u90e8\u5206\u6307\u660e\u65b9\u5411\u3002\u9996\u5148\u6211\u4eec\u4f1a\u544a\u8bc9\u4f60 \\(YOLOv3\\) \u7684\u65b9\u6848\u3002\u5176\u6b21\u6211\u4eec\u4f1a\u544a\u8bc9\u4f60\u6211\u4eec\u662f\u5982\u4f55\u5b9e\u73b0\u7684\u3002\u6211\u4eec\u4e5f\u4f1a\u544a\u8bc9\u4f60\u6211\u4eec\u5c1d\u8bd5\u8fc7\u4f46\u5e76\u4e0d\u594f\u6548\u7684\u4e00\u4e9b\u4e8b\u60c5\u3002\u6700\u540e\u6211\u4eec\u5c06\u63a2\u8ba8\u8fd9\u4e9b\u7684\u610f\u4e49\u3002","title":"1.\u5f15\u8a00"},{"location":"thesis_interpretation/03_yolo.html#2","text":"\u8fd9\u8282\u4e3b\u8981\u4ecb\u7ecd \\(YOLOv3\\) \u7684\u66f4\u65b0\u65b9\u6848\uff1a\u6211\u4eec\u4e3b\u8981\u4ece\u5176\u4ed6\u4eba\u7684\u7814\u7a76\u5de5\u4f5c\u91cc\u83b7\u5f97\u4e86\u4e00\u4e9b\u597d\u601d\u8def\u3001\u597d\u60f3\u6cd5\u3002\u6211\u4eec\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u6bd4\u5176\u4ed6\u7f51\u7edc\u66f4\u597d\u7684\u5206\u7c7b\u7f51\u7edc\u3002\u4e3a\u4e86\u65b9\u4fbf\u7406\u89e3\uff0c\u8ba9\u6211\u4eec\u4ece\u5934\u5f00\u59cb\u6162\u6162\u4ecb\u7ecd\u6574\u4e2a\u6a21\u578b\u7cfb\u7edf\u3002 \u56fe1. \u6e90\u81ea \\(Focal \\ Loss\\) \u8bba\u6587[9]\u3002 \\(YOLOv3\\) \u7684\u8fd0\u884c\u901f\u5ea6\u660e\u663e\u5feb\u4e8e\u5176\u4ed6\u6027\u80fd\u76f8\u5f53\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002\u68c0\u6d4b\u65f6\u95f4\u57fa\u4e8e \\(M40\\) \u6216 \\(Titan \\ X\\) \uff08 \u5176\u4e2d \\(M40,Titan X\\) \u662f\u76f8\u4f3c\u7684\u4e24\u79cd \\(GPU\\) \uff09\u3002","title":"2.\u65b9\u6848"},{"location":"thesis_interpretation/03_yolo.html#21","text":"\u548c \\(YOLO9000\\) \u4e00\u6837\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u4e5f\u4f7f\u7528\u7ef4\u5ea6\u805a\u7c7b\u7b97\u6cd5\u751f\u6210\u7684\u951a\u6846\uff08 anchor boxes \uff09[15] \u6765\u9884\u6d4b\u8fb9\u754c\u6846\u3002\u7f51\u7edc\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u76844\u4e2a\u5750\u6807\uff1a \\(t_x\u3001t_y\u3001t_w\u3001t_h\\) \u3002\u5047\u8bbe\u683c\u5b50\u8ddd\u79bb\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u504f\u79fb\u91cf\u4e3a \\((c_x\uff0cc_y)\\) \uff0c\u4e14\u4e4b\u524d\u7684\u8fb9\u754c\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e3a \\(p_w, p_h\\) \uff0c\u5219\u9884\u6d4b\u7ed3\u679c: \\[ {\\large \\begin{align} b_{x} & = \\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} & = \\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} & = p_{w} e^{t_{w}} \\\\ b_{h} & = p_{h} e^{t_{h}} \\end{align}} \\] \u2003\u5728\u8bad\u7ec3\u4e2d\u6211\u4eec\u4f7f\u7528\u8bef\u5dee\u5e73\u65b9\u548c\u635f\u5931\u8ba1\u7b97\u3002\u5982\u679c\u67d0\u4e2a\u9884\u6d4b\u5750\u6807\u7684 \\(ground \\ truth\\) \u662f \\(\\hat{t}_*\\) \uff0c\u90a3\u4e48\u5bf9\u5e94\u7684\u68af\u5ea6\u5c31\u662f \\(ground \\ truth \\ value\\) \uff08\u7531 \\(ground \\ truth \\ box\\) \u8ba1\u7b97\u800c\u5f97\uff09\u548c\u9884\u6d4b\u503c\u4e4b\u5dee\uff1a \\(\\hat{t}_* - t_*\\) \u3002\u901a\u8fc7\u53d8\u6362\u4e0a\u8ff0\u516c\u5f0f\u8ba1\u7b97,\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5f97\u5230 \\(ground \\ truth \\ value\\) \u3002 \u56fe2\uff1a \u7ef4\u5ea6\u5148\u9a8c\u548c\u4f4d\u7f6e\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u3002 \\(\\large{\\sigma(t_x)}\\) , \\(\\large{\\sigma(t_y)}\\) \u662f\u57fa\u4e8e\u77e9\u5f62\u6846\u4e2d\u5fc3\u70b9\u5de6\u4e0a\u89d2\u683c\u70b9\u5750\u6807\u7684\u504f\u79fb\u91cf\uff0c \\(\\large{\\sigma}\\) \u662f\u6fc0\u6d3b\u51fd\u6570\uff0c\u8bba\u6587\u4e2d\u4f5c\u8005\u4f7f\u7528 sigmoid [15]\u3002 \\(\\large{P_w,P_h}\\) \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u3001\u9ad8\uff0c\u901a\u8fc7\u4e0a\u8ff0\u516c\u5f0f\uff0c\u8ba1\u7b97\u51fa\u5b9e\u9645\u9884\u6d4b\u6846\u7684\u5bbd\u9ad8 \u3002 \u2003 \\(YOLOv3\\) \u4f7f\u7528\u903b\u8f91\u56de\u5f52\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u662f\u76ee\u6807\u7684\u5206\u6570\u3002\u5982\u679c\u771f\u5b9e\u6807\u7b7e\u6846\u4e0e\u67d0\u4e2a\u8fb9\u754c\u6846\u91cd\u53e0\u7684\u9762\u79ef\u6bd4\u4e0e\u5176\u4ed6\u4efb\u4f55\u8fb9\u754c\u6846\u90fd\u5927\uff0c\u90a3\u4e48\u8fd9\u4e2a\u5148\u9a8c\u8fb9\u754c\u6846\u5f97\u5206\u4e3a1\u3002\u6309\u7167[17]\u7684\u505a\u6cd5\uff0c\u5982\u679c\u5148\u9a8c\u8fb9\u754c\u6846\u4e0d\u662f\u6700\u597d\u7684\uff0c\u4f46\u662f\u786e\u5b9e\u4e0e\u76ee\u6807\u7684\u771f\u5b9e\u6807\u7b7e\u6846\u91cd\u53e0\u7684\u9762\u79ef\u5927\u4e8e\u9608\u503c\uff0c\u6211\u4eec\u4e5f\u4f1a\u5ffd\u7565\u8fd9\u4e2a\u9884\u6d4b\u3002\u6211\u4eec\u4f7f\u7528\u9608\u503c\u4e3a0.5\u3002\u4e0e[17]\u4e0d\u540c\u7684\u662f\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u53ea\u4e3a\u6bcf\u4e2a\u771f\u5b9e\u76ee\u6807\u5206\u914d\u4e00\u4e2a\u8fb9\u754c\u6846\u3002\u5982\u679c\u5148\u9a8c\u8fb9\u754c\u6846\u672a\u5206\u914d\u5230\u771f\u5b9e\u76ee\u6807\uff0c\u5219\u4e0d\u4f1a\u4ea7\u751f\u5750\u6807\u6216\u7c7b\u522b\u9884\u6d4b\u7684\u635f\u5931\uff0c\u53ea\u4f1a\u4ea7\u751f\u662f\u5426\u662f\u76ee\u6807\u7684\u635f\u5931\u3002","title":"2.1 \u8fb9\u754c\u6846\u9884\u6d4b"},{"location":"thesis_interpretation/03_yolo.html#22","text":"\u6bcf\u4e2a\u8fb9\u754c\u6846\u90fd\u4f1a\u4f7f\u7528\u591a\u6807\u7b7e\u5206\u7c7b\u6765\u9884\u6d4b\u6846\u4e2d\u53ef\u80fd\u5305\u542b\u7684\u7c7b\u3002\u6211\u4eec\u4e0d\u7528 \\(softmax\\) \uff0c\u800c\u662f\u7528\u5355\u72ec\u7684\u903b\u8f91\u5206\u7c7b\u5668\uff0c\u56e0\u4e3a\u6211\u4eec\u53d1\u73b0\u524d\u8005\u5bf9\u4e8e\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u6ca1\u4ec0\u4e48\u4f5c\u7528\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u7528binary cross-entropy\uff08\u4e8c\u5143\u4ea4\u53c9\u71b5\uff09\u635f\u5931\u6765\u9884\u6d4b\u7c7b\u522b\u3002 \u2003\u5f53\u6211\u4eec\u8f6c\u5411\u66f4\u590d\u6742\u7684\u9886\u57df\uff0c\u4f8b\u5982 \\(Open \\ Images \\ Dataset\\) [7]\uff0c\u4e0a\u9762\u7684\u8fd9\u79cd\u6539\u53d8\u5c06\u53d8\u5f97\u5f88\u6709\u7528\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u4e2d\u6709\u8bb8\u591a\u91cd\u53e0\u7684\u6807\u7b7e\uff08\u4f8b\u5982\u5973\u6027\u548c\u4eba\uff09\u3002\u4f7f\u7528 \\(softmax\\) \u4f1a\u5047\u5b9a\u6bcf\u4e2a\u6846\u53ea\u5305\u542b\u4e00\u4e2a\u7c7b\uff0c\u4f46\u901a\u5e38\u60c5\u51b5\u5e76\u975e\u5982\u6b64\u3002\u591a\u6807\u7b7e\u7684\u65b9\u5f0f\u53ef\u4ee5\u66f4\u597d\u5730\u5bf9\u6570\u636e\u8fdb\u884c\u5efa\u6a21\u3002","title":"2.2 \u5206\u7c7b\u9884\u6d4b"},{"location":"thesis_interpretation/03_yolo.html#23","text":"\\(YOLOv3\\) \u5728 3 \u79cd\u4e0d\u540c\u5c3a\u5ea6\u4e0a\u9884\u6d4b\u6846\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u4f7f\u7528\u7c7b\u4f3c\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc\u7684\u76f8\u4f3c\u6982\u5ff5( \u8be6\u7ec6\u53ef\u89c1\u8bba\u6587\uff1ahttps://arxiv.org/pdf/1612.03144.pdf )\uff0c\u5e76\u4ece\u8fd9\u4e9b\u5c3a\u5ea6\u4e2d\u63d0\u53d6\u7279\u5f81[8]\u3002\u6211\u4eec\u5728\u57fa\u7840\u7279\u5f81\u63d0\u53d6\u5668\u4e0a\u6dfb\u52a0\u4e86\u51e0\u4e2a\u5377\u79ef\u5c42\u3002\u5176\u4e2d\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42 \u9884\u6d4b\u4e86\u4e00\u4e2a\u7f16\u7801\u8fb9\u754c\u6846\u3001\u662f\u5426\u662f\u76ee\u6807\u548c\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c \u7684\u4e09\u7ef4\u5f20\u91cf\u3002\u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c[8]\u4e2d\uff0c\u6211\u4eec\u4e3a\u6bcf\u4e2a\u5c3a\u5ea6\u9884\u6d4b3\u4e2a\u6846\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u8fb9\u754c\u6846\u6709 4\u4e2a\u504f\u79fb\u91cf\u30011\u4e2a\u76ee\u6807\u9884\u6d4b\u548c80\u4e2a\u7c7b\u522b\u9884\u6d4b\uff0c\u6700\u7ec8\u7684\u5f20\u91cf\u5927\u5c0f\u4e3a \\(N\u00d7N\u00d7[3\u00d7(4+1+80)]\\) \u3002 \u2003\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4ece\u524d\u9762\u76842\u4e2a\u5c42\u4e2d\u63d0\u53d6\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u5176\u4e0a\u91c7\u68372\u500d\u3002\u6211\u4eec\u8fd8\u4ece\u7f51\u7edc\u4e2d\u7684\u8f83\u524d\u7684\u5c42\u4e2d\u83b7\u53d6\u4e00\u4e2a\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u5176\u4e0e\u6211\u4eec\u7684\u4e0a\u91c7\u6837\u7279\u5f81\u56fe\u8fdb\u884c\u62fc\u63a5\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u6211\u4eec\u80fd\u591f\u4ece\u4e0a\u91c7\u6837\u7684\u7279\u5f81\u56fe\u4e2d\u83b7\u5f97\u66f4\u6709\u610f\u4e49\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u540c\u65f6\u53ef\u4ee5\u4ece\u66f4\u524d\u7684\u5c42\u4e2d\u83b7\u53d6\u66f4\u7ec6\u7c92\u5ea6\u7684\u4fe1\u606f\u3002\u7136\u540e\uff0c\u6211\u4eec\u6dfb\u52a0\u51e0\u4e2a\u5377\u79ef\u5c42\u6765\u5904\u7406\u8fd9\u4e2a\u7279\u5f81\u6620\u5c04\u7ec4\u5408\uff0c\u5e76\u6700\u7ec8\u9884\u6d4b\u51fa\u4e00\u4e2a\u76f8\u4f3c\u7684\u3001\u5927\u5c0f\u662f\u539f\u5148\u4e24\u500d\u7684\u5f20\u91cf\u3002 \u2003\u6211\u4eec\u518d\u6b21\u4f7f\u7528\u76f8\u540c\u7684\u8bbe\u8ba1\u6765\u9884\u6d4b\u6700\u7ec8\u5c3a\u5bf8\u7684\u8fb9\u754c\u6846\u3002\u56e0\u6b64\uff0c\u7b2c\u4e09\u4e2a\u5c3a\u5bf8\u7684\u9884\u6d4b\u5c06\u65e2\u80fd\u4ece\u6240\u6709\u5148\u524d\u7684\u8ba1\u7b97\uff0c\u53c8\u80fd\u4ece\u7f51\u7edc\u524d\u9762\u7684\u5c42\u4e2d\u7684\u7ec6\u7c92\u5ea6\u7684\u7279\u5f81\u4e2d\u83b7\u76ca\u3002 \u2003\u6211\u4eec\u4ecd\u7136\u4f7f\u7528k-means\u805a\u7c7b\u7b97\u6cd5\u6765\u786e\u5b9a\u6211\u4eec\u7684\u5148\u9a8c\u8fb9\u754c\u6846\u3002\u6211\u4eec\u53ea\u662f\u9009\u62e9\u4e869\u4e2a\u805a\u7c7b( clusters )\u548c3\u4e2a\u4efb\u610f\u7684\u5c3a\u5ea6( scales arbitrarily )\uff0c \u7136\u540e\u5728\u5c3a\u5ea6\u4e0a\u5c06\u805a\u7c7b\u5747\u5300\u5730\u5212\u5206\u805a\u7c7b\u3002 \u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\uff0c9\u4e2a\u805a\u7c7b\u5206\u522b \u4e3a \\((10\u00d713)\u3001(16\u00d730)\u3001(33\u00d723)\u3001(30\u00d761)\u3001(62\u00d745)\u3001(59\u00d7119)\u3001(116 \u00d7 90)\u3001(156 \u00d7 198)\u3001(373 \u00d7 326)\\) \u3002","title":"2.3 \u8de8\u5c3a\u5ea6\u9884\u6d4b"},{"location":"thesis_interpretation/03_yolo.html#24","text":"\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u65b0\u7684\u7f51\u7edc\u6765\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002\u6211\u4eec\u7684\u65b0\u7f51\u7edc\u878d\u5408\u4e86 \\(YOLOv2\u3001Darknet-19\\) \u548c\u65b0\u53d1\u660e\u7684\u6b8b\u5dee\u7f51\u7edc\u7684\u601d\u60f3\u3002\u6211\u4eec\u7684\u7f51\u7edc\u4f7f\u7528\u8fde\u7eed\u7684 \\(3\u00d73\\) \u548c \\(1\u00d71\\) \u5377\u79ef\u5c42\u548c\u6dfb\u52a0\u4e86\u4e00\u4e9b\u5feb\u6377\u8fde\u63a5\uff08shortcut connetction\uff09\uff0c\u4ece\u800c\u89c4\u6a21\u66f4\u5927\uff0c\u76ee\u524d\u5b83\u670953\u4e2a\u5377\u79ef\u5c42\uff0c\u6240\u4ee5\u6211\u4eec\u79f0\u4e4b\u4e3a... \\(Darknet-53!\\) \u88681. Darknet-53. \u6211\u4eec\u7684\u7f51\u7edc\u5728\u6027\u80fd\u4e0a\u8fdc\u8d85Darknet-19\uff0c\u5728\u6548\u7387\u4e0a\u4e5f\u4f18\u4e8eResNet-101\u548cResNet-152\u3002\u8fd9\u91cc\u662f\u4e00\u4e9b\u7f51\u7edc\u5728ImageNet\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\uff1a \\[ \\begin{eqnarray} \\text { Backbone } & \\text { Top-1 } & \\text { Top-5 } & \\text { Bn Ops } & \\text { BFLOP/s } & \\text { FPS } \\\\ \\hline \\text { Darknet-19[15] } & 74.1 & 91.8 & 7.29 & 1246 & \\mathbf{1 7 1} \\\\ \\text { ResNet-101[5] } & 77.1 & 93.7 & 19.7 & 1039 & 53 \\\\ \\text { ResNet-152[5] } & \\mathbf{7 7 . 6} & \\mathbf{9 3 . 8} & 29.4 & 1090 & 37 \\\\ \\text { Darknet-53 } & 77.2 & \\mathbf{9 3 . 8} & 18.7 & \\mathbf{1 4 5 7} & 78 \\end{eqnarray} \\] \u88682.\u7f51\u7edc\u7684\u6bd4\u8f83\u3002\u4e0d\u540cbackbones\u7684\u5404\u79cd\u7f51\u7edc\u5728\u51c6\u786e\u5ea6\u3001Bn Ops\uff08\u5341\u4ebf\u64cd\u4f5c\u6570\uff09\u3001BFLOP/s\uff08\u6bcf\u79d2\u5341\u4ebf\u6d6e\u70b9\u64cd\u4f5c\uff09\u548cFPS\u4e0a\u7684\u6bd4\u8f83\u3002 \u2003\u6bcf\u4e2a\u7f51\u7edc\u90fd\u5728\u76f8\u540c\u7684\u914d\u7f6e\u4e0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5747\u7528 \\(256 \u00d7256\\) \u7684\u56fe\u7247\u4e0a\u8fdb\u884c\u5355\u7cbe\u5ea6\u6d4b\u8bd5\u3002\u8fd0\u884c\u65f6\u95f4\u901a\u8fc7\u5728 \\(Titan \\ X\\) \u4e0a\u5904\u7406 \\(256 \u00d7 256\\) \u56fe\u7247\u6d4b\u51fa\u3002\u4ece\u88682\u53ef\u4ee5\u770b\u51fa\uff0c \\(Darknet-53\\) \u4e0d\u4ec5\u7cbe\u5ea6\u53ef\u4ee5\u5ab2\u7f8e\u6700\u5148\u8fdb\u7684\u5206\u7c7b\u5668\uff0c\u800c\u4e14\u5b83\u6709\u8f83\u5c11\u6d6e\u70b9\u8fd0\u7b97\u64cd\u4f5c\uff0c\u66f4\u5feb\u7684\u901f\u5ea6\u3002 \\(Darknet-53\\) \u6bd4 \\(ResNet-101\\) \u6027\u80fd\u66f4\u597d\u800c\u4e14\u8981\u5feb1.5\u500d\u3002 \\(Darknet-53\\) \u6027\u80fd\u4e0e \\(ResNet-152\\) \u76f8\u8fd1\uff0c\u4f46\u662f\u8981\u6bd4\u5b83\u5feb2\u500d\u3002 \u2003 \\(Darknet-53\\) \u4e5f\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u6bcf\u79d2\u6d6e\u70b9\u8fd0\u7b97\u6d4b\u91cf\u3002\u8fd9\u610f\u5473\u7740\u7f51\u7edc\u7ed3\u6784\u53ef\u4ee5\u66f4\u597d\u5730\u5229\u7528GPU\uff0c\u4f7f\u5176\u9884\u6d4b\u6548\u7387\u66f4\u9ad8\uff0c\u901f\u5ea6\u66f4\u5feb\u3002ResNets\u66f4\u6162\uff0c\u5927\u62b5\u662f\u56e0\u4e3a\u5176\u5c42\u6570\u592a\u591a\uff0c\u6240\u4ee5\u4e0d\u662f\u90a3\u4e48\u6709\u6548\u7387\u3002","title":"2.4 \u7279\u5f81\u63d0\u53d6\u5668"},{"location":"thesis_interpretation/03_yolo.html#25","text":"\u6211\u4eec\u4f9d\u65e7\u53ea\u662f\u8bad\u7ec3\u5b8c\u6574\u7684\u56fe\u50cf\uff0c\u6ca1\u6709\u5c06\u96be\u4ee5\u6b63\u786e\u5206\u7c7b\u7684\u6837\u672c\u53cd\u590d\u8bad\u7ec3\uff0c\u4e5f\u6ca1\u6709\u8fdb\u884c\u5176\u4ed6\u4efb\u4f55\u64cd\u4f5c\u3002\u6211\u4eec\u4f7f\u7528\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u4f7f\u7528\u5927\u91cf\u7684\u6570\u636e\u589e\u5f3a\u3001\u6279\u91cf\u6807\u51c6\u5316\u7b49\u6807\u51c6\u7684\u64cd\u4f5c\u3002\u6211\u4eec\u4f7f\u7528 \\(Darknet\\) \u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5[12]\u3002 \\(YOLOv3\\) is pretty good! See table 3. In terms of COCOs weird average mean AP metric it is on par with the SSD variants but is 3\u00d7 faster. It is still quite a bit behind other models like RetinaNet in this metric though. Table 3. I\u2019m seriously just stealing all these tables from [9] they take soooo long to make from scratch. Ok, \\(YOLOv3\\) is doing alright. Keep in mind that RetinaNet has like 3.8\u00d7 longer to process an image. \\(YOLOv3\\) is much better than SSD variants and comparable to state-of-the-art models on the AP50 metric.","title":"2.5 \u8bad\u7ec3"},{"location":"thesis_interpretation/03_yolo.html#3","text":"\\(YOLOv3\\) \u8868\u73b0\u975e\u5e38\u597d\uff01\u8bf7\u770b\u88683\u3002\u5c31COCO\u7684\u5e73\u5747AP\u6307\u6807\u800c\u8a00\uff0c\u5b83\u4e0eSSD\u7c7b\u7684\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u63d0\u9ad8\u4e863\u500d\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u5b83\u4ecd\u7136\u5728\u8fd9\u4e2a\u6307\u6807\u4e0a\u6bd4\u50cfRetinaNet\u8fd9\u6837\u7684\u5176\u4ed6\u6a21\u578b\u5dee\u4e9b\u3002 \u88683.\u6211\u5f88\u8ba4\u771f\u5730\u4ece[9]\u4e2d \\(\u201c\u7a83\u53d6\u201d\\) \u4e86\u4ed6\u4eec\u82b1\u4e86\u5f88\u957f\u65f6\u95f4\u624d\u4ece\u5934\u5f00\u59cb\u5236\u4f5c\u8fd9\u4e9b\u8868\u683c\u3002\u597d\u7684\uff0c \\(YOLOv3\\) \u6ca1\u95ee\u9898\u3002\u8bf7\u8bb0\u4f4f\uff0c \\(RetinaNet\\) \u5904\u7406\u4e00\u5f20\u56fe\u50cf\u7684\u65f6\u95f4\u662f \\(YOLOv3\\) \u7684 \\(3.8\\) \u500d\u3002 \\(YOLOv3\\) \u6bd4 \\(SSD\\) \u8981\u597d\u5f97\u591a\uff0c\u5e76\u4e14\u5728 \\(AP50\\) \u6807\u51c6\u4e0b\u53ef\u4ee5\u4e0e\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5ab2\u7f8e\uff01 \u2003\u7136\u800c\uff0c\u5f53\u6211\u4eec\u4f7f\u7528 \\(\u201c\u65e7\u7684\u201d\\) \u68c0\u6d4b\u6307\u6807\u2014\u2014\u5728 \\(IOU=0.5\u7684mAP\\) \uff08\u6216\u56fe\u8868\u4e2d\u7684 \\(AP50\\) \uff09\u65f6\uff0c \\(YOLOv3\\) \u975e\u5e38\u5f3a\u5927\u3002\u5176\u6027\u80fd\u51e0\u4e4e\u4e0eRetinaNet\u76f8\u5f53\uff0c\u5e76\u4e14\u8fdc\u5f3a\u4e8e \\(SSD\\) \u3002\u8fd9\u8868\u660e \\(YOLOv3\\) \u662f\u4e00\u4e2a\u975e\u5e38\u5f3a\u5927\u7684\u68c0\u6d4b\u5668\uff0c\u64c5\u957f\u4e3a\u76ee\u6807\u751f\u6210\u6070\u5f53\u7684\u6846\u3002\u7136\u800c\uff0c\u968f\u7740 \\(IOU\\) \u9608\u503c\u589e\u52a0\uff0c\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8fd9\u8868\u660e \\(YOLOv3\\) \u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4e0e\u76ee\u6807\u4e0d\u80fd\u5b8c\u7f8e\u5bf9\u9f50\u3002 Figure 3. Again adapted from the [9], this time displaying speed/accuracy tradeoff on the mAP at .5 IOU metric. You can tell \\(YOLOv3\\) is good because it\u2019s very high and far to the left. Can you cite your own paper? Guess who\u2019s going to try, this guy ! [16]. Oh, I forgot, we also fix a data loading bug in YOLOv2, that helped by like 2 mAP. Just sneaking this in here to not throw off layout. \u56fe3. \u518d\u6b21\u6539\u7f16\u81ea[9]\uff0c\u8fd9\u6b21\u663e\u793a\u7684\u662f\u5728 \\(0.5 \\ IOU\\) \u6307\u6807\u4e0a\u901f\u5ea6/\u51c6\u786e\u5ea6\u7684\u6743\u8861\u3002\u4f60\u53ef\u4ee5\u8bf4 \\(YOLOv3\\) \u662f\u597d\u7684\uff0c\u56e0\u4e3a\u5b83\u975e\u5e38\u9ad8\u5e76\u4e14\u5728\u5de6\u8fb9\u5f88\u8fdc\u3002 \u4f60\u80fd\u5f15\u7528\u4f60\u81ea\u5df1\u7684\u8bba\u6587\u5417\uff1f\u731c\u731c\u8c01\u4f1a\u53bb\u5c1d\u8bd5\uff0c\u8fd9\u4e2a\u4eba\u2192[16]\u3002\u54e6\uff0c\u6211\u5fd8\u4e86\uff0c\u6211\u4eec\u8fd8\u4fee\u590d\u4e86YOLOv2\u4e2d\u7684\u6570\u636e\u52a0\u8f7dbug\uff0c\u8be5bug\u7684\u4fee\u590d\u63d0\u5347\u4e862 mAP, \u53ea\u662f\u5728\u8fd9\u91cc\u5077\u5077\u63d0\u4e00\u4e0b\uff0c\u8fd9\u4e0d\u662f\u91cd\u70b9\u3002 \u2003\u5728\u4e4b\u524d\u7684 \\(YOLO\\) \u4e0d\u64c5\u957f\u68c0\u6d4b\u5c0f\u7269\u4f53\u3002\u4f46\u662f\uff0c\u73b0\u5728\u6211\u4eec\u770b\u5230\u4e86\u8fd9\u79cd\u8d8b\u52bf\u7684\u9006\u8f6c\u3002\u968f\u7740\u65b0\u7684\u591a\u5c3a\u5ea6\u9884\u6d4b\uff0c\u6211\u4eec\u770b\u5230 \\(YOLOv3\\) \u5177\u6709\u76f8\u5bf9\u8f83\u9ad8\u7684 \\(APS\\) \u6027\u80fd\u3002\u4f46\u662f\uff0c\u5b83\u5728\u4e2d\u578b\u548c\u5927\u578b\u7269\u4f53\u68c0\u6d4b\u4e0a\u7684\u6027\u80fd\u8fd8\u76f8\u5bf9\u8f83\u5dee\u3002\u8fd9\u53ef\u80fd\u9700\u8981\u66f4\u591a\u7684\u8c03\u7814\u548c\u5b9e\u9a8c\u624d\u80fd\u77e5\u9053\u5982\u4f55\u53bb\u6539\u8fdb\u8fd9\u4e00\u70b9\u3002 \u2003\u5f53\u6211\u4eec\u5728 \\(AP50\\) \u6307\u6807\u4e0a\u7ed8\u5236\u51c6\u786e\u5ea6\u548c\u901f\u5ea6\u5173\u7cfb\u56fe\u65f6\uff08\u8bf7\u89c1\u56fe3\uff09\uff0c\u6211\u4eec\u770b\u5230 \\(YOLOv3\\) \u4e0e\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\u5177\u6709\u663e\u7740\u7684\u4f18\u52bf\u3002\u4e5f\u5c31\u662f\u8bf4 \\(YOLOv3\\) \uff0c\u901f\u5ea6\u66f4\u5feb\u3001\u6027\u80fd\u66f4\u597d\u3002","title":"3 \u6211\u4eec\u662f\u5982\u4f55\u505a\u7684"},{"location":"thesis_interpretation/03_yolo.html#4","text":"\u6211\u4eec\u5728\u5b9e\u73b0 \\(YOLOv3\\) \u7684\u8fc7\u7a0b\u4e2d\u5c1d\u8bd5\u4e86\u5f88\u591a\u4e1c\u897f\uff0c\u4f46\u662f\u5f88\u591a\u90fd\u5931\u8d25\u4e86\uff0c\u4ee5\u4e0b\u662f\u6211\u4eec\u8fd8\u8bb0\u5f97\u7684\u4e00\u4e9b\u5931\u8d25\u7684\u5c1d\u8bd5\u3002 \u2003 Anchor\u6846\u7684x\u3001y\u504f\u79fb\u9884\u6d4b \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528\u5e38\u89c4\u7684Anchor\u6846\u9884\u6d4b\u673a\u5236\uff0c\u6bd4\u5982\u5229\u7528\u7ebf\u6027\u6fc0\u6d3b\u5c06\u5750\u6807x\u3001y\u7684\u504f\u79fb\u7a0b\u5ea6\u9884\u6d4b\u4e3a\u8fb9\u754c\u6846\u5bbd\u5ea6\u6216\u9ad8\u5ea6\u7684\u500d\u6570\u3002\u4f46\u6211\u4eec\u53d1\u73b0\u8fd9\u79cd\u65b9\u6cd5\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u4e14\u6548\u679c\u4e0d\u4f73\u3002 \u2003 \u7528\u7ebf\u6027\u6fc0\u6d3b\u4ee3\u66ff\u903b\u8f91\u6fc0\u6d3b\u51fd\u6570\u8fdb\u884cx\u3001y\u9884\u6d4b \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u4ee3\u66ff\u903b\u8f91\u6fc0\u6d3b\u6765\u76f4\u63a5\u9884\u6d4bx\u3001y\u504f\u79fb\u3002\u8fd9\u4e2a\u6539\u53d8\u5bfc\u81f4mAP\u4e0b\u964d\u4e86\u51e0\u4e2a\u70b9\u3002 \u2003 focal loss \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528focal loss\u3002\u5b83\u4f7f\u5f97mAP\u4e0b\u964d2\u4e2a\u70b9\u3002 \\(YOLOv3\\) \u53ef\u80fd\u5df2\u7ecf\u5bf9focal loss \u8bd5\u56fe\u89e3\u51b3\u7684\u95ee\u9898\u5177\u6709\u76f8\u5f53\u7684\u9c81\u68d2\u6027\uff0c\u56e0\u4e3a\u5b83\u5177\u6709\u5355\u72ec\u7684\u76ee\u6807\u9884\u6d4b\u548c\u6761\u4ef6\u7c7b\u522b\u9884\u6d4b\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u5927\u591a\u6570\u6837\u672c\u6765\u8bf4\uff0c\u7c7b\u522b\u9884\u6d4b\u6ca1\u6709\u635f\u5931\uff1f\u6216\u8005\u6709\u4e00\u4e9b\uff1f\u6211\u4eec\u5e76\u4e0d\u5b8c\u5168\u786e\u5b9a\u3002 \u2003 \u53ccIOU\u9608\u503c\u548c\u771f\u503c\u5206\u914d \u3002 \\(Faster \\ R-CNN\\) \u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528\u4e24\u4e2a \\(IOU\\) \u9608\u503c\u3002\u5982\u679c\u4e00\u4e2a\u9884\u6d4b\u4e0e\u771f\u5b9e\u6807\u7b7e\u6846\u91cd\u53e0\u8d85\u8fc7 \\(0.7\\) \uff0c\u5b83\u5c31\u662f\u4e00\u4e2a\u6b63\u6837\u672c\uff0c\u82e5\u91cd\u53e0\u5728 \\([0.3\uff0c0.7]\\) \u4e4b\u95f4\uff0c\u90a3\u4e48\u5b83\u4f1a\u88ab\u5ffd\u7565\uff0c\u82e5\u5b83\u4e0e\u6240\u6709\u7684\u771f\u5b9e\u6807\u7b7e\u6846\u7684 \\(IOU\\) \u5c0f\u4e8e0.3\uff0c\u90a3\u4e48\u5c31\u4f1a\u88ab\u5224\u5b9a\u4e3a\u4e00\u4e2a\u8d1f\u6837\u672c\u3002\u6211\u4eec\u5c1d\u8bd5\u4e86\u7c7b\u4f3c\u7684\u7b56\u7565\uff0c\u4f46\u6700\u7ec8\u7684\u6548\u679c\u5e76\u4e0d\u597d\u3002 \u2003\u6211\u4eec\u975e\u5e38\u559c\u6b22\u76ee\u524d\u7684\u6a21\u578b\uff0c\u5b83\u81f3\u5c11\u5728\u5c40\u90e8\u8fbe\u5230\u4e86\u6700\u4f73\u3002\u4e0a\u8ff0\u7684\u6709\u4e9b\u6280\u672f\u53ef\u80fd\u4f1a\u4f7f\u6211\u4eec\u7684\u6a21\u578b\u66f4\u597d\uff0c\u4f46\u6211\u4eec\u53ef\u80fd\u8fd8\u9700\u8981\u5bf9\u4ed6\u4eec\u505a\u4e00\u4e9b\u8c03\u6574\u3002","title":"4 \u5931\u8d25\u7684\u5c1d\u8bd5"},{"location":"thesis_interpretation/03_yolo.html#5","text":"\\(YOLOv3\\) \u662f\u4e00\u4e2a\u5f88\u68d2\u7684\u68c0\u6d4b\u5668\uff0c\u5b83\u7531\u51c6\u53c8\u5feb\u3002\u867d\u7136\u5b83\u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\uff0c0.3\u548c0.95 IOU \u4e0b\u7684\u5e73\u5747AP\u5e76\u4e0d\u597d\uff0c\u4f46\u5728\u65e7\u7684 0.5 IOU\u7684\u68c0\u6d4b\u6307\u6807\u4e0b\uff0c\u5b83\u8fd8\u662f\u975e\u5e38\u4e0d\u9519\u7684\u3002 \u2003 \u4e3a\u4ec0\u4e48\u6211\u4eec\u8981\u6539\u53d8\u6307\u6807\uff1f \\(COCO\\) \u7684\u539f\u8bba\u6587\u6709\u8fd9\u6837\u4e00\u53e5\u542b\u7cca\u4e0d\u6e05\u7684\u53e5\u5b50\uff1a \\(\u201cA \\ full \\ discussion \\ of \\ evaluation \\ metrics \\ will \\ be \\ added \\ once \\ the \\ evaluation \\ server \\ is \\ complete\u201d\\) \u3002Russakovsky\u7b49\u4eba\u7684\u62a5\u544a\u4e2d\u8bf4\uff0c\u4eba\u4eec\u5f88\u96be\u533a\u52060.3\u548c0.5\u7684IOU\u3002\u201c\u8bad\u7ec3\u4eba\u7c7b\u7528\u89c6\u89c9\u68c0\u67e50.3 IOU\u7684\u8fb9\u754c\u6846\uff0c\u5e76\u4e14\u4e0e0.5 IOU\u7684\u6846\u533a\u522b\u5f00\u6765\u662f\u975e\u5e38\u56f0\u96be\u7684\u3002\u201c[16]\u5982\u679c\u4eba\u7c7b\u5f88\u96be\u8bf4\u51fa\u5dee\u5f02\uff0c\u90a3\u4e48\u5b83\u4e5f\u6ca1\u6709\u591a\u91cd\u8981\u5427\uff1f \u2003\u4e5f\u8bb8\u6709\u4e2a\u66f4\u597d\u7684\u95ee\u9898\u503c\u5f97\u6211\u4eec\u63a2\u8ba8\u201c\u6211\u4eec\u7528\u5b83\u6765\u5e72\u4ec0\u4e48\u201d\u8bb8\u591a\u4ece\u4e8b\u8fd9\u9879\u7814\u7a76\u7684\u4eba\u90fd\u5728Google\u548cFacebook\uff0c\u6211\u60f3\u81f3\u5c11\u6211\u4eec\u77e5\u9053\u8fd9\u4e2a\u6280\u672f\u662f\u638c\u63e1\u5728\u597d\u4eba\u624b\u91cc\uff0c\u7edd\u5bf9\u4e0d\u4f1a\u628a\u5b83\u7528\u6765\u6536\u96c6\u4f60\u7684\u4e2a\u4eba\u4fe1\u606f\u7136\u540e\u5356\u7ed9\u2026\u2026\u7b49\u7b49\uff0c\u4f60\u7a76\u7adf\u60f3\u7528\u5b83\u6765\u5e72\u561b\uff01\uff01\u5662\u3002 \u2003\u5176\u4ed6\u82b1\u5927\u94b1\u8d44\u52a9\u89c6\u89c9\u7814\u7a76\u7684\u4eba\u8fd8\u6709\u519b\u65b9\uff0c\u4ed6\u4eec\u4ece\u6765\u6ca1\u6709\u505a\u8fc7\u4efb\u4f55\u53ef\u6015\u7684\u4e8b\u60c5\uff0c\u4f8b\u5982\u7528\u65b0\u6280\u672f\u6740\u6b7b\u5f88\u591a\u4eba\uff0c\u7b49\u7b49..... \u6211\u5f3a\u70c8\u5730\u5e0c\u671b\uff0c\u5927\u591a\u6570\u4f7f\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u4eba\u90fd\u7528\u5b83\u6765\u505a\u4e00\u4e9b\u5feb\u4e50\u4e14\u6709\u76ca\u7684\u4e8b\u60c5\uff0c\u6bd4\u5982\u8ba1\u7b97\u4e00\u4e2a\u56fd\u5bb6\u516c\u56ed\u91cc\u6591\u9a6c\u7684\u6570\u91cf[13]\uff0c\u6216\u8005\u8ffd\u8e2a\u5728\u9644\u8fd1\u5f98\u5f8a\u7684\u732b[19]\u3002\u4f46\u8ba1\u7b97\u673a\u89c6\u89c9\u5df2\u7ecf\u88ab\u7528\u4e8e\u503c\u5f97\u6000\u7591\u7684\u7528\u9014\uff0c\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\uff0c\u6211\u4eec\u6709\u8d23\u4efb\u8003\u8651\u6211\u4eec\u7684\u5de5\u4f5c\u53ef\u80fd\u9020\u6210\u7684\u635f\u5bb3\uff0c\u5e76\u601d\u8003\u5982\u4f55\u51cf\u8f7b\u5b83\u7684\u5f71\u54cd\u3002\u6211\u4eec\u6b20\u8fd9\u4e2a\u4e16\u754c\u592a\u591a\u3002 \u6700\u540e\uff0c\u4e0d\u8981\u518d@\u6211\u4e86\u3002\uff08\u56e0\u4e3a\u6211\u5df2\u7ecf\u9000\u51faTwitter\u8fd9\u4e2a\u662f\u975e\u4e4b\u5730\u4e86\uff09\u3002 In closing, do not@me. (Because I finally quit Twitter).","title":"5 \u8fd9\u4e00\u5207\u610f\u5473\u7740\u4ec0\u4e48"},{"location":"thesis_interpretation/03_yolo.html#references","text":"[1] Analogy. Wikipedia, Mar 2018. 1 [2] M. Everingham, L. V an Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) challenge. International journal of computer vision, 88(2):303\u2013 338, 2010. 6 [3] C.-Y . Fu, W. Liu, A. Ranga, A. Tyagi, and A. C. Berg. Dssd: Deconvolutional single shot detector. arXiv preprint arXiv:1701.06659, 2017. 3 [4] D. Gordon, A. Kembhavi, M. Rastegari, J. Redmon, D. Fox, and A. Farhadi. Iqa: Visual question answering in interactive environments. arXiv preprint arXiv:1712.03316, 2017. 1 [5] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016. 3 [6] J. Huang, V . Rathod, C. Sun, M. Zhu, A. Korattikara, A. Fathi, I. Fischer, Z. Wojna, Y . Song, S. Guadarrama, et al Speed/accuracy trade-offs for modern convolutional object detectors. 3 [7] I. Krasin, T. Duerig, N. Alldrin, V . Ferrari, S. Abu-El-Haija, A. Kuznetsova, H. Rom, J. Uijlings, S. Popov, A. V eit, S. Belongie, V . Gomes, A. Gupta, C. Sun, G. Chechik, D. Cai, Z. Feng, D. Narayanan, and K. Murphy. Openimages: A public dataset for large-scale multi-label and multi-class image classification. Dataset available from https://github.com/openimages, 2017. 2 [8] T.-Y . Lin, P . Dollar, R. Girshick, K. He, B. Hariharan, and S. Belongie. Feature pyramid networks for object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2117\u20132125, 2017. 2, 3 [9] T.-Y . Lin, P . Goyal, R. Girshick, K. He, and P . Doll\u00e1r. Focal loss for dense object detection. arXiv preprint arXiv:1708.02002, 2017. 1, 3, 4 [10] T.-Y . Lin, M. Maire, S. Belongie, J. Hays, P . Perona, D. Ramanan, P . Doll\u00e1r, and C. L. Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision, pages 740\u2013755. Springer, 2014. 2 [11] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.Y . Fu, and A. C. Berg. Ssd: Single shot multibox detector. In European conference on computer vision, pages 21\u201337. Springer, 2016. 3 [12] I. Newton. Philosophiae naturalis principia mathematica. William Dawson & Sons Ltd., London, 1687. 1 [13] J. Parham, J. Crall, C. Stewart, T. Berger-Wolf, and D. Rubenstein. Animal population censusing at scale with citizen science and photographic identification. 2017. 4 [14] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 3 [15] J. Redmon and A. Farhadi. Y olo9000: Better, faster, stronger. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pages 6517\u20136525. IEEE, 2017. 1, 2, 3 [16] J. Redmon and A. Farhadi. Y olov3: An incremental improvement. arXiv, 2018. 4 [17] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497, 2015. 2 [18] O. Russakovsky, L.-J. Li, and L. Fei-Fei. Best of both worlds: human-machine collaboration for object annotation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2121\u20132131, 2015. 4 [19] M. Scott. Smart camera gimbal bot scanlime:027, Dec 2017. 4 [20] A. Shrivastava, R. Sukthankar, J. Malik, and A. Gupta. Be- yond skip connections: Top-down modulation for object de- tection. arXiv preprint arXiv:1612.06851, 2016. 3 [21] C. Szegedy, S. Ioffe, V . V anhoucke, and A. A. Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. 2017. 3","title":"References"},{"location":"thesis_interpretation/04_yolo.html","text":"[2004.10934] YOLOv4: Optimal Speed and Accuracy of Object Detection (arxiv.org) Abstract \u6458\u8981 \u2003There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is re- quired. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and com- bine some of them to achieve state-of-the-art results: 43.5% AP (65.7% AP50) for the MS COCO dataset at a real- time speed of \u223c65 FPS on Tesla V100. Source code is at https://github.com/AlexeyAB/darknet. \u636e\u8bf4\u6709\u5927\u91cf\u7279\u5f81\u53ef\u4ee5\u63d0\u9ad8\u5377\u79ef\u795e\u7ecf\u7f51\u7edc (CNN) \u7684\u51c6\u786e\u6027\u3002 \u9700\u8981\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u5bf9\u8fd9\u4e9b\u7279\u5f81\u7684\u7ec4\u5408\u8fdb\u884c\u5b9e\u9645\u6d4b\u8bd5\uff0c\u5e76\u5bf9\u7ed3\u679c\u8fdb\u884c\u7406\u8bba\u8bba\u8bc1\u3002 \u67d0\u4e9b\u7279\u5f81\u4e13\u95e8\u9488\u5bf9\u67d0\u4e9b\u6a21\u578b\uff0c\u4e13\u95e8\u9488\u5bf9\u67d0\u4e9b\u95ee\u9898\uff0c\u6216\u4ec5\u9488\u5bf9\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\uff1b \u800c\u4e00\u4e9b\u7279\u6027\uff0c\u5982\u6279\u91cf\u5f52\u4e00\u5316\u548c\u6b8b\u5dee\u8fde\u63a5\uff0c\u9002\u7528\u4e8e\u5927\u591a\u6570\u6a21\u578b\u3001\u4efb\u52a1\u548c\u6570\u636e\u96c6\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u901a\u7528\uff08universal\uff09\u7279\u5f81\u5305\u62ec\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5 (WRC)\u3001\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5 (CSP)\u3001\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3001\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u548c Mish \u6fc0\u6d3b\u3002 \u6211\u4eec\u4f7f\u7528\u65b0\u529f\u80fd\uff1aWRC\u3001CSP\u3001CmBN\u3001SAT\u3001Mish \u6fc0\u6d3b\u3001Mosaic \u6570\u636e\u589e\u5f3a\u3001DropBlock \u6b63\u5219\u5316\u548c CIoU \u635f\u5931\uff0c\u5e76\u7ed3\u5408\u5176\u4e2d\u7684\u4e00\u4e9b\u6765\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff1a\u5728 Tesla V100 \u4e0a\u4ee5 ~65 FPS \u7684\u5b9e\u65f6\u901f\u5ea6\u7528\u4e8e MS COCO \u6570\u636e\u96c6\uff0c\u7ed3\u679c\u4e3a43.5% AP\uff0865.7 % AP50) \u3002 \u6e90\u4ee3\u7801\u4f4d\u4e8e https://github.com/AlexeyAB/darknet\u3002 Introduction \u5f15\u8a00 \u2003The majority of CNN-based object detectors are largely applicable only for recommendation systems. For example, searching for free parking spaces via urban video cameras is executed by slow accurate models, whereas car collision warning is related to fast inaccurate models. Improving the real-time object detector accuracy enables using them not only for hint generating recommendation systems, but also for stand-alone process management and human input reduction. Real-time object detector operation on conven- tional Graphics Processing Units (GPU) allows their mass usage at an affordable price. The most accurate modern neural networks do not operate in real time and require large number of GPUs for training with a large mini-batch-size. We address such problems through creating a CNN that op- erates in real-time on a conventional GPU, and for which training requires only one conventional GPU. \u2003\u5927\u591a\u6570\u57fa\u4e8e CNN \u7684\u5bf9\u8c61\u68c0\u6d4b\u5668\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4ec5\u9002\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\uff08recommendation system\uff09\u3002 \u4f8b\u5982\uff0c\u901a\u8fc7\u57ce\u5e02\u6444\u50cf\u673a\u641c\u7d22\u514d\u8d39\u505c\u8f66\u4f4d\u662f\u7531\u6162\u901f\u51c6\u786e\u6a21\u578b\u6267\u884c\u7684\uff0c\u800c\u6c7d\u8f66\u78b0\u649e\u8b66\u544a\u4e0e\u5feb\u901f\u4e0d\u51c6\u786e\u6a21\u578b\u6709\u5173\u3002 \u63d0\u9ad8\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u4e0d\u4ec5\u53ef\u4ee5\u5c06\u5b83\u4eec\u7528\u4e8e\u63d0\u793a\u751f\u6210\u63a8\u8350\u7cfb\u7edf\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u72ec\u7acb\u6d41\u7a0b\u7ba1\u7406\uff08stand-alone process management\uff09\u548c\u51cf\u5c11\u4eba\u5de5\u8f93\u5165\u3002 \u4f20\u7edf\u56fe\u5f62\u5904\u7406\u5355\u5143 (GPU) \u4e0a\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u64cd\u4f5c\u5141\u8bb8\u4ee5\u5b9e\u60e0\u7684\u4ef7\u683c\u5927\u89c4\u6a21\u4f7f\u7528\u3002 \u6700\u7cbe\u786e\u7684\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u65e0\u6cd5\u5b9e\u65f6\u8fd0\u884c\uff0c\u5e76\u4e14\u9700\u8981\u5927\u91cf\u7684 GPU \u8fdb\u884c\u5927\u578b\u5c0f\u578b\u6279\u5904\u7406\u5927\u5c0f\u7684\u8bad\u7ec3\u3002\u6211\u4eec\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a\u5728\u4f20\u7edf GPU \u4e0a\u5b9e\u65f6\u8fd0\u884c\u7684 CNN \u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4e3a\u6b64\u8bad\u7ec3\u53ea\u9700\u8981\u4e00\u4e2a\u5e38\u89c4 GPU\u3002 Figure 1: Comparison of the proposed YOLOv4 and other state-of-the-art object detectors. YOLOv4 runs twice faster than EfficientDet with comparable performance. Improves YOLOv3\u2019s AP and FPS by 10% and 12%, respectively. \u56fe1\uff1a\u5bf9YOLOv4\u548c\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u8fdb\u884c\u6bd4\u8f83\u3002\u5177\u6709\u540c\u7b49\u7684\u6027\u80fd\u60c5\u51b5\u4e0b\uff0cYOLOv4\u7684\u901f\u5ea6\u662f EfficientDet \u7684\u4e24\u500d\u3002\u5e76\u4e14 YOLOv4 \u5c06YOLOv3 \u7684 AP \u548c FPS \u5206\u522b\u63d0\u9ad8\u4e86 10% \u548c 12%\u3002 \u2003The main goal of this work is designing a fast operating speed of an object detector in production systems and opti- mization for parallel computations, rather than the low com- putation volume theoretical indicator (BFLOP). We hope that the designed object can be easily trained and used. For example, anyone who uses a conventional GPU to train and test can achieve real-time, high quality, and convincing ob- ject detection results, as the YOLOv4 results shown in Fig- ure 1. Our contributions are summarized as follows: \u2003\u8fd9\u9879\u5de5\u4f5c\u7684\u4e3b\u8981\u76ee\u6807\u662f\u8bbe\u8ba1\u751f\u4ea7\u7cfb\u7edf\u4e2d\u8fd0\u884c\u901f\u5ea6\u8f83\u5feb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5e76\u4f18\u5316\u5e76\u884c\u8ba1\u7b97\uff0c\u800c\u4e0d\u662f\u4f4e\u8ba1\u7b97\u91cf\u7406\u8bba\u6307\u6807 \uff08BFLOP\uff09\u3002\u6211\u4eec\u5e0c\u671b\u8bbe\u8ba1\u7684\u68c0\u6d4b\u5668\u80fd\u591f\u8f7b\u677e\u8bad\u7ec3\u548c\u4f7f\u7528\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u4efb\u4f55\u4f20\u7edf GPU \u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u4eba\u90fd\u53ef\u4ee5\u83b7\u5f97\u5b9e\u65f6\u3001\u9ad8\u8d28\u91cf\u548c\u4ee4\u4eba\u4fe1\u670d\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\uff0c\u5982\u56fe 1 \u6240\u793a\u7684 YOLOv4 \u7ed3\u679c\u6240\u793a\u3002\u6211\u4eec\u7684\u8d21\u732e\u603b\u7ed3\u5982\u4e0b\uff1a 1\uff09 We develope an efficient and powerful object detection model. It makes everyone can use a 1080 Ti or 2080 Ti GPU to train a super fast and accurate object detector. 1\uff09\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u9ad8\u6548\u800c\u5f3a\u5927\u7684\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u3002 \u5b83\u4f7f\u6bcf\u4e2a\u4eba\u90fd\u53ef\u4ee5\u4f7f\u7528 1080 Ti \u6216 2080 Ti GPU \u6765\u8bad\u7ec3\u4e00\u4e2a\u8d85\u5feb\u901f\u548c\u51c6\u786e\u7684\u76ee\u6807 \u68c0\u6d4b\u5668\u3002 2\uff09We verify the influence of state-of-the-art Bag-of- Freebies and Bag-of-Specials methods of object detec- tion during the detector training. 2\uff09\u5728\u68c0\u6d4b\u5668\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u9a8c\u8bc1\u4e86\u6700\u5148\u8fdb\u7684 Bag-of-Freebies \u548c Bag-of-Specials \u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u7684\u5f71\u54cd\u3002 3\uff09We modify state-of-the-art methods and make them more effecient and suitable for single GPU training, including CBN [89], PAN [49], SAM [85], etc. 3\uff09\u6211\u4eec\u4fee\u6539\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u66f4\u6709\u6548\uff0c\u66f4\u9002\u5408\u5355 GPU \u8bad\u7ec3\uff0c\u65b9\u6cd5\u5305\u62ec CBN [89]\u3001PAN [49]\u3001SAM [85] \u7b49\u3002 \u56fe2\uff1a\u76ee\u6807\u68c0\u6d4b\u5668 2. Related work \u76f8\u5173\u5de5\u4f5c 2.1. Object detection models \u76ee\u6807\u68c0\u6d4b\u6a21\u578b \u2003A modern detector is usually composed of two parts,a backbone which is pre-trained on ImageNet and a head which is used to predict classes and bounding boxes of objects.For those detectors running on GPU platform, their backbone could be VGG [68], ResNet [26], ResNeXt [86], or DenseNet [30]. For those detectors running on CPU platform, their backbone could be SqueezeNet [31], MobileNet [28, 66, 27, 74], or ShuffleNet [97, 53]. As to the head part, it is usually categorized into two kinds, i.e., one-stage object detector and two-stage object detector. The most representative two-stage object detector is the R-CNN [19] series, including fast R-CNN [18], faster R-CNN [64], R-FCN [9], and Libra R-CNN [58]. It is also possible to make a two- stage object detector an anchor-free object detector, such as RepPoints [87]. As for one-stage object detector, the most representative models are YOLO [61, 62, 63], SSD [50], and RetinaNet [45]. In recent years, anchor-free one-stage object detectors are developed. The detectors of this sort are CenterNet [13], CornerNet [37, 38], FCOS [78], etc. Object detectors developed in recent years often insert some layers between backbone and head, and these layers are usually used to collect feature maps from different stages. We can call it the neck of an object detector. Usually, a neck is composed of several bottom-up paths and several topdown paths. Networks equipped with this mechanism include Feature Pyramid Network (FPN) [44], Path Aggregation Network (PAN) [49], BiFPN [77], and NAS-FPN [17]. \u2003\u73b0\u4ee3\u68c0\u6d4b\u5668\u901a\u5e38\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u4e00\u4e2a\u662f\u5728 ImageNet \u4e0a\u9884\u5148\u8bad\u7ec3\u7684\u9aa8\u5e72\u7f51\uff0c\u53e6\u4e00\u4e2a\u662f\u7528\u4e8e\u9884\u6d4b\u7269\u4f53\u7684\u7c7b\u548c\u8fb9\u754c\u6846\u7684\u5934\u90e8\u3002\u5bf9\u4e8e\u5728 GPU \u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u4e3b\u5e72\u53ef\u4ee5\u662f VGG [68]\u3001ResNet [26]\u3001ResNeXt [86]\u6216DenseNet [30]\u3002\u5bf9\u4e8e\u5728 CPU \u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u4e3b\u5e72\u53ef\u4ee5\u662fSqueezeNet [31], MobileNet [28, 66, 27, 74], \u6216 ShuffleNet [97, 53].\u3002\u81f3\u4e8e\u5934\u90e8\u90e8\u5206\uff0c\u901a\u5e38\u5206\u4e3a\u4e24\u7c7b \uff0c \u5373\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u548c\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668 \u3002\u6700\u5177\u4ee3\u8868\u6027\u7684\u4e24\u7ea7\u76ee\u6807\u68c0\u6d4b\u5668\u662fR-CNN[19]\u7cfb\u5217\uff0c\u5305\u62ecfast R-CNN [18], faster R-CNN [64], R-FCN [9], \u548c Libra R-CNN [58] \u3002\u4e5f\u53ef\u4ee5\u4f7f\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u6210\u4e3a\u65e0\u951a\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5982 RepPoints [87]\u3002\u81f3\u4e8e\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u6700\u5177\u4ee3\u8868\u6027\u7684\u578b\u53f7\u662fYOLO[61\u300162\u300163]\u3001SSD[50]\u548cRetinaNet[45]\u3002\u8fd1\u5e74\u6765\uff0c\u7814\u5236\u4e86\u65e0\u951a\u5f0f\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u3002\u6b64\u7c7b\u68c0\u6d4b\u5668\u6709 CenterNet [13]\u3001CornerNet [37\u3001 38]\u3001FCOS [78]\u7b49\u3002\u8fd1\u5e74\u6765\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u7814\u53d1\u901a\u5e38\u662f\u5728\u9aa8\u5e72\u548c\u5934\u90e8\u4e4b\u95f4\u7684\u6dfb\u52a0\u4e00\u4e9b\u5c42\uff0c\u8fd9\u4e9b\u5c42\u901a\u5e38\u7528\u4e8e\u6536\u96c6\u4e0d\u540c\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u3002\u6211\u4eec\u53ef\u4ee5\u79f0\u5b83\u4e3a\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u8116\u5b50\u3002\u901a\u5e38\uff0c\u9888\u90e8\u7531\u51e0\u4e2a\u81ea\u4e0b\u800c\u4e0a\u7684\u8def\u5f84\u548c\u51e0\u4e2a\u81ea\u4e0a\u800c\u4e0b\u7684\u8def\u5f84\u7ec4\u6210\u3002\u914d\u5907\u6b64\u673a\u5236\u7684\u7f51\u7edc\u5305\u62ec\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc \uff08FPN\uff09 [44]\u3001\u8def\u5f84\u805a\u5408\u7f51\u7edc \uff08PAN\uff09 [49]\u3001BiFPN [77]\u548c NAS-FPN [17]\u3002 \u2003In addition to the above models, some researchers put their emphasis on directly building a new backbone (DetNet [43], DetNAS [7]) or a new whole model (SpineNet [12], HitDetector [20]) for object detection. \u2003\u9664\u4e86\u4e0a\u8ff0\u6a21\u578b\u5916\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u8fd8\u628a\u91cd\u70b9\u76f4\u63a5\u653e\u5728\u6784\u5efa\u4e00\u4e2a\u65b0\u7684\u4e3b\u5e72\uff08DetNet [43]\uff0cDetNAS [7]\uff09\u6216\u65b0\u7684\u5b8c\u6574\u6a21\u578b\uff08SpineNet [12]\uff0cHitDetector [20]\uff09\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u3002 \u2003To sum up, an ordinary object detector is composed of several parts: \u2003\u7efc\u4e0a\u6240\u8ff0\uff0c\u4e00\u4e2a\u666e\u901a\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u7531\u5982\u4e0b\u90e8\u5206\u7ec4\u6210\uff1a Input: Image, Patches, Image Pyramid Backbones: VGG16 [68], ResNet-50 [26], SpineNet [12], EfficientNet-B0/B7 [75], CSPResNeXt50 [81], CSPDarknet53 [81] Neck: Additional blocks: SPP [25], ASPP [5], RFB [47], SAM [85] Path-aggregation blocks: FPN [44], PAN [49], NAS-FPN [17], Fully-connected FPN, BiFPN [77], ASFF [48], SFAM [98] Heads: Dense Prediction (one-stage): RPN [64], SSD [50], YOLO [61], RetinaNet [45] (anchor based) CornerNet [37], CenterNet [13], MatrixNet [60], FCOS [78] (anchor free) Sparse Prediction (two-stage): Faster R-CNN [64], R-FCN [9], Mask R-CNN [23] (anchor based) RepPoints [87] (anchor free) 2.2. Bag of freebies \u2003Usually, a conventional object detector is trained offline. Therefore, researchers always like to take this advantage and develop better training methods which can make the object detector receive better accuracy without increasing the inference cost. We call these methods that only change the training strategy or only increase the training cost as \u201cbag of freebies.\u201d What is often adopted by object detection methods and meets the definition of bag of freebies is data augmentation. The purpose of data augmentation is to increase the variability of the input images, so that the designed object detection model has higher robustness to the images obtained from different environments. For examples, photometric distortions and geometric distortions are two commonly used data augmentation method and they definitely benefit the object detection task. In dealing with photometric distortion, we adjust the brightness, contrast, hue, saturation, and noise of an image. For geometric distortion, we add random scaling, cropping, flipping, and rotating. \u2003\u901a\u5e38\uff0c\u4f20\u7edf\u7684\u7269\u4f53\u68c0\u6d4b\u5668\u662f\u79bb\u7ebf\u8bad\u7ec3\u7684\u3002 \u56e0\u6b64\uff0c\u7814\u7a76\u4eba\u5458\u603b\u662f\u559c\u6b22\u5229\u7528\u8fd9\u4e00\u4f18\u52bf\uff0c\u5f00\u53d1\u66f4\u597d\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u76ee\u6807\u68c0\u6d4b\u5668\u5728\u4e0d\u589e\u52a0\u63a8\u7406\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u66f4\u597d\u7684\u51c6\u786e\u6027\u3002\u6211\u4eec\u5c06\u8fd9\u4e9b\u53ea\u4f1a\u6539\u53d8\u8bad\u7ec3\u7b56\u7565\u6216\u53ea\u4f1a\u589e\u52a0\u8bad\u7ec3\u6210\u672c\u7684\u65b9\u6cd5\u79f0\u4e3a \u201cbag of freebies\u201d\u3002\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u7ecf\u5e38\u91c7\u7528\u4e14\u7b26\u5408bag of freebies \u5b9a\u4e49\u7684\u662f\u6570\u636e\u589e\u5f3a\uff08data augmentation\uff09\u3002\u6570\u636e\u589e\u5f3a\u7684\u76ee\u7684\u662f\u589e\u52a0\u8f93\u5165\u56fe\u50cf\u7684\u53ef\u53d8\u6027\uff08variability\uff09\uff0c\u4f7f\u8bbe\u8ba1\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u5bf9\u4e0d\u540c\u73af\u5883\u4e0b\u83b7\u5f97\u7684\u56fe\u50cf\u5177\u6709\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002\u4f8b\u5982\uff0c\u5149\u5ea6\u5931\u771f\uff08photometric distortion\uff09\u548c\u51e0\u4f55\u5931\u771f\uff08geometric distortion\uff09\u662f\u4e24\u79cd\u5e38\u7528\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b83\u4eec\u7edd\u5bf9\u6709\u5229\u4e8e\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u3002\u5728\u5904\u7406\u5149\u5ea6\u5931\u771f\u65f6\uff0c\u6211\u4eec\u8c03\u6574\u56fe\u50cf\u7684\u4eae\u5ea6\uff08brightness\uff09\u3001\u5bf9\u6bd4\u5ea6\uff08contrast\uff09\u3001\u8272\u8c03\uff08hue\uff09\u3001\u9971\u548c\u5ea6\uff08saturation\uff09\u548c\u566a\u58f0\uff08noise\uff09\u3002 \u5bf9\u4e8e\u51e0\u4f55\u5931\u771f\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u968f\u673a\u7f29\u653e\uff08random scale\uff09\u3001\u88c1\u526a\uff08crop\uff09\u3001\u7ffb\u8f6c\uff08flip\uff09\u548c\u65cb\u8f6c\uff08rotate\uff09\u3002 \u2003The data augmentation methods mentioned above are all pixel-wise adjustments, and all original pixel information in the adjusted area is retained. In addition, some researchers engaged in data augmentation put their emphasis on sim- ulating object occlusion issues. They have achieved good results in image classification and object detection. For ex- ample, random erase [100] and CutOut [11] can randomly select the rectangle region in an image and fill in a random or complementary value of zero. As for hide-and-seek [69] and grid mask [6], they randomly or evenly select multiple rectangle regions in an image and replace them to all ze- ros. If similar concepts are applied to feature maps, there are DropOut [71], DropConnect [80], and DropBlock [16] methods. In addition, some researchers have proposed the methods of using multiple images together to perform data augmentation. For example, MixUp [92] uses two images to multiply and superimpose with different coefficient ra- tios, and then adjusts the label with these superimposed ra- tios. As for CutMix [91], it is to cover the cropped image to rectangle region of other images, and adjusts the label according to the size of the mix area. In addition to the above mentioned methods, style transfer GAN [15] is also used for data augmentation, and such usage can effectively reduce the texture bias learned by CNN. \u2003\u4e0a\u9762\u63d0\u5230\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u90fd\u662f\u9010\u50cf\u7d20\uff08pixel-wise\uff09\u8c03\u6574\u7684\uff0c\u5e76\u4e14\u4fdd\u7559\u4e86\u8c03\u6574\u533a\u57df\u5185\u7684\u6240\u6709\u539f\u59cb\u50cf\u7d20\u4fe1\u606f\u3002 \u6b64\u5916\uff0c\u4e00\u4e9b\u4ece\u4e8b\u6570\u636e\u589e\u5f3a\u7684\u7814\u7a76\u4eba\u5458\u5c06\u91cd\u70b9\u653e\u5728\u6a21\u62df\u5bf9\u8c61\u906e\u6321\uff08occlusion\uff09\u95ee\u9898\u4e0a\u3002\u4ed6\u4eec\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u76ee\u6807\u68c0\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u5f88\u597d\u7684\u6548\u679c\u3002 \u4f8b\u5982\uff0c\u968f\u673a\u64e6\u9664[100]\u548cCutOut[11]\u53ef\u4ee5\u968f\u673a\u9009\u62e9\u56fe\u50cf\u4e2d\u7684\u77e9\u5f62\u533a\u57df\u5e76\u586b\u5145\u968f\u673a\u503c\u6216\u4e92\u8865\u503c\u96f6\uff08complementary value of zero\uff09\u3002\u81f3\u4e8e\u6349\u8ff7\u85cf\uff08hide-and-seek\uff09 [69] \u548c\u7f51\u683c\u8499\u7248\uff08grid mask\uff09 [6]\uff0c\u5b83\u4eec\u968f\u673a\u6216\u5747\u5300\u5730\u9009\u62e9\u56fe\u50cf\u4e2d\u7684\u591a\u4e2a\u77e9\u5f62\u533a\u57df\u5e76\u5c06\u5b83\u4eec\u5168\u66ff\u6362\u4e3a\u96f6\u3002 \u5982\u679c\u5c06\u7c7b\u4f3c\u7684\u6982\u5ff5\u5e94\u7528\u4e8e\u7279\u5f81\u56fe\uff0c\u5219\u6709 DropOut [71]\u3001DropConnect [80] \u548c DropBlock [16] \u65b9\u6cd5\u3002 \u6b64\u5916\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u5c06\u591a\u4e2a\u56fe\u50cf\u4e00\u8d77\u4f7f\u7528\u6765\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u65b9\u6cd5\u3002 \u4f8b\u5982\uff0cMixUp [92] \u4f7f\u7528\u4e24\u5e45\u56fe\u50cf\u6765\u4f7f\u4e0d\u540c\u7684\u7cfb\u6570\u6bd4\u4f8b\uff08coefficient ratio\uff09\u76f8\u4e58\u53e0\u52a0\uff08superimpose\uff09\uff0c\u7136\u540e\u7528\u8fd9\u4e9b\u53e0\u52a0\u6bd4\u4f8b\u8c03\u6574\u6807\u7b7e\u3002\u81f3\u4e8eCutMix [91]\uff0c\u5c31\u662f\u5c06\u88c1\u526a\u540e\u7684\u56fe\u50cf\u8986\u76d6\u5230\u5176\u4ed6\u56fe\u50cf\u7684\u77e9\u5f62\u533a\u57df\uff0c\u5e76\u6839\u636e\u6df7\u5408\u533a\u57df\u7684\u5927\u5c0f\u8c03\u6574\u6807\u7b7e\u3002 \u9664\u4e86\u4e0a\u8ff0\u65b9\u6cd5\u5916\uff0c\u98ce\u683c\u8fc1\u79fb GAN [15] \u4e5f\u88ab\u7528\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u8fd9\u79cd\u7528\u6cd5\u53ef\u4ee5\u6709\u6548\u51cf\u5c11 CNN \u5b66\u4e60\u5230\u7684\u7eb9\u7406\uff08texture\uff09\u504f\u5dee\u3002 \u2003Different from the various approaches proposed above, some other bag of freebies methods are dedicated to solving the problem that the semantic distribution in the dataset may have bias. In dealing with the problem of semantic distribution bias, a very important issue is that there is a problem of data imbalance between different classes, and this problem is often solved by hard negative example mining [72] or online hard example mining [67] in two-stage object detector. But the example mining method is not applicable to one-stage object detector, because this kind of detector belongs to the dense prediction architecture. Therefore Lin et al. [45] proposed focal loss to deal with the problem of data imbalance existing between various classes. Another very important issue is that it is difficult to express the relationship of the degree of association between different categories with the one-hot hard representation. This representation scheme is often used when executing labeling. The label smoothing proposed in [73] is to convert hard label into soft label for training, which can make model more robust. In order to obtain a better soft label, Islam et al. [33] introduced the concept of knowledge distillation to design the label refinement network. \u2003\u4e0e\u4e0a\u9762\u63d0\u51fa\u7684\u5404\u79cd\u65b9\u6cd5\u4e0d\u540c\uff0c\u5176\u4ed6\u4e00\u4e9bbag of freebies\u65b9\u6cd5\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3\u6570\u636e\u96c6\u4e2d\u8bed\u4e49\u5206\u5e03\uff08semantic distribution\uff09\u53ef\u80fd\u5b58\u5728\u504f\u5dee\u7684\u95ee\u9898\u3002\u5728\u5904\u7406\u8bed\u4e49\u5206\u5e03\u504f\u5dee\u95ee\u9898\u65f6\uff0c\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u662f\u4e0d\u540c\u7c7b\u4e4b\u95f4\u5b58\u5728\u6570\u636e\u4e0d\u5e73\u8861\uff08data imbalance\uff09\u7684\u95ee\u9898\u3002 \u8fd9\u4e2a\u95ee\u9898\u901a\u5e38\u901a\u8fc7\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u4e2d\u7684\u786c\u53cd\u4f8b\u6316\u6398\uff08hard negative example mining\uff09[72]\u6216\u5728\u7ebf\u786c\u793a\u4f8b\u6316\u6398\uff08online hard example mining\uff09[67]\u6765\u89e3\u51b3\u3002 \u4f46\u662f\u793a\u4f8b\u6316\u6398\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u56e0\u4e3a\u8fd9\u79cd\u68c0\u6d4b\u5668\u5c5e\u4e8e\u5bc6\u96c6\u9884\u6d4b\u67b6\u6784\u3002\u56e0\u6b64 Lin \u7b49\u4eba [45] \u63d0\u51fa\u4e86focal loss \u6765\u5904\u7406\u5404\u4e2a\u7c7b\u4e4b\u95f4\u5b58\u5728\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002 \u53e6\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u662f\uff0c\u4f7f\u7528one-hot hard\u8868\u793a\u5f88\u96be\u8868\u8fbe\u4e0d\u540c\u7c7b\u522b\u4e4b\u95f4\u7684\u5173\u8054\u7a0b\u5ea6\u7684\u5173\u7cfb\u3002 \u8fd9\u79cd\u8868\u793a\u65b9\u6848\u5728\u8fdb\u884c\u6807\u6ce8\u65f6\u7ecf\u5e38\u4f7f\u7528\u3002[73]\u4e2d\u63d0\u51fa\u7684\u6807\u7b7e\u5e73\u6ed1\uff08label smoothing\uff09\u662f\u5c06\u786c\u6807\u7b7e\uff08hard label\uff09\u8f6c\u6362\u4e3a\u8f6f\u6807\u7b7e\uff08soft label\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u4ee5\u4f7f\u6a21\u578b\u66f4\u52a0\u9c81\u68d2\u3002 \u4e3a\u4e86\u83b7\u5f97\u66f4\u597d\u7684\u8f6f\u6807\u7b7e\uff0cIslam\u7b49[33]\u5f15\u5165\u4e86\u77e5\u8bc6\u84b8\u998f\uff08knowledge distillation\uff09\u7684\u6982\u5ff5\u6765\u8bbe\u8ba1\u6807\u7b7e\u7ec6\u5316\u7f51\u7edc\uff08label refinement network\uff09\u3002 \u2003The last bag of freebies is the objective function of Bounding Box (BBox) regression. The traditional object detector usually uses Mean Square Error (MSE) to directly perform regression on the center point coordinates and height and width of the BBox, i.e., \\({x_{center}, y_{center}, w, h}\\) , or the upper left point and the lower right point, i.e., \\({x_{top-left}, y_{top-left}, x_{bottom-right}, y_{bottom-right} }\\) . As for anchor-based method, it is to estimate the corresponding offset, for example \\({x_{center-offset}, y_{center-offset},w_{offset}, h_{offset}}\\) and \\({x_{top-left-offset}, y_{top-left-offset},x_{bottom-right-offset}, y_{bottom-right-offset}}\\) . However, to directly estimate the coordinate values of each point of the BBox is to treat these points as independent variables, but in fact does not consider the integrity of the object itself. In order to make this issue processed better, some researchers recently proposed IoU loss [90], which puts the coverage of predicted BBox area and ground truth BBox area into consideration. The IoU loss computing process will trigger the calculation of the four coordinate points of the BBox by executing IoU with the ground truth, and then connecting the generated results into a whole code. Because IoU is a scale invariant representation, it can solve the problem that when traditional methods calculate the \\(l_1\\) or \\(l_2\\) loss of \\({x, y, w,h}\\) , the loss will increase with the scale. Recently, some researchers have continued to improve IoU loss. For example, GIoU loss [65] is to include the shape and orientation of object in addition to the coverage area. They proposed to find the smallest area BBox that can simultaneously cover the predicted BBox and ground truth BBox, and use this BBox as the denominator to replace the denominator originally used in IoU loss. As for DIoU loss [99], it additionally considers the distance of the center of an object, and CIoU loss [99], on the other hand simultaneously considers the overlapping area, the distance between center points, and the aspect ratio. CIoU can achieve better convergence speed and accuracy on the BBox regression problem. \u2003\u6700\u540e\u4e00\u4e9b bag of freebies \u662f\u8fb9\u754c\u6846 (BBox) \u56de\u5f52\u7684\u76ee\u6807\u51fd\u6570\u3002 \u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u901a\u5e38\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u76f4\u63a5\u5bf9BBox\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u8fdb\u884c\u56de\u5f52\uff0c\u5373 \\({x_{center}, y_{center},w, h}\\) \uff0c\u6216\u5de6\u4e0a\u70b9\u548c\u53f3\u4e0b\u70b9\uff0c\u5373 \\({x_{top-left}, y_{top-left}, x_{bottom-right}, y_{bottom-right} }\\) \u3002\u5bf9\u4e8eanchor-based\u65b9\u6cd5\uff0c\u5c31\u662f\u4f30\u8ba1\u5bf9\u5e94\u7684offset\uff0c\u4f8b\u5982 \\({x_{center-offset}, y_{center-offset},w_{offset}, h_{offset}}\\) \u548c \\({x_{top-left-offset}, y_{top-left-offset},x_{bottom-right-offset}, y_{bottom-right-offset}}\\) \u3002\u4f46\u662f\uff0c\u76f4\u63a5\u4f30\u8ba1BBox\u6bcf\u4e2a\u70b9\u7684\u5750\u6807\u503c\uff0c\u5c31\u662f\u628a\u8fd9\u4e9b\u70b9\u5f53\u6210\u81ea\u53d8\u91cf\uff08independent variable\uff09\uff0c\u5b9e\u9645\u4e0a\u5e76\u6ca1\u6709\u8003\u8651\u5bf9\u8c61\u672c\u8eab\u7684\u5b8c\u6574\u6027\u3002 \u4e3a\u4e86\u66f4\u597d\u5730\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff0c\u6700\u8fd1\u6709\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86 IoU loss [90]\uff0c\u5b83\u8003\u8651\u4e86\u9884\u6d4b BBox \u533a\u57df\u548c\u771f\u5b9eBBox \u533a\u57df\u7684\u8986\u76d6\u8303\u56f4\u3002IoU \u635f\u5931\u8ba1\u7b97\u8fc7\u7a0b\u901a\u8fc7\u4f7f\u7528\u771f\u5b9e\u503c\u8ba1\u7b97IoU \u6765\u89e6\u53d1BBox \u56db\u4e2a\u5750\u6807\u70b9\u7684\u8ba1\u7b97\uff0c\u7136\u540e\u5c06\u751f\u6210\u7684\u7ed3\u679c\u8fde\u63a5\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u4ee3\u7801\u3002\u7531\u4e8eIoU\u662f\u6bd4\u4f8b\u4e0d\u53d8\u7684\u8868\u793a\uff0c\u53ef\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97 \\({x,y,w,h}\\) \u7684 \\(l_1\\) \u6216 \\(l_2\\) \u635f\u5931\u65f6\uff0c\u635f\u5931\u4f1a\u968f\u7740\u6bd4\u4f8b\u589e\u52a0\u7684\u95ee\u9898\u3002\u6700\u8fd1\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u7ee7\u7eed\u6539\u8fdb IoU \u635f\u5931\u3002\u4f8b\u5982\uff0cGIoU loss[65]\u9664\u4e86\u8986\u76d6\u533a\u57df\u5916\uff0c\u8fd8\u5305\u62ec\u7269\u4f53\u7684\u5f62\u72b6\u548c\u65b9\u5411\uff08orientation\uff09\u3002\u4ed6\u4eec\u63d0\u51fa\u5bfb\u627e\u53ef\u540c\u65f6\u8986\u76d6\u9884\u6d4bBBox\u548c\u771f\u5b9eBBox\u7684\u6700\u5c0f\u9762\u79efBBox\uff0c\u5e76\u7528\u8fd9\u4e2aBBox\u4f5c\u4e3a\u5206\u6bcd\uff08denominator\uff09\u6765\u4ee3\u66ff\u539f\u6765\u5728IoU loss\u4e2d\u4f7f\u7528\u7684\u5206\u6bcd\u3002\u81f3\u4e8eDIoU loss [99]\uff0c\u5b83\u989d\u5916\u8003\u8651\u4e86\u7269\u4f53\u4e2d\u5fc3\u7684\u8ddd\u79bb\uff0c\u800cCIoU loss [99]\uff0c\u53e6\u4e00\u65b9\u9762\u540c\u65f6\u8003\u8651\u4e86\u91cd\u53e0\u533a\u57df\u3001\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u548c\u5bbd\u9ad8\u6bd4\u3002CIoU \u5728 BBox \u56de\u5f52\u95ee\u9898\u4e0a\u53ef\u4ee5\u8fbe\u5230\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u7cbe\u5ea6\u3002 2.3. Bag of specials \u2003For those plugin modules and post-processing methods that only increase the inference cost by a small amount but can significantly improve the accuracy of object detection, we call them \u201cbag of specials\u201d. Generally speaking, these plugin modules are for enhancing certain attributes in a model, such as enlarging receptive field, introducing attention mechanism, or strengthening feature integration capability, etc., and post-processing is a method for screening model prediction results. \u2003\u5bf9\u4e8e\u90a3\u4e9b\u53ea\u589e\u52a0\u5c11\u91cf\u63a8\u7406\u6210\u672c\u4f46\u53ef\u4ee5\u663e\u7740\u63d0\u9ad8\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u7684\u63d2\u4ef6\u6a21\u5757\uff08plugin module\uff09\u548c\u540e\u5904\u7406\uff08post-processing\uff09\u65b9\u6cd5\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a\u201cbag of specials\u201d\u3002 \u4e00\u822c\u6765\u8bf4\uff0c\u8fd9\u4e9b\u63d2\u4ef6\u6a21\u5757\u662f\u4e3a\u4e86\u589e\u5f3a\u6a21\u578b\u4e2d\u7684\u67d0\u4e9b\u5c5e\u6027\uff08attribute\uff09\uff0c\u6bd4\u5982\u6269\u5927\u611f\u53d7\u91ce\uff08receptive field\uff09\u3001\u5f15\u5165\u6ce8\u610f\u529b\u673a\u5236\uff08attention mechanism\uff09\u3001\u6216\u8005\u52a0\u5f3a\u7279\u5f81\u6574\u5408\uff08integration\uff09\u80fd\u529b\u7b49\uff0c\u540e\u5904\u7406\u662f\u4e00\u79cd\u7b5b\u9009\uff08screen\uff09\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u65b9\u6cd5\u3002 \u2003Common modules that can be used to enhance receptive field are SPP [25], ASPP [5], and RFB [47]. The SPP module was originated from Spatial Pyramid Matching (SPM) [39], and SPMs original method was to split feature map into several d \u00d7 d equal blocks, where d can be \\({1, 2, 3, ...}\\) , thus forming spatial pyramid, and then extracting bag-of-word features. SPP integrates SPM into CNN and use max-pooling operation instead of bag-of-word operation. Since the SPP module proposed by He et al. [25] will output one dimensional feature vector, it is infeasible to be applied in Fully Convolutional Network (FCN). Thus in the design of YOLOv3 [63], Redmon and Farhadi improve SPP module to the concatenation of max-pooling outputs with kernel size \\(k \u00d7 k\\) , where \\(k = {1, 5, 9, 13}\\) , and stride equals to 1. Under this design, a relatively large k \u00d7 k maxpooling effectively increase the receptive field of backbone feature. After adding the improved version of SPP module, YOLOv3-608 upgrades AP50 by 2.7% on the MS COCO object detection task at the cost of 0.5% extra computation. The difference in operation between ASPP [5] module and improved SPP module is mainly from the original k\u00d7k kernel size, max-pooling of stride equals to 1 to several \\(3 \u00d7 3\\) kernel size, dilated ratio equals to k, and stride equals to 1 in dilated convolution operation. RFB module is to use several dilated convolutions of k\u00d7k kernel, dilated ratio equals to k, and stride equals to 1 to obtain a more comprehensive spatial coverage than ASPP . RFB [47] only costs 7% extra inference time to increase the AP50 of SSD on MS COCO by 5.7%. \u2003\u53ef\u7528\u4e8e\u589e\u5f3a\u611f\u53d7\u91ce\u7684\u5e38\u89c1\u6a21\u5757\u6709 SPP [25]\u3001ASPP [5] \u548c RFB [47]\u3002SPP\u6a21\u5757\u8d77\u6e90\u4e8eSpatial Pyramid Matching\uff08SPM\uff09[39]\uff0cSPM\u7684\u539f\u59cb\u65b9\u6cd5\u662f\u5c06\u7279\u5f81\u56fe\u5206\u5272\u6210\u51e0\u4e2a \\(d \u00d7 d\\) \u76f8\u7b49\u7684\u5757\uff0c\u5176\u4e2d \\(d\\) \u53ef\u4ee5\u662f \\({1, 2, 3, ...}\\) \uff0c\u56e0\u6b64\u5f62\u6210\u7a7a\u95f4\u91d1\u5b57\u5854\uff0c\u7136\u540e\u63d0\u53d6\u8bcd\u888b\uff08bag-of-word\uff09\u7279\u5f81\u3002SPP \u5c06 SPM \u96c6\u6210\u5230 CNN \u4e2d\u5e76\u4f7f\u7528\u6700\u5927\u6c60\u5316\u64cd\u4f5c\u800c\u4e0d\u662f\u8bcd\u888b\u64cd\u4f5c\u3002\u7531\u4e8eHe\u7b49\u4eba[25]\u63d0\u51fa\u7684SPP\u6a21\u5757\u4f1a\u8f93\u51fa\u4e00\u7ef4\u7279\u5f81\u5411\u91cf\uff0c\u56e0\u6b64\u4e0d\u9002\u7528\u4e8e\u5168\u5377\u79ef\u7f51\u7edc\uff08FCN\uff09\u3002\u56e0\u6b64\uff0c\u5728 YOLOv3 [63] \u7684\u8bbe\u8ba1\u4e2d\uff0cRedmon \u548c Farhadi \u5c06 SPP \u6a21\u5757\u6539\u8fdb\u4e3a \u5185\u6838\u5927\u5c0f\u4e3a \\(k \u00d7 k\\) \u7684\u6700\u5927\u6c60\u5316\u8f93\u51fa\u7684\u4e32\u8054\uff0c\u5176\u4e2d \\(k = {1, 5, 9, 13}\\) \uff0c\u6b65\u5e45\u7b49\u4e8e 1\u3002 \u5728\u8fd9\u79cd\u8bbe\u8ba1\u4e0b\uff0c\u76f8\u5bf9\u8f83\u5927\u7684 \\(k \u00d7 k\\) \u6700\u5927\u6c60\u5316\u6709\u6548\u5730\u589e\u52a0\u4e86\u4e3b\u5e72\uff08backbone\uff09\u7279\u5f81\u7684\u611f\u53d7\u91ce\u3002\u6dfb\u52a0\u6539\u8fdb\u7248SPP\u6a21\u5757\u540e\uff0cYOLOv3-608\u5728MS COCO\u7269\u4f53\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4ee50.5%\u7684\u989d\u5916\u8ba1\u7b97\u4e3a\u4ee3\u4ef7\u5c06AP50\u63d0\u5347\u4e862.7%\u3002ASPP [5] \u6a21\u5757\u548c\u6539\u8fdb\u7684 SPP \u6a21\u5757\u5728\u64cd\u4f5c\u4e0a\u7684\u533a\u522b\u4e3b\u8981\u662f\u539f\u59cb\u7684 \\(k\u00d7k\\) \u6838\u5927\u5c0f\uff0c\u6700\u5927\u6c60\u5316\u7684\u6b65\u5e45\u7b49\u4e8e1 \u5230\u51e0\u4e2a \\(3\u00d73\\) \u6838\u5927\u5c0f\uff0c\u6269\u5f20\u6bd4\uff08dilated ratio\uff09\u7b49\u4e8e k\uff0c\u5728\u6269\u5f20\u5377\u79ef\uff08dilated convolution\uff09\u64cd\u4f5c\u4e2d\u6b65\u5e45\u7b49\u4e8e 1\u3002RFB\u6a21\u5757\u662f\u4f7f\u7528\u51e0\u4e2ak\u00d7k\u6838\u7684\u6269\u5f20\u5377\u79ef\uff0c\u6269\u5f20\u6bd4\u7b49\u4e8ek\uff0c\u6b65\u5e45\u7b49\u4e8e1\uff0c\u4ee5\u83b7\u5f97\u6bd4ASPP\u66f4\u5168\u9762\u7684\u7a7a\u95f4\u8986\u76d6\u3002RFB [47] \u4ec5\u82b1\u8d39 7% \u7684\u989d\u5916\u63a8\u7406\u65f6\u95f4\u5373\u53ef\u5bf9 MS COCO \u4e0a SSD \u7684 AP50 \u63d0\u9ad8 5.7%\u3002 \u2003The attention module that is often used in object detection is mainly divided into channel-wise attention and point-wise attention, and the representatives of these two attention models are Squeeze-and-Excitation (SE) [29] and Spatial Attention Module (SAM) [85], respectively. Although SE module can improve the power of ResNet50 in the ImageNet image classification task 1% top-1 accuracy at the cost of only increasing the computational effort by 2%, but on a GPU usually it will increase the inference time by about 10%, so it is more appropriate to be used in mobile devices. But for SAM, it only needs to pay 0.1% extra calculation and it can improve ResNet50-SE 0.5% top-1 accuracy on the ImageNet image classification task. Best of all, it does not affect the speed of inference on the GPU at all. \u2003\u76ee\u6807\u68c0\u6d4b\u4e2d\u7ecf\u5e38\u4f7f\u7528\u7684\u6ce8\u610f\u529b\u6a21\u5757\uff08attention module\uff09\u4e3b\u8981\u5206\u4e3a\u9010\u901a\u9053\u6ce8\u610f\u529b\uff08channel-wise attention\uff09\u548c\u9010\u70b9\u6ce8\u610f\u529b\uff08point-wise attention\uff09\uff0c\u8fd9\u4e24\u79cd\u6ce8\u610f\u529b\u6a21\u578b\u7684\u4ee3\u8868\u5206\u522b\u662fSqueeze-and-Excitation\uff08SE\uff09[29]\u548cSpatial Attention Module\uff08SAM\uff09[85]\u3002\u867d\u7136 SE \u6a21\u5757\u53ef\u4ee5\u5c06 ResNet50 \u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u63d0\u9ad8 1% \\(top-1\\) \u51c6\u786e\u7387\uff0c\u4ee3\u4ef7\u662f\u53ea\u589e\u52a0 2% \u7684\u8ba1\u7b97\u91cf\uff0c\u4f46\u5728 GPU \u4e0a\u901a\u5e38\u4f1a\u589e\u52a0\u5927\u7ea6 10% \u7684\u63a8\u7406\u65f6\u95f4\uff0c \u6240\u4ee5\u66f4\u9002\u5408\u7528\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u3002\u4f46\u5bf9\u4e8e SAM \u6765\u8bf4\uff0c\u5b83\u53ea\u9700\u8981\u989d\u5916\u4ed8\u51fa 0.1% \u7684\u8ba1\u7b97\uff0c\u5c31\u53ef\u4ee5\u5c06 ResNet50-SE \u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684 \\(top-1\\) \u51c6\u786e\u7387\u63d0\u9ad8 0.5%\u3002 \u6700\u91cd\u8981\u7684\u662f\uff0c\u5b83\u4e0d\u4f1a\u5f71\u54cd GPU \u4e0a\u7684\u63a8\u7406\u901f\u5ea6\u3002 \u2003In terms of feature integration, the early practice is to use skip connection [51] or hyper-column [22] to integrate low- level physical feature to high-level semantic feature. Since multi-scale prediction methods such as FPN have become popular, many lightweight modules that integrate different feature pyramid have been proposed. The modules of this sort include SFAM [98], ASFF [48], and BiFPN [77]. The main idea of SFAM is to use SE module to execute channel- wise level re-weighting on multi-scale concatenated feature maps. As for ASFF, it uses softmax as point-wise level re- weighting and then adds feature maps of different scales. In BiFPN, the multi-input weighted residual connections is proposed to execute scale-wise level re-weighting, and then add feature maps of different scales. \u2003\u5728\u7279\u5f81\u6574\u5408\uff08feature integration\uff09\u65b9\u9762\uff0c\u65e9\u671f\u7684\u505a\u6cd5\u662f\u4f7f\u7528\u8df3\u8fc7\u8fde\u63a5\uff08skip connection\uff09[51]\u6216\u8d85\u5217\uff08hyper-column\uff09[22]\u5c06\u4f4e\u7ea7\u7269\u7406\u7279\u5f81\u6574\u5408\u5230\u9ad8\u7ea7\u8bed\u4e49\u7279\u5f81\uff08semantic feature\uff09\u3002 \u968f\u7740FPN\u7b49\u591a\u6bd4\u4f8b\uff08multi-scale\uff09\u9884\u6d4b\u65b9\u6cd5\u7684\u6d41\u884c\uff0c\u8bb8\u591a\u96c6\u6210\u4e0d\u540c\u7279\u5f81\u91d1\u5b57\u5854\u7684\u8f7b\u91cf\u7ea7\u6a21\u5757\u88ab\u63d0\u51fa\u3002 \u8fd9\u7c7b\u6a21\u5757\u5305\u62ec SFAM [98]\u3001ASFF [48] \u548c BiFPN [77]\u3002 SFAM \u7684\u4e3b\u8981\u601d\u60f3\u662f\u4f7f\u7528 SE \u6a21\u5757\u5728\u591a\u6bd4\u4f8b\u7ea7\u8054\uff08multi-scale concatenated\uff09\u7279\u5f81\u56fe\u4e0a\u6267\u884c\u9010\u901a\u9053\u6c34\u5e73\u7684\u91cd\u65b0\u52a0\u6743\uff08channel-wise level re-weighting\uff09\u3002 \u81f3\u4e8eASFF\uff0c\u5b83\u4f7f\u7528softmax\u4f5c\u4e3a\u9010\u70b9\u7ea7\u91cd\u52a0\u6743\uff08point-wise level re-weighting\uff09\uff0c\u7136\u540e\u6dfb\u52a0\u4e0d\u540c\u6bd4\u4f8b\u7684\u7279\u5f81\u56fe\u3002 \u5728 BiFPN \u4e2d\uff0c\u63d0\u51fa\u4e86\u4f7f\u7528\u591a\u8f93\u5165\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\uff08multi-input weighted residual connections\uff09\u6765\u6267\u884c\u6309\u5c3a\u5ea6\u7ea7\u522b\u91cd\u65b0\u52a0\u6743\uff08scale-wise level re-weighting\uff09\uff0c\u7136\u540e\u6dfb\u52a0\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u3002 \u2003In the research of deep learning, some people put their focus on searching for good activation function. A good activation function can make the gradient more efficiently propagated, and at the same time it will not cause too much extra computational cost. In 2010, Nair and Hin- ton [56] propose ReLU to substantially solve the gradient vanish problem which is frequently encountered in tradi- tional tanh and sigmoid activation function. Subsequently, LReLU [54], PReLU [24], ReLU6 [28], Scaled Exponential Linear Unit (SELU) [35], Swish [59], hard-Swish [27], and Mish [55], etc., which are also used to solve the gradient vanish problem, have been proposed. The main purpose of LReLU and PReLU is to solve the problem that the gradi- ent of ReLU is zero when the output is less than zero. As for ReLU6 and hard-Swish, they are specially designed for quantization networks. For self-normalizing a neural net- work, the SELU activation function is proposed to satisfy the goal. One thing to be noted is that both Swish and Mish are continuously differentiable activation function. \u2003\u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\u4e2d\uff0c\u6709\u4eba\u628a\u91cd\u70b9\u653e\u5728\u5bfb\u627e\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u4e0a\u3002\u4e00\u4e2a\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u53ef\u4ee5\u8ba9\u68af\u5ea6\u66f4\u6709\u6548\u5730\u4f20\u64ad\uff0c\u540c\u65f6\u4e0d\u4f1a\u9020\u6210\u592a\u591a\u989d\u5916\u7684\u8ba1\u7b97\u6210\u672c\u30022010 \u5e74\uff0cNair \u548c Hinton [56] \u63d0\u51fa ReLU \u6765\u5b9e\u8d28\u6027\u5730\u89e3\u51b3\u4f20\u7edf tanh \u548c sigmoid \u6fc0\u6d3b\u51fd\u6570\u4e2d\u7ecf\u5e38\u9047\u5230\u7684\u68af\u5ea6\u6d88\u5931\uff08gradient vanish\uff09\u95ee\u9898\u3002\u968f\u540e\uff0cLReLU [54]\u3001PReLU [24]\u3001ReLU6 [28]\u3001Scaled Exponential Linear Unit (SELU) [35]\u3001Swish [59]\u3001hard-Swish [27] \u548c Mish [55] \u7b49\u88ab\u63d0\u51fa\uff0c\u4e5f\u7528\u4e8e\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002LReLU\u548cPReLU\u7684\u4e3b\u8981\u76ee\u7684\u662f\u89e3\u51b3\u8f93\u51fa\u5c0f\u4e8e\u96f6\u65f6ReLU\u68af\u5ea6\u4e3a\u96f6\u7684\u95ee\u9898\u3002\u81f3\u4e8e ReLU6 \u548c hard-Swish\uff0c\u5b83\u4eec\u662f\u4e13\u95e8\u4e3a\u91cf\u5316\uff08quantization\uff09\u7f51\u7edc\u8bbe\u8ba1\u7684\u3002\u4e3a\u4e86\u81ea\u5f52\u4e00\u5316\uff08self-normalize\uff09\u795e\u7ecf\u7f51\u7edc\uff0cSELU \u6fc0\u6d3b\u51fd\u6570\u88ab\u63d0\u51fa\u4ee5\u5b9e\u73b0\u8be5\u76ee\u6807\u3002\u9700\u8981\u6ce8\u610f\u7684\u4e00\u4ef6\u4e8b\u662f Swish \u548c Mish \u90fd\u662f\u8fde\u7eed\u53ef\u5fae\uff08continuously differentiable\uff09\u7684\u6fc0\u6d3b\u51fd\u6570\u3002 \u2003The post-processing method commonly used in deep- learning-based object detection is NMS, which can be used to filter those BBoxes that badly predict the same ob- ject, and only retain the candidate BBoxes with higher re- sponse. The way NMS tries to improve is consistent with the method of optimizing an objective function. The orig- inal method proposed by NMS does not consider the con- text information, so Girshick et al. [19] added classification confidence score in R-CNN as a reference, and according to the order of confidence score, greedy NMS was performed in the order of high score to low score. As for soft NMS [1], it considers the problem that the occlusion of an object may cause the degradation of confidence score in greedy NMS with IoU score. The DIoU NMS [99] developers way of thinking is to add the information of the center point dis- tance to the BBox screening process on the basis of soft NMS. It is worth mentioning that, since none of above post- processing methods directly refer to the captured image fea- tures, post-processing is no longer required in the subse- quent development of an anchor-free method. \u2003\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7269\u4f53\u68c0\u6d4b\u5e38\u7528\u7684\u540e\u5904\u7406\uff08post-processing\uff09\u65b9\u6cd5\u662fNMS\uff0c\u5b83\u53ef\u4ee5\u7528\u6765\u8fc7\u6ee4\u90a3\u4e9b\u5bf9\u540c\u4e00\u7269\u4f53\u9884\u6d4b\u4e0d\u597d\u7684BBox\uff0c\u53ea\u4fdd\u7559\u54cd\u5e94\u8f83\u9ad8\u7684\u5019\u9009BBox\u3002NMS \u5c1d\u8bd5\u6539\u8fdb\u7684\u65b9\u5f0f\u4e0e\u4f18\u5316\u76ee\u6807\u51fd\u6570\u7684\u65b9\u6cd5\u4e00\u81f4\u3002 NMS \u63d0\u51fa\u7684\u539f\u59cb\u65b9\u6cd5\u6ca1\u6709\u8003\u8651\u4e0a\u4e0b\u6587\uff08context\uff09\u4fe1\u606f\uff0c\u56e0\u6b64 Girshick \u7b49\u4eba [19] \u5728 R-CNN \u4e2d\u6dfb\u52a0\u4e86\u5206\u7c7b\u7f6e\u4fe1\u5ea6\uff08classification confidence score\uff09\u5206\u6570\u4f5c\u4e3a\u53c2\u8003\uff0c\u5e76\u6309\u7167\u7f6e\u4fe1\u5ea6\u5f97\u5206\u7684\u987a\u5e8f\uff0c\u4ece\u9ad8\u5206\u5230\u4f4e\u5206\u7684\u987a\u5e8f\u8fdb\u884c\u8d2a\u5a6a\uff08greedy\uff09NMS\u3002\u5bf9\u4e8e soft NMS [1]\uff0c\u5b83\u8003\u8651\u4e86\u5728\u5177\u6709 IoU \u5206\u6570\u7684 greedy NMS \u4e2d\u5bf9\u8c61\u7684\u906e\u6321\uff08occlusion\uff09\u53ef\u80fd\u5bfc\u81f4\u7f6e\u4fe1\u5ea6\u4e0b\u964d\u7684\u95ee\u9898\u3002 DIoU NMS [99] \u5f00\u53d1\u8005\u7684\u601d\u8def\u662f\u5728\u8f6f NMS \u7684\u57fa\u7840\u4e0a\uff0c\u5728 BBox \u7b5b\u9009\uff08screen\uff09\u8fc7\u7a0b\u4e2d\u52a0\u5165\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u4fe1\u606f\u3002 \u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u7531\u4e8e\u4e0a\u8ff0\u540e\u5904\u7406\u65b9\u6cd5\u90fd\u6ca1\u6709\u76f4\u63a5\u53c2\u8003\u6355\u83b7\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u56e0\u6b64\u5728\u540e\u7eed\u5f00\u53d1anchor-free\u65b9\u6cd5\u65f6\u4e0d\u518d\u9700\u8981\u8fdb\u884c\u540e\u5904\u7406\u3002 3. Methodology \u65b9\u6cd5\u8bba \u2003The basic aim is fast operating speed of neural network, in production systems and optimization for parallel compu- tations, rather than the low computation volume theoreti- cal indicator (BFLOP). We present two options of real-time neural networks: \u2003\u57fa\u672c\u76ee\u6807\u662f\u795e\u7ecf\u7f51\u7edc\u5728\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u5feb\u901f\u8fd0\u884c\u548c\u5e76\u884c\u8ba1\u7b97\uff08parallel computation\uff09\u7684\u4f18\u5316\uff0c\u800c\u4e0d\u662f\u4f4e\u8ba1\u7b97\u91cf\u7406\u8bba\u6307\u6807\uff08low computation volume theoretical indicator\uff09\uff08BFLOP\uff09\u3002 \u6211\u4eec\u63d0\u4f9b\u4e86\u4e24\u79cd\u5b9e\u65f6\u795e\u7ecf\u7f51\u7edc\u9009\u9879\uff1a For GPU we use a small number of groups (1 - 8) in convolutional layers: CSPResNeXt50 / CSPDarknet53 \u5bf9\u4e8e GPU\uff0c\u6211\u4eec\u5728\u5377\u79ef\u5c42\u4e2d\u4f7f\u7528\u5c11\u91cf\u7ec4 (1 - 8)\uff1aCSPResNeXt50 / CSPDarknet53 For VPU - we use grouped-convolution, but we refrain from using Squeeze-and-excitement (SE) blocks specifically this includes the following models: EfficientNet-lite / MixNet [76] / GhostNet [21] / Mo-bileNetV3 \u5bf9\u4e8e VPU - \u6211\u4eec\u4f7f\u7528\u5206\u7ec4\u5377\u79ef\uff0c\u4f46\u6211\u4eec\u907f\u514d\u4f7f\u7528 Squeeze-and-excitement (SE) \u5757 , - \u5177\u4f53\u5305\u62ec\u6a21\u578b\uff1aEfficientNet-lite / MixNet [76] / GhostNet [21] / MobileNetV3 3.1. Selection of architecture \u67b6\u6784\u9009\u62e9 \u2003Our objective is to find the optimal balance among the in- put network resolution, the convolutional layer number, the parameter number \\((filter size^2 * filters * channel / groups)\\) , and the number of layer outputs (filters). For instance, our numerous studies demonstrate that the CSPResNext50 is considerably better compared to CSPDarknet53 in terms of object classification on the ILSVRC2012 (ImageNet) dataset [10]. However, conversely, the CSPDarknet53 is better compared to CSPResNext50 in terms of detecting ob- jects on the MS COCO dataset [46]. \u2003\u6211\u4eec\u7684\u76ee\u6807\u662f\u5728\u8f93\u5165\u7f51\u7edc\u5206\u8fa8\u7387\u3001\u5377\u79ef\u5c42\u6570\u3001\u53c2\u6570\u6570\u91cf \\((filter size^2 * filters * channel / groups)\\) \u548c\u5c42\u8f93\u51fa\u6570\uff08\u8fc7\u6ee4\u5668\uff09\u4e4b\u95f4\u627e\u5230\u6700\u4f73\u5e73\u8861\u3002 \u4f8b\u5982\uff0c\u6211\u4eec\u7684\u5927\u91cf\u7814\u7a76\u8868\u660e\uff0c\u5728 ILSVRC2012 (ImageNet) \u6570\u636e\u96c6 [10] \u4e0a\u7684\u5bf9\u8c61\u5206\u7c7b\u65b9\u9762\uff0cCSPResNext50 \u4e0e CSPDarknet53 \u76f8\u6bd4\u8981\u597d\u5f97\u591a\u3002 \u7136\u800c\uff0c\u76f8\u53cd\uff0c\u5728 MS COCO \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0cCSPDarknet53 \u6bd4 CSPResNext50 \u66f4\u597d [46]\u3002 \u2003The next objective is to select additional blocks for increasing the receptive field and the best method of parameter aggregation from different backbone levels for different detector levels: e.g. FPN, PAN, ASFF, BiFPN. \u2003\u4e0b\u4e00\u4e2a\u76ee\u6807\u662f\u9009\u62e9\u989d\u5916\u7684\u5757\u6765\u589e\u52a0\u611f\u53d7\u91ce\uff0c\u4ee5\u53ca\u4ece\u4e0d\u540c\u7684\u4e3b\u5e72\u7ea7\u522b\u4e3a\u4e0d\u540c\u7684\u68c0\u6d4b\u5668\u7ea7\u522b\u9009\u62e9\u53c2\u6570\u805a\u5408\uff08parameter aggregation\uff09\u7684\u6700\u4f73\u65b9\u6cd5\uff1a\u4f8b\u5982 FPN\u3001PAN\u3001ASFF\u3001BiFPN\u3002 \u2003A reference model which is optimal for classification is not always optimal for a detector. In contrast to the classifier, the detector requires the following: \u2003\u5bf9\u4e8e\u5206\u7c7b\u800c\u8a00\u6700\u4f73\u7684\u53c2\u8003\u6a21\u578b\u5bf9\u4e8e\u68c0\u6d4b\u5668\u800c\u8a00\u5e76\u4e0d\u603b\u662f\u6700\u4f73\u7684\u3002 \u4e0e\u5206\u7c7b\u5668\u76f8\u6bd4\uff0c\u68c0\u6d4b\u5668\u9700\u8981\u4ee5\u4e0b\u5185\u5bb9\uff1a Higher input network size (resolution) \u2013 for detecting multiple small-sized objects \u66f4\u9ad8\u7684\u8f93\u5165\u7f51\u7edc\u5c3a\u5bf8\uff08\u5206\u8fa8\u7387\uff09\u2014\u2014 \u7528\u4e8e\u68c0\u6d4b\u591a\u4e2a\u5c0f\u5c3a\u5bf8\u7269\u4f53 More layers \u2013 for a higher receptive field to cover the increased size of input network \u66f4\u591a\u5c42\u2014\u2014\u7528\u4e8e\u66f4\u9ad8\u7684\u611f\u53d7\u91ce\u4ee5\u8986\u76d6\u589e\u52a0\u7684\u8f93\u5165\u7f51\u7edc\u5927\u5c0f More parameters \u2013 for greater capacity of a model to detect multiple objects of different sizes in a single im- age \u66f4\u591a\u53c2\u6570\u2014\u2014\u4f7f\u6a21\u578b\u6709\u66f4\u5927\u7684\u80fd\u529b\u5728\u5355\u4e2a\u56fe\u50cf\u4e2d\u68c0\u6d4b\u591a\u4e2a\u4e0d\u540c\u5927\u5c0f\u7684\u5bf9\u8c61 \\(\\text { \u8868 1: \u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u3002 }\\) \u2003Hypothetically speaking, we can assume that a model with a larger receptive field size (with a larger number of convolutional layers \\(3 \u00d7 3\\) ) and a larger number of parameters should be selected as the backbone. Table 1 shows the information of CSPResNeXt50, CSPDarknet53, and EfficientNet B3. The CSPResNext50 contains only 16 convolutional layers \\(3 \u00d7 3\\) , a \\(425 \u00d7 425\\) receptive field and 20.6 M parameters, while CSPDarknet53 contains 29 convolu- tional layers \\(3 \u00d7 3\\) , a \\(725 \u00d7 725\\) receptive field and 27.6 M parameters. This theoretical justification, together with our numerous experiments, show that CSPDarknet53 neural network is the optimal model of the two as the backbone for a detector. \u2003\u5047\u8bbe\u5730\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u5047\u8bbe\u5e94\u8be5\u9009\u62e9\u5177\u6709\u66f4\u5927\u611f\u53d7\u91ce\u5927\u5c0f\uff08\u5177\u6709\u66f4\u591a\u5377\u79ef\u5c42 3 \u00d7 3\uff09\u548c\u66f4\u591a\u53c2\u6570\u7684\u6a21\u578b\u4f5c\u4e3a\u4e3b\u5e72\u3002 \u8868 1 \u663e\u793a\u4e86 CSPResNeXt50\u3001CSPDarknet53 \u548c EfficientNet B3 \u7684\u4fe1\u606f\u3002 CSPResNext50 \u4ec5\u5305\u542b 16 \u4e2a 3 \u00d7 3 \u5377\u79ef\u5c42\u3001425 \u00d7 425 \u611f\u53d7\u91ce\u548c 20.6 M \u53c2\u6570\uff0c\u800c CSPDarknet53 \u5305\u542b 29 \u4e2a\u5377\u79ef\u5c42 3 \u00d7 3\u3001725 \u00d7 725 \u611f\u53d7\u91ce\u548c 27.6 M \u53c2\u6570\u3002 \u8fd9\u4e2a\u7406\u8bba\u8bc1\u660e\uff0c\u52a0\u4e0a\u6211\u4eec\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u8868\u660e CSPDarknet53 \u795e\u7ecf\u7f51\u7edc\u662f\u4e24\u8005\u7684\u6700\u4f73\u6a21\u578b\uff0c\u4f5c\u4e3a\u68c0\u6d4b\u5668\u7684\u4e3b\u5e72\u3002 \u2003The influence of the receptive field with different sizes is summarized as follows: \u2003\u4e0d\u540c\u5927\u5c0f\u7684\u611f\u53d7\u91ce\u7684\u5f71\u54cd\u603b\u7ed3\u5982\u4e0b: Up to the object size - allows viewing the entire object \u6700\u591a\u5230\u5bf9\u8c61\u5927\u5c0f \u2013 \u5141\u8bb8\u67e5\u770b\u6574\u4e2a\u5bf9\u8c61 Up to network size - allows viewing the context around the object \u6700\u591a\u7f51\u7edc\u5927\u5c0f \u2013 \u5141\u8bb8\u67e5\u770b\u5bf9\u8c61\u5468\u56f4\u7684\u4e0a\u4e0b\u6587 Exceeding the network size - increases the number of connections between the image point and the final activation \u8d85\u8fc7\u7f51\u7edc\u5927\u5c0f \u2013 \u589e\u52a0\u56fe\u50cf\u70b9\u548c\u6700\u7ec8\u6fc0\u6d3b\u4e4b\u95f4\u7684\u8fde\u63a5\u6570 \u2003 We add the SPP block over the CSPDarknet53, since it significantly increases the receptive field, separates out the most significant context features and causes almost no reduction of the network operation speed. We use PANet as the method of parameter aggregation from different backbone levels for different detector levels, instead of the FPN used in YOLOv3. \u2003\u6211\u4eec\u5728 CSPDarknet53 \u4e0a\u6dfb\u52a0\u4e86 SPP \u5757\uff0c\u56e0\u4e3a\u5b83\u663e\u7740\u589e\u52a0\u4e86\u611f\u53d7\u91ce\uff0c\u5206\u79bb\u51fa\u6700\u91cd\u8981\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u5e76\u4e14\u51e0\u4e4e\u4e0d\u4f1a\u964d\u4f4e\u7f51\u7edc\u8fd0\u884c\u901f\u5ea6\u3002 \u6211\u4eec\u4f7f\u7528 PANet \u4f5c\u4e3a\u6765\u81ea\u4e0d\u540c\u4e3b\u5e72\u7ea7\u522b\u7684\u5bf9\u4e0d\u540c\u68c0\u6d4b\u5668\u7ea7\u522b\u7684\u53c2\u6570\u805a\u5408\u65b9\u6cd5\uff0c\u800c\u4e0d\u662f YOLOv3 \u4e2d\u4f7f\u7528\u7684 FPN\u3002 \u2003Finally, we choose CSPDarknet53 backbone, SPP additional module, PANet path-aggregation neck, and YOLOv3 (anchor based) head as the architecture of YOLOv4. \u2003\u6700\u540e\uff0c\u6211\u4eec\u9009\u62e9 CSPDarknet53 \u4e3b\u5e72\u3001SPP \u9644\u52a0\u6a21\u5757\u3001PANet \u8def\u5f84\u805a\u5408\u9888\u90e8\u548c YOLOv3\uff08(anchor based\uff09\u5934\u90e8\u4f5c\u4e3a YOLOv4 \u7684\u67b6\u6784\u3002 \u2003n the future we plan to expand significantly the content of Bag of Freebies (BoF) for the detector, which theoreti- cally can address some problems and increase the detector accuracy, and sequentially check the influence of each fea- ture in an experimental fashion. \u2003\u672a\u6765\u6211\u4eec\u8ba1\u5212\u5927\u529b\u6269\u5c55\u68c0\u6d4b\u5668\u7684Bag of Freebies (BoF) \u5185\u5bb9\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u89e3\u51b3\u4e00\u4e9b\u95ee\u9898\u5e76\u63d0\u9ad8\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4ee5\u5b9e\u9a8c\u65b9\u5f0f\u4f9d\u6b21\u68c0\u67e5\u6bcf\u4e2a\u7279\u5f81\u7684\u5f71\u54cd\u3002 \u2003We do not use Cross-GPU Batch Normalization (CGBN or SyncBN) or expensive specialized devices. This al- lows anyone to reproduce our state-of-the-art outcomes on a conventional graphic processor e.g. GTX 1080Ti or RTX 2080Ti. \u2003\u6211\u4eec\u4e0d\u4f7f\u7528\u8de8 GPU\uff08Cross-GPU\uff09\u6279\u91cf\u5f52\u4e00\u5316\uff08CGBN \u6216 SyncBN\uff09\u6216\u6602\u8d35\u7684\u4e13\u7528\u8bbe\u5907\u3002 \u8fd9\u5141\u8bb8\u4efb\u4f55\u4eba\u5728\u4f20\u7edf\u56fe\u5f62\u5904\u7406\u5668\u4e0a\u91cd\u73b0\u6211\u4eec\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u4f8b\u5982 GTX 1080Ti \u6216 RTX 2080Ti\u3002 3.2. Selection of BoF and BoS \u2003For improving the object detection training, a CNN usu- ally uses the following: \u2003\u4e3a\u4e86\u6539\u8fdb\u76ee\u6807\u68c0\u6d4b\u8bad\u7ec3\uff0cCNN \u901a\u5e38\u4f7f\u7528\u4ee5\u4e0b\u5185\u5bb9\uff1a Activations: ReLU, leaky-ReLU, parametric-ReLU, ReLU6, SELU, Swish, or Mish \u6fc0\u6d3b\uff1aReLU\u3001leaky-ReLU\u3001\u53c2\u6570\u5316 ReLU\uff08parametric-ReLU\uff09\u3001ReLU6\u3001SELU\u3001Swish \u6216 Mish Bounding box regression loss: MSE, IoU, GIoU,CIoU, DIoU \u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\uff1aMSE\u3001IoU\u3001GIoU\u3001CIoU\u3001DIoU Data augmentation: CutOut, MixUp, CutMix \u6570\u636e\u589e\u5f3a\uff1aCutOut\u3001MixUp\u3001CutMix Regularization method: DropOut, DropPath [36],Spatial DropOut [79], or DropBlock \u6b63\u5219\u5316\u65b9\u6cd5\uff1aDropOut\u3001DropPath [36]\u3001Spatial DropOut [79] \u6216 DropBlock Normalization of the network activations by their mean and variance: Batch Normalization (BN) [32], Cross-GPU Batch Normalization (CGBN or SyncBN)[93], Filter Response Normalization (FRN) [70], or Cross-Iteration Batch Normalization (CBN) [89] \u901a\u8fc7\u5747\u503c\u548c\u65b9\u5dee\u5bf9\u7f51\u7edc\u6fc0\u6d3b\u8fdb\u884c\u5f52\u4e00\u5316\uff1a\u6279\u5f52\u4e00\u5316 (BN) [32]\u3001Cross-GPU \u6279\u5f52\u4e00\u5316\uff08CGBN \u6216 SyncBN\uff09[93]\u3001\u6ee4\u6ce2\u5668\u54cd\u5e94\uff08Filter Response\uff09\u5f52\u4e00\u5316 (FRN) [70] \u6216\u4ea4\u53c9\u8fed\u4ee3\uff08Cross-Iteration\uff09\u6279\u5f52\u4e00\u5316 (CBN) [89] Skip-connections: Residual connections, Weighted residual connections, Multi-input weighted residual connections, or Cross stage partial connections (CSP) \u8df3\u8fc7\u8fde\u63a5\uff08Skip-connections\uff09\uff1a\u6b8b\u5dee\u8fde\u63a5\uff08Residual connection\uff09\u3001\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\u3001\u591a\u8f93\u5165\uff08Multi-input\uff09\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\u6216\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5\uff08Cross stage partial connections\uff09 (CSP) \u2003As for training activation function, since PReLU and SELU are more difficult to train, and ReLU6 is specifically designed for quantization network, we therefore remove the above activation functions from the candidate list. In the method of reqularization, the people who published Drop- Block have compared their method with other methods in detail, and their regularization method has won a lot. There- fore, we did not hesitate to choose DropBlock as our reg- ularization method. As for the selection of normalization method, since we focus on a training strategy that uses only one GPU, syncBN is not considered. \u2003\u81f3\u4e8e\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\uff0c\u7531\u4e8e PReLU \u548c SELU \u66f4\u96be\u8bad\u7ec3\uff0c\u800c ReLU6 \u662f\u4e13\u95e8\u4e3a\u91cf\u5316\uff08quantization\uff09\u7f51\u7edc\u8bbe\u8ba1\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u4ece\u5019\u9009\u5217\u8868\u4e2d\u5220\u9664\u4e86\u4e0a\u8ff0\u6fc0\u6d3b\u51fd\u6570\u3002 \u5728\u6b63\u5219\u5316\u7684\u65b9\u6cd5\u4e0a\uff0c\u53d1\u8868Drop-Block\u7684\u4eba\u8be6\u7ec6\u5bf9\u6bd4\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\u548c\u5176\u4ed6\u65b9\u6cd5\uff0c\u4ed6\u4eec\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u8d62\u5f97\u4e86\u5f88\u591a\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u6beb\u4e0d\u72b9\u8c6b\u5730\u9009\u62e9 DropBlock \u4f5c\u4e3a\u6211\u4eec\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002 \u81f3\u4e8e\u5f52\u4e00\u5316\u65b9\u6cd5\u7684\u9009\u62e9\uff0c\u7531\u4e8e\u6211\u4eec\u4e13\u6ce8\u4e8e\u4ec5\u4f7f\u7528\u4e00\u4e2a GPU \u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u56e0\u6b64\u6ca1\u6709\u8003\u8651 syncBN\u3002 3.3. Additional improvements \u2003In order to make the designed detector more suitable for training on single GPU, we made additional design and im- provement as follows: \u2003\u4e3a\u4e86\u4f7f\u6240\u8bbe\u8ba1\u7684\u68c0\u6d4b\u5668\u66f4\u9002\u5408\u5728\u5355\u4e00GPU\u4e0a\u8bad\u7ec3\uff0c\u6211\u4eec\u505a\u4e86\u5982\u4e0b\u989d\u5916\u7684\u8bbe\u8ba1\u548c\u6539\u8fdb: We introduce a new method of data augmentation Mosaic, and Self-Adversarial Training (SA T) \u6211\u4eec\u5f15\u5165\u4e86\u6570\u636e\u589e\u5f3a\u9a6c\u8d5b\u514b\uff08Mosaic\uff09\u548c\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u7684\u65b0\u65b9\u6cd5 We select optimal hyper-parameters while applying genetic algorithms \u6211\u4eec\u5728\u5e94\u7528\u9057\u4f20\u7b97\u6cd5\uff08genetic algorithm\uff09\u7684\u540c\u65f6\u9009\u62e9\u6700\u4f73\u8d85\u53c2\u6570 We modify some exsiting methods to make our design suitble for efficient training and detection - modified SAM, modified PAN, and Cross mini-Batch Normalization (CmBN) \u6211\u4eec\u4fee\u6539\u4e86\u4e00\u4e9b\u73b0\u6709\u7684\u65b9\u6cd5\uff0c\u4f7f\u6211\u4eec\u7684\u8bbe\u8ba1\u9002\u5408\u9ad8\u6548\u7684\u8bad\u7ec3\u548c\u68c0\u6d4b\u2014\u2014\u4fee\u6539\u7684 SAM\u3001\u4fee\u6539\u7684 PAN \u548c\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN) \u2003Mosaic represents a new data augmentation method that mixes 4 training images. Thus 4 different contexts are mixed, while CutMix mixes only 2 input images. This al- lows detection of objects outside their normal context. In addition, batch normalization calculates activation statistics from 4 different images on each layer. This significantly reduces the need for a large mini-batch size. \u2003Mosaic \u4ee3\u8868\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b83\u6df7\u5408\u4e86 4 \u4e2a\u8bad\u7ec3\u56fe\u50cf\u3002 \u56e0\u6b64\u6df7\u5408\u4e86 4 \u4e2a\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\uff0c\u800c CutMix \u4ec5\u6df7\u5408\u4e86 2 \u4e2a\u8f93\u5165\u56fe\u50cf\u3002 \u8fd9\u5141\u8bb8\u68c0\u6d4b\u6b63\u5e38\u4e0a\u4e0b\u6587\u4e4b\u5916\u7684\u5bf9\u8c61\u3002 \u6b64\u5916\uff0c\u6279\u91cf\u5f52\u4e00\u5316\u8ba1\u7b97\u6bcf\u5c42 4 \u4e2a\u4e0d\u540c\u56fe\u50cf\u7684\u6fc0\u6d3b\u7edf\u8ba1\u6570\u636e\u3002 \u8fd9\u663e\u7740\u51cf\u5c11\u4e86\u5bf9\u5927\u5c3a\u5bf8 mini-batch \u7684\u9700\u6c42\u3002 Figure 3: Mosaic represents a new method of data augmentation. \u56fe3:\u9a6c\u8d5b\u514b\u8868\u793a\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u7684\u65b0\u65b9\u6cd5\u3002 \u2003Self-Adversarial Training (SAT) also represents a new data augmentation technique that operates in 2 forward backward stages. In the 1st stage the neural network alters the original image instead of the network weights. In this way the neural network executes an adversarial attack on it- self, altering the original image to create the deception that there is no desired object on the image. In the 2nd stage, the neural network is trained to detect an object on this modified image in the normal way. \u2003 \u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u4e5f\u4ee3\u8868\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u5b83\u5728 2 \u4e2a\u524d\u5411\u548c\u540e\u5411\u9636\u6bb5\u4e2d\u8fd0\u884c\u3002 \u5728\u7b2c\u4e00\u9636\u6bb5\uff0c\u795e\u7ecf\u7f51\u7edc\u6539\u53d8\u539f\u59cb\u56fe\u50cf\u800c\u4e0d\u662f\u7f51\u7edc\u6743\u91cd\u3002 \u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u795e\u7ecf\u7f51\u7edc\u5bf9\u81ea\u8eab\u6267\u884c\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u6539\u53d8\u539f\u59cb\u56fe\u50cf \u4ee5\u5236\u9020\u56fe\u50cf\u4e0a\u6ca1\u6709\u6240\u9700\u5bf9\u8c61\u7684\u6b3a\u9a97\uff08deception\uff09\u3002 \u5728\u7b2c\u4e8c\u9636\u6bb5\uff0c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4ee5\u6b63\u5e38\u65b9\u5f0f\u68c0\u6d4b\u6b64\u4fee\u6539\u56fe\u50cf\u4e0a\u7684\u5bf9\u8c61\u3002 Figure 4: Cross mini-Batch Normalization. \u56fe 4\uff1a\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316\u3002 \u2003CmBN represents a CBN modified version, as shown in Figure 4, defined as Cross mini-Batch Normalization (CmBN). This collects statistics only between mini-batches within a single batch. \u2003 CmBN \u8868\u793a CBN \u4fee\u6539\u7248\u672c\uff0c\u5982\u56fe 4 \u6240\u793a\uff0c\u5b9a\u4e49\u4e3a\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3002 \u8fd9\u4ec5\u5728\u5355\u4e2a\u6279\u6b21\u5185\u7684\u5c0f\u6279\u6b21\u4e4b\u95f4\u6536\u96c6\u7edf\u8ba1\u4fe1\u606f\u3002 \u2003 We modify SAM from spatial-wise attention to point- wise attention, and replace shortcut connection of PAN to concatenation, as shown in Figure 5 and Figure 6, respec- tively. \u2003 \u6211\u4eec\u5c06 SAM \u4ece\u6309\u7a7a\u95f4\u6ce8\u610f\uff08spatial-wise attention\uff09\u4fee\u6539\u4e3a\u9010\u70b9\u6ce8\u610f\uff08point-wise attention\uff09\uff0c\u5e76\u5c06 PAN \u7684\u5feb\u6377\u8fde\u63a5\uff08shortcut connection\uff09\u66ff\u6362\u4e3a\u4e32\u8054\uff08concatenation\uff09\uff0c\u5206\u522b\u5982\u56fe 5 \u548c\u56fe 6 \u6240\u793a\u3002 3.4. YOLOv4 In this section, we shall elaborate the details of YOLOv4. \u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u8be6\u7ec6\u9610\u8ff0YOLOv4\u7684\u7ec6\u8282\u3002 YOLOv4 consists of: YOLOv4 \u5305\u62ec\uff1a Backbone: CSPDarknet53 [81] Neck: SPP [25], PAN [49] Head: YOLOv3 [63] YOLO v4 uses: YOLO v4 \u4f7f\u7528: Bag of Freebies (BoF) for backbone: CutMix and Mosaic data augmentation, DropBlock regularization, Class label smoothing \u9aa8\u5e72\u7684BoF\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u3001DropBlock \u6b63\u5219\u5316\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\uff08Class label smoothing\uff09 Bag of Specials (BoS) for backbone: Mish activation, Cross-stage partial connections (CSP), Multiinput weighted residual connections (MiWRC) \u9aa8\u5e72\u7684BoS\uff1aMish \u6fc0\u6d3b\u3001\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5 (CSP)\u3001\u591a\u8f93\u5165\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5 (MiWRC) Bag of Freebies (BoF) for detector: CIoU-loss, CmBN, DropBlock regularization, Mosaic data augmentation, Self-Adversarial Training, Eliminate grid sensitivity, Using multiple anchors for a single ground truth, Cosine annealing scheduler [52], Optimal hyperparameters, Random training shapes \u68c0\u6d4b\u5668\u7684BoF\uff1aCIoU-loss\u3001CmBN\u3001DropBlock \u6b63\u5219\u5316\u3001Mosaic \u6570\u636e\u589e\u5f3a\u3001\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3\uff08SAT\uff09\u3001\u6d88\u9664\u7f51\u683c\u654f\u611f\u6027\uff08Eliminate grid sensitivity\uff09\u3001\u4f7f\u7528\u591a\u4e2a\u951a\u70b9\uff08multiple anchors\uff09\u83b7\u53d6\u5355\u4e2a\u771f\u5b9e\u503c\u3001\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\u7a0b\u5e8f\uff08Cosine annealing scheduler\uff09 [52]\u3001\u6700\u4f18\u8d85\u53c2\u6570\uff0c\u968f\u673a\u8bad\u7ec3\u5f62\u72b6 Bag of Specials (BoS) for detector: Mish activation, SPP-block, SAM-block, PAN path-aggregation block,DIoU-NMS \u7528\u4e8e\u68c0\u6d4b\u5668\u7684\u7279\u6709\u5305 \uff08BoS\uff09\uff1a \u8bef\u533a\u6fc0\u6d3b\u3001 SPP \u5757\u3001 SAM \u5757\u3001 PAN \u8def\u5f84\u805a\u5408\u5757\u3001 DIoU-NMS 4. Experiments \u5b9e\u9a8c \u2003We test the influence of different training improvement techniques on accuracy of the classifier on ImageNet (ILSVRC 2012 val) dataset, and then on the accuracy of the detector on MS COCO (test-dev 2017) dataset. \u2003\u6211\u4eec\u5728 ImageNet (ILSVRC 2012 val) \u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u4e0d\u540c\u8bad\u7ec3\u6539\u8fdb\u6280\u672f\u5bf9\u5206\u7c7b\u5668\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u7136\u540e\u5728 MS COCO (test-dev 2017) \u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u3002 4.1. Experimental setup \u5b9e\u9a8c\u8bbe\u7f6e \u2003In ImageNet image classification experiments, the default hyper-parameters are as follows: the training steps is 8,000,000; the batch size and the mini-batch size are 128 and 32, respectively; the polynomial decay learning rate scheduling strategy is adopted with initial learning rate 0.1; the warm-up steps is 1000; the momentum and weight decay are respectively set as 0.9 and 0.005. All of our BoS experiments use the same hyper-parameter as the default setting, and in the BoF experiments, we add an additional 50% training steps. In the BoF experiments, we verify MixUp, CutMix, Mosaic, Bluring data augmentation, and label smoothing regularization methods. In the BoS experiments, we compared the effects of LReLU, Swish, and Mish activation function. All experiments are trained with a 1080 Ti or 2080 Ti GPU. \u2003\u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u5b9e\u9a8c\u4e2d\uff0c\u9ed8\u8ba4\u8d85\u53c2\u6570\u5982\u4e0b\uff1a\u8bad\u7ec3\u6b65\u6570\u4e3a 8,000,000\uff1b \u5927\u6279\u91cf\u548c\u5c0f\u6279\u91cf\u5927\u5c0f\u5206\u522b\u4e3a 128 \u548c 32\uff1b \u91c7\u7528\u591a\u9879\u5f0f\u8870\u51cf\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08polynomial decay learning rate scheduling strategy\uff09\uff0c\u521d\u59cb\u5b66\u4e60\u73870.1\uff1b \u9884\u70ed\uff08warm-up\uff09\u6b65\u6570\u4e3a1000\uff1b \u52a8\u91cf\u8870\u51cf\u548c\u6743\u91cd\u8870\u51cf\u5206\u522b\u8bbe\u7f6e\u4e3a 0.9 \u548c 0.005\u3002\u6211\u4eec\u6240\u6709\u7684 BoS \u5b9e\u9a8c\u90fd\u4f7f\u7528\u4e0e\u9ed8\u8ba4\u8bbe\u7f6e\u76f8\u540c\u7684\u8d85\u53c2\u6570\uff0c\u5e76\u4e14\u5728 BoF \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u989d\u5916\u7684 50% \u8bad\u7ec3\u6b65\u6570\u3002 \u5728 BoF \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u9a8c\u8bc1\u4e86 MixUp\u3001CutMix\u3001Mosaic\u3001Bluring \u6570\u636e\u589e\u5f3a\u548c\u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316\uff08label smoothing regularization\uff09\u65b9\u6cd5\u3002 \u5728 BoS \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6bd4\u8f83\u4e86 LReLU\u3001Swish \u548c Mish \u6fc0\u6d3b\u51fd\u6570\u7684\u6548\u679c\u3002 \u6240\u6709\u5b9e\u9a8c\u5747\u4f7f\u7528 1080 Ti \u6216 2080 Ti GPU \u8fdb\u884c\u8bad\u7ec3\u3002 \u2003In MS COCO object detection experiments, the default hyper-parameters are as follows: the training steps is 500,500; the step decay learning rate scheduling strategy is adopted with initial learning rate 0.01 and multiply with a factor 0.1 at the 400,000 steps and the 450,000 steps, respectively; The momentum and weight decay are respec- tively set as 0.9 and 0.0005. All architectures use a single GPU to execute multi-scale training in the batch size of 64 while mini-batch size is 8 or 4 depend on the architectures and GPU memory limitation. Except for us- ing genetic algorithm for hyper-parameter search experiments, all other experiments use default setting. Genetic algorithm used YOLOv3-SPP to train with GIoU loss and search 300 epochs for min-val 5k sets. We adopt searched learning rate 0.00261, momentum 0.949, IoU threshold for assigning ground truth 0.213, and loss normalizer 0.07 for genetic algorithm experiments. We have verified a large number of BoF, including grid sensitivity elimination, mosaic data augmentation, IoU threshold, genetic algorithm, class label smoothing, cross mini-batch normalization, self-adversarial training, cosine annealing scheduler, dynamic mini-batch size, DropBlock, Optimized Anchors, different kind of IoU losses. We also conduct experiments on various BoS, including Mish, SPP, SAM, RFB, BiFPN, and Gaus-sian YOLO [8]. For all experiments, we only use one GPU for training, so techniques such as syncBN that optimizes multiple GPUs are not used. \u2003\u5728 MS COCO \u6570\u636e\u96c6\u4e0a\u76ee\u6807\u68c0\u6d4b\u5b9e\u9a8c\u4e2d\uff0c\u9ed8\u8ba4\u8d85\u53c2\u6570\u5982\u4e0b\uff1a\u8bad\u7ec3\u6b65\u6570\u4e3a 500,500\uff1b \u91c7\u7528\u6b65\u957f\u8870\u51cf\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08step decay learning rate scheduling strategy\uff09\uff0c\u521d\u59cb\u5b66\u4e60\u73870.01\uff0c\u5206\u522b\u572840\u4e07\u6b65\u548c45\u4e07\u6b65\u4e58\u4ee5\u56e0\u5b500.1\uff1b \u52a8\u91cf\u548c\u6743\u91cd\u8870\u51cf\u5206\u522b\u8bbe\u7f6e\u4e3a 0.9 \u548c 0.0005\u3002\u6240\u6709\u67b6\u6784\uff08architecture\uff09\u90fd\u4f7f\u7528\u5355\u4e2a GPU \u4ee5 64 \u7684\u6279\u91cf\u5927\u5c0f\u6267\u884c\u591a\u6bd4\u4f8b\uff08multi-scale\uff09\u8bad\u7ec3\uff0c\u800c\u5c0f\u6279\u91cf\u5927\u5c0f\u4e3a 8 \u6216 4\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u67b6\u6784\u548c GPU \u5185\u5b58\u9650\u5236\u3002 \u9664\u4e86\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u8d85\u53c2\u6570\u641c\u7d22\u5b9e\u9a8c\u5916\uff0c\u5176\u4ed6\u6240\u6709\u5b9e\u9a8c\u5747\u4f7f\u7528\u9ed8\u8ba4\u8bbe\u7f6e\u3002 \u9057\u4f20\u7b97\u6cd5\u4f7f\u7528 YOLOv3-SPP \u8bad\u7ec3 GIoU\u635f\u5931\u5e76\u641c\u7d22 300 \u4e2a epoch \u4ee5\u83b7\u53d6min-val 5k \u96c6\u3002 \u6211\u4eec\u91c7\u7528\u641c\u7d22\u5b66\u4e60\u7387 0.00261\uff0c\u52a8\u91cf 0.949\uff0c\u5206\u914d\u771f\u5b9e\u503c\u7684 IoU \u9608\u503c 0.213\uff0c\u9057\u4f20\u7b97\u6cd5\u5b9e\u9a8c\u7684\u635f\u5931\u5f52\u4e00\u5316\u5668 0.07\u3002 \u6211\u4eec\u5df2\u7ecf\u9a8c\u8bc1\u4e86\u5927\u91cf\u7684 BoF\uff0c\u5305\u62ec\u7f51\u683c\u654f\u611f\u6027\u6d88\u9664\uff08grid sensitivity elimination\uff09\u3001\u9a6c\u8d5b\u514b\u6570\u636e\u589e\u5f3a\u3001IoU \u9608\u503c\u3001\u9057\u4f20\u7b97\u6cd5\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\u3001\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3001\u81ea\u5bf9\u6297\u8bad\u7ec3\u3001\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\u5668\u3001\u52a8\u6001\u5c0f\u6279\u91cf\u5927\u5c0f\u3001DropBlock , \u4f18\u5316\u7684\u951a\u70b9\uff08Optimized Anchor\uff09\uff0c\u4e0d\u540c\u79cd\u7c7b\u7684 IoU \u635f\u5931\u3002 \u6211\u4eec\u8fd8\u5bf9\u5404\u79cd BoS \u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5305\u62ec Mish\u3001SPP\u3001SAM\u3001RFB\u3001BiFPN \u548cGaussian YOLO [8]\u3002 \u5bf9\u4e8e\u6240\u6709\u5b9e\u9a8c\uff0c\u6211\u4eec\u53ea\u4f7f\u7528\u4e00\u4e2a GPU \u8fdb\u884c\u8bad\u7ec3\uff0c\u56e0\u6b64\u6ca1\u6709\u4f7f\u7528\u4f18\u5316\u591a\u4e2a GPU \u7684\u540c\u6b65BN\uff08syncBN\uff09 \u7b49\u6280\u672f\u3002 4.2. Influence of different features on Classifier \u4e0d\u540c\u7279\u5f81\u5bf9\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u5f71\u54cd \u2003First, we study the influence of different features on classifier training; specifically, the influence of Class la- bel smoothing, the influence of different data augmentation techniques, bilateral blurring, MixUp, CutMix and Mosaic, as shown in Fugure 7, and the influence of different activa- tions, such as Leaky-ReLU (by default), Swish, and Mish. \u2003\u9996\u5148\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u4e0d\u540c\u7279\u5f81\u5bf9\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u5f71\u54cd\uff1b \u5177\u4f53\u6765\u8bf4\uff0cClass label smoothing\u7684\u5f71\u54cd\uff0c\u4e0d\u540c\u6570\u636e\u589e\u5f3a\u6280\u672f\u7684\u5f71\u54cd\uff0c\u53cc\u8fb9\u6a21\u7cca\uff08bilateral blurring\uff09\uff0cMixUp\uff0cCutMix\u548cMosaic\uff0c\u5982Fugure 7\u6240\u793a\uff0c\u4ee5\u53ca\u4e0d\u540c\u6fc0\u6d3b\u7684\u5f71\u54cd\uff0c\u4f8b\u5982Leaky-ReLU\uff08\u9ed8\u8ba4\uff09\uff0cSwish \uff0c\u548cMish\u3002 Figure 7: V arious method of data augmentation. \u56fe7:\u5404\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002 \u2003In our experiments, as illustrated in Table 2, the classifier\u2019s accuracy is improved by introducing the features such as: CutMix and Mosaic data augmentation, Class label smoothing, and Mish activation. As a result, our BoF-backbone (Bag of Freebies) for classifier training includes the following: CutMix and Mosaic data augmentation and Class label smoothing. In addition we use Mish activation as a complementary option, as shown in Table 2 and Table \u2003 \u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5982\u8868 2 \u6240\u793a\uff0c\u901a\u8fc7\u5f15\u5165\u4ee5\u4e0b\u7279\u5f81\u6765\u63d0\u9ad8\u5206\u7c7b\u5668\u7684\u51c6\u786e\u6027\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\u548c Mish \u6fc0\u6d3b\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u7528\u4e8e\u5206\u7c7b\u5668\u8bad\u7ec3\u7684 BoF-backbone\uff08Bag of Freebies\uff09\u5305\u62ec\u4ee5\u4e0b\u5185\u5bb9\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u4ee5\u53ca\u7c7b\u6807\u7b7e\u5e73\u6ed1\u3002 \u6b64\u5916\uff0c\u6211\u4eec\u4f7f\u7528 Mish \u6fc0\u6d3b\u4f5c\u4e3a\u8865\u5145\u9009\u9879\uff08complementary option\uff09\uff0c\u5982\u8868 2 \u548c\u8868 3 \u6240\u793a\u3002 Table 2: Influence of BoF and Mish on the CSPResNeXt-50 classifier accuracy. \u88682:BoF\u548cMish\u5bf9CSPResNeXt-50\u5206\u7c7b\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002 Table 3: Influence of BoF and Mish on the CSPDarknet-53 classifier accuracy. \u88683:BoF\u548cMish\u5bf9CSPDarknet-53\u5206\u7c7b\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002 4.3. Influence of different features on Detector \u2003Further study concerns the influence of different Bag-of-Freebies (BoF-detector) on the detector training accuracy, as shown in Table 4. We significantly expand the BoF list through studying different features that increase the detector accuracy without affecting FPS: \u2003\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u6d89\u53ca\u4e0d\u540c\u7684\u514d\u8d39\u888b(BOF\u63a2\u6d4b\u5668)\u5bf9\u63a2\u6d4b\u5668\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u5982\u88684\u6240\u793a\u3002\u6211\u4eec\u901a\u8fc7\u7814\u7a76\u5728\u4e0d\u5f71\u54cdFPS\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u63a2\u6d4b\u5668\u7cbe\u5ea6\u7684\u4e0d\u540c\u7279\u6027\uff0c\u663e\u8457\u6269\u5c55\u4e86BOF\u5217\u8868\uff1a S: Eliminate grid sensitivity the equation \\(b_x = \u03c3(t_x )+ c_x , b_y = \u03c3(t_y )+c_y\\) , where \\(c_x\\) and \\(c_y\\) are always whole numbers, is used in YOLOv3 for evaluating the object coordinates, therefore, extremely high \\(t_x\\) absolute values are required for the \\(b_x\\) value approaching the \\(c_x \\ or \\ c_{ x} + 1\\) values. We solve this problem through multiplying the sigmoid by a factor exceeding 1.0, so eliminating the effect of grid on which the object is undetectable. S\uff1a \u6d88\u9664\u7f51\u683c\u7075\u654f\u5ea6\u65b9\u7a0b \\(b_x = \u03c3(t_x )+ c_x , b_y = \u03c3(t_y )+c_y\\) \uff0c \u5176\u4e2d \\(c_x\\) \u548c \\(c_y\\) \u59cb\u7ec8\u4e3a\u6574\u6570\uff0c \u5728 YOLOv3 \u4e2d\u4f7f\u7528\u7528\u4e8e\u8bc4\u4f30\u76ee\u6807\u5750\u6807\uff0c \u56e0\u6b64\uff0c\u63a5\u8fd1 \\(c_x \\ or \\ c_{ x} + 1\\) \u503c\u7684 \\(b_x\\) \u503c\u9700\u8981\u6781\u9ad8\u7684 \\(t_x\\) \u7edd\u5bf9\u503c\u3002\u6211\u4eec\u901a\u8fc7\u5c06 sigmoid \u4e58\u4ee5\u8d85\u8fc7 1.0 \u7684\u56e0\u5b50\u6765\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u5bf9\u8c61\u65e0\u6cd5\u68c0\u6d4b\u5230\u7684\u7f51\u683c\u7684\u5f71\u54cd\u3002 M: Mosaic data augmentation \u2013 using the 4-image mosaic during training instead of single image M\uff1a\u9a6c\u8d5b\u514b\u6570\u636e\u6269\u589e \u2013 \u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528 4 \u56fe\u50cf\u9576\u5d4c\uff0c\u800c\u4e0d\u662f\u5355\u4e2a\u56fe\u50cf IT: IoU threshold \u2013 using multiple anchors for a single ground truth IoU (truth, anchor) > IoU-threshold IT\uff1aIoU \u9608\u503c \u2013 \u4f7f\u7528\u591a\u4e2a\u951a\u70b9\u8fdb\u884c\u5355\u4e2a\u63a5\u5730\u771f\u76f8 IoU\uff08\u771f\u3001\u951a\uff09\u548c IoU \u9608\u503c | GA: Genetic algorithms \u2013 using genetic algorithms for selecting the optimal hyperparameters during network training on the \ufb01rst 10% of time periods GA\uff1a\u9057\u4f20\u7b97\u6cd5 \u2013 \u5728\u524d 10% \u7684\u65f6\u95f4\u6bb5\u7684\u7f51\u7edc\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u9009\u62e9\u6700\u4f73\u8d85\u53c2\u6570* LS: Class label smoothing \u2013 using class label smoothing for sigmoid activation LS\uff1a\u7c7b\u6807\u7b7e\u5e73\u6ed1 \u2013 \u4f7f\u7528\u7c7b\u6807\u7b7e\u5e73\u6ed1\u8fdb\u884c sigmoid \u6fc0\u6d3b CBN: CmBN \u2013 using Cross mini-Batch Normalization for collecting statistics inside the entire batch, instead of collecting statistics inside a single mini-batch CBN\uff1a CmBN \u2013 \u4f7f\u7528\u4ea4\u53c9\u5c0f\u6279\u5904\u7406\u89c4\u8303\u5316\u6536\u96c6\u6574\u4e2a\u6279\u5904\u7406\u4e2d\u7684\u7edf\u8ba1\u4fe1\u606f\uff0c\u800c\u4e0d\u662f\u5728\u5355\u4e2a\u5c0f\u6279\u5904\u7406\u4e2d\u6536\u96c6\u7edf\u8ba1\u4fe1\u606f* CA: Cosine annealing scheduler \u2013 altering the learning rate during sinusoid training CA\uff1a\u534f\u548c\u7d20\u9000\u706b\u8c03\u5ea6\u5668 \u2013 \u6539\u53d8\u6b63\u5f26\u8bad\u7ec3\u4e2d\u7684\u5b66\u4e60\u901f\u7387* DM: Dynamic mini-batch size \u2013 automatic increase of mini-batch size during small resolution training by using Random training shapes DM\uff1a\u52a8\u6001\u5c0f\u6279\u91cf\u5c3a\u5bf8 \u2013 \u4f7f\u7528\u968f\u673a\u8bad\u7ec3\u5f62\u72b6\u5728\u5c0f\u5206\u8fa8\u7387\u8bad\u7ec3\u671f\u95f4\u81ea\u52a8\u589e\u52a0\u5c0f\u6279\u91cf\u5927\u5c0f OA: Optimized Anchors \u2013 using the optimized anchors for training with the 512\u00d7512 network resolution OA\uff1a\u4f18\u5316\u7684\u951a\u70b9 \u2013 \u4f7f\u7528\u4f18\u5316\u7684\u951a\u70b9\u8fdb\u884c 512\u00d7512 \u7f51\u7edc\u5206\u8fa8\u7387\u7684\u8bad\u7ec3* GIoU, CIoU, DIoU, MSE \u2013 using different loss algorithms for bounded box regression GIoU\u3001CIoU\u3001DIoU\u3001MSE \u2013 \u5bf9\u8fb9\u754c\u6846\u56de\u5f52\u4f7f\u7528\u4e0d\u540c\u7684\u635f\u5931\u7b97\u6cd5 \u2003Further study concerns the in\ufb02uence of different Bagof-Specials (BoS-detector) on the detector training accuracy, including PAN, RFB, SAM, Gaussian YOLO (G), and ASFF, as shown in Table 5. In our experiments, the detector gets best performance when using SPP, PAN, and SAM. \u2003\u8fdb\u4e00\u6b65\u7814\u7a76\u6d89\u53ca\u4e0d\u540c\u7684\u5df4\u6208\u592b\u7279\u8f91\uff08BoS-\u68c0\u6d4b\u5668\uff09\u5bf9\u68c0\u6d4b\u5668\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u5305\u62ecPAN\u3001RFB\u3001SAM\u3001\u9ad8\u65afYOLO\uff08G\uff09\u548cASFF\uff0c\u5982\u88685\u6240\u793a\u3002\u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u68c0\u6d4b\u5668\u5728\u4f7f\u7528 SPP\u3001PAN \u548c SAM \u65f6\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002 Table 4: Ablation Studies of Bag-of-Freebies. (CSPResNeXt50-PANet-SPP , 512x512). Table 5: Ablation Studies of Bag-of-Specials. (Size 512x512). 4.4. Influence of different backbones and pretrained weightings on Detector training \u2003Further on we study the influence of different backbone models on the detector accuracy, as shown in Table 6. We notice that the model characterized with the best classifica- tion accuracy is not always the best in terms of the detector accuracy. \u2003 \u6700\u540e\uff0c\u6211\u4eec\u5206\u6790\u4e86\u5728\u4e0d\u540c\u6700\u5c0f\u6279\u91cf\u5927\u5c0f\u4e0b\u8bad\u7ec3\u7684\u6a21\u578b\u6240\u83b7\u5f97\u7684\u7ed3\u679c\uff0c\u7ed3\u679c\u5982\u88687\u6240\u793a\u3002\u4ece\u88687\u6240\u793a\u7684\u7ed3\u679c\u4e2d\uff0c\u6211\u4eec\u53d1\u73b0\u5728\u6dfb\u52a0BoF\u548cBoS\u8bad\u7ec3\u7b56\u7565\u4e4b\u540e\uff0c\u6700\u5c0f\u6279\u91cf\u5927\u5c0f\u51e0\u4e4e\u6ca1\u6709\u5f71\u54cd\u5728\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u4e0a\u3002\u8be5\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5f15\u5165BoF\u548cBoS\u4e4b\u540e\uff0c\u4e0d\u518d\u9700\u8981\u4f7f\u7528\u6602\u8d35\u7684GPU\u8fdb\u884c\u8bad\u7ec3\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u4efb\u4f55\u4eba\u90fd\u53ea\u80fd\u4f7f\u7528\u4f20\u7edf\u7684GPU\u6765\u8bad\u7ec3\u51fa\u8272\u7684\u63a2\u6d4b\u5668\u3002 Table 7: Using different mini-batch size for detector training. \u88687\uff1a\u4f7f\u7528\u4e0d\u540c\u7684\u5c0f\u6279\u91cf\u5bf9\u4e8e\u68c0\u6d4b\u5668\u8bad\u7ec3\u3002 5.Results \u2003Comparison of the results obtained with other state-of-the-art object detectors are shown in Figure 8. Our YOLOv4 are located on the Pareto optimality curve and are superior to the fastest and most accurate detectors in terms of both speed and accuracy. \u2003\u5f97\u5230\u7684\u7ed3\u679c\u4e0e\u5176\u4ed6\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u6bd4\u8f83\u5982\u56fe8\u6240\u793a\u3002\u6211\u4eec\u7684yolo4\u4f4d\u4e8ePareto optimality\u66f2\u7ebf\u4e0a\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u90fd\u4f18\u4e8e\u6700\u5feb\u548c\u6700\u7cbe\u786e\u7684\u63a2\u6d4b\u5668\u3002 \u2003Since different methods use GPUs of different architectures for inference time verification, we operate YOLOv4 on commonly adopted GPUs of Maxwell, Pascal, and Volta architectures, and compare them with other state-of-the-art methods. Table 8 lists the frame rate comparison results of using Maxwell GPU, and it can be GTX Titan X (Maxwell) or Tesla M40 GPU. Table 9 lists the frame rate comparison results of using Pascal GPU, and it can be Titan X (Pascal), Titan Xp, GTX 1080 Ti, or Tesla P100 GPU. As for Table 10, it lists the frame rate comparison results of using V olta GPU, and it can be Titan V olta or Tesla V100 GPU. \u2003\u7531\u4e8e\u4e0d\u540c\u7684\u65b9\u6cd5\u4f7f\u7528\u4e0d\u540c\u4f53\u7cfb\u7ed3\u6784\u7684GPU\u8fdb\u884c\u63a8\u7406\u65f6\u95f4\u9a8c\u8bc1\uff0c\u6211\u4eec\u5728\u5e38\u7528\u7684Maxwell\u3001Pascal\u548cVoltaArchitecture\u4f53\u7cfb\u7ed3\u6784\u7684GPU\u4e0a\u8fd0\u884cYOLOv4\uff0c\u5e76\u5c06\u5b83\u4eec\u4e0e\u5176\u4ed6\u5148\u8fdb\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u88688\u5217\u51fa\u4e86\u4f7f\u7528Maxwell GPU\u7684\u5e27\u7387\u6bd4\u8f83\u7ed3\u679c\uff0c\u53ef\u4ee5\u662fGTX Titan X(Maxwell)\u6216Tesla M40 GPU\u3002\u88689\u5217\u51fa\u4e86\u4f7f\u7528Pascal GPU\u7684\u5e27\u7387\u6bd4\u8f83\u7ed3\u679c\uff0c\u5b83\u53ef\u4ee5\u662fTitan X(Pascal)\u3001Titan XP\u3001GTX 1080 Ti\u6216Tesla P100 GPU\u3002\u886810\u5217\u51fa\u4e86\u4f7f\u7528VoltaGPU\u7684\u5e27\u7387\u5bf9\u6bd4\u7ed3\u679c\uff0c\u53ef\u4ee5\u662fTitan Volta\uff0c\u4e5f\u53ef\u4ee5\u662fTesla V100 GPU\u3002 6. Conclusions We offer a state-of-the-art detector which is faster (FPS) and more accurate (MS COCO \\(AP_{50...95}\\) and \\(AP_{50}\\) ) than all available alternative detectors. The detector described can be trained and used on a conventional GPU with 8-16 GB-VRAM this makes its broad use possible. The original concept of one-stage anchor-based detectors has proven its viability. We have verified a large number of features, and selected for use such of them for improving the accuracy of both the classifier and the detector. These features can be used as best-practice for future studies and developments. \u2003\u6211\u4eec\u63d0\u4f9b\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u901f\u5ea6\uff08FPS\uff09\u548c\u51c6\u786e\u5ea6\uff08MS COCO \\(AP_{50 ... 95}\\) \u548c \\(AP_{50}\\) \uff09\u6bd4\u6240\u6709\u53ef\u7528\u7684\u66ff\u4ee3\u68c0\u6d4b\u5668\u90fd\u9ad8\u3002\u6240\u63cf\u8ff0\u7684\u68c0\u6d4b\u5668\u53ef\u4ee5\u5728\u5177\u67098-16GB-VRAM\u7684\u5e38\u89c4GPU\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u4f7f\u7528\uff0c\u8fd9\u4f7f\u5f97\u5b83\u7684\u5e7f\u6cdb\u4f7f\u7528\u6210\u4e3a\u53ef\u80fd\u3002\u5355\u9636\u6bb5\u57fa\u4e8e\u951a\u6846\u7684\u68c0\u6d4b\u5668\u7684\u539f\u59cb\u6982\u5ff5\u5df2\u8bc1\u660e\u5176\u53ef\u884c\u6027\u3002\u6211\u4eec\u5df2\u7ecf\u9a8c\u8bc1\u4e86\u5927\u91cf\u7279\u5f81\uff0c\u5e76\u9009\u62e9\u4f7f\u7528\u5176\u4e2d\u7684\u4e00\u4e9b\u7279\u5f81\u4ee5\u63d0\u9ad8\u5206\u7c7b\u5668\u548c\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u3002\u8fd9\u4e9b\u529f\u80fd\u53ef\u4ee5\u7528\u4f5c\u5c06\u6765\u7814\u7a76\u548c\u5f00\u53d1\u7684\u6700\u4f73\u5b9e\u8df5\u3002 7. Acknowledgements \u2003The authors wish to thank Glenn Jocher for the ideas of Mosaic data augmentation, the selection of hyper-parameters by using genetic algorithms and solving the grid sensitivity problem https://github.com/ultralytics/yolov3. \u2003\u4f5c\u8005\u8981\u611f\u8c22Glenn Jocher\u8fdb\u884cMosaic\u6570\u636e\u589e\u5f3a\u7684\u60f3\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u9009\u62e9\u8d85\u53c2\u6570\u5e76\u89e3\u51b3\u7f51\u683c\u654f\u611f\u6027\u95ee\u9898\u7684\u65b9\u6cd5https://github.com/ultralytics/yolov3.10\u3002","title":"YOLOv4"},{"location":"thesis_interpretation/04_yolo.html#abstract","text":"There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is re- quired. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and com- bine some of them to achieve state-of-the-art results: 43.5% AP (65.7% AP50) for the MS COCO dataset at a real- time speed of \u223c65 FPS on Tesla V100. Source code is at https://github.com/AlexeyAB/darknet. \u636e\u8bf4\u6709\u5927\u91cf\u7279\u5f81\u53ef\u4ee5\u63d0\u9ad8\u5377\u79ef\u795e\u7ecf\u7f51\u7edc (CNN) \u7684\u51c6\u786e\u6027\u3002 \u9700\u8981\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u5bf9\u8fd9\u4e9b\u7279\u5f81\u7684\u7ec4\u5408\u8fdb\u884c\u5b9e\u9645\u6d4b\u8bd5\uff0c\u5e76\u5bf9\u7ed3\u679c\u8fdb\u884c\u7406\u8bba\u8bba\u8bc1\u3002 \u67d0\u4e9b\u7279\u5f81\u4e13\u95e8\u9488\u5bf9\u67d0\u4e9b\u6a21\u578b\uff0c\u4e13\u95e8\u9488\u5bf9\u67d0\u4e9b\u95ee\u9898\uff0c\u6216\u4ec5\u9488\u5bf9\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\uff1b \u800c\u4e00\u4e9b\u7279\u6027\uff0c\u5982\u6279\u91cf\u5f52\u4e00\u5316\u548c\u6b8b\u5dee\u8fde\u63a5\uff0c\u9002\u7528\u4e8e\u5927\u591a\u6570\u6a21\u578b\u3001\u4efb\u52a1\u548c\u6570\u636e\u96c6\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u901a\u7528\uff08universal\uff09\u7279\u5f81\u5305\u62ec\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5 (WRC)\u3001\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5 (CSP)\u3001\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3001\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u548c Mish \u6fc0\u6d3b\u3002 \u6211\u4eec\u4f7f\u7528\u65b0\u529f\u80fd\uff1aWRC\u3001CSP\u3001CmBN\u3001SAT\u3001Mish \u6fc0\u6d3b\u3001Mosaic \u6570\u636e\u589e\u5f3a\u3001DropBlock \u6b63\u5219\u5316\u548c CIoU \u635f\u5931\uff0c\u5e76\u7ed3\u5408\u5176\u4e2d\u7684\u4e00\u4e9b\u6765\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff1a\u5728 Tesla V100 \u4e0a\u4ee5 ~65 FPS \u7684\u5b9e\u65f6\u901f\u5ea6\u7528\u4e8e MS COCO \u6570\u636e\u96c6\uff0c\u7ed3\u679c\u4e3a43.5% AP\uff0865.7 % AP50) \u3002 \u6e90\u4ee3\u7801\u4f4d\u4e8e https://github.com/AlexeyAB/darknet\u3002","title":"Abstract \u6458\u8981"},{"location":"thesis_interpretation/04_yolo.html#introduction","text":"The majority of CNN-based object detectors are largely applicable only for recommendation systems. For example, searching for free parking spaces via urban video cameras is executed by slow accurate models, whereas car collision warning is related to fast inaccurate models. Improving the real-time object detector accuracy enables using them not only for hint generating recommendation systems, but also for stand-alone process management and human input reduction. Real-time object detector operation on conven- tional Graphics Processing Units (GPU) allows their mass usage at an affordable price. The most accurate modern neural networks do not operate in real time and require large number of GPUs for training with a large mini-batch-size. We address such problems through creating a CNN that op- erates in real-time on a conventional GPU, and for which training requires only one conventional GPU. \u2003\u5927\u591a\u6570\u57fa\u4e8e CNN \u7684\u5bf9\u8c61\u68c0\u6d4b\u5668\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4ec5\u9002\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\uff08recommendation system\uff09\u3002 \u4f8b\u5982\uff0c\u901a\u8fc7\u57ce\u5e02\u6444\u50cf\u673a\u641c\u7d22\u514d\u8d39\u505c\u8f66\u4f4d\u662f\u7531\u6162\u901f\u51c6\u786e\u6a21\u578b\u6267\u884c\u7684\uff0c\u800c\u6c7d\u8f66\u78b0\u649e\u8b66\u544a\u4e0e\u5feb\u901f\u4e0d\u51c6\u786e\u6a21\u578b\u6709\u5173\u3002 \u63d0\u9ad8\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u4e0d\u4ec5\u53ef\u4ee5\u5c06\u5b83\u4eec\u7528\u4e8e\u63d0\u793a\u751f\u6210\u63a8\u8350\u7cfb\u7edf\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u72ec\u7acb\u6d41\u7a0b\u7ba1\u7406\uff08stand-alone process management\uff09\u548c\u51cf\u5c11\u4eba\u5de5\u8f93\u5165\u3002 \u4f20\u7edf\u56fe\u5f62\u5904\u7406\u5355\u5143 (GPU) \u4e0a\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u64cd\u4f5c\u5141\u8bb8\u4ee5\u5b9e\u60e0\u7684\u4ef7\u683c\u5927\u89c4\u6a21\u4f7f\u7528\u3002 \u6700\u7cbe\u786e\u7684\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u65e0\u6cd5\u5b9e\u65f6\u8fd0\u884c\uff0c\u5e76\u4e14\u9700\u8981\u5927\u91cf\u7684 GPU \u8fdb\u884c\u5927\u578b\u5c0f\u578b\u6279\u5904\u7406\u5927\u5c0f\u7684\u8bad\u7ec3\u3002\u6211\u4eec\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a\u5728\u4f20\u7edf GPU \u4e0a\u5b9e\u65f6\u8fd0\u884c\u7684 CNN \u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4e3a\u6b64\u8bad\u7ec3\u53ea\u9700\u8981\u4e00\u4e2a\u5e38\u89c4 GPU\u3002 Figure 1: Comparison of the proposed YOLOv4 and other state-of-the-art object detectors. YOLOv4 runs twice faster than EfficientDet with comparable performance. Improves YOLOv3\u2019s AP and FPS by 10% and 12%, respectively. \u56fe1\uff1a\u5bf9YOLOv4\u548c\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u8fdb\u884c\u6bd4\u8f83\u3002\u5177\u6709\u540c\u7b49\u7684\u6027\u80fd\u60c5\u51b5\u4e0b\uff0cYOLOv4\u7684\u901f\u5ea6\u662f EfficientDet \u7684\u4e24\u500d\u3002\u5e76\u4e14 YOLOv4 \u5c06YOLOv3 \u7684 AP \u548c FPS \u5206\u522b\u63d0\u9ad8\u4e86 10% \u548c 12%\u3002 \u2003The main goal of this work is designing a fast operating speed of an object detector in production systems and opti- mization for parallel computations, rather than the low com- putation volume theoretical indicator (BFLOP). We hope that the designed object can be easily trained and used. For example, anyone who uses a conventional GPU to train and test can achieve real-time, high quality, and convincing ob- ject detection results, as the YOLOv4 results shown in Fig- ure 1. Our contributions are summarized as follows: \u2003\u8fd9\u9879\u5de5\u4f5c\u7684\u4e3b\u8981\u76ee\u6807\u662f\u8bbe\u8ba1\u751f\u4ea7\u7cfb\u7edf\u4e2d\u8fd0\u884c\u901f\u5ea6\u8f83\u5feb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5e76\u4f18\u5316\u5e76\u884c\u8ba1\u7b97\uff0c\u800c\u4e0d\u662f\u4f4e\u8ba1\u7b97\u91cf\u7406\u8bba\u6307\u6807 \uff08BFLOP\uff09\u3002\u6211\u4eec\u5e0c\u671b\u8bbe\u8ba1\u7684\u68c0\u6d4b\u5668\u80fd\u591f\u8f7b\u677e\u8bad\u7ec3\u548c\u4f7f\u7528\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u4efb\u4f55\u4f20\u7edf GPU \u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u4eba\u90fd\u53ef\u4ee5\u83b7\u5f97\u5b9e\u65f6\u3001\u9ad8\u8d28\u91cf\u548c\u4ee4\u4eba\u4fe1\u670d\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\uff0c\u5982\u56fe 1 \u6240\u793a\u7684 YOLOv4 \u7ed3\u679c\u6240\u793a\u3002\u6211\u4eec\u7684\u8d21\u732e\u603b\u7ed3\u5982\u4e0b\uff1a 1\uff09 We develope an efficient and powerful object detection model. It makes everyone can use a 1080 Ti or 2080 Ti GPU to train a super fast and accurate object detector. 1\uff09\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u9ad8\u6548\u800c\u5f3a\u5927\u7684\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u3002 \u5b83\u4f7f\u6bcf\u4e2a\u4eba\u90fd\u53ef\u4ee5\u4f7f\u7528 1080 Ti \u6216 2080 Ti GPU \u6765\u8bad\u7ec3\u4e00\u4e2a\u8d85\u5feb\u901f\u548c\u51c6\u786e\u7684\u76ee\u6807 \u68c0\u6d4b\u5668\u3002 2\uff09We verify the influence of state-of-the-art Bag-of- Freebies and Bag-of-Specials methods of object detec- tion during the detector training. 2\uff09\u5728\u68c0\u6d4b\u5668\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u9a8c\u8bc1\u4e86\u6700\u5148\u8fdb\u7684 Bag-of-Freebies \u548c Bag-of-Specials \u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u7684\u5f71\u54cd\u3002 3\uff09We modify state-of-the-art methods and make them more effecient and suitable for single GPU training, including CBN [89], PAN [49], SAM [85], etc. 3\uff09\u6211\u4eec\u4fee\u6539\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u66f4\u6709\u6548\uff0c\u66f4\u9002\u5408\u5355 GPU \u8bad\u7ec3\uff0c\u65b9\u6cd5\u5305\u62ec CBN [89]\u3001PAN [49]\u3001SAM [85] \u7b49\u3002 \u56fe2\uff1a\u76ee\u6807\u68c0\u6d4b\u5668","title":"Introduction \u5f15\u8a00"},{"location":"thesis_interpretation/04_yolo.html#2-related-work","text":"","title":"2. Related work \u76f8\u5173\u5de5\u4f5c"},{"location":"thesis_interpretation/04_yolo.html#21-object-detection-models","text":"A modern detector is usually composed of two parts,a backbone which is pre-trained on ImageNet and a head which is used to predict classes and bounding boxes of objects.For those detectors running on GPU platform, their backbone could be VGG [68], ResNet [26], ResNeXt [86], or DenseNet [30]. For those detectors running on CPU platform, their backbone could be SqueezeNet [31], MobileNet [28, 66, 27, 74], or ShuffleNet [97, 53]. As to the head part, it is usually categorized into two kinds, i.e., one-stage object detector and two-stage object detector. The most representative two-stage object detector is the R-CNN [19] series, including fast R-CNN [18], faster R-CNN [64], R-FCN [9], and Libra R-CNN [58]. It is also possible to make a two- stage object detector an anchor-free object detector, such as RepPoints [87]. As for one-stage object detector, the most representative models are YOLO [61, 62, 63], SSD [50], and RetinaNet [45]. In recent years, anchor-free one-stage object detectors are developed. The detectors of this sort are CenterNet [13], CornerNet [37, 38], FCOS [78], etc. Object detectors developed in recent years often insert some layers between backbone and head, and these layers are usually used to collect feature maps from different stages. We can call it the neck of an object detector. Usually, a neck is composed of several bottom-up paths and several topdown paths. Networks equipped with this mechanism include Feature Pyramid Network (FPN) [44], Path Aggregation Network (PAN) [49], BiFPN [77], and NAS-FPN [17]. \u2003\u73b0\u4ee3\u68c0\u6d4b\u5668\u901a\u5e38\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u4e00\u4e2a\u662f\u5728 ImageNet \u4e0a\u9884\u5148\u8bad\u7ec3\u7684\u9aa8\u5e72\u7f51\uff0c\u53e6\u4e00\u4e2a\u662f\u7528\u4e8e\u9884\u6d4b\u7269\u4f53\u7684\u7c7b\u548c\u8fb9\u754c\u6846\u7684\u5934\u90e8\u3002\u5bf9\u4e8e\u5728 GPU \u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u4e3b\u5e72\u53ef\u4ee5\u662f VGG [68]\u3001ResNet [26]\u3001ResNeXt [86]\u6216DenseNet [30]\u3002\u5bf9\u4e8e\u5728 CPU \u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u4e3b\u5e72\u53ef\u4ee5\u662fSqueezeNet [31], MobileNet [28, 66, 27, 74], \u6216 ShuffleNet [97, 53].\u3002\u81f3\u4e8e\u5934\u90e8\u90e8\u5206\uff0c\u901a\u5e38\u5206\u4e3a\u4e24\u7c7b \uff0c \u5373\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u548c\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668 \u3002\u6700\u5177\u4ee3\u8868\u6027\u7684\u4e24\u7ea7\u76ee\u6807\u68c0\u6d4b\u5668\u662fR-CNN[19]\u7cfb\u5217\uff0c\u5305\u62ecfast R-CNN [18], faster R-CNN [64], R-FCN [9], \u548c Libra R-CNN [58] \u3002\u4e5f\u53ef\u4ee5\u4f7f\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u6210\u4e3a\u65e0\u951a\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5982 RepPoints [87]\u3002\u81f3\u4e8e\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u6700\u5177\u4ee3\u8868\u6027\u7684\u578b\u53f7\u662fYOLO[61\u300162\u300163]\u3001SSD[50]\u548cRetinaNet[45]\u3002\u8fd1\u5e74\u6765\uff0c\u7814\u5236\u4e86\u65e0\u951a\u5f0f\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u3002\u6b64\u7c7b\u68c0\u6d4b\u5668\u6709 CenterNet [13]\u3001CornerNet [37\u3001 38]\u3001FCOS [78]\u7b49\u3002\u8fd1\u5e74\u6765\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u7814\u53d1\u901a\u5e38\u662f\u5728\u9aa8\u5e72\u548c\u5934\u90e8\u4e4b\u95f4\u7684\u6dfb\u52a0\u4e00\u4e9b\u5c42\uff0c\u8fd9\u4e9b\u5c42\u901a\u5e38\u7528\u4e8e\u6536\u96c6\u4e0d\u540c\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u3002\u6211\u4eec\u53ef\u4ee5\u79f0\u5b83\u4e3a\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u8116\u5b50\u3002\u901a\u5e38\uff0c\u9888\u90e8\u7531\u51e0\u4e2a\u81ea\u4e0b\u800c\u4e0a\u7684\u8def\u5f84\u548c\u51e0\u4e2a\u81ea\u4e0a\u800c\u4e0b\u7684\u8def\u5f84\u7ec4\u6210\u3002\u914d\u5907\u6b64\u673a\u5236\u7684\u7f51\u7edc\u5305\u62ec\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc \uff08FPN\uff09 [44]\u3001\u8def\u5f84\u805a\u5408\u7f51\u7edc \uff08PAN\uff09 [49]\u3001BiFPN [77]\u548c NAS-FPN [17]\u3002 \u2003In addition to the above models, some researchers put their emphasis on directly building a new backbone (DetNet [43], DetNAS [7]) or a new whole model (SpineNet [12], HitDetector [20]) for object detection. \u2003\u9664\u4e86\u4e0a\u8ff0\u6a21\u578b\u5916\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u8fd8\u628a\u91cd\u70b9\u76f4\u63a5\u653e\u5728\u6784\u5efa\u4e00\u4e2a\u65b0\u7684\u4e3b\u5e72\uff08DetNet [43]\uff0cDetNAS [7]\uff09\u6216\u65b0\u7684\u5b8c\u6574\u6a21\u578b\uff08SpineNet [12]\uff0cHitDetector [20]\uff09\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u3002 \u2003To sum up, an ordinary object detector is composed of several parts: \u2003\u7efc\u4e0a\u6240\u8ff0\uff0c\u4e00\u4e2a\u666e\u901a\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u7531\u5982\u4e0b\u90e8\u5206\u7ec4\u6210\uff1a Input: Image, Patches, Image Pyramid Backbones: VGG16 [68], ResNet-50 [26], SpineNet [12], EfficientNet-B0/B7 [75], CSPResNeXt50 [81], CSPDarknet53 [81] Neck: Additional blocks: SPP [25], ASPP [5], RFB [47], SAM [85] Path-aggregation blocks: FPN [44], PAN [49], NAS-FPN [17], Fully-connected FPN, BiFPN [77], ASFF [48], SFAM [98] Heads: Dense Prediction (one-stage): RPN [64], SSD [50], YOLO [61], RetinaNet [45] (anchor based) CornerNet [37], CenterNet [13], MatrixNet [60], FCOS [78] (anchor free) Sparse Prediction (two-stage): Faster R-CNN [64], R-FCN [9], Mask R-CNN [23] (anchor based) RepPoints [87] (anchor free)","title":"2.1. Object detection models  \u76ee\u6807\u68c0\u6d4b\u6a21\u578b"},{"location":"thesis_interpretation/04_yolo.html#22-bag-of-freebies","text":"Usually, a conventional object detector is trained offline. Therefore, researchers always like to take this advantage and develop better training methods which can make the object detector receive better accuracy without increasing the inference cost. We call these methods that only change the training strategy or only increase the training cost as \u201cbag of freebies.\u201d What is often adopted by object detection methods and meets the definition of bag of freebies is data augmentation. The purpose of data augmentation is to increase the variability of the input images, so that the designed object detection model has higher robustness to the images obtained from different environments. For examples, photometric distortions and geometric distortions are two commonly used data augmentation method and they definitely benefit the object detection task. In dealing with photometric distortion, we adjust the brightness, contrast, hue, saturation, and noise of an image. For geometric distortion, we add random scaling, cropping, flipping, and rotating. \u2003\u901a\u5e38\uff0c\u4f20\u7edf\u7684\u7269\u4f53\u68c0\u6d4b\u5668\u662f\u79bb\u7ebf\u8bad\u7ec3\u7684\u3002 \u56e0\u6b64\uff0c\u7814\u7a76\u4eba\u5458\u603b\u662f\u559c\u6b22\u5229\u7528\u8fd9\u4e00\u4f18\u52bf\uff0c\u5f00\u53d1\u66f4\u597d\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u76ee\u6807\u68c0\u6d4b\u5668\u5728\u4e0d\u589e\u52a0\u63a8\u7406\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u66f4\u597d\u7684\u51c6\u786e\u6027\u3002\u6211\u4eec\u5c06\u8fd9\u4e9b\u53ea\u4f1a\u6539\u53d8\u8bad\u7ec3\u7b56\u7565\u6216\u53ea\u4f1a\u589e\u52a0\u8bad\u7ec3\u6210\u672c\u7684\u65b9\u6cd5\u79f0\u4e3a \u201cbag of freebies\u201d\u3002\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u7ecf\u5e38\u91c7\u7528\u4e14\u7b26\u5408bag of freebies \u5b9a\u4e49\u7684\u662f\u6570\u636e\u589e\u5f3a\uff08data augmentation\uff09\u3002\u6570\u636e\u589e\u5f3a\u7684\u76ee\u7684\u662f\u589e\u52a0\u8f93\u5165\u56fe\u50cf\u7684\u53ef\u53d8\u6027\uff08variability\uff09\uff0c\u4f7f\u8bbe\u8ba1\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u5bf9\u4e0d\u540c\u73af\u5883\u4e0b\u83b7\u5f97\u7684\u56fe\u50cf\u5177\u6709\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002\u4f8b\u5982\uff0c\u5149\u5ea6\u5931\u771f\uff08photometric distortion\uff09\u548c\u51e0\u4f55\u5931\u771f\uff08geometric distortion\uff09\u662f\u4e24\u79cd\u5e38\u7528\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b83\u4eec\u7edd\u5bf9\u6709\u5229\u4e8e\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u3002\u5728\u5904\u7406\u5149\u5ea6\u5931\u771f\u65f6\uff0c\u6211\u4eec\u8c03\u6574\u56fe\u50cf\u7684\u4eae\u5ea6\uff08brightness\uff09\u3001\u5bf9\u6bd4\u5ea6\uff08contrast\uff09\u3001\u8272\u8c03\uff08hue\uff09\u3001\u9971\u548c\u5ea6\uff08saturation\uff09\u548c\u566a\u58f0\uff08noise\uff09\u3002 \u5bf9\u4e8e\u51e0\u4f55\u5931\u771f\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u968f\u673a\u7f29\u653e\uff08random scale\uff09\u3001\u88c1\u526a\uff08crop\uff09\u3001\u7ffb\u8f6c\uff08flip\uff09\u548c\u65cb\u8f6c\uff08rotate\uff09\u3002 \u2003The data augmentation methods mentioned above are all pixel-wise adjustments, and all original pixel information in the adjusted area is retained. In addition, some researchers engaged in data augmentation put their emphasis on sim- ulating object occlusion issues. They have achieved good results in image classification and object detection. For ex- ample, random erase [100] and CutOut [11] can randomly select the rectangle region in an image and fill in a random or complementary value of zero. As for hide-and-seek [69] and grid mask [6], they randomly or evenly select multiple rectangle regions in an image and replace them to all ze- ros. If similar concepts are applied to feature maps, there are DropOut [71], DropConnect [80], and DropBlock [16] methods. In addition, some researchers have proposed the methods of using multiple images together to perform data augmentation. For example, MixUp [92] uses two images to multiply and superimpose with different coefficient ra- tios, and then adjusts the label with these superimposed ra- tios. As for CutMix [91], it is to cover the cropped image to rectangle region of other images, and adjusts the label according to the size of the mix area. In addition to the above mentioned methods, style transfer GAN [15] is also used for data augmentation, and such usage can effectively reduce the texture bias learned by CNN. \u2003\u4e0a\u9762\u63d0\u5230\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u90fd\u662f\u9010\u50cf\u7d20\uff08pixel-wise\uff09\u8c03\u6574\u7684\uff0c\u5e76\u4e14\u4fdd\u7559\u4e86\u8c03\u6574\u533a\u57df\u5185\u7684\u6240\u6709\u539f\u59cb\u50cf\u7d20\u4fe1\u606f\u3002 \u6b64\u5916\uff0c\u4e00\u4e9b\u4ece\u4e8b\u6570\u636e\u589e\u5f3a\u7684\u7814\u7a76\u4eba\u5458\u5c06\u91cd\u70b9\u653e\u5728\u6a21\u62df\u5bf9\u8c61\u906e\u6321\uff08occlusion\uff09\u95ee\u9898\u4e0a\u3002\u4ed6\u4eec\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u76ee\u6807\u68c0\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u5f88\u597d\u7684\u6548\u679c\u3002 \u4f8b\u5982\uff0c\u968f\u673a\u64e6\u9664[100]\u548cCutOut[11]\u53ef\u4ee5\u968f\u673a\u9009\u62e9\u56fe\u50cf\u4e2d\u7684\u77e9\u5f62\u533a\u57df\u5e76\u586b\u5145\u968f\u673a\u503c\u6216\u4e92\u8865\u503c\u96f6\uff08complementary value of zero\uff09\u3002\u81f3\u4e8e\u6349\u8ff7\u85cf\uff08hide-and-seek\uff09 [69] \u548c\u7f51\u683c\u8499\u7248\uff08grid mask\uff09 [6]\uff0c\u5b83\u4eec\u968f\u673a\u6216\u5747\u5300\u5730\u9009\u62e9\u56fe\u50cf\u4e2d\u7684\u591a\u4e2a\u77e9\u5f62\u533a\u57df\u5e76\u5c06\u5b83\u4eec\u5168\u66ff\u6362\u4e3a\u96f6\u3002 \u5982\u679c\u5c06\u7c7b\u4f3c\u7684\u6982\u5ff5\u5e94\u7528\u4e8e\u7279\u5f81\u56fe\uff0c\u5219\u6709 DropOut [71]\u3001DropConnect [80] \u548c DropBlock [16] \u65b9\u6cd5\u3002 \u6b64\u5916\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u5c06\u591a\u4e2a\u56fe\u50cf\u4e00\u8d77\u4f7f\u7528\u6765\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u65b9\u6cd5\u3002 \u4f8b\u5982\uff0cMixUp [92] \u4f7f\u7528\u4e24\u5e45\u56fe\u50cf\u6765\u4f7f\u4e0d\u540c\u7684\u7cfb\u6570\u6bd4\u4f8b\uff08coefficient ratio\uff09\u76f8\u4e58\u53e0\u52a0\uff08superimpose\uff09\uff0c\u7136\u540e\u7528\u8fd9\u4e9b\u53e0\u52a0\u6bd4\u4f8b\u8c03\u6574\u6807\u7b7e\u3002\u81f3\u4e8eCutMix [91]\uff0c\u5c31\u662f\u5c06\u88c1\u526a\u540e\u7684\u56fe\u50cf\u8986\u76d6\u5230\u5176\u4ed6\u56fe\u50cf\u7684\u77e9\u5f62\u533a\u57df\uff0c\u5e76\u6839\u636e\u6df7\u5408\u533a\u57df\u7684\u5927\u5c0f\u8c03\u6574\u6807\u7b7e\u3002 \u9664\u4e86\u4e0a\u8ff0\u65b9\u6cd5\u5916\uff0c\u98ce\u683c\u8fc1\u79fb GAN [15] \u4e5f\u88ab\u7528\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u8fd9\u79cd\u7528\u6cd5\u53ef\u4ee5\u6709\u6548\u51cf\u5c11 CNN \u5b66\u4e60\u5230\u7684\u7eb9\u7406\uff08texture\uff09\u504f\u5dee\u3002 \u2003Different from the various approaches proposed above, some other bag of freebies methods are dedicated to solving the problem that the semantic distribution in the dataset may have bias. In dealing with the problem of semantic distribution bias, a very important issue is that there is a problem of data imbalance between different classes, and this problem is often solved by hard negative example mining [72] or online hard example mining [67] in two-stage object detector. But the example mining method is not applicable to one-stage object detector, because this kind of detector belongs to the dense prediction architecture. Therefore Lin et al. [45] proposed focal loss to deal with the problem of data imbalance existing between various classes. Another very important issue is that it is difficult to express the relationship of the degree of association between different categories with the one-hot hard representation. This representation scheme is often used when executing labeling. The label smoothing proposed in [73] is to convert hard label into soft label for training, which can make model more robust. In order to obtain a better soft label, Islam et al. [33] introduced the concept of knowledge distillation to design the label refinement network. \u2003\u4e0e\u4e0a\u9762\u63d0\u51fa\u7684\u5404\u79cd\u65b9\u6cd5\u4e0d\u540c\uff0c\u5176\u4ed6\u4e00\u4e9bbag of freebies\u65b9\u6cd5\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3\u6570\u636e\u96c6\u4e2d\u8bed\u4e49\u5206\u5e03\uff08semantic distribution\uff09\u53ef\u80fd\u5b58\u5728\u504f\u5dee\u7684\u95ee\u9898\u3002\u5728\u5904\u7406\u8bed\u4e49\u5206\u5e03\u504f\u5dee\u95ee\u9898\u65f6\uff0c\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u662f\u4e0d\u540c\u7c7b\u4e4b\u95f4\u5b58\u5728\u6570\u636e\u4e0d\u5e73\u8861\uff08data imbalance\uff09\u7684\u95ee\u9898\u3002 \u8fd9\u4e2a\u95ee\u9898\u901a\u5e38\u901a\u8fc7\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u4e2d\u7684\u786c\u53cd\u4f8b\u6316\u6398\uff08hard negative example mining\uff09[72]\u6216\u5728\u7ebf\u786c\u793a\u4f8b\u6316\u6398\uff08online hard example mining\uff09[67]\u6765\u89e3\u51b3\u3002 \u4f46\u662f\u793a\u4f8b\u6316\u6398\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u56e0\u4e3a\u8fd9\u79cd\u68c0\u6d4b\u5668\u5c5e\u4e8e\u5bc6\u96c6\u9884\u6d4b\u67b6\u6784\u3002\u56e0\u6b64 Lin \u7b49\u4eba [45] \u63d0\u51fa\u4e86focal loss \u6765\u5904\u7406\u5404\u4e2a\u7c7b\u4e4b\u95f4\u5b58\u5728\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002 \u53e6\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u662f\uff0c\u4f7f\u7528one-hot hard\u8868\u793a\u5f88\u96be\u8868\u8fbe\u4e0d\u540c\u7c7b\u522b\u4e4b\u95f4\u7684\u5173\u8054\u7a0b\u5ea6\u7684\u5173\u7cfb\u3002 \u8fd9\u79cd\u8868\u793a\u65b9\u6848\u5728\u8fdb\u884c\u6807\u6ce8\u65f6\u7ecf\u5e38\u4f7f\u7528\u3002[73]\u4e2d\u63d0\u51fa\u7684\u6807\u7b7e\u5e73\u6ed1\uff08label smoothing\uff09\u662f\u5c06\u786c\u6807\u7b7e\uff08hard label\uff09\u8f6c\u6362\u4e3a\u8f6f\u6807\u7b7e\uff08soft label\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u4ee5\u4f7f\u6a21\u578b\u66f4\u52a0\u9c81\u68d2\u3002 \u4e3a\u4e86\u83b7\u5f97\u66f4\u597d\u7684\u8f6f\u6807\u7b7e\uff0cIslam\u7b49[33]\u5f15\u5165\u4e86\u77e5\u8bc6\u84b8\u998f\uff08knowledge distillation\uff09\u7684\u6982\u5ff5\u6765\u8bbe\u8ba1\u6807\u7b7e\u7ec6\u5316\u7f51\u7edc\uff08label refinement network\uff09\u3002 \u2003The last bag of freebies is the objective function of Bounding Box (BBox) regression. The traditional object detector usually uses Mean Square Error (MSE) to directly perform regression on the center point coordinates and height and width of the BBox, i.e., \\({x_{center}, y_{center}, w, h}\\) , or the upper left point and the lower right point, i.e., \\({x_{top-left}, y_{top-left}, x_{bottom-right}, y_{bottom-right} }\\) . As for anchor-based method, it is to estimate the corresponding offset, for example \\({x_{center-offset}, y_{center-offset},w_{offset}, h_{offset}}\\) and \\({x_{top-left-offset}, y_{top-left-offset},x_{bottom-right-offset}, y_{bottom-right-offset}}\\) . However, to directly estimate the coordinate values of each point of the BBox is to treat these points as independent variables, but in fact does not consider the integrity of the object itself. In order to make this issue processed better, some researchers recently proposed IoU loss [90], which puts the coverage of predicted BBox area and ground truth BBox area into consideration. The IoU loss computing process will trigger the calculation of the four coordinate points of the BBox by executing IoU with the ground truth, and then connecting the generated results into a whole code. Because IoU is a scale invariant representation, it can solve the problem that when traditional methods calculate the \\(l_1\\) or \\(l_2\\) loss of \\({x, y, w,h}\\) , the loss will increase with the scale. Recently, some researchers have continued to improve IoU loss. For example, GIoU loss [65] is to include the shape and orientation of object in addition to the coverage area. They proposed to find the smallest area BBox that can simultaneously cover the predicted BBox and ground truth BBox, and use this BBox as the denominator to replace the denominator originally used in IoU loss. As for DIoU loss [99], it additionally considers the distance of the center of an object, and CIoU loss [99], on the other hand simultaneously considers the overlapping area, the distance between center points, and the aspect ratio. CIoU can achieve better convergence speed and accuracy on the BBox regression problem. \u2003\u6700\u540e\u4e00\u4e9b bag of freebies \u662f\u8fb9\u754c\u6846 (BBox) \u56de\u5f52\u7684\u76ee\u6807\u51fd\u6570\u3002 \u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u901a\u5e38\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u76f4\u63a5\u5bf9BBox\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u8fdb\u884c\u56de\u5f52\uff0c\u5373 \\({x_{center}, y_{center},w, h}\\) \uff0c\u6216\u5de6\u4e0a\u70b9\u548c\u53f3\u4e0b\u70b9\uff0c\u5373 \\({x_{top-left}, y_{top-left}, x_{bottom-right}, y_{bottom-right} }\\) \u3002\u5bf9\u4e8eanchor-based\u65b9\u6cd5\uff0c\u5c31\u662f\u4f30\u8ba1\u5bf9\u5e94\u7684offset\uff0c\u4f8b\u5982 \\({x_{center-offset}, y_{center-offset},w_{offset}, h_{offset}}\\) \u548c \\({x_{top-left-offset}, y_{top-left-offset},x_{bottom-right-offset}, y_{bottom-right-offset}}\\) \u3002\u4f46\u662f\uff0c\u76f4\u63a5\u4f30\u8ba1BBox\u6bcf\u4e2a\u70b9\u7684\u5750\u6807\u503c\uff0c\u5c31\u662f\u628a\u8fd9\u4e9b\u70b9\u5f53\u6210\u81ea\u53d8\u91cf\uff08independent variable\uff09\uff0c\u5b9e\u9645\u4e0a\u5e76\u6ca1\u6709\u8003\u8651\u5bf9\u8c61\u672c\u8eab\u7684\u5b8c\u6574\u6027\u3002 \u4e3a\u4e86\u66f4\u597d\u5730\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff0c\u6700\u8fd1\u6709\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86 IoU loss [90]\uff0c\u5b83\u8003\u8651\u4e86\u9884\u6d4b BBox \u533a\u57df\u548c\u771f\u5b9eBBox \u533a\u57df\u7684\u8986\u76d6\u8303\u56f4\u3002IoU \u635f\u5931\u8ba1\u7b97\u8fc7\u7a0b\u901a\u8fc7\u4f7f\u7528\u771f\u5b9e\u503c\u8ba1\u7b97IoU \u6765\u89e6\u53d1BBox \u56db\u4e2a\u5750\u6807\u70b9\u7684\u8ba1\u7b97\uff0c\u7136\u540e\u5c06\u751f\u6210\u7684\u7ed3\u679c\u8fde\u63a5\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u4ee3\u7801\u3002\u7531\u4e8eIoU\u662f\u6bd4\u4f8b\u4e0d\u53d8\u7684\u8868\u793a\uff0c\u53ef\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97 \\({x,y,w,h}\\) \u7684 \\(l_1\\) \u6216 \\(l_2\\) \u635f\u5931\u65f6\uff0c\u635f\u5931\u4f1a\u968f\u7740\u6bd4\u4f8b\u589e\u52a0\u7684\u95ee\u9898\u3002\u6700\u8fd1\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u7ee7\u7eed\u6539\u8fdb IoU \u635f\u5931\u3002\u4f8b\u5982\uff0cGIoU loss[65]\u9664\u4e86\u8986\u76d6\u533a\u57df\u5916\uff0c\u8fd8\u5305\u62ec\u7269\u4f53\u7684\u5f62\u72b6\u548c\u65b9\u5411\uff08orientation\uff09\u3002\u4ed6\u4eec\u63d0\u51fa\u5bfb\u627e\u53ef\u540c\u65f6\u8986\u76d6\u9884\u6d4bBBox\u548c\u771f\u5b9eBBox\u7684\u6700\u5c0f\u9762\u79efBBox\uff0c\u5e76\u7528\u8fd9\u4e2aBBox\u4f5c\u4e3a\u5206\u6bcd\uff08denominator\uff09\u6765\u4ee3\u66ff\u539f\u6765\u5728IoU loss\u4e2d\u4f7f\u7528\u7684\u5206\u6bcd\u3002\u81f3\u4e8eDIoU loss [99]\uff0c\u5b83\u989d\u5916\u8003\u8651\u4e86\u7269\u4f53\u4e2d\u5fc3\u7684\u8ddd\u79bb\uff0c\u800cCIoU loss [99]\uff0c\u53e6\u4e00\u65b9\u9762\u540c\u65f6\u8003\u8651\u4e86\u91cd\u53e0\u533a\u57df\u3001\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u548c\u5bbd\u9ad8\u6bd4\u3002CIoU \u5728 BBox \u56de\u5f52\u95ee\u9898\u4e0a\u53ef\u4ee5\u8fbe\u5230\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u7cbe\u5ea6\u3002","title":"2.2. Bag of freebies"},{"location":"thesis_interpretation/04_yolo.html#23-bag-of-specials","text":"For those plugin modules and post-processing methods that only increase the inference cost by a small amount but can significantly improve the accuracy of object detection, we call them \u201cbag of specials\u201d. Generally speaking, these plugin modules are for enhancing certain attributes in a model, such as enlarging receptive field, introducing attention mechanism, or strengthening feature integration capability, etc., and post-processing is a method for screening model prediction results. \u2003\u5bf9\u4e8e\u90a3\u4e9b\u53ea\u589e\u52a0\u5c11\u91cf\u63a8\u7406\u6210\u672c\u4f46\u53ef\u4ee5\u663e\u7740\u63d0\u9ad8\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u7684\u63d2\u4ef6\u6a21\u5757\uff08plugin module\uff09\u548c\u540e\u5904\u7406\uff08post-processing\uff09\u65b9\u6cd5\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a\u201cbag of specials\u201d\u3002 \u4e00\u822c\u6765\u8bf4\uff0c\u8fd9\u4e9b\u63d2\u4ef6\u6a21\u5757\u662f\u4e3a\u4e86\u589e\u5f3a\u6a21\u578b\u4e2d\u7684\u67d0\u4e9b\u5c5e\u6027\uff08attribute\uff09\uff0c\u6bd4\u5982\u6269\u5927\u611f\u53d7\u91ce\uff08receptive field\uff09\u3001\u5f15\u5165\u6ce8\u610f\u529b\u673a\u5236\uff08attention mechanism\uff09\u3001\u6216\u8005\u52a0\u5f3a\u7279\u5f81\u6574\u5408\uff08integration\uff09\u80fd\u529b\u7b49\uff0c\u540e\u5904\u7406\u662f\u4e00\u79cd\u7b5b\u9009\uff08screen\uff09\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u65b9\u6cd5\u3002 \u2003Common modules that can be used to enhance receptive field are SPP [25], ASPP [5], and RFB [47]. The SPP module was originated from Spatial Pyramid Matching (SPM) [39], and SPMs original method was to split feature map into several d \u00d7 d equal blocks, where d can be \\({1, 2, 3, ...}\\) , thus forming spatial pyramid, and then extracting bag-of-word features. SPP integrates SPM into CNN and use max-pooling operation instead of bag-of-word operation. Since the SPP module proposed by He et al. [25] will output one dimensional feature vector, it is infeasible to be applied in Fully Convolutional Network (FCN). Thus in the design of YOLOv3 [63], Redmon and Farhadi improve SPP module to the concatenation of max-pooling outputs with kernel size \\(k \u00d7 k\\) , where \\(k = {1, 5, 9, 13}\\) , and stride equals to 1. Under this design, a relatively large k \u00d7 k maxpooling effectively increase the receptive field of backbone feature. After adding the improved version of SPP module, YOLOv3-608 upgrades AP50 by 2.7% on the MS COCO object detection task at the cost of 0.5% extra computation. The difference in operation between ASPP [5] module and improved SPP module is mainly from the original k\u00d7k kernel size, max-pooling of stride equals to 1 to several \\(3 \u00d7 3\\) kernel size, dilated ratio equals to k, and stride equals to 1 in dilated convolution operation. RFB module is to use several dilated convolutions of k\u00d7k kernel, dilated ratio equals to k, and stride equals to 1 to obtain a more comprehensive spatial coverage than ASPP . RFB [47] only costs 7% extra inference time to increase the AP50 of SSD on MS COCO by 5.7%. \u2003\u53ef\u7528\u4e8e\u589e\u5f3a\u611f\u53d7\u91ce\u7684\u5e38\u89c1\u6a21\u5757\u6709 SPP [25]\u3001ASPP [5] \u548c RFB [47]\u3002SPP\u6a21\u5757\u8d77\u6e90\u4e8eSpatial Pyramid Matching\uff08SPM\uff09[39]\uff0cSPM\u7684\u539f\u59cb\u65b9\u6cd5\u662f\u5c06\u7279\u5f81\u56fe\u5206\u5272\u6210\u51e0\u4e2a \\(d \u00d7 d\\) \u76f8\u7b49\u7684\u5757\uff0c\u5176\u4e2d \\(d\\) \u53ef\u4ee5\u662f \\({1, 2, 3, ...}\\) \uff0c\u56e0\u6b64\u5f62\u6210\u7a7a\u95f4\u91d1\u5b57\u5854\uff0c\u7136\u540e\u63d0\u53d6\u8bcd\u888b\uff08bag-of-word\uff09\u7279\u5f81\u3002SPP \u5c06 SPM \u96c6\u6210\u5230 CNN \u4e2d\u5e76\u4f7f\u7528\u6700\u5927\u6c60\u5316\u64cd\u4f5c\u800c\u4e0d\u662f\u8bcd\u888b\u64cd\u4f5c\u3002\u7531\u4e8eHe\u7b49\u4eba[25]\u63d0\u51fa\u7684SPP\u6a21\u5757\u4f1a\u8f93\u51fa\u4e00\u7ef4\u7279\u5f81\u5411\u91cf\uff0c\u56e0\u6b64\u4e0d\u9002\u7528\u4e8e\u5168\u5377\u79ef\u7f51\u7edc\uff08FCN\uff09\u3002\u56e0\u6b64\uff0c\u5728 YOLOv3 [63] \u7684\u8bbe\u8ba1\u4e2d\uff0cRedmon \u548c Farhadi \u5c06 SPP \u6a21\u5757\u6539\u8fdb\u4e3a \u5185\u6838\u5927\u5c0f\u4e3a \\(k \u00d7 k\\) \u7684\u6700\u5927\u6c60\u5316\u8f93\u51fa\u7684\u4e32\u8054\uff0c\u5176\u4e2d \\(k = {1, 5, 9, 13}\\) \uff0c\u6b65\u5e45\u7b49\u4e8e 1\u3002 \u5728\u8fd9\u79cd\u8bbe\u8ba1\u4e0b\uff0c\u76f8\u5bf9\u8f83\u5927\u7684 \\(k \u00d7 k\\) \u6700\u5927\u6c60\u5316\u6709\u6548\u5730\u589e\u52a0\u4e86\u4e3b\u5e72\uff08backbone\uff09\u7279\u5f81\u7684\u611f\u53d7\u91ce\u3002\u6dfb\u52a0\u6539\u8fdb\u7248SPP\u6a21\u5757\u540e\uff0cYOLOv3-608\u5728MS COCO\u7269\u4f53\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4ee50.5%\u7684\u989d\u5916\u8ba1\u7b97\u4e3a\u4ee3\u4ef7\u5c06AP50\u63d0\u5347\u4e862.7%\u3002ASPP [5] \u6a21\u5757\u548c\u6539\u8fdb\u7684 SPP \u6a21\u5757\u5728\u64cd\u4f5c\u4e0a\u7684\u533a\u522b\u4e3b\u8981\u662f\u539f\u59cb\u7684 \\(k\u00d7k\\) \u6838\u5927\u5c0f\uff0c\u6700\u5927\u6c60\u5316\u7684\u6b65\u5e45\u7b49\u4e8e1 \u5230\u51e0\u4e2a \\(3\u00d73\\) \u6838\u5927\u5c0f\uff0c\u6269\u5f20\u6bd4\uff08dilated ratio\uff09\u7b49\u4e8e k\uff0c\u5728\u6269\u5f20\u5377\u79ef\uff08dilated convolution\uff09\u64cd\u4f5c\u4e2d\u6b65\u5e45\u7b49\u4e8e 1\u3002RFB\u6a21\u5757\u662f\u4f7f\u7528\u51e0\u4e2ak\u00d7k\u6838\u7684\u6269\u5f20\u5377\u79ef\uff0c\u6269\u5f20\u6bd4\u7b49\u4e8ek\uff0c\u6b65\u5e45\u7b49\u4e8e1\uff0c\u4ee5\u83b7\u5f97\u6bd4ASPP\u66f4\u5168\u9762\u7684\u7a7a\u95f4\u8986\u76d6\u3002RFB [47] \u4ec5\u82b1\u8d39 7% \u7684\u989d\u5916\u63a8\u7406\u65f6\u95f4\u5373\u53ef\u5bf9 MS COCO \u4e0a SSD \u7684 AP50 \u63d0\u9ad8 5.7%\u3002 \u2003The attention module that is often used in object detection is mainly divided into channel-wise attention and point-wise attention, and the representatives of these two attention models are Squeeze-and-Excitation (SE) [29] and Spatial Attention Module (SAM) [85], respectively. Although SE module can improve the power of ResNet50 in the ImageNet image classification task 1% top-1 accuracy at the cost of only increasing the computational effort by 2%, but on a GPU usually it will increase the inference time by about 10%, so it is more appropriate to be used in mobile devices. But for SAM, it only needs to pay 0.1% extra calculation and it can improve ResNet50-SE 0.5% top-1 accuracy on the ImageNet image classification task. Best of all, it does not affect the speed of inference on the GPU at all. \u2003\u76ee\u6807\u68c0\u6d4b\u4e2d\u7ecf\u5e38\u4f7f\u7528\u7684\u6ce8\u610f\u529b\u6a21\u5757\uff08attention module\uff09\u4e3b\u8981\u5206\u4e3a\u9010\u901a\u9053\u6ce8\u610f\u529b\uff08channel-wise attention\uff09\u548c\u9010\u70b9\u6ce8\u610f\u529b\uff08point-wise attention\uff09\uff0c\u8fd9\u4e24\u79cd\u6ce8\u610f\u529b\u6a21\u578b\u7684\u4ee3\u8868\u5206\u522b\u662fSqueeze-and-Excitation\uff08SE\uff09[29]\u548cSpatial Attention Module\uff08SAM\uff09[85]\u3002\u867d\u7136 SE \u6a21\u5757\u53ef\u4ee5\u5c06 ResNet50 \u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u63d0\u9ad8 1% \\(top-1\\) \u51c6\u786e\u7387\uff0c\u4ee3\u4ef7\u662f\u53ea\u589e\u52a0 2% \u7684\u8ba1\u7b97\u91cf\uff0c\u4f46\u5728 GPU \u4e0a\u901a\u5e38\u4f1a\u589e\u52a0\u5927\u7ea6 10% \u7684\u63a8\u7406\u65f6\u95f4\uff0c \u6240\u4ee5\u66f4\u9002\u5408\u7528\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u3002\u4f46\u5bf9\u4e8e SAM \u6765\u8bf4\uff0c\u5b83\u53ea\u9700\u8981\u989d\u5916\u4ed8\u51fa 0.1% \u7684\u8ba1\u7b97\uff0c\u5c31\u53ef\u4ee5\u5c06 ResNet50-SE \u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684 \\(top-1\\) \u51c6\u786e\u7387\u63d0\u9ad8 0.5%\u3002 \u6700\u91cd\u8981\u7684\u662f\uff0c\u5b83\u4e0d\u4f1a\u5f71\u54cd GPU \u4e0a\u7684\u63a8\u7406\u901f\u5ea6\u3002 \u2003In terms of feature integration, the early practice is to use skip connection [51] or hyper-column [22] to integrate low- level physical feature to high-level semantic feature. Since multi-scale prediction methods such as FPN have become popular, many lightweight modules that integrate different feature pyramid have been proposed. The modules of this sort include SFAM [98], ASFF [48], and BiFPN [77]. The main idea of SFAM is to use SE module to execute channel- wise level re-weighting on multi-scale concatenated feature maps. As for ASFF, it uses softmax as point-wise level re- weighting and then adds feature maps of different scales. In BiFPN, the multi-input weighted residual connections is proposed to execute scale-wise level re-weighting, and then add feature maps of different scales. \u2003\u5728\u7279\u5f81\u6574\u5408\uff08feature integration\uff09\u65b9\u9762\uff0c\u65e9\u671f\u7684\u505a\u6cd5\u662f\u4f7f\u7528\u8df3\u8fc7\u8fde\u63a5\uff08skip connection\uff09[51]\u6216\u8d85\u5217\uff08hyper-column\uff09[22]\u5c06\u4f4e\u7ea7\u7269\u7406\u7279\u5f81\u6574\u5408\u5230\u9ad8\u7ea7\u8bed\u4e49\u7279\u5f81\uff08semantic feature\uff09\u3002 \u968f\u7740FPN\u7b49\u591a\u6bd4\u4f8b\uff08multi-scale\uff09\u9884\u6d4b\u65b9\u6cd5\u7684\u6d41\u884c\uff0c\u8bb8\u591a\u96c6\u6210\u4e0d\u540c\u7279\u5f81\u91d1\u5b57\u5854\u7684\u8f7b\u91cf\u7ea7\u6a21\u5757\u88ab\u63d0\u51fa\u3002 \u8fd9\u7c7b\u6a21\u5757\u5305\u62ec SFAM [98]\u3001ASFF [48] \u548c BiFPN [77]\u3002 SFAM \u7684\u4e3b\u8981\u601d\u60f3\u662f\u4f7f\u7528 SE \u6a21\u5757\u5728\u591a\u6bd4\u4f8b\u7ea7\u8054\uff08multi-scale concatenated\uff09\u7279\u5f81\u56fe\u4e0a\u6267\u884c\u9010\u901a\u9053\u6c34\u5e73\u7684\u91cd\u65b0\u52a0\u6743\uff08channel-wise level re-weighting\uff09\u3002 \u81f3\u4e8eASFF\uff0c\u5b83\u4f7f\u7528softmax\u4f5c\u4e3a\u9010\u70b9\u7ea7\u91cd\u52a0\u6743\uff08point-wise level re-weighting\uff09\uff0c\u7136\u540e\u6dfb\u52a0\u4e0d\u540c\u6bd4\u4f8b\u7684\u7279\u5f81\u56fe\u3002 \u5728 BiFPN \u4e2d\uff0c\u63d0\u51fa\u4e86\u4f7f\u7528\u591a\u8f93\u5165\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\uff08multi-input weighted residual connections\uff09\u6765\u6267\u884c\u6309\u5c3a\u5ea6\u7ea7\u522b\u91cd\u65b0\u52a0\u6743\uff08scale-wise level re-weighting\uff09\uff0c\u7136\u540e\u6dfb\u52a0\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u3002 \u2003In the research of deep learning, some people put their focus on searching for good activation function. A good activation function can make the gradient more efficiently propagated, and at the same time it will not cause too much extra computational cost. In 2010, Nair and Hin- ton [56] propose ReLU to substantially solve the gradient vanish problem which is frequently encountered in tradi- tional tanh and sigmoid activation function. Subsequently, LReLU [54], PReLU [24], ReLU6 [28], Scaled Exponential Linear Unit (SELU) [35], Swish [59], hard-Swish [27], and Mish [55], etc., which are also used to solve the gradient vanish problem, have been proposed. The main purpose of LReLU and PReLU is to solve the problem that the gradi- ent of ReLU is zero when the output is less than zero. As for ReLU6 and hard-Swish, they are specially designed for quantization networks. For self-normalizing a neural net- work, the SELU activation function is proposed to satisfy the goal. One thing to be noted is that both Swish and Mish are continuously differentiable activation function. \u2003\u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\u4e2d\uff0c\u6709\u4eba\u628a\u91cd\u70b9\u653e\u5728\u5bfb\u627e\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u4e0a\u3002\u4e00\u4e2a\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u53ef\u4ee5\u8ba9\u68af\u5ea6\u66f4\u6709\u6548\u5730\u4f20\u64ad\uff0c\u540c\u65f6\u4e0d\u4f1a\u9020\u6210\u592a\u591a\u989d\u5916\u7684\u8ba1\u7b97\u6210\u672c\u30022010 \u5e74\uff0cNair \u548c Hinton [56] \u63d0\u51fa ReLU \u6765\u5b9e\u8d28\u6027\u5730\u89e3\u51b3\u4f20\u7edf tanh \u548c sigmoid \u6fc0\u6d3b\u51fd\u6570\u4e2d\u7ecf\u5e38\u9047\u5230\u7684\u68af\u5ea6\u6d88\u5931\uff08gradient vanish\uff09\u95ee\u9898\u3002\u968f\u540e\uff0cLReLU [54]\u3001PReLU [24]\u3001ReLU6 [28]\u3001Scaled Exponential Linear Unit (SELU) [35]\u3001Swish [59]\u3001hard-Swish [27] \u548c Mish [55] \u7b49\u88ab\u63d0\u51fa\uff0c\u4e5f\u7528\u4e8e\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002LReLU\u548cPReLU\u7684\u4e3b\u8981\u76ee\u7684\u662f\u89e3\u51b3\u8f93\u51fa\u5c0f\u4e8e\u96f6\u65f6ReLU\u68af\u5ea6\u4e3a\u96f6\u7684\u95ee\u9898\u3002\u81f3\u4e8e ReLU6 \u548c hard-Swish\uff0c\u5b83\u4eec\u662f\u4e13\u95e8\u4e3a\u91cf\u5316\uff08quantization\uff09\u7f51\u7edc\u8bbe\u8ba1\u7684\u3002\u4e3a\u4e86\u81ea\u5f52\u4e00\u5316\uff08self-normalize\uff09\u795e\u7ecf\u7f51\u7edc\uff0cSELU \u6fc0\u6d3b\u51fd\u6570\u88ab\u63d0\u51fa\u4ee5\u5b9e\u73b0\u8be5\u76ee\u6807\u3002\u9700\u8981\u6ce8\u610f\u7684\u4e00\u4ef6\u4e8b\u662f Swish \u548c Mish \u90fd\u662f\u8fde\u7eed\u53ef\u5fae\uff08continuously differentiable\uff09\u7684\u6fc0\u6d3b\u51fd\u6570\u3002 \u2003The post-processing method commonly used in deep- learning-based object detection is NMS, which can be used to filter those BBoxes that badly predict the same ob- ject, and only retain the candidate BBoxes with higher re- sponse. The way NMS tries to improve is consistent with the method of optimizing an objective function. The orig- inal method proposed by NMS does not consider the con- text information, so Girshick et al. [19] added classification confidence score in R-CNN as a reference, and according to the order of confidence score, greedy NMS was performed in the order of high score to low score. As for soft NMS [1], it considers the problem that the occlusion of an object may cause the degradation of confidence score in greedy NMS with IoU score. The DIoU NMS [99] developers way of thinking is to add the information of the center point dis- tance to the BBox screening process on the basis of soft NMS. It is worth mentioning that, since none of above post- processing methods directly refer to the captured image fea- tures, post-processing is no longer required in the subse- quent development of an anchor-free method. \u2003\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7269\u4f53\u68c0\u6d4b\u5e38\u7528\u7684\u540e\u5904\u7406\uff08post-processing\uff09\u65b9\u6cd5\u662fNMS\uff0c\u5b83\u53ef\u4ee5\u7528\u6765\u8fc7\u6ee4\u90a3\u4e9b\u5bf9\u540c\u4e00\u7269\u4f53\u9884\u6d4b\u4e0d\u597d\u7684BBox\uff0c\u53ea\u4fdd\u7559\u54cd\u5e94\u8f83\u9ad8\u7684\u5019\u9009BBox\u3002NMS \u5c1d\u8bd5\u6539\u8fdb\u7684\u65b9\u5f0f\u4e0e\u4f18\u5316\u76ee\u6807\u51fd\u6570\u7684\u65b9\u6cd5\u4e00\u81f4\u3002 NMS \u63d0\u51fa\u7684\u539f\u59cb\u65b9\u6cd5\u6ca1\u6709\u8003\u8651\u4e0a\u4e0b\u6587\uff08context\uff09\u4fe1\u606f\uff0c\u56e0\u6b64 Girshick \u7b49\u4eba [19] \u5728 R-CNN \u4e2d\u6dfb\u52a0\u4e86\u5206\u7c7b\u7f6e\u4fe1\u5ea6\uff08classification confidence score\uff09\u5206\u6570\u4f5c\u4e3a\u53c2\u8003\uff0c\u5e76\u6309\u7167\u7f6e\u4fe1\u5ea6\u5f97\u5206\u7684\u987a\u5e8f\uff0c\u4ece\u9ad8\u5206\u5230\u4f4e\u5206\u7684\u987a\u5e8f\u8fdb\u884c\u8d2a\u5a6a\uff08greedy\uff09NMS\u3002\u5bf9\u4e8e soft NMS [1]\uff0c\u5b83\u8003\u8651\u4e86\u5728\u5177\u6709 IoU \u5206\u6570\u7684 greedy NMS \u4e2d\u5bf9\u8c61\u7684\u906e\u6321\uff08occlusion\uff09\u53ef\u80fd\u5bfc\u81f4\u7f6e\u4fe1\u5ea6\u4e0b\u964d\u7684\u95ee\u9898\u3002 DIoU NMS [99] \u5f00\u53d1\u8005\u7684\u601d\u8def\u662f\u5728\u8f6f NMS \u7684\u57fa\u7840\u4e0a\uff0c\u5728 BBox \u7b5b\u9009\uff08screen\uff09\u8fc7\u7a0b\u4e2d\u52a0\u5165\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u4fe1\u606f\u3002 \u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u7531\u4e8e\u4e0a\u8ff0\u540e\u5904\u7406\u65b9\u6cd5\u90fd\u6ca1\u6709\u76f4\u63a5\u53c2\u8003\u6355\u83b7\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u56e0\u6b64\u5728\u540e\u7eed\u5f00\u53d1anchor-free\u65b9\u6cd5\u65f6\u4e0d\u518d\u9700\u8981\u8fdb\u884c\u540e\u5904\u7406\u3002","title":"2.3. Bag of specials"},{"location":"thesis_interpretation/04_yolo.html#3-methodology","text":"The basic aim is fast operating speed of neural network, in production systems and optimization for parallel compu- tations, rather than the low computation volume theoreti- cal indicator (BFLOP). We present two options of real-time neural networks: \u2003\u57fa\u672c\u76ee\u6807\u662f\u795e\u7ecf\u7f51\u7edc\u5728\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u5feb\u901f\u8fd0\u884c\u548c\u5e76\u884c\u8ba1\u7b97\uff08parallel computation\uff09\u7684\u4f18\u5316\uff0c\u800c\u4e0d\u662f\u4f4e\u8ba1\u7b97\u91cf\u7406\u8bba\u6307\u6807\uff08low computation volume theoretical indicator\uff09\uff08BFLOP\uff09\u3002 \u6211\u4eec\u63d0\u4f9b\u4e86\u4e24\u79cd\u5b9e\u65f6\u795e\u7ecf\u7f51\u7edc\u9009\u9879\uff1a For GPU we use a small number of groups (1 - 8) in convolutional layers: CSPResNeXt50 / CSPDarknet53 \u5bf9\u4e8e GPU\uff0c\u6211\u4eec\u5728\u5377\u79ef\u5c42\u4e2d\u4f7f\u7528\u5c11\u91cf\u7ec4 (1 - 8)\uff1aCSPResNeXt50 / CSPDarknet53 For VPU - we use grouped-convolution, but we refrain from using Squeeze-and-excitement (SE) blocks specifically this includes the following models: EfficientNet-lite / MixNet [76] / GhostNet [21] / Mo-bileNetV3 \u5bf9\u4e8e VPU - \u6211\u4eec\u4f7f\u7528\u5206\u7ec4\u5377\u79ef\uff0c\u4f46\u6211\u4eec\u907f\u514d\u4f7f\u7528 Squeeze-and-excitement (SE) \u5757 , - \u5177\u4f53\u5305\u62ec\u6a21\u578b\uff1aEfficientNet-lite / MixNet [76] / GhostNet [21] / MobileNetV3","title":"3. Methodology \u65b9\u6cd5\u8bba"},{"location":"thesis_interpretation/04_yolo.html#31-selection-of-architecture","text":"Our objective is to find the optimal balance among the in- put network resolution, the convolutional layer number, the parameter number \\((filter size^2 * filters * channel / groups)\\) , and the number of layer outputs (filters). For instance, our numerous studies demonstrate that the CSPResNext50 is considerably better compared to CSPDarknet53 in terms of object classification on the ILSVRC2012 (ImageNet) dataset [10]. However, conversely, the CSPDarknet53 is better compared to CSPResNext50 in terms of detecting ob- jects on the MS COCO dataset [46]. \u2003\u6211\u4eec\u7684\u76ee\u6807\u662f\u5728\u8f93\u5165\u7f51\u7edc\u5206\u8fa8\u7387\u3001\u5377\u79ef\u5c42\u6570\u3001\u53c2\u6570\u6570\u91cf \\((filter size^2 * filters * channel / groups)\\) \u548c\u5c42\u8f93\u51fa\u6570\uff08\u8fc7\u6ee4\u5668\uff09\u4e4b\u95f4\u627e\u5230\u6700\u4f73\u5e73\u8861\u3002 \u4f8b\u5982\uff0c\u6211\u4eec\u7684\u5927\u91cf\u7814\u7a76\u8868\u660e\uff0c\u5728 ILSVRC2012 (ImageNet) \u6570\u636e\u96c6 [10] \u4e0a\u7684\u5bf9\u8c61\u5206\u7c7b\u65b9\u9762\uff0cCSPResNext50 \u4e0e CSPDarknet53 \u76f8\u6bd4\u8981\u597d\u5f97\u591a\u3002 \u7136\u800c\uff0c\u76f8\u53cd\uff0c\u5728 MS COCO \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0cCSPDarknet53 \u6bd4 CSPResNext50 \u66f4\u597d [46]\u3002 \u2003The next objective is to select additional blocks for increasing the receptive field and the best method of parameter aggregation from different backbone levels for different detector levels: e.g. FPN, PAN, ASFF, BiFPN. \u2003\u4e0b\u4e00\u4e2a\u76ee\u6807\u662f\u9009\u62e9\u989d\u5916\u7684\u5757\u6765\u589e\u52a0\u611f\u53d7\u91ce\uff0c\u4ee5\u53ca\u4ece\u4e0d\u540c\u7684\u4e3b\u5e72\u7ea7\u522b\u4e3a\u4e0d\u540c\u7684\u68c0\u6d4b\u5668\u7ea7\u522b\u9009\u62e9\u53c2\u6570\u805a\u5408\uff08parameter aggregation\uff09\u7684\u6700\u4f73\u65b9\u6cd5\uff1a\u4f8b\u5982 FPN\u3001PAN\u3001ASFF\u3001BiFPN\u3002 \u2003A reference model which is optimal for classification is not always optimal for a detector. In contrast to the classifier, the detector requires the following: \u2003\u5bf9\u4e8e\u5206\u7c7b\u800c\u8a00\u6700\u4f73\u7684\u53c2\u8003\u6a21\u578b\u5bf9\u4e8e\u68c0\u6d4b\u5668\u800c\u8a00\u5e76\u4e0d\u603b\u662f\u6700\u4f73\u7684\u3002 \u4e0e\u5206\u7c7b\u5668\u76f8\u6bd4\uff0c\u68c0\u6d4b\u5668\u9700\u8981\u4ee5\u4e0b\u5185\u5bb9\uff1a Higher input network size (resolution) \u2013 for detecting multiple small-sized objects \u66f4\u9ad8\u7684\u8f93\u5165\u7f51\u7edc\u5c3a\u5bf8\uff08\u5206\u8fa8\u7387\uff09\u2014\u2014 \u7528\u4e8e\u68c0\u6d4b\u591a\u4e2a\u5c0f\u5c3a\u5bf8\u7269\u4f53 More layers \u2013 for a higher receptive field to cover the increased size of input network \u66f4\u591a\u5c42\u2014\u2014\u7528\u4e8e\u66f4\u9ad8\u7684\u611f\u53d7\u91ce\u4ee5\u8986\u76d6\u589e\u52a0\u7684\u8f93\u5165\u7f51\u7edc\u5927\u5c0f More parameters \u2013 for greater capacity of a model to detect multiple objects of different sizes in a single im- age \u66f4\u591a\u53c2\u6570\u2014\u2014\u4f7f\u6a21\u578b\u6709\u66f4\u5927\u7684\u80fd\u529b\u5728\u5355\u4e2a\u56fe\u50cf\u4e2d\u68c0\u6d4b\u591a\u4e2a\u4e0d\u540c\u5927\u5c0f\u7684\u5bf9\u8c61 \\(\\text { \u8868 1: \u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u3002 }\\) \u2003Hypothetically speaking, we can assume that a model with a larger receptive field size (with a larger number of convolutional layers \\(3 \u00d7 3\\) ) and a larger number of parameters should be selected as the backbone. Table 1 shows the information of CSPResNeXt50, CSPDarknet53, and EfficientNet B3. The CSPResNext50 contains only 16 convolutional layers \\(3 \u00d7 3\\) , a \\(425 \u00d7 425\\) receptive field and 20.6 M parameters, while CSPDarknet53 contains 29 convolu- tional layers \\(3 \u00d7 3\\) , a \\(725 \u00d7 725\\) receptive field and 27.6 M parameters. This theoretical justification, together with our numerous experiments, show that CSPDarknet53 neural network is the optimal model of the two as the backbone for a detector. \u2003\u5047\u8bbe\u5730\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u5047\u8bbe\u5e94\u8be5\u9009\u62e9\u5177\u6709\u66f4\u5927\u611f\u53d7\u91ce\u5927\u5c0f\uff08\u5177\u6709\u66f4\u591a\u5377\u79ef\u5c42 3 \u00d7 3\uff09\u548c\u66f4\u591a\u53c2\u6570\u7684\u6a21\u578b\u4f5c\u4e3a\u4e3b\u5e72\u3002 \u8868 1 \u663e\u793a\u4e86 CSPResNeXt50\u3001CSPDarknet53 \u548c EfficientNet B3 \u7684\u4fe1\u606f\u3002 CSPResNext50 \u4ec5\u5305\u542b 16 \u4e2a 3 \u00d7 3 \u5377\u79ef\u5c42\u3001425 \u00d7 425 \u611f\u53d7\u91ce\u548c 20.6 M \u53c2\u6570\uff0c\u800c CSPDarknet53 \u5305\u542b 29 \u4e2a\u5377\u79ef\u5c42 3 \u00d7 3\u3001725 \u00d7 725 \u611f\u53d7\u91ce\u548c 27.6 M \u53c2\u6570\u3002 \u8fd9\u4e2a\u7406\u8bba\u8bc1\u660e\uff0c\u52a0\u4e0a\u6211\u4eec\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u8868\u660e CSPDarknet53 \u795e\u7ecf\u7f51\u7edc\u662f\u4e24\u8005\u7684\u6700\u4f73\u6a21\u578b\uff0c\u4f5c\u4e3a\u68c0\u6d4b\u5668\u7684\u4e3b\u5e72\u3002 \u2003The influence of the receptive field with different sizes is summarized as follows: \u2003\u4e0d\u540c\u5927\u5c0f\u7684\u611f\u53d7\u91ce\u7684\u5f71\u54cd\u603b\u7ed3\u5982\u4e0b: Up to the object size - allows viewing the entire object \u6700\u591a\u5230\u5bf9\u8c61\u5927\u5c0f \u2013 \u5141\u8bb8\u67e5\u770b\u6574\u4e2a\u5bf9\u8c61 Up to network size - allows viewing the context around the object \u6700\u591a\u7f51\u7edc\u5927\u5c0f \u2013 \u5141\u8bb8\u67e5\u770b\u5bf9\u8c61\u5468\u56f4\u7684\u4e0a\u4e0b\u6587 Exceeding the network size - increases the number of connections between the image point and the final activation \u8d85\u8fc7\u7f51\u7edc\u5927\u5c0f \u2013 \u589e\u52a0\u56fe\u50cf\u70b9\u548c\u6700\u7ec8\u6fc0\u6d3b\u4e4b\u95f4\u7684\u8fde\u63a5\u6570 \u2003 We add the SPP block over the CSPDarknet53, since it significantly increases the receptive field, separates out the most significant context features and causes almost no reduction of the network operation speed. We use PANet as the method of parameter aggregation from different backbone levels for different detector levels, instead of the FPN used in YOLOv3. \u2003\u6211\u4eec\u5728 CSPDarknet53 \u4e0a\u6dfb\u52a0\u4e86 SPP \u5757\uff0c\u56e0\u4e3a\u5b83\u663e\u7740\u589e\u52a0\u4e86\u611f\u53d7\u91ce\uff0c\u5206\u79bb\u51fa\u6700\u91cd\u8981\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u5e76\u4e14\u51e0\u4e4e\u4e0d\u4f1a\u964d\u4f4e\u7f51\u7edc\u8fd0\u884c\u901f\u5ea6\u3002 \u6211\u4eec\u4f7f\u7528 PANet \u4f5c\u4e3a\u6765\u81ea\u4e0d\u540c\u4e3b\u5e72\u7ea7\u522b\u7684\u5bf9\u4e0d\u540c\u68c0\u6d4b\u5668\u7ea7\u522b\u7684\u53c2\u6570\u805a\u5408\u65b9\u6cd5\uff0c\u800c\u4e0d\u662f YOLOv3 \u4e2d\u4f7f\u7528\u7684 FPN\u3002 \u2003Finally, we choose CSPDarknet53 backbone, SPP additional module, PANet path-aggregation neck, and YOLOv3 (anchor based) head as the architecture of YOLOv4. \u2003\u6700\u540e\uff0c\u6211\u4eec\u9009\u62e9 CSPDarknet53 \u4e3b\u5e72\u3001SPP \u9644\u52a0\u6a21\u5757\u3001PANet \u8def\u5f84\u805a\u5408\u9888\u90e8\u548c YOLOv3\uff08(anchor based\uff09\u5934\u90e8\u4f5c\u4e3a YOLOv4 \u7684\u67b6\u6784\u3002 \u2003n the future we plan to expand significantly the content of Bag of Freebies (BoF) for the detector, which theoreti- cally can address some problems and increase the detector accuracy, and sequentially check the influence of each fea- ture in an experimental fashion. \u2003\u672a\u6765\u6211\u4eec\u8ba1\u5212\u5927\u529b\u6269\u5c55\u68c0\u6d4b\u5668\u7684Bag of Freebies (BoF) \u5185\u5bb9\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u89e3\u51b3\u4e00\u4e9b\u95ee\u9898\u5e76\u63d0\u9ad8\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4ee5\u5b9e\u9a8c\u65b9\u5f0f\u4f9d\u6b21\u68c0\u67e5\u6bcf\u4e2a\u7279\u5f81\u7684\u5f71\u54cd\u3002 \u2003We do not use Cross-GPU Batch Normalization (CGBN or SyncBN) or expensive specialized devices. This al- lows anyone to reproduce our state-of-the-art outcomes on a conventional graphic processor e.g. GTX 1080Ti or RTX 2080Ti. \u2003\u6211\u4eec\u4e0d\u4f7f\u7528\u8de8 GPU\uff08Cross-GPU\uff09\u6279\u91cf\u5f52\u4e00\u5316\uff08CGBN \u6216 SyncBN\uff09\u6216\u6602\u8d35\u7684\u4e13\u7528\u8bbe\u5907\u3002 \u8fd9\u5141\u8bb8\u4efb\u4f55\u4eba\u5728\u4f20\u7edf\u56fe\u5f62\u5904\u7406\u5668\u4e0a\u91cd\u73b0\u6211\u4eec\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u4f8b\u5982 GTX 1080Ti \u6216 RTX 2080Ti\u3002","title":"3.1. Selection of architecture \u67b6\u6784\u9009\u62e9"},{"location":"thesis_interpretation/04_yolo.html#32-selection-of-bof-and-bos","text":"For improving the object detection training, a CNN usu- ally uses the following: \u2003\u4e3a\u4e86\u6539\u8fdb\u76ee\u6807\u68c0\u6d4b\u8bad\u7ec3\uff0cCNN \u901a\u5e38\u4f7f\u7528\u4ee5\u4e0b\u5185\u5bb9\uff1a Activations: ReLU, leaky-ReLU, parametric-ReLU, ReLU6, SELU, Swish, or Mish \u6fc0\u6d3b\uff1aReLU\u3001leaky-ReLU\u3001\u53c2\u6570\u5316 ReLU\uff08parametric-ReLU\uff09\u3001ReLU6\u3001SELU\u3001Swish \u6216 Mish Bounding box regression loss: MSE, IoU, GIoU,CIoU, DIoU \u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\uff1aMSE\u3001IoU\u3001GIoU\u3001CIoU\u3001DIoU Data augmentation: CutOut, MixUp, CutMix \u6570\u636e\u589e\u5f3a\uff1aCutOut\u3001MixUp\u3001CutMix Regularization method: DropOut, DropPath [36],Spatial DropOut [79], or DropBlock \u6b63\u5219\u5316\u65b9\u6cd5\uff1aDropOut\u3001DropPath [36]\u3001Spatial DropOut [79] \u6216 DropBlock Normalization of the network activations by their mean and variance: Batch Normalization (BN) [32], Cross-GPU Batch Normalization (CGBN or SyncBN)[93], Filter Response Normalization (FRN) [70], or Cross-Iteration Batch Normalization (CBN) [89] \u901a\u8fc7\u5747\u503c\u548c\u65b9\u5dee\u5bf9\u7f51\u7edc\u6fc0\u6d3b\u8fdb\u884c\u5f52\u4e00\u5316\uff1a\u6279\u5f52\u4e00\u5316 (BN) [32]\u3001Cross-GPU \u6279\u5f52\u4e00\u5316\uff08CGBN \u6216 SyncBN\uff09[93]\u3001\u6ee4\u6ce2\u5668\u54cd\u5e94\uff08Filter Response\uff09\u5f52\u4e00\u5316 (FRN) [70] \u6216\u4ea4\u53c9\u8fed\u4ee3\uff08Cross-Iteration\uff09\u6279\u5f52\u4e00\u5316 (CBN) [89] Skip-connections: Residual connections, Weighted residual connections, Multi-input weighted residual connections, or Cross stage partial connections (CSP) \u8df3\u8fc7\u8fde\u63a5\uff08Skip-connections\uff09\uff1a\u6b8b\u5dee\u8fde\u63a5\uff08Residual connection\uff09\u3001\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\u3001\u591a\u8f93\u5165\uff08Multi-input\uff09\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\u6216\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5\uff08Cross stage partial connections\uff09 (CSP) \u2003As for training activation function, since PReLU and SELU are more difficult to train, and ReLU6 is specifically designed for quantization network, we therefore remove the above activation functions from the candidate list. In the method of reqularization, the people who published Drop- Block have compared their method with other methods in detail, and their regularization method has won a lot. There- fore, we did not hesitate to choose DropBlock as our reg- ularization method. As for the selection of normalization method, since we focus on a training strategy that uses only one GPU, syncBN is not considered. \u2003\u81f3\u4e8e\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\uff0c\u7531\u4e8e PReLU \u548c SELU \u66f4\u96be\u8bad\u7ec3\uff0c\u800c ReLU6 \u662f\u4e13\u95e8\u4e3a\u91cf\u5316\uff08quantization\uff09\u7f51\u7edc\u8bbe\u8ba1\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u4ece\u5019\u9009\u5217\u8868\u4e2d\u5220\u9664\u4e86\u4e0a\u8ff0\u6fc0\u6d3b\u51fd\u6570\u3002 \u5728\u6b63\u5219\u5316\u7684\u65b9\u6cd5\u4e0a\uff0c\u53d1\u8868Drop-Block\u7684\u4eba\u8be6\u7ec6\u5bf9\u6bd4\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\u548c\u5176\u4ed6\u65b9\u6cd5\uff0c\u4ed6\u4eec\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u8d62\u5f97\u4e86\u5f88\u591a\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u6beb\u4e0d\u72b9\u8c6b\u5730\u9009\u62e9 DropBlock \u4f5c\u4e3a\u6211\u4eec\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002 \u81f3\u4e8e\u5f52\u4e00\u5316\u65b9\u6cd5\u7684\u9009\u62e9\uff0c\u7531\u4e8e\u6211\u4eec\u4e13\u6ce8\u4e8e\u4ec5\u4f7f\u7528\u4e00\u4e2a GPU \u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u56e0\u6b64\u6ca1\u6709\u8003\u8651 syncBN\u3002","title":"3.2. Selection of BoF and BoS"},{"location":"thesis_interpretation/04_yolo.html#33-additional-improvements","text":"In order to make the designed detector more suitable for training on single GPU, we made additional design and im- provement as follows: \u2003\u4e3a\u4e86\u4f7f\u6240\u8bbe\u8ba1\u7684\u68c0\u6d4b\u5668\u66f4\u9002\u5408\u5728\u5355\u4e00GPU\u4e0a\u8bad\u7ec3\uff0c\u6211\u4eec\u505a\u4e86\u5982\u4e0b\u989d\u5916\u7684\u8bbe\u8ba1\u548c\u6539\u8fdb: We introduce a new method of data augmentation Mosaic, and Self-Adversarial Training (SA T) \u6211\u4eec\u5f15\u5165\u4e86\u6570\u636e\u589e\u5f3a\u9a6c\u8d5b\u514b\uff08Mosaic\uff09\u548c\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u7684\u65b0\u65b9\u6cd5 We select optimal hyper-parameters while applying genetic algorithms \u6211\u4eec\u5728\u5e94\u7528\u9057\u4f20\u7b97\u6cd5\uff08genetic algorithm\uff09\u7684\u540c\u65f6\u9009\u62e9\u6700\u4f73\u8d85\u53c2\u6570 We modify some exsiting methods to make our design suitble for efficient training and detection - modified SAM, modified PAN, and Cross mini-Batch Normalization (CmBN) \u6211\u4eec\u4fee\u6539\u4e86\u4e00\u4e9b\u73b0\u6709\u7684\u65b9\u6cd5\uff0c\u4f7f\u6211\u4eec\u7684\u8bbe\u8ba1\u9002\u5408\u9ad8\u6548\u7684\u8bad\u7ec3\u548c\u68c0\u6d4b\u2014\u2014\u4fee\u6539\u7684 SAM\u3001\u4fee\u6539\u7684 PAN \u548c\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN) \u2003Mosaic represents a new data augmentation method that mixes 4 training images. Thus 4 different contexts are mixed, while CutMix mixes only 2 input images. This al- lows detection of objects outside their normal context. In addition, batch normalization calculates activation statistics from 4 different images on each layer. This significantly reduces the need for a large mini-batch size. \u2003Mosaic \u4ee3\u8868\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b83\u6df7\u5408\u4e86 4 \u4e2a\u8bad\u7ec3\u56fe\u50cf\u3002 \u56e0\u6b64\u6df7\u5408\u4e86 4 \u4e2a\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\uff0c\u800c CutMix \u4ec5\u6df7\u5408\u4e86 2 \u4e2a\u8f93\u5165\u56fe\u50cf\u3002 \u8fd9\u5141\u8bb8\u68c0\u6d4b\u6b63\u5e38\u4e0a\u4e0b\u6587\u4e4b\u5916\u7684\u5bf9\u8c61\u3002 \u6b64\u5916\uff0c\u6279\u91cf\u5f52\u4e00\u5316\u8ba1\u7b97\u6bcf\u5c42 4 \u4e2a\u4e0d\u540c\u56fe\u50cf\u7684\u6fc0\u6d3b\u7edf\u8ba1\u6570\u636e\u3002 \u8fd9\u663e\u7740\u51cf\u5c11\u4e86\u5bf9\u5927\u5c3a\u5bf8 mini-batch \u7684\u9700\u6c42\u3002 Figure 3: Mosaic represents a new method of data augmentation. \u56fe3:\u9a6c\u8d5b\u514b\u8868\u793a\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u7684\u65b0\u65b9\u6cd5\u3002 \u2003Self-Adversarial Training (SAT) also represents a new data augmentation technique that operates in 2 forward backward stages. In the 1st stage the neural network alters the original image instead of the network weights. In this way the neural network executes an adversarial attack on it- self, altering the original image to create the deception that there is no desired object on the image. In the 2nd stage, the neural network is trained to detect an object on this modified image in the normal way. \u2003 \u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u4e5f\u4ee3\u8868\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u5b83\u5728 2 \u4e2a\u524d\u5411\u548c\u540e\u5411\u9636\u6bb5\u4e2d\u8fd0\u884c\u3002 \u5728\u7b2c\u4e00\u9636\u6bb5\uff0c\u795e\u7ecf\u7f51\u7edc\u6539\u53d8\u539f\u59cb\u56fe\u50cf\u800c\u4e0d\u662f\u7f51\u7edc\u6743\u91cd\u3002 \u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u795e\u7ecf\u7f51\u7edc\u5bf9\u81ea\u8eab\u6267\u884c\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u6539\u53d8\u539f\u59cb\u56fe\u50cf \u4ee5\u5236\u9020\u56fe\u50cf\u4e0a\u6ca1\u6709\u6240\u9700\u5bf9\u8c61\u7684\u6b3a\u9a97\uff08deception\uff09\u3002 \u5728\u7b2c\u4e8c\u9636\u6bb5\uff0c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4ee5\u6b63\u5e38\u65b9\u5f0f\u68c0\u6d4b\u6b64\u4fee\u6539\u56fe\u50cf\u4e0a\u7684\u5bf9\u8c61\u3002 Figure 4: Cross mini-Batch Normalization. \u56fe 4\uff1a\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316\u3002 \u2003CmBN represents a CBN modified version, as shown in Figure 4, defined as Cross mini-Batch Normalization (CmBN). This collects statistics only between mini-batches within a single batch. \u2003 CmBN \u8868\u793a CBN \u4fee\u6539\u7248\u672c\uff0c\u5982\u56fe 4 \u6240\u793a\uff0c\u5b9a\u4e49\u4e3a\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3002 \u8fd9\u4ec5\u5728\u5355\u4e2a\u6279\u6b21\u5185\u7684\u5c0f\u6279\u6b21\u4e4b\u95f4\u6536\u96c6\u7edf\u8ba1\u4fe1\u606f\u3002 \u2003 We modify SAM from spatial-wise attention to point- wise attention, and replace shortcut connection of PAN to concatenation, as shown in Figure 5 and Figure 6, respec- tively. \u2003 \u6211\u4eec\u5c06 SAM \u4ece\u6309\u7a7a\u95f4\u6ce8\u610f\uff08spatial-wise attention\uff09\u4fee\u6539\u4e3a\u9010\u70b9\u6ce8\u610f\uff08point-wise attention\uff09\uff0c\u5e76\u5c06 PAN \u7684\u5feb\u6377\u8fde\u63a5\uff08shortcut connection\uff09\u66ff\u6362\u4e3a\u4e32\u8054\uff08concatenation\uff09\uff0c\u5206\u522b\u5982\u56fe 5 \u548c\u56fe 6 \u6240\u793a\u3002","title":"3.3. Additional improvements"},{"location":"thesis_interpretation/04_yolo.html#34-yolov4","text":"In this section, we shall elaborate the details of YOLOv4. \u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u8be6\u7ec6\u9610\u8ff0YOLOv4\u7684\u7ec6\u8282\u3002 YOLOv4 consists of: YOLOv4 \u5305\u62ec\uff1a Backbone: CSPDarknet53 [81] Neck: SPP [25], PAN [49] Head: YOLOv3 [63] YOLO v4 uses: YOLO v4 \u4f7f\u7528: Bag of Freebies (BoF) for backbone: CutMix and Mosaic data augmentation, DropBlock regularization, Class label smoothing \u9aa8\u5e72\u7684BoF\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u3001DropBlock \u6b63\u5219\u5316\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\uff08Class label smoothing\uff09 Bag of Specials (BoS) for backbone: Mish activation, Cross-stage partial connections (CSP), Multiinput weighted residual connections (MiWRC) \u9aa8\u5e72\u7684BoS\uff1aMish \u6fc0\u6d3b\u3001\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5 (CSP)\u3001\u591a\u8f93\u5165\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5 (MiWRC) Bag of Freebies (BoF) for detector: CIoU-loss, CmBN, DropBlock regularization, Mosaic data augmentation, Self-Adversarial Training, Eliminate grid sensitivity, Using multiple anchors for a single ground truth, Cosine annealing scheduler [52], Optimal hyperparameters, Random training shapes \u68c0\u6d4b\u5668\u7684BoF\uff1aCIoU-loss\u3001CmBN\u3001DropBlock \u6b63\u5219\u5316\u3001Mosaic \u6570\u636e\u589e\u5f3a\u3001\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3\uff08SAT\uff09\u3001\u6d88\u9664\u7f51\u683c\u654f\u611f\u6027\uff08Eliminate grid sensitivity\uff09\u3001\u4f7f\u7528\u591a\u4e2a\u951a\u70b9\uff08multiple anchors\uff09\u83b7\u53d6\u5355\u4e2a\u771f\u5b9e\u503c\u3001\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\u7a0b\u5e8f\uff08Cosine annealing scheduler\uff09 [52]\u3001\u6700\u4f18\u8d85\u53c2\u6570\uff0c\u968f\u673a\u8bad\u7ec3\u5f62\u72b6 Bag of Specials (BoS) for detector: Mish activation, SPP-block, SAM-block, PAN path-aggregation block,DIoU-NMS \u7528\u4e8e\u68c0\u6d4b\u5668\u7684\u7279\u6709\u5305 \uff08BoS\uff09\uff1a \u8bef\u533a\u6fc0\u6d3b\u3001 SPP \u5757\u3001 SAM \u5757\u3001 PAN \u8def\u5f84\u805a\u5408\u5757\u3001 DIoU-NMS","title":"3.4. YOLOv4"},{"location":"thesis_interpretation/04_yolo.html#4-experiments","text":"We test the influence of different training improvement techniques on accuracy of the classifier on ImageNet (ILSVRC 2012 val) dataset, and then on the accuracy of the detector on MS COCO (test-dev 2017) dataset. \u2003\u6211\u4eec\u5728 ImageNet (ILSVRC 2012 val) \u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u4e0d\u540c\u8bad\u7ec3\u6539\u8fdb\u6280\u672f\u5bf9\u5206\u7c7b\u5668\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u7136\u540e\u5728 MS COCO (test-dev 2017) \u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u3002","title":"4. Experiments  \u5b9e\u9a8c"},{"location":"thesis_interpretation/04_yolo.html#41-experimental-setup","text":"In ImageNet image classification experiments, the default hyper-parameters are as follows: the training steps is 8,000,000; the batch size and the mini-batch size are 128 and 32, respectively; the polynomial decay learning rate scheduling strategy is adopted with initial learning rate 0.1; the warm-up steps is 1000; the momentum and weight decay are respectively set as 0.9 and 0.005. All of our BoS experiments use the same hyper-parameter as the default setting, and in the BoF experiments, we add an additional 50% training steps. In the BoF experiments, we verify MixUp, CutMix, Mosaic, Bluring data augmentation, and label smoothing regularization methods. In the BoS experiments, we compared the effects of LReLU, Swish, and Mish activation function. All experiments are trained with a 1080 Ti or 2080 Ti GPU. \u2003\u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u5b9e\u9a8c\u4e2d\uff0c\u9ed8\u8ba4\u8d85\u53c2\u6570\u5982\u4e0b\uff1a\u8bad\u7ec3\u6b65\u6570\u4e3a 8,000,000\uff1b \u5927\u6279\u91cf\u548c\u5c0f\u6279\u91cf\u5927\u5c0f\u5206\u522b\u4e3a 128 \u548c 32\uff1b \u91c7\u7528\u591a\u9879\u5f0f\u8870\u51cf\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08polynomial decay learning rate scheduling strategy\uff09\uff0c\u521d\u59cb\u5b66\u4e60\u73870.1\uff1b \u9884\u70ed\uff08warm-up\uff09\u6b65\u6570\u4e3a1000\uff1b \u52a8\u91cf\u8870\u51cf\u548c\u6743\u91cd\u8870\u51cf\u5206\u522b\u8bbe\u7f6e\u4e3a 0.9 \u548c 0.005\u3002\u6211\u4eec\u6240\u6709\u7684 BoS \u5b9e\u9a8c\u90fd\u4f7f\u7528\u4e0e\u9ed8\u8ba4\u8bbe\u7f6e\u76f8\u540c\u7684\u8d85\u53c2\u6570\uff0c\u5e76\u4e14\u5728 BoF \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u989d\u5916\u7684 50% \u8bad\u7ec3\u6b65\u6570\u3002 \u5728 BoF \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u9a8c\u8bc1\u4e86 MixUp\u3001CutMix\u3001Mosaic\u3001Bluring \u6570\u636e\u589e\u5f3a\u548c\u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316\uff08label smoothing regularization\uff09\u65b9\u6cd5\u3002 \u5728 BoS \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6bd4\u8f83\u4e86 LReLU\u3001Swish \u548c Mish \u6fc0\u6d3b\u51fd\u6570\u7684\u6548\u679c\u3002 \u6240\u6709\u5b9e\u9a8c\u5747\u4f7f\u7528 1080 Ti \u6216 2080 Ti GPU \u8fdb\u884c\u8bad\u7ec3\u3002 \u2003In MS COCO object detection experiments, the default hyper-parameters are as follows: the training steps is 500,500; the step decay learning rate scheduling strategy is adopted with initial learning rate 0.01 and multiply with a factor 0.1 at the 400,000 steps and the 450,000 steps, respectively; The momentum and weight decay are respec- tively set as 0.9 and 0.0005. All architectures use a single GPU to execute multi-scale training in the batch size of 64 while mini-batch size is 8 or 4 depend on the architectures and GPU memory limitation. Except for us- ing genetic algorithm for hyper-parameter search experiments, all other experiments use default setting. Genetic algorithm used YOLOv3-SPP to train with GIoU loss and search 300 epochs for min-val 5k sets. We adopt searched learning rate 0.00261, momentum 0.949, IoU threshold for assigning ground truth 0.213, and loss normalizer 0.07 for genetic algorithm experiments. We have verified a large number of BoF, including grid sensitivity elimination, mosaic data augmentation, IoU threshold, genetic algorithm, class label smoothing, cross mini-batch normalization, self-adversarial training, cosine annealing scheduler, dynamic mini-batch size, DropBlock, Optimized Anchors, different kind of IoU losses. We also conduct experiments on various BoS, including Mish, SPP, SAM, RFB, BiFPN, and Gaus-sian YOLO [8]. For all experiments, we only use one GPU for training, so techniques such as syncBN that optimizes multiple GPUs are not used. \u2003\u5728 MS COCO \u6570\u636e\u96c6\u4e0a\u76ee\u6807\u68c0\u6d4b\u5b9e\u9a8c\u4e2d\uff0c\u9ed8\u8ba4\u8d85\u53c2\u6570\u5982\u4e0b\uff1a\u8bad\u7ec3\u6b65\u6570\u4e3a 500,500\uff1b \u91c7\u7528\u6b65\u957f\u8870\u51cf\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08step decay learning rate scheduling strategy\uff09\uff0c\u521d\u59cb\u5b66\u4e60\u73870.01\uff0c\u5206\u522b\u572840\u4e07\u6b65\u548c45\u4e07\u6b65\u4e58\u4ee5\u56e0\u5b500.1\uff1b \u52a8\u91cf\u548c\u6743\u91cd\u8870\u51cf\u5206\u522b\u8bbe\u7f6e\u4e3a 0.9 \u548c 0.0005\u3002\u6240\u6709\u67b6\u6784\uff08architecture\uff09\u90fd\u4f7f\u7528\u5355\u4e2a GPU \u4ee5 64 \u7684\u6279\u91cf\u5927\u5c0f\u6267\u884c\u591a\u6bd4\u4f8b\uff08multi-scale\uff09\u8bad\u7ec3\uff0c\u800c\u5c0f\u6279\u91cf\u5927\u5c0f\u4e3a 8 \u6216 4\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u67b6\u6784\u548c GPU \u5185\u5b58\u9650\u5236\u3002 \u9664\u4e86\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u8d85\u53c2\u6570\u641c\u7d22\u5b9e\u9a8c\u5916\uff0c\u5176\u4ed6\u6240\u6709\u5b9e\u9a8c\u5747\u4f7f\u7528\u9ed8\u8ba4\u8bbe\u7f6e\u3002 \u9057\u4f20\u7b97\u6cd5\u4f7f\u7528 YOLOv3-SPP \u8bad\u7ec3 GIoU\u635f\u5931\u5e76\u641c\u7d22 300 \u4e2a epoch \u4ee5\u83b7\u53d6min-val 5k \u96c6\u3002 \u6211\u4eec\u91c7\u7528\u641c\u7d22\u5b66\u4e60\u7387 0.00261\uff0c\u52a8\u91cf 0.949\uff0c\u5206\u914d\u771f\u5b9e\u503c\u7684 IoU \u9608\u503c 0.213\uff0c\u9057\u4f20\u7b97\u6cd5\u5b9e\u9a8c\u7684\u635f\u5931\u5f52\u4e00\u5316\u5668 0.07\u3002 \u6211\u4eec\u5df2\u7ecf\u9a8c\u8bc1\u4e86\u5927\u91cf\u7684 BoF\uff0c\u5305\u62ec\u7f51\u683c\u654f\u611f\u6027\u6d88\u9664\uff08grid sensitivity elimination\uff09\u3001\u9a6c\u8d5b\u514b\u6570\u636e\u589e\u5f3a\u3001IoU \u9608\u503c\u3001\u9057\u4f20\u7b97\u6cd5\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\u3001\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3001\u81ea\u5bf9\u6297\u8bad\u7ec3\u3001\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\u5668\u3001\u52a8\u6001\u5c0f\u6279\u91cf\u5927\u5c0f\u3001DropBlock , \u4f18\u5316\u7684\u951a\u70b9\uff08Optimized Anchor\uff09\uff0c\u4e0d\u540c\u79cd\u7c7b\u7684 IoU \u635f\u5931\u3002 \u6211\u4eec\u8fd8\u5bf9\u5404\u79cd BoS \u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5305\u62ec Mish\u3001SPP\u3001SAM\u3001RFB\u3001BiFPN \u548cGaussian YOLO [8]\u3002 \u5bf9\u4e8e\u6240\u6709\u5b9e\u9a8c\uff0c\u6211\u4eec\u53ea\u4f7f\u7528\u4e00\u4e2a GPU \u8fdb\u884c\u8bad\u7ec3\uff0c\u56e0\u6b64\u6ca1\u6709\u4f7f\u7528\u4f18\u5316\u591a\u4e2a GPU \u7684\u540c\u6b65BN\uff08syncBN\uff09 \u7b49\u6280\u672f\u3002","title":"4.1. Experimental setup \u5b9e\u9a8c\u8bbe\u7f6e"},{"location":"thesis_interpretation/04_yolo.html#42-influence-of-different-features-on-classifier","text":"First, we study the influence of different features on classifier training; specifically, the influence of Class la- bel smoothing, the influence of different data augmentation techniques, bilateral blurring, MixUp, CutMix and Mosaic, as shown in Fugure 7, and the influence of different activa- tions, such as Leaky-ReLU (by default), Swish, and Mish. \u2003\u9996\u5148\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u4e0d\u540c\u7279\u5f81\u5bf9\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u5f71\u54cd\uff1b \u5177\u4f53\u6765\u8bf4\uff0cClass label smoothing\u7684\u5f71\u54cd\uff0c\u4e0d\u540c\u6570\u636e\u589e\u5f3a\u6280\u672f\u7684\u5f71\u54cd\uff0c\u53cc\u8fb9\u6a21\u7cca\uff08bilateral blurring\uff09\uff0cMixUp\uff0cCutMix\u548cMosaic\uff0c\u5982Fugure 7\u6240\u793a\uff0c\u4ee5\u53ca\u4e0d\u540c\u6fc0\u6d3b\u7684\u5f71\u54cd\uff0c\u4f8b\u5982Leaky-ReLU\uff08\u9ed8\u8ba4\uff09\uff0cSwish \uff0c\u548cMish\u3002 Figure 7: V arious method of data augmentation. \u56fe7:\u5404\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002 \u2003In our experiments, as illustrated in Table 2, the classifier\u2019s accuracy is improved by introducing the features such as: CutMix and Mosaic data augmentation, Class label smoothing, and Mish activation. As a result, our BoF-backbone (Bag of Freebies) for classifier training includes the following: CutMix and Mosaic data augmentation and Class label smoothing. In addition we use Mish activation as a complementary option, as shown in Table 2 and Table \u2003 \u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5982\u8868 2 \u6240\u793a\uff0c\u901a\u8fc7\u5f15\u5165\u4ee5\u4e0b\u7279\u5f81\u6765\u63d0\u9ad8\u5206\u7c7b\u5668\u7684\u51c6\u786e\u6027\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\u548c Mish \u6fc0\u6d3b\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u7528\u4e8e\u5206\u7c7b\u5668\u8bad\u7ec3\u7684 BoF-backbone\uff08Bag of Freebies\uff09\u5305\u62ec\u4ee5\u4e0b\u5185\u5bb9\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u4ee5\u53ca\u7c7b\u6807\u7b7e\u5e73\u6ed1\u3002 \u6b64\u5916\uff0c\u6211\u4eec\u4f7f\u7528 Mish \u6fc0\u6d3b\u4f5c\u4e3a\u8865\u5145\u9009\u9879\uff08complementary option\uff09\uff0c\u5982\u8868 2 \u548c\u8868 3 \u6240\u793a\u3002 Table 2: Influence of BoF and Mish on the CSPResNeXt-50 classifier accuracy. \u88682:BoF\u548cMish\u5bf9CSPResNeXt-50\u5206\u7c7b\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002 Table 3: Influence of BoF and Mish on the CSPDarknet-53 classifier accuracy. \u88683:BoF\u548cMish\u5bf9CSPDarknet-53\u5206\u7c7b\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002","title":"4.2. Influence of different features on Classifier \u4e0d\u540c\u7279\u5f81\u5bf9\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u5f71\u54cd"},{"location":"thesis_interpretation/04_yolo.html#43-influence-of-different-features-on-detector","text":"Further study concerns the influence of different Bag-of-Freebies (BoF-detector) on the detector training accuracy, as shown in Table 4. We significantly expand the BoF list through studying different features that increase the detector accuracy without affecting FPS: \u2003\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u6d89\u53ca\u4e0d\u540c\u7684\u514d\u8d39\u888b(BOF\u63a2\u6d4b\u5668)\u5bf9\u63a2\u6d4b\u5668\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u5982\u88684\u6240\u793a\u3002\u6211\u4eec\u901a\u8fc7\u7814\u7a76\u5728\u4e0d\u5f71\u54cdFPS\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u63a2\u6d4b\u5668\u7cbe\u5ea6\u7684\u4e0d\u540c\u7279\u6027\uff0c\u663e\u8457\u6269\u5c55\u4e86BOF\u5217\u8868\uff1a S: Eliminate grid sensitivity the equation \\(b_x = \u03c3(t_x )+ c_x , b_y = \u03c3(t_y )+c_y\\) , where \\(c_x\\) and \\(c_y\\) are always whole numbers, is used in YOLOv3 for evaluating the object coordinates, therefore, extremely high \\(t_x\\) absolute values are required for the \\(b_x\\) value approaching the \\(c_x \\ or \\ c_{ x} + 1\\) values. We solve this problem through multiplying the sigmoid by a factor exceeding 1.0, so eliminating the effect of grid on which the object is undetectable. S\uff1a \u6d88\u9664\u7f51\u683c\u7075\u654f\u5ea6\u65b9\u7a0b \\(b_x = \u03c3(t_x )+ c_x , b_y = \u03c3(t_y )+c_y\\) \uff0c \u5176\u4e2d \\(c_x\\) \u548c \\(c_y\\) \u59cb\u7ec8\u4e3a\u6574\u6570\uff0c \u5728 YOLOv3 \u4e2d\u4f7f\u7528\u7528\u4e8e\u8bc4\u4f30\u76ee\u6807\u5750\u6807\uff0c \u56e0\u6b64\uff0c\u63a5\u8fd1 \\(c_x \\ or \\ c_{ x} + 1\\) \u503c\u7684 \\(b_x\\) \u503c\u9700\u8981\u6781\u9ad8\u7684 \\(t_x\\) \u7edd\u5bf9\u503c\u3002\u6211\u4eec\u901a\u8fc7\u5c06 sigmoid \u4e58\u4ee5\u8d85\u8fc7 1.0 \u7684\u56e0\u5b50\u6765\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u5bf9\u8c61\u65e0\u6cd5\u68c0\u6d4b\u5230\u7684\u7f51\u683c\u7684\u5f71\u54cd\u3002 M: Mosaic data augmentation \u2013 using the 4-image mosaic during training instead of single image M\uff1a\u9a6c\u8d5b\u514b\u6570\u636e\u6269\u589e \u2013 \u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528 4 \u56fe\u50cf\u9576\u5d4c\uff0c\u800c\u4e0d\u662f\u5355\u4e2a\u56fe\u50cf IT: IoU threshold \u2013 using multiple anchors for a single ground truth IoU (truth, anchor) > IoU-threshold IT\uff1aIoU \u9608\u503c \u2013 \u4f7f\u7528\u591a\u4e2a\u951a\u70b9\u8fdb\u884c\u5355\u4e2a\u63a5\u5730\u771f\u76f8 IoU\uff08\u771f\u3001\u951a\uff09\u548c IoU \u9608\u503c | GA: Genetic algorithms \u2013 using genetic algorithms for selecting the optimal hyperparameters during network training on the \ufb01rst 10% of time periods GA\uff1a\u9057\u4f20\u7b97\u6cd5 \u2013 \u5728\u524d 10% \u7684\u65f6\u95f4\u6bb5\u7684\u7f51\u7edc\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u9009\u62e9\u6700\u4f73\u8d85\u53c2\u6570* LS: Class label smoothing \u2013 using class label smoothing for sigmoid activation LS\uff1a\u7c7b\u6807\u7b7e\u5e73\u6ed1 \u2013 \u4f7f\u7528\u7c7b\u6807\u7b7e\u5e73\u6ed1\u8fdb\u884c sigmoid \u6fc0\u6d3b CBN: CmBN \u2013 using Cross mini-Batch Normalization for collecting statistics inside the entire batch, instead of collecting statistics inside a single mini-batch CBN\uff1a CmBN \u2013 \u4f7f\u7528\u4ea4\u53c9\u5c0f\u6279\u5904\u7406\u89c4\u8303\u5316\u6536\u96c6\u6574\u4e2a\u6279\u5904\u7406\u4e2d\u7684\u7edf\u8ba1\u4fe1\u606f\uff0c\u800c\u4e0d\u662f\u5728\u5355\u4e2a\u5c0f\u6279\u5904\u7406\u4e2d\u6536\u96c6\u7edf\u8ba1\u4fe1\u606f* CA: Cosine annealing scheduler \u2013 altering the learning rate during sinusoid training CA\uff1a\u534f\u548c\u7d20\u9000\u706b\u8c03\u5ea6\u5668 \u2013 \u6539\u53d8\u6b63\u5f26\u8bad\u7ec3\u4e2d\u7684\u5b66\u4e60\u901f\u7387* DM: Dynamic mini-batch size \u2013 automatic increase of mini-batch size during small resolution training by using Random training shapes DM\uff1a\u52a8\u6001\u5c0f\u6279\u91cf\u5c3a\u5bf8 \u2013 \u4f7f\u7528\u968f\u673a\u8bad\u7ec3\u5f62\u72b6\u5728\u5c0f\u5206\u8fa8\u7387\u8bad\u7ec3\u671f\u95f4\u81ea\u52a8\u589e\u52a0\u5c0f\u6279\u91cf\u5927\u5c0f OA: Optimized Anchors \u2013 using the optimized anchors for training with the 512\u00d7512 network resolution OA\uff1a\u4f18\u5316\u7684\u951a\u70b9 \u2013 \u4f7f\u7528\u4f18\u5316\u7684\u951a\u70b9\u8fdb\u884c 512\u00d7512 \u7f51\u7edc\u5206\u8fa8\u7387\u7684\u8bad\u7ec3* GIoU, CIoU, DIoU, MSE \u2013 using different loss algorithms for bounded box regression GIoU\u3001CIoU\u3001DIoU\u3001MSE \u2013 \u5bf9\u8fb9\u754c\u6846\u56de\u5f52\u4f7f\u7528\u4e0d\u540c\u7684\u635f\u5931\u7b97\u6cd5 \u2003Further study concerns the in\ufb02uence of different Bagof-Specials (BoS-detector) on the detector training accuracy, including PAN, RFB, SAM, Gaussian YOLO (G), and ASFF, as shown in Table 5. In our experiments, the detector gets best performance when using SPP, PAN, and SAM. \u2003\u8fdb\u4e00\u6b65\u7814\u7a76\u6d89\u53ca\u4e0d\u540c\u7684\u5df4\u6208\u592b\u7279\u8f91\uff08BoS-\u68c0\u6d4b\u5668\uff09\u5bf9\u68c0\u6d4b\u5668\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u5305\u62ecPAN\u3001RFB\u3001SAM\u3001\u9ad8\u65afYOLO\uff08G\uff09\u548cASFF\uff0c\u5982\u88685\u6240\u793a\u3002\u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u68c0\u6d4b\u5668\u5728\u4f7f\u7528 SPP\u3001PAN \u548c SAM \u65f6\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002 Table 4: Ablation Studies of Bag-of-Freebies. (CSPResNeXt50-PANet-SPP , 512x512). Table 5: Ablation Studies of Bag-of-Specials. (Size 512x512).","title":"4.3. Influence of different features on Detector"},{"location":"thesis_interpretation/04_yolo.html#44-influence-of-different-backbones-and-pretrained-weightings-on-detector-training","text":"Further on we study the influence of different backbone models on the detector accuracy, as shown in Table 6. We notice that the model characterized with the best classifica- tion accuracy is not always the best in terms of the detector accuracy. \u2003 \u6700\u540e\uff0c\u6211\u4eec\u5206\u6790\u4e86\u5728\u4e0d\u540c\u6700\u5c0f\u6279\u91cf\u5927\u5c0f\u4e0b\u8bad\u7ec3\u7684\u6a21\u578b\u6240\u83b7\u5f97\u7684\u7ed3\u679c\uff0c\u7ed3\u679c\u5982\u88687\u6240\u793a\u3002\u4ece\u88687\u6240\u793a\u7684\u7ed3\u679c\u4e2d\uff0c\u6211\u4eec\u53d1\u73b0\u5728\u6dfb\u52a0BoF\u548cBoS\u8bad\u7ec3\u7b56\u7565\u4e4b\u540e\uff0c\u6700\u5c0f\u6279\u91cf\u5927\u5c0f\u51e0\u4e4e\u6ca1\u6709\u5f71\u54cd\u5728\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u4e0a\u3002\u8be5\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5f15\u5165BoF\u548cBoS\u4e4b\u540e\uff0c\u4e0d\u518d\u9700\u8981\u4f7f\u7528\u6602\u8d35\u7684GPU\u8fdb\u884c\u8bad\u7ec3\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u4efb\u4f55\u4eba\u90fd\u53ea\u80fd\u4f7f\u7528\u4f20\u7edf\u7684GPU\u6765\u8bad\u7ec3\u51fa\u8272\u7684\u63a2\u6d4b\u5668\u3002 Table 7: Using different mini-batch size for detector training. \u88687\uff1a\u4f7f\u7528\u4e0d\u540c\u7684\u5c0f\u6279\u91cf\u5bf9\u4e8e\u68c0\u6d4b\u5668\u8bad\u7ec3\u3002","title":"4.4. Influence of different backbones and pretrained weightings on Detector training"},{"location":"thesis_interpretation/04_yolo.html#5results","text":"Comparison of the results obtained with other state-of-the-art object detectors are shown in Figure 8. Our YOLOv4 are located on the Pareto optimality curve and are superior to the fastest and most accurate detectors in terms of both speed and accuracy. \u2003\u5f97\u5230\u7684\u7ed3\u679c\u4e0e\u5176\u4ed6\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u6bd4\u8f83\u5982\u56fe8\u6240\u793a\u3002\u6211\u4eec\u7684yolo4\u4f4d\u4e8ePareto optimality\u66f2\u7ebf\u4e0a\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u90fd\u4f18\u4e8e\u6700\u5feb\u548c\u6700\u7cbe\u786e\u7684\u63a2\u6d4b\u5668\u3002 \u2003Since different methods use GPUs of different architectures for inference time verification, we operate YOLOv4 on commonly adopted GPUs of Maxwell, Pascal, and Volta architectures, and compare them with other state-of-the-art methods. Table 8 lists the frame rate comparison results of using Maxwell GPU, and it can be GTX Titan X (Maxwell) or Tesla M40 GPU. Table 9 lists the frame rate comparison results of using Pascal GPU, and it can be Titan X (Pascal), Titan Xp, GTX 1080 Ti, or Tesla P100 GPU. As for Table 10, it lists the frame rate comparison results of using V olta GPU, and it can be Titan V olta or Tesla V100 GPU. \u2003\u7531\u4e8e\u4e0d\u540c\u7684\u65b9\u6cd5\u4f7f\u7528\u4e0d\u540c\u4f53\u7cfb\u7ed3\u6784\u7684GPU\u8fdb\u884c\u63a8\u7406\u65f6\u95f4\u9a8c\u8bc1\uff0c\u6211\u4eec\u5728\u5e38\u7528\u7684Maxwell\u3001Pascal\u548cVoltaArchitecture\u4f53\u7cfb\u7ed3\u6784\u7684GPU\u4e0a\u8fd0\u884cYOLOv4\uff0c\u5e76\u5c06\u5b83\u4eec\u4e0e\u5176\u4ed6\u5148\u8fdb\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u88688\u5217\u51fa\u4e86\u4f7f\u7528Maxwell GPU\u7684\u5e27\u7387\u6bd4\u8f83\u7ed3\u679c\uff0c\u53ef\u4ee5\u662fGTX Titan X(Maxwell)\u6216Tesla M40 GPU\u3002\u88689\u5217\u51fa\u4e86\u4f7f\u7528Pascal GPU\u7684\u5e27\u7387\u6bd4\u8f83\u7ed3\u679c\uff0c\u5b83\u53ef\u4ee5\u662fTitan X(Pascal)\u3001Titan XP\u3001GTX 1080 Ti\u6216Tesla P100 GPU\u3002\u886810\u5217\u51fa\u4e86\u4f7f\u7528VoltaGPU\u7684\u5e27\u7387\u5bf9\u6bd4\u7ed3\u679c\uff0c\u53ef\u4ee5\u662fTitan Volta\uff0c\u4e5f\u53ef\u4ee5\u662fTesla V100 GPU\u3002","title":"5.Results"},{"location":"thesis_interpretation/04_yolo.html#6-conclusions","text":"We offer a state-of-the-art detector which is faster (FPS) and more accurate (MS COCO \\(AP_{50...95}\\) and \\(AP_{50}\\) ) than all available alternative detectors. The detector described can be trained and used on a conventional GPU with 8-16 GB-VRAM this makes its broad use possible. The original concept of one-stage anchor-based detectors has proven its viability. We have verified a large number of features, and selected for use such of them for improving the accuracy of both the classifier and the detector. These features can be used as best-practice for future studies and developments. \u2003\u6211\u4eec\u63d0\u4f9b\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u901f\u5ea6\uff08FPS\uff09\u548c\u51c6\u786e\u5ea6\uff08MS COCO \\(AP_{50 ... 95}\\) \u548c \\(AP_{50}\\) \uff09\u6bd4\u6240\u6709\u53ef\u7528\u7684\u66ff\u4ee3\u68c0\u6d4b\u5668\u90fd\u9ad8\u3002\u6240\u63cf\u8ff0\u7684\u68c0\u6d4b\u5668\u53ef\u4ee5\u5728\u5177\u67098-16GB-VRAM\u7684\u5e38\u89c4GPU\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u4f7f\u7528\uff0c\u8fd9\u4f7f\u5f97\u5b83\u7684\u5e7f\u6cdb\u4f7f\u7528\u6210\u4e3a\u53ef\u80fd\u3002\u5355\u9636\u6bb5\u57fa\u4e8e\u951a\u6846\u7684\u68c0\u6d4b\u5668\u7684\u539f\u59cb\u6982\u5ff5\u5df2\u8bc1\u660e\u5176\u53ef\u884c\u6027\u3002\u6211\u4eec\u5df2\u7ecf\u9a8c\u8bc1\u4e86\u5927\u91cf\u7279\u5f81\uff0c\u5e76\u9009\u62e9\u4f7f\u7528\u5176\u4e2d\u7684\u4e00\u4e9b\u7279\u5f81\u4ee5\u63d0\u9ad8\u5206\u7c7b\u5668\u548c\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u3002\u8fd9\u4e9b\u529f\u80fd\u53ef\u4ee5\u7528\u4f5c\u5c06\u6765\u7814\u7a76\u548c\u5f00\u53d1\u7684\u6700\u4f73\u5b9e\u8df5\u3002","title":"6. Conclusions"},{"location":"thesis_interpretation/04_yolo.html#7-acknowledgements","text":"The authors wish to thank Glenn Jocher for the ideas of Mosaic data augmentation, the selection of hyper-parameters by using genetic algorithms and solving the grid sensitivity problem https://github.com/ultralytics/yolov3. \u2003\u4f5c\u8005\u8981\u611f\u8c22Glenn Jocher\u8fdb\u884cMosaic\u6570\u636e\u589e\u5f3a\u7684\u60f3\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u9009\u62e9\u8d85\u53c2\u6570\u5e76\u89e3\u51b3\u7f51\u683c\u654f\u611f\u6027\u95ee\u9898\u7684\u65b9\u6cd5https://github.com/ultralytics/yolov3.10\u3002","title":"7. Acknowledgements"},{"location":"thesis_interpretation/06_yolo.html","text":"\u8bba\u6587\uff1aYOLOv6: A Single-Stage Object Detection Framework for Industrial Applications \u4ee3\u7801\uff1ahttps://github.com/meituan/YOLOv6 \u5b98\u65b9\u535a\u6587\uff1ahttps://blog.csdn.net/MeituanTech/article/details/125437630","title":"YOLOv6"},{"location":"tutorials/00_chapter/overview.html","text":"0x0 \u52a8\u673a \u4e3a\u4e86\u8bf4\u660e\u4f7f\u7528 OneFlow \u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u53ef\u884c\u6027\u4ee5\u53ca\u6027\u80fd\u7684\u4f18\u8d8a\u6027\uff0c\u6700\u8fd1\u6211\u4eec\u5c06 ultralytics \u7248 YOLOv5\uff08https://github.com/ultralytics/yolov5\uff09\u901a\u8fc7import oneflow as torch\u7684\u65b9\u5f0f\u8fc1\u79fb\u4e3a\u4e86OneFlow\u540e\u7aef\uff08\u5bf9\u5e94YOLOv5\u7684commit\u53f7\u4e3a\uff1a 48a85314bc80d8023c99bfb114cea98d71dd0591 \uff09\u3002\u5e76\u5bf9 YOLOv5 \u4e2d\u76f8\u5173\u7684\u6559\u7a0b\u8fdb\u884c\u4e86\u6c49\u5316\uff0c\u6dfb\u52a0\u4e86\u4e00\u7cfb\u5217\u8be6\u7ec6\u7684\u4ee3\u7801\u89e3\u8bfb\uff0c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u90e8\u7f72\u6559\u7a0b\uff0c\u5e0c\u671b\u4f7f\u5f97 YOLOv5 \u9879\u76ee\u5bf9\u7528\u6237\u66f4\u52a0\u900f\u660e\u5316\u3002\u53e6\u5916\u6211\u4eec\u4e5f\u5c06\u5728\u6027\u80fd\u8fd9\u4e2a\u89d2\u5ea6\u8fdb\u884c\u6df1\u5165\u63a2\u7d22\uff0c\u672c\u6b21\u6211\u4eec\u53d1\u5e03\u7684OneFlow\u540e\u7aef\u7684YOLOv5\u53ea\u662f\u4e00\u4e2a\u57fa\u7840\u7248\u672c\uff0c\u6ca1\u6709\u7528\u4e0a\u4efb\u4f55\u7684\u4f18\u5316\u6280\u5de7\u3002\u76ee\u524d\u6211\u4eec\u5728\u5c0f Batch \u8fdb\u884c\u8bad\u7ec3\u65f6\u76f8\u6bd4\u4e8e PyTorch \u67095%-10%\u5de6\u53f3\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u800c\u5bf9\u4e8e\u5927 Batch \u5219\u6027\u80fd\u548c PyTorch \u6301\u5e73\u3002\u76f8\u4fe1\u5728\u540e\u7eed\u7684\u4e00\u4e9b\u5b9a\u5236\u5316\u7684\u6027\u80fd\u4f18\u5316\u6280\u5de7\u4e0b\uff08\u6bd4\u5982nn.Graph\u52a0\u6301\uff0c\u7b97\u5b50\u7684\u4f18\u5316\uff09\uff0c\u6211\u4eec\u53ef\u4ee5\u7ee7\u7eed\u63d0\u5347YOLOv5\u5728COCO\u7b49\u6570\u636e\u96c6\u7684\u8bad\u7ec3\u901f\u5ea6\uff0c\u66f4\u6709\u6548\u7f29\u77ed\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\u3002 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 \ud83c\udf89\u6587\u6863\u7f51\u7ad9\u5730\u5740\uff1ahttps://start.oneflow.org/oneflow-yolo-doc/index.html OneFlow \u5b89\u88c5\u65b9\u6cd5\uff1ahttps://github.com/Oneflow-Inc/oneflow#install-oneflow \u4e0d\u8fc7\u5373\u4f7f\u4f60\u5bf9 OneFlow \u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u4e0d\u592a\u611f\u5174\u8da3\uff0c\u6211\u4eec\u76f8\u4fe1 \u6587\u6863\u7f51\u7ad9 \u4e2d\u5bf9 YOLOv5 \u6559\u7a0b\u7684\u6c49\u5316\u4ee5\u53ca\u6e90\u7801\u5256\u6790\u4e5f\u4f1a\u662f\u4ece\u96f6\u5f00\u59cb\u6df1\u5165\u5b66\u4e60 YOLOv5 \u4e00\u4efd\u4e0d\u9519\u7684\u8d44\u6599\u3002\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6\u6700\u65b0\u7684\u52a8\u6001\u3002 0x1. \u5dee\u5f02 \u6211\u4eec\u5c06 YOLOv5 \u7684\u540e\u7aef\u4ece PyTorch \u6362\u6210 OneFlow \u4e4b\u540e\u9664\u4e86\u6027\u80fd\u4f18\u52bf\u5916\u8fd8\u505a\u4e86\u4e00\u4e9b\u5dee\u5f02\u5316\u7684\u5185\u5bb9\uff0c\u5176\u4e2d\u4e00\u4e9b\u5185\u5bb9\u5df2\u7ecf\u5b8c\u6210\uff0c\u8fd8\u6709\u4e00\u4e9b\u6b63\u5728\u8fdb\u884c\u4e2d\uff0c\u4e0b\u9762\u7b80\u5355\u5c55\u793a\u4e00\u4e0b\uff1a 1. YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790 2. \u5982\u4f55\u51c6\u5907yolov5\u6a21\u578b\u8bad\u7ec3\u6570\u636e 3. \u5feb\u901f\u5f00\u59cb 4. \u6a21\u578b\u8bad\u7ec3 5. \u6d4b\u8bd5\u65f6\u589e\u5f3a (TTA) 6. \u6a21\u578b\u878d\u5408 (Model Ensembling) 7. \u4ece OneFlow Hub \u52a0\u8f7d YOLOv5 8. \u6570\u636e\u589e\u5f3a 9. \u77e9\u5f62\u63a8\u7406 10. IOU\u6df1\u5165\u89e3\u6790 11. \u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30 12. ONNX\u6a21\u578b\u5bfc\u51fa \u8fd9\u4e00\u7cfb\u5217\u7684\u6587\u7ae0\u6211\u4eec\u5c06\u9010\u6b65\u5f00\u53d1\uff0cReview \u4ee5\u53ca\u53d1\u5e03\u5e76\u4e14\u4f1a\u6709\u76f8\u5e94\u7684\u89c6\u9891\u8bb2\u89e3\uff0c\u6211\u4eec\u5c06\u8fd9\u4e2a\u7cfb\u5217\u7684\u6587\u7ae0\u53eb\u4f5c\uff1a \u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b \ud83c\udf89\ud83c\udf89\ud83c\udf89 0x2. \u5728COCO\u4e0a\u7684\u7cbe\u5ea6\u8868\u73b0 \u6211\u4eec\u4ee5 yolov5n \u7f51\u7edc\u4e3a\u4f8b\uff0c result.csv \u8fd9\u4e2a\u65e5\u5fd7\u5c55\u793a\u4e86\u6211\u4eec\u57fa\u4e8e one-yolov5 \u5728 COCO \u4e0a\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 YOLOv5n \u7f51\u7edc\u7684\u65e5\u5fd7\u3002\u4e0b\u56fe\u5c55\u793a\u4e86 box_loss , obj_loss , cls_loss \uff0c map_0.5 , map_0.5:0.95 \u7b49\u6307\u6807\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u60c5\u51b5\uff1a \u6700\u7ec8\u5728\u7b2c 300 \u4e2a epoch \u65f6\uff0c\u6211\u4eec\u7684 map_0.5 \u8fbe\u5230\u4e86 0.45174 \uff0c map_0.5:0.95 \u8fbe\u5230\u4e86 0.27726 \u3002 \u548c ultralytics/yolov5 \u7ed9\u51fa\u7684\u7cbe\u5ea6\u6570\u636e \u4e00\u81f4\uff08\u6ce8\u610f\u5b98\u7f51\u7ed9\u51fa\u7684\u7cbe\u5ea6\u6307\u5b9a iou \u4e3a 0.65 \u7684\u7cbe\u5ea6\uff0c\u800c\u4e0a\u8ff0 csv \u6587\u4ef6\u4e2d\u662f\u5728 iou \u4e3a 0.60 \u4e0b\u7684\u7cbe\u5ea6\uff0c\u4f7f\u7528\u6211\u4eec\u8bad\u7ec3\u7684\u6743\u91cd\u5e76\u628a iou \u6307\u5b9a\u4e3a 0.65 \u53ef\u4ee5\u5b8c\u5168\u5bf9\u9f50\u5b98\u65b9\u7ed9\u51fa\u7684\u7cbe\u5ea6\u6570\u636e\uff09\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 ultralytics/yolov5 \u6765\u9a8c\u8bc1\u4e00\u4e0b\uff1a python val . py -- weights yolov5n . pt -- data data / coco . yaml -- img 640 -- iou 0.60 \u8f93\u51fa\uff1a val: data = data/coco.yaml, weights =[ 'yolov5n.pt' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, max_det = 300 , task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = False, dnn = False YOLOv5 \ud83d\ude80 v6.1-384-g7fd9867 Python-3.8.13 torch-1.10.0+cu113 CUDA:0 ( NVIDIA GeForce RTX 3080 Ti, 12054MiB ) cuda:0 Fusing layers... YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4 .5 GFLOPs val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588 Class Images Instances P R mAP50 mAP50-95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 00 :40< 00 :00, 3 . all 5000 36335 0 .573 0 .432 0 .456 0 .277 \u4e0a\u9762\u7684\u8f93\u51fa\u53ef\u4ee5\u8bf4\u660e\u6211\u4eec\u548c ultralytics/yolov5 \u7684\u7cbe\u5ea6\u662f\u5b8c\u5168\u5bf9\u9f50\u7684\u3002 \u5728 one-yolov5 \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 yolov5n \u8fdb\u884c\u7cbe\u5ea6\u590d\u73b0\u7684\u547d\u4ee4\u4e3a (2\u5361DDP\u6a21\u5f0f) \uff1a python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- data data / coco . yaml -- weights ' ' -- cfg models / yolov5n . yaml -- batch 64 0x3. \u5728COCO\u4e0a\u7684\u6027\u80fd\u8868\u73b0 \u4ee5\u4e0b\u7684\u6027\u80fd\u7ed3\u679c\u90fd\u662f\u76f4\u63a5\u5c06 PyTorch \u5207\u6362\u4e3a OneFlow \u4e4b\u540e\u6d4b\u8bd5\u7684\uff0c \u5e76\u6ca1\u6709\u505a\u9488\u5bf9\u6027\u4f18\u5316 \uff0c\u540e\u7eed\u4f1a\u5728\u6b64\u57fa\u7840\u4e0a\u7ee7\u7eed\u63d0\u5347 OneFlow \u540e\u7aef YOLOv5 \u7684\u8bad\u7ec3\u901f\u5ea6\u3002 \u5728 3080Ti \u7684\u6027\u80fd\u6d4b\u8bd5\u7ed3\u679c \u5355\u5361\u6d4b\u8bd5\u7ed3\u679c \u4ee5\u4e0b\u4e3aGTX 3080ti(12GB) \u7684yolov5\u6d4b\u8bd5\u7ed3\u679c\uff08oneflow\u540e\u7aef vs PyTorch\u540e\u7aef\uff09 \u4ee5\u4e0b\u6d4b\u8bd5\u7ed3\u679c\u7684\u6570\u636e\u914d\u7f6e\u5747\u4e3acoco.yaml\uff0c\u6a21\u578b\u914d\u7f6e\u4e5f\u5b8c\u5168\u4e00\u6837\uff0c\u5e76\u8bb0\u5f55\u8bad\u7ec3\u5b8ccoco\u6570\u636e\u96c61\u4e2aepoch\u9700\u8981\u7684\u65f6\u95f4 \u7531\u4e8eoneflow eager\u76ee\u524damp\u7684\u652f\u6301\u8fd8\u4e0d\u5b8c\u5584\uff0c\u6240\u4ee5\u6211\u4eec\u63d0\u4f9b\u7684\u7ed3\u679c\u5747\u4e3afp32\u6a21\u5f0f\u4e0b\u8fdb\u884c\u8bad\u7ec3\u7684\u6027\u80fd\u7ed3\u679c PyTorch\u7248\u672c yolov5 code base\u94fe\u63a5\uff1ahttps://github.com/ultralytics/yolov5 OneFlow\u7248\u672c yolov5 code base\u94fe\u63a5\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 cuda \u7248\u672c 11.7, cudnn \u7248\u672c\u4e3a 8.5.0 \u6d4b\u8bd5\u7684\u547d\u4ee4\u4e3a\uff1a python train.py --batch 16 --cfg models/yolov5n.yaml --weights '' --data coco.yaml --img 640 --device 0 \uff0c\u5176\u4e2d batch \u53c2\u6570\u662f\u52a8\u6001\u53d8\u5316\u7684 \u53ef\u4ee5\u770b\u5230\uff0c\u5728 batch \u6bd4\u8f83\u5c0f\u7684\u65f6\u5019 OneFlow \u540e\u7aef\u7684 YOLOv5 \u76f8\u6bd4\u4e8e PyTorch \u6709 5%-10% \u5de6\u53f3\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u8fd9\u53ef\u80fd\u5f97\u76ca\u4e8e OneFlow \u7684 Eager \u8fd0\u884c\u65f6\u7cfb\u7edf\u53ef\u4ee5\u66f4\u5feb\u7684\u505a CUDA Kernel Launch\u3002\u800c batch \u6bd4\u8f83\u5927\u7684\u65f6\u5019 OneFlow \u540e\u7aef\u7684 YOLOv5 \u76f8\u6bd4\u4e8e PyTorch \u7684\u6027\u80fd\u5dee\u4e0d\u591a\u662f\u6301\u5e73\uff0c\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u5f53 Batch \u6bd4\u8f83\u5927\u7684\u65f6\u5019 CUDA Kernel Launch \u7684\u5f00\u9500\u76f8\u6bd4\u4e8e\u8ba1\u7b97\u7684\u5f00\u9500\u4f1a\u6bd4\u8f83\u5c0f\u3002 \u4e24\u5361DDP\u6d4b\u8bd5\u7ed3\u679c \u914d\u7f6e\u548c\u5355\u5361\u5747\u4e00\u81f4 \u6d4b\u8bd5\u7684\u547d\u4ee4\u4e3a\uff1a python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 16 --data coco.yaml --weights '' --device 0,1 \uff0c\u5176\u4e2d batch \u53c2\u6570\u662f\u52a8\u6001\u53d8\u5316\u7684 \u5f97\u76ca\u4e8e\u5355\u5361\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5728 2 \u5361DDP\u6a21\u5f0f\u4e0b\uff0cOneFlow \u540e\u7aef\u7684 YOLOv5 \u5728\u5c0f batch \u7684\u8bad\u7ec3\u65f6\u95f4\u4e5f\u662f\u7a0d\u5fae\u9886\u5148 PyTorch \u540e\u7aef\u7684 YoloV5 \uff0c\u800c\u5bf9\u4e8e\u5927 Batch \u6765\u8bf4\u6027\u80fd\u548c PyTorch \u76f8\u6bd4\u4e5f\u662f\u5dee\u4e0d\u591a\u6301\u5e73\u3002 0x4. \u603b\u7ed3 \u6211\u4eec\u57fa\u4e8e OneFlow \u79fb\u690d\u4e86 ultralytics \u7248\u7684 YOLOv5 \uff0c\u5728\u7cbe\u5ea6\u8bad\u7ec3\u8fbe\u6807\u7684\u60c5\u51b5\u4e0b\u8fd8\u53ef\u4ee5\u5728 Batch \u6bd4\u8f83\u5c0f\u65f6\u53d6\u5f97\u4e00\u4e9b\u6027\u80fd\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9 YOLOv5 \u4e2d\u76f8\u5173\u7684\u6559\u7a0b\u8fdb\u884c\u4e86\u6c49\u5316\uff0c\u6dfb\u52a0\u4e86\u4e00\u7cfb\u5217\u8be6\u7ec6\u7684\u4ee3\u7801\u89e3\u8bfb\uff0c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u90e8\u7f72\u6559\u7a0b\uff0c\u5e0c\u671b\u4f7f\u5f97 YOLOv5 \u9879\u76ee\u5bf9\u7528\u6237\u66f4\u52a0\u900f\u660e\u5316\u3002\u76f8\u4fe1\u5bf9\u60f3\u6df1\u5165\u4e86\u89e3 YOLOv5 \u7684\u8bfb\u8005\u6211\u4eec\u7684 \u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b \u4e5f\u662f\u4e00\u4efd\u4e0d\u9519\u7684\u5b66\u4e60\u8d44\u6599\u3002","title":"one-yolov5 \u7279\u70b9\u89e3\u6790"},{"location":"tutorials/00_chapter/overview.html#0x0","text":"\u4e3a\u4e86\u8bf4\u660e\u4f7f\u7528 OneFlow \u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u53ef\u884c\u6027\u4ee5\u53ca\u6027\u80fd\u7684\u4f18\u8d8a\u6027\uff0c\u6700\u8fd1\u6211\u4eec\u5c06 ultralytics \u7248 YOLOv5\uff08https://github.com/ultralytics/yolov5\uff09\u901a\u8fc7import oneflow as torch\u7684\u65b9\u5f0f\u8fc1\u79fb\u4e3a\u4e86OneFlow\u540e\u7aef\uff08\u5bf9\u5e94YOLOv5\u7684commit\u53f7\u4e3a\uff1a 48a85314bc80d8023c99bfb114cea98d71dd0591 \uff09\u3002\u5e76\u5bf9 YOLOv5 \u4e2d\u76f8\u5173\u7684\u6559\u7a0b\u8fdb\u884c\u4e86\u6c49\u5316\uff0c\u6dfb\u52a0\u4e86\u4e00\u7cfb\u5217\u8be6\u7ec6\u7684\u4ee3\u7801\u89e3\u8bfb\uff0c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u90e8\u7f72\u6559\u7a0b\uff0c\u5e0c\u671b\u4f7f\u5f97 YOLOv5 \u9879\u76ee\u5bf9\u7528\u6237\u66f4\u52a0\u900f\u660e\u5316\u3002\u53e6\u5916\u6211\u4eec\u4e5f\u5c06\u5728\u6027\u80fd\u8fd9\u4e2a\u89d2\u5ea6\u8fdb\u884c\u6df1\u5165\u63a2\u7d22\uff0c\u672c\u6b21\u6211\u4eec\u53d1\u5e03\u7684OneFlow\u540e\u7aef\u7684YOLOv5\u53ea\u662f\u4e00\u4e2a\u57fa\u7840\u7248\u672c\uff0c\u6ca1\u6709\u7528\u4e0a\u4efb\u4f55\u7684\u4f18\u5316\u6280\u5de7\u3002\u76ee\u524d\u6211\u4eec\u5728\u5c0f Batch \u8fdb\u884c\u8bad\u7ec3\u65f6\u76f8\u6bd4\u4e8e PyTorch \u67095%-10%\u5de6\u53f3\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u800c\u5bf9\u4e8e\u5927 Batch \u5219\u6027\u80fd\u548c PyTorch \u6301\u5e73\u3002\u76f8\u4fe1\u5728\u540e\u7eed\u7684\u4e00\u4e9b\u5b9a\u5236\u5316\u7684\u6027\u80fd\u4f18\u5316\u6280\u5de7\u4e0b\uff08\u6bd4\u5982nn.Graph\u52a0\u6301\uff0c\u7b97\u5b50\u7684\u4f18\u5316\uff09\uff0c\u6211\u4eec\u53ef\u4ee5\u7ee7\u7eed\u63d0\u5347YOLOv5\u5728COCO\u7b49\u6570\u636e\u96c6\u7684\u8bad\u7ec3\u901f\u5ea6\uff0c\u66f4\u6709\u6548\u7f29\u77ed\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\u3002 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 \ud83c\udf89\u6587\u6863\u7f51\u7ad9\u5730\u5740\uff1ahttps://start.oneflow.org/oneflow-yolo-doc/index.html OneFlow \u5b89\u88c5\u65b9\u6cd5\uff1ahttps://github.com/Oneflow-Inc/oneflow#install-oneflow \u4e0d\u8fc7\u5373\u4f7f\u4f60\u5bf9 OneFlow \u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u4e0d\u592a\u611f\u5174\u8da3\uff0c\u6211\u4eec\u76f8\u4fe1 \u6587\u6863\u7f51\u7ad9 \u4e2d\u5bf9 YOLOv5 \u6559\u7a0b\u7684\u6c49\u5316\u4ee5\u53ca\u6e90\u7801\u5256\u6790\u4e5f\u4f1a\u662f\u4ece\u96f6\u5f00\u59cb\u6df1\u5165\u5b66\u4e60 YOLOv5 \u4e00\u4efd\u4e0d\u9519\u7684\u8d44\u6599\u3002\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6\u6700\u65b0\u7684\u52a8\u6001\u3002","title":"0x0 \u52a8\u673a"},{"location":"tutorials/00_chapter/overview.html#0x1","text":"\u6211\u4eec\u5c06 YOLOv5 \u7684\u540e\u7aef\u4ece PyTorch \u6362\u6210 OneFlow \u4e4b\u540e\u9664\u4e86\u6027\u80fd\u4f18\u52bf\u5916\u8fd8\u505a\u4e86\u4e00\u4e9b\u5dee\u5f02\u5316\u7684\u5185\u5bb9\uff0c\u5176\u4e2d\u4e00\u4e9b\u5185\u5bb9\u5df2\u7ecf\u5b8c\u6210\uff0c\u8fd8\u6709\u4e00\u4e9b\u6b63\u5728\u8fdb\u884c\u4e2d\uff0c\u4e0b\u9762\u7b80\u5355\u5c55\u793a\u4e00\u4e0b\uff1a 1. YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790 2. \u5982\u4f55\u51c6\u5907yolov5\u6a21\u578b\u8bad\u7ec3\u6570\u636e 3. \u5feb\u901f\u5f00\u59cb 4. \u6a21\u578b\u8bad\u7ec3 5. \u6d4b\u8bd5\u65f6\u589e\u5f3a (TTA) 6. \u6a21\u578b\u878d\u5408 (Model Ensembling) 7. \u4ece OneFlow Hub \u52a0\u8f7d YOLOv5 8. \u6570\u636e\u589e\u5f3a 9. \u77e9\u5f62\u63a8\u7406 10. IOU\u6df1\u5165\u89e3\u6790 11. \u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30 12. ONNX\u6a21\u578b\u5bfc\u51fa \u8fd9\u4e00\u7cfb\u5217\u7684\u6587\u7ae0\u6211\u4eec\u5c06\u9010\u6b65\u5f00\u53d1\uff0cReview \u4ee5\u53ca\u53d1\u5e03\u5e76\u4e14\u4f1a\u6709\u76f8\u5e94\u7684\u89c6\u9891\u8bb2\u89e3\uff0c\u6211\u4eec\u5c06\u8fd9\u4e2a\u7cfb\u5217\u7684\u6587\u7ae0\u53eb\u4f5c\uff1a \u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b \ud83c\udf89\ud83c\udf89\ud83c\udf89","title":"0x1. \u5dee\u5f02"},{"location":"tutorials/00_chapter/overview.html#0x2-coco","text":"\u6211\u4eec\u4ee5 yolov5n \u7f51\u7edc\u4e3a\u4f8b\uff0c result.csv \u8fd9\u4e2a\u65e5\u5fd7\u5c55\u793a\u4e86\u6211\u4eec\u57fa\u4e8e one-yolov5 \u5728 COCO \u4e0a\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 YOLOv5n \u7f51\u7edc\u7684\u65e5\u5fd7\u3002\u4e0b\u56fe\u5c55\u793a\u4e86 box_loss , obj_loss , cls_loss \uff0c map_0.5 , map_0.5:0.95 \u7b49\u6307\u6807\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u60c5\u51b5\uff1a \u6700\u7ec8\u5728\u7b2c 300 \u4e2a epoch \u65f6\uff0c\u6211\u4eec\u7684 map_0.5 \u8fbe\u5230\u4e86 0.45174 \uff0c map_0.5:0.95 \u8fbe\u5230\u4e86 0.27726 \u3002 \u548c ultralytics/yolov5 \u7ed9\u51fa\u7684\u7cbe\u5ea6\u6570\u636e \u4e00\u81f4\uff08\u6ce8\u610f\u5b98\u7f51\u7ed9\u51fa\u7684\u7cbe\u5ea6\u6307\u5b9a iou \u4e3a 0.65 \u7684\u7cbe\u5ea6\uff0c\u800c\u4e0a\u8ff0 csv \u6587\u4ef6\u4e2d\u662f\u5728 iou \u4e3a 0.60 \u4e0b\u7684\u7cbe\u5ea6\uff0c\u4f7f\u7528\u6211\u4eec\u8bad\u7ec3\u7684\u6743\u91cd\u5e76\u628a iou \u6307\u5b9a\u4e3a 0.65 \u53ef\u4ee5\u5b8c\u5168\u5bf9\u9f50\u5b98\u65b9\u7ed9\u51fa\u7684\u7cbe\u5ea6\u6570\u636e\uff09\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 ultralytics/yolov5 \u6765\u9a8c\u8bc1\u4e00\u4e0b\uff1a python val . py -- weights yolov5n . pt -- data data / coco . yaml -- img 640 -- iou 0.60 \u8f93\u51fa\uff1a val: data = data/coco.yaml, weights =[ 'yolov5n.pt' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, max_det = 300 , task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = False, dnn = False YOLOv5 \ud83d\ude80 v6.1-384-g7fd9867 Python-3.8.13 torch-1.10.0+cu113 CUDA:0 ( NVIDIA GeForce RTX 3080 Ti, 12054MiB ) cuda:0 Fusing layers... YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4 .5 GFLOPs val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588 Class Images Instances P R mAP50 mAP50-95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 00 :40< 00 :00, 3 . all 5000 36335 0 .573 0 .432 0 .456 0 .277 \u4e0a\u9762\u7684\u8f93\u51fa\u53ef\u4ee5\u8bf4\u660e\u6211\u4eec\u548c ultralytics/yolov5 \u7684\u7cbe\u5ea6\u662f\u5b8c\u5168\u5bf9\u9f50\u7684\u3002 \u5728 one-yolov5 \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 yolov5n \u8fdb\u884c\u7cbe\u5ea6\u590d\u73b0\u7684\u547d\u4ee4\u4e3a (2\u5361DDP\u6a21\u5f0f) \uff1a python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- data data / coco . yaml -- weights ' ' -- cfg models / yolov5n . yaml -- batch 64","title":"0x2. \u5728COCO\u4e0a\u7684\u7cbe\u5ea6\u8868\u73b0"},{"location":"tutorials/00_chapter/overview.html#0x3-coco","text":"\u4ee5\u4e0b\u7684\u6027\u80fd\u7ed3\u679c\u90fd\u662f\u76f4\u63a5\u5c06 PyTorch \u5207\u6362\u4e3a OneFlow \u4e4b\u540e\u6d4b\u8bd5\u7684\uff0c \u5e76\u6ca1\u6709\u505a\u9488\u5bf9\u6027\u4f18\u5316 \uff0c\u540e\u7eed\u4f1a\u5728\u6b64\u57fa\u7840\u4e0a\u7ee7\u7eed\u63d0\u5347 OneFlow \u540e\u7aef YOLOv5 \u7684\u8bad\u7ec3\u901f\u5ea6\u3002","title":"0x3. \u5728COCO\u4e0a\u7684\u6027\u80fd\u8868\u73b0"},{"location":"tutorials/00_chapter/overview.html#3080ti","text":"","title":"\u5728 3080Ti \u7684\u6027\u80fd\u6d4b\u8bd5\u7ed3\u679c"},{"location":"tutorials/00_chapter/overview.html#_1","text":"\u4ee5\u4e0b\u4e3aGTX 3080ti(12GB) \u7684yolov5\u6d4b\u8bd5\u7ed3\u679c\uff08oneflow\u540e\u7aef vs PyTorch\u540e\u7aef\uff09 \u4ee5\u4e0b\u6d4b\u8bd5\u7ed3\u679c\u7684\u6570\u636e\u914d\u7f6e\u5747\u4e3acoco.yaml\uff0c\u6a21\u578b\u914d\u7f6e\u4e5f\u5b8c\u5168\u4e00\u6837\uff0c\u5e76\u8bb0\u5f55\u8bad\u7ec3\u5b8ccoco\u6570\u636e\u96c61\u4e2aepoch\u9700\u8981\u7684\u65f6\u95f4 \u7531\u4e8eoneflow eager\u76ee\u524damp\u7684\u652f\u6301\u8fd8\u4e0d\u5b8c\u5584\uff0c\u6240\u4ee5\u6211\u4eec\u63d0\u4f9b\u7684\u7ed3\u679c\u5747\u4e3afp32\u6a21\u5f0f\u4e0b\u8fdb\u884c\u8bad\u7ec3\u7684\u6027\u80fd\u7ed3\u679c PyTorch\u7248\u672c yolov5 code base\u94fe\u63a5\uff1ahttps://github.com/ultralytics/yolov5 OneFlow\u7248\u672c yolov5 code base\u94fe\u63a5\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 cuda \u7248\u672c 11.7, cudnn \u7248\u672c\u4e3a 8.5.0 \u6d4b\u8bd5\u7684\u547d\u4ee4\u4e3a\uff1a python train.py --batch 16 --cfg models/yolov5n.yaml --weights '' --data coco.yaml --img 640 --device 0 \uff0c\u5176\u4e2d batch \u53c2\u6570\u662f\u52a8\u6001\u53d8\u5316\u7684 \u53ef\u4ee5\u770b\u5230\uff0c\u5728 batch \u6bd4\u8f83\u5c0f\u7684\u65f6\u5019 OneFlow \u540e\u7aef\u7684 YOLOv5 \u76f8\u6bd4\u4e8e PyTorch \u6709 5%-10% \u5de6\u53f3\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u8fd9\u53ef\u80fd\u5f97\u76ca\u4e8e OneFlow \u7684 Eager \u8fd0\u884c\u65f6\u7cfb\u7edf\u53ef\u4ee5\u66f4\u5feb\u7684\u505a CUDA Kernel Launch\u3002\u800c batch \u6bd4\u8f83\u5927\u7684\u65f6\u5019 OneFlow \u540e\u7aef\u7684 YOLOv5 \u76f8\u6bd4\u4e8e PyTorch \u7684\u6027\u80fd\u5dee\u4e0d\u591a\u662f\u6301\u5e73\uff0c\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u5f53 Batch \u6bd4\u8f83\u5927\u7684\u65f6\u5019 CUDA Kernel Launch \u7684\u5f00\u9500\u76f8\u6bd4\u4e8e\u8ba1\u7b97\u7684\u5f00\u9500\u4f1a\u6bd4\u8f83\u5c0f\u3002","title":"\u5355\u5361\u6d4b\u8bd5\u7ed3\u679c"},{"location":"tutorials/00_chapter/overview.html#ddp","text":"\u914d\u7f6e\u548c\u5355\u5361\u5747\u4e00\u81f4 \u6d4b\u8bd5\u7684\u547d\u4ee4\u4e3a\uff1a python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 16 --data coco.yaml --weights '' --device 0,1 \uff0c\u5176\u4e2d batch \u53c2\u6570\u662f\u52a8\u6001\u53d8\u5316\u7684 \u5f97\u76ca\u4e8e\u5355\u5361\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5728 2 \u5361DDP\u6a21\u5f0f\u4e0b\uff0cOneFlow \u540e\u7aef\u7684 YOLOv5 \u5728\u5c0f batch \u7684\u8bad\u7ec3\u65f6\u95f4\u4e5f\u662f\u7a0d\u5fae\u9886\u5148 PyTorch \u540e\u7aef\u7684 YoloV5 \uff0c\u800c\u5bf9\u4e8e\u5927 Batch \u6765\u8bf4\u6027\u80fd\u548c PyTorch \u76f8\u6bd4\u4e5f\u662f\u5dee\u4e0d\u591a\u6301\u5e73\u3002","title":"\u4e24\u5361DDP\u6d4b\u8bd5\u7ed3\u679c"},{"location":"tutorials/00_chapter/overview.html#0x4","text":"\u6211\u4eec\u57fa\u4e8e OneFlow \u79fb\u690d\u4e86 ultralytics \u7248\u7684 YOLOv5 \uff0c\u5728\u7cbe\u5ea6\u8bad\u7ec3\u8fbe\u6807\u7684\u60c5\u51b5\u4e0b\u8fd8\u53ef\u4ee5\u5728 Batch \u6bd4\u8f83\u5c0f\u65f6\u53d6\u5f97\u4e00\u4e9b\u6027\u80fd\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9 YOLOv5 \u4e2d\u76f8\u5173\u7684\u6559\u7a0b\u8fdb\u884c\u4e86\u6c49\u5316\uff0c\u6dfb\u52a0\u4e86\u4e00\u7cfb\u5217\u8be6\u7ec6\u7684\u4ee3\u7801\u89e3\u8bfb\uff0c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u90e8\u7f72\u6559\u7a0b\uff0c\u5e0c\u671b\u4f7f\u5f97 YOLOv5 \u9879\u76ee\u5bf9\u7528\u6237\u66f4\u52a0\u900f\u660e\u5316\u3002\u76f8\u4fe1\u5bf9\u60f3\u6df1\u5165\u4e86\u89e3 YOLOv5 \u7684\u8bfb\u8005\u6211\u4eec\u7684 \u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b \u4e5f\u662f\u4e00\u4efd\u4e0d\u9519\u7684\u5b66\u4e60\u8d44\u6599\u3002","title":"0x4. \u603b\u7ed3"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790 \u5f15\u8a00 YOLOv5\u9488\u5bf9\u4e0d\u540c\u5927\u5c0f\uff08n, s, m, l, x\uff09\u7684\u7f51\u7edc\u6574\u4f53\u67b6\u6784\u90fd\u662f\u4e00\u6837\u7684\uff0c\u53ea\u4e0d\u8fc7\u4f1a\u5728\u6bcf\u4e2a\u5b50\u6a21\u5757\u4e2d\u91c7\u7528\u4e0d\u540c\u7684\u6df1\u5ea6\u548c\u5bbd\u5ea6\uff0c \u5206\u522b\u5e94\u5bf9yaml\u6587\u4ef6\u4e2d\u7684depth_multiple\u548cwidth_multiple\u53c2\u6570\u3002 \u8fd8\u9700\u8981\u6ce8\u610f\u4e00\u70b9\uff0c\u5b98\u65b9\u9664\u4e86n, s, m, l, x\u7248\u672c\u5916\u8fd8\u6709n6, s6, m6, l6, x6\uff0c\u533a\u522b\u5728\u4e8e\u540e\u8005\u662f\u9488\u5bf9\u66f4\u5927\u5206\u8fa8\u7387\u7684\u56fe\u7247\u6bd4\u59821280x1280, \u5f53\u7136\u7ed3\u6784\u4e0a\u4e5f\u6709\u4e9b\u5dee\u5f02\uff0c\u524d\u8005\u53ea\u4f1a\u4e0b\u91c7\u6837\u523032\u500d\u4e14\u91c7\u75283\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42 , \u800c\u540e\u8005\u4f1a\u4e0b\u91c7\u683764\u500d\uff0c\u91c7\u75284\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u3002 \u672c\u7ae0\u5c06\u4ee5 yolov5s\u4e3a\u4f8b \uff0c\u4ece\u914d\u7f6e\u6587\u4ef6 models/ yolov5s.yaml \u5230 models/ yolo.py \u6e90\u7801\u8fdb\u884c\u89e3\u8bfb\u3002 yolov5s.yaml \u6587\u4ef6\u5185\u5bb9: nc : 80 # number of classes \u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u6570 depth_multiple : 0.33 # model depth multiple \u6a21\u578b\u5c42\u6570\u56e0\u5b50(\u7528\u6765\u8c03\u6574\u7f51\u7edc\u7684\u6df1\u5ea6) width_multiple : 0.50 # layer channel multiple \u6a21\u578b\u901a\u9053\u6570\u56e0\u5b50(\u7528\u6765\u8c03\u6574\u7f51\u7edc\u7684\u5bbd\u5ea6) # \u5982\u4f55\u7406\u89e3\u8fd9\u4e2adepth_multiple\u548cwidth_multiple\u5462? # \u5b83\u51b3\u5b9a\u7684\u662f\u6574\u4e2a\u6a21\u578b\u4e2d\u7684\u6df1\u5ea6\uff08\u5c42\u6570\uff09\u548c\u5bbd\u5ea6\uff08\u901a\u9053\u6570\uff09,\u5177\u4f53\u600e\u4e48\u8c03\u6574\u7684\u7ed3\u5408\u540e\u9762\u7684backbone\u4ee3\u7801\u89e3\u91ca\u3002 anchors : # \u8868\u793a\u4f5c\u7528\u4e8e\u5f53\u524d\u7279\u5f81\u56fe\u7684Anchor\u5927\u5c0f\u4e3a xxx # 9\u4e2aanchor\uff0c\u5176\u4e2dP\u8868\u793a\u7279\u5f81\u56fe\u7684\u5c42\u7ea7\uff0cP3/8\u8be5\u5c42\u7279\u5f81\u56fe\u7f29\u653e\u4e3a1/8,\u662f\u7b2c3\u5c42\u7279\u5f81 - [ 10 , 13 , 16 , 30 , 33 , 23 ] # P3/8\uff0c \u8868\u793a[10,13],[16,30], [33,23]3\u4e2aanchor - [ 30 , 61 , 62 , 45 , 59 , 119 ] # P4/16 - [ 116 , 90 , 156 , 198 , 373 , 326 ] # P5/32 # YOLOv5s v6.0 backbone backbone : # [from, number, module, args] [[ -1 , 1 , Conv , [ 64 , 6 , 2 , 2 ]], # 0-P1/2 [ -1 , 1 , Conv , [ 128 , 3 , 2 ]], # 1-P2/4 [ -1 , 3 , C3 , [ 128 ]], [ -1 , 1 , Conv , [ 256 , 3 , 2 ]], # 3-P3/8 [ -1 , 6 , C3 , [ 256 ]], [ -1 , 1 , Conv , [ 512 , 3 , 2 ]], # 5-P4/16 [ -1 , 9 , C3 , [ 512 ]], [ -1 , 1 , Conv , [ 1024 , 3 , 2 ]], # 7-P5/32 [ -1 , 3 , C3 , [ 1024 ]], [ -1 , 1 , SPPF , [ 1024 , 5 ]], # 9 ] # YOLOv5s v6.0 head head : [[ -1 , 1 , Conv , [ 512 , 1 , 1 ]], [ -1 , 1 , nn.Upsample , [ None , 2 , 'nearest' ]], [[ -1 , 6 ], 1 , Concat , [ 1 ]], # cat backbone P4 [ -1 , 3 , C3 , [ 512 , False ]], # 13 [ -1 , 1 , Conv , [ 256 , 1 , 1 ]], [ -1 , 1 , nn.Upsample , [ None , 2 , 'nearest' ]], [[ -1 , 4 ], 1 , Concat , [ 1 ]], # cat backbone P3 [ -1 , 3 , C3 , [ 256 , False ]], # 17 (P3/8-small) [ -1 , 1 , Conv , [ 256 , 3 , 2 ]], [[ -1 , 14 ], 1 , Concat , [ 1 ]], # cat head P4 [ -1 , 3 , C3 , [ 512 , False ]], # 20 (P4/16-medium) [ -1 , 1 , Conv , [ 512 , 3 , 2 ]], [[ -1 , 10 ], 1 , Concat , [ 1 ]], # cat head P5 [ -1 , 3 , C3 , [ 1024 , False ]], # 23 (P5/32-large) [[ 17 , 20 , 23 ], 1 , Detect , [ nc , anchors ]], # Detect(P3, P4, P5) ] anchors \u89e3\u8bfb yolov5 \u521d\u59cb\u5316\u4e86 9 \u4e2a anchors\uff0c\u5206\u522b\u5728\u4e09\u4e2a\u7279\u5f81\u56fe \uff08feature map\uff09\u4e2d\u4f7f\u7528\uff0c\u6bcf\u4e2a feature map \u7684\u6bcf\u4e2a grid cell \u90fd\u6709\u4e09\u4e2a anchor \u8fdb\u884c\u9884\u6d4b\u3002 \u5206\u914d\u89c4\u5219\uff1a \u5c3a\u5ea6\u8d8a\u5927\u7684 feature map \u8d8a\u9760\u524d\uff0c\u76f8\u5bf9\u539f\u56fe\u7684\u4e0b\u91c7\u6837\u7387\u8d8a\u5c0f\uff0c\u611f\u53d7\u91ce\u8d8a\u5c0f\uff0c \u6240\u4ee5\u76f8\u5bf9\u53ef\u4ee5\u9884\u6d4b\u4e00\u4e9b\u5c3a\u5ea6\u6bd4\u8f83\u5c0f\u7684\u7269\u4f53(\u5c0f\u76ee\u6807)\uff0c\u5206\u914d\u5230\u7684 anchors \u8d8a\u5c0f\u3002 \u5c3a\u5ea6\u8d8a\u5c0f\u7684 feature map \u8d8a\u9760\u540e\uff0c\u76f8\u5bf9\u539f\u56fe\u7684\u4e0b\u91c7\u6837\u7387\u8d8a\u5927\uff0c\u611f\u53d7\u91ce\u8d8a\u5927\uff0c \u6240\u4ee5\u53ef\u4ee5\u9884\u6d4b\u4e00\u4e9b\u5c3a\u5ea6\u6bd4\u8f83\u5927\u7684\u7269\u4f53(\u5927\u76ee\u6807)\uff0c\u6240\u4ee5\u5206\u914d\u5230\u7684 anchors \u8d8a\u5927\u3002 \u5373\u5728\u5c0f\u7279\u5f81\u56fe\uff08feature map\uff09\u4e0a\u68c0\u6d4b\u5927\u76ee\u6807\uff0c\u4e2d\u7b49\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u4e0a\u68c0\u6d4b\u4e2d\u7b49\u76ee\u6807\uff0c \u5728\u5927\u7279\u5f81\u56fe\u4e0a\u68c0\u6d4b\u5c0f\u76ee\u6807\u3002 backbone & head\u89e3\u8bfb [from, number, module, args] \u53c2\u6570 \u56db\u4e2a\u53c2\u6570\u7684\u610f\u4e49\u5206\u522b\u662f\uff1a 1. \u7b2c\u4e00\u4e2a\u53c2\u6570 from \uff1a\u4ece\u54ea\u4e00\u5c42\u83b7\u5f97\u8f93\u5165\uff0c-1\u8868\u793a\u4ece\u4e0a\u4e00\u5c42\u83b7\u5f97\uff0c[-1, 6]\u8868\u793a\u4ece\u4e0a\u5c42\u548c\u7b2c6\u5c42\u4e24\u5c42\u83b7\u5f97\u3002 2. \u7b2c\u4e8c\u4e2a\u53c2\u6570 number\uff1a\u8868\u793a\u6709\u51e0\u4e2a\u76f8\u540c\u7684\u6a21\u5757\uff0c\u5982\u679c\u4e3a9\u5219\u8868\u793a\u67099\u4e2a\u76f8\u540c\u7684\u6a21\u5757\u3002 3. \u7b2c\u4e09\u4e2a\u53c2\u6570 module\uff1a\u6a21\u5757\u7684\u540d\u79f0\uff0c\u8fd9\u4e9b\u6a21\u5757\u5199\u5728common.py\u4e2d\u3002 4. \u7b2c\u56db\u4e2a\u53c2\u6570 args\uff1a\u7c7b\u7684\u521d\u59cb\u5316\u53c2\u6570\uff0c\u7528\u4e8e\u89e3\u6790\u4f5c\u4e3a moudle \u7684\u4f20\u5165\u53c2\u6570\u3002 \u4e0b\u9762\u4ee5\u7b2c\u4e00\u4e2a\u6a21\u5757Conv \u4e3a\u4f8b\u4ecb\u7ecd\u4e0bcommon.py\u4e2d\u7684\u6a21\u5757 Conv \u6a21\u5757\u5b9a\u4e49\u5982\u4e0b: class Conv ( nn . Module ): # Standard convolution def __init__ ( self , c1 , c2 , k = 1 , s = 1 , p = None , g = 1 , act = True ): # ch_in, ch_out, kernel, stride, padding, groups \"\"\" @Pargm c1: \u8f93\u5165\u901a\u9053\u6570 @Pargm c2: \u8f93\u51fa\u901a\u9053\u6570 @Pargm k : \u5377\u79ef\u6838\u5927\u5c0f(kernel_size) @Pargm s : \u5377\u79ef\u6b65\u957f (stride) @Pargm p : \u7279\u5f81\u56fe\u586b\u5145\u5bbd\u5ea6 (padding) @Pargm g : \u63a7\u5236\u5206\u7ec4\uff0c\u5fc5\u987b\u6574\u9664\u8f93\u5165\u7684\u901a\u9053\u6570(\u4fdd\u8bc1\u8f93\u5165\u7684\u901a\u9053\u80fd\u88ab\u6b63\u786e\u5206\u7ec4) \"\"\" super () . __init__ () # https://oneflow.readthedocs.io/en/master/generated/oneflow.nn.Conv2d.html?highlight=Conv self . conv = nn . Conv2d ( c1 , c2 , k , s , autopad ( k , p ), groups = g , bias = False ) self . bn = nn . BatchNorm2d ( c2 ) self . act = nn . SiLU () if act is True else ( act if isinstance ( act , nn . Module ) else nn . Identity ()) def forward ( self , x ): return self . act ( self . bn ( self . conv ( x ))) def forward_fuse ( self , x ): return self . act ( self . conv ( x )) \u6bd4\u5982\u4e0a\u9762\u628awidth_multiple\u8bbe\u7f6e\u4e3a\u4e860.5\uff0c\u90a3\u4e48\u7b2c\u4e00\u4e2a [64, 6, 2, 2] \u5c31\u4f1a\u88ab\u89e3\u6790\u4e3a [3,64*0.5=32,6,2,2]\uff0c\u5176\u4e2d\u7b2c\u4e00\u4e2a 3 \u4e3a\u8f93\u5165channel(\u56e0\u4e3a\u8f93\u5165)\uff0c32 \u4e3a\u8f93\u51fachannel\u3002 \u5173\u4e8e\u8c03\u6574\u7f51\u7edc\u5927\u5c0f\u7684\u8be6\u89e3\u8bf4\u660e \u5728 yolo.py \u7684 286 \u884c\u6709\u5bf9yaml \u6587\u4ef6\u7684nc,depth_multiple\u7b49\u53c2\u6570\u8bfb\u53d6\uff0c\u5177\u4f53\u4ee3\u7801\u5982\u4e0b: anchors , nc , gd , gw = d [ 'anchors' ], d [ 'nc' ], d [ 'depth_multiple' ], d [ 'width_multiple' ], d . get ( \"activation\" ) \"width_multiple\"\u53c2\u6570\u7684\u4f5c\u7528\u524d\u9762\u4ecb\u7ecdargs\u53c2\u6570\u4e2d\u5df2\u7ecf\u4ecb\u7ecd\u8fc7\u4e86\uff0c\u90a3\u4e48\"depth_multiple\"\u53c8\u662f\u4ec0\u4e48\u4f5c\u7528\u5462\uff1f \u5728 yolo.py \u7684 300 \u884c\u6709\u5bf9\u53c2\u6570\u7684\u5177\u4f53\u5b9a\u4e49\uff1a n = n_ = max ( round ( n * gd ), 1 ) if n > 1 else n # depth gain \u6682\u4e14\u5c06\u8fd9\u6bb5\u4ee3\u7801\u5f53\u4f5c\u516c\u5f0f(1) \u5176\u4e2d gd \u5c31\u662fdepth_multiple\u7684\u503c\uff0cn\u7684\u503c\u5c31\u662fbackbone\u4e2d\u5217\u8868\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\uff1a \u6839\u636e\u516c\u793a(1) \u5f88\u5bb9\u6613\u770b\u51fa gd \u5f71\u54cd n \u7684\u5927\u5c0f\uff0c\u4ece\u800c\u5f71\u54cd\u7f51\u7edc\u7684\u7ed3\u6784\u5927\u5c0f\u3002 \u540e\u9762\u5404\u5c42\u4e4b\u95f4\u7684\u6a21\u5757\u6570\u91cf\u3001\u5377\u79ef\u6838\u5927\u5c0f\u548c\u6570\u91cf\u7b49\u4e5f\u90fd\u4ea7\u751f\u4e86\u53d8\u5316\uff0cYOLOv5l \u4e0e YOLOv5s \u76f8\u6bd4\u8f83\u8d77\u6765\u8bad\u7ec3\u53c2\u6570\u7684\u5927\u5c0f\u6210\u500d\u6570\u589e\u957f\uff0c \u5176\u6a21\u578b\u7684\u6df1\u5ea6\u548c\u5bbd\u5ea6\u4e5f\u4f1a\u5927\u5f88\u591a\uff0c\u8fd9\u5c31\u4f7f\u5f97 YOLOv5l \u7684 \u7cbe\u5ea6\u503c\u8981\u6bd4 YOLOv5s \u597d\u5f88\u591a\uff0c\u56e0\u6b64\u5728\u6700\u7ec8\u63a8\u7406\u65f6\u7684\u68c0\u6d4b\u7cbe\u5ea6\u9ad8\uff0c\u4f46\u662f\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u66f4\u6162\u3002 \u6240\u4ee5 YOLOv5 \u63d0\u4f9b\u4e86\u4e0d\u540c\u7684\u9009\u62e9\uff0c\u5982\u679c\u60f3\u8981\u8ffd\u6c42\u63a8\u7406\u901f\u5ea6\u53ef\u9009\u7528\u8f83\u5c0f\u4e00\u4e9b\u7684\u6a21\u578b\u5982 YOLOv5s\u3001YOLOv5m\uff0c\u5982\u679c\u60f3\u8981\u8ffd\u6c42\u7cbe\u5ea6\u66f4\u9ad8\u5bf9\u63a8\u7406\u901f\u5ea6\u8981\u6c42\u4e0d\u9ad8\u7684\u53ef\u4ee5\u9009\u62e9\u5176\u4ed6\u4e24\u4e2a\u7a0d\u5927\u7684\u6a21\u578b\u3002 \u5982\u4e0b\u9762\u8fd9\u5f20\u56fe\uff1a \u56fe2.1 :yolov5 \u6a21\u578b\u6bd4\u8f83\u56fe \u6765\u6e90:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data Conv\u6a21\u5757\u89e3\u8bfb \u7f51\u7edc\u7ed3\u6784\u9884\u89c8 \u4e0b\u9762\u662f\u6839\u636e yolov5s.yaml \u7ed8\u5236\u7684\u7f51\u7edc\u6574\u4f53\u7ed3\u6784\u7b80\u5316\u7248\u3002 \u56fe2.2 :yolov5s \u7f51\u7edc\u6574\u4f53\u7ed3\u6784 \u8be6\u7ec6\u7684\u7f51\u7edc\u7ed3\u6784\u56fe\uff1ahttps://oneflow-static.oss-cn-beijing.aliyuncs.com/one-yolo/imgs/yolov5s.onnx.png \u901a\u8fc7export.py\u5bfc\u51fa\u7684onnx\u683c\u5f0f\uff0c\u5e76\u901a\u8fc7 https://netron.app/ \u7f51\u7ad9\u5bfc\u51fa\u7684\u56fe\u7247(\u6a21\u578b\u5bfc\u51fa\u5c06\u5728\u672c\u6559\u7a0b\u7684\u540e\u7eed\u6587\u7ae0\u5355\u72ec\u4ecb\u7ecd)\u3002 \u6a21\u5757\u7ec4\u4ef6\u53f3\u8fb9\u53c2\u6570 \u8868\u793a\u7279\u5f81\u56fe\u7684\u7684\u5f62\u72b6\uff0c\u6bd4\u5982 \u5728 \u7b2c \u4e00 \u5c42( Conv )\u8f93\u5165 \u56fe\u7247\u5f62\u72b6\u4e3a [ 3, 640, 640] ,\u5173\u4e8e\u8fd9\u4e9b\u53c2\u6570\uff0c\u53ef\u4ee5\u56fa\u5b9a\u4e00\u5f20\u56fe\u7247\u8f93\u5165\u5230\u7f51\u7edc\u5e76\u901a\u8fc7 yolov5s.yaml \u7684\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\u5f97\u5230\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u5de5\u7a0b models/ yolo.py \u901a\u8fc7\u4ee3\u7801\u8fdb\u884cprint\u67e5\u770b,\u8be6\u7ec6\u6570\u636e\u53ef\u4ee5\u53c2\u8003\u9644\u4ef6\u88682.1\u3002 [1, 128, 80, 80],[1, 256, 40, 40],[1, 512, 20, 20] \u4f5c\u4e3a\u8f93\u5165\u7ecf\u8fc7Detect\u7684forward, \u63a5\u7740flow.cat()\u51fd\u6570\u62fc\u63a5\u6210\u4e3aoutput: [1, 25200, 85]\u3002 yolo.py \u89e3\u8bfb \u6587\u4ef6\u5730\u5740 \u6587\u4ef6\u4e3b\u8981\u5305\u542b \u4e09\u5927\u90e8\u5206 Detect\u7c7b\uff0c Model\u7c7b\uff0c\u548c parse_model \u51fd\u6570 \u53ef\u4ee5\u901a\u8fc7 python models/ yolo.py --cfg yolov5s.yaml \u8fd0\u884c\u8be5\u811a\u672c\u8fdb\u884c\u89c2\u5bdf parse_model\u51fd\u6570\u89e3\u8bfb def parse_model ( d , ch ): # model_dict, input_channels(3) \"\"\"\u7528\u5728\u4e0b\u9762Model\u6a21\u5757\u4e2d \u89e3\u6790\u6a21\u578b\u6587\u4ef6(\u5b57\u5178\u5f62\u5f0f)\uff0c\u5e76\u642d\u5efa\u7f51\u7edc\u7ed3\u6784 \u8fd9\u4e2a\u51fd\u6570\u5176\u5b9e\u4e3b\u8981\u505a\u7684\u5c31\u662f: \u66f4\u65b0\u5f53\u524d\u5c42\u7684args\uff08\u53c2\u6570\uff09,\u8ba1\u7b97c2\uff08\u5f53\u524d\u5c42\u7684\u8f93\u51fachannel\uff09 => \u4f7f\u7528\u5f53\u524d\u5c42\u7684\u53c2\u6570\u642d\u5efa\u5f53\u524d\u5c42 => \u751f\u6210 layers + save @Params d: model_dict \u6a21\u578b\u6587\u4ef6 \u5b57\u5178\u5f62\u5f0f {dict:7} [yolov5s.yaml](https://github.com/Oneflow-Inc/one-yolov5/blob/main/models/yolov5s.yaml)\u4e2d\u76846\u4e2a\u5143\u7d20 + ch #Params ch: \u8bb0\u5f55\u6a21\u578b\u6bcf\u4e00\u5c42\u7684\u8f93\u51fachannel \u521d\u59cbch=[3] \u540e\u9762\u4f1a\u5220\u9664 @return nn.Sequential(*layers): \u7f51\u7edc\u7684\u6bcf\u4e00\u5c42\u7684\u5c42\u7ed3\u6784 @return sorted(save): \u628a\u6240\u6709\u5c42\u7ed3\u6784\u4e2dfrom\u4e0d\u662f-1\u7684\u503c\u8bb0\u4e0b \u5e76\u6392\u5e8f [4, 6, 10, 14, 17, 20, 23] \"\"\" LOGGER . info ( f \" \\n { '' : >3 }{ 'from' : >18 }{ 'n' : >3 }{ 'params' : >10 } { 'module' : <40 }{ 'arguments' : <30 } \" ) # \u8bfb\u53d6d\u5b57\u5178\u4e2d\u7684anchors\u548cparameters(nc\u3001depth_multiple\u3001width_multiple) anchors , nc , gd , gw = d [ 'anchors' ], d [ 'nc' ], d [ 'depth_multiple' ], d [ 'width_multiple' ] # na: number of anchors \u6bcf\u4e00\u4e2apredict head\u4e0a\u7684anchor\u6570 = 3 na = ( len ( anchors [ 0 ]) // 2 ) if isinstance ( anchors , list ) else anchors # number of anchors no = na * ( nc + 5 ) # number of outputs = anchors * (classes + 5) \u6bcf\u4e00\u4e2apredict head\u5c42\u7684\u8f93\u51fachannel # \u5f00\u59cb\u642d\u5efa\u7f51\u7edc # layers: \u4fdd\u5b58\u6bcf\u4e00\u5c42\u7684\u5c42\u7ed3\u6784 # save: \u8bb0\u5f55\u4e0b\u6240\u6709\u5c42\u7ed3\u6784\u4e2dfrom\u4e2d\u4e0d\u662f-1\u7684\u5c42\u7ed3\u6784\u5e8f\u53f7 # c2: \u4fdd\u5b58\u5f53\u524d\u5c42\u7684\u8f93\u51fachannel layers , save , c2 = [], [], ch [ - 1 ] # layers, savelist, ch out # enumerate() \u51fd\u6570\u7528\u4e8e\u5c06\u4e00\u4e2a\u53ef\u904d\u5386\u7684\u6570\u636e\u5bf9\u8c61(\u5982\u5217\u8868\u3001\u5143\u7ec4\u6216\u5b57\u7b26\u4e32)\u7ec4\u5408\u4e3a\u4e00\u4e2a\u7d22\u5f15\u5e8f\u5217\uff0c\u540c\u65f6\u5217\u51fa\u6570\u636e\u548c\u6570\u636e\u4e0b\u6807\uff0c\u4e00\u822c\u7528\u5728 for \u5faa\u73af\u5f53\u4e2d\u3002 for i , ( f , n , m , args ) in enumerate ( d [ 'backbone' ] + d [ 'head' ]): # from, number, module, args m = eval ( m ) if isinstance ( m , str ) else m # eval strings for j , a in enumerate ( args ): # args\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u8fd9\u4e00\u6b65\u628a\u5217\u8868\u4e2d\u7684\u5185\u5bb9\u53d6\u51fa\u6765 with contextlib . suppress ( NameError ): args [ j ] = eval ( a ) if isinstance ( a , str ) else a # eval strings # \u5c06\u6df1\u5ea6\u4e0e\u6df1\u5ea6\u56e0\u5b50\u76f8\u4e58\uff0c\u8ba1\u7b97\u5c42\u6df1\u5ea6\u3002\u6df1\u5ea6\u6700\u5c0f\u4e3a1. n = n_ = max ( round ( n * gd ), 1 ) if n > 1 else n # depth gain # \u5982\u679c\u5f53\u524d\u7684\u6a21\u5757m\u5728\u672c\u9879\u76ee\u5b9a\u4e49\u7684\u6a21\u5757\u7c7b\u578b\u4e2d\uff0c\u5c31\u53ef\u4ee5\u5904\u7406\u8fd9\u4e2a\u6a21\u5757 if m in ( Conv , GhostConv , Bottleneck , GhostBottleneck , SPP , SPPF , DWConv , MixConv2d , Focus , CrossConv , BottleneckCSP , C3 , C3TR , C3SPP , C3Ghost , nn . ConvTranspose2d , DWConvTranspose2d , C3x ): # c1: \u8f93\u5165\u901a\u9053\u6570 c2\uff1a\u8f93\u51fa\u901a\u9053\u6570 c1 , c2 = ch [ f ], args [ 0 ] # \u8be5\u5c42\u4e0d\u662f\u6700\u540e\u4e00\u5c42\uff0c\u5219\u5c06\u901a\u9053\u6570\u4e58\u4ee5\u5bbd\u5ea6\u56e0\u5b50 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5bbd\u5ea6\u56e0\u5b50\u4f5c\u7528\u4e8e\u9664\u4e86\u6700\u540e\u4e00\u5c42\u4e4b\u5916\u7684\u6240\u6709\u5c42 if c2 != no : # if not output # make_divisible\u7684\u4f5c\u7528\uff0c\u4f7f\u5f97\u539f\u59cb\u7684\u901a\u9053\u6570\u4e58\u4ee5\u5bbd\u5ea6\u56e0\u5b50\u4e4b\u540e\u53d6\u6574\u52308\u7684\u500d\u6570\uff0c\u8fd9\u6837\u5904\u7406\u4e00\u822c\u662f\u8ba9\u6a21\u578b\u7684\u5e76\u884c\u6027\u548c\u63a8\u7406\u6027\u80fd\u66f4\u597d\u3002 c2 = make_divisible ( c2 * gw , 8 ) # \u5c06\u524d\u9762\u7684\u8fd0\u7b97\u7ed3\u679c\u4fdd\u5b58\u5728args\u4e2d\uff0c\u5b83\u4e5f\u5c31\u662f\u8fd9\u4e2a\u6a21\u5757\u6700\u7ec8\u7684\u8f93\u5165\u53c2\u6570\u3002 args = [ c1 , c2 , * args [ 1 :]] # \u6839\u636e\u6bcf\u5c42\u7f51\u7edc\u53c2\u6570\u7684\u4e0d\u540c\uff0c\u5206\u522b\u5904\u7406\u53c2\u6570 \u5177\u4f53\u5404\u4e2a\u7c7b\u7684\u53c2\u6570\u662f\u4ec0\u4e48\u8bf7\u53c2\u8003\u5b83\u4eec\u7684__init__\u65b9\u6cd5\u8fd9\u91cc\u4e0d\u518d\u8be6\u7ec6\u89e3\u91ca\u4e86 if m in [ BottleneckCSP , C3 , C3TR , C3Ghost , C3x ]: # \u8fd9\u91cc\u7684\u610f\u601d\u5c31\u662f\u91cd\u590dn\u6b21\uff0c\u6bd4\u5982conv\u8fd9\u4e2a\u6a21\u5757\u91cd\u590dn\u6b21\uff0c\u8fd9\u4e2an \u662f\u4e0a\u9762\u7b97\u51fa\u6765\u7684 depth args . insert ( 2 , n ) # number of repeats n = 1 elif m is nn . BatchNorm2d : args = [ ch [ f ]] elif m is Concat : c2 = sum ( ch [ x ] for x in f ) elif m is Detect : args . append ([ ch [ x ] for x in f ]) if isinstance ( args [ 1 ], int ): # number of anchors args [ 1 ] = [ list ( range ( args [ 1 ] * 2 ))] * len ( f ) elif m is Contract : c2 = ch [ f ] * args [ 0 ] ** 2 elif m is Expand : c2 = ch [ f ] // args [ 0 ] ** 2 else : c2 = ch [ f ] # \u6784\u5efa\u6574\u4e2a\u7f51\u7edc\u6a21\u5757 \u8fd9\u91cc\u5c31\u662f\u6839\u636e\u6a21\u5757\u7684\u91cd\u590d\u6b21\u6570n\u4ee5\u53ca\u6a21\u5757\u672c\u8eab\u548c\u5b83\u7684\u53c2\u6570\u6765\u6784\u5efa\u8fd9\u4e2a\u6a21\u5757\u548c\u53c2\u6570\u5bf9\u5e94\u7684Module m_ = nn . Sequential ( * ( m ( * args ) for _ in range ( n ))) if n > 1 else m ( * args ) # module # \u83b7\u53d6\u6a21\u5757(module type)\u5177\u4f53\u540d\u4f8b\u5982 models.common.Conv , models.common.C3 , models.common.SPPF \u7b49\u3002 t = str ( m )[ 8 : - 2 ] . replace ( '__main__.' , '' ) # replace\u51fd\u6570\u4f5c\u7528\u662f\u5b57\u7b26\u4e32\"__main__\"\u66ff\u6362\u4e3a''\uff0c\u5728\u5f53\u524d\u9879\u76ee\u6ca1\u6709\u7528\u5230\u8fd9\u4e2a\u66ff\u6362\u3002 np = sum ( x . numel () for x in m_ . parameters ()) # number params m_ . i , m_ . f , m_ . type , m_ . np = i , f , t , np # attach index, 'from' index, type, number params LOGGER . info ( f ' { i : >3 }{ str ( f ) : >18 }{ n_ : >3 }{ np : 10.0f } { t : <40 }{ str ( args ) : <30 } ' ) # print \"\"\" \u5982\u679cx\u4e0d\u662f-1\uff0c\u5219\u5c06\u5176\u4fdd\u5b58\u5728save\u5217\u8868\u4e2d\uff0c\u8868\u793a\u8be5\u5c42\u9700\u8981\u4fdd\u5b58\u7279\u5f81\u56fe\u3002 \u8fd9\u91cc x % i \u4e0e x \u7b49\u4ef7\u4f8b\u5982\u5728\u6700\u540e\u4e00\u5c42 : f = [17,20,23] , i = 24 y = [ x % i for x in ([f] if isinstance(f, int) else f) if x != -1 ] print(y) # [17, 20, 23] # \u5199\u6210x % i \u53ef\u80fd\u56e0\u4e3a\uff1ai - 1 = -1 % i (\u6bd4\u5982 f = [-1]\uff0c\u5219 [x % i for x in f] \u4ee3\u8868 [11] ) \"\"\" save . extend ( x % i for x in ([ f ] if isinstance ( f , int ) else f ) if x != - 1 ) # append to savelist layers . append ( m_ ) if i == 0 : # \u5982\u679c\u662f\u521d\u6b21\u8fed\u4ee3\uff0c\u5219\u65b0\u521b\u5efa\u4e00\u4e2ach\uff08\u56e0\u4e3a\u5f62\u53c2ch\u5728\u521b\u5efa\u7b2c\u4e00\u4e2a\u7f51\u7edc\u6a21\u5757\u65f6\u9700\u8981\u7528\u5230\uff0c\u6240\u4ee5\u521b\u5efa\u7f51\u7edc\u6a21\u5757\u4e4b\u540e\u518d\u521d\u59cb\u5316ch\uff09 ch = [] ch . append ( c2 ) # \u5c06\u6240\u6709\u7684\u5c42\u5c01\u88c5\u4e3ann.Sequential , \u5bf9\u4fdd\u5b58\u7684\u7279\u5f81\u56fe\u6392\u5e8f return nn . Sequential ( * layers ), sorted ( save ) Model \u7c7b\u89e3\u8bfb class Model ( nn . Module ): # YOLOv5 model def __init__ ( self , cfg = '[yolov5s.yaml](https://github.com/Oneflow-Inc/one-yolov5/blob/main/models/yolov5s.yaml)' , ch = 3 , nc = None , anchors = None ): # model, input channels, number of classes super () . __init__ () # \u5982\u679ccfg\u5df2\u7ecf\u662f\u5b57\u5178\uff0c\u5219\u76f4\u63a5\u8d4b\u503c\uff0c\u5426\u5219\u5148\u52a0\u8f7dcfg\u8def\u5f84\u7684\u6587\u4ef6\u4e3a\u5b57\u5178\u5e76\u8d4b\u503c\u7ed9self.yaml\u3002 if isinstance ( cfg , dict ): self . yaml = cfg # model dict else : # is *.yaml \u52a0\u8f7dyaml\u6a21\u5757 import yaml # for flow hub self . yaml_file = Path ( cfg ) . name with open ( cfg , encoding = 'ascii' , errors = 'ignore' ) as f : self . yaml = yaml . safe_load ( f ) # model dict \u4eceyaml\u6587\u4ef6\u4e2d\u52a0\u8f7d\u51fa\u5b57\u5178 # Define model # ch: \u8f93\u5165\u901a\u9053\u6570\u3002 \u5047\u5982self.yaml\u6709\u952e\u2018ch\u2019\uff0c\u5219\u5c06\u8be5\u952e\u5bf9\u5e94\u7684\u503c\u8d4b\u7ed9\u5185\u90e8\u53d8\u91cfch\u3002\u5047\u5982\u6ca1\u6709\u2018ch\u2019\uff0c\u5219\u5c06\u5f62\u53c2ch\u8d4b\u7ed9\u5185\u90e8\u53d8\u91cfch ch = self . yaml [ 'ch' ] = self . yaml . get ( 'ch' , ch ) # input channels # \u5047\u5982yaml\u4e2d\u7684nc\u548c\u65b9\u6cd5\u5f62\u53c2\u4e2d\u7684nc\u4e0d\u4e00\u81f4\uff0c\u5219\u8986\u76d6yaml\u4e2d\u7684nc\u3002 if nc and nc != self . yaml [ 'nc' ]: LOGGER . info ( f \"Overriding model.yaml nc= { self . yaml [ 'nc' ] } with nc= { nc } \" ) self . yaml [ 'nc' ] = nc # override yaml value if anchors : # anchors \u5148\u9a8c\u6846\u7684\u914d\u7f6e LOGGER . info ( f 'Overriding model.yaml anchors with anchors= { anchors } ' ) self . yaml [ 'anchors' ] = round ( anchors ) # override yaml value # \u5f97\u5230\u6a21\u578b\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7684\u4fdd\u5b58\u7684\u7279\u5f81\u56fe\u5217\u8868\u3002 self . model , self . save = parse_model ( deepcopy ( self . yaml ), ch = [ ch ]) # model, savelist self . names = [ str ( i ) for i in range ( self . yaml [ 'nc' ])] # default names \u521d\u59cb\u5316\u7c7b\u540d\u5217\u8868\uff0c\u9ed8\u8ba4\u4e3a[0,1,2...] # self.inplace=True \u9ed8\u8ba4True \u8282\u7701\u5185\u5b58 self . inplace = self . yaml . get ( 'inplace' , True ) # Build strides, anchors \u786e\u5b9a\u6b65\u957f\u3001\u6b65\u957f\u5bf9\u5e94\u7684\u951a\u6846 m = self . model [ - 1 ] # Detect() if isinstance ( m , Detect ): # \u68c0\u9a8c\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42\u662fDetect\u6a21\u5757 s = 256 # 2x min stride m . inplace = self . inplace # \u8ba1\u7b97\u4e09\u4e2afeature map\u4e0b\u91c7\u6837\u7684\u500d\u7387 [8, 16, 32] m . stride = flow . tensor ([ s / x . shape [ - 2 ] for x in self . forward ( flow . zeros ( 1 , ch , s , s ))]) # forward # \u68c0\u67e5anchor\u987a\u5e8f\u4e0estride\u987a\u5e8f\u662f\u5426\u4e00\u81f4 anchor\u7684\u987a\u5e8f\u5e94\u8be5\u662f\u4ece\u5c0f\u5230\u5927\uff0c\u8fd9\u91cc\u6392\u4e00\u4e0b\u5e8f check_anchor_order ( m ) # must be in pixel-space (not grid-space) # \u5bf9\u5e94\u7684anchor\u8fdb\u884c\u7f29\u653e\u64cd\u4f5c\uff0c\u539f\u56e0\uff1a\u5f97\u5230anchor\u5728\u5b9e\u9645\u7684\u7279\u5f81\u56fe\u4e2d\u7684\u4f4d\u7f6e\uff0c\u56e0\u4e3a\u52a0\u8f7d\u7684\u539f\u59cbanchor\u5927\u5c0f\u662f\u76f8\u5bf9\u4e8e\u539f\u56fe\u7684\u50cf\u7d20\uff0c\u4f46\u662f\u7ecf\u8fc7\u5377\u79ef\u6c60\u5316\u4e4b\u540e\uff0c\u7279\u5f81\u56fe\u7684\u957f\u5bbd\u53d8\u5c0f\u4e86\u3002 m . anchors /= m . stride . view ( - 1 , 1 , 1 ) self . stride = m . stride self . _initialize_biases () # only run once \u521d\u59cb\u5316\u504f\u7f6e # Init weights, biases # \u8c03\u7528oneflow_utils.py\u4e0binitialize_weights\u521d\u59cb\u5316\u6a21\u578b\u6743\u91cd initialize_weights ( self ) self . info () # \u6253\u5370\u6a21\u578b\u4fe1\u606f LOGGER . info ( '' ) # \u7ba1\u7406\u524d\u5411\u4f20\u64ad\u51fd\u6570 def forward ( self , x , augment = False , profile = False , visualize = False ): if augment : # \u662f\u5426\u5728\u6d4b\u8bd5\u65f6\u4e5f\u4f7f\u7528\u6570\u636e\u589e\u5f3a Test Time Augmentation(TTA) return self . _forward_augment ( x ) # augmented inference, None return self . _forward_once ( x , profile , visualize ) # single-scale inference, train # \u5e26\u6570\u636e\u589e\u5f3a\u7684\u524d\u5411\u4f20\u64ad def _forward_augment ( self , x ): img_size = x . shape [ - 2 :] # height, width s = [ 1 , 0.83 , 0.67 ] # scales f = [ None , 3 , None ] # flips (2-ud, 3-lr) y = [] # outputs for si , fi in zip ( s , f ): xi = scale_img ( x . flip ( fi ) if fi else x , si , gs = int ( self . stride . max ())) yi = self . _forward_once ( xi )[ 0 ] # forward # cv2.imwrite(f'img_{si}.jpg', 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1]) # save yi = self . _descale_pred ( yi , fi , si , img_size ) y . append ( yi ) y = self . _clip_augmented ( y ) # clip augmented tails return flow . cat ( y , 1 ), None # augmented inference, train # \u524d\u5411\u4f20\u64ad\u5177\u4f53\u5b9e\u73b0 def _forward_once ( self , x , profile = False , visualize = False ): \"\"\" @params x: \u8f93\u5165\u56fe\u50cf @params profile: True \u53ef\u4ee5\u505a\u4e00\u4e9b\u6027\u80fd\u8bc4\u4f30 @params feature_vis: True \u53ef\u4ee5\u505a\u4e00\u4e9b\u7279\u5f81\u53ef\u89c6\u5316 \"\"\" # y: \u5b58\u653e\u7740self.save=True\u7684\u6bcf\u4e00\u5c42\u7684\u8f93\u51fa\uff0c\u56e0\u4e3a\u540e\u9762\u7684\u7279\u5f81\u878d\u5408\u64cd\u4f5c\u8981\u7528\u5230\u8fd9\u4e9b\u7279\u5f81\u56fe y , dt = [], [] # outputs # \u524d\u5411\u63a8\u7406\u6bcf\u4e00\u5c42\u7ed3\u6784 m.i=index m.f=from m.type=\u7c7b\u540d m.np=number of params for m in self . model : # if not from previous layer m.f=\u5f53\u524d\u5c42\u7684\u8f93\u5165\u6765\u81ea\u54ea\u4e00\u5c42\u7684\u8f93\u51fa s\u7684m.f\u90fd\u662f-1 if m . f != - 1 : # if not from previous layer x = y [ m . f ] if isinstance ( m . f , int ) else [ x if j == - 1 else y [ j ] for j in m . f ] # from earlier layers if profile : self . _profile_one_layer ( m , x , dt ) x = m ( x ) # run y . append ( x if m . i in self . save else None ) # save output if visualize : feature_visualization ( x , m . type , m . i , save_dir = visualize ) return x # \u5c06\u63a8\u7406\u7ed3\u679c\u6062\u590d\u5230\u539f\u56fe\u56fe\u7247\u5c3a\u5bf8(\u9006\u64cd\u4f5c) def _descale_pred ( self , p , flips , scale , img_size ): # de-scale predictions following augmented inference (inverse operation) \"\"\"\u7528\u5728\u4e0a\u9762\u7684__init__\u51fd\u6570\u4e0a \u5c06\u63a8\u7406\u7ed3\u679c\u6062\u590d\u5230\u539f\u56fe\u56fe\u7247\u5c3a\u5bf8 Test Time Augmentation(TTA)\u4e2d\u7528\u5230 de-scale predictions following augmented inference (inverse operation) @params p: \u63a8\u7406\u7ed3\u679c @params flips: @params scale: @params img_size: \"\"\" if self . inplace : p [ ... , : 4 ] /= scale # de-scale if flips == 2 : p [ ... , 1 ] = img_size [ 0 ] - p [ ... , 1 ] # de-flip ud elif flips == 3 : p [ ... , 0 ] = img_size [ 1 ] - p [ ... , 0 ] # de-flip lr else : x , y , wh = p [ ... , 0 : 1 ] / scale , p [ ... , 1 : 2 ] / scale , p [ ... , 2 : 4 ] / scale # de-scale if flips == 2 : y = img_size [ 0 ] - y # de-flip ud elif flips == 3 : x = img_size [ 1 ] - x # de-flip lr p = flow . cat (( x , y , wh , p [ ... , 4 :]), - 1 ) return p # \u8fd9\u4e2a\u662fTTA\u7684\u65f6\u5019\u5bf9\u539f\u56fe\u7247\u8fdb\u884c\u88c1\u526a\uff0c\u4e5f\u662f\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u5f0f\uff0c\u7528\u5728TTA\u6d4b\u8bd5\u7684\u65f6\u5019\u3002 def _clip_augmented ( self , y ): # Clip YOLOv5 augmented inference tails nl = self . model [ - 1 ] . nl # number of detection layers (P3-P5) g = sum ( 4 ** x for x in range ( nl )) # grid points e = 1 # exclude layer count i = ( y [ 0 ] . shape [ 1 ] // g ) * sum ( 4 ** x for x in range ( e )) # indices y [ 0 ] = y [ 0 ][:, : - i ] # large i = ( y [ - 1 ] . shape [ 1 ] // g ) * sum ( 4 ** ( nl - 1 - x ) for x in range ( e )) # indices y [ - 1 ] = y [ - 1 ][:, i :] # small return y # \u6253\u5370\u65e5\u5fd7\u4fe1\u606f \u524d\u5411\u63a8\u7406\u65f6\u95f4 def _profile_one_layer ( self , m , x , dt ): c = isinstance ( m , Detect ) # is final layer, copy input as inplace fix o = thop . profile ( m , inputs = ( x . copy () if c else x ,), verbose = False )[ 0 ] / 1E9 * 2 if thop else 0 # FLOPs t = time_sync () for _ in range ( 10 ): m ( x . copy () if c else x ) dt . append (( time_sync () - t ) * 100 ) if m == self . model [ 0 ]: LOGGER . info ( f \" { 'time (ms)' : >10s } { 'GFLOPs' : >10s } { 'params' : >10s } module\" ) LOGGER . info ( f ' { dt [ - 1 ] : 10.2f } { o : 10.2f } { m . np : 10.0f } { m . type } ' ) if c : LOGGER . info ( f \" { sum ( dt ) : 10.2f } { '-' : >10s } { '-' : >10s } Total\" ) # initialize biases into Detect(), cf is class frequency def _initialize_biases ( self , cf = None ): # https://arxiv.org/abs/1708.02002 section 3.3 # cf = flow.bincount(flow.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1. m = self . model [ - 1 ] # Detect() module for mi , s in zip ( m . m , m . stride ): # from b = mi . bias . view ( m . na , - 1 ) . detach () # conv.bias(255) to (3,85) b [:, 4 ] += math . log ( 8 / ( 640 / s ) ** 2 ) # obj (8 objects per 640 image) b [:, 5 :] += math . log ( 0.6 / ( m . nc - 0.999999 )) if cf is None else flow . log ( cf / cf . sum ()) # cls mi . bias = flow . nn . Parameter ( b . view ( - 1 ), requires_grad = True ) # \u6253\u5370\u6a21\u578b\u4e2d\u6700\u540eDetect\u5c42\u7684\u504f\u7f6ebiases\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42biases\u4fe1\u606f) def _print_biases ( self ): \"\"\" \u6253\u5370\u6a21\u578b\u4e2d\u6700\u540eDetect\u6a21\u5757\u91cc\u9762\u7684\u5377\u79ef\u5c42\u7684\u504f\u7f6ebiases\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42biases\u4fe1\u606f) \"\"\" m = self . model [ - 1 ] # Detect() module for mi in m . m : # from b = mi . bias . detach () . view ( m . na , - 1 ) . T # conv.bias(255) to (3,85) LOGGER . info ( ( ' %6g Conv2d.bias:' + ' %10.3g ' * 6 ) % ( mi . weight . shape [ 1 ], * b [: 5 ] . mean ( 1 ) . tolist (), b [ 5 :] . mean ())) def _print_weights ( self ): \"\"\" \u6253\u5370\u6a21\u578b\u4e2dBottleneck\u5c42\u7684\u6743\u91cd\u53c2\u6570weights\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42weights\u4fe1\u606f) \"\"\" for m in self . model . modules (): if type ( m ) is Bottleneck : LOGGER . info ( ' %10.3g ' % ( m . w . detach () . sigmoid () * 2 )) # shortcut weights # fuse()\u662f\u7528\u6765\u8fdb\u884cconv\u548cbn\u5c42\u5408\u5e76\uff0c\u4e3a\u4e86\u63d0\u901f\u6a21\u578b\u63a8\u7406\u901f\u5ea6\u3002 def fuse ( self ): # fuse model Conv2d() + BatchNorm2d() layers \"\"\"\u7528\u5728detect.py\u3001val.py fuse model Conv2d() + BatchNorm2d() layers \u8c03\u7528oneflow_utils.py\u4e2d\u7684fuse_conv_and_bn\u51fd\u6570\u548ccommon.py\u4e2dConv\u6a21\u5757\u7684fuseforward\u51fd\u6570 \"\"\" LOGGER . info ( 'Fusing layers... ' ) for m in self . model . modules (): # \u5982\u679c\u5f53\u524d\u5c42\u662f\u5377\u79ef\u5c42Conv\u4e14\u6709bn\u7ed3\u6784, \u90a3\u4e48\u5c31\u8c03\u7528fuse_conv_and_bn\u51fd\u6570\u8bb2conv\u548cbn\u8fdb\u884c\u878d\u5408, \u52a0\u901f\u63a8\u7406 if isinstance ( m , ( Conv , DWConv )) and hasattr ( m , 'bn' ): m . conv = fuse_conv_and_bn ( m . conv , m . bn ) # update conv delattr ( m , 'bn' ) # remove batchnorm \u79fb\u9664bn remove batchnorm m . forward = m . forward_fuse # update forward \u66f4\u65b0\u524d\u5411\u4f20\u64ad update forward (\u53cd\u5411\u4f20\u64ad\u4e0d\u7528\u7ba1, \u56e0\u4e3a\u8fd9\u79cd\u63a8\u7406\u53ea\u7528\u5728\u63a8\u7406\u9636\u6bb5) self . info () # \u6253\u5370conv+bn\u878d\u5408\u540e\u7684\u6a21\u578b\u4fe1\u606f return self # \u6253\u5370\u6a21\u578b\u7ed3\u6784\u4fe1\u606f \u5728\u5f53\u524d\u7c7b__init__\u51fd\u6570\u7ed3\u5c3e\u5904\u6709\u8c03\u7528 def info ( self , verbose = False , img_size = 640 ): # print model information model_info ( self , verbose , img_size ) def _apply ( self , fn ): # Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers self = super () . _apply ( fn ) m = self . model [ - 1 ] # Detect() if isinstance ( m , Detect ): m . stride = fn ( m . stride ) m . grid = list ( map ( fn , m . grid )) if isinstance ( m . anchor_grid , list ): m . anchor_grid = list ( map ( fn , m . anchor_grid )) return self Detect\u7c7b\u89e3\u8bfb class Detect ( nn . Module ): \"\"\" Detect\u6a21\u5757\u662f\u7528\u6765\u6784\u5efaDetect\u5c42\u7684\uff0c\u5c06\u8f93\u5165feature map \u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u64cd\u4f5c\u548c\u516c\u5f0f\u8ba1\u7b97\u5230\u6211\u4eec\u60f3\u8981\u7684shape, \u4e3a\u540e\u9762\u7684\u8ba1\u7b97\u635f\u5931\u6216\u8005NMS\u540e\u5904\u7406\u4f5c\u51c6\u5907 \"\"\" stride = None # strides computed during build onnx_dynamic = False # ONNX export parameter export = False # export mode def __init__ ( self , nc = 80 , anchors = (), ch = (), inplace = True ): # detection layer super () . __init__ () # nc:\u5206\u7c7b\u6570\u91cf self . nc = nc # number of classes COCO : 80 # no:\u6bcf\u4e2aanchor\u7684\u8f93\u51fa\u6570 COCO: 80 + 5 = 85 self . no = nc + 5 # number of outputs per anchor Detect\u7684\u4e2a\u6570 3 # nl:\u9884\u6d4b\u5c42\u6570\uff0c\u6b64\u6b21\u4e3a3 self . nl = len ( anchors ) # number of detection layers # na:anchors\u7684\u6570\u91cf\uff0c\u6b64\u6b21\u4e3a3 self . na = len ( anchors [ 0 ]) // 2 # number of anchors # grid:\u683c\u5b50\u5750\u6807\u7cfb\uff0c\u5de6\u4e0a\u89d2\u4e3a(1,1),\u53f3\u4e0b\u89d2\u4e3a(input.w/stride,input.h/stride) self . grid = [ flow . zeros ( 1 )] * self . nl # init grid self . anchor_grid = [ flow . zeros ( 1 )] * self . nl # init anchor grid # \u5199\u5165\u7f13\u5b58\u4e2d\uff0c\u5e76\u547d\u540d\u4e3aanchors # register_buffer # \u6a21\u578b\u4e2d\u9700\u8981\u4fdd\u5b58\u7684\u53c2\u6570\u4e00\u822c\u6709\u4e24\u79cd\uff1a\u4e00\u79cd\u662f\u53cd\u5411\u4f20\u64ad\u9700\u8981\u88aboptimizer\u66f4\u65b0\u7684\uff0c\u79f0\u4e3aparameter; \u53e6\u4e00\u79cd\u4e0d\u8981\u88ab\u66f4\u65b0\u79f0\u4e3abuffer # buffer\u7684\u53c2\u6570\u66f4\u65b0\u662f\u5728forward\u4e2d\uff0c\u800coptim.step\u53ea\u80fd\u66f4\u65b0nn.parameter\u7c7b\u578b\u7684\u53c2\u6570 self . register_buffer ( 'anchors' , flow . tensor ( anchors ) . float () . view ( self . nl , - 1 , 2 )) # shape(nl,na,2) # \u5c06\u8f93\u51fa\u901a\u8fc7\u5377\u79ef\u5230 self.no * self.na \u7684\u901a\u9053\uff0c\u8fbe\u5230\u5168\u8fde\u63a5\u7684\u4f5c\u7528 self . m = nn . ModuleList ( nn . Conv2d ( x , self . no * self . na , 1 ) for x in ch ) # output conv self . inplace = inplace # use inplace ops (e.g. slice assignment) def forward ( self , x ): z = [] # inference output for i in range ( self . nl ): x [ i ] = self . m [ i ]( x [ i ]) # conv bs , _ , ny , nx = x [ i ] . shape # x(bs,255,20,20) to x(bs,3,20,20,85) x [ i ] = x [ i ] . view ( bs , self . na , self . no , ny , nx ) . permute ( 0 , 1 , 3 , 4 , 2 ) . contiguous () if not self . training : # inference # \u6784\u9020\u7f51\u683c # \u56e0\u4e3a\u63a8\u7406\u8fd4\u56de\u7684\u4e0d\u662f\u5f52\u4e00\u5316\u540e\u7684\u7f51\u683c\u504f\u79fb\u91cf \u9700\u8981\u518d\u52a0\u4e0a\u7f51\u683c\u7684\u4f4d\u7f6e \u5f97\u5230\u6700\u7ec8\u7684\u63a8\u7406\u5750\u6807 \u518d\u9001\u5165nms # \u6240\u4ee5\u8fd9\u91cc\u6784\u5efa\u7f51\u683c\u5c31\u662f\u4e3a\u4e86\u8bb0\u5f55\u6bcf\u4e2agrid\u7684\u7f51\u683c\u5750\u6807 \u65b9\u9762\u540e\u9762\u4f7f\u7528 if self . onnx_dynamic or self . grid [ i ] . shape [ 2 : 4 ] != x [ i ] . shape [ 2 : 4 ]: # \u5411\u524d\u4f20\u64ad\u65f6\u9700\u8981\u5c06\u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u5230grid\u7edd\u5bf9\u5750\u6807\u7cfb\u4e2d self . grid [ i ], self . anchor_grid [ i ] = self . _make_grid ( nx , ny , i ) y = x [ i ] . sigmoid () if self . inplace : # \u9ed8\u8ba4\u6267\u884c \u4e0d\u4f7f\u7528AWS Inferentia # \u8fd9\u91cc\u7684\u516c\u5f0f\u548cyolov3\u3001v4\u4e2d\u4f7f\u7528\u7684\u4e0d\u4e00\u6837 \u662fyolov5\u4f5c\u8005\u81ea\u5df1\u7528\u7684 \u6548\u679c\u66f4\u597d y [ ... , 0 : 2 ] = ( y [ ... , 0 : 2 ] * 2 + self . grid [ i ]) * self . stride [ i ] # xy y [ ... , 2 : 4 ] = ( y [ ... , 2 : 4 ] * 2 ) ** 2 * self . anchor_grid [ i ] # wh else : # for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953 xy , wh , conf = y . split (( 2 , 2 , self . nc + 1 ), 4 ) # y.tensor_split((2, 4, 5), 4) xy = ( xy * 2 + self . grid [ i ]) * self . stride [ i ] # xy wh = ( wh * 2 ) ** 2 * self . anchor_grid [ i ] # wh y = flow . cat (( xy , wh , conf ), 4 ) # z [oneflow.Size([1, 19200, 85]) oneflow.Size([1, 4800, 85]) oneflow.Size([1, 1200, 85])] z . append ( y . view ( bs , - 1 , self . no )) return x if self . training else ( flow . cat ( z , 1 ),) if self . export else ( flow . cat ( z , 1 ), x ) # \u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u5230grid\u7edd\u5bf9\u5750\u6807\u7cfb def _make_grid ( self , nx = 20 , ny = 20 , i = 0 ): d = self . anchors [ i ] . device t = self . anchors [ i ] . dtype shape = 1 , self . na , ny , nx , 2 # grid shape y , x = flow . arange ( ny , device = d , dtype = t ), flow . arange ( nx , device = d , dtype = t ) yv , xv = flow . meshgrid ( y , x , indexing = \"ij\" ) grid = flow . stack (( xv , yv ), 2 ) . expand ( shape ) - 0.5 # add grid offset, i.e. y = 2.0 * x - 0.5 anchor_grid = ( self . anchors [ i ] * self . stride [ i ]) . view (( 1 , self . na , 1 , 1 , 2 )) . expand ( shape ) return grid , anchor_grid \u9644\u4ef6 \u88682.1 yolov5s.yaml \u89e3\u6790\u8868 \u5c42\u6570 form moudule arguments input output 0 -1 Conv [3, 32, 6, 2, 2] [3, 640, 640] [32, 320, 320] 1 -1 Conv [32, 64, 3, 2] [32, 320, 320] [64, 160, 160] 2 -1 C3 [64, 64, 1] [64, 160, 160] [64, 160, 160] 3 -1 Conv [64, 128, 3, 2] [64, 160, 160] [128, 80, 80] 4 -1 C3 [128, 128, 2] [128, 80, 80] [128, 80, 80] 5 -1 Conv [128, 256, 3, 2] [128, 80, 80] [256, 40, 40] 6 -1 C3 [256, 256, 3] [256, 40, 40] [256, 40, 40] 7 -1 Conv [256, 512, 3, 2] [256, 40, 40] [512, 20, 20] 8 -1 C3 [512, 512, 1] [512, 20, 20] [512, 20, 20] 9 -1 SPPF [512, 512, 5] [512, 20, 20] [512, 20, 20] 10 -1 Conv [512, 256, 1, 1] [512, 20, 20] [256, 20, 20] 11 -1 Upsample [None, 2, 'nearest'] [256, 20, 20] [256, 40, 40] 12 [-1, 6] Concat [1] [1, 256, 40, 40],[1, 256, 40, 40] [512, 40, 40] 13 -1 C3 [512, 256, 1, False] [512, 40, 40] [256, 40, 40] 14 -1 Conv [256, 128, 1, 1] [256, 40, 40] [128, 40, 40] 15 -1 Upsample [None, 2, 'nearest'] [128, 40, 40] [128, 80, 80] 16 [-1, 4] Concat [1] [1, 128, 80, 80],[1, 128, 80, 80] [256, 80, 80] 17 -1 C3 [256, 128, 1, False] [256, 80, 80] [128, 80, 80] 18 -1 Conv [128, 128, 3, 2] [128, 80, 80] [128, 40, 40] 19 [-1, 14] Concat [1] [1, 128, 40, 40],[1, 128, 40, 40] [256, 40, 40] 20 -1 C3 [256, 256, 1, False] [256, 40, 40] [256, 40, 40] 21 -1 Conv [256, 256, 3, 2] [256, 40, 40] [256, 20, 20] 22 [-1, 10] Concat [1] [1, 256, 20, 20],[1, 256, 20, 20] [512, 20, 20] 23 -1 C3 [512, 512, 1, False] [512, 20, 20] [512, 20, 20] 24 [17, 20, 23] Detect [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]] [1, 128, 80, 80],[1, 256, 40, 40],[1, 512, 20, 20] [1, 3, 80, 80, 85],[1, 3, 40, 40, 85],[1, 3, 20, 20, 85] \u53c2\u8003\u6587\u7ae0: https://zhuanlan.zhihu.com/p/436891962?ivk_sa=1025922q https://zhuanlan.zhihu.com/p/110204563 https://www.it610.com/article/1550621248474648576.htm","title":"1.1. YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"\u524d\u8a00"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#yolov5","text":"","title":"YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_2","text":"YOLOv5\u9488\u5bf9\u4e0d\u540c\u5927\u5c0f\uff08n, s, m, l, x\uff09\u7684\u7f51\u7edc\u6574\u4f53\u67b6\u6784\u90fd\u662f\u4e00\u6837\u7684\uff0c\u53ea\u4e0d\u8fc7\u4f1a\u5728\u6bcf\u4e2a\u5b50\u6a21\u5757\u4e2d\u91c7\u7528\u4e0d\u540c\u7684\u6df1\u5ea6\u548c\u5bbd\u5ea6\uff0c \u5206\u522b\u5e94\u5bf9yaml\u6587\u4ef6\u4e2d\u7684depth_multiple\u548cwidth_multiple\u53c2\u6570\u3002 \u8fd8\u9700\u8981\u6ce8\u610f\u4e00\u70b9\uff0c\u5b98\u65b9\u9664\u4e86n, s, m, l, x\u7248\u672c\u5916\u8fd8\u6709n6, s6, m6, l6, x6\uff0c\u533a\u522b\u5728\u4e8e\u540e\u8005\u662f\u9488\u5bf9\u66f4\u5927\u5206\u8fa8\u7387\u7684\u56fe\u7247\u6bd4\u59821280x1280, \u5f53\u7136\u7ed3\u6784\u4e0a\u4e5f\u6709\u4e9b\u5dee\u5f02\uff0c\u524d\u8005\u53ea\u4f1a\u4e0b\u91c7\u6837\u523032\u500d\u4e14\u91c7\u75283\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42 , \u800c\u540e\u8005\u4f1a\u4e0b\u91c7\u683764\u500d\uff0c\u91c7\u75284\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u3002 \u672c\u7ae0\u5c06\u4ee5 yolov5s\u4e3a\u4f8b \uff0c\u4ece\u914d\u7f6e\u6587\u4ef6 models/ yolov5s.yaml \u5230 models/ yolo.py \u6e90\u7801\u8fdb\u884c\u89e3\u8bfb\u3002","title":"\u5f15\u8a00"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#yolov5syaml","text":"nc : 80 # number of classes \u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u6570 depth_multiple : 0.33 # model depth multiple \u6a21\u578b\u5c42\u6570\u56e0\u5b50(\u7528\u6765\u8c03\u6574\u7f51\u7edc\u7684\u6df1\u5ea6) width_multiple : 0.50 # layer channel multiple \u6a21\u578b\u901a\u9053\u6570\u56e0\u5b50(\u7528\u6765\u8c03\u6574\u7f51\u7edc\u7684\u5bbd\u5ea6) # \u5982\u4f55\u7406\u89e3\u8fd9\u4e2adepth_multiple\u548cwidth_multiple\u5462? # \u5b83\u51b3\u5b9a\u7684\u662f\u6574\u4e2a\u6a21\u578b\u4e2d\u7684\u6df1\u5ea6\uff08\u5c42\u6570\uff09\u548c\u5bbd\u5ea6\uff08\u901a\u9053\u6570\uff09,\u5177\u4f53\u600e\u4e48\u8c03\u6574\u7684\u7ed3\u5408\u540e\u9762\u7684backbone\u4ee3\u7801\u89e3\u91ca\u3002 anchors : # \u8868\u793a\u4f5c\u7528\u4e8e\u5f53\u524d\u7279\u5f81\u56fe\u7684Anchor\u5927\u5c0f\u4e3a xxx # 9\u4e2aanchor\uff0c\u5176\u4e2dP\u8868\u793a\u7279\u5f81\u56fe\u7684\u5c42\u7ea7\uff0cP3/8\u8be5\u5c42\u7279\u5f81\u56fe\u7f29\u653e\u4e3a1/8,\u662f\u7b2c3\u5c42\u7279\u5f81 - [ 10 , 13 , 16 , 30 , 33 , 23 ] # P3/8\uff0c \u8868\u793a[10,13],[16,30], [33,23]3\u4e2aanchor - [ 30 , 61 , 62 , 45 , 59 , 119 ] # P4/16 - [ 116 , 90 , 156 , 198 , 373 , 326 ] # P5/32 # YOLOv5s v6.0 backbone backbone : # [from, number, module, args] [[ -1 , 1 , Conv , [ 64 , 6 , 2 , 2 ]], # 0-P1/2 [ -1 , 1 , Conv , [ 128 , 3 , 2 ]], # 1-P2/4 [ -1 , 3 , C3 , [ 128 ]], [ -1 , 1 , Conv , [ 256 , 3 , 2 ]], # 3-P3/8 [ -1 , 6 , C3 , [ 256 ]], [ -1 , 1 , Conv , [ 512 , 3 , 2 ]], # 5-P4/16 [ -1 , 9 , C3 , [ 512 ]], [ -1 , 1 , Conv , [ 1024 , 3 , 2 ]], # 7-P5/32 [ -1 , 3 , C3 , [ 1024 ]], [ -1 , 1 , SPPF , [ 1024 , 5 ]], # 9 ] # YOLOv5s v6.0 head head : [[ -1 , 1 , Conv , [ 512 , 1 , 1 ]], [ -1 , 1 , nn.Upsample , [ None , 2 , 'nearest' ]], [[ -1 , 6 ], 1 , Concat , [ 1 ]], # cat backbone P4 [ -1 , 3 , C3 , [ 512 , False ]], # 13 [ -1 , 1 , Conv , [ 256 , 1 , 1 ]], [ -1 , 1 , nn.Upsample , [ None , 2 , 'nearest' ]], [[ -1 , 4 ], 1 , Concat , [ 1 ]], # cat backbone P3 [ -1 , 3 , C3 , [ 256 , False ]], # 17 (P3/8-small) [ -1 , 1 , Conv , [ 256 , 3 , 2 ]], [[ -1 , 14 ], 1 , Concat , [ 1 ]], # cat head P4 [ -1 , 3 , C3 , [ 512 , False ]], # 20 (P4/16-medium) [ -1 , 1 , Conv , [ 512 , 3 , 2 ]], [[ -1 , 10 ], 1 , Concat , [ 1 ]], # cat head P5 [ -1 , 3 , C3 , [ 1024 , False ]], # 23 (P5/32-large) [[ 17 , 20 , 23 ], 1 , Detect , [ nc , anchors ]], # Detect(P3, P4, P5) ]","title":"yolov5s.yaml\u6587\u4ef6\u5185\u5bb9:"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#anchors","text":"yolov5 \u521d\u59cb\u5316\u4e86 9 \u4e2a anchors\uff0c\u5206\u522b\u5728\u4e09\u4e2a\u7279\u5f81\u56fe \uff08feature map\uff09\u4e2d\u4f7f\u7528\uff0c\u6bcf\u4e2a feature map \u7684\u6bcf\u4e2a grid cell \u90fd\u6709\u4e09\u4e2a anchor \u8fdb\u884c\u9884\u6d4b\u3002 \u5206\u914d\u89c4\u5219\uff1a \u5c3a\u5ea6\u8d8a\u5927\u7684 feature map \u8d8a\u9760\u524d\uff0c\u76f8\u5bf9\u539f\u56fe\u7684\u4e0b\u91c7\u6837\u7387\u8d8a\u5c0f\uff0c\u611f\u53d7\u91ce\u8d8a\u5c0f\uff0c \u6240\u4ee5\u76f8\u5bf9\u53ef\u4ee5\u9884\u6d4b\u4e00\u4e9b\u5c3a\u5ea6\u6bd4\u8f83\u5c0f\u7684\u7269\u4f53(\u5c0f\u76ee\u6807)\uff0c\u5206\u914d\u5230\u7684 anchors \u8d8a\u5c0f\u3002 \u5c3a\u5ea6\u8d8a\u5c0f\u7684 feature map \u8d8a\u9760\u540e\uff0c\u76f8\u5bf9\u539f\u56fe\u7684\u4e0b\u91c7\u6837\u7387\u8d8a\u5927\uff0c\u611f\u53d7\u91ce\u8d8a\u5927\uff0c \u6240\u4ee5\u53ef\u4ee5\u9884\u6d4b\u4e00\u4e9b\u5c3a\u5ea6\u6bd4\u8f83\u5927\u7684\u7269\u4f53(\u5927\u76ee\u6807)\uff0c\u6240\u4ee5\u5206\u914d\u5230\u7684 anchors \u8d8a\u5927\u3002 \u5373\u5728\u5c0f\u7279\u5f81\u56fe\uff08feature map\uff09\u4e0a\u68c0\u6d4b\u5927\u76ee\u6807\uff0c\u4e2d\u7b49\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u4e0a\u68c0\u6d4b\u4e2d\u7b49\u76ee\u6807\uff0c \u5728\u5927\u7279\u5f81\u56fe\u4e0a\u68c0\u6d4b\u5c0f\u76ee\u6807\u3002","title":"anchors \u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#backbone-head","text":"","title":"backbone &amp; head\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#from-number-module-args","text":"\u56db\u4e2a\u53c2\u6570\u7684\u610f\u4e49\u5206\u522b\u662f\uff1a 1. \u7b2c\u4e00\u4e2a\u53c2\u6570 from \uff1a\u4ece\u54ea\u4e00\u5c42\u83b7\u5f97\u8f93\u5165\uff0c-1\u8868\u793a\u4ece\u4e0a\u4e00\u5c42\u83b7\u5f97\uff0c[-1, 6]\u8868\u793a\u4ece\u4e0a\u5c42\u548c\u7b2c6\u5c42\u4e24\u5c42\u83b7\u5f97\u3002 2. \u7b2c\u4e8c\u4e2a\u53c2\u6570 number\uff1a\u8868\u793a\u6709\u51e0\u4e2a\u76f8\u540c\u7684\u6a21\u5757\uff0c\u5982\u679c\u4e3a9\u5219\u8868\u793a\u67099\u4e2a\u76f8\u540c\u7684\u6a21\u5757\u3002 3. \u7b2c\u4e09\u4e2a\u53c2\u6570 module\uff1a\u6a21\u5757\u7684\u540d\u79f0\uff0c\u8fd9\u4e9b\u6a21\u5757\u5199\u5728common.py\u4e2d\u3002 4. \u7b2c\u56db\u4e2a\u53c2\u6570 args\uff1a\u7c7b\u7684\u521d\u59cb\u5316\u53c2\u6570\uff0c\u7528\u4e8e\u89e3\u6790\u4f5c\u4e3a moudle \u7684\u4f20\u5165\u53c2\u6570\u3002 \u4e0b\u9762\u4ee5\u7b2c\u4e00\u4e2a\u6a21\u5757Conv \u4e3a\u4f8b\u4ecb\u7ecd\u4e0bcommon.py\u4e2d\u7684\u6a21\u5757 Conv \u6a21\u5757\u5b9a\u4e49\u5982\u4e0b: class Conv ( nn . Module ): # Standard convolution def __init__ ( self , c1 , c2 , k = 1 , s = 1 , p = None , g = 1 , act = True ): # ch_in, ch_out, kernel, stride, padding, groups \"\"\" @Pargm c1: \u8f93\u5165\u901a\u9053\u6570 @Pargm c2: \u8f93\u51fa\u901a\u9053\u6570 @Pargm k : \u5377\u79ef\u6838\u5927\u5c0f(kernel_size) @Pargm s : \u5377\u79ef\u6b65\u957f (stride) @Pargm p : \u7279\u5f81\u56fe\u586b\u5145\u5bbd\u5ea6 (padding) @Pargm g : \u63a7\u5236\u5206\u7ec4\uff0c\u5fc5\u987b\u6574\u9664\u8f93\u5165\u7684\u901a\u9053\u6570(\u4fdd\u8bc1\u8f93\u5165\u7684\u901a\u9053\u80fd\u88ab\u6b63\u786e\u5206\u7ec4) \"\"\" super () . __init__ () # https://oneflow.readthedocs.io/en/master/generated/oneflow.nn.Conv2d.html?highlight=Conv self . conv = nn . Conv2d ( c1 , c2 , k , s , autopad ( k , p ), groups = g , bias = False ) self . bn = nn . BatchNorm2d ( c2 ) self . act = nn . SiLU () if act is True else ( act if isinstance ( act , nn . Module ) else nn . Identity ()) def forward ( self , x ): return self . act ( self . bn ( self . conv ( x ))) def forward_fuse ( self , x ): return self . act ( self . conv ( x )) \u6bd4\u5982\u4e0a\u9762\u628awidth_multiple\u8bbe\u7f6e\u4e3a\u4e860.5\uff0c\u90a3\u4e48\u7b2c\u4e00\u4e2a [64, 6, 2, 2] \u5c31\u4f1a\u88ab\u89e3\u6790\u4e3a [3,64*0.5=32,6,2,2]\uff0c\u5176\u4e2d\u7b2c\u4e00\u4e2a 3 \u4e3a\u8f93\u5165channel(\u56e0\u4e3a\u8f93\u5165)\uff0c32 \u4e3a\u8f93\u51fachannel\u3002","title":"[from, number, module, args] \u53c2\u6570"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_3","text":"\u5728 yolo.py \u7684 286 \u884c\u6709\u5bf9yaml \u6587\u4ef6\u7684nc,depth_multiple\u7b49\u53c2\u6570\u8bfb\u53d6\uff0c\u5177\u4f53\u4ee3\u7801\u5982\u4e0b: anchors , nc , gd , gw = d [ 'anchors' ], d [ 'nc' ], d [ 'depth_multiple' ], d [ 'width_multiple' ], d . get ( \"activation\" ) \"width_multiple\"\u53c2\u6570\u7684\u4f5c\u7528\u524d\u9762\u4ecb\u7ecdargs\u53c2\u6570\u4e2d\u5df2\u7ecf\u4ecb\u7ecd\u8fc7\u4e86\uff0c\u90a3\u4e48\"depth_multiple\"\u53c8\u662f\u4ec0\u4e48\u4f5c\u7528\u5462\uff1f \u5728 yolo.py \u7684 300 \u884c\u6709\u5bf9\u53c2\u6570\u7684\u5177\u4f53\u5b9a\u4e49\uff1a n = n_ = max ( round ( n * gd ), 1 ) if n > 1 else n # depth gain \u6682\u4e14\u5c06\u8fd9\u6bb5\u4ee3\u7801\u5f53\u4f5c\u516c\u5f0f(1) \u5176\u4e2d gd \u5c31\u662fdepth_multiple\u7684\u503c\uff0cn\u7684\u503c\u5c31\u662fbackbone\u4e2d\u5217\u8868\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\uff1a \u6839\u636e\u516c\u793a(1) \u5f88\u5bb9\u6613\u770b\u51fa gd \u5f71\u54cd n \u7684\u5927\u5c0f\uff0c\u4ece\u800c\u5f71\u54cd\u7f51\u7edc\u7684\u7ed3\u6784\u5927\u5c0f\u3002 \u540e\u9762\u5404\u5c42\u4e4b\u95f4\u7684\u6a21\u5757\u6570\u91cf\u3001\u5377\u79ef\u6838\u5927\u5c0f\u548c\u6570\u91cf\u7b49\u4e5f\u90fd\u4ea7\u751f\u4e86\u53d8\u5316\uff0cYOLOv5l \u4e0e YOLOv5s \u76f8\u6bd4\u8f83\u8d77\u6765\u8bad\u7ec3\u53c2\u6570\u7684\u5927\u5c0f\u6210\u500d\u6570\u589e\u957f\uff0c \u5176\u6a21\u578b\u7684\u6df1\u5ea6\u548c\u5bbd\u5ea6\u4e5f\u4f1a\u5927\u5f88\u591a\uff0c\u8fd9\u5c31\u4f7f\u5f97 YOLOv5l \u7684 \u7cbe\u5ea6\u503c\u8981\u6bd4 YOLOv5s \u597d\u5f88\u591a\uff0c\u56e0\u6b64\u5728\u6700\u7ec8\u63a8\u7406\u65f6\u7684\u68c0\u6d4b\u7cbe\u5ea6\u9ad8\uff0c\u4f46\u662f\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u66f4\u6162\u3002 \u6240\u4ee5 YOLOv5 \u63d0\u4f9b\u4e86\u4e0d\u540c\u7684\u9009\u62e9\uff0c\u5982\u679c\u60f3\u8981\u8ffd\u6c42\u63a8\u7406\u901f\u5ea6\u53ef\u9009\u7528\u8f83\u5c0f\u4e00\u4e9b\u7684\u6a21\u578b\u5982 YOLOv5s\u3001YOLOv5m\uff0c\u5982\u679c\u60f3\u8981\u8ffd\u6c42\u7cbe\u5ea6\u66f4\u9ad8\u5bf9\u63a8\u7406\u901f\u5ea6\u8981\u6c42\u4e0d\u9ad8\u7684\u53ef\u4ee5\u9009\u62e9\u5176\u4ed6\u4e24\u4e2a\u7a0d\u5927\u7684\u6a21\u578b\u3002 \u5982\u4e0b\u9762\u8fd9\u5f20\u56fe\uff1a \u56fe2.1 :yolov5 \u6a21\u578b\u6bd4\u8f83\u56fe \u6765\u6e90:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data","title":"\u5173\u4e8e\u8c03\u6574\u7f51\u7edc\u5927\u5c0f\u7684\u8be6\u89e3\u8bf4\u660e"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#conv","text":"","title":"Conv\u6a21\u5757\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_4","text":"\u4e0b\u9762\u662f\u6839\u636e yolov5s.yaml \u7ed8\u5236\u7684\u7f51\u7edc\u6574\u4f53\u7ed3\u6784\u7b80\u5316\u7248\u3002 \u56fe2.2 :yolov5s \u7f51\u7edc\u6574\u4f53\u7ed3\u6784 \u8be6\u7ec6\u7684\u7f51\u7edc\u7ed3\u6784\u56fe\uff1ahttps://oneflow-static.oss-cn-beijing.aliyuncs.com/one-yolo/imgs/yolov5s.onnx.png \u901a\u8fc7export.py\u5bfc\u51fa\u7684onnx\u683c\u5f0f\uff0c\u5e76\u901a\u8fc7 https://netron.app/ \u7f51\u7ad9\u5bfc\u51fa\u7684\u56fe\u7247(\u6a21\u578b\u5bfc\u51fa\u5c06\u5728\u672c\u6559\u7a0b\u7684\u540e\u7eed\u6587\u7ae0\u5355\u72ec\u4ecb\u7ecd)\u3002 \u6a21\u5757\u7ec4\u4ef6\u53f3\u8fb9\u53c2\u6570 \u8868\u793a\u7279\u5f81\u56fe\u7684\u7684\u5f62\u72b6\uff0c\u6bd4\u5982 \u5728 \u7b2c \u4e00 \u5c42( Conv )\u8f93\u5165 \u56fe\u7247\u5f62\u72b6\u4e3a [ 3, 640, 640] ,\u5173\u4e8e\u8fd9\u4e9b\u53c2\u6570\uff0c\u53ef\u4ee5\u56fa\u5b9a\u4e00\u5f20\u56fe\u7247\u8f93\u5165\u5230\u7f51\u7edc\u5e76\u901a\u8fc7 yolov5s.yaml \u7684\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\u5f97\u5230\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u5de5\u7a0b models/ yolo.py \u901a\u8fc7\u4ee3\u7801\u8fdb\u884cprint\u67e5\u770b,\u8be6\u7ec6\u6570\u636e\u53ef\u4ee5\u53c2\u8003\u9644\u4ef6\u88682.1\u3002 [1, 128, 80, 80],[1, 256, 40, 40],[1, 512, 20, 20] \u4f5c\u4e3a\u8f93\u5165\u7ecf\u8fc7Detect\u7684forward, \u63a5\u7740flow.cat()\u51fd\u6570\u62fc\u63a5\u6210\u4e3aoutput: [1, 25200, 85]\u3002","title":"\u7f51\u7edc\u7ed3\u6784\u9884\u89c8"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#yolopy","text":"\u6587\u4ef6\u5730\u5740 \u6587\u4ef6\u4e3b\u8981\u5305\u542b \u4e09\u5927\u90e8\u5206 Detect\u7c7b\uff0c Model\u7c7b\uff0c\u548c parse_model \u51fd\u6570 \u53ef\u4ee5\u901a\u8fc7 python models/ yolo.py --cfg yolov5s.yaml \u8fd0\u884c\u8be5\u811a\u672c\u8fdb\u884c\u89c2\u5bdf","title":"yolo.py \u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#parse_model","text":"def parse_model ( d , ch ): # model_dict, input_channels(3) \"\"\"\u7528\u5728\u4e0b\u9762Model\u6a21\u5757\u4e2d \u89e3\u6790\u6a21\u578b\u6587\u4ef6(\u5b57\u5178\u5f62\u5f0f)\uff0c\u5e76\u642d\u5efa\u7f51\u7edc\u7ed3\u6784 \u8fd9\u4e2a\u51fd\u6570\u5176\u5b9e\u4e3b\u8981\u505a\u7684\u5c31\u662f: \u66f4\u65b0\u5f53\u524d\u5c42\u7684args\uff08\u53c2\u6570\uff09,\u8ba1\u7b97c2\uff08\u5f53\u524d\u5c42\u7684\u8f93\u51fachannel\uff09 => \u4f7f\u7528\u5f53\u524d\u5c42\u7684\u53c2\u6570\u642d\u5efa\u5f53\u524d\u5c42 => \u751f\u6210 layers + save @Params d: model_dict \u6a21\u578b\u6587\u4ef6 \u5b57\u5178\u5f62\u5f0f {dict:7} [yolov5s.yaml](https://github.com/Oneflow-Inc/one-yolov5/blob/main/models/yolov5s.yaml)\u4e2d\u76846\u4e2a\u5143\u7d20 + ch #Params ch: \u8bb0\u5f55\u6a21\u578b\u6bcf\u4e00\u5c42\u7684\u8f93\u51fachannel \u521d\u59cbch=[3] \u540e\u9762\u4f1a\u5220\u9664 @return nn.Sequential(*layers): \u7f51\u7edc\u7684\u6bcf\u4e00\u5c42\u7684\u5c42\u7ed3\u6784 @return sorted(save): \u628a\u6240\u6709\u5c42\u7ed3\u6784\u4e2dfrom\u4e0d\u662f-1\u7684\u503c\u8bb0\u4e0b \u5e76\u6392\u5e8f [4, 6, 10, 14, 17, 20, 23] \"\"\" LOGGER . info ( f \" \\n { '' : >3 }{ 'from' : >18 }{ 'n' : >3 }{ 'params' : >10 } { 'module' : <40 }{ 'arguments' : <30 } \" ) # \u8bfb\u53d6d\u5b57\u5178\u4e2d\u7684anchors\u548cparameters(nc\u3001depth_multiple\u3001width_multiple) anchors , nc , gd , gw = d [ 'anchors' ], d [ 'nc' ], d [ 'depth_multiple' ], d [ 'width_multiple' ] # na: number of anchors \u6bcf\u4e00\u4e2apredict head\u4e0a\u7684anchor\u6570 = 3 na = ( len ( anchors [ 0 ]) // 2 ) if isinstance ( anchors , list ) else anchors # number of anchors no = na * ( nc + 5 ) # number of outputs = anchors * (classes + 5) \u6bcf\u4e00\u4e2apredict head\u5c42\u7684\u8f93\u51fachannel # \u5f00\u59cb\u642d\u5efa\u7f51\u7edc # layers: \u4fdd\u5b58\u6bcf\u4e00\u5c42\u7684\u5c42\u7ed3\u6784 # save: \u8bb0\u5f55\u4e0b\u6240\u6709\u5c42\u7ed3\u6784\u4e2dfrom\u4e2d\u4e0d\u662f-1\u7684\u5c42\u7ed3\u6784\u5e8f\u53f7 # c2: \u4fdd\u5b58\u5f53\u524d\u5c42\u7684\u8f93\u51fachannel layers , save , c2 = [], [], ch [ - 1 ] # layers, savelist, ch out # enumerate() \u51fd\u6570\u7528\u4e8e\u5c06\u4e00\u4e2a\u53ef\u904d\u5386\u7684\u6570\u636e\u5bf9\u8c61(\u5982\u5217\u8868\u3001\u5143\u7ec4\u6216\u5b57\u7b26\u4e32)\u7ec4\u5408\u4e3a\u4e00\u4e2a\u7d22\u5f15\u5e8f\u5217\uff0c\u540c\u65f6\u5217\u51fa\u6570\u636e\u548c\u6570\u636e\u4e0b\u6807\uff0c\u4e00\u822c\u7528\u5728 for \u5faa\u73af\u5f53\u4e2d\u3002 for i , ( f , n , m , args ) in enumerate ( d [ 'backbone' ] + d [ 'head' ]): # from, number, module, args m = eval ( m ) if isinstance ( m , str ) else m # eval strings for j , a in enumerate ( args ): # args\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u8fd9\u4e00\u6b65\u628a\u5217\u8868\u4e2d\u7684\u5185\u5bb9\u53d6\u51fa\u6765 with contextlib . suppress ( NameError ): args [ j ] = eval ( a ) if isinstance ( a , str ) else a # eval strings # \u5c06\u6df1\u5ea6\u4e0e\u6df1\u5ea6\u56e0\u5b50\u76f8\u4e58\uff0c\u8ba1\u7b97\u5c42\u6df1\u5ea6\u3002\u6df1\u5ea6\u6700\u5c0f\u4e3a1. n = n_ = max ( round ( n * gd ), 1 ) if n > 1 else n # depth gain # \u5982\u679c\u5f53\u524d\u7684\u6a21\u5757m\u5728\u672c\u9879\u76ee\u5b9a\u4e49\u7684\u6a21\u5757\u7c7b\u578b\u4e2d\uff0c\u5c31\u53ef\u4ee5\u5904\u7406\u8fd9\u4e2a\u6a21\u5757 if m in ( Conv , GhostConv , Bottleneck , GhostBottleneck , SPP , SPPF , DWConv , MixConv2d , Focus , CrossConv , BottleneckCSP , C3 , C3TR , C3SPP , C3Ghost , nn . ConvTranspose2d , DWConvTranspose2d , C3x ): # c1: \u8f93\u5165\u901a\u9053\u6570 c2\uff1a\u8f93\u51fa\u901a\u9053\u6570 c1 , c2 = ch [ f ], args [ 0 ] # \u8be5\u5c42\u4e0d\u662f\u6700\u540e\u4e00\u5c42\uff0c\u5219\u5c06\u901a\u9053\u6570\u4e58\u4ee5\u5bbd\u5ea6\u56e0\u5b50 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5bbd\u5ea6\u56e0\u5b50\u4f5c\u7528\u4e8e\u9664\u4e86\u6700\u540e\u4e00\u5c42\u4e4b\u5916\u7684\u6240\u6709\u5c42 if c2 != no : # if not output # make_divisible\u7684\u4f5c\u7528\uff0c\u4f7f\u5f97\u539f\u59cb\u7684\u901a\u9053\u6570\u4e58\u4ee5\u5bbd\u5ea6\u56e0\u5b50\u4e4b\u540e\u53d6\u6574\u52308\u7684\u500d\u6570\uff0c\u8fd9\u6837\u5904\u7406\u4e00\u822c\u662f\u8ba9\u6a21\u578b\u7684\u5e76\u884c\u6027\u548c\u63a8\u7406\u6027\u80fd\u66f4\u597d\u3002 c2 = make_divisible ( c2 * gw , 8 ) # \u5c06\u524d\u9762\u7684\u8fd0\u7b97\u7ed3\u679c\u4fdd\u5b58\u5728args\u4e2d\uff0c\u5b83\u4e5f\u5c31\u662f\u8fd9\u4e2a\u6a21\u5757\u6700\u7ec8\u7684\u8f93\u5165\u53c2\u6570\u3002 args = [ c1 , c2 , * args [ 1 :]] # \u6839\u636e\u6bcf\u5c42\u7f51\u7edc\u53c2\u6570\u7684\u4e0d\u540c\uff0c\u5206\u522b\u5904\u7406\u53c2\u6570 \u5177\u4f53\u5404\u4e2a\u7c7b\u7684\u53c2\u6570\u662f\u4ec0\u4e48\u8bf7\u53c2\u8003\u5b83\u4eec\u7684__init__\u65b9\u6cd5\u8fd9\u91cc\u4e0d\u518d\u8be6\u7ec6\u89e3\u91ca\u4e86 if m in [ BottleneckCSP , C3 , C3TR , C3Ghost , C3x ]: # \u8fd9\u91cc\u7684\u610f\u601d\u5c31\u662f\u91cd\u590dn\u6b21\uff0c\u6bd4\u5982conv\u8fd9\u4e2a\u6a21\u5757\u91cd\u590dn\u6b21\uff0c\u8fd9\u4e2an \u662f\u4e0a\u9762\u7b97\u51fa\u6765\u7684 depth args . insert ( 2 , n ) # number of repeats n = 1 elif m is nn . BatchNorm2d : args = [ ch [ f ]] elif m is Concat : c2 = sum ( ch [ x ] for x in f ) elif m is Detect : args . append ([ ch [ x ] for x in f ]) if isinstance ( args [ 1 ], int ): # number of anchors args [ 1 ] = [ list ( range ( args [ 1 ] * 2 ))] * len ( f ) elif m is Contract : c2 = ch [ f ] * args [ 0 ] ** 2 elif m is Expand : c2 = ch [ f ] // args [ 0 ] ** 2 else : c2 = ch [ f ] # \u6784\u5efa\u6574\u4e2a\u7f51\u7edc\u6a21\u5757 \u8fd9\u91cc\u5c31\u662f\u6839\u636e\u6a21\u5757\u7684\u91cd\u590d\u6b21\u6570n\u4ee5\u53ca\u6a21\u5757\u672c\u8eab\u548c\u5b83\u7684\u53c2\u6570\u6765\u6784\u5efa\u8fd9\u4e2a\u6a21\u5757\u548c\u53c2\u6570\u5bf9\u5e94\u7684Module m_ = nn . Sequential ( * ( m ( * args ) for _ in range ( n ))) if n > 1 else m ( * args ) # module # \u83b7\u53d6\u6a21\u5757(module type)\u5177\u4f53\u540d\u4f8b\u5982 models.common.Conv , models.common.C3 , models.common.SPPF \u7b49\u3002 t = str ( m )[ 8 : - 2 ] . replace ( '__main__.' , '' ) # replace\u51fd\u6570\u4f5c\u7528\u662f\u5b57\u7b26\u4e32\"__main__\"\u66ff\u6362\u4e3a''\uff0c\u5728\u5f53\u524d\u9879\u76ee\u6ca1\u6709\u7528\u5230\u8fd9\u4e2a\u66ff\u6362\u3002 np = sum ( x . numel () for x in m_ . parameters ()) # number params m_ . i , m_ . f , m_ . type , m_ . np = i , f , t , np # attach index, 'from' index, type, number params LOGGER . info ( f ' { i : >3 }{ str ( f ) : >18 }{ n_ : >3 }{ np : 10.0f } { t : <40 }{ str ( args ) : <30 } ' ) # print \"\"\" \u5982\u679cx\u4e0d\u662f-1\uff0c\u5219\u5c06\u5176\u4fdd\u5b58\u5728save\u5217\u8868\u4e2d\uff0c\u8868\u793a\u8be5\u5c42\u9700\u8981\u4fdd\u5b58\u7279\u5f81\u56fe\u3002 \u8fd9\u91cc x % i \u4e0e x \u7b49\u4ef7\u4f8b\u5982\u5728\u6700\u540e\u4e00\u5c42 : f = [17,20,23] , i = 24 y = [ x % i for x in ([f] if isinstance(f, int) else f) if x != -1 ] print(y) # [17, 20, 23] # \u5199\u6210x % i \u53ef\u80fd\u56e0\u4e3a\uff1ai - 1 = -1 % i (\u6bd4\u5982 f = [-1]\uff0c\u5219 [x % i for x in f] \u4ee3\u8868 [11] ) \"\"\" save . extend ( x % i for x in ([ f ] if isinstance ( f , int ) else f ) if x != - 1 ) # append to savelist layers . append ( m_ ) if i == 0 : # \u5982\u679c\u662f\u521d\u6b21\u8fed\u4ee3\uff0c\u5219\u65b0\u521b\u5efa\u4e00\u4e2ach\uff08\u56e0\u4e3a\u5f62\u53c2ch\u5728\u521b\u5efa\u7b2c\u4e00\u4e2a\u7f51\u7edc\u6a21\u5757\u65f6\u9700\u8981\u7528\u5230\uff0c\u6240\u4ee5\u521b\u5efa\u7f51\u7edc\u6a21\u5757\u4e4b\u540e\u518d\u521d\u59cb\u5316ch\uff09 ch = [] ch . append ( c2 ) # \u5c06\u6240\u6709\u7684\u5c42\u5c01\u88c5\u4e3ann.Sequential , \u5bf9\u4fdd\u5b58\u7684\u7279\u5f81\u56fe\u6392\u5e8f return nn . Sequential ( * layers ), sorted ( save )","title":"parse_model\u51fd\u6570\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#model","text":"class Model ( nn . Module ): # YOLOv5 model def __init__ ( self , cfg = '[yolov5s.yaml](https://github.com/Oneflow-Inc/one-yolov5/blob/main/models/yolov5s.yaml)' , ch = 3 , nc = None , anchors = None ): # model, input channels, number of classes super () . __init__ () # \u5982\u679ccfg\u5df2\u7ecf\u662f\u5b57\u5178\uff0c\u5219\u76f4\u63a5\u8d4b\u503c\uff0c\u5426\u5219\u5148\u52a0\u8f7dcfg\u8def\u5f84\u7684\u6587\u4ef6\u4e3a\u5b57\u5178\u5e76\u8d4b\u503c\u7ed9self.yaml\u3002 if isinstance ( cfg , dict ): self . yaml = cfg # model dict else : # is *.yaml \u52a0\u8f7dyaml\u6a21\u5757 import yaml # for flow hub self . yaml_file = Path ( cfg ) . name with open ( cfg , encoding = 'ascii' , errors = 'ignore' ) as f : self . yaml = yaml . safe_load ( f ) # model dict \u4eceyaml\u6587\u4ef6\u4e2d\u52a0\u8f7d\u51fa\u5b57\u5178 # Define model # ch: \u8f93\u5165\u901a\u9053\u6570\u3002 \u5047\u5982self.yaml\u6709\u952e\u2018ch\u2019\uff0c\u5219\u5c06\u8be5\u952e\u5bf9\u5e94\u7684\u503c\u8d4b\u7ed9\u5185\u90e8\u53d8\u91cfch\u3002\u5047\u5982\u6ca1\u6709\u2018ch\u2019\uff0c\u5219\u5c06\u5f62\u53c2ch\u8d4b\u7ed9\u5185\u90e8\u53d8\u91cfch ch = self . yaml [ 'ch' ] = self . yaml . get ( 'ch' , ch ) # input channels # \u5047\u5982yaml\u4e2d\u7684nc\u548c\u65b9\u6cd5\u5f62\u53c2\u4e2d\u7684nc\u4e0d\u4e00\u81f4\uff0c\u5219\u8986\u76d6yaml\u4e2d\u7684nc\u3002 if nc and nc != self . yaml [ 'nc' ]: LOGGER . info ( f \"Overriding model.yaml nc= { self . yaml [ 'nc' ] } with nc= { nc } \" ) self . yaml [ 'nc' ] = nc # override yaml value if anchors : # anchors \u5148\u9a8c\u6846\u7684\u914d\u7f6e LOGGER . info ( f 'Overriding model.yaml anchors with anchors= { anchors } ' ) self . yaml [ 'anchors' ] = round ( anchors ) # override yaml value # \u5f97\u5230\u6a21\u578b\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7684\u4fdd\u5b58\u7684\u7279\u5f81\u56fe\u5217\u8868\u3002 self . model , self . save = parse_model ( deepcopy ( self . yaml ), ch = [ ch ]) # model, savelist self . names = [ str ( i ) for i in range ( self . yaml [ 'nc' ])] # default names \u521d\u59cb\u5316\u7c7b\u540d\u5217\u8868\uff0c\u9ed8\u8ba4\u4e3a[0,1,2...] # self.inplace=True \u9ed8\u8ba4True \u8282\u7701\u5185\u5b58 self . inplace = self . yaml . get ( 'inplace' , True ) # Build strides, anchors \u786e\u5b9a\u6b65\u957f\u3001\u6b65\u957f\u5bf9\u5e94\u7684\u951a\u6846 m = self . model [ - 1 ] # Detect() if isinstance ( m , Detect ): # \u68c0\u9a8c\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42\u662fDetect\u6a21\u5757 s = 256 # 2x min stride m . inplace = self . inplace # \u8ba1\u7b97\u4e09\u4e2afeature map\u4e0b\u91c7\u6837\u7684\u500d\u7387 [8, 16, 32] m . stride = flow . tensor ([ s / x . shape [ - 2 ] for x in self . forward ( flow . zeros ( 1 , ch , s , s ))]) # forward # \u68c0\u67e5anchor\u987a\u5e8f\u4e0estride\u987a\u5e8f\u662f\u5426\u4e00\u81f4 anchor\u7684\u987a\u5e8f\u5e94\u8be5\u662f\u4ece\u5c0f\u5230\u5927\uff0c\u8fd9\u91cc\u6392\u4e00\u4e0b\u5e8f check_anchor_order ( m ) # must be in pixel-space (not grid-space) # \u5bf9\u5e94\u7684anchor\u8fdb\u884c\u7f29\u653e\u64cd\u4f5c\uff0c\u539f\u56e0\uff1a\u5f97\u5230anchor\u5728\u5b9e\u9645\u7684\u7279\u5f81\u56fe\u4e2d\u7684\u4f4d\u7f6e\uff0c\u56e0\u4e3a\u52a0\u8f7d\u7684\u539f\u59cbanchor\u5927\u5c0f\u662f\u76f8\u5bf9\u4e8e\u539f\u56fe\u7684\u50cf\u7d20\uff0c\u4f46\u662f\u7ecf\u8fc7\u5377\u79ef\u6c60\u5316\u4e4b\u540e\uff0c\u7279\u5f81\u56fe\u7684\u957f\u5bbd\u53d8\u5c0f\u4e86\u3002 m . anchors /= m . stride . view ( - 1 , 1 , 1 ) self . stride = m . stride self . _initialize_biases () # only run once \u521d\u59cb\u5316\u504f\u7f6e # Init weights, biases # \u8c03\u7528oneflow_utils.py\u4e0binitialize_weights\u521d\u59cb\u5316\u6a21\u578b\u6743\u91cd initialize_weights ( self ) self . info () # \u6253\u5370\u6a21\u578b\u4fe1\u606f LOGGER . info ( '' ) # \u7ba1\u7406\u524d\u5411\u4f20\u64ad\u51fd\u6570 def forward ( self , x , augment = False , profile = False , visualize = False ): if augment : # \u662f\u5426\u5728\u6d4b\u8bd5\u65f6\u4e5f\u4f7f\u7528\u6570\u636e\u589e\u5f3a Test Time Augmentation(TTA) return self . _forward_augment ( x ) # augmented inference, None return self . _forward_once ( x , profile , visualize ) # single-scale inference, train # \u5e26\u6570\u636e\u589e\u5f3a\u7684\u524d\u5411\u4f20\u64ad def _forward_augment ( self , x ): img_size = x . shape [ - 2 :] # height, width s = [ 1 , 0.83 , 0.67 ] # scales f = [ None , 3 , None ] # flips (2-ud, 3-lr) y = [] # outputs for si , fi in zip ( s , f ): xi = scale_img ( x . flip ( fi ) if fi else x , si , gs = int ( self . stride . max ())) yi = self . _forward_once ( xi )[ 0 ] # forward # cv2.imwrite(f'img_{si}.jpg', 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1]) # save yi = self . _descale_pred ( yi , fi , si , img_size ) y . append ( yi ) y = self . _clip_augmented ( y ) # clip augmented tails return flow . cat ( y , 1 ), None # augmented inference, train # \u524d\u5411\u4f20\u64ad\u5177\u4f53\u5b9e\u73b0 def _forward_once ( self , x , profile = False , visualize = False ): \"\"\" @params x: \u8f93\u5165\u56fe\u50cf @params profile: True \u53ef\u4ee5\u505a\u4e00\u4e9b\u6027\u80fd\u8bc4\u4f30 @params feature_vis: True \u53ef\u4ee5\u505a\u4e00\u4e9b\u7279\u5f81\u53ef\u89c6\u5316 \"\"\" # y: \u5b58\u653e\u7740self.save=True\u7684\u6bcf\u4e00\u5c42\u7684\u8f93\u51fa\uff0c\u56e0\u4e3a\u540e\u9762\u7684\u7279\u5f81\u878d\u5408\u64cd\u4f5c\u8981\u7528\u5230\u8fd9\u4e9b\u7279\u5f81\u56fe y , dt = [], [] # outputs # \u524d\u5411\u63a8\u7406\u6bcf\u4e00\u5c42\u7ed3\u6784 m.i=index m.f=from m.type=\u7c7b\u540d m.np=number of params for m in self . model : # if not from previous layer m.f=\u5f53\u524d\u5c42\u7684\u8f93\u5165\u6765\u81ea\u54ea\u4e00\u5c42\u7684\u8f93\u51fa s\u7684m.f\u90fd\u662f-1 if m . f != - 1 : # if not from previous layer x = y [ m . f ] if isinstance ( m . f , int ) else [ x if j == - 1 else y [ j ] for j in m . f ] # from earlier layers if profile : self . _profile_one_layer ( m , x , dt ) x = m ( x ) # run y . append ( x if m . i in self . save else None ) # save output if visualize : feature_visualization ( x , m . type , m . i , save_dir = visualize ) return x # \u5c06\u63a8\u7406\u7ed3\u679c\u6062\u590d\u5230\u539f\u56fe\u56fe\u7247\u5c3a\u5bf8(\u9006\u64cd\u4f5c) def _descale_pred ( self , p , flips , scale , img_size ): # de-scale predictions following augmented inference (inverse operation) \"\"\"\u7528\u5728\u4e0a\u9762\u7684__init__\u51fd\u6570\u4e0a \u5c06\u63a8\u7406\u7ed3\u679c\u6062\u590d\u5230\u539f\u56fe\u56fe\u7247\u5c3a\u5bf8 Test Time Augmentation(TTA)\u4e2d\u7528\u5230 de-scale predictions following augmented inference (inverse operation) @params p: \u63a8\u7406\u7ed3\u679c @params flips: @params scale: @params img_size: \"\"\" if self . inplace : p [ ... , : 4 ] /= scale # de-scale if flips == 2 : p [ ... , 1 ] = img_size [ 0 ] - p [ ... , 1 ] # de-flip ud elif flips == 3 : p [ ... , 0 ] = img_size [ 1 ] - p [ ... , 0 ] # de-flip lr else : x , y , wh = p [ ... , 0 : 1 ] / scale , p [ ... , 1 : 2 ] / scale , p [ ... , 2 : 4 ] / scale # de-scale if flips == 2 : y = img_size [ 0 ] - y # de-flip ud elif flips == 3 : x = img_size [ 1 ] - x # de-flip lr p = flow . cat (( x , y , wh , p [ ... , 4 :]), - 1 ) return p # \u8fd9\u4e2a\u662fTTA\u7684\u65f6\u5019\u5bf9\u539f\u56fe\u7247\u8fdb\u884c\u88c1\u526a\uff0c\u4e5f\u662f\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u5f0f\uff0c\u7528\u5728TTA\u6d4b\u8bd5\u7684\u65f6\u5019\u3002 def _clip_augmented ( self , y ): # Clip YOLOv5 augmented inference tails nl = self . model [ - 1 ] . nl # number of detection layers (P3-P5) g = sum ( 4 ** x for x in range ( nl )) # grid points e = 1 # exclude layer count i = ( y [ 0 ] . shape [ 1 ] // g ) * sum ( 4 ** x for x in range ( e )) # indices y [ 0 ] = y [ 0 ][:, : - i ] # large i = ( y [ - 1 ] . shape [ 1 ] // g ) * sum ( 4 ** ( nl - 1 - x ) for x in range ( e )) # indices y [ - 1 ] = y [ - 1 ][:, i :] # small return y # \u6253\u5370\u65e5\u5fd7\u4fe1\u606f \u524d\u5411\u63a8\u7406\u65f6\u95f4 def _profile_one_layer ( self , m , x , dt ): c = isinstance ( m , Detect ) # is final layer, copy input as inplace fix o = thop . profile ( m , inputs = ( x . copy () if c else x ,), verbose = False )[ 0 ] / 1E9 * 2 if thop else 0 # FLOPs t = time_sync () for _ in range ( 10 ): m ( x . copy () if c else x ) dt . append (( time_sync () - t ) * 100 ) if m == self . model [ 0 ]: LOGGER . info ( f \" { 'time (ms)' : >10s } { 'GFLOPs' : >10s } { 'params' : >10s } module\" ) LOGGER . info ( f ' { dt [ - 1 ] : 10.2f } { o : 10.2f } { m . np : 10.0f } { m . type } ' ) if c : LOGGER . info ( f \" { sum ( dt ) : 10.2f } { '-' : >10s } { '-' : >10s } Total\" ) # initialize biases into Detect(), cf is class frequency def _initialize_biases ( self , cf = None ): # https://arxiv.org/abs/1708.02002 section 3.3 # cf = flow.bincount(flow.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1. m = self . model [ - 1 ] # Detect() module for mi , s in zip ( m . m , m . stride ): # from b = mi . bias . view ( m . na , - 1 ) . detach () # conv.bias(255) to (3,85) b [:, 4 ] += math . log ( 8 / ( 640 / s ) ** 2 ) # obj (8 objects per 640 image) b [:, 5 :] += math . log ( 0.6 / ( m . nc - 0.999999 )) if cf is None else flow . log ( cf / cf . sum ()) # cls mi . bias = flow . nn . Parameter ( b . view ( - 1 ), requires_grad = True ) # \u6253\u5370\u6a21\u578b\u4e2d\u6700\u540eDetect\u5c42\u7684\u504f\u7f6ebiases\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42biases\u4fe1\u606f) def _print_biases ( self ): \"\"\" \u6253\u5370\u6a21\u578b\u4e2d\u6700\u540eDetect\u6a21\u5757\u91cc\u9762\u7684\u5377\u79ef\u5c42\u7684\u504f\u7f6ebiases\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42biases\u4fe1\u606f) \"\"\" m = self . model [ - 1 ] # Detect() module for mi in m . m : # from b = mi . bias . detach () . view ( m . na , - 1 ) . T # conv.bias(255) to (3,85) LOGGER . info ( ( ' %6g Conv2d.bias:' + ' %10.3g ' * 6 ) % ( mi . weight . shape [ 1 ], * b [: 5 ] . mean ( 1 ) . tolist (), b [ 5 :] . mean ())) def _print_weights ( self ): \"\"\" \u6253\u5370\u6a21\u578b\u4e2dBottleneck\u5c42\u7684\u6743\u91cd\u53c2\u6570weights\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42weights\u4fe1\u606f) \"\"\" for m in self . model . modules (): if type ( m ) is Bottleneck : LOGGER . info ( ' %10.3g ' % ( m . w . detach () . sigmoid () * 2 )) # shortcut weights # fuse()\u662f\u7528\u6765\u8fdb\u884cconv\u548cbn\u5c42\u5408\u5e76\uff0c\u4e3a\u4e86\u63d0\u901f\u6a21\u578b\u63a8\u7406\u901f\u5ea6\u3002 def fuse ( self ): # fuse model Conv2d() + BatchNorm2d() layers \"\"\"\u7528\u5728detect.py\u3001val.py fuse model Conv2d() + BatchNorm2d() layers \u8c03\u7528oneflow_utils.py\u4e2d\u7684fuse_conv_and_bn\u51fd\u6570\u548ccommon.py\u4e2dConv\u6a21\u5757\u7684fuseforward\u51fd\u6570 \"\"\" LOGGER . info ( 'Fusing layers... ' ) for m in self . model . modules (): # \u5982\u679c\u5f53\u524d\u5c42\u662f\u5377\u79ef\u5c42Conv\u4e14\u6709bn\u7ed3\u6784, \u90a3\u4e48\u5c31\u8c03\u7528fuse_conv_and_bn\u51fd\u6570\u8bb2conv\u548cbn\u8fdb\u884c\u878d\u5408, \u52a0\u901f\u63a8\u7406 if isinstance ( m , ( Conv , DWConv )) and hasattr ( m , 'bn' ): m . conv = fuse_conv_and_bn ( m . conv , m . bn ) # update conv delattr ( m , 'bn' ) # remove batchnorm \u79fb\u9664bn remove batchnorm m . forward = m . forward_fuse # update forward \u66f4\u65b0\u524d\u5411\u4f20\u64ad update forward (\u53cd\u5411\u4f20\u64ad\u4e0d\u7528\u7ba1, \u56e0\u4e3a\u8fd9\u79cd\u63a8\u7406\u53ea\u7528\u5728\u63a8\u7406\u9636\u6bb5) self . info () # \u6253\u5370conv+bn\u878d\u5408\u540e\u7684\u6a21\u578b\u4fe1\u606f return self # \u6253\u5370\u6a21\u578b\u7ed3\u6784\u4fe1\u606f \u5728\u5f53\u524d\u7c7b__init__\u51fd\u6570\u7ed3\u5c3e\u5904\u6709\u8c03\u7528 def info ( self , verbose = False , img_size = 640 ): # print model information model_info ( self , verbose , img_size ) def _apply ( self , fn ): # Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers self = super () . _apply ( fn ) m = self . model [ - 1 ] # Detect() if isinstance ( m , Detect ): m . stride = fn ( m . stride ) m . grid = list ( map ( fn , m . grid )) if isinstance ( m . anchor_grid , list ): m . anchor_grid = list ( map ( fn , m . anchor_grid )) return self","title":"Model \u7c7b\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#detect","text":"class Detect ( nn . Module ): \"\"\" Detect\u6a21\u5757\u662f\u7528\u6765\u6784\u5efaDetect\u5c42\u7684\uff0c\u5c06\u8f93\u5165feature map \u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u64cd\u4f5c\u548c\u516c\u5f0f\u8ba1\u7b97\u5230\u6211\u4eec\u60f3\u8981\u7684shape, \u4e3a\u540e\u9762\u7684\u8ba1\u7b97\u635f\u5931\u6216\u8005NMS\u540e\u5904\u7406\u4f5c\u51c6\u5907 \"\"\" stride = None # strides computed during build onnx_dynamic = False # ONNX export parameter export = False # export mode def __init__ ( self , nc = 80 , anchors = (), ch = (), inplace = True ): # detection layer super () . __init__ () # nc:\u5206\u7c7b\u6570\u91cf self . nc = nc # number of classes COCO : 80 # no:\u6bcf\u4e2aanchor\u7684\u8f93\u51fa\u6570 COCO: 80 + 5 = 85 self . no = nc + 5 # number of outputs per anchor Detect\u7684\u4e2a\u6570 3 # nl:\u9884\u6d4b\u5c42\u6570\uff0c\u6b64\u6b21\u4e3a3 self . nl = len ( anchors ) # number of detection layers # na:anchors\u7684\u6570\u91cf\uff0c\u6b64\u6b21\u4e3a3 self . na = len ( anchors [ 0 ]) // 2 # number of anchors # grid:\u683c\u5b50\u5750\u6807\u7cfb\uff0c\u5de6\u4e0a\u89d2\u4e3a(1,1),\u53f3\u4e0b\u89d2\u4e3a(input.w/stride,input.h/stride) self . grid = [ flow . zeros ( 1 )] * self . nl # init grid self . anchor_grid = [ flow . zeros ( 1 )] * self . nl # init anchor grid # \u5199\u5165\u7f13\u5b58\u4e2d\uff0c\u5e76\u547d\u540d\u4e3aanchors # register_buffer # \u6a21\u578b\u4e2d\u9700\u8981\u4fdd\u5b58\u7684\u53c2\u6570\u4e00\u822c\u6709\u4e24\u79cd\uff1a\u4e00\u79cd\u662f\u53cd\u5411\u4f20\u64ad\u9700\u8981\u88aboptimizer\u66f4\u65b0\u7684\uff0c\u79f0\u4e3aparameter; \u53e6\u4e00\u79cd\u4e0d\u8981\u88ab\u66f4\u65b0\u79f0\u4e3abuffer # buffer\u7684\u53c2\u6570\u66f4\u65b0\u662f\u5728forward\u4e2d\uff0c\u800coptim.step\u53ea\u80fd\u66f4\u65b0nn.parameter\u7c7b\u578b\u7684\u53c2\u6570 self . register_buffer ( 'anchors' , flow . tensor ( anchors ) . float () . view ( self . nl , - 1 , 2 )) # shape(nl,na,2) # \u5c06\u8f93\u51fa\u901a\u8fc7\u5377\u79ef\u5230 self.no * self.na \u7684\u901a\u9053\uff0c\u8fbe\u5230\u5168\u8fde\u63a5\u7684\u4f5c\u7528 self . m = nn . ModuleList ( nn . Conv2d ( x , self . no * self . na , 1 ) for x in ch ) # output conv self . inplace = inplace # use inplace ops (e.g. slice assignment) def forward ( self , x ): z = [] # inference output for i in range ( self . nl ): x [ i ] = self . m [ i ]( x [ i ]) # conv bs , _ , ny , nx = x [ i ] . shape # x(bs,255,20,20) to x(bs,3,20,20,85) x [ i ] = x [ i ] . view ( bs , self . na , self . no , ny , nx ) . permute ( 0 , 1 , 3 , 4 , 2 ) . contiguous () if not self . training : # inference # \u6784\u9020\u7f51\u683c # \u56e0\u4e3a\u63a8\u7406\u8fd4\u56de\u7684\u4e0d\u662f\u5f52\u4e00\u5316\u540e\u7684\u7f51\u683c\u504f\u79fb\u91cf \u9700\u8981\u518d\u52a0\u4e0a\u7f51\u683c\u7684\u4f4d\u7f6e \u5f97\u5230\u6700\u7ec8\u7684\u63a8\u7406\u5750\u6807 \u518d\u9001\u5165nms # \u6240\u4ee5\u8fd9\u91cc\u6784\u5efa\u7f51\u683c\u5c31\u662f\u4e3a\u4e86\u8bb0\u5f55\u6bcf\u4e2agrid\u7684\u7f51\u683c\u5750\u6807 \u65b9\u9762\u540e\u9762\u4f7f\u7528 if self . onnx_dynamic or self . grid [ i ] . shape [ 2 : 4 ] != x [ i ] . shape [ 2 : 4 ]: # \u5411\u524d\u4f20\u64ad\u65f6\u9700\u8981\u5c06\u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u5230grid\u7edd\u5bf9\u5750\u6807\u7cfb\u4e2d self . grid [ i ], self . anchor_grid [ i ] = self . _make_grid ( nx , ny , i ) y = x [ i ] . sigmoid () if self . inplace : # \u9ed8\u8ba4\u6267\u884c \u4e0d\u4f7f\u7528AWS Inferentia # \u8fd9\u91cc\u7684\u516c\u5f0f\u548cyolov3\u3001v4\u4e2d\u4f7f\u7528\u7684\u4e0d\u4e00\u6837 \u662fyolov5\u4f5c\u8005\u81ea\u5df1\u7528\u7684 \u6548\u679c\u66f4\u597d y [ ... , 0 : 2 ] = ( y [ ... , 0 : 2 ] * 2 + self . grid [ i ]) * self . stride [ i ] # xy y [ ... , 2 : 4 ] = ( y [ ... , 2 : 4 ] * 2 ) ** 2 * self . anchor_grid [ i ] # wh else : # for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953 xy , wh , conf = y . split (( 2 , 2 , self . nc + 1 ), 4 ) # y.tensor_split((2, 4, 5), 4) xy = ( xy * 2 + self . grid [ i ]) * self . stride [ i ] # xy wh = ( wh * 2 ) ** 2 * self . anchor_grid [ i ] # wh y = flow . cat (( xy , wh , conf ), 4 ) # z [oneflow.Size([1, 19200, 85]) oneflow.Size([1, 4800, 85]) oneflow.Size([1, 1200, 85])] z . append ( y . view ( bs , - 1 , self . no )) return x if self . training else ( flow . cat ( z , 1 ),) if self . export else ( flow . cat ( z , 1 ), x ) # \u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u5230grid\u7edd\u5bf9\u5750\u6807\u7cfb def _make_grid ( self , nx = 20 , ny = 20 , i = 0 ): d = self . anchors [ i ] . device t = self . anchors [ i ] . dtype shape = 1 , self . na , ny , nx , 2 # grid shape y , x = flow . arange ( ny , device = d , dtype = t ), flow . arange ( nx , device = d , dtype = t ) yv , xv = flow . meshgrid ( y , x , indexing = \"ij\" ) grid = flow . stack (( xv , yv ), 2 ) . expand ( shape ) - 0.5 # add grid offset, i.e. y = 2.0 * x - 0.5 anchor_grid = ( self . anchors [ i ] * self . stride [ i ]) . view (( 1 , self . na , 1 , 1 , 2 )) . expand ( shape ) return grid , anchor_grid","title":"Detect\u7c7b\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_5","text":"\u88682.1 yolov5s.yaml \u89e3\u6790\u8868 \u5c42\u6570 form moudule arguments input output 0 -1 Conv [3, 32, 6, 2, 2] [3, 640, 640] [32, 320, 320] 1 -1 Conv [32, 64, 3, 2] [32, 320, 320] [64, 160, 160] 2 -1 C3 [64, 64, 1] [64, 160, 160] [64, 160, 160] 3 -1 Conv [64, 128, 3, 2] [64, 160, 160] [128, 80, 80] 4 -1 C3 [128, 128, 2] [128, 80, 80] [128, 80, 80] 5 -1 Conv [128, 256, 3, 2] [128, 80, 80] [256, 40, 40] 6 -1 C3 [256, 256, 3] [256, 40, 40] [256, 40, 40] 7 -1 Conv [256, 512, 3, 2] [256, 40, 40] [512, 20, 20] 8 -1 C3 [512, 512, 1] [512, 20, 20] [512, 20, 20] 9 -1 SPPF [512, 512, 5] [512, 20, 20] [512, 20, 20] 10 -1 Conv [512, 256, 1, 1] [512, 20, 20] [256, 20, 20] 11 -1 Upsample [None, 2, 'nearest'] [256, 20, 20] [256, 40, 40] 12 [-1, 6] Concat [1] [1, 256, 40, 40],[1, 256, 40, 40] [512, 40, 40] 13 -1 C3 [512, 256, 1, False] [512, 40, 40] [256, 40, 40] 14 -1 Conv [256, 128, 1, 1] [256, 40, 40] [128, 40, 40] 15 -1 Upsample [None, 2, 'nearest'] [128, 40, 40] [128, 80, 80] 16 [-1, 4] Concat [1] [1, 128, 80, 80],[1, 128, 80, 80] [256, 80, 80] 17 -1 C3 [256, 128, 1, False] [256, 80, 80] [128, 80, 80] 18 -1 Conv [128, 128, 3, 2] [128, 80, 80] [128, 40, 40] 19 [-1, 14] Concat [1] [1, 128, 40, 40],[1, 128, 40, 40] [256, 40, 40] 20 -1 C3 [256, 256, 1, False] [256, 40, 40] [256, 40, 40] 21 -1 Conv [256, 256, 3, 2] [256, 40, 40] [256, 20, 20] 22 [-1, 10] Concat [1] [1, 256, 20, 20],[1, 256, 20, 20] [512, 20, 20] 23 -1 C3 [512, 512, 1, False] [512, 20, 20] [512, 20, 20] 24 [17, 20, 23] Detect [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]] [1, 128, 80, 80],[1, 256, 40, 40],[1, 512, 20, 20] [1, 3, 80, 80, 85],[1, 3, 40, 40, 85],[1, 3, 20, 20, 85]","title":"\u9644\u4ef6"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_6","text":"https://zhuanlan.zhihu.com/p/436891962?ivk_sa=1025922q https://zhuanlan.zhihu.com/p/110204563 https://www.it610.com/article/1550621248474648576.htm","title":"\u53c2\u8003\u6587\u7ae0:"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u672c\u6587\u4e3b\u8981\u4ecb\u7ecd one-yolov5 \u4f7f\u7528\u7684\u6570\u636e\u96c6\u7684\u683c\u5f0f\u4ee5\u53ca\u5982\u4f55\u5236\u4f5c\u4e00\u4e2a\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u8bad\u7ec3\u6548\u679c\u7684\u6570\u636e\u96c6\u3002\u672c\u8282\u6559\u7a0b\u597d\u7684\u6570\u636e\u96c6\u6807\u51c6\u90e8\u5206\u7ffb\u8bd1\u4e86 ultralytics/yolov5 wiki \u4e2d \u5bf9\u6570\u636e\u96c6\u76f8\u5173\u7684\u63cf\u8ff0 \u3002 \u6570\u636e\u96c6\u7ed3\u6784\u89e3\u8bfb 1.\u521b\u5efadataset.yaml COCO128\u662f\u5b98\u65b9\u7ed9\u7684\u4e00\u4e2a\u5c0f\u7684\u6570\u636e\u96c6 \u7531 COCO \u6570\u636e\u96c6\u524d 128 \u5f20\u56fe\u7247\u7ec4\u6210\u3002 \u8fd9128\u5e45\u56fe\u50cf\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\uff0c\u5224\u65ad yolov5 \u811a\u672c\u662f\u5426\u80fd\u591f\u8fc7\u6b63\u5e38\u8fdb\u884c\u3002 \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6 coco128.yaml \u5b9a\u4e49\u4e86\u5982\u4e0b\u7684\u914d\u7f6e\u9009\u9879\uff1a # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license # COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics # Example usage: python train.py --data coco128.yaml # parent # \u251c\u2500\u2500 one-yolov5 # \u2514\u2500\u2500 datasets # \u2514\u2500\u2500 coco128 \u2190 downloads here (7 MB) # train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/] # \u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u76f8\u540c train: ../coco128/images/train2017/ val: ../coco128/images/train2017/ # number of classes nc: 80 # \u7c7b\u522b\u6570 # class names \u7c7b\u540d\u5217\u8868 names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'] # Download script/URL (optional) \u7528\u4e8e\u81ea\u52a8\u4e0b\u8f7d\u7684\u53ef\u9009\u4e0b\u8f7d\u547d\u4ee4/URL \u3002 download: https://ultralytics.com/assets/coco128.zip \u6ce8\u610f\uff1a\u5982\u679c\u662f\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u7684\u8bdd\u6309\u81ea\u5df1\u9700\u6c42\u4fee\u6539\u8fd9\u4e2ayaml\u6587\u4ef6\u3002\u4e3b\u8981\u4fee\u6539\u4ee5\u4e0b\u4e24\u70b9\u3002 1. \u4fee\u6539\u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u4e3a\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u8def\u5f84 2. \u4fee\u6539\u7c7b\u522b\u6570\u548c\u7c7b\u540d\u5217\u8868 \u518d\u5c55\u793a\u4e00\u4e0b coco.yaml \u7684\u6570\u636e\u96c6\u8def\u5f84\u914d\u7f6e\uff0c\u8fd9\u91cc\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u5c31\u662f\u76f4\u63a5\u7528txt\u8868\u793a\uff1a 2.\u521b\u5efa Labels \u4f7f\u7528\u5de5\u5177\u4f8b\u5982 CVAT , makesense.ai , Labelbox \uff0cLabelImg(\u5728\u672c\u7ae0\u5982\u4f55\u5236\u4f5c\u6570\u636e\u96c6\u4e2d\u4ecb\u7ecdLabelImg\u5de5\u5177\u4f7f\u7528) \u7b49\uff0c\u5728\u4f60\u81ea\u5df1\u7684\u6570\u636e\u96c6\u63d0\u4f9b\u7684\u56fe\u7247\u4e0a\u505a\u76ee\u6807\u6846\u7684\u6807\u6ce8\uff0c\u5c06\u6807\u6ce8\u4fe1\u606f\u5bfc\u51fa\u4e3a\u4e00\u4e2atxt\u540e\u7f00\u7ed3\u5c3e\u7684\u6587\u4ef6\u3002\uff08\u5982\u679c\u56fe\u50cf\u4e2d\u6ca1\u6709\u76ee\u6807\uff0c\u5219\u4e0d\u9700\u8981*.txt\u6587\u4ef6\uff09\u3002 *.txt\u6587\u4ef6\u89c4\u8303\u5982\u4e0b\u6240\u793a: - \u6bcf\u4e00\u884c \u4e00\u4e2a\u76ee\u6807\u3002 - \u6bcf\u4e00\u884c\u662f class x_center y_center width height \u683c\u5f0f\u3002 - \u6846\u5750\u6807\u5fc5\u987b\u91c7\u7528\u6807\u51c6\u5316xywh\u683c\u5f0f\uff08\u4ece0\u52301\uff09\u3002\u5982\u679c\u6846\u4ee5\u50cf\u7d20\u4e3a\u5355\u4f4d\uff0c\u5219\u5c06x_center\u548cwidth\u9664\u4ee5\u56fe\u50cf\u5bbd\u5ea6\uff0c\u5c06y_centre\u548cheight\u9664\u4ee5\u56fe\u50cf\u9ad8\u5ea6\u3002 - \u7c7b\u53f7\u4e3a\u96f6\u7d22\u5f15\u7684\u7f16\u53f7\uff08\u4ece0\u5f00\u59cb\u8ba1\u6570\uff09\u3002 **\u8fd9\u91cc\u5047\u8bbe\u4ee5 COCO \u6570\u636e\u96c6\u7684\u76ee\u6807\u7c7b\u522b\u7ea6\u5b9a\u6765\u6807\u6ce8** \u4e0e\u4e0a\u8ff0\u56fe\u50cf\u76f8\u5bf9\u5e94\u7684\u6807\u7b7e\u6587\u4ef6\u5305\u542b2\u4e2a\u4eba\uff08class 0\uff09\u548c \u4e00\u4e2a\u9886\u5e26\uff08class 27\uff09\uff1a 3.COCO128 \u6570\u636e\u96c6\u76ee\u5f55\u7ed3\u6784\u7ec4\u7ec7 \u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u4eec\u7684 coco128 \u662f\u4f4d\u4e8e yolov5 \u76ee\u5f55\u9644\u8fd1\u3002yolov5 \u901a\u8fc7\u5c06\u6bcf\u4e2a\u56fe\u50cf\u8def\u5f84 xx/images/xx.jpg \u66ff\u6362\u4e3a xx/labels/xx.txt \u6765\u81ea\u52a8\u5b9a\u4f4d\u6bcf\u4e2a\u56fe\u50cf\u7684\u6807\u7b7e\u3002\u4f8b\u5982\uff1a dataset / images / im0 . jpg # image dataset / labels / im0 . txt # label \u5236\u4f5c\u6570\u636e\u96c6 \u6570\u636e\u96c6\u6807\u6ce8\u5de5\u5177 \u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd LabelImg: \u662f\u4e00\u79cd\u77e9\u5f62\u6807\u6ce8\u5de5\u5177\uff0c\u5e38\u7528\u4e8e\u76ee\u6807\u8bc6\u522b\u548c\u76ee\u6807\u68c0\u6d4b,\u53ef\u76f4\u63a5\u751f\u6210 yolov5 \u8bfb\u53d6\u7684txt\u6807\u7b7e\u683c\u5f0f\uff0c\u4f46\u5176\u53ea\u80fd\u8fdb\u884c\u77e9\u5f62\u6846\u6807\u6ce8\u3002(\u5f53\u7136\u4e5f\u53ef\u4ee5\u9009\u7528\u5176\u5b83\u7684\u5de5\u5177\u8fdb\u884c\u6807\u6ce8\u5e76\u4e14\u7f51\u4e0a\u90fd\u6709\u5927\u91cf\u5173\u4e8e\u6807\u6ce8\u5de5\u5177\u7684\u6559\u7a0b\u3002) \u9996\u5148labelimg\u7684\u5b89\u88c5\u5341\u5206\u7b80\u5355\uff0c\u76f4\u63a5\u4f7f\u7528cmd\u4e2d\u7684pip\u8fdb\u884c\u5b89\u88c5\uff0c\u5728cmd\u4e2d\u8f93\u5165\u547d\u4ee4\u884c\uff1a pip install labelimg \u5b89\u88c5\u540e\u76f4\u63a5\u8f93\u5165\u547d\u4ee4\uff1a labelimg \u5373\u53ef\u6253\u5f00\u8fd0\u884c\u3002 \u70b9\u51fbOpen Dir\u9009\u62e9\u6570\u636e\u96c6\u6587\u4ef6\u5939\uff0c\u518d\u70b9\u51fbCreate RectBox\u8fdb\u884c\u6807\u6ce8\u3002 \u5f53\u4f60\u7ed8\u5236\u6846\u7ed3\u675f\u5c31\u4f1a\u5f39\u51fa\u6807\u7b7e\u9009\u62e9\u6846\uff0c\u7136\u540e\u6807\u6ce8\u7c7b\u522b\u3002\u8fd9\u4e2a\u7c7b\u522b\u7f16\u8f91\u66f4\u6539\u5728Labelimg\u6587\u4ef6\u91cc\uff0c\u91cc\u9762\u6709classes.txt\u6587\u6863\uff0c\u6253\u5f00\u624b\u52a8\u66f4\u6539\u7c7b\u522b\u5373\u53ef\u3002\uff08\u5f53\u51fa\u73b0\u65b0\u7c7b\u522b\u65f6\u4e5f\u53ef\u5728\u6807\u7b7e\u9009\u62e9\u6846\u91cc\u8f93\u5165\u70b9OK\u5c31\u81ea\u52a8\u6dfb\u52a0\u7c7b\u522b\u4e86\uff09 \u6807\u6ce8\u597d\u540e\u9009\u62e9 yolo \u683c\u5f0f\uff0c\u70b9\u51fb Save \u4fdd\u5b58\u3002\u6807\u6ce8\u7ed3\u679c\u4fdd\u5b58\u5728 \u56fe\u7247\u540d.txt \u6587\u4ef6\u4e2d\uff0ctxt\u6587\u4ef6\u548c\u56fe\u7247\u540d\u79f0\u4e00\u81f4\uff0c\u5185\u5bb9\u5982\u4e0b\uff1a \u4e00\u4e2a\u597d\u7684\u6570\u636e\u96c6\u6807\u51c6\uff1f \u6bcf\u4e2a\u7c7b\u7684\u56fe\u50cf\u3002 >= 1500 \u5f20\u56fe\u7247\u3002 \u6bcf\u4e2a\u7c7b\u7684\u5b9e\u4f8b\u3002\u2265 \u5efa\u8bae\u6bcf\u4e2a\u7c7b10000\u4e2a\u5b9e\u4f8b\uff08\u6807\u8bb0\u5bf9\u8c61\uff09 \u56fe\u7247\u5f62\u8c61\u591a\u6837\u3002\u5fc5\u987b\u4ee3\u8868\u5df2\u90e8\u7f72\u7684\u73af\u5883\u3002\u5bf9\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u4f7f\u7528\u6848\u4f8b\uff0c\u6211\u4eec\u63a8\u8350\u6765\u81ea\u4e00\u5929\u4e2d\u4e0d\u540c\u65f6\u95f4\u3001\u4e0d\u540c\u5b63\u8282\u3001\u4e0d\u540c\u5929\u6c14\u3001\u4e0d\u540c\u7167\u660e\u3001\u4e0d\u540c\u89d2\u5ea6\u3001\u4e0d\u540c\u6765\u6e90\uff08\u5728\u7ebf\u91c7\u96c6\u3001\u672c\u5730\u91c7\u96c6\u3001\u4e0d\u540c\u6444\u50cf\u673a\uff09\u7b49\u7684\u56fe\u50cf\u3002 \u6807\u7b7e\u4e00\u81f4\u6027\u3002\u5fc5\u987b\u6807\u8bb0\u6240\u6709\u56fe\u50cf\u4e2d\u6240\u6709\u7c7b\u7684\u6240\u6709\u5b9e\u4f8b\u3002\u90e8\u5206\u6807\u8bb0\u5c06\u4e0d\u8d77\u4f5c\u7528\u3002 \u6807\u7b7e\u51c6\u786e\u6027\u3002 \u6807\u7b7e\u5fc5\u987b\u7d27\u5bc6\u5730\u5305\u56f4\u6bcf\u4e2a\u5bf9\u8c61\u3002\u5bf9\u8c61\u4e0e\u5176\u8fb9\u754c\u6846\u4e4b\u95f4\u4e0d\u5e94\u5b58\u5728\u4efb\u4f55\u7a7a\u95f4\u3002\u4efb\u4f55\u5bf9\u8c61\u90fd\u4e0d\u5e94\u7f3a\u5c11\u6807\u7b7e\u3002 \u6807\u7b7e\u9a8c\u8bc1\u3002\u67e5\u770btrain_batch .jpg \u5728 \u8bad\u7ec3\u5f00\u59cb\u9a8c\u8bc1\u6807\u7b7e\u662f\u5426\u6b63\u786e\uff0c\u5373\u53c2\u89c1 mosaic \uff08\u5728 yolov5 \u7684\u8bad\u7ec3\u65e5\u5fd7 runs/train/exp \u6587\u4ef6\u5939\u91cc\u9762\u53ef\u4ee5\u770b\u5230\uff09\u3002 \u80cc\u666f\u56fe\u50cf\u3002\u80cc\u666f\u56fe\u50cf\u662f\u6ca1\u6709\u6dfb\u52a0\u5230\u6570\u636e\u96c6\u4ee5\u51cf\u5c11 False Positives\uff08FP\uff09\u7684\u5bf9\u8c61\u7684\u56fe\u50cf\u3002\u6211\u4eec\u5efa\u8bae\u4f7f\u7528\u5927\u7ea60-10%\u7684\u80cc\u666f\u56fe\u50cf\u6765\u5e2e\u52a9\u51cf\u5c11FPs\uff08COCO\u67091000\u4e2a\u80cc\u666f\u56fe\u50cf\u4f9b\u53c2\u8003\uff0c\u5360\u603b\u6570\u76841%\uff09\u3002\u80cc\u666f\u56fe\u50cf\u4e0d\u9700\u8981\u6807\u7b7e\u3002 \u4e0b\u56fe\u5c55\u793a\u4e86\u591a\u79cd\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7279\u70b9\uff1a \u5176\u4e2d\uff1a Instances per category \u8868\u793a\u6bcf\u4e2a\u7c7b\u522b\u7684\u5b9e\u4f8b\u6570 Categories per image \u8868\u793a\u6bcf\u5e45\u56fe\u50cf\u7684\u7c7b\u522b (a) Instances per image \u8868\u793a\u6bcf\u5e45\u56fe\u50cf\u7684\u5b9e\u4f8b\u6570 (b) Number of categories vs. number of instances \u8868\u793a\u7c7b\u522b\u6570\u76ee vs \u5b9e\u4f8b\u6570\u76ee \uff08\u6211\u4eec\u53ef\u4ee5\u770b\u5230 COCO \u6570\u636e\u96c6\u7684\u7c7b\u522b\u548c\u5b9e\u4f8b\u7684\u6570\u76ee\u8fbe\u5230\u4e86\u4e00\u4e2a\u8f83\u597d\u7684\u5e73\u8861\uff09 (c) Instance size \u8868\u793a\u5b9e\u4f8b\u4e2a\u6570 (d) Number of categories \u8868\u793a\u7c7b\u522b\u6570 (e) Percent of image size \u8868\u793a\u56fe\u50cf\u5927\u5c0f\u767e\u5206\u6bd4 \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results https://docs.ultralytics.com/tutorials/train-custom-datasets/#weights-biases-logging-new","title":"2.1. \u5982\u4f55\u51c6\u5907YOLOv5\u6a21\u578b\u8bad\u7ec3\u6570\u636e"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u672c\u6587\u4e3b\u8981\u4ecb\u7ecd one-yolov5 \u4f7f\u7528\u7684\u6570\u636e\u96c6\u7684\u683c\u5f0f\u4ee5\u53ca\u5982\u4f55\u5236\u4f5c\u4e00\u4e2a\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u8bad\u7ec3\u6548\u679c\u7684\u6570\u636e\u96c6\u3002\u672c\u8282\u6559\u7a0b\u597d\u7684\u6570\u636e\u96c6\u6807\u51c6\u90e8\u5206\u7ffb\u8bd1\u4e86 ultralytics/yolov5 wiki \u4e2d \u5bf9\u6570\u636e\u96c6\u76f8\u5173\u7684\u63cf\u8ff0 \u3002","title":"\u524d\u8a00"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_2","text":"","title":"\u6570\u636e\u96c6\u7ed3\u6784\u89e3\u8bfb"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#1datasetyaml","text":"COCO128\u662f\u5b98\u65b9\u7ed9\u7684\u4e00\u4e2a\u5c0f\u7684\u6570\u636e\u96c6 \u7531 COCO \u6570\u636e\u96c6\u524d 128 \u5f20\u56fe\u7247\u7ec4\u6210\u3002 \u8fd9128\u5e45\u56fe\u50cf\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\uff0c\u5224\u65ad yolov5 \u811a\u672c\u662f\u5426\u80fd\u591f\u8fc7\u6b63\u5e38\u8fdb\u884c\u3002 \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6 coco128.yaml \u5b9a\u4e49\u4e86\u5982\u4e0b\u7684\u914d\u7f6e\u9009\u9879\uff1a # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license # COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics # Example usage: python train.py --data coco128.yaml # parent # \u251c\u2500\u2500 one-yolov5 # \u2514\u2500\u2500 datasets # \u2514\u2500\u2500 coco128 \u2190 downloads here (7 MB) # train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/] # \u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u76f8\u540c train: ../coco128/images/train2017/ val: ../coco128/images/train2017/ # number of classes nc: 80 # \u7c7b\u522b\u6570 # class names \u7c7b\u540d\u5217\u8868 names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'] # Download script/URL (optional) \u7528\u4e8e\u81ea\u52a8\u4e0b\u8f7d\u7684\u53ef\u9009\u4e0b\u8f7d\u547d\u4ee4/URL \u3002 download: https://ultralytics.com/assets/coco128.zip \u6ce8\u610f\uff1a\u5982\u679c\u662f\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u7684\u8bdd\u6309\u81ea\u5df1\u9700\u6c42\u4fee\u6539\u8fd9\u4e2ayaml\u6587\u4ef6\u3002\u4e3b\u8981\u4fee\u6539\u4ee5\u4e0b\u4e24\u70b9\u3002 1. \u4fee\u6539\u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u4e3a\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u8def\u5f84 2. \u4fee\u6539\u7c7b\u522b\u6570\u548c\u7c7b\u540d\u5217\u8868 \u518d\u5c55\u793a\u4e00\u4e0b coco.yaml \u7684\u6570\u636e\u96c6\u8def\u5f84\u914d\u7f6e\uff0c\u8fd9\u91cc\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u5c31\u662f\u76f4\u63a5\u7528txt\u8868\u793a\uff1a","title":"1.\u521b\u5efadataset.yaml"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#2-labels","text":"\u4f7f\u7528\u5de5\u5177\u4f8b\u5982 CVAT , makesense.ai , Labelbox \uff0cLabelImg(\u5728\u672c\u7ae0\u5982\u4f55\u5236\u4f5c\u6570\u636e\u96c6\u4e2d\u4ecb\u7ecdLabelImg\u5de5\u5177\u4f7f\u7528) \u7b49\uff0c\u5728\u4f60\u81ea\u5df1\u7684\u6570\u636e\u96c6\u63d0\u4f9b\u7684\u56fe\u7247\u4e0a\u505a\u76ee\u6807\u6846\u7684\u6807\u6ce8\uff0c\u5c06\u6807\u6ce8\u4fe1\u606f\u5bfc\u51fa\u4e3a\u4e00\u4e2atxt\u540e\u7f00\u7ed3\u5c3e\u7684\u6587\u4ef6\u3002\uff08\u5982\u679c\u56fe\u50cf\u4e2d\u6ca1\u6709\u76ee\u6807\uff0c\u5219\u4e0d\u9700\u8981*.txt\u6587\u4ef6\uff09\u3002 *.txt\u6587\u4ef6\u89c4\u8303\u5982\u4e0b\u6240\u793a: - \u6bcf\u4e00\u884c \u4e00\u4e2a\u76ee\u6807\u3002 - \u6bcf\u4e00\u884c\u662f class x_center y_center width height \u683c\u5f0f\u3002 - \u6846\u5750\u6807\u5fc5\u987b\u91c7\u7528\u6807\u51c6\u5316xywh\u683c\u5f0f\uff08\u4ece0\u52301\uff09\u3002\u5982\u679c\u6846\u4ee5\u50cf\u7d20\u4e3a\u5355\u4f4d\uff0c\u5219\u5c06x_center\u548cwidth\u9664\u4ee5\u56fe\u50cf\u5bbd\u5ea6\uff0c\u5c06y_centre\u548cheight\u9664\u4ee5\u56fe\u50cf\u9ad8\u5ea6\u3002 - \u7c7b\u53f7\u4e3a\u96f6\u7d22\u5f15\u7684\u7f16\u53f7\uff08\u4ece0\u5f00\u59cb\u8ba1\u6570\uff09\u3002 **\u8fd9\u91cc\u5047\u8bbe\u4ee5 COCO \u6570\u636e\u96c6\u7684\u76ee\u6807\u7c7b\u522b\u7ea6\u5b9a\u6765\u6807\u6ce8** \u4e0e\u4e0a\u8ff0\u56fe\u50cf\u76f8\u5bf9\u5e94\u7684\u6807\u7b7e\u6587\u4ef6\u5305\u542b2\u4e2a\u4eba\uff08class 0\uff09\u548c \u4e00\u4e2a\u9886\u5e26\uff08class 27\uff09\uff1a","title":"2.\u521b\u5efa Labels"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#3coco128","text":"\u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u4eec\u7684 coco128 \u662f\u4f4d\u4e8e yolov5 \u76ee\u5f55\u9644\u8fd1\u3002yolov5 \u901a\u8fc7\u5c06\u6bcf\u4e2a\u56fe\u50cf\u8def\u5f84 xx/images/xx.jpg \u66ff\u6362\u4e3a xx/labels/xx.txt \u6765\u81ea\u52a8\u5b9a\u4f4d\u6bcf\u4e2a\u56fe\u50cf\u7684\u6807\u7b7e\u3002\u4f8b\u5982\uff1a dataset / images / im0 . jpg # image dataset / labels / im0 . txt # label","title":"3.COCO128 \u6570\u636e\u96c6\u76ee\u5f55\u7ed3\u6784\u7ec4\u7ec7"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_3","text":"","title":"\u5236\u4f5c\u6570\u636e\u96c6"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_4","text":"\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd LabelImg: \u662f\u4e00\u79cd\u77e9\u5f62\u6807\u6ce8\u5de5\u5177\uff0c\u5e38\u7528\u4e8e\u76ee\u6807\u8bc6\u522b\u548c\u76ee\u6807\u68c0\u6d4b,\u53ef\u76f4\u63a5\u751f\u6210 yolov5 \u8bfb\u53d6\u7684txt\u6807\u7b7e\u683c\u5f0f\uff0c\u4f46\u5176\u53ea\u80fd\u8fdb\u884c\u77e9\u5f62\u6846\u6807\u6ce8\u3002(\u5f53\u7136\u4e5f\u53ef\u4ee5\u9009\u7528\u5176\u5b83\u7684\u5de5\u5177\u8fdb\u884c\u6807\u6ce8\u5e76\u4e14\u7f51\u4e0a\u90fd\u6709\u5927\u91cf\u5173\u4e8e\u6807\u6ce8\u5de5\u5177\u7684\u6559\u7a0b\u3002) \u9996\u5148labelimg\u7684\u5b89\u88c5\u5341\u5206\u7b80\u5355\uff0c\u76f4\u63a5\u4f7f\u7528cmd\u4e2d\u7684pip\u8fdb\u884c\u5b89\u88c5\uff0c\u5728cmd\u4e2d\u8f93\u5165\u547d\u4ee4\u884c\uff1a pip install labelimg \u5b89\u88c5\u540e\u76f4\u63a5\u8f93\u5165\u547d\u4ee4\uff1a labelimg \u5373\u53ef\u6253\u5f00\u8fd0\u884c\u3002 \u70b9\u51fbOpen Dir\u9009\u62e9\u6570\u636e\u96c6\u6587\u4ef6\u5939\uff0c\u518d\u70b9\u51fbCreate RectBox\u8fdb\u884c\u6807\u6ce8\u3002 \u5f53\u4f60\u7ed8\u5236\u6846\u7ed3\u675f\u5c31\u4f1a\u5f39\u51fa\u6807\u7b7e\u9009\u62e9\u6846\uff0c\u7136\u540e\u6807\u6ce8\u7c7b\u522b\u3002\u8fd9\u4e2a\u7c7b\u522b\u7f16\u8f91\u66f4\u6539\u5728Labelimg\u6587\u4ef6\u91cc\uff0c\u91cc\u9762\u6709classes.txt\u6587\u6863\uff0c\u6253\u5f00\u624b\u52a8\u66f4\u6539\u7c7b\u522b\u5373\u53ef\u3002\uff08\u5f53\u51fa\u73b0\u65b0\u7c7b\u522b\u65f6\u4e5f\u53ef\u5728\u6807\u7b7e\u9009\u62e9\u6846\u91cc\u8f93\u5165\u70b9OK\u5c31\u81ea\u52a8\u6dfb\u52a0\u7c7b\u522b\u4e86\uff09 \u6807\u6ce8\u597d\u540e\u9009\u62e9 yolo \u683c\u5f0f\uff0c\u70b9\u51fb Save \u4fdd\u5b58\u3002\u6807\u6ce8\u7ed3\u679c\u4fdd\u5b58\u5728 \u56fe\u7247\u540d.txt \u6587\u4ef6\u4e2d\uff0ctxt\u6587\u4ef6\u548c\u56fe\u7247\u540d\u79f0\u4e00\u81f4\uff0c\u5185\u5bb9\u5982\u4e0b\uff1a","title":"\u6570\u636e\u96c6\u6807\u6ce8\u5de5\u5177"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_5","text":"\u6bcf\u4e2a\u7c7b\u7684\u56fe\u50cf\u3002 >= 1500 \u5f20\u56fe\u7247\u3002 \u6bcf\u4e2a\u7c7b\u7684\u5b9e\u4f8b\u3002\u2265 \u5efa\u8bae\u6bcf\u4e2a\u7c7b10000\u4e2a\u5b9e\u4f8b\uff08\u6807\u8bb0\u5bf9\u8c61\uff09 \u56fe\u7247\u5f62\u8c61\u591a\u6837\u3002\u5fc5\u987b\u4ee3\u8868\u5df2\u90e8\u7f72\u7684\u73af\u5883\u3002\u5bf9\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u4f7f\u7528\u6848\u4f8b\uff0c\u6211\u4eec\u63a8\u8350\u6765\u81ea\u4e00\u5929\u4e2d\u4e0d\u540c\u65f6\u95f4\u3001\u4e0d\u540c\u5b63\u8282\u3001\u4e0d\u540c\u5929\u6c14\u3001\u4e0d\u540c\u7167\u660e\u3001\u4e0d\u540c\u89d2\u5ea6\u3001\u4e0d\u540c\u6765\u6e90\uff08\u5728\u7ebf\u91c7\u96c6\u3001\u672c\u5730\u91c7\u96c6\u3001\u4e0d\u540c\u6444\u50cf\u673a\uff09\u7b49\u7684\u56fe\u50cf\u3002 \u6807\u7b7e\u4e00\u81f4\u6027\u3002\u5fc5\u987b\u6807\u8bb0\u6240\u6709\u56fe\u50cf\u4e2d\u6240\u6709\u7c7b\u7684\u6240\u6709\u5b9e\u4f8b\u3002\u90e8\u5206\u6807\u8bb0\u5c06\u4e0d\u8d77\u4f5c\u7528\u3002 \u6807\u7b7e\u51c6\u786e\u6027\u3002 \u6807\u7b7e\u5fc5\u987b\u7d27\u5bc6\u5730\u5305\u56f4\u6bcf\u4e2a\u5bf9\u8c61\u3002\u5bf9\u8c61\u4e0e\u5176\u8fb9\u754c\u6846\u4e4b\u95f4\u4e0d\u5e94\u5b58\u5728\u4efb\u4f55\u7a7a\u95f4\u3002\u4efb\u4f55\u5bf9\u8c61\u90fd\u4e0d\u5e94\u7f3a\u5c11\u6807\u7b7e\u3002 \u6807\u7b7e\u9a8c\u8bc1\u3002\u67e5\u770btrain_batch .jpg \u5728 \u8bad\u7ec3\u5f00\u59cb\u9a8c\u8bc1\u6807\u7b7e\u662f\u5426\u6b63\u786e\uff0c\u5373\u53c2\u89c1 mosaic \uff08\u5728 yolov5 \u7684\u8bad\u7ec3\u65e5\u5fd7 runs/train/exp \u6587\u4ef6\u5939\u91cc\u9762\u53ef\u4ee5\u770b\u5230\uff09\u3002 \u80cc\u666f\u56fe\u50cf\u3002\u80cc\u666f\u56fe\u50cf\u662f\u6ca1\u6709\u6dfb\u52a0\u5230\u6570\u636e\u96c6\u4ee5\u51cf\u5c11 False Positives\uff08FP\uff09\u7684\u5bf9\u8c61\u7684\u56fe\u50cf\u3002\u6211\u4eec\u5efa\u8bae\u4f7f\u7528\u5927\u7ea60-10%\u7684\u80cc\u666f\u56fe\u50cf\u6765\u5e2e\u52a9\u51cf\u5c11FPs\uff08COCO\u67091000\u4e2a\u80cc\u666f\u56fe\u50cf\u4f9b\u53c2\u8003\uff0c\u5360\u603b\u6570\u76841%\uff09\u3002\u80cc\u666f\u56fe\u50cf\u4e0d\u9700\u8981\u6807\u7b7e\u3002 \u4e0b\u56fe\u5c55\u793a\u4e86\u591a\u79cd\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7279\u70b9\uff1a \u5176\u4e2d\uff1a Instances per category \u8868\u793a\u6bcf\u4e2a\u7c7b\u522b\u7684\u5b9e\u4f8b\u6570 Categories per image \u8868\u793a\u6bcf\u5e45\u56fe\u50cf\u7684\u7c7b\u522b (a) Instances per image \u8868\u793a\u6bcf\u5e45\u56fe\u50cf\u7684\u5b9e\u4f8b\u6570 (b) Number of categories vs. number of instances \u8868\u793a\u7c7b\u522b\u6570\u76ee vs \u5b9e\u4f8b\u6570\u76ee \uff08\u6211\u4eec\u53ef\u4ee5\u770b\u5230 COCO \u6570\u636e\u96c6\u7684\u7c7b\u522b\u548c\u5b9e\u4f8b\u7684\u6570\u76ee\u8fbe\u5230\u4e86\u4e00\u4e2a\u8f83\u597d\u7684\u5e73\u8861\uff09 (c) Instance size \u8868\u793a\u5b9e\u4f8b\u4e2a\u6570 (d) Number of categories \u8868\u793a\u7c7b\u522b\u6570 (e) Percent of image size \u8868\u793a\u56fe\u50cf\u5927\u5c0f\u767e\u5206\u6bd4","title":"\u4e00\u4e2a\u597d\u7684\u6570\u636e\u96c6\u6807\u51c6\uff1f"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_6","text":"https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results https://docs.ultralytics.com/tutorials/train-custom-datasets/#weights-biases-logging-new","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/03_chapter/TTA.html","text":"\u6d4b\u8bd5\u65f6\u6570\u636e\u589e\u5f3a \ud83d\ude80 \ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5728YOLOv5\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u63a8\u7406\u4e2d\u5982\u4f55\u4f7f\u7528 Test Time Augmentation (TTA) \u63d0\u9ad8mAP\u548cRecall \ud83d\ude80\u3002 \ud83d\udccc\u5f00\u59cb\u4e4b\u524d \u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install \ud83d\udccc\u666e\u901a\u6d4b\u8bd5 \u5728\u5c1d\u8bd5 TTA \u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u80fd\u591f\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u547d\u4ee4\u5728COCO val2017\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5YOLOv5x\u3002 yolov5x \u662f\u53ef\u7528\u7684\u6700\u5927\u5e76\u4e14\u6700\u7cbe\u786e\u7684\u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u7684\u662f yolov5s , yolov5m \u548c yolov5l \u6216\u8005 \u81ea\u5df1\u4ece\u6570\u636e\u96c6\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u3002 ./weights/best \u3002\u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 READEME table $ python val . py -- weights yolov5x -- data coco . yaml -- img 640 -- half \ud83d\udce2 \u8f93\u51fa: val: data = data/coco.yaml, weights =[ 'yolov5x' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = True, dnn = False YOLOv5 \ud83d\ude80 v1.0-8-g94ec5c4 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 01 :55< 00 :00, 1 .36it/ all 5000 36335 0 .743 0 .627 0 .685 0 .503 Speed: 0 .1ms pre-process, 7 .5ms inference, 2 .1ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json... ... Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0 .50 | area = all | maxDets = 100 ] = 0 .689 Average Precision ( AP ) @ [ IoU = 0 .75 | area = all | maxDets = 100 ] = 0 .545 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .339 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .557 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .650 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 1 ] = 0 .382 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 10 ] = 0 .628 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .523 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .730 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .826 \ud83d\udcccTTA\u6d4b\u8bd5 \u5728val.py \u540e\u9644\u52a0 --augment \u9009\u9879\u542f\u7528TTA\u3002( \u5c06\u56fe\u50cf\u5927\u5c0f\u589e\u52a0\u7ea630%\u5de6\u53f3\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7ed3\u679c\u54e6 \ud83d\ude80)\u3002 \u2757\u8bf7\u6ce8\u610f: \u542f\u7528TTA\u7684\u63a8\u65ad\u901a\u5e38\u9700\u8981\u6b63\u5e38\u63a8\u65ad\u65f6\u95f4\u76842-3\u500d\uff0c\u56e0\u4e3a\u56fe\u50cf\u5de6\u53f3\u7ffb\u8f6c\u5e76\u4ee53\u79cd\u4e0d\u540c\u5206\u8fa8\u7387\u5904\u7406\uff0c\u8f93\u51fa\u5728NMS\u4e4b\u524d\u5408\u5e76\u3002 \u901f\u5ea6\u4e0b\u964d\u7684\u90e8\u5206\u539f\u56e0\u662f\u56fe\u50cf\u5c3a\u5bf8\u8f83\u5927\uff08832 vs 640\uff09\uff0c\u5f53\u7136\u4e5f\u6709\u90e8\u5206\u539f\u56e0\u662f TTA \u64cd\u4f5c\u9020\u6210\u7684\u3002 $ python val . py -- weights yolov5x -- data coco . yaml -- img 832 -- augment -- half \u8f93\u51fa: ( python3 .8 ) fengwen @oneflow - 25 : ~/ one - yolov5 $ python val . py -- weights yolov5x -- data data / coco . yaml -- img 832 -- augment -- half loaded library : / lib / x86_64 - linux - gnu / libibverbs . so .1 val : data = data / coco . yaml , weights = [ 'yolov5x' ], batch_size = 32 , imgsz = 832 , conf_thres = 0.001 , iou_thres = 0.6 , task = val , device = , workers = 8 , single_cls = False , augment = True , verbose = False , save_txt = False , save_hybrid = False , save_conf = False , save_json = True , project = runs / val , name = exp , exist_ok = False , half = True , dnn = False YOLOv5 \ud83d\ude80 v1 .0 - 31 - g6b1387c Python - 3.8.13 oneflow - 0.8.1 . dev20221021 + cu112 Fusing layers ... Model summary : 322 layers , 86705005 parameters , 571965 gradients val : Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels ... 4952 found , 48 missing , 0 empty , 0 corrupt : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | Class Images Labels P R mAP @ .5 mAP @ .5 : .95 : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 / 157 [ 04 : 39 < 00 : 00 , 1.78 s / it ] all 5000 36335 0.743 0.645 0.7 0.518 Speed : 0.1 ms pre - process , 40.6 ms inference , 2.2 ms NMS per image at shape ( 32 , 3 , 832 , 832 ) Evaluating pycocotools mAP ... saving runs / val / exp / yolov5x_predictions . json ... ... Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.519 # <--- TTA mAP Average Precision ( AP ) @ [ IoU = 0.50 | area = all | maxDets = 100 ] = 0.704 Average Precision ( AP ) @ [ IoU = 0.75 | area = all | maxDets = 100 ] = 0.564 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.358 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.565 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.662 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 1 ] = 0.389 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 10 ] = 0.645 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.698 # <--- TTA mAR Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.556 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.745 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.837 \ud83d\udce2 \u58f0\u660e:\u4e0a\u8ff0\u4e24\u6b21\u6d4b\u8bd5\u7684mAP\uff0cmAR\u7ed3\u679c\u5982\u4e0b\uff1a | | mAP | mAR | |----------|-------|-------| | baseline | 0.505 | 0.677 | | TTA | 0.519 | 0.698 | \ud83d\udcccTTA\u63a8\u7406 \u5728 detect.py \u4e2d\u4f7f\u7528 TTA \u7684\u64cd\u4f5c\u4e0e val.py \u4e2d\u4f7f\u7528TTA\u76f8\u540c\uff1a\u53ea\u9700\u5c06\u5176\u9644\u52a0 --augment \u5230\u4efb\u4f55\u73b0\u6709\u68c0\u6d4b\u4efb\u52a1\u4e2d\u3002 detect.py \u6307\u4ee4\u300c\u6848\u4f8b\ud83c\udf30\u300d: $ python detect . py -- weights yolov5s -- img 832 -- source data / images -- augment \u8f93\u51fa: loaded library: /lib/x86_64-linux-gnu/libibverbs.so.1 detect: weights=['yolov5x'], source=data/images/, data=data/coco128.yaml, imgsz=[832, 832], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=True, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 v1.0-31-g6b1387c Python-3.8.13 oneflow-0.8.1.dev20221021+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/fengwen/one-yolov5/data/images/bus.jpg: 832x640 4 persons, 1 bicycle, 1 bus, Done. (0.057s) detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 2/2 /home/fengwen/one-yolov5/data/images/zidane.jpg: 480x832 3 persons, 2 ties, Done. (0.041s) 0.5ms pre-process, 48.6ms inference, 2.1ms NMS per image at shape (1, 3, 832, 832) OneFlow Hub TTA TTA\u81ea\u52a8\u96c6\u6210\u5230\u6240\u6709YOLOv5 OneFlow Hub\u6a21\u578b\u4e2d\uff0c\u5e76\u53ef\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u4f20\u9012 augment=True \u53c2\u6570\u8fdb\u884c\u5f00\u542f\u3002 import oneflow as flow # \u6a21\u578b model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # or yolov5n - yolov5x6, custom # \u56fe\u50cf img = 'https://raw.githubusercontent.com/Oneflow-Inc/one-yolov5/main/data/images/zidane.jpg' # or file, Path, PIL, OpenCV, numpy, list # \u63a8\u7406 results = model ( img ) # \u7ed3\u679c results . print () # or .show(), .save(), .crop(), .pandas(), etc. \u81ea\u5b9a\u4e49 \u6211\u4eec\u53ef\u4ee5\u81ea\u5b9a\u4e49TTA\u64cd\u4f5c\u5728 YOLOv5 forward_augment() \u65b9\u6cd5\u4e2d, \u5e94\u7528\u7684TTA\u64cd\u4f5c\u7ec6\u8282\u5177\u4f53\u53ef\u89c1\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/bbdf286ad1b1d3fd2c82cecdfa4487db423d9cfe/models/yolo.py#L141-L153 \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/issues/303","title":"3.4  \u6d4b\u8bd5\u65f6\u589e\u5f3a (TTA)"},{"location":"tutorials/03_chapter/TTA.html#_1","text":"\ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5728YOLOv5\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u63a8\u7406\u4e2d\u5982\u4f55\u4f7f\u7528 Test Time Augmentation (TTA) \u63d0\u9ad8mAP\u548cRecall \ud83d\ude80\u3002","title":"\u6d4b\u8bd5\u65f6\u6570\u636e\u589e\u5f3a \ud83d\ude80"},{"location":"tutorials/03_chapter/TTA.html#_2","text":"\u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install","title":"\ud83d\udccc\u5f00\u59cb\u4e4b\u524d"},{"location":"tutorials/03_chapter/TTA.html#_3","text":"\u5728\u5c1d\u8bd5 TTA \u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u80fd\u591f\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u547d\u4ee4\u5728COCO val2017\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5YOLOv5x\u3002 yolov5x \u662f\u53ef\u7528\u7684\u6700\u5927\u5e76\u4e14\u6700\u7cbe\u786e\u7684\u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u7684\u662f yolov5s , yolov5m \u548c yolov5l \u6216\u8005 \u81ea\u5df1\u4ece\u6570\u636e\u96c6\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u3002 ./weights/best \u3002\u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 READEME table $ python val . py -- weights yolov5x -- data coco . yaml -- img 640 -- half \ud83d\udce2 \u8f93\u51fa: val: data = data/coco.yaml, weights =[ 'yolov5x' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = True, dnn = False YOLOv5 \ud83d\ude80 v1.0-8-g94ec5c4 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 01 :55< 00 :00, 1 .36it/ all 5000 36335 0 .743 0 .627 0 .685 0 .503 Speed: 0 .1ms pre-process, 7 .5ms inference, 2 .1ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json... ... Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0 .50 | area = all | maxDets = 100 ] = 0 .689 Average Precision ( AP ) @ [ IoU = 0 .75 | area = all | maxDets = 100 ] = 0 .545 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .339 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .557 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .650 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 1 ] = 0 .382 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 10 ] = 0 .628 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .523 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .730 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .826","title":"\ud83d\udccc\u666e\u901a\u6d4b\u8bd5"},{"location":"tutorials/03_chapter/TTA.html#tta","text":"\u5728val.py \u540e\u9644\u52a0 --augment \u9009\u9879\u542f\u7528TTA\u3002( \u5c06\u56fe\u50cf\u5927\u5c0f\u589e\u52a0\u7ea630%\u5de6\u53f3\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7ed3\u679c\u54e6 \ud83d\ude80)\u3002 \u2757\u8bf7\u6ce8\u610f: \u542f\u7528TTA\u7684\u63a8\u65ad\u901a\u5e38\u9700\u8981\u6b63\u5e38\u63a8\u65ad\u65f6\u95f4\u76842-3\u500d\uff0c\u56e0\u4e3a\u56fe\u50cf\u5de6\u53f3\u7ffb\u8f6c\u5e76\u4ee53\u79cd\u4e0d\u540c\u5206\u8fa8\u7387\u5904\u7406\uff0c\u8f93\u51fa\u5728NMS\u4e4b\u524d\u5408\u5e76\u3002 \u901f\u5ea6\u4e0b\u964d\u7684\u90e8\u5206\u539f\u56e0\u662f\u56fe\u50cf\u5c3a\u5bf8\u8f83\u5927\uff08832 vs 640\uff09\uff0c\u5f53\u7136\u4e5f\u6709\u90e8\u5206\u539f\u56e0\u662f TTA \u64cd\u4f5c\u9020\u6210\u7684\u3002 $ python val . py -- weights yolov5x -- data coco . yaml -- img 832 -- augment -- half \u8f93\u51fa: ( python3 .8 ) fengwen @oneflow - 25 : ~/ one - yolov5 $ python val . py -- weights yolov5x -- data data / coco . yaml -- img 832 -- augment -- half loaded library : / lib / x86_64 - linux - gnu / libibverbs . so .1 val : data = data / coco . yaml , weights = [ 'yolov5x' ], batch_size = 32 , imgsz = 832 , conf_thres = 0.001 , iou_thres = 0.6 , task = val , device = , workers = 8 , single_cls = False , augment = True , verbose = False , save_txt = False , save_hybrid = False , save_conf = False , save_json = True , project = runs / val , name = exp , exist_ok = False , half = True , dnn = False YOLOv5 \ud83d\ude80 v1 .0 - 31 - g6b1387c Python - 3.8.13 oneflow - 0.8.1 . dev20221021 + cu112 Fusing layers ... Model summary : 322 layers , 86705005 parameters , 571965 gradients val : Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels ... 4952 found , 48 missing , 0 empty , 0 corrupt : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | Class Images Labels P R mAP @ .5 mAP @ .5 : .95 : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 / 157 [ 04 : 39 < 00 : 00 , 1.78 s / it ] all 5000 36335 0.743 0.645 0.7 0.518 Speed : 0.1 ms pre - process , 40.6 ms inference , 2.2 ms NMS per image at shape ( 32 , 3 , 832 , 832 ) Evaluating pycocotools mAP ... saving runs / val / exp / yolov5x_predictions . json ... ... Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.519 # <--- TTA mAP Average Precision ( AP ) @ [ IoU = 0.50 | area = all | maxDets = 100 ] = 0.704 Average Precision ( AP ) @ [ IoU = 0.75 | area = all | maxDets = 100 ] = 0.564 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.358 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.565 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.662 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 1 ] = 0.389 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 10 ] = 0.645 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.698 # <--- TTA mAR Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.556 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.745 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.837 \ud83d\udce2 \u58f0\u660e:\u4e0a\u8ff0\u4e24\u6b21\u6d4b\u8bd5\u7684mAP\uff0cmAR\u7ed3\u679c\u5982\u4e0b\uff1a | | mAP | mAR | |----------|-------|-------| | baseline | 0.505 | 0.677 | | TTA | 0.519 | 0.698 |","title":"\ud83d\udcccTTA\u6d4b\u8bd5"},{"location":"tutorials/03_chapter/TTA.html#tta_1","text":"\u5728 detect.py \u4e2d\u4f7f\u7528 TTA \u7684\u64cd\u4f5c\u4e0e val.py \u4e2d\u4f7f\u7528TTA\u76f8\u540c\uff1a\u53ea\u9700\u5c06\u5176\u9644\u52a0 --augment \u5230\u4efb\u4f55\u73b0\u6709\u68c0\u6d4b\u4efb\u52a1\u4e2d\u3002 detect.py \u6307\u4ee4\u300c\u6848\u4f8b\ud83c\udf30\u300d: $ python detect . py -- weights yolov5s -- img 832 -- source data / images -- augment \u8f93\u51fa: loaded library: /lib/x86_64-linux-gnu/libibverbs.so.1 detect: weights=['yolov5x'], source=data/images/, data=data/coco128.yaml, imgsz=[832, 832], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=True, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 v1.0-31-g6b1387c Python-3.8.13 oneflow-0.8.1.dev20221021+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/fengwen/one-yolov5/data/images/bus.jpg: 832x640 4 persons, 1 bicycle, 1 bus, Done. (0.057s) detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 2/2 /home/fengwen/one-yolov5/data/images/zidane.jpg: 480x832 3 persons, 2 ties, Done. (0.041s) 0.5ms pre-process, 48.6ms inference, 2.1ms NMS per image at shape (1, 3, 832, 832)","title":"\ud83d\udcccTTA\u63a8\u7406"},{"location":"tutorials/03_chapter/TTA.html#oneflow-hub-tta","text":"TTA\u81ea\u52a8\u96c6\u6210\u5230\u6240\u6709YOLOv5 OneFlow Hub\u6a21\u578b\u4e2d\uff0c\u5e76\u53ef\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u4f20\u9012 augment=True \u53c2\u6570\u8fdb\u884c\u5f00\u542f\u3002 import oneflow as flow # \u6a21\u578b model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # or yolov5n - yolov5x6, custom # \u56fe\u50cf img = 'https://raw.githubusercontent.com/Oneflow-Inc/one-yolov5/main/data/images/zidane.jpg' # or file, Path, PIL, OpenCV, numpy, list # \u63a8\u7406 results = model ( img ) # \u7ed3\u679c results . print () # or .show(), .save(), .crop(), .pandas(), etc.","title":"OneFlow Hub TTA"},{"location":"tutorials/03_chapter/TTA.html#_4","text":"\u6211\u4eec\u53ef\u4ee5\u81ea\u5b9a\u4e49TTA\u64cd\u4f5c\u5728 YOLOv5 forward_augment() \u65b9\u6cd5\u4e2d, \u5e94\u7528\u7684TTA\u64cd\u4f5c\u7ec6\u8282\u5177\u4f53\u53ef\u89c1\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/bbdf286ad1b1d3fd2c82cecdfa4487db423d9cfe/models/yolo.py#L141-L153","title":"\u81ea\u5b9a\u4e49"},{"location":"tutorials/03_chapter/TTA.html#_5","text":"https://github.com/ultralytics/yolov5/issues/303","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html","text":"\ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5982\u4f55\u4ece OneFlow Hub \u52a0\u8f7d one-yolov5 \u3002\ud83d\ude80 \u5f00\u59cb\u4e4b\u524d \u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 \u6240\u9700\u7684\u4f9d\u8d56\u5e93 , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u4e0d\u9700\u8981\u514b\u9686 https://github.com/Oneflow-Inc/one-yolov5 \u4f7f\u7528 OneFlow Hub \u52a0\u8f7d one-yolov5 \u7b80\u5355\u7684\u4f8b\u5b50 \u6b64\u793a\u4f8b\u4ece OneFlow Hub \u52a0\u8f7d\u9884\u8bad\u7ec3\u7684 YOLOv5s \u6a21\u578b\u4f5c\u4e3a model \uff0c\u5e76\u4f20\u4e00\u5f20\u56fe\u50cf\u8fdb\u884c\u63a8\u7406\u3002 yolov5s \u662f\u6700\u8f7b\u3001\u6700\u5feb\u7684 YOLOv5 \u6a21\u578b\u3002 \u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 README \u3002 import oneflow as flow # \u6a21\u578b model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # or yolov5n - yolov5x6, custom # \u56fe\u50cf img = 'https://raw.githubusercontent.com/Oneflow-Inc/one-yolov5/main/data/images/zidane.jpg' # or file, Path, PIL, OpenCV, numpy, list # \u63a8\u7406 results = model ( img ) # \u7ed3\u679c results . print () # or .show(), .save(), .crop(), .pandas(), etc. print ( results . pandas () . xyxy [ 0 ]) xmin ymin xmax ymax confidence class name 0 743.290649 48.343842 1141.756348 720.000000 0.879861 0 person 1 441.989624 437.336670 496.585083 710.036255 0.675118 27 tie 2 123.051117 193.237976 714.690674 719.771362 0.666694 0 person 3 978.989807 313.579468 1025.302856 415.526184 0.261517 27 tie \u66f4\u7ec6\u8282\u7684\u4f8b\u5b50 \u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4e86\u4f7f\u7528 PIL \u548c OpenCV \u5206\u522b\u4f5c\u4e3a\u56fe\u50cf\u6e90\u7684\u6279\u91cf\u63a8\u7406\u3002 result \u53ef\u4ee5\u6253\u5370\u5230\u63a7\u5236\u53f0\uff0c\u4fdd\u5b58\u5230 runs/hub , \u5728\u652f\u6301\u7684\u73af\u5883\u4e2d\u663e\u793a\u5230\u5c4f\u5e55\u4e0a\uff0c\u5e76\u4f5c\u4e3a\u5f20\u91cf\u6216 pandas \u6570\u636e\u8fd4\u56de\u3002 import cv2 import oneflow as flow from PIL import Image # Model model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # Images for f in 'zidane.jpg' , 'bus.jpg' : flow . hub . download_url_to_file ( 'https://ultralytics.com/images/' + f , f ) # download 2 images im1 = Image . open ( 'zidane.jpg' ) # PIL image im2 = cv2 . imread ( 'bus.jpg' )[ ... , :: - 1 ] # OpenCV image (BGR to RGB) # Inference results = model ([ im1 , im2 ], size = 640 ) # batch of images # Results results . print () results . save () # or .show() results . xyxy [ 0 ] # im1 predictions (tensor) print ( results . pandas () . xyxy [ 0 ]) # im1 predictions (pandas) \u5bf9\u4e8e\u6240\u6709\u63a8\u7406\u9009\u9879\uff0c\u8bf7\u53c2\u9605 YOLOv5 AutoShape() forward\u65b9\u6cd5 \u3002 \u63a8\u7406\u8bbe\u7f6e YOLOv5 \u6a21\u578b\u5305\u542b\u5404\u79cd\u63a8\u7406\u5c5e\u6027\uff0c\u4f8b\u5982\u7f6e\u4fe1\u5ea6\u9608\u503c\u3001IoU \u9608\u503c\u7b49\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u8bbe\u7f6e\uff1a model . conf = 0.25 # NMS confidence threshold iou = 0.45 # NMS IoU threshold agnostic = False # NMS class-agnostic multi_label = False # NMS multiple labels per box classes = None # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs max_det = 1000 # maximum number of detections per image amp = False # Automatic Mixed Precision (AMP) inference results = model ( im , size = 320 ) # custom inference size \u8bbe\u5907 \u6a21\u578b\u521b\u5efa\u540e\u53ef\u4ee5\u8fc1\u79fb\u5230\u4efb\u610f\u8bbe\u5907\u4e0a model . cpu () # CPU model . cuda () # GPU model . to ( device ) # i.e. device=flow.device(0) \u6a21\u578b\u4e5f\u53ef\u4ee5\u5728\u4efb\u610f device \u4e0a\u76f4\u63a5\u521b\u5efa\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 'cpu' ) # load on CPU \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a \u5728\u63a8\u7406\u4e4b\u524d\uff0c\u8f93\u5165\u56fe\u50cf\u4e5f\u4f1a\u81ea\u52a8\u4f20\u8f93\u5230\u6a21\u578b\u6240\u5728\u7684\u8bbe\u5907\u4e0a\u3002 \u9759\u97f3\u8f93\u51fa \u4f7f\u7528 _verbose=False ,\u6a21\u578b\u53ef\u4ee5\u88ab\u9759\u97f3\u7684\u52a0\u8f7d\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , _verbose = False ) # load silently \u8f93\u5165\u901a\u9053 model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , channels = 4 ) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9664\u4e86\u7b2c\u4e00\u4e2a\u8f93\u5165\u5c42\u5916\u5c06\u7531\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u7ec4\u6210\uff0c\u5b83\u4e0d\u518d\u4e0e\u9884\u8bad\u7ec3\u7684\u8f93\u5165\u5c42\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u3002 \u8f93\u5165\u5c42\u5c06\u4fdd\u6301\u7531\u968f\u673a\u6743\u91cd\u521d\u59cb\u5316\u3002 \u7c7b\u522b\u6570 \u8981\u52a0\u8f7d\u5177\u6709 10 \u4e2a\u8f93\u51fa\u7c7b\u800c\u4e0d\u662f\u9ed8\u8ba4\u7684 80 \u4e2a\u8f93\u51fa\u7c7b\u7684\u9884\u8bad\u7ec3 YOLOv5s \u6a21\u578b\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , classes = 10 ) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9664\u4e86\u8f93\u51fa\u5c42\u5c06\u7531\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u7ec4\u6210\uff0c\u5b83\u4eec\u4e0d\u518d\u4e0e\u9884\u8bad\u7ec3\u7684\u8f93\u51fa\u5c42\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u3002 \u8f93\u51fa\u5c42\u5c06\u4fdd\u6301\u7531\u968f\u673a\u6743\u91cd\u521d\u59cb\u5316\u3002 \u5f3a\u5236\u91cd\u65b0\u52a0\u8f7d \u5982\u679c\u60a8\u5728\u4e0a\u8ff0\u6b65\u9aa4\u4e2d\u9047\u5230\u95ee\u9898\uff0c\u8bbe\u7f6e force_reload=True \u53ef\u80fd\u6709\u52a9\u4e8e\u4e22\u5f03\u73b0\u6709\u7f13\u5b58\u5e76\u5f3a\u5236\u4ece OneFlow Hub \u91cd\u65b0\u4e0b\u8f7d\u6700\u65b0\u7684 YOLOv5 \u7248\u672c\u3002 \u622a\u56fe\u63a8\u7406 \u8981\u5728\u684c\u9762\u5c4f\u5e55\u4e0a\u8fd0\u884c\u63a8\u7406\uff1a import oneflow as flow from PIL import ImageGrab # Model model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , _verbose = False ) # Image im = ImageGrab . grab () # take a screenshot # Inference results = model ( im ) \u591a GPU \u63a8\u7406 YOLOv5 \u6a21\u578b\u53ef\u4ee5\u52a0\u8f7d\u5230\u591a\u4e2a GPU \u5b9e\u73b0\u591a\u7ebf\u7a0b\u63a8\u7406\uff1a import oneflow as flow import threading def run ( model , im ): results = model ( im ) results . save () # Models model0 = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 0 ) model1 = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 1 ) # Inference threading . Thread ( target = run , args = [ model0 , 'https://ultralytics.com/images/zidane.jpg' ], daemon = True ) . start () threading . Thread ( target = run , args = [ model1 , 'https://ultralytics.com/images/bus.jpg' ], daemon = True ) . start () \u8bad\u7ec3 \u8981\u52a0\u8f7d YOLOv5 \u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u800c\u4e0d\u662f\u63a8\u7406\uff0c\u8bf7\u8bbe\u7f6e autoshape=False\u3002 \u8981\u52a0\u8f7d\u5177\u6709\u968f\u673a\u521d\u59cb\u5316\u6743\u91cd\u7684\u6a21\u578b\uff08\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\uff09\uff0c\u8bf7\u4f7f\u7528 pretrained=False\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u60a8\u5fc5\u987b\u63d0\u4f9b\u81ea\u5df1\u7684\u8bad\u7ec3\u811a\u672c\u3002 \u6216\u8005\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 YOLOv5 \u8bad\u7ec3\u81ea\u5b9a\u4e49\u6570\u636e\u6559\u7a0b \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , autoshape = False ) # load pretrained model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , autoshape = False , pretrained = False ) # load scratch Base64 \u7ed3\u679c \u7528\u4e8e API \u670d\u52a1\u3002 \u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 #2291 \u548c Flask REST API \u793a\u4f8b\u3002 results = model ( im ) # inference results . ims # array of original images (as np array) passed to model for inference results . render () # updates results.ims with boxes and labels for im in results . ims : buffered = BytesIO () im_base64 = Image . fromarray ( im ) im_base64 . save ( buffered , format = \"JPEG\" ) print ( base64 . b64encode ( buffered . getvalue ()) . decode ( 'utf-8' )) # base64 encoded image with results \u88c1\u526a\u7ed3\u679c \u8fd4\u56de\u7684\u68c0\u6d4b\u7ed3\u679c\u53ef\u4ee5\u88ab\u88c1\u526a\uff1a results = model ( im ) # inference crops = results . crop ( save = True ) # cropped detections dictionary Pandas \u7ed3\u679c \u7ed3\u679c\u53ef\u4ee5\u4f5c\u4e3a Pandas DataFrames \u8fd4\u56de\uff1a results = model ( im ) # inference results . pandas () . xyxy [ 0 ] # Pandas DataFrame Pandas\u8f93\u51fa\uff08\u70b9\u51fb\u5c55\u5f00\uff09 print(results.pandas().xyxy[0]) xmin ymin xmax ymax confidence class name 0 743.290649 48.343842 1141.756348 720.000000 0.879861 0 person 1 441.989624 437.336670 496.585083 710.036255 0.675118 27 tie 2 123.051117 193.237976 714.690674 719.771362 0.666694 0 person 3 978.989807 313.579468 1025.302856 415.526184 0.261517 27 tie \u6392\u5e8f\u540e\u7684\u7ed3\u679c \u7ed3\u679c\u53ef\u4ee5\u6309\u5217\u6392\u5e8f\uff0c\u4f8b\u5982\u4ece\u5de6\u5230\u53f3\uff08x\u8f74\uff09\u5bf9\u8f66\u724c\u6570\u5b57\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u6392\u5e8f\uff1a results = model ( im ) # inference results . pandas () . xyxy [ 0 ] . sort_values ( 'xmin' ) # sorted left-right Box-Cropped \u7ed3\u679c \u7ed3\u679c\u53ef\u4ee5\u8fd4\u56de\u5e76\u4fdd\u5b58\u4e3a detection crops\uff1a results = model ( im ) # inference crops = results . crop ( save = True ) # cropped detections dictionary JSON \u7ed3\u679c \u7ed3\u679c\u4e00\u65e6\u4f7f\u7528 .pandas \u88ab\u4fdd\u5b58\u4e3a pandas \u6570\u636e\u683c\u5f0f\uff0c\u5c31\u53ef\u4ee5\u518d\u4f7f\u7528 .to_json() \u65b9\u6cd5\u4fdd\u5b58\u4e3a JSON \u683c\u5f0f\u3002\u53ef\u4ee5\u4f7f\u7528 orient \u53c2\u6570\u4fee\u6539 JSON \u683c\u5f0f\u3002\u8bf7\u67e5\u770b pandas \u7684 .to_json() \u65b9\u6cd5\u7684 \u6587\u6863 \u4e86\u89e3\u7ec6\u8282\u3002 results = model ( ims ) # inference results . pandas () . xyxy [ 0 ] . to_json ( orient = \"records\" ) # JSON img1 predictions Json\u8f93\u51fa\uff08\u70b9\u51fb\u5c55\u5f00\uff09 [{\"xmin\":743.2906494141,\"ymin\":48.3438415527,\"xmax\":1141.7563476562,\"ymax\":720.0,\"confidence\":0.87986058,\"class\":0,\"name\":\"person\"},{\"xmin\":441.9896240234,\"ymin\":437.3366699219,\"xmax\":496.5850830078,\"ymax\":710.0362548828,\"confidence\":0.6751183867,\"class\":27,\"name\":\"tie\"},{\"xmin\":123.0511169434,\"ymin\":193.2379760742,\"xmax\":714.6906738281,\"ymax\":719.7713623047,\"confidence\":0.6666944027,\"class\":0,\"name\":\"person\"},{\"xmin\":978.9898071289,\"ymin\":313.5794677734,\"xmax\":1025.3028564453,\"ymax\":415.526184082,\"confidence\":0.2615173161,\"class\":27,\"name\":\"tie\"}] \u81ea\u5b9a\u4e49\u6a21\u578b \u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4f7f\u7528 OneFlow Hub \u52a0\u8f7d\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684\u5728VOC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u768420\u4e2a\u7c7b\u522b\u7684 YOLOV5s \u6a21\u578b best \u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'custom' , path = 'path/to/best' ) # local model model = oneflow . hub . load ( '/path/to/one-yolov5' , 'custom' , path = 'path/to/best' ) # local repo TensorRT, ONNX \u548c OpenVINO \u6a21\u578b OneFlow Hub \u652f\u6301\u5bf9\u5927\u591a\u6570 YOLOv5 \u5bfc\u51fa\u683c\u5f0f\u8fdb\u884c\u63a8\u7406\uff0c\u5305\u62ec\u81ea\u5b9a\u4e49\u8bad\u7ec3\u6a21\u578b\u3002\u67e5\u770b TFLite, ONNX, CoreML, TensorRT \u6a21\u578b\u5bfc\u51fa\u6559\u7a0b \u67e5\u770b\u7ec6\u8282\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u5728 GPU benchmarks \u4e0a TensorRT \u53ef\u80fd\u6bd4PyTorch\u5feb3-5\u500d\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u5728 CPU benchmarks \u4e0a ONNX \u548c OpenVINO \u53ef\u80fd\u6bd4 PyTorch \u5feb2-3\u500d\u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'custom' , path = 'yolov5s/' ) # OneFlow 'yolov5s.onnx' ) # ONNX 'yolov5s_openvino_model/' ) # OpenVINO 'yolov5s.engine' ) # TensorRT 'yolov5s.mlmodel' ) # CoreML (macOS-only) 'yolov5s.tflite' ) # TFLite \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/issues/36","title":"3.2. \u4eceOneFlow Hub \u52a0\u8f7dYOLOv5"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_1","text":"\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 \u6240\u9700\u7684\u4f9d\u8d56\u5e93 , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u4e0d\u9700\u8981\u514b\u9686 https://github.com/Oneflow-Inc/one-yolov5","title":"\u5f00\u59cb\u4e4b\u524d"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#oneflow-hub-one-yolov5","text":"","title":"\u4f7f\u7528 OneFlow Hub \u52a0\u8f7d one-yolov5"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_2","text":"\u6b64\u793a\u4f8b\u4ece OneFlow Hub \u52a0\u8f7d\u9884\u8bad\u7ec3\u7684 YOLOv5s \u6a21\u578b\u4f5c\u4e3a model \uff0c\u5e76\u4f20\u4e00\u5f20\u56fe\u50cf\u8fdb\u884c\u63a8\u7406\u3002 yolov5s \u662f\u6700\u8f7b\u3001\u6700\u5feb\u7684 YOLOv5 \u6a21\u578b\u3002 \u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 README \u3002 import oneflow as flow # \u6a21\u578b model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # or yolov5n - yolov5x6, custom # \u56fe\u50cf img = 'https://raw.githubusercontent.com/Oneflow-Inc/one-yolov5/main/data/images/zidane.jpg' # or file, Path, PIL, OpenCV, numpy, list # \u63a8\u7406 results = model ( img ) # \u7ed3\u679c results . print () # or .show(), .save(), .crop(), .pandas(), etc. print ( results . pandas () . xyxy [ 0 ]) xmin ymin xmax ymax confidence class name 0 743.290649 48.343842 1141.756348 720.000000 0.879861 0 person 1 441.989624 437.336670 496.585083 710.036255 0.675118 27 tie 2 123.051117 193.237976 714.690674 719.771362 0.666694 0 person 3 978.989807 313.579468 1025.302856 415.526184 0.261517 27 tie","title":"\u7b80\u5355\u7684\u4f8b\u5b50"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_3","text":"\u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4e86\u4f7f\u7528 PIL \u548c OpenCV \u5206\u522b\u4f5c\u4e3a\u56fe\u50cf\u6e90\u7684\u6279\u91cf\u63a8\u7406\u3002 result \u53ef\u4ee5\u6253\u5370\u5230\u63a7\u5236\u53f0\uff0c\u4fdd\u5b58\u5230 runs/hub , \u5728\u652f\u6301\u7684\u73af\u5883\u4e2d\u663e\u793a\u5230\u5c4f\u5e55\u4e0a\uff0c\u5e76\u4f5c\u4e3a\u5f20\u91cf\u6216 pandas \u6570\u636e\u8fd4\u56de\u3002 import cv2 import oneflow as flow from PIL import Image # Model model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # Images for f in 'zidane.jpg' , 'bus.jpg' : flow . hub . download_url_to_file ( 'https://ultralytics.com/images/' + f , f ) # download 2 images im1 = Image . open ( 'zidane.jpg' ) # PIL image im2 = cv2 . imread ( 'bus.jpg' )[ ... , :: - 1 ] # OpenCV image (BGR to RGB) # Inference results = model ([ im1 , im2 ], size = 640 ) # batch of images # Results results . print () results . save () # or .show() results . xyxy [ 0 ] # im1 predictions (tensor) print ( results . pandas () . xyxy [ 0 ]) # im1 predictions (pandas) \u5bf9\u4e8e\u6240\u6709\u63a8\u7406\u9009\u9879\uff0c\u8bf7\u53c2\u9605 YOLOv5 AutoShape() forward\u65b9\u6cd5 \u3002","title":"\u66f4\u7ec6\u8282\u7684\u4f8b\u5b50"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_4","text":"YOLOv5 \u6a21\u578b\u5305\u542b\u5404\u79cd\u63a8\u7406\u5c5e\u6027\uff0c\u4f8b\u5982\u7f6e\u4fe1\u5ea6\u9608\u503c\u3001IoU \u9608\u503c\u7b49\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u8bbe\u7f6e\uff1a model . conf = 0.25 # NMS confidence threshold iou = 0.45 # NMS IoU threshold agnostic = False # NMS class-agnostic multi_label = False # NMS multiple labels per box classes = None # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs max_det = 1000 # maximum number of detections per image amp = False # Automatic Mixed Precision (AMP) inference results = model ( im , size = 320 ) # custom inference size","title":"\u63a8\u7406\u8bbe\u7f6e"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_5","text":"\u6a21\u578b\u521b\u5efa\u540e\u53ef\u4ee5\u8fc1\u79fb\u5230\u4efb\u610f\u8bbe\u5907\u4e0a model . cpu () # CPU model . cuda () # GPU model . to ( device ) # i.e. device=flow.device(0) \u6a21\u578b\u4e5f\u53ef\u4ee5\u5728\u4efb\u610f device \u4e0a\u76f4\u63a5\u521b\u5efa\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 'cpu' ) # load on CPU \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a \u5728\u63a8\u7406\u4e4b\u524d\uff0c\u8f93\u5165\u56fe\u50cf\u4e5f\u4f1a\u81ea\u52a8\u4f20\u8f93\u5230\u6a21\u578b\u6240\u5728\u7684\u8bbe\u5907\u4e0a\u3002","title":"\u8bbe\u5907"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_6","text":"\u4f7f\u7528 _verbose=False ,\u6a21\u578b\u53ef\u4ee5\u88ab\u9759\u97f3\u7684\u52a0\u8f7d\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , _verbose = False ) # load silently","title":"\u9759\u97f3\u8f93\u51fa"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_7","text":"model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , channels = 4 ) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9664\u4e86\u7b2c\u4e00\u4e2a\u8f93\u5165\u5c42\u5916\u5c06\u7531\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u7ec4\u6210\uff0c\u5b83\u4e0d\u518d\u4e0e\u9884\u8bad\u7ec3\u7684\u8f93\u5165\u5c42\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u3002 \u8f93\u5165\u5c42\u5c06\u4fdd\u6301\u7531\u968f\u673a\u6743\u91cd\u521d\u59cb\u5316\u3002","title":"\u8f93\u5165\u901a\u9053"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_8","text":"\u8981\u52a0\u8f7d\u5177\u6709 10 \u4e2a\u8f93\u51fa\u7c7b\u800c\u4e0d\u662f\u9ed8\u8ba4\u7684 80 \u4e2a\u8f93\u51fa\u7c7b\u7684\u9884\u8bad\u7ec3 YOLOv5s \u6a21\u578b\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , classes = 10 ) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9664\u4e86\u8f93\u51fa\u5c42\u5c06\u7531\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u7ec4\u6210\uff0c\u5b83\u4eec\u4e0d\u518d\u4e0e\u9884\u8bad\u7ec3\u7684\u8f93\u51fa\u5c42\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u3002 \u8f93\u51fa\u5c42\u5c06\u4fdd\u6301\u7531\u968f\u673a\u6743\u91cd\u521d\u59cb\u5316\u3002","title":"\u7c7b\u522b\u6570"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_9","text":"\u5982\u679c\u60a8\u5728\u4e0a\u8ff0\u6b65\u9aa4\u4e2d\u9047\u5230\u95ee\u9898\uff0c\u8bbe\u7f6e force_reload=True \u53ef\u80fd\u6709\u52a9\u4e8e\u4e22\u5f03\u73b0\u6709\u7f13\u5b58\u5e76\u5f3a\u5236\u4ece OneFlow Hub \u91cd\u65b0\u4e0b\u8f7d\u6700\u65b0\u7684 YOLOv5 \u7248\u672c\u3002","title":"\u5f3a\u5236\u91cd\u65b0\u52a0\u8f7d"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_10","text":"\u8981\u5728\u684c\u9762\u5c4f\u5e55\u4e0a\u8fd0\u884c\u63a8\u7406\uff1a import oneflow as flow from PIL import ImageGrab # Model model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , _verbose = False ) # Image im = ImageGrab . grab () # take a screenshot # Inference results = model ( im )","title":"\u622a\u56fe\u63a8\u7406"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#gpu","text":"YOLOv5 \u6a21\u578b\u53ef\u4ee5\u52a0\u8f7d\u5230\u591a\u4e2a GPU \u5b9e\u73b0\u591a\u7ebf\u7a0b\u63a8\u7406\uff1a import oneflow as flow import threading def run ( model , im ): results = model ( im ) results . save () # Models model0 = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 0 ) model1 = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 1 ) # Inference threading . Thread ( target = run , args = [ model0 , 'https://ultralytics.com/images/zidane.jpg' ], daemon = True ) . start () threading . Thread ( target = run , args = [ model1 , 'https://ultralytics.com/images/bus.jpg' ], daemon = True ) . start ()","title":"\u591a GPU \u63a8\u7406"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_11","text":"\u8981\u52a0\u8f7d YOLOv5 \u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u800c\u4e0d\u662f\u63a8\u7406\uff0c\u8bf7\u8bbe\u7f6e autoshape=False\u3002 \u8981\u52a0\u8f7d\u5177\u6709\u968f\u673a\u521d\u59cb\u5316\u6743\u91cd\u7684\u6a21\u578b\uff08\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\uff09\uff0c\u8bf7\u4f7f\u7528 pretrained=False\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u60a8\u5fc5\u987b\u63d0\u4f9b\u81ea\u5df1\u7684\u8bad\u7ec3\u811a\u672c\u3002 \u6216\u8005\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 YOLOv5 \u8bad\u7ec3\u81ea\u5b9a\u4e49\u6570\u636e\u6559\u7a0b \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , autoshape = False ) # load pretrained model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , autoshape = False , pretrained = False ) # load scratch","title":"\u8bad\u7ec3"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#base64","text":"\u7528\u4e8e API \u670d\u52a1\u3002 \u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 #2291 \u548c Flask REST API \u793a\u4f8b\u3002 results = model ( im ) # inference results . ims # array of original images (as np array) passed to model for inference results . render () # updates results.ims with boxes and labels for im in results . ims : buffered = BytesIO () im_base64 = Image . fromarray ( im ) im_base64 . save ( buffered , format = \"JPEG\" ) print ( base64 . b64encode ( buffered . getvalue ()) . decode ( 'utf-8' )) # base64 encoded image with results","title":"Base64 \u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_12","text":"\u8fd4\u56de\u7684\u68c0\u6d4b\u7ed3\u679c\u53ef\u4ee5\u88ab\u88c1\u526a\uff1a results = model ( im ) # inference crops = results . crop ( save = True ) # cropped detections dictionary","title":"\u88c1\u526a\u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#pandas","text":"\u7ed3\u679c\u53ef\u4ee5\u4f5c\u4e3a Pandas DataFrames \u8fd4\u56de\uff1a results = model ( im ) # inference results . pandas () . xyxy [ 0 ] # Pandas DataFrame Pandas\u8f93\u51fa\uff08\u70b9\u51fb\u5c55\u5f00\uff09 print(results.pandas().xyxy[0]) xmin ymin xmax ymax confidence class name 0 743.290649 48.343842 1141.756348 720.000000 0.879861 0 person 1 441.989624 437.336670 496.585083 710.036255 0.675118 27 tie 2 123.051117 193.237976 714.690674 719.771362 0.666694 0 person 3 978.989807 313.579468 1025.302856 415.526184 0.261517 27 tie","title":"Pandas \u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_13","text":"\u7ed3\u679c\u53ef\u4ee5\u6309\u5217\u6392\u5e8f\uff0c\u4f8b\u5982\u4ece\u5de6\u5230\u53f3\uff08x\u8f74\uff09\u5bf9\u8f66\u724c\u6570\u5b57\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u6392\u5e8f\uff1a results = model ( im ) # inference results . pandas () . xyxy [ 0 ] . sort_values ( 'xmin' ) # sorted left-right","title":"\u6392\u5e8f\u540e\u7684\u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#box-cropped","text":"\u7ed3\u679c\u53ef\u4ee5\u8fd4\u56de\u5e76\u4fdd\u5b58\u4e3a detection crops\uff1a results = model ( im ) # inference crops = results . crop ( save = True ) # cropped detections dictionary","title":"Box-Cropped \u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#json","text":"\u7ed3\u679c\u4e00\u65e6\u4f7f\u7528 .pandas \u88ab\u4fdd\u5b58\u4e3a pandas \u6570\u636e\u683c\u5f0f\uff0c\u5c31\u53ef\u4ee5\u518d\u4f7f\u7528 .to_json() \u65b9\u6cd5\u4fdd\u5b58\u4e3a JSON \u683c\u5f0f\u3002\u53ef\u4ee5\u4f7f\u7528 orient \u53c2\u6570\u4fee\u6539 JSON \u683c\u5f0f\u3002\u8bf7\u67e5\u770b pandas \u7684 .to_json() \u65b9\u6cd5\u7684 \u6587\u6863 \u4e86\u89e3\u7ec6\u8282\u3002 results = model ( ims ) # inference results . pandas () . xyxy [ 0 ] . to_json ( orient = \"records\" ) # JSON img1 predictions Json\u8f93\u51fa\uff08\u70b9\u51fb\u5c55\u5f00\uff09 [{\"xmin\":743.2906494141,\"ymin\":48.3438415527,\"xmax\":1141.7563476562,\"ymax\":720.0,\"confidence\":0.87986058,\"class\":0,\"name\":\"person\"},{\"xmin\":441.9896240234,\"ymin\":437.3366699219,\"xmax\":496.5850830078,\"ymax\":710.0362548828,\"confidence\":0.6751183867,\"class\":27,\"name\":\"tie\"},{\"xmin\":123.0511169434,\"ymin\":193.2379760742,\"xmax\":714.6906738281,\"ymax\":719.7713623047,\"confidence\":0.6666944027,\"class\":0,\"name\":\"person\"},{\"xmin\":978.9898071289,\"ymin\":313.5794677734,\"xmax\":1025.3028564453,\"ymax\":415.526184082,\"confidence\":0.2615173161,\"class\":27,\"name\":\"tie\"}]","title":"JSON \u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_14","text":"\u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4f7f\u7528 OneFlow Hub \u52a0\u8f7d\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684\u5728VOC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u768420\u4e2a\u7c7b\u522b\u7684 YOLOV5s \u6a21\u578b best \u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'custom' , path = 'path/to/best' ) # local model model = oneflow . hub . load ( '/path/to/one-yolov5' , 'custom' , path = 'path/to/best' ) # local repo","title":"\u81ea\u5b9a\u4e49\u6a21\u578b"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#tensorrt-onnx-openvino","text":"OneFlow Hub \u652f\u6301\u5bf9\u5927\u591a\u6570 YOLOv5 \u5bfc\u51fa\u683c\u5f0f\u8fdb\u884c\u63a8\u7406\uff0c\u5305\u62ec\u81ea\u5b9a\u4e49\u8bad\u7ec3\u6a21\u578b\u3002\u67e5\u770b TFLite, ONNX, CoreML, TensorRT \u6a21\u578b\u5bfc\u51fa\u6559\u7a0b \u67e5\u770b\u7ec6\u8282\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u5728 GPU benchmarks \u4e0a TensorRT \u53ef\u80fd\u6bd4PyTorch\u5feb3-5\u500d\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u5728 CPU benchmarks \u4e0a ONNX \u548c OpenVINO \u53ef\u80fd\u6bd4 PyTorch \u5feb2-3\u500d\u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'custom' , path = 'yolov5s/' ) # OneFlow 'yolov5s.onnx' ) # ONNX 'yolov5s_openvino_model/' ) # OpenVINO 'yolov5s.engine' ) # TensorRT 'yolov5s.mlmodel' ) # CoreML (macOS-only) 'yolov5s.tflite' ) # TFLite","title":"TensorRT, ONNX \u548c OpenVINO \u6a21\u578b"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_15","text":"https://github.com/ultralytics/yolov5/issues/36","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/03_chapter/model_ensembling.html","text":"\u6a21\u578b\u878d\u5408 (Model Ensembling) From https://www.sciencedirect.com/topics/computer-science/ensemble-modeling: Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data. The motivation for using ensemble models is to reduce the generalization error of the prediction. As long as the base models are diverse and independent, the prediction error of the model decreases when the ensemble approach is used. The approach seeks the wisdom of crowds in making a prediction. Even though the ensemble model has multiple base models within the model, it acts and performs as a single model. \ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5728YOLOv5\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u63a8\u7406\u4e2d\u5982\u4f55\u4f7f\u7528\u6a21\u578b\u878d\u5408 (Model Ensembling)\u63d0\u9ad8mAP\u548cRecall \ud83d\ude80 \ud83d\udccc\u5f00\u59cb\u4e4b\u524d \u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install \ud83d\udccc\u666e\u901a\u6d4b\u8bd5 \u5728\u5c1d\u8bd5 TTA \u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u80fd\u591f\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u547d\u4ee4\u5728COCO val2017\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5YOLOv5x\u3002 yolov5x \u662f\u53ef\u7528\u7684\u6700\u5927\u5e76\u4e14\u6700\u7cbe\u786e\u7684\u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u7684\u6a21\u578b\u662f yolov5s , yolov5m \u548c yolov5l \u7b49 \u6216\u8005 \u81ea\u5df1\u4ece\u6570\u636e\u96c6\u8bad\u7ec3\u51fa\u7684\u6a21\u578b ./weights/best \u3002\u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 READEME table $ python val . py -- weights ./ yolov5x -- data coco . yaml -- img 640 -- half \ud83d\udce2 \u8f93\u51fa: val: data = data/coco.yaml, weights =[ './yolov5x' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = True, dnn = False YOLOv5 \ud83d\ude80 v1.0-8-g94ec5c4 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 01 :55< 00 :00, 1 .36it/ all 5000 36335 0 .743 0 .627 0 .685 0 .503 Speed: 0 .1ms pre-process, 7 .5ms inference, 2 .1ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json... ... Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0 .50 | area = all | maxDets = 100 ] = 0 .689 Average Precision ( AP ) @ [ IoU = 0 .75 | area = all | maxDets = 100 ] = 0 .545 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .339 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .557 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .650 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 1 ] = 0 .382 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 10 ] = 0 .628 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .523 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .730 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .826 \ud83d\udccc \u878d\u5408\u6d4b\u8bd5 \u901a\u8fc7\u5728\u4efb\u4f55\u73b0\u6709\u7684 val.py\u6216detect.py\u547d\u4ee4\u4e2d\u7684 --weights \u53c2\u6570\u540e\u6dfb\u52a0\u989d\u5916\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u6d4b\u8bd5\u548c\u63a8\u7406\u65f6\u5c06\u591a\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u878d\u5408\u5728\u4e00\u8d77\u3002 \ud83d\udce2 \u5c06 yolov5x , yolov5l6 \u4e24\u4e2a\u6a21\u578b\u7684\u878d\u5408\u6d4b\u8bd5\u7684\u6307\u4ee4\u5982\u4e0b\uff1a python val.py --weights ./yolov5x ./yolov5l6 --data data/coco.yaml --img 640 --half val: data=data/coco.yaml, weights=['./yolov5x', './yolov5l6'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False YOLOv5 \ud83d\ude80 v1.0-29-g8ed33f3 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients Fusing layers... Model summary: 346 layers, 76726332 parameters, 653820 gradients Ensemble created with ['./yolov5x', './yolov5l6'] val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157/157 [03:14<00:00, 1.24s/i all 5000 36335 0.73 0.644 0.693 0.513 Speed: 0.1ms pre-process, 23.7ms inference, 2.3ms NMS per image at shape (32, 3, 640, 640) # <--- ensemble speed Evaluating pycocotools mAP... saving runs/val/exp21/yolov5x_predictions.json... ... Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.515 # <--- ensemble mAP Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.697 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.556 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.389 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.637 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.690 # <--- ensemble mAR Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.517 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.842 \ud83d\udce2 \u58f0\u660e:\u4e0a\u8ff0\u4e24\u6b21\u6d4b\u8bd5\u7684mAP\uff0cmAR\u7ed3\u679c\u5982\u4e0b\uff1a mAP mAR baseline 0.505 0.677 ensemble 0.515 0.690 \ud83d\udccc\u878d\u5408\u63a8\u7406 \u9644\u52a0\u989d\u5916\u7684\u6a21\u578b\u5728 --weights \u9009\u9879\u540e\u81ea\u52a8\u542f\u7528\u878d\u5408\u63a8\u7406\uff1a python detect.py --weights ./yolov5x ./yolov5l6 --img 640 --source data/images Output: detect: weights=['./yolov5x', './yolov5l6'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 v1.0-31-g6b1387c Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients Fusing layers... Model summary: 346 layers, 76726332 parameters, 653820 gradients Ensemble created with ['./yolov5x', './yolov5l6'] detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/fengwen/one-yolov5/data/images/bus.jpg: 640x512 4 persons, 1 bus, 1 handbag, 1 tie, Done. (0.028s) detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 2/2 /home/fengwen/one-yolov5/data/images/zidane.jpg: 384x640 3 persons, 2 ties, Done. (0.023s) 0.6ms pre-process, 25.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 640) \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/issues/318","title":"3.5 \u6a21\u578b\u878d\u5408 (Model Ensembling)"},{"location":"tutorials/03_chapter/model_ensembling.html#model-ensembling","text":"From https://www.sciencedirect.com/topics/computer-science/ensemble-modeling: Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data. The motivation for using ensemble models is to reduce the generalization error of the prediction. As long as the base models are diverse and independent, the prediction error of the model decreases when the ensemble approach is used. The approach seeks the wisdom of crowds in making a prediction. Even though the ensemble model has multiple base models within the model, it acts and performs as a single model. \ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5728YOLOv5\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u63a8\u7406\u4e2d\u5982\u4f55\u4f7f\u7528\u6a21\u578b\u878d\u5408 (Model Ensembling)\u63d0\u9ad8mAP\u548cRecall \ud83d\ude80","title":"\u6a21\u578b\u878d\u5408 (Model Ensembling)"},{"location":"tutorials/03_chapter/model_ensembling.html#_1","text":"\u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install","title":"\ud83d\udccc\u5f00\u59cb\u4e4b\u524d"},{"location":"tutorials/03_chapter/model_ensembling.html#_2","text":"\u5728\u5c1d\u8bd5 TTA \u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u80fd\u591f\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u547d\u4ee4\u5728COCO val2017\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5YOLOv5x\u3002 yolov5x \u662f\u53ef\u7528\u7684\u6700\u5927\u5e76\u4e14\u6700\u7cbe\u786e\u7684\u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u7684\u6a21\u578b\u662f yolov5s , yolov5m \u548c yolov5l \u7b49 \u6216\u8005 \u81ea\u5df1\u4ece\u6570\u636e\u96c6\u8bad\u7ec3\u51fa\u7684\u6a21\u578b ./weights/best \u3002\u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 READEME table $ python val . py -- weights ./ yolov5x -- data coco . yaml -- img 640 -- half \ud83d\udce2 \u8f93\u51fa: val: data = data/coco.yaml, weights =[ './yolov5x' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = True, dnn = False YOLOv5 \ud83d\ude80 v1.0-8-g94ec5c4 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 01 :55< 00 :00, 1 .36it/ all 5000 36335 0 .743 0 .627 0 .685 0 .503 Speed: 0 .1ms pre-process, 7 .5ms inference, 2 .1ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json... ... Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0 .50 | area = all | maxDets = 100 ] = 0 .689 Average Precision ( AP ) @ [ IoU = 0 .75 | area = all | maxDets = 100 ] = 0 .545 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .339 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .557 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .650 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 1 ] = 0 .382 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 10 ] = 0 .628 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .523 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .730 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .826","title":"\ud83d\udccc\u666e\u901a\u6d4b\u8bd5"},{"location":"tutorials/03_chapter/model_ensembling.html#_3","text":"\u901a\u8fc7\u5728\u4efb\u4f55\u73b0\u6709\u7684 val.py\u6216detect.py\u547d\u4ee4\u4e2d\u7684 --weights \u53c2\u6570\u540e\u6dfb\u52a0\u989d\u5916\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u6d4b\u8bd5\u548c\u63a8\u7406\u65f6\u5c06\u591a\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u878d\u5408\u5728\u4e00\u8d77\u3002 \ud83d\udce2 \u5c06 yolov5x , yolov5l6 \u4e24\u4e2a\u6a21\u578b\u7684\u878d\u5408\u6d4b\u8bd5\u7684\u6307\u4ee4\u5982\u4e0b\uff1a python val.py --weights ./yolov5x ./yolov5l6 --data data/coco.yaml --img 640 --half val: data=data/coco.yaml, weights=['./yolov5x', './yolov5l6'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False YOLOv5 \ud83d\ude80 v1.0-29-g8ed33f3 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients Fusing layers... Model summary: 346 layers, 76726332 parameters, 653820 gradients Ensemble created with ['./yolov5x', './yolov5l6'] val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157/157 [03:14<00:00, 1.24s/i all 5000 36335 0.73 0.644 0.693 0.513 Speed: 0.1ms pre-process, 23.7ms inference, 2.3ms NMS per image at shape (32, 3, 640, 640) # <--- ensemble speed Evaluating pycocotools mAP... saving runs/val/exp21/yolov5x_predictions.json... ... Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.515 # <--- ensemble mAP Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.697 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.556 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.389 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.637 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.690 # <--- ensemble mAR Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.517 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.842 \ud83d\udce2 \u58f0\u660e:\u4e0a\u8ff0\u4e24\u6b21\u6d4b\u8bd5\u7684mAP\uff0cmAR\u7ed3\u679c\u5982\u4e0b\uff1a mAP mAR baseline 0.505 0.677 ensemble 0.515 0.690","title":"\ud83d\udccc \u878d\u5408\u6d4b\u8bd5"},{"location":"tutorials/03_chapter/model_ensembling.html#_4","text":"\u9644\u52a0\u989d\u5916\u7684\u6a21\u578b\u5728 --weights \u9009\u9879\u540e\u81ea\u52a8\u542f\u7528\u878d\u5408\u63a8\u7406\uff1a python detect.py --weights ./yolov5x ./yolov5l6 --img 640 --source data/images Output: detect: weights=['./yolov5x', './yolov5l6'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 v1.0-31-g6b1387c Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients Fusing layers... Model summary: 346 layers, 76726332 parameters, 653820 gradients Ensemble created with ['./yolov5x', './yolov5l6'] detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/fengwen/one-yolov5/data/images/bus.jpg: 640x512 4 persons, 1 bus, 1 handbag, 1 tie, Done. (0.028s) detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 2/2 /home/fengwen/one-yolov5/data/images/zidane.jpg: 384x640 3 persons, 2 ties, Done. (0.023s) 0.6ms pre-process, 25.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 640)","title":"\ud83d\udccc\u878d\u5408\u63a8\u7406"},{"location":"tutorials/03_chapter/model_ensembling.html#_5","text":"https://github.com/ultralytics/yolov5/issues/318","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/03_chapter/model_train.html","text":"\ud83d\udce2 \u58f0\u660e:Model Train(\u4ee5coco\u6570\u636e\u96c6\u4e3a\u4f8b) \u9879\u76ee\u7ed3\u6784\u9884\u89c8 \ud83c\udfe0 \u8bad\u7ec3\u6307\u4ee4(\u4f7f\u7528coco\u6570\u636e\u96c6\u4e3a\ud83c\udf30) \ud83d\udccc\u4e24\u79cd\u8bad\u7ec3\u65b9\u5f0f \u5e26\u6743\u91cd\u8bad\u7ec3 \ud83d\ude80 $ python path/to/train.py --data coco.yaml --weights yolov5s --img 640 \u4e0d\u5e26\u6743\u91cd\u8bad\u7ec3 \ud83d\ude80 $ python path/to/train.py --data coco.yaml --weights '' --cfg yolov5s.yaml --img 640 \ud83d\udccc\u5355GPU\u8bad\u7ec3 $ python train.py --data coco.yaml --weights yolov5s --device 0 \ud83d\udccc\u591aGPU\u8bad\u7ec3 $ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --weights yolov5s --device 0,1 \u6ce8\u610f\u26a0\ufe0f\uff1a --nproc_per_node \u6307\u5b9a\u8981\u4f7f\u7528\u591a\u5c11GPU\u3002\u4e3e\u4e2a\u4f8b\u5b50\ud83c\udf30:\u5728\u4e0a\u9762\ud83d\udc46 \u591aGPU\u8bad\u7ec3\u6307\u4ee4\u4e2d\u5b83\u662f2\u3002 --batch \u6279\u5904\u7406\u6570\u91cf\uff08 \u5373\u4e00\u6b21\u8bad\u7ec3\u6240\u9009\u53d6\u7684\u6837\u672c\u6570 )\u3002\u5b83\u5c06\u5e73\u5747\u5206\u914d\u7ed9\u6bcf\u4e2aGPU\u3002\u5728\u4e0a\u9762\ud83d\udc46\u7684\u793a\u4f8b\u4e2d\uff0c\u6bcfGPU\u5206\u914d 64/2\uff1d32 \u4e2a\u6837\u672c\u3002 \u4e0a\u9762\u7684\u4ee3\u7801\u9ed8\u8ba4\u4f7f\u7528GPU 0\u2026\uff08N-1\uff09\u3002\u4f7f\u7528\u7279\u5b9a\u7684GPU\ud83e\udd14\ufe0f\uff1f \u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5728 --device \u540e\u8ddf\u6307\u5b9aGPU\u6765\u5b9e\u73b0\u3002\u300c\u6848\u4f8b\ud83c\udf30\u300d\uff0c\u5728\u4e0b\u9762\u7684\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528GPU 2,3\u3002 $ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights '' --device 2,3 \ud83d\udccc\u4f7f\u7528SyncBatchNorm SyncBatchNorm \u53ef\u4ee5\u63d0\u9ad8\u591agpu\u8bad\u7ec3\u7684\u51c6\u786e\u6027\uff0c\u4f46\u4f1a\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u901f\u5ea6\u3002\u5b83\u4ec5\u9002\u7528\u4e8e\u591aGPU DistributedDataParallel \u8bad\u7ec3\u3002 \u5efa\u8bae\u6700\u597d\u5728\u6bcf\u4e2aGPU\u4e0a\u7684\u6837\u672c\u6570\u91cf\u8f83\u5c0f\uff08 \u6837\u672c\u6570\u91cf<=8 \uff09\u65f6\u4f7f\u7528\u3002 \u8981\u4f7f\u7528SyncBatchNorm\uff0c\u53ea\u9700\u5c06\u6dfb\u52a0 --sync-bn \u53c2\u6570\u9009\u9879\uff0c\u5177\u4f53\u300c\u6848\u4f8b\ud83c\udf30\u300d\u5982\u4e0b: $ python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' -- sync - bn \ud83d\udce2 \u66f4\u591a\u53c2\u6570\u89e3\u6790\u8be6\u89c1 \u9644\u4ef6\u88683.1 \u3002 \u8bad\u7ec3\u7ed3\u679c\ud83c\udf1f \ud83d\udccc\u672c\u5730\u65e5\u5fd7 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u7ed3\u679c\u90fd\u8bb0\u5f55\u4e3aruns/train\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u65b0\u8bad\u7ec3\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u8bad\u7ec3\u7ed3\u679c\u76ee\u5f55\uff0c\u5982runs/train/exp2\u3001runs/train/exp3\u7b49\u3002\u67e5\u770b\u8bad\u7ec3\u548c\u6d4b\u8bd5JPG\u4ee5\u67e5\u770b mosaics, labels, predictions and augmentation \u6548\u679c\u3002 \u6ce8\u610f\uff1aMosaic Dataloader \u7528\u4e8e\u8bad\u7ec3\uff08\u5982\u4e0b\u6240\u793a\uff09\uff0c\u8fd9\u662fUltralytics\u53d1\u8868\u7684\u65b0\u6982\u5ff5\uff0c\u9996\u6b21\u51fa\u73b0\u5728 YOLOv4 \u4e2d\u3002 train_batch0.jpg \u663e\u793a batch \u4e3a 0 \u7684 (mosaics and labels): val_batch0_labels.jpg \u5c55\u793a\u6d4b\u8bd5 batch \u4e3a 0 \u7684labels: val_batch0_pred.jpg \u5c55\u793a\u6d4b\u8bd5 batch \u4e3a 0 predictions(\u9884\u6d4b): \u8bad\u7ec3\u8bad\u635f\u5931\u548c\u6027\u80fd\u7684\u6307\u6807\u6709\u8bb0\u5f55\u5230Tensorboard\u548c\u81ea\u5b9a\u4e49\u7ed3\u679c\u4e2d results.csv\u65e5\u5fd7\u6587\u4ef6 \uff0c\u8bad\u7ec3\u8bad\u5b8c\u6210\u540e\u4f5c\u4e3a\u7ed3\u679c\u7ed8\u5236 results.png\u5982\u4e0b\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5728COCO128\u4e0a\u8bad\u7ec3\u7684YOLOV5\u7ed3\u679c - \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 (\u84dd\u8272)\u3002 - \u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd --weights yolov5s (\u6a59\u8272)\u3002 \u5177\u4f53\u7684\u6307\u6807\u5206\u6790\u8be6\u89c1\u6587\u7ae0 \u300a\u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30\u300b \u6a21\u578b\u6d4b\u8bd5(val.py) \ud83d\udd25 \u4e0b\u9762\u7684\u547d\u4ee4\u662f\u5728COCO val2017\u6570\u636e\u96c6\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5 YOLOv5x \u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5s \uff0c yolov5l \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 README-TABLE $ python val . py -- weights yolov5x -- data coco . yaml -- img 640 \u6a21\u578b\u9884\u6d4b\ud83d\udd25 python detect . py -- weights yolov5s -- img 832 \u8bad\u7ec3\u6280\u5de7\ud83d\udd25 \ud83d\udce2 \u58f0\u660e\uff1a\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c \u53ea\u8981\u6570\u636e\u96c6\u8db3\u591f\u5927\u4e14\u6807\u8bb0\u826f\u597d \uff0c\u5c31\u53ef\u4ee5\u5728\u4e0d\u6539\u53d8\u6a21\u578b\u6216\u8bad\u7ec3\u8bbe\u7f6e\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u826f\u597d\u7684\u7ed3\u679c\u3002 \u5982\u679c\u4e00\u5f00\u59cb\u4f60\u6ca1\u6709\u5f97\u5230\u597d\u7684\u7ed3\u679c\uff0c\u4f60\u53ef\u4ee5\u91c7\u53d6\u4e00\u4e9b\u6b65\u9aa4\u6765\u6539\u8fdb\uff0c\u4f46\u6211\u4eec\u59cb\u7ec8\u5efa\u8bae\u7528\u6237\u5728\u8003\u8651\u4efb\u4f55\u66f4\u6539\u4e4b\u524d\u5148\u4f7f\u7528\u6240\u6709\u9ed8\u8ba4\u8bbe\u7f6e\u8fdb\u884c\u4e00\u6b21\u8bad\u7ec3\u3002\u8fd9\u6709\u52a9\u4e8e\u5efa\u7acb\u8bc4\u4f30\u57fa\u51c6\u548c\u53d1\u73b0\u9700\u8981\u6539\u8fdb\u7684\u5730\u65b9 \ud83d\ude80\u3002 \ud83d\udccc\u6a21\u578b\u9009\u62e9 \u7c7b\u4f3c\u4e8eYOLOv5x\u548cYOLOv5x6\u7684\u5927\u578b\u6a21\u578b\u5728\u51e0\u4e4e\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u4f1a\u4ea7\u751f\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u4f46\u53c2\u6570\u66f4\u591a\uff0c\u9700\u8981\u66f4\u591a\u7684CUDA\u5185\u5b58\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd0\u884c\u901f\u5ea6\u8f83\u6162\u3002 \u5bf9\u4e8e\u79fb\u52a8\u90e8\u7f72\uff0c\u6211\u4eec\u63a8\u8350YOLOv5s/m\uff0c\u5bf9\u4e8e\u4e91\u90e8\u7f72\uff0c\u6211\u4eec\u5efa\u8baeYOLOV5l/x\u3002 \u6709\u5173\u6240\u6709\u6a21\u578b\u7684\u5b8c\u6574\u6bd4\u8f83\uff0c\u8bf7\u53c2\u9605 \u8be6\u7ec6\u8868 \u4ece\u9884\u5148\u8bad\u7ec3\u7684\u6743\u91cd\u5f00\u59cb\u8bad\u7ec3\u3002\u5efa\u8bae\u7528\u4e8e\u4e2d\u5c0f\u578b\u6570\u636e\u96c6\uff08\u5373 VOC \u3001 VisDrone \u3001 GlobalWheat \uff09\u3002\u5c06\u6a21\u578b\u7684\u540d\u79f0\u4f20\u9012\u7ed9--weights\u53c2\u6570\u3002\u6a21\u578b\u81ea\u52a8\u4ece latest YOLOv5 releasse \u4e0b\u8f7d \u3002 python train . py -- data custom . yaml -- weights yolov5s yolov5m yolov5l yolov5x custom_pretrained # \u81ea\u5b9a\u4e49\u7684\u7f51\u7edc\u7ed3\u6784\u6587\u4ef6 \u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7684\u8bdd\uff0c\u63a8\u8350\u7528\u5927\u7684\u6570\u636e\u96c6(\u5373 COCO\u3001Objects365\u3001OIv6 )\u5728 --cfg \u9009\u9879\u540e\u4f20\u9012\u60a8\u611f\u5174\u8da3\u7684\u7f51\u7edc\u7ed3\u6784\u6587\u4ef6\u53c2\u6570 \u4ee5\u53ca\u7a7a\u7684 --weights '' \u53c2\u6570\uff1a python train . py -- data custom . yaml -- weights '' -- cfg yolov5s . yaml yolov5m . yaml yolov5l . yaml yolov5x . yaml \ud83d\udccc\u8bad\u7ec3\u914d\u7f6e \u5728\u4fee\u6539\u4efb\u4f55\u5185\u5bb9\u4e4b\u524d\uff0c\u9996\u5148\u4f7f\u7528\u9ed8\u8ba4\u8bbe\u7f6e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u5efa\u7acb\u6027\u80fd\u57fa\u7ebf\u3002\u8bad\u7ec3\u53c2\u6570\u7684\u5b8c\u6574\u5217\u8868,\u80fd\u591f\u53d1\u73b0\u5728train.py\u6587\u4ef6\u4e2d\u3002 Epochs : \u9ed8\u8ba4\u8bad\u7ec3300\u4e2aepochs\u3002\u5982\u679c\u65e9\u671f\u8fc7\u62df\u5408\uff0c\u5219\u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u3002\u5982\u679c\u5728300\u4e2a\u5468\u671f\u540e\u672a\u53d1\u751f\u8fc7\u62df\u5408\uff0c\u5219\u53ef\u4ee5\u8bad\u7ec3\u66f4\u957f\uff0c\u6bd4\u5982600\u30011200\u4e2aepochs\u3002 Image size: COCO\u4ee5 --img 640,\u7684\u5206\u8fa8\u7387\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u96c6\u4e2d\u6709\u5927\u91cf\u7684\u5c0f\u5bf9\u8c61\uff0c\u5b83\u53ef\u4ee5\u4ece\u66f4\u9ad8\u5206\u8fa8\u7387\uff08\u5982--img 1280\uff09\u7684\u8bad\u7ec3\u4e2d\u8bad\u7ec3\u3002 \u5982\u679c\u6709\u8bb8\u591a\u5c0f\u5bf9\u8c61\uff0c\u5219\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u5c06\u4ece\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8bad\u7ec3\u4e2d\u83b7\u76ca\u3002\u6700\u597d\u7684\u63a8\u65ad\u7ed3\u679c\u662f\u5728\u76f8\u540c\u7684--img \u5904\u83b7\u5f97\u7684 \uff0c\u5373\u5982\u679c\u5728-img 1280\u5904\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e5f\u5e94\u8be5\u5728--img 1280\u5904\u8fdb\u884c\u6d4b\u8bd5\u548c\u68c0\u6d4b\u3002 Batch Size: \u4f7f\u7528\u66f4\u5927\u7684 --batch-size \u3002\u80fd\u591f\u6709\u6548\u7f13\u89e3\u5c0f\u6837\u672c\u6570\u4ea7\u751f\u7684batchnorm\u7edf\u8ba1\u7684\u9519\u8bef\u3002 Hyperparameters\uff1a \u9ed8\u8ba4\u8d85\u53c2\u6570\u5728hyp.scratch-low.yaml\u6587\u4ef6\u4e2d\u3002\u6211\u4eec\u5efa\u8bae\u60a8\u5728\u8003\u8651\u4fee\u6539\u4efb\u4f55\u8d85\u53c2\u6570\u4e4b\u524d\uff0c\u5148\u4f7f\u7528\u9ed8\u8ba4\u8d85\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u589e\u52a0\u589e\u5f3a\u8d85\u53c2\u6570\u5c06\u51cf\u5c11\u548c\u5ef6\u8fdf\u8fc7\u5ea6\u62df\u5408\uff0c\u5141\u8bb8\u66f4\u957f\u7684\u8bad\u7ec3\u548c\u5f97\u5230\u66f4\u9ad8mAP\u503c\u3002\u51cf\u5c11\u635f\u8017\u5206\u91cf\u589e\u76ca\u8d85\u53c2\u6570\uff0c\u5982hyp['obj']\uff0c\u5c06\u6709\u52a9\u4e8e\u51cf\u5c11\u8fd9\u4e9b\u7279\u5b9a\u635f\u8017\u5206\u91cf\u4e2d\u7684\u8fc7\u5ea6\u62df\u5408\u3002\u6709\u5173\u4f18\u5316\u8fd9\u4e9b\u8d85\u53c2\u6570\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 \u300a\u8d85\u53c2\u6570\u6f14\u5316\u6559\u7a0b\u300b \u3002 \u62d3\u5c55 \ud83d\udcd8 \ud83d\udccc\u4f7f\u7528\u591a\u673a\u8bad\u7ec3 \u8fd9\u4ec5\u9002\u7528\u4e8e\u591aGPU\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u3002 \u5728\u8bad\u7ec3\u4e4b\u524d\uff0c\u786e\u4fdd\u6240\u6709\u673a\u5668\u4e0a\u7684\u6587\u4ef6\u90fd\u76f8\u540c\uff0c\u6570\u636e\u96c6\u3001\u4ee3\u7801\u5e93\u7b49\u3002\u4e4b\u540e\uff0c\u786e\u4fdd\u673a\u5668\u53ef\u4ee5\u76f8\u4e92\u901a\u4fe1\u3002 \u60a8\u5fc5\u987b\u9009\u62e9\u4e00\u53f0\u4e3b\u673a\u5668\uff08\u5176\u4ed6\u673a\u5668\u5c06\u4e0e\u4e4b\u5bf9\u8bdd\uff09\u3002\u8bb0\u4e0b\u5b83\u7684\u5730\u5740\uff08master_addr\uff09\u5e76\u9009\u62e9\u4e00\u4e2a\u7aef\u53e3\uff08master-port\uff09\u3002\u5bf9\u4e8e\u4e0b\u9762\u7684\u793a\u4f8b\uff0c\u5c06\u4f7f\u7528master_addr=192.168.1.1\u548cmaster_ port=1234\u3002 \u8981\u4f7f\u7528\u5b83\uff0c\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u6307\u4ee4\uff1a # On master machine 0 $ python - m oneflow . distributed . launch -- nproc_per_node G -- nnodes N -- node_rank 0 -- master_addr \"192.168.1.1\" -- master_port 1234 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' # On machine R $ python - m oneflow . distributed . launch -- nproc_per_node G -- nnodes N -- node_rank R -- master_addr \"192.168.1.1\" -- master_port 1234 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' \u5176\u4e2dG\u662f\u6bcf\u53f0\u673a\u5668\u7684GPU\u6570\u91cf\uff0cN\u662f\u673a\u5668\u6570\u91cf\uff0cR\u662f\u4ece0\u5230\uff08N-1\uff09\u7684\u673a\u5668\u6570\u91cf\u3002 \u5047\u8bbe\u6211\u6709\u4e24\u53f0\u673a\u5668\uff0c\u6bcf\u53f0\u673a\u5668\u6709\u4e24\u4e2aGPU\uff0c\u5bf9\u4e8e\u4e0a\u9762\u7684\u60c5\u51b5\uff0cG=2\uff0cN=2\uff0cR=1\u3002 \u5728\u8fde\u63a5\u6240\u6709N\u53f0\u673a\u5668\u4e4b\u524d\uff0c\u8bad\u7ec3\u4e0d\u4f1a\u5f00\u59cb\u3002\u8f93\u51fa\u5c06\u4ec5\u663e\u793a\u5728\u4e3b\u673a\u4e0a\uff01 \u6ce8\u610f\u26a0\ufe0f oneflow\u76ee\u524d\u4e0d\u652f\u6301windows\u5e73\u53f0 --batch \u5fc5\u987b\u662fGPU\u6570\u91cf\u7684\u500d\u6570\u3002 GPU 0 \u5c06\u6bd4\u5176\u4ed6GPU\u5360\u7528\u7565\u591a\u7684\u5185\u5b58\uff0c\u56e0\u4e3a\u5b83\u7ef4\u62a4EMA\u5e76\u8d1f\u8d23\u68c0\u67e5\u70b9\u7b49\u3002 \u5982\u679c\u60a8\u5f97\u5230 RuntimeError: Address already in use \uff0c\u53ef\u80fd\u662f\u56e0\u4e3a\u60a8\u4e00\u6b21\u6b63\u5728\u8fd0\u884c\u591a\u4e2a\u57f9\u8bad\u3002\u8981\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u53ea\u9700\u901a\u8fc7\u6dfb\u52a0--master_port\u6765\u4f7f\u7528\u4e0d\u540c\u7684\u7aef\u53e3\u53f7\uff0c\u5982\u4e0b\u6240\u793a $ python - m oneflow . distributed . launch -- master_port 1234 -- nproc_per_node 2 ... \u7ed3\u679c DDP \u5206\u6790\u7ed3\u679c\u5728 AWS EC2 P4d instance with 8x A100 SXM4-40GB for YOLOv5l for 1 COCO epoch. \u914d\u7f6e\u4ee3\u7801\u26a1 # prepare t = https : // github . com / Oneflow - Inc / one - yolov5 : latest && sudo docker pull $ t && sudo docker run - it -- ipc = host -- gpus all - v \"$(pwd)\" / coco : / usr / src / coco $ t pip install -- pre oneflow - f https : // staging . oneflow . info / branch / master / cu112 cd .. && rm - rf app && git clone https : // github . com / Oneflow - Inc / one - yolov5 - b master app && cd app cp data / coco . yaml data / coco_profile . yaml # profile python train . py -- batch - size 16 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- batch - size 32 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 python - m oneflow . distributed . launch -- nproc_per_node 4 train . py -- batch - size 64 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 , 2 , 3 python - m oneflow . distributed . launch -- nproc_per_node 8 train . py -- batch - size 128 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 \ud83d\udce2 \u5feb\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u9644\u4ef6 \u88683.1 \u88683.1 : train.py\u53c2\u6570\u89e3\u6790\u8868 \u53c2\u6570 help \u5e2e\u52a9 --weight initial weights path \u52a0\u8f7d\u7684\u6743\u91cd\u6587\u4ef6\u8def\u5f84 --cfg model.yaml path \u6a21\u578b\u914d\u7f6e\u6587\u4ef6\uff0c\u7f51\u7edc\u7ed3\u6784 \u8def\u5f84 --data dataset.yaml path \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6\uff0c\u6570\u636e\u96c6\u8def\u5f84 --hyp hyperparameters path \u8d85\u53c2\u6570\u6587\u4ef6 \u8def\u5f84 --epochs Total training rounds \u8bad\u7ec3\u603b\u8f6e\u6b21 --batch-size total batch size for all GPUs, -1 for autobatch \u4e00\u6b21\u8bad\u7ec3\u6240\u9009\u53d6\u7684\u6837\u672c\u6570 --imgsz train, val image size (pixels) \u8f93\u5165\u56fe\u7247\u5206\u8fa8\u7387\u5927\u5c0f --rect rectangular training \u662f\u5426\u91c7\u7528\u77e9\u5f62\u8bad\u7ec3\uff0c\u9ed8\u8ba4False --resume resume most recent training \u63a5\u7740\u6253\u65ad\u8bad\u7ec3\u4e0a\u6b21\u7684\u7ed3\u679c\u63a5\u7740\u8bad\u7ec3 --nosave only save final checkpoint \u53ea\u4fdd\u5b58\u6700\u7ec8\u7684\u6a21\u578b\uff0c\u9ed8\u8ba4False --noautoanchor disable AutoAnchor \u4e0d\u81ea\u52a8\u8c03\u6574anchor\uff0c\u9ed8\u8ba4False --noplots save no plot files \u4e0d\u4fdd\u5b58\u6253\u5370\u6587\u4ef6\uff0c\u9ed8\u8ba4False --evolve evolve hyperparameters for x generations \u662f\u5426\u8fdb\u884c\u8d85\u53c2\u6570\u8fdb\u5316\uff0c\u9ed8\u8ba4False --bucket gsutil bucket \u8c37\u6b4c\u4e91\u76d8bucket\uff0c\u4e00\u822c\u4e0d\u4f1a\u7528\u5230 --cache --cache images in \"ram\" (default) or \"disk\" \u662f\u5426\u63d0\u524d\u7f13\u5b58\u56fe\u7247\u5230\u5185\u5b58\uff0c\u4ee5\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\uff0c\u9ed8\u8ba4False --device cuda device, i.e. 0 or 0,1,2,3 or cpu \u8bad\u7ec3\u7684\u8bbe\u5907\uff0ccpu\uff1b0(\u8868\u793a\u4e00\u4e2agpu\u8bbe\u5907cuda:0)\uff1b0,1,2,3(\u591a\u4e2agpu\u8bbe\u5907) --multi-scale vary img-size +/- 50%% \u662f\u5426\u8fdb\u884c\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u9ed8\u8ba4False --single-cls train multi-class data as single-class \u6570\u636e\u96c6\u662f\u5426\u53ea\u6709\u4e00\u4e2a\u7c7b\u522b\uff0c\u9ed8\u8ba4False --optimizer optimizer \u4f18\u5316\u5668 --sync-bn use SyncBatchNorm, only available in DDP mode \u662f\u5426\u4f7f\u7528\u8de8\u5361\u540c\u6b65BN,\u5728DDP\u6a21\u5f0f\u4f7f\u7528 --workers max dataloader workers (per RANK in DDP mode) dataloader\u7684\u6700\u5927worker\u6570\u91cf --project save to project path \u4fdd\u5b58\u5230\u9879\u76ee\u7ed3\u679c\u5730\u5740 --name save to project/name/ \u4fdd\u5b58\u5230\u9879\u76ee\u7ed3\u679c/\u540d\u79f0 --exist-ok existing project/name ok, do not increment \u73b0\u6709\u9879\u76ee/\u540d\u79f0\u786e\u5b9a\uff0c\u4e0d\u9012\u589e\uff0c\u9ed8\u8ba4False --quad quad dataloader \u56db\u5143\u6570\u636e\u52a0\u8f7d\u5668 \u5f00\u542f\u4e4b\u540e\u5728\u5c3a\u5bf8\u5927\u4e8e640\u7684\u56fe\u50cf\u4e0a\u8bc6\u522b\u6548\u679c\u66f4\u597d\uff0c\u4f46\u662f\u6709\u53ef\u80fd\u4f1a\u4f7f\u5728640\u5c3a\u5bf8\u7684\u56fe\u7247\u4e0a\u6548\u679c\u66f4\u5dee --cos-lr cosine LR scheduler \u662f\u5426\u91c7\u7528\u9000\u706b\u4f59\u5f26\u5b66\u4e60\u7387\uff0c\u9ed8\u8ba4False --label-smoothing Label smoothing epsilon \u6807\u7b7e\u5e73\u6ed1 --patience EarlyStopping patience (epochs without improvement) \u65e9\u505c\u673a\u5236\uff0c\u9ed8\u8ba4False --freez Freeze layers: backbone=10, first3=0 1 2 \u51bb\u7ed3\u5c42\u6570\uff0c\u9ed8\u8ba4\u4e0d\u51bb\u7ed3 --save-period Save checkpoint every x epochs (disabled if < 1) \u7528\u4e8e\u8bb0\u5f55\u8bad\u7ec3\u65e5\u5fd7\u4fe1\u606f\uff0cint \u578b\uff0c\u9ed8\u8ba4 -1 --seed Global training seed \u968f\u673a\u6570\u79cd\u5b50\u8bbe\u7f6e --local_rank Automatic DDP Multi-GPU argument, do not modify \u81ea\u52a8\u5355\u673a\u591a\u5361\u8bad\u7ec3 \u4e00\u822c\u4e0d\u6539\u52a8 \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data https://docs.ultralytics.com/quick-start/","title":"3.3  \u6a21\u578b\u8bad\u7ec3"},{"location":"tutorials/03_chapter/model_train.html#_1","text":"","title":"\u9879\u76ee\u7ed3\u6784\u9884\u89c8 \ud83c\udfe0"},{"location":"tutorials/03_chapter/model_train.html#coco","text":"","title":"\u8bad\u7ec3\u6307\u4ee4(\u4f7f\u7528coco\u6570\u636e\u96c6\u4e3a\ud83c\udf30)"},{"location":"tutorials/03_chapter/model_train.html#_2","text":"\u5e26\u6743\u91cd\u8bad\u7ec3 \ud83d\ude80 $ python path/to/train.py --data coco.yaml --weights yolov5s --img 640 \u4e0d\u5e26\u6743\u91cd\u8bad\u7ec3 \ud83d\ude80 $ python path/to/train.py --data coco.yaml --weights '' --cfg yolov5s.yaml --img 640","title":"\ud83d\udccc\u4e24\u79cd\u8bad\u7ec3\u65b9\u5f0f"},{"location":"tutorials/03_chapter/model_train.html#gpu","text":"$ python train.py --data coco.yaml --weights yolov5s --device 0","title":"\ud83d\udccc\u5355GPU\u8bad\u7ec3"},{"location":"tutorials/03_chapter/model_train.html#gpu_1","text":"$ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --weights yolov5s --device 0,1 \u6ce8\u610f\u26a0\ufe0f\uff1a --nproc_per_node \u6307\u5b9a\u8981\u4f7f\u7528\u591a\u5c11GPU\u3002\u4e3e\u4e2a\u4f8b\u5b50\ud83c\udf30:\u5728\u4e0a\u9762\ud83d\udc46 \u591aGPU\u8bad\u7ec3\u6307\u4ee4\u4e2d\u5b83\u662f2\u3002 --batch \u6279\u5904\u7406\u6570\u91cf\uff08 \u5373\u4e00\u6b21\u8bad\u7ec3\u6240\u9009\u53d6\u7684\u6837\u672c\u6570 )\u3002\u5b83\u5c06\u5e73\u5747\u5206\u914d\u7ed9\u6bcf\u4e2aGPU\u3002\u5728\u4e0a\u9762\ud83d\udc46\u7684\u793a\u4f8b\u4e2d\uff0c\u6bcfGPU\u5206\u914d 64/2\uff1d32 \u4e2a\u6837\u672c\u3002 \u4e0a\u9762\u7684\u4ee3\u7801\u9ed8\u8ba4\u4f7f\u7528GPU 0\u2026\uff08N-1\uff09\u3002\u4f7f\u7528\u7279\u5b9a\u7684GPU\ud83e\udd14\ufe0f\uff1f \u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5728 --device \u540e\u8ddf\u6307\u5b9aGPU\u6765\u5b9e\u73b0\u3002\u300c\u6848\u4f8b\ud83c\udf30\u300d\uff0c\u5728\u4e0b\u9762\u7684\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528GPU 2,3\u3002 $ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights '' --device 2,3","title":"\ud83d\udccc\u591aGPU\u8bad\u7ec3"},{"location":"tutorials/03_chapter/model_train.html#syncbatchnorm","text":"SyncBatchNorm \u53ef\u4ee5\u63d0\u9ad8\u591agpu\u8bad\u7ec3\u7684\u51c6\u786e\u6027\uff0c\u4f46\u4f1a\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u901f\u5ea6\u3002\u5b83\u4ec5\u9002\u7528\u4e8e\u591aGPU DistributedDataParallel \u8bad\u7ec3\u3002 \u5efa\u8bae\u6700\u597d\u5728\u6bcf\u4e2aGPU\u4e0a\u7684\u6837\u672c\u6570\u91cf\u8f83\u5c0f\uff08 \u6837\u672c\u6570\u91cf<=8 \uff09\u65f6\u4f7f\u7528\u3002 \u8981\u4f7f\u7528SyncBatchNorm\uff0c\u53ea\u9700\u5c06\u6dfb\u52a0 --sync-bn \u53c2\u6570\u9009\u9879\uff0c\u5177\u4f53\u300c\u6848\u4f8b\ud83c\udf30\u300d\u5982\u4e0b: $ python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' -- sync - bn \ud83d\udce2 \u66f4\u591a\u53c2\u6570\u89e3\u6790\u8be6\u89c1 \u9644\u4ef6\u88683.1 \u3002","title":"\ud83d\udccc\u4f7f\u7528SyncBatchNorm"},{"location":"tutorials/03_chapter/model_train.html#_3","text":"","title":"\u8bad\u7ec3\u7ed3\u679c\ud83c\udf1f"},{"location":"tutorials/03_chapter/model_train.html#_4","text":"\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u7ed3\u679c\u90fd\u8bb0\u5f55\u4e3aruns/train\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u65b0\u8bad\u7ec3\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u8bad\u7ec3\u7ed3\u679c\u76ee\u5f55\uff0c\u5982runs/train/exp2\u3001runs/train/exp3\u7b49\u3002\u67e5\u770b\u8bad\u7ec3\u548c\u6d4b\u8bd5JPG\u4ee5\u67e5\u770b mosaics, labels, predictions and augmentation \u6548\u679c\u3002 \u6ce8\u610f\uff1aMosaic Dataloader \u7528\u4e8e\u8bad\u7ec3\uff08\u5982\u4e0b\u6240\u793a\uff09\uff0c\u8fd9\u662fUltralytics\u53d1\u8868\u7684\u65b0\u6982\u5ff5\uff0c\u9996\u6b21\u51fa\u73b0\u5728 YOLOv4 \u4e2d\u3002 train_batch0.jpg \u663e\u793a batch \u4e3a 0 \u7684 (mosaics and labels): val_batch0_labels.jpg \u5c55\u793a\u6d4b\u8bd5 batch \u4e3a 0 \u7684labels: val_batch0_pred.jpg \u5c55\u793a\u6d4b\u8bd5 batch \u4e3a 0 predictions(\u9884\u6d4b): \u8bad\u7ec3\u8bad\u635f\u5931\u548c\u6027\u80fd\u7684\u6307\u6807\u6709\u8bb0\u5f55\u5230Tensorboard\u548c\u81ea\u5b9a\u4e49\u7ed3\u679c\u4e2d results.csv\u65e5\u5fd7\u6587\u4ef6 \uff0c\u8bad\u7ec3\u8bad\u5b8c\u6210\u540e\u4f5c\u4e3a\u7ed3\u679c\u7ed8\u5236 results.png\u5982\u4e0b\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5728COCO128\u4e0a\u8bad\u7ec3\u7684YOLOV5\u7ed3\u679c - \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 (\u84dd\u8272)\u3002 - \u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd --weights yolov5s (\u6a59\u8272)\u3002 \u5177\u4f53\u7684\u6307\u6807\u5206\u6790\u8be6\u89c1\u6587\u7ae0 \u300a\u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30\u300b","title":"\ud83d\udccc\u672c\u5730\u65e5\u5fd7"},{"location":"tutorials/03_chapter/model_train.html#valpy","text":"\u4e0b\u9762\u7684\u547d\u4ee4\u662f\u5728COCO val2017\u6570\u636e\u96c6\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5 YOLOv5x \u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5s \uff0c yolov5l \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 README-TABLE $ python val . py -- weights yolov5x -- data coco . yaml -- img 640","title":"\u6a21\u578b\u6d4b\u8bd5(val.py) \ud83d\udd25"},{"location":"tutorials/03_chapter/model_train.html#_5","text":"python detect . py -- weights yolov5s -- img 832","title":"\u6a21\u578b\u9884\u6d4b\ud83d\udd25"},{"location":"tutorials/03_chapter/model_train.html#_6","text":"\ud83d\udce2 \u58f0\u660e\uff1a\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c \u53ea\u8981\u6570\u636e\u96c6\u8db3\u591f\u5927\u4e14\u6807\u8bb0\u826f\u597d \uff0c\u5c31\u53ef\u4ee5\u5728\u4e0d\u6539\u53d8\u6a21\u578b\u6216\u8bad\u7ec3\u8bbe\u7f6e\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u826f\u597d\u7684\u7ed3\u679c\u3002 \u5982\u679c\u4e00\u5f00\u59cb\u4f60\u6ca1\u6709\u5f97\u5230\u597d\u7684\u7ed3\u679c\uff0c\u4f60\u53ef\u4ee5\u91c7\u53d6\u4e00\u4e9b\u6b65\u9aa4\u6765\u6539\u8fdb\uff0c\u4f46\u6211\u4eec\u59cb\u7ec8\u5efa\u8bae\u7528\u6237\u5728\u8003\u8651\u4efb\u4f55\u66f4\u6539\u4e4b\u524d\u5148\u4f7f\u7528\u6240\u6709\u9ed8\u8ba4\u8bbe\u7f6e\u8fdb\u884c\u4e00\u6b21\u8bad\u7ec3\u3002\u8fd9\u6709\u52a9\u4e8e\u5efa\u7acb\u8bc4\u4f30\u57fa\u51c6\u548c\u53d1\u73b0\u9700\u8981\u6539\u8fdb\u7684\u5730\u65b9 \ud83d\ude80\u3002","title":"\u8bad\u7ec3\u6280\u5de7\ud83d\udd25"},{"location":"tutorials/03_chapter/model_train.html#_7","text":"\u7c7b\u4f3c\u4e8eYOLOv5x\u548cYOLOv5x6\u7684\u5927\u578b\u6a21\u578b\u5728\u51e0\u4e4e\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u4f1a\u4ea7\u751f\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u4f46\u53c2\u6570\u66f4\u591a\uff0c\u9700\u8981\u66f4\u591a\u7684CUDA\u5185\u5b58\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd0\u884c\u901f\u5ea6\u8f83\u6162\u3002 \u5bf9\u4e8e\u79fb\u52a8\u90e8\u7f72\uff0c\u6211\u4eec\u63a8\u8350YOLOv5s/m\uff0c\u5bf9\u4e8e\u4e91\u90e8\u7f72\uff0c\u6211\u4eec\u5efa\u8baeYOLOV5l/x\u3002 \u6709\u5173\u6240\u6709\u6a21\u578b\u7684\u5b8c\u6574\u6bd4\u8f83\uff0c\u8bf7\u53c2\u9605 \u8be6\u7ec6\u8868 \u4ece\u9884\u5148\u8bad\u7ec3\u7684\u6743\u91cd\u5f00\u59cb\u8bad\u7ec3\u3002\u5efa\u8bae\u7528\u4e8e\u4e2d\u5c0f\u578b\u6570\u636e\u96c6\uff08\u5373 VOC \u3001 VisDrone \u3001 GlobalWheat \uff09\u3002\u5c06\u6a21\u578b\u7684\u540d\u79f0\u4f20\u9012\u7ed9--weights\u53c2\u6570\u3002\u6a21\u578b\u81ea\u52a8\u4ece latest YOLOv5 releasse \u4e0b\u8f7d \u3002 python train . py -- data custom . yaml -- weights yolov5s yolov5m yolov5l yolov5x custom_pretrained # \u81ea\u5b9a\u4e49\u7684\u7f51\u7edc\u7ed3\u6784\u6587\u4ef6 \u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7684\u8bdd\uff0c\u63a8\u8350\u7528\u5927\u7684\u6570\u636e\u96c6(\u5373 COCO\u3001Objects365\u3001OIv6 )\u5728 --cfg \u9009\u9879\u540e\u4f20\u9012\u60a8\u611f\u5174\u8da3\u7684\u7f51\u7edc\u7ed3\u6784\u6587\u4ef6\u53c2\u6570 \u4ee5\u53ca\u7a7a\u7684 --weights '' \u53c2\u6570\uff1a python train . py -- data custom . yaml -- weights '' -- cfg yolov5s . yaml yolov5m . yaml yolov5l . yaml yolov5x . yaml","title":"\ud83d\udccc\u6a21\u578b\u9009\u62e9"},{"location":"tutorials/03_chapter/model_train.html#_8","text":"\u5728\u4fee\u6539\u4efb\u4f55\u5185\u5bb9\u4e4b\u524d\uff0c\u9996\u5148\u4f7f\u7528\u9ed8\u8ba4\u8bbe\u7f6e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u5efa\u7acb\u6027\u80fd\u57fa\u7ebf\u3002\u8bad\u7ec3\u53c2\u6570\u7684\u5b8c\u6574\u5217\u8868,\u80fd\u591f\u53d1\u73b0\u5728train.py\u6587\u4ef6\u4e2d\u3002 Epochs : \u9ed8\u8ba4\u8bad\u7ec3300\u4e2aepochs\u3002\u5982\u679c\u65e9\u671f\u8fc7\u62df\u5408\uff0c\u5219\u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u3002\u5982\u679c\u5728300\u4e2a\u5468\u671f\u540e\u672a\u53d1\u751f\u8fc7\u62df\u5408\uff0c\u5219\u53ef\u4ee5\u8bad\u7ec3\u66f4\u957f\uff0c\u6bd4\u5982600\u30011200\u4e2aepochs\u3002 Image size: COCO\u4ee5 --img 640,\u7684\u5206\u8fa8\u7387\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u96c6\u4e2d\u6709\u5927\u91cf\u7684\u5c0f\u5bf9\u8c61\uff0c\u5b83\u53ef\u4ee5\u4ece\u66f4\u9ad8\u5206\u8fa8\u7387\uff08\u5982--img 1280\uff09\u7684\u8bad\u7ec3\u4e2d\u8bad\u7ec3\u3002 \u5982\u679c\u6709\u8bb8\u591a\u5c0f\u5bf9\u8c61\uff0c\u5219\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u5c06\u4ece\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8bad\u7ec3\u4e2d\u83b7\u76ca\u3002\u6700\u597d\u7684\u63a8\u65ad\u7ed3\u679c\u662f\u5728\u76f8\u540c\u7684--img \u5904\u83b7\u5f97\u7684 \uff0c\u5373\u5982\u679c\u5728-img 1280\u5904\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e5f\u5e94\u8be5\u5728--img 1280\u5904\u8fdb\u884c\u6d4b\u8bd5\u548c\u68c0\u6d4b\u3002 Batch Size: \u4f7f\u7528\u66f4\u5927\u7684 --batch-size \u3002\u80fd\u591f\u6709\u6548\u7f13\u89e3\u5c0f\u6837\u672c\u6570\u4ea7\u751f\u7684batchnorm\u7edf\u8ba1\u7684\u9519\u8bef\u3002 Hyperparameters\uff1a \u9ed8\u8ba4\u8d85\u53c2\u6570\u5728hyp.scratch-low.yaml\u6587\u4ef6\u4e2d\u3002\u6211\u4eec\u5efa\u8bae\u60a8\u5728\u8003\u8651\u4fee\u6539\u4efb\u4f55\u8d85\u53c2\u6570\u4e4b\u524d\uff0c\u5148\u4f7f\u7528\u9ed8\u8ba4\u8d85\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u589e\u52a0\u589e\u5f3a\u8d85\u53c2\u6570\u5c06\u51cf\u5c11\u548c\u5ef6\u8fdf\u8fc7\u5ea6\u62df\u5408\uff0c\u5141\u8bb8\u66f4\u957f\u7684\u8bad\u7ec3\u548c\u5f97\u5230\u66f4\u9ad8mAP\u503c\u3002\u51cf\u5c11\u635f\u8017\u5206\u91cf\u589e\u76ca\u8d85\u53c2\u6570\uff0c\u5982hyp['obj']\uff0c\u5c06\u6709\u52a9\u4e8e\u51cf\u5c11\u8fd9\u4e9b\u7279\u5b9a\u635f\u8017\u5206\u91cf\u4e2d\u7684\u8fc7\u5ea6\u62df\u5408\u3002\u6709\u5173\u4f18\u5316\u8fd9\u4e9b\u8d85\u53c2\u6570\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 \u300a\u8d85\u53c2\u6570\u6f14\u5316\u6559\u7a0b\u300b \u3002","title":"\ud83d\udccc\u8bad\u7ec3\u914d\u7f6e"},{"location":"tutorials/03_chapter/model_train.html#_9","text":"","title":"\u62d3\u5c55 \ud83d\udcd8"},{"location":"tutorials/03_chapter/model_train.html#_10","text":"\u8fd9\u4ec5\u9002\u7528\u4e8e\u591aGPU\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u3002 \u5728\u8bad\u7ec3\u4e4b\u524d\uff0c\u786e\u4fdd\u6240\u6709\u673a\u5668\u4e0a\u7684\u6587\u4ef6\u90fd\u76f8\u540c\uff0c\u6570\u636e\u96c6\u3001\u4ee3\u7801\u5e93\u7b49\u3002\u4e4b\u540e\uff0c\u786e\u4fdd\u673a\u5668\u53ef\u4ee5\u76f8\u4e92\u901a\u4fe1\u3002 \u60a8\u5fc5\u987b\u9009\u62e9\u4e00\u53f0\u4e3b\u673a\u5668\uff08\u5176\u4ed6\u673a\u5668\u5c06\u4e0e\u4e4b\u5bf9\u8bdd\uff09\u3002\u8bb0\u4e0b\u5b83\u7684\u5730\u5740\uff08master_addr\uff09\u5e76\u9009\u62e9\u4e00\u4e2a\u7aef\u53e3\uff08master-port\uff09\u3002\u5bf9\u4e8e\u4e0b\u9762\u7684\u793a\u4f8b\uff0c\u5c06\u4f7f\u7528master_addr=192.168.1.1\u548cmaster_ port=1234\u3002 \u8981\u4f7f\u7528\u5b83\uff0c\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u6307\u4ee4\uff1a # On master machine 0 $ python - m oneflow . distributed . launch -- nproc_per_node G -- nnodes N -- node_rank 0 -- master_addr \"192.168.1.1\" -- master_port 1234 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' # On machine R $ python - m oneflow . distributed . launch -- nproc_per_node G -- nnodes N -- node_rank R -- master_addr \"192.168.1.1\" -- master_port 1234 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' \u5176\u4e2dG\u662f\u6bcf\u53f0\u673a\u5668\u7684GPU\u6570\u91cf\uff0cN\u662f\u673a\u5668\u6570\u91cf\uff0cR\u662f\u4ece0\u5230\uff08N-1\uff09\u7684\u673a\u5668\u6570\u91cf\u3002 \u5047\u8bbe\u6211\u6709\u4e24\u53f0\u673a\u5668\uff0c\u6bcf\u53f0\u673a\u5668\u6709\u4e24\u4e2aGPU\uff0c\u5bf9\u4e8e\u4e0a\u9762\u7684\u60c5\u51b5\uff0cG=2\uff0cN=2\uff0cR=1\u3002 \u5728\u8fde\u63a5\u6240\u6709N\u53f0\u673a\u5668\u4e4b\u524d\uff0c\u8bad\u7ec3\u4e0d\u4f1a\u5f00\u59cb\u3002\u8f93\u51fa\u5c06\u4ec5\u663e\u793a\u5728\u4e3b\u673a\u4e0a\uff01","title":"\ud83d\udccc\u4f7f\u7528\u591a\u673a\u8bad\u7ec3"},{"location":"tutorials/03_chapter/model_train.html#_11","text":"oneflow\u76ee\u524d\u4e0d\u652f\u6301windows\u5e73\u53f0 --batch \u5fc5\u987b\u662fGPU\u6570\u91cf\u7684\u500d\u6570\u3002 GPU 0 \u5c06\u6bd4\u5176\u4ed6GPU\u5360\u7528\u7565\u591a\u7684\u5185\u5b58\uff0c\u56e0\u4e3a\u5b83\u7ef4\u62a4EMA\u5e76\u8d1f\u8d23\u68c0\u67e5\u70b9\u7b49\u3002 \u5982\u679c\u60a8\u5f97\u5230 RuntimeError: Address already in use \uff0c\u53ef\u80fd\u662f\u56e0\u4e3a\u60a8\u4e00\u6b21\u6b63\u5728\u8fd0\u884c\u591a\u4e2a\u57f9\u8bad\u3002\u8981\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u53ea\u9700\u901a\u8fc7\u6dfb\u52a0--master_port\u6765\u4f7f\u7528\u4e0d\u540c\u7684\u7aef\u53e3\u53f7\uff0c\u5982\u4e0b\u6240\u793a $ python - m oneflow . distributed . launch -- master_port 1234 -- nproc_per_node 2 ...","title":"\u6ce8\u610f\u26a0\ufe0f"},{"location":"tutorials/03_chapter/model_train.html#_12","text":"DDP \u5206\u6790\u7ed3\u679c\u5728 AWS EC2 P4d instance with 8x A100 SXM4-40GB for YOLOv5l for 1 COCO epoch.","title":"\u7ed3\u679c"},{"location":"tutorials/03_chapter/model_train.html#_13","text":"# prepare t = https : // github . com / Oneflow - Inc / one - yolov5 : latest && sudo docker pull $ t && sudo docker run - it -- ipc = host -- gpus all - v \"$(pwd)\" / coco : / usr / src / coco $ t pip install -- pre oneflow - f https : // staging . oneflow . info / branch / master / cu112 cd .. && rm - rf app && git clone https : // github . com / Oneflow - Inc / one - yolov5 - b master app && cd app cp data / coco . yaml data / coco_profile . yaml # profile python train . py -- batch - size 16 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- batch - size 32 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 python - m oneflow . distributed . launch -- nproc_per_node 4 train . py -- batch - size 64 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 , 2 , 3 python - m oneflow . distributed . launch -- nproc_per_node 8 train . py -- batch - size 128 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 \ud83d\udce2 \u5feb\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"\u914d\u7f6e\u4ee3\u7801\u26a1"},{"location":"tutorials/03_chapter/model_train.html#_14","text":"\u88683.1 \u88683.1 : train.py\u53c2\u6570\u89e3\u6790\u8868 \u53c2\u6570 help \u5e2e\u52a9 --weight initial weights path \u52a0\u8f7d\u7684\u6743\u91cd\u6587\u4ef6\u8def\u5f84 --cfg model.yaml path \u6a21\u578b\u914d\u7f6e\u6587\u4ef6\uff0c\u7f51\u7edc\u7ed3\u6784 \u8def\u5f84 --data dataset.yaml path \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6\uff0c\u6570\u636e\u96c6\u8def\u5f84 --hyp hyperparameters path \u8d85\u53c2\u6570\u6587\u4ef6 \u8def\u5f84 --epochs Total training rounds \u8bad\u7ec3\u603b\u8f6e\u6b21 --batch-size total batch size for all GPUs, -1 for autobatch \u4e00\u6b21\u8bad\u7ec3\u6240\u9009\u53d6\u7684\u6837\u672c\u6570 --imgsz train, val image size (pixels) \u8f93\u5165\u56fe\u7247\u5206\u8fa8\u7387\u5927\u5c0f --rect rectangular training \u662f\u5426\u91c7\u7528\u77e9\u5f62\u8bad\u7ec3\uff0c\u9ed8\u8ba4False --resume resume most recent training \u63a5\u7740\u6253\u65ad\u8bad\u7ec3\u4e0a\u6b21\u7684\u7ed3\u679c\u63a5\u7740\u8bad\u7ec3 --nosave only save final checkpoint \u53ea\u4fdd\u5b58\u6700\u7ec8\u7684\u6a21\u578b\uff0c\u9ed8\u8ba4False --noautoanchor disable AutoAnchor \u4e0d\u81ea\u52a8\u8c03\u6574anchor\uff0c\u9ed8\u8ba4False --noplots save no plot files \u4e0d\u4fdd\u5b58\u6253\u5370\u6587\u4ef6\uff0c\u9ed8\u8ba4False --evolve evolve hyperparameters for x generations \u662f\u5426\u8fdb\u884c\u8d85\u53c2\u6570\u8fdb\u5316\uff0c\u9ed8\u8ba4False --bucket gsutil bucket \u8c37\u6b4c\u4e91\u76d8bucket\uff0c\u4e00\u822c\u4e0d\u4f1a\u7528\u5230 --cache --cache images in \"ram\" (default) or \"disk\" \u662f\u5426\u63d0\u524d\u7f13\u5b58\u56fe\u7247\u5230\u5185\u5b58\uff0c\u4ee5\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\uff0c\u9ed8\u8ba4False --device cuda device, i.e. 0 or 0,1,2,3 or cpu \u8bad\u7ec3\u7684\u8bbe\u5907\uff0ccpu\uff1b0(\u8868\u793a\u4e00\u4e2agpu\u8bbe\u5907cuda:0)\uff1b0,1,2,3(\u591a\u4e2agpu\u8bbe\u5907) --multi-scale vary img-size +/- 50%% \u662f\u5426\u8fdb\u884c\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u9ed8\u8ba4False --single-cls train multi-class data as single-class \u6570\u636e\u96c6\u662f\u5426\u53ea\u6709\u4e00\u4e2a\u7c7b\u522b\uff0c\u9ed8\u8ba4False --optimizer optimizer \u4f18\u5316\u5668 --sync-bn use SyncBatchNorm, only available in DDP mode \u662f\u5426\u4f7f\u7528\u8de8\u5361\u540c\u6b65BN,\u5728DDP\u6a21\u5f0f\u4f7f\u7528 --workers max dataloader workers (per RANK in DDP mode) dataloader\u7684\u6700\u5927worker\u6570\u91cf --project save to project path \u4fdd\u5b58\u5230\u9879\u76ee\u7ed3\u679c\u5730\u5740 --name save to project/name/ \u4fdd\u5b58\u5230\u9879\u76ee\u7ed3\u679c/\u540d\u79f0 --exist-ok existing project/name ok, do not increment \u73b0\u6709\u9879\u76ee/\u540d\u79f0\u786e\u5b9a\uff0c\u4e0d\u9012\u589e\uff0c\u9ed8\u8ba4False --quad quad dataloader \u56db\u5143\u6570\u636e\u52a0\u8f7d\u5668 \u5f00\u542f\u4e4b\u540e\u5728\u5c3a\u5bf8\u5927\u4e8e640\u7684\u56fe\u50cf\u4e0a\u8bc6\u522b\u6548\u679c\u66f4\u597d\uff0c\u4f46\u662f\u6709\u53ef\u80fd\u4f1a\u4f7f\u5728640\u5c3a\u5bf8\u7684\u56fe\u7247\u4e0a\u6548\u679c\u66f4\u5dee --cos-lr cosine LR scheduler \u662f\u5426\u91c7\u7528\u9000\u706b\u4f59\u5f26\u5b66\u4e60\u7387\uff0c\u9ed8\u8ba4False --label-smoothing Label smoothing epsilon \u6807\u7b7e\u5e73\u6ed1 --patience EarlyStopping patience (epochs without improvement) \u65e9\u505c\u673a\u5236\uff0c\u9ed8\u8ba4False --freez Freeze layers: backbone=10, first3=0 1 2 \u51bb\u7ed3\u5c42\u6570\uff0c\u9ed8\u8ba4\u4e0d\u51bb\u7ed3 --save-period Save checkpoint every x epochs (disabled if < 1) \u7528\u4e8e\u8bb0\u5f55\u8bad\u7ec3\u65e5\u5fd7\u4fe1\u606f\uff0cint \u578b\uff0c\u9ed8\u8ba4 -1 --seed Global training seed \u968f\u673a\u6570\u79cd\u5b50\u8bbe\u7f6e --local_rank Automatic DDP Multi-GPU argument, do not modify \u81ea\u52a8\u5355\u673a\u591a\u5361\u8bad\u7ec3 \u4e00\u822c\u4e0d\u6539\u52a8","title":"\u9644\u4ef6"},{"location":"tutorials/03_chapter/model_train.html#_15","text":"https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data https://docs.ultralytics.com/quick-start/","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/03_chapter/quick_start.html","text":"\u5b89\u88c5 \ud83d\udcda git clone https://github.com/Oneflow-Inc/one-yolov5 # clone cd one-yolov5 pip install -r requirements.txt # install \u8bad\u7ec3 \ud83d\ude80 \ud83d\udccc\u5355\u5361 $ python train.py --data coco.yaml --weights yolov5s --device 0 \ud83d\udccc\u591a\u5361 $ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --weights yolov5s --device 0,1 \u6ce8\u610f\u26a0\ufe0f\uff1a --nproc_per_node \u6307\u5b9a\u8981\u4f7f\u7528\u591a\u5c11GPU\u3002\u4e3e\u4e2a\u4f8b\u5b50\ud83c\udf30:\u5728\u4e0a\u9762\ud83d\udc46 \u591aGPU\u8bad\u7ec3\u6307\u4ee4\u4e2d\u5b83\u662f2\u3002 --batch \u662f\u603b\u6279\u91cf\u5927\u5c0f\u3002\u5b83\u5c06\u5e73\u5747\u5206\u914d\u7ed9\u6bcf\u4e2aGPU\u3002\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u6bcfGPU\u662f64/2\uff1d32\u3002 --cfg : \u6307\u5b9a\u4e00\u4e2a\u5305\u542b\u6240\u6709\u8bc4\u4f30\u53c2\u6570\u7684\u914d\u7f6e\u6587\u4ef6\u3002 \u4e0a\u9762\u7684\u4ee3\u7801\u9ed8\u8ba4\u4f7f\u7528GPU 0\u2026\uff08N-1\uff09\u3002\u4f7f\u7528\u7279\u5b9a\u7684GPU\ud83e\udd14\ufe0f\uff1f \u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5728 --device \u540e\u8ddf\u6307\u5b9aGPU\u6765\u5b9e\u73b0\u3002\u300c\u6848\u4f8b\ud83c\udf30\u300d\uff0c\u5728\u4e0b\u9762\u7684\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528GPU 2,3\u3002 $ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights '' --device 2,3 \ud83d\udccc\u6062\u590d\u8bad\u7ec3 \u5982\u679c\u60a8\u7684\u8bad\u7ec3\u8fdb\u7a0b\u4e2d\u65ad\u4e86\uff0c\u60a8\u53ef\u4ee5\u8fd9\u6837\u6062\u590d\u5148\u524d\u7684\u8bad\u7ec3\u8fdb\u7a0b\u3002 # \u591a\u5361\u8bad\u7ec3. python -m oneflow.distributed.launch --nproc_per_node 2 train.py --resume \u60a8\u4e5f\u53ef\u4ee5\u901a\u8fc7 --resume \u53c2\u6570\u6307\u5b9a\u8981\u6062\u590d\u7684\u6a21\u578b\u8def\u5f84 # \u8bb0\u5f97\u628a /path/to/your/checkpoint/path \u66ff\u6362\u4e3a\u60a8\u8981\u6062\u590d\u8bad\u7ec3\u7684\u6a21\u578b\u6743\u91cd\u8def\u5f84 --resume /path/to/your/checkpoint/path \u8bc4\u4f30 \ud83d\udc63 \u4e0b\u9762\u7684\u547d\u4ee4\u662f\u5728COCO val2017\u6570\u636e\u96c6\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5 yolov5x \u6a21\u578b\u3002 yolov5x \u662f\u53ef\u7528\u5c0f\u6a21\u578b\u4e2d\u6700\u5927\u4e14\u6700\u7cbe\u786e\u7684\uff0c\u5176\u5b83\u53ef\u7528\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5s \uff0c yolov5l \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 README-TABLE $ python val . py -- weights yolov5x -- data coco . yaml -- img 640 \u63a8\u7406 \ud83d\udc4d \u9996\u5148\uff0c\u4e0b\u8f7d\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u6743\u91cd\u6587\u4ef6\uff0c\u6216\u9009\u62e9\u60a8\u81ea\u5df1\u8bad\u7ec3\u7684\u6a21\u578b\uff1b \u7136\u540e\uff0c \u901a\u8fc7 detect.py\u6587\u4ef6\u8fdb\u884c\u63a8\u7406\u26a1\u3002 python path / to / detect . py -- weights yolov5s -- source 0 # webcam img . jpg # image vid . mp4 # video path / # directory path /*. jpg # glob 'https://youtu.be/Zgi9g1ksQHc' # YouTube 'rtsp://example.com/media.mp4' # RTSP, RTMP, HTTP stream \u5feb\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"3.1. \u5feb\u901f\u5f00\u59cb"},{"location":"tutorials/03_chapter/quick_start.html#_1","text":"git clone https://github.com/Oneflow-Inc/one-yolov5 # clone cd one-yolov5 pip install -r requirements.txt # install","title":"\u5b89\u88c5 \ud83d\udcda"},{"location":"tutorials/03_chapter/quick_start.html#_2","text":"","title":"\u8bad\u7ec3 \ud83d\ude80"},{"location":"tutorials/03_chapter/quick_start.html#_3","text":"$ python train.py --data coco.yaml --weights yolov5s --device 0","title":"\ud83d\udccc\u5355\u5361"},{"location":"tutorials/03_chapter/quick_start.html#_4","text":"$ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --weights yolov5s --device 0,1 \u6ce8\u610f\u26a0\ufe0f\uff1a --nproc_per_node \u6307\u5b9a\u8981\u4f7f\u7528\u591a\u5c11GPU\u3002\u4e3e\u4e2a\u4f8b\u5b50\ud83c\udf30:\u5728\u4e0a\u9762\ud83d\udc46 \u591aGPU\u8bad\u7ec3\u6307\u4ee4\u4e2d\u5b83\u662f2\u3002 --batch \u662f\u603b\u6279\u91cf\u5927\u5c0f\u3002\u5b83\u5c06\u5e73\u5747\u5206\u914d\u7ed9\u6bcf\u4e2aGPU\u3002\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u6bcfGPU\u662f64/2\uff1d32\u3002 --cfg : \u6307\u5b9a\u4e00\u4e2a\u5305\u542b\u6240\u6709\u8bc4\u4f30\u53c2\u6570\u7684\u914d\u7f6e\u6587\u4ef6\u3002 \u4e0a\u9762\u7684\u4ee3\u7801\u9ed8\u8ba4\u4f7f\u7528GPU 0\u2026\uff08N-1\uff09\u3002\u4f7f\u7528\u7279\u5b9a\u7684GPU\ud83e\udd14\ufe0f\uff1f \u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5728 --device \u540e\u8ddf\u6307\u5b9aGPU\u6765\u5b9e\u73b0\u3002\u300c\u6848\u4f8b\ud83c\udf30\u300d\uff0c\u5728\u4e0b\u9762\u7684\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528GPU 2,3\u3002 $ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights '' --device 2,3","title":"\ud83d\udccc\u591a\u5361"},{"location":"tutorials/03_chapter/quick_start.html#_5","text":"\u5982\u679c\u60a8\u7684\u8bad\u7ec3\u8fdb\u7a0b\u4e2d\u65ad\u4e86\uff0c\u60a8\u53ef\u4ee5\u8fd9\u6837\u6062\u590d\u5148\u524d\u7684\u8bad\u7ec3\u8fdb\u7a0b\u3002 # \u591a\u5361\u8bad\u7ec3. python -m oneflow.distributed.launch --nproc_per_node 2 train.py --resume \u60a8\u4e5f\u53ef\u4ee5\u901a\u8fc7 --resume \u53c2\u6570\u6307\u5b9a\u8981\u6062\u590d\u7684\u6a21\u578b\u8def\u5f84 # \u8bb0\u5f97\u628a /path/to/your/checkpoint/path \u66ff\u6362\u4e3a\u60a8\u8981\u6062\u590d\u8bad\u7ec3\u7684\u6a21\u578b\u6743\u91cd\u8def\u5f84 --resume /path/to/your/checkpoint/path","title":"\ud83d\udccc\u6062\u590d\u8bad\u7ec3"},{"location":"tutorials/03_chapter/quick_start.html#_6","text":"\u4e0b\u9762\u7684\u547d\u4ee4\u662f\u5728COCO val2017\u6570\u636e\u96c6\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5 yolov5x \u6a21\u578b\u3002 yolov5x \u662f\u53ef\u7528\u5c0f\u6a21\u578b\u4e2d\u6700\u5927\u4e14\u6700\u7cbe\u786e\u7684\uff0c\u5176\u5b83\u53ef\u7528\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5s \uff0c yolov5l \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 README-TABLE $ python val . py -- weights yolov5x -- data coco . yaml -- img 640","title":"\u8bc4\u4f30 \ud83d\udc63"},{"location":"tutorials/03_chapter/quick_start.html#_7","text":"\u9996\u5148\uff0c\u4e0b\u8f7d\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u6743\u91cd\u6587\u4ef6\uff0c\u6216\u9009\u62e9\u60a8\u81ea\u5df1\u8bad\u7ec3\u7684\u6a21\u578b\uff1b \u7136\u540e\uff0c \u901a\u8fc7 detect.py\u6587\u4ef6\u8fdb\u884c\u63a8\u7406\u26a1\u3002 python path / to / detect . py -- weights yolov5s -- source 0 # webcam img . jpg # image vid . mp4 # video path / # directory path /*. jpg # glob 'https://youtu.be/Zgi9g1ksQHc' # YouTube 'rtsp://example.com/media.mp4' # RTSP, RTMP, HTTP stream \u5feb\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"\u63a8\u7406 \ud83d\udc4d"},{"location":"tutorials/04_chapter/mosaic.html","text":"\u5f15\u8a00 \\(YOLOv5\\) \u5728\u8bad\u7ec3\u6a21\u578b\u7684\u65f6\u5019\u4f7f\u7528\ud83d\ude80\u56fe\u50cf\u7a7a\u95f4\u548c\u8272\u5f69\u7a7a\u95f4\u7684\u6570\u636e\u589e\u5f3a( \u5728\u9a8c\u8bc1\u6a21\u578b\u7684\u65f6\u5019\u6ca1\u6709\u4f7f\u7528 )\uff0c\u901a\u8fc7\u8bad\u7ec3\u65f6\u91c7\u7528\u6570\u636e\u589e\u5f3a \u4ece\u800c\u4f7f\u5f97\u6bcf\u6b21\u52a0\u8f7d\u90fd\u662f\u65b0\u7684\u548c\u552f\u4e00\u7684\u56fe\u50cf\uff08 \u5373\u539f\u59cb\u56fe\u50cf+3\u4e2a\u968f\u673a\u56fe\u50cf \uff09\u5982\u4e0b\u56fe\u6240\u793a\u3002 \u56fe4.1 \u6570\u636e\u589e\u5f3a\u3002\u7ecf\u8fc7\u6570\u636e\u589e\u5f3a\u540e\u56fe\u50cf\u4e0d\u4f1a\u4ee5\u76f8\u540c\u7684\u65b9\u5f0f\u5448\u73b0\u4e24\u6b21\u3002 \u56fe\u7247\u6765\u6e90\uff1ahttps://docs.ultralytics.com/FAQ/augmentation/ \u8d85\u53c2\u6570\u6587\u4ef6 \u6570\u636e\u589e\u5f3a\u9ed8\u8ba4\u4f7f\u7528\u914d\u7f6e\u8d85\u53c2\u6570\u6587\u4ef6hyp.scratch.yaml\uff0c \u4e0b\u9762\u4ee5 hyp.scratch-low.yaml \u6587\u4ef6\u90e8\u5206\u53c2\u6570\u4e3a\u4f8b\uff0c\u5177\u4f53\u53c2\u6570\u89e3\u6790\u53ef\u89c1\u9644\u4ef6 \u88682.1 $ python train.py --hyp hyp.scratch-low.yaml Mosaic \u56fe4.2 Mosaic\u6570\u636e\u589e\u5f3a\u3002\u628a4\u5f20\u56fe\u7247\uff0c\u901a\u8fc7\u968f\u673a\u7f29\u653e\u3001\u968f\u673a\u88c1\u51cf\u3001\u968f\u673a\u6392\u5e03\u7684\u65b9\u5f0f\u8fdb\u884c\u62fc\u63a5\u3002 Copy paste \u56fe4.3 \u5206\u5272\u586b\u8865 Random affine (Rotation, Scale, Translation and Shear)\uff08\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u548c\u526a\u5207\uff09 \u56fe4.4 \u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u548c\u526a\u5207 \u56fe\u50cf MixUp \u56fe4.5 \u56fe\u50cf\u878d\u5408 Albumentations YOLOv5 \ud83d\ude80 \u96c6\u6210\u4e86Albumentations(\u4e00\u4e2a\u6d41\u884c\u7684\u5f00\u6e90\u56fe\u50cf\u589e\u5f3a\u5305)\u3002 \u53ef\u4ee5\u901a\u8fc7\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u66f4\u597d\u5730\u8bad\u7ec3\uff0c\u4e16\u754c\u4e0a\u6700\u68d2\u7684\u89c6\u89c9AI\u6a21\u578b\ud83d\ude03! \u56fe4.6 Albumentations Augment HSV (Hue, Saturation, Value) \u8272\u8c03\u3001\u9971\u548c\u5ea6\u3001\u66dd\u5149\u5ea6 \u56fe4.5 \u8272\u8c03\u3001\u9971\u548c\u5ea6\u3001\u66dd\u5149\u5ea6 Random horizontal flip (\u968f\u673a\u6c34\u5e73\u6216\u7ffb\u8f6c) \u56fe4.6 \u968f\u673a\u6c34\u5e73\u6216\u7ffb\u8f6c Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5 Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u5c06\u591a\u5f20\u56fe\u7247\u6309\u7167\u4e00\u5b9a\u6bd4\u4f8b\u7ec4\u5408\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u4f7f\u6a21\u578b\u5728\u66f4\u5c0f\u7684\u8303\u56f4\u5185\u8bc6\u522b\u76ee\u6807\u3002Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u53c2\u8003 CutMix\u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u3002CutMix\u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u4f7f\u7528\u4e24\u5f20\u56fe\u7247\u8fdb\u884c\u62fc\u63a5\uff0c\u800c Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u4e00\u822c\u4f7f\u7528\u56db\u5f20\u8fdb\u884c\u62fc\u63a5\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002 Mosaic\u65b9\u6cd5\u6b65\u9aa4 \u968f\u673a\u9009\u53d6\u56fe\u7247\u62fc\u63a5\u57fa\u51c6\u70b9\u5750\u6807 \\((x_c\uff0cy_c)\\) \uff0c\u53e6\u968f\u673a\u9009\u53d6\u56db\u5f20\u56fe\u7247\u3002 \u56db\u5f20\u56fe\u7247\u6839\u636e\u57fa\u51c6\u70b9\uff0c\u5206\u522b\u7ecf\u8fc7 \u5c3a\u5bf8\u8c03\u6574 \u548c \u6bd4\u4f8b\u7f29\u653e \u540e\uff0c\u653e\u7f6e\u5728\u6307\u5b9a\u5c3a\u5bf8\u7684\u5927\u56fe\u7684\u5de6\u4e0a\uff0c\u53f3\u4e0a\uff0c\u5de6\u4e0b\uff0c\u53f3\u4e0b\u4f4d\u7f6e\u3002 \u6839\u636e\u6bcf\u5f20\u56fe\u7247\u7684\u5c3a\u5bf8\u53d8\u6362\u65b9\u5f0f\uff0c\u5c06\u6620\u5c04\u5173\u7cfb\u5bf9\u5e94\u5230\u56fe\u7247\u6807\u7b7e\u4e0a\u3002 \u4f9d\u636e\u6307\u5b9a\u7684\u6a2a\u7eb5\u5750\u6807\uff0c\u5bf9\u5927\u56fe\u8fdb\u884c\u62fc\u63a5\u3002\u5904\u7406\u8d85\u8fc7\u8fb9\u754c\u7684\u68c0\u6d4b\u6846\u5750\u6807\u3002 Mosaic\u65b9\u6cd5\u4f18\u70b9 \u589e\u52a0\u6570\u636e\u591a\u6837\u6027\uff0c\u968f\u673a\u9009\u53d6\u56db\u5f20\u56fe\u50cf\u8fdb\u884c\u7ec4\u5408\uff0c\u7ec4\u5408\u5f97\u5230\u56fe\u50cf\u4e2a\u6570\u6bd4\u539f\u56fe\u4e2a\u6570\u8981\u591a\u3002 \u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u6df7\u5408\u56db\u5f20\u5177\u6709\u4e0d\u540c\u8bed\u4e49\u4fe1\u606f\u7684\u56fe\u7247\uff0c\u53ef\u4ee5\u8ba9\u6a21\u578b\u68c0\u6d4b\u8d85\u51fa\u5e38\u89c4\u8bed\u5883\u7684\u76ee\u6807\u3002 \u52a0\u5f3a\u6279\u5f52\u4e00\u5316\u5c42\uff08 \\(Batch \\ Normalization\\) \uff09\u7684\u6548\u679c\u3002\u5f53\u6a21\u578b\u8bbe\u7f6e \\(BN\\) \u64cd\u4f5c\u540e\uff0c\u8bad\u7ec3\u65f6\u4f1a\u5c3d\u53ef\u80fd\u589e\u5927\u6279\u6837\u672c\u603b\u91cf\uff08 \\(BatchSize\\) \uff09\uff0c\u56e0\u4e3a \\(BN\\) \u539f\u7406\u4e3a\u8ba1\u7b97\u6bcf\u4e00\u4e2a\u7279\u5f81\u5c42\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5982\u679c\u6279\u6837\u672c\u603b\u91cf\u8d8a\u5927\uff0c\u90a3\u4e48 \\(BN\\) \u8ba1\u7b97\u7684\u5747\u503c\u548c\u65b9\u5dee\u5c31\u8d8a\u63a5\u8fd1\u4e8e\u6574\u4e2a\u6570\u636e\u96c6\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u6548\u679c\u8d8a\u597d\u3002 Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u6709\u5229\u4e8e\u63d0\u5347\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u3002Mosaic \u6570\u636e\u589e\u5f3a\u56fe\u50cf\u7531\u56db\u5f20\u539f\u59cb\u56fe\u50cf\u62fc\u63a5\u800c\u6210\uff0c\u8fd9\u6837\u6bcf\u5f20\u56fe\u50cf\u4f1a\u6709\u66f4\u5927\u6982\u7387\u5305\u542b\u5c0f\u76ee\u6807\u3002 Mosaic\u6e90\u7801\u89e3\u8bfb \u601d\u8def\u6982\u62ec\uff1a\u5c06\u4e00\u5f20\u9009\u5b9a\u7684\u56fe\u7247\u548c\u968f\u673a\u76843\u5f20\u56fe\u7247\u8fdb\u884c\u968f\u673a\u88c1\u526a\uff0c\u518d\u62fc\u63a5\u5230\u4e00\u5f20\u56fe\u4e0a\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e ,\u53ef\u89c1\u672c\u6587 \u56fe4.2 \u3002 \u8fd9\u6837\u53ef\u4ee5\u4e30\u5bcc\u56fe\u7247\u7684\u80cc\u666f\uff0c\u800c\u4e14\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u8d77\u53d8\u76f8\u7684\u63d0\u9ad8\u4e86 \\(batch-size\\) \u5927\u5c0f\uff0c\u540c\u65f6\u5728\u8fdb\u884c \\(batch \\ normalization\\) \uff08\u6279\u91cf\u5f52\u4e00\u5316\uff09\u7684\u65f6\u5019\u4e5f\u4f1a\u8ba1\u7b97\u56db\u5f20\u56fe\u7247\u3002 \u8fd9\u4e2d\u65b9\u5f0f\u80fd\u4f7f\u5f97 \\(YOLOv5\\) \u5bf9\u4e8e \\(batch-size\\) \u5927\u5c0f\u5bf9\u6a21\u578b\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002 \u4e0b\u9762\u5bf9 utils/dataloaders.py\u4e2dMosaic \u7684\u5b9e\u73b0\u8fdb\u884c\u89e3\u8bfb\u3002 def load_mosaic ( self , index ): # YOLOv5 4-mosaic loader. Loads 1 image + 3 random images into a 4-image mosaic \"\"\" @param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 @return: img4: mosaic\u548c\u4eff\u5c04\u589e\u5f3a\u540e\u7684\u4e00\u5f20\u56fe\u7247 labels4: img4\u5bf9\u5e94\u7684target \"\"\" labels4 , segments4 = [], [] # \u83b7\u53d6\u56fe\u50cf\u5c3a\u5bf8 s = self . img_size # \u8fd9\u91cc\u662f\u968f\u673a\u751f\u6210mosaic\u4e2d\u5fc3\u70b9 yc , xc = ( int ( random . uniform ( - x , 2 * s + x )) for x in self . mosaic_border ) # mosaic center x, y # \u968f\u673a\u751f\u6210\u53e6\u59163\u5f20\u56fe\u7247\u7684\u7d22\u5f15 indices = [ index ] + random . choices ( self . indices , k = 3 ) # 3 additional image indices # \u5bf9\u8fd9\u4e9b\u7d22\u5f15\u503c\u968f\u673a\u6392\u5e8f random . shuffle ( indices ) # \u904d\u5386\u8fd94\u5f20\u56fe\u7247 for i , index in enumerate ( indices ): # Load image # \u52a0\u8f7d\u56fe\u7247\u5e76\u8fd4\u56de\u9ad8\u5bbd img , _ , ( h , w ) = self . load_image ( index ) # place img in img4 \u653e\u7f6e\u56fe\u7247 if i == 0 : # top left(\u5de6\u4e0a\u89d2) # \u751f\u6210\u80cc\u666f\u56fe np.full()\u51fd\u6570\u586b\u5145\u521d\u59cb\u5316\u5927\u56fe\uff0c\u5c3a\u5bf8\u662f4\u5f20\u56fe\u90a3\u4e48\u5927 img4 = np . full (( s * 2 , s * 2 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles # \u8bbe\u7f6e\u5927\u56fe\u4e0a\u7684\u4f4d\u7f6e\uff08\u8981\u4e48\u539f\u56fe\u5927\u5c0f\uff0c\u8981\u4e48\u653e\u5927\uff09\uff08w\uff0ch\uff09\u6216\uff08xc\uff0cyc\uff09\uff08\u65b0\u751f\u6210\u7684\u90a3\u5f20\u5927\u56fe\uff09 x1a , y1a , x2a , y2a = max ( xc - w , 0 ), max ( yc - h , 0 ), xc , yc # xmin, ymin, xmax, ymax (large image) # \u9009\u53d6\u5c0f\u56fe\u4e0a\u7684\u4f4d\u7f6e\uff08\u539f\u56fe\uff09 x1b , y1b , x2b , y2b = w - ( x2a - x1a ), h - ( y2a - y1a ), w , h # xmin, ymin, xmax, ymax (small image) elif i == 1 : # top right(\u53f3\u4e0a\u89d2) x1a , y1a , x2a , y2a = xc , max ( yc - h , 0 ), min ( xc + w , s * 2 ), yc x1b , y1b , x2b , y2b = 0 , h - ( y2a - y1a ), min ( w , x2a - x1a ), h elif i == 2 : # bottom left(\u5de6\u4e0b\u89d2) x1a , y1a , x2a , y2a = max ( xc - w , 0 ), yc , xc , min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = w - ( x2a - x1a ), 0 , w , min ( y2a - y1a , h ) elif i == 3 : # bottom right(\u53f3\u4e0b\u89d2) x1a , y1a , x2a , y2a = xc , yc , min ( xc + w , s * 2 ), min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = 0 , 0 , min ( w , x2a - x1a ), min ( y2a - y1a , h ) # \u5927\u56fe\u4e0a\u8d34\u4e0a\u5bf9\u5e94\u7684\u5c0f\u56fe img4 [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] padw = x1a - x1b padh = y1a - y1b # \u8ba1\u7b97\u5c0f\u56fe\u5230\u5927\u56fe\u4e0a\u65f6\u6240\u4ea7\u751f\u7684\u504f\u79fb\uff0c\u7528\u6765\u8ba1\u7b97mosaic\u589e\u5f3a\u540e\u7684\u6807\u7b7e\u7684\u4f4d\u7f6e # Labels \u83b7\u53d6\u6807\u7b7e \"\"\" \u5bf9label\u6807\u6ce8\u8fdb\u884c\u521d\u59cb\u5316\u64cd\u4f5c\uff1a \u5148\u8bfb\u53d6\u5bf9\u5e94\u56fe\u7247\u7684label\uff0c\u7136\u540e\u5c06xywh\u683c\u5f0f\u7684label\u6807\u51c6\u5316\u4e3a\u50cf\u7d20xy\u683c\u5f0f\u7684\u3002 segments4\u8f6c\u4e3a\u50cf\u7d20\u6bb5\u683c\u5f0f \u7136\u540e\u7edf\u7edf\u586b\u8fdb\u4e4b\u524d\u51c6\u5907\u7684\u6807\u6ce8\u5217\u8868 \"\"\" labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : # \u5c06xywh\uff08\u767e\u5206\u6bd4\u90a3\u4e9b\u503c\uff09\u6807\u51c6\u5316\u4e3a\u50cf\u7d20xy\u683c\u5f0f labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padw , padh ) # normalized xywh to pixel xyxy format # \u8f6c\u4e3a\u50cf\u7d20\u6bb5 segments = [ xyn2xy ( x , w , h , padw , padh ) for x in segments ] labels4 . append ( labels ) segments4 . extend ( segments ) # Concat/clip labels \u62fc\u63a5 labels4 = np . concatenate ( labels4 , 0 ) for x in ( labels4 [:, 1 :], * segments4 ): # np.clip\u622a\u53d6\u51fd\u6570\uff0c\u56fa\u5b9a\u503c\u57280\u52302s\u5185 np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img4, labels4 = replicate(img4, labels4) # replicate # Augment # \u8fdb\u884cmosaic\u7684\u65f6\u5019\u5c06\u56db\u5f20\u56fe\u7247\u6574\u5408\u5230\u4e00\u8d77\u4e4b\u540eshape\u4e3a[2*img_size,2*img_size] # \u5bf9mosaic\u6574\u5408\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u88c1\u526a\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size img4 , labels4 , segments4 = copy_paste ( img4 , labels4 , segments4 , p = self . hyp [ 'copy_paste' ]) img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove \u9644\u4ef6 \u88684.1 :\u6570\u636e\u589e\u5f3a\u53c2\u6570\u8868 \u53c2\u6570\u540d \u914d\u7f6e \u89e3\u6790 hsv_h: 0.015 # image HSV-Hue augmentation (fraction) \u8272\u8c03 hsv_s: 0.7 # image HSV-Saturation augmentation (fraction) \u9971\u548c\u5ea6 hsv_v: 0.4 # image HSV-Value augmentation (fraction) \u66dd\u5149\u5ea6 degrees: 0.0 # image rotation (+/- deg) \u65cb\u8f6c translate: 0.1 # image translation (+/- fraction) \u5e73\u79fb scale: 0.9 # image scale (+/- gain) \u7f29\u653e shear: 0.0 # image shear (+/- deg) \u9519\u5207(\u975e\u5782\u76f4\u6295\u5f71) perspective: 0.0 # image perspective (+/- fraction), range 0-0.001 \u900f\u89c6\u53d8\u6362 flipud: 0.0 # image flip up-down (probability) \u4e0a\u4e0b\u7ffb\u8f6c fliplr: 0.5 # image flip left-right (probability)\u5de6\u53f3\u7ffb\u8f6c mosaic: 1.0 # image mosaic (probability) \u56fe\u62fc\u63a5 mixup: 0.1 # image mixup (probability) \u56fe\u50cf\u878d\u5408 copy_paste: 0.0 # segment copy-paste (probability) \u5206\u5272\u586b\u8865 \u53c2\u8003\u6587\u7ae0 https://docs.ultralytics.com/FAQ/augmentation/","title":"4.1 mosaic \u89e3\u8bfb"},{"location":"tutorials/04_chapter/mosaic.html#_1","text":"\\(YOLOv5\\) \u5728\u8bad\u7ec3\u6a21\u578b\u7684\u65f6\u5019\u4f7f\u7528\ud83d\ude80\u56fe\u50cf\u7a7a\u95f4\u548c\u8272\u5f69\u7a7a\u95f4\u7684\u6570\u636e\u589e\u5f3a( \u5728\u9a8c\u8bc1\u6a21\u578b\u7684\u65f6\u5019\u6ca1\u6709\u4f7f\u7528 )\uff0c\u901a\u8fc7\u8bad\u7ec3\u65f6\u91c7\u7528\u6570\u636e\u589e\u5f3a \u4ece\u800c\u4f7f\u5f97\u6bcf\u6b21\u52a0\u8f7d\u90fd\u662f\u65b0\u7684\u548c\u552f\u4e00\u7684\u56fe\u50cf\uff08 \u5373\u539f\u59cb\u56fe\u50cf+3\u4e2a\u968f\u673a\u56fe\u50cf \uff09\u5982\u4e0b\u56fe\u6240\u793a\u3002 \u56fe4.1 \u6570\u636e\u589e\u5f3a\u3002\u7ecf\u8fc7\u6570\u636e\u589e\u5f3a\u540e\u56fe\u50cf\u4e0d\u4f1a\u4ee5\u76f8\u540c\u7684\u65b9\u5f0f\u5448\u73b0\u4e24\u6b21\u3002 \u56fe\u7247\u6765\u6e90\uff1ahttps://docs.ultralytics.com/FAQ/augmentation/","title":"\u5f15\u8a00"},{"location":"tutorials/04_chapter/mosaic.html#_2","text":"\u6570\u636e\u589e\u5f3a\u9ed8\u8ba4\u4f7f\u7528\u914d\u7f6e\u8d85\u53c2\u6570\u6587\u4ef6hyp.scratch.yaml\uff0c \u4e0b\u9762\u4ee5 hyp.scratch-low.yaml \u6587\u4ef6\u90e8\u5206\u53c2\u6570\u4e3a\u4f8b\uff0c\u5177\u4f53\u53c2\u6570\u89e3\u6790\u53ef\u89c1\u9644\u4ef6 \u88682.1 $ python train.py --hyp hyp.scratch-low.yaml","title":"\u8d85\u53c2\u6570\u6587\u4ef6"},{"location":"tutorials/04_chapter/mosaic.html#mosaic","text":"\u56fe4.2 Mosaic\u6570\u636e\u589e\u5f3a\u3002\u628a4\u5f20\u56fe\u7247\uff0c\u901a\u8fc7\u968f\u673a\u7f29\u653e\u3001\u968f\u673a\u88c1\u51cf\u3001\u968f\u673a\u6392\u5e03\u7684\u65b9\u5f0f\u8fdb\u884c\u62fc\u63a5\u3002","title":"Mosaic"},{"location":"tutorials/04_chapter/mosaic.html#copy-paste","text":"\u56fe4.3 \u5206\u5272\u586b\u8865","title":"Copy paste"},{"location":"tutorials/04_chapter/mosaic.html#random-affine","text":"(Rotation, Scale, Translation and Shear)\uff08\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u548c\u526a\u5207\uff09 \u56fe4.4 \u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u548c\u526a\u5207 \u56fe\u50cf","title":"Random affine"},{"location":"tutorials/04_chapter/mosaic.html#mixup","text":"\u56fe4.5 \u56fe\u50cf\u878d\u5408","title":"MixUp"},{"location":"tutorials/04_chapter/mosaic.html#albumentations","text":"YOLOv5 \ud83d\ude80 \u96c6\u6210\u4e86Albumentations(\u4e00\u4e2a\u6d41\u884c\u7684\u5f00\u6e90\u56fe\u50cf\u589e\u5f3a\u5305)\u3002 \u53ef\u4ee5\u901a\u8fc7\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u66f4\u597d\u5730\u8bad\u7ec3\uff0c\u4e16\u754c\u4e0a\u6700\u68d2\u7684\u89c6\u89c9AI\u6a21\u578b\ud83d\ude03! \u56fe4.6 Albumentations","title":"Albumentations"},{"location":"tutorials/04_chapter/mosaic.html#augment-hsv","text":"(Hue, Saturation, Value) \u8272\u8c03\u3001\u9971\u548c\u5ea6\u3001\u66dd\u5149\u5ea6 \u56fe4.5 \u8272\u8c03\u3001\u9971\u548c\u5ea6\u3001\u66dd\u5149\u5ea6","title":"Augment HSV"},{"location":"tutorials/04_chapter/mosaic.html#random-horizontal-flip","text":"(\u968f\u673a\u6c34\u5e73\u6216\u7ffb\u8f6c) \u56fe4.6 \u968f\u673a\u6c34\u5e73\u6216\u7ffb\u8f6c","title":"Random horizontal flip"},{"location":"tutorials/04_chapter/mosaic.html#mosaic_1","text":"Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u5c06\u591a\u5f20\u56fe\u7247\u6309\u7167\u4e00\u5b9a\u6bd4\u4f8b\u7ec4\u5408\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u4f7f\u6a21\u578b\u5728\u66f4\u5c0f\u7684\u8303\u56f4\u5185\u8bc6\u522b\u76ee\u6807\u3002Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u53c2\u8003 CutMix\u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u3002CutMix\u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u4f7f\u7528\u4e24\u5f20\u56fe\u7247\u8fdb\u884c\u62fc\u63a5\uff0c\u800c Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u4e00\u822c\u4f7f\u7528\u56db\u5f20\u8fdb\u884c\u62fc\u63a5\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002","title":"Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5"},{"location":"tutorials/04_chapter/mosaic.html#mosaic_2","text":"\u968f\u673a\u9009\u53d6\u56fe\u7247\u62fc\u63a5\u57fa\u51c6\u70b9\u5750\u6807 \\((x_c\uff0cy_c)\\) \uff0c\u53e6\u968f\u673a\u9009\u53d6\u56db\u5f20\u56fe\u7247\u3002 \u56db\u5f20\u56fe\u7247\u6839\u636e\u57fa\u51c6\u70b9\uff0c\u5206\u522b\u7ecf\u8fc7 \u5c3a\u5bf8\u8c03\u6574 \u548c \u6bd4\u4f8b\u7f29\u653e \u540e\uff0c\u653e\u7f6e\u5728\u6307\u5b9a\u5c3a\u5bf8\u7684\u5927\u56fe\u7684\u5de6\u4e0a\uff0c\u53f3\u4e0a\uff0c\u5de6\u4e0b\uff0c\u53f3\u4e0b\u4f4d\u7f6e\u3002 \u6839\u636e\u6bcf\u5f20\u56fe\u7247\u7684\u5c3a\u5bf8\u53d8\u6362\u65b9\u5f0f\uff0c\u5c06\u6620\u5c04\u5173\u7cfb\u5bf9\u5e94\u5230\u56fe\u7247\u6807\u7b7e\u4e0a\u3002 \u4f9d\u636e\u6307\u5b9a\u7684\u6a2a\u7eb5\u5750\u6807\uff0c\u5bf9\u5927\u56fe\u8fdb\u884c\u62fc\u63a5\u3002\u5904\u7406\u8d85\u8fc7\u8fb9\u754c\u7684\u68c0\u6d4b\u6846\u5750\u6807\u3002","title":"Mosaic\u65b9\u6cd5\u6b65\u9aa4"},{"location":"tutorials/04_chapter/mosaic.html#mosaic_3","text":"\u589e\u52a0\u6570\u636e\u591a\u6837\u6027\uff0c\u968f\u673a\u9009\u53d6\u56db\u5f20\u56fe\u50cf\u8fdb\u884c\u7ec4\u5408\uff0c\u7ec4\u5408\u5f97\u5230\u56fe\u50cf\u4e2a\u6570\u6bd4\u539f\u56fe\u4e2a\u6570\u8981\u591a\u3002 \u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u6df7\u5408\u56db\u5f20\u5177\u6709\u4e0d\u540c\u8bed\u4e49\u4fe1\u606f\u7684\u56fe\u7247\uff0c\u53ef\u4ee5\u8ba9\u6a21\u578b\u68c0\u6d4b\u8d85\u51fa\u5e38\u89c4\u8bed\u5883\u7684\u76ee\u6807\u3002 \u52a0\u5f3a\u6279\u5f52\u4e00\u5316\u5c42\uff08 \\(Batch \\ Normalization\\) \uff09\u7684\u6548\u679c\u3002\u5f53\u6a21\u578b\u8bbe\u7f6e \\(BN\\) \u64cd\u4f5c\u540e\uff0c\u8bad\u7ec3\u65f6\u4f1a\u5c3d\u53ef\u80fd\u589e\u5927\u6279\u6837\u672c\u603b\u91cf\uff08 \\(BatchSize\\) \uff09\uff0c\u56e0\u4e3a \\(BN\\) \u539f\u7406\u4e3a\u8ba1\u7b97\u6bcf\u4e00\u4e2a\u7279\u5f81\u5c42\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5982\u679c\u6279\u6837\u672c\u603b\u91cf\u8d8a\u5927\uff0c\u90a3\u4e48 \\(BN\\) \u8ba1\u7b97\u7684\u5747\u503c\u548c\u65b9\u5dee\u5c31\u8d8a\u63a5\u8fd1\u4e8e\u6574\u4e2a\u6570\u636e\u96c6\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u6548\u679c\u8d8a\u597d\u3002 Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u6709\u5229\u4e8e\u63d0\u5347\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u3002Mosaic \u6570\u636e\u589e\u5f3a\u56fe\u50cf\u7531\u56db\u5f20\u539f\u59cb\u56fe\u50cf\u62fc\u63a5\u800c\u6210\uff0c\u8fd9\u6837\u6bcf\u5f20\u56fe\u50cf\u4f1a\u6709\u66f4\u5927\u6982\u7387\u5305\u542b\u5c0f\u76ee\u6807\u3002","title":"Mosaic\u65b9\u6cd5\u4f18\u70b9"},{"location":"tutorials/04_chapter/mosaic.html#mosaic_4","text":"\u601d\u8def\u6982\u62ec\uff1a\u5c06\u4e00\u5f20\u9009\u5b9a\u7684\u56fe\u7247\u548c\u968f\u673a\u76843\u5f20\u56fe\u7247\u8fdb\u884c\u968f\u673a\u88c1\u526a\uff0c\u518d\u62fc\u63a5\u5230\u4e00\u5f20\u56fe\u4e0a\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e ,\u53ef\u89c1\u672c\u6587 \u56fe4.2 \u3002 \u8fd9\u6837\u53ef\u4ee5\u4e30\u5bcc\u56fe\u7247\u7684\u80cc\u666f\uff0c\u800c\u4e14\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u8d77\u53d8\u76f8\u7684\u63d0\u9ad8\u4e86 \\(batch-size\\) \u5927\u5c0f\uff0c\u540c\u65f6\u5728\u8fdb\u884c \\(batch \\ normalization\\) \uff08\u6279\u91cf\u5f52\u4e00\u5316\uff09\u7684\u65f6\u5019\u4e5f\u4f1a\u8ba1\u7b97\u56db\u5f20\u56fe\u7247\u3002 \u8fd9\u4e2d\u65b9\u5f0f\u80fd\u4f7f\u5f97 \\(YOLOv5\\) \u5bf9\u4e8e \\(batch-size\\) \u5927\u5c0f\u5bf9\u6a21\u578b\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002 \u4e0b\u9762\u5bf9 utils/dataloaders.py\u4e2dMosaic \u7684\u5b9e\u73b0\u8fdb\u884c\u89e3\u8bfb\u3002 def load_mosaic ( self , index ): # YOLOv5 4-mosaic loader. Loads 1 image + 3 random images into a 4-image mosaic \"\"\" @param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 @return: img4: mosaic\u548c\u4eff\u5c04\u589e\u5f3a\u540e\u7684\u4e00\u5f20\u56fe\u7247 labels4: img4\u5bf9\u5e94\u7684target \"\"\" labels4 , segments4 = [], [] # \u83b7\u53d6\u56fe\u50cf\u5c3a\u5bf8 s = self . img_size # \u8fd9\u91cc\u662f\u968f\u673a\u751f\u6210mosaic\u4e2d\u5fc3\u70b9 yc , xc = ( int ( random . uniform ( - x , 2 * s + x )) for x in self . mosaic_border ) # mosaic center x, y # \u968f\u673a\u751f\u6210\u53e6\u59163\u5f20\u56fe\u7247\u7684\u7d22\u5f15 indices = [ index ] + random . choices ( self . indices , k = 3 ) # 3 additional image indices # \u5bf9\u8fd9\u4e9b\u7d22\u5f15\u503c\u968f\u673a\u6392\u5e8f random . shuffle ( indices ) # \u904d\u5386\u8fd94\u5f20\u56fe\u7247 for i , index in enumerate ( indices ): # Load image # \u52a0\u8f7d\u56fe\u7247\u5e76\u8fd4\u56de\u9ad8\u5bbd img , _ , ( h , w ) = self . load_image ( index ) # place img in img4 \u653e\u7f6e\u56fe\u7247 if i == 0 : # top left(\u5de6\u4e0a\u89d2) # \u751f\u6210\u80cc\u666f\u56fe np.full()\u51fd\u6570\u586b\u5145\u521d\u59cb\u5316\u5927\u56fe\uff0c\u5c3a\u5bf8\u662f4\u5f20\u56fe\u90a3\u4e48\u5927 img4 = np . full (( s * 2 , s * 2 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles # \u8bbe\u7f6e\u5927\u56fe\u4e0a\u7684\u4f4d\u7f6e\uff08\u8981\u4e48\u539f\u56fe\u5927\u5c0f\uff0c\u8981\u4e48\u653e\u5927\uff09\uff08w\uff0ch\uff09\u6216\uff08xc\uff0cyc\uff09\uff08\u65b0\u751f\u6210\u7684\u90a3\u5f20\u5927\u56fe\uff09 x1a , y1a , x2a , y2a = max ( xc - w , 0 ), max ( yc - h , 0 ), xc , yc # xmin, ymin, xmax, ymax (large image) # \u9009\u53d6\u5c0f\u56fe\u4e0a\u7684\u4f4d\u7f6e\uff08\u539f\u56fe\uff09 x1b , y1b , x2b , y2b = w - ( x2a - x1a ), h - ( y2a - y1a ), w , h # xmin, ymin, xmax, ymax (small image) elif i == 1 : # top right(\u53f3\u4e0a\u89d2) x1a , y1a , x2a , y2a = xc , max ( yc - h , 0 ), min ( xc + w , s * 2 ), yc x1b , y1b , x2b , y2b = 0 , h - ( y2a - y1a ), min ( w , x2a - x1a ), h elif i == 2 : # bottom left(\u5de6\u4e0b\u89d2) x1a , y1a , x2a , y2a = max ( xc - w , 0 ), yc , xc , min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = w - ( x2a - x1a ), 0 , w , min ( y2a - y1a , h ) elif i == 3 : # bottom right(\u53f3\u4e0b\u89d2) x1a , y1a , x2a , y2a = xc , yc , min ( xc + w , s * 2 ), min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = 0 , 0 , min ( w , x2a - x1a ), min ( y2a - y1a , h ) # \u5927\u56fe\u4e0a\u8d34\u4e0a\u5bf9\u5e94\u7684\u5c0f\u56fe img4 [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] padw = x1a - x1b padh = y1a - y1b # \u8ba1\u7b97\u5c0f\u56fe\u5230\u5927\u56fe\u4e0a\u65f6\u6240\u4ea7\u751f\u7684\u504f\u79fb\uff0c\u7528\u6765\u8ba1\u7b97mosaic\u589e\u5f3a\u540e\u7684\u6807\u7b7e\u7684\u4f4d\u7f6e # Labels \u83b7\u53d6\u6807\u7b7e \"\"\" \u5bf9label\u6807\u6ce8\u8fdb\u884c\u521d\u59cb\u5316\u64cd\u4f5c\uff1a \u5148\u8bfb\u53d6\u5bf9\u5e94\u56fe\u7247\u7684label\uff0c\u7136\u540e\u5c06xywh\u683c\u5f0f\u7684label\u6807\u51c6\u5316\u4e3a\u50cf\u7d20xy\u683c\u5f0f\u7684\u3002 segments4\u8f6c\u4e3a\u50cf\u7d20\u6bb5\u683c\u5f0f \u7136\u540e\u7edf\u7edf\u586b\u8fdb\u4e4b\u524d\u51c6\u5907\u7684\u6807\u6ce8\u5217\u8868 \"\"\" labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : # \u5c06xywh\uff08\u767e\u5206\u6bd4\u90a3\u4e9b\u503c\uff09\u6807\u51c6\u5316\u4e3a\u50cf\u7d20xy\u683c\u5f0f labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padw , padh ) # normalized xywh to pixel xyxy format # \u8f6c\u4e3a\u50cf\u7d20\u6bb5 segments = [ xyn2xy ( x , w , h , padw , padh ) for x in segments ] labels4 . append ( labels ) segments4 . extend ( segments ) # Concat/clip labels \u62fc\u63a5 labels4 = np . concatenate ( labels4 , 0 ) for x in ( labels4 [:, 1 :], * segments4 ): # np.clip\u622a\u53d6\u51fd\u6570\uff0c\u56fa\u5b9a\u503c\u57280\u52302s\u5185 np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img4, labels4 = replicate(img4, labels4) # replicate # Augment # \u8fdb\u884cmosaic\u7684\u65f6\u5019\u5c06\u56db\u5f20\u56fe\u7247\u6574\u5408\u5230\u4e00\u8d77\u4e4b\u540eshape\u4e3a[2*img_size,2*img_size] # \u5bf9mosaic\u6574\u5408\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u88c1\u526a\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size img4 , labels4 , segments4 = copy_paste ( img4 , labels4 , segments4 , p = self . hyp [ 'copy_paste' ]) img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove","title":"Mosaic\u6e90\u7801\u89e3\u8bfb"},{"location":"tutorials/04_chapter/mosaic.html#_3","text":"\u88684.1 :\u6570\u636e\u589e\u5f3a\u53c2\u6570\u8868 \u53c2\u6570\u540d \u914d\u7f6e \u89e3\u6790 hsv_h: 0.015 # image HSV-Hue augmentation (fraction) \u8272\u8c03 hsv_s: 0.7 # image HSV-Saturation augmentation (fraction) \u9971\u548c\u5ea6 hsv_v: 0.4 # image HSV-Value augmentation (fraction) \u66dd\u5149\u5ea6 degrees: 0.0 # image rotation (+/- deg) \u65cb\u8f6c translate: 0.1 # image translation (+/- fraction) \u5e73\u79fb scale: 0.9 # image scale (+/- gain) \u7f29\u653e shear: 0.0 # image shear (+/- deg) \u9519\u5207(\u975e\u5782\u76f4\u6295\u5f71) perspective: 0.0 # image perspective (+/- fraction), range 0-0.001 \u900f\u89c6\u53d8\u6362 flipud: 0.0 # image flip up-down (probability) \u4e0a\u4e0b\u7ffb\u8f6c fliplr: 0.5 # image flip left-right (probability)\u5de6\u53f3\u7ffb\u8f6c mosaic: 1.0 # image mosaic (probability) \u56fe\u62fc\u63a5 mixup: 0.1 # image mixup (probability) \u56fe\u50cf\u878d\u5408 copy_paste: 0.0 # segment copy-paste (probability) \u5206\u5272\u586b\u8865","title":"\u9644\u4ef6"},{"location":"tutorials/04_chapter/mosaic.html#_4","text":"https://docs.ultralytics.com/FAQ/augmentation/","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html","text":"\u5f15\u8a00 \u672c\u6587\u4e3b\u8981\u4ecb\u7ecd\u5728YOLOv5\u9879\u76ee\u4e2d \u8ba1\u7b97mAP\u7528\u5230\u7684\u4e00\u4e9bnumpy\u64cd\u4f5c\uff0c\u51fd\u6570\u4f7f\u7528\u5728 utils/metrics.py \u4e2d\u3002 \u7528\u5230\u7684python/numpy\u7684\u64cd\u4f5c\u6bd4\u5982\uff1a np.cumsum()\u3001np.interp()\u3001np.maximum.accumulate()\u3001np.trapz()\u7b49\u3002\u63a5\u4e0b\u6765\u5c06\u5728\u4e0b\u9762\u9010\u4e00\u4ecb\u7ecd\u3002 import numpy as np np.cumsum() \u8fd4\u56de\u5143\u7d20\u6cbf\u7ed9\u5b9a\u8f74\u7684\u7d2f\u79ef\u548c\u3002 numpy.cumsum(a, axis=None, dtype=None, out=None) source \u53c2\u6570 a :\u6570\u7ec4 axis: \u8f74\u7d22\u5f15,\u6574\u578b\uff0c\u82e5a\u4e3an\u7ef4\u6570\u7ec4\uff0c\u5219axis\u7684\u53d6\u503c\u8303\u56f4\u4e3a[0,n-1] dtype: \u8fd4\u56de\u7ed3\u679c\u7684\u6570\u636e\u7c7b\u578b\uff0c\u82e5\u4e0d\u6307\u5b9a\uff0c\u5219\u9ed8\u8ba4\u4e0ea\u4e00\u81f4n out: \u6570\u636e\u7c7b\u578b\u4e3a\u6570\u7ec4\u3002\u7528\u6765\u653e\u7f6e\u7ed3\u679c\u7684\u66ff\u4ee3\u8f93\u51fa\u6570\u7ec4\uff0c\u5b83\u5fc5\u987b\u5177\u6709\u4e0e\u8f93\u51fa\u7ed3\u679c\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u548c\u6570\u636e\u7f13\u51b2\u533a\u957f\u5ea6 \u8fd4\u56de \u6cbf\u7740\u6307\u5b9a\u8f74\u7684\u5143\u7d20\u7d2f\u52a0\u548c\u6240\u7ec4\u6210\u7684\u6570\u7ec4\uff0c\u5176\u5f62\u72b6\u5e94\u4e0e\u8f93\u5165\u6570\u7ec4a\u4e00\u81f4 \u66f4\u591a\u4fe1\u606f\u8bf7\u53c2\u9605\u8bfb: API_CN API_EN np . cumsum ( a ) # \u8ba1\u7b97\u7d2f\u79ef\u548c\u7684\u8f74\u3002\u9ed8\u8ba4\uff08\u65e0\uff09\u662f\u5728\u5c55\u5e73\u7684\u6570\u7ec4\u4e0a\u8ba1\u7b97cumsum\u3002 array([ 1, 3, 6, 10, 15, 21]) a = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) np . cumsum ( a , dtype = float ) # \u6307\u5b9a\u8f93\u51fa\u7684\u7279\u5b9a\u7684\u7c7b\u578b array([ 1., 3., 6., 10., 15., 21.]) np . cumsum ( a , axis = 0 ) # 3\u5217\u4e2d\u6bcf\u4e00\u5217\u7684\u884c\u603b\u548c array([[1, 2, 3], [5, 7, 9]]) x = np . ones (( 3 , 4 ), dtype = int ) np . cumsum ( x , axis = 0 ) array([[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3]]) np . cumsum ( a , axis = 1 ) # 2\u884c\u4e2d\u6bcf\u884c\u7684\u5217\u603b\u548c array([[ 1, 3, 6], [ 4, 9, 15]]) np.interp() \u53c2\u6570 x: \u6570\u7ec4 \u5f85\u63d2\u5165\u6570\u636e\u7684\u6a2a\u5750\u6807 xp: \u4e00\u7ef4\u6d6e\u70b9\u6570\u5e8f\u5217 \u539f\u59cb\u6570\u636e\u70b9\u7684\u6a2a\u5750\u6807\uff0c\u5982\u679cperiod\u53c2\u6570\u6ca1\u6709\u6307\u5b9a\u90a3\u4e48\u5c31\u5fc5\u987b\u662f\u9012\u589e\u7684 \u5426\u5219\uff0c\u5728\u4f7f\u7528xp = xp % period\u6b63\u5219 \u5316\u4e4b\u540e\uff0cxp\u5728\u5185\u90e8\u8fdb\u884c\u6392\u5e8f fp: \u4e00\u7ef4\u6d6e\u70b9\u6570\u6216\u590d\u6570\u5e8f\u5217 \u539f\u59cb\u6570\u636e\u70b9\u7684\u7eb5\u5750\u6807\uff0c\u548cxp\u5e8f\u5217\u7b49\u957f. left: \u53ef\u9009\u53c2\u6570\uff0c\u7c7b\u578b\u4e3a\u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09 \u5f53x < xp[0]\u65f6\u7684\u63d2\u503c\u8fd4\u56de\u503c\uff0c\u9ed8\u8ba4\u4e3afp[0]. right: \u53ef\u9009\u53c2\u6570\uff0c\u7c7b\u578b\u4e3a\u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09\uff0c\u5f53x > xp[-1]\u65f6\u7684\u63d2\u503c\u8fd4\u56de\u503c\uff0c\u9ed8\u8ba4\u4e3afp[-1]. period: None\u6216\u8005\u6d6e\u70b9\u6570\uff0c\u53ef\u9009\u53c2\u6570 \u6a2a\u5750\u6807\u7684\u5468\u671f \u6b64\u53c2\u6570\u4f7f\u5f97\u53ef\u4ee5\u6b63\u786e\u63d2\u5165angular x-coordinates. \u5982\u679c\u8be5\u53c2\u6570\u88ab\u8bbe\u5b9a\uff0c\u90a3\u4e48\u5ffd\u7565left\u53c2\u6570\u548cright\u53c2\u6570 \u8fd4\u56de \u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09\u6216ndarray. \u63d2\u5165\u6570\u636e\u7684\u7eb5\u5750\u6807\uff0c\u548cx\u5f62\u72b6\u76f8\u540c \u6ce8\u610f\uff01 \u5728\u6ca1\u6709\u8bbe\u7f6eperiod\u53c2\u6570\u65f6\uff0c\u9ed8\u8ba4\u8981\u6c42xp\u53c2\u6570\u662f\u9012\u589e\u5e8f\u5217 # \u63d2\u5165\u4e00\u4e2a\u503c import numpy as np import matplotlib.pyplot as plt x = 2.5 xp = [ 1 , 2 , 3 ] fp = [ 3 , 2 , 0 ] y = np . interp ( x , xp , fp ) # 1.0 plt . plot ( xp , fp , '-o' ) plt . plot ( x , y , 'x' ) # \u753b\u63d2\u503c plt . show () # \u63d2\u5165\u4e00\u4e2a\u5e8f\u5217 import numpy as np import matplotlib.pyplot as plt x = [ 0 , 1 , 1.5 , 2.72 , 3.14 ] xp = [ 1 , 2 , 3 ] fp = [ 3 , 2 , 0 ] y = np . interp ( x , xp , fp ) # array([ 3. , 3. , 2.5 , 0.56, 0. ]) plt . plot ( xp , fp , '-o' ) plt . plot ( x , y , 'x' ) plt . show () np.maximum.accumulate \u8ba1\u7b97\u6570\u7ec4\uff08\u6216\u6570\u7ec4\u7684\u7279\u5b9a\u8f74\uff09\u7684\u7d2f\u79ef\u6700\u5927\u503c import numpy as np d = np . random . randint ( low = 1 , high = 10 , size = ( 2 , 3 )) print ( \"d: \\n \" , d ) c = np . maximum . accumulate ( d , axis = 1 ) print ( \"c: \\n \" , c ) d: [[1 9 5] [2 6 1]] c: [[1 9 9] [2 6 6]] np.trapz() numpy.trapz(y, x=None, dx=1.0, axis=- 1) \u4f7f\u7528\u590d\u5408\u68af\u5f62\u89c4\u5219\u6cbf\u7ed9\u5b9a\u8f74\u79ef\u5206\u3002 import matplotlib.pyplot as plt import numpy as np y = [ 1 , 2 , 3 ] ; x = [ i + 1 for i in range ( len ( y ))] print ( np . trapz ( x )) plt . fill_between ( x , y ) plt . show () # (1 + 3)*(3 - 1)/2 = 4 4.0 import matplotlib.pyplot as plt import numpy as np y = [ 1 , 2 , 3 ] x = [ 4 , 6 , 8 ] print ( np . trapz ( y , x )) plt . fill_between ( x , y ) plt . show () # (3 + 1)*(8 - 4) / 2 = 8 8.0 \u53c2\u8003\u6587\u7ae0 numpy API\u6587\u6863 CN\uff1a https://www.osgeo.cn/numpy/dev/index.html numpy API\u6587\u6863 EN\uff1a https://numpy.org/doc/stable/reference/index.html axis\u7684\u57fa\u672c\u4f7f\u7528\uff1a https://www.jb51.net/article/242067.htm","title":"5.4 \u8ba1\u7b97mAP\u7528\u5230\u7684numpy\u51fd\u6570"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#_1","text":"\u672c\u6587\u4e3b\u8981\u4ecb\u7ecd\u5728YOLOv5\u9879\u76ee\u4e2d \u8ba1\u7b97mAP\u7528\u5230\u7684\u4e00\u4e9bnumpy\u64cd\u4f5c\uff0c\u51fd\u6570\u4f7f\u7528\u5728 utils/metrics.py \u4e2d\u3002 \u7528\u5230\u7684python/numpy\u7684\u64cd\u4f5c\u6bd4\u5982\uff1a np.cumsum()\u3001np.interp()\u3001np.maximum.accumulate()\u3001np.trapz()\u7b49\u3002\u63a5\u4e0b\u6765\u5c06\u5728\u4e0b\u9762\u9010\u4e00\u4ecb\u7ecd\u3002 import numpy as np","title":"\u5f15\u8a00"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#npcumsum","text":"\u8fd4\u56de\u5143\u7d20\u6cbf\u7ed9\u5b9a\u8f74\u7684\u7d2f\u79ef\u548c\u3002 numpy.cumsum(a, axis=None, dtype=None, out=None) source \u53c2\u6570 a :\u6570\u7ec4 axis: \u8f74\u7d22\u5f15,\u6574\u578b\uff0c\u82e5a\u4e3an\u7ef4\u6570\u7ec4\uff0c\u5219axis\u7684\u53d6\u503c\u8303\u56f4\u4e3a[0,n-1] dtype: \u8fd4\u56de\u7ed3\u679c\u7684\u6570\u636e\u7c7b\u578b\uff0c\u82e5\u4e0d\u6307\u5b9a\uff0c\u5219\u9ed8\u8ba4\u4e0ea\u4e00\u81f4n out: \u6570\u636e\u7c7b\u578b\u4e3a\u6570\u7ec4\u3002\u7528\u6765\u653e\u7f6e\u7ed3\u679c\u7684\u66ff\u4ee3\u8f93\u51fa\u6570\u7ec4\uff0c\u5b83\u5fc5\u987b\u5177\u6709\u4e0e\u8f93\u51fa\u7ed3\u679c\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u548c\u6570\u636e\u7f13\u51b2\u533a\u957f\u5ea6 \u8fd4\u56de \u6cbf\u7740\u6307\u5b9a\u8f74\u7684\u5143\u7d20\u7d2f\u52a0\u548c\u6240\u7ec4\u6210\u7684\u6570\u7ec4\uff0c\u5176\u5f62\u72b6\u5e94\u4e0e\u8f93\u5165\u6570\u7ec4a\u4e00\u81f4 \u66f4\u591a\u4fe1\u606f\u8bf7\u53c2\u9605\u8bfb: API_CN API_EN np . cumsum ( a ) # \u8ba1\u7b97\u7d2f\u79ef\u548c\u7684\u8f74\u3002\u9ed8\u8ba4\uff08\u65e0\uff09\u662f\u5728\u5c55\u5e73\u7684\u6570\u7ec4\u4e0a\u8ba1\u7b97cumsum\u3002 array([ 1, 3, 6, 10, 15, 21]) a = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) np . cumsum ( a , dtype = float ) # \u6307\u5b9a\u8f93\u51fa\u7684\u7279\u5b9a\u7684\u7c7b\u578b array([ 1., 3., 6., 10., 15., 21.]) np . cumsum ( a , axis = 0 ) # 3\u5217\u4e2d\u6bcf\u4e00\u5217\u7684\u884c\u603b\u548c array([[1, 2, 3], [5, 7, 9]]) x = np . ones (( 3 , 4 ), dtype = int ) np . cumsum ( x , axis = 0 ) array([[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3]]) np . cumsum ( a , axis = 1 ) # 2\u884c\u4e2d\u6bcf\u884c\u7684\u5217\u603b\u548c array([[ 1, 3, 6], [ 4, 9, 15]])","title":"np.cumsum()"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#npinterp","text":"\u53c2\u6570 x: \u6570\u7ec4 \u5f85\u63d2\u5165\u6570\u636e\u7684\u6a2a\u5750\u6807 xp: \u4e00\u7ef4\u6d6e\u70b9\u6570\u5e8f\u5217 \u539f\u59cb\u6570\u636e\u70b9\u7684\u6a2a\u5750\u6807\uff0c\u5982\u679cperiod\u53c2\u6570\u6ca1\u6709\u6307\u5b9a\u90a3\u4e48\u5c31\u5fc5\u987b\u662f\u9012\u589e\u7684 \u5426\u5219\uff0c\u5728\u4f7f\u7528xp = xp % period\u6b63\u5219 \u5316\u4e4b\u540e\uff0cxp\u5728\u5185\u90e8\u8fdb\u884c\u6392\u5e8f fp: \u4e00\u7ef4\u6d6e\u70b9\u6570\u6216\u590d\u6570\u5e8f\u5217 \u539f\u59cb\u6570\u636e\u70b9\u7684\u7eb5\u5750\u6807\uff0c\u548cxp\u5e8f\u5217\u7b49\u957f. left: \u53ef\u9009\u53c2\u6570\uff0c\u7c7b\u578b\u4e3a\u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09 \u5f53x < xp[0]\u65f6\u7684\u63d2\u503c\u8fd4\u56de\u503c\uff0c\u9ed8\u8ba4\u4e3afp[0]. right: \u53ef\u9009\u53c2\u6570\uff0c\u7c7b\u578b\u4e3a\u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09\uff0c\u5f53x > xp[-1]\u65f6\u7684\u63d2\u503c\u8fd4\u56de\u503c\uff0c\u9ed8\u8ba4\u4e3afp[-1]. period: None\u6216\u8005\u6d6e\u70b9\u6570\uff0c\u53ef\u9009\u53c2\u6570 \u6a2a\u5750\u6807\u7684\u5468\u671f \u6b64\u53c2\u6570\u4f7f\u5f97\u53ef\u4ee5\u6b63\u786e\u63d2\u5165angular x-coordinates. \u5982\u679c\u8be5\u53c2\u6570\u88ab\u8bbe\u5b9a\uff0c\u90a3\u4e48\u5ffd\u7565left\u53c2\u6570\u548cright\u53c2\u6570 \u8fd4\u56de \u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09\u6216ndarray. \u63d2\u5165\u6570\u636e\u7684\u7eb5\u5750\u6807\uff0c\u548cx\u5f62\u72b6\u76f8\u540c \u6ce8\u610f\uff01 \u5728\u6ca1\u6709\u8bbe\u7f6eperiod\u53c2\u6570\u65f6\uff0c\u9ed8\u8ba4\u8981\u6c42xp\u53c2\u6570\u662f\u9012\u589e\u5e8f\u5217 # \u63d2\u5165\u4e00\u4e2a\u503c import numpy as np import matplotlib.pyplot as plt x = 2.5 xp = [ 1 , 2 , 3 ] fp = [ 3 , 2 , 0 ] y = np . interp ( x , xp , fp ) # 1.0 plt . plot ( xp , fp , '-o' ) plt . plot ( x , y , 'x' ) # \u753b\u63d2\u503c plt . show () # \u63d2\u5165\u4e00\u4e2a\u5e8f\u5217 import numpy as np import matplotlib.pyplot as plt x = [ 0 , 1 , 1.5 , 2.72 , 3.14 ] xp = [ 1 , 2 , 3 ] fp = [ 3 , 2 , 0 ] y = np . interp ( x , xp , fp ) # array([ 3. , 3. , 2.5 , 0.56, 0. ]) plt . plot ( xp , fp , '-o' ) plt . plot ( x , y , 'x' ) plt . show ()","title":"np.interp()"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#npmaximumaccumulate","text":"\u8ba1\u7b97\u6570\u7ec4\uff08\u6216\u6570\u7ec4\u7684\u7279\u5b9a\u8f74\uff09\u7684\u7d2f\u79ef\u6700\u5927\u503c import numpy as np d = np . random . randint ( low = 1 , high = 10 , size = ( 2 , 3 )) print ( \"d: \\n \" , d ) c = np . maximum . accumulate ( d , axis = 1 ) print ( \"c: \\n \" , c ) d: [[1 9 5] [2 6 1]] c: [[1 9 9] [2 6 6]]","title":"np.maximum.accumulate"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#nptrapz","text":"numpy.trapz(y, x=None, dx=1.0, axis=- 1) \u4f7f\u7528\u590d\u5408\u68af\u5f62\u89c4\u5219\u6cbf\u7ed9\u5b9a\u8f74\u79ef\u5206\u3002 import matplotlib.pyplot as plt import numpy as np y = [ 1 , 2 , 3 ] ; x = [ i + 1 for i in range ( len ( y ))] print ( np . trapz ( x )) plt . fill_between ( x , y ) plt . show () # (1 + 3)*(3 - 1)/2 = 4 4.0 import matplotlib.pyplot as plt import numpy as np y = [ 1 , 2 , 3 ] x = [ 4 , 6 , 8 ] print ( np . trapz ( y , x )) plt . fill_between ( x , y ) plt . show () # (3 + 1)*(8 - 4) / 2 = 8 8.0","title":"np.trapz()"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#_2","text":"numpy API\u6587\u6863 CN\uff1a https://www.osgeo.cn/numpy/dev/index.html numpy API\u6587\u6863 EN\uff1a https://numpy.org/doc/stable/reference/index.html axis\u7684\u57fa\u672c\u4f7f\u7528\uff1a https://www.jb51.net/article/242067.htm","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \ud83d\udcd8\u6458\u8981 \u8fb9\u754c\u6846\u56de\u5f52\u662f\u76ee\u6807\u68c0\u6d4b\u7684\u5173\u952e\u6b65\u9aa4 \uff0c\u5728\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u867d\u7136 \\(\\ell_n\\) -norm loss \u88ab\u5e7f\u6cdb\u7528\u4e8e\u8fb9\u754c\u6846\u56de\u5f52\uff0c\u4f46\u5b83\u4e0d\u662f\u9488\u5bf9\u8bc4\u4f30\u6307\u6807\u91cf\u8eab\u5b9a\u5236\u7684\uff0c\u5373 Intersection over Union (IoU)\u3002\u6700\u8fd1\uff0c\u5df2\u7ecf\u63d0\u51fa\u4e86 IoU \u635f\u5931\u548cgeneralized IoU (GIoU) Loss\u4f5c\u4e3a\u8bc4\u4f30IoU\u7684\u6307\u6807 \uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u6536\u655b\u901f\u5ea6\u6162\u548c\u56de\u5f52\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u7ed3\u5408\u9884\u6d4b\u6846\u548c\u76ee\u6807\u6846\u4e4b\u95f4\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\u6765\u63d0\u51fa\u8ddd\u79bb-IoU (DIoU) Loss\uff0c\u5b83\u5728\u8bad\u7ec3\u4e2d\u7684\u6536\u655b\u901f\u5ea6\u6bd4 IoU \u548c GIoU Loss\u5feb\u5f97\u591a\u3002 \u6b64\u5916\uff0c\u672c\u6587\u603b\u7ed3\u4e86\u8fb9\u754c\u6846\u56de\u5f52\u4e2d\u7684\u4e09\u4e2a\u51e0\u4f55\u56e0\u7d20\uff0c\u5373 \u91cd\u53e0\u9762\u79ef\uff08overlap area\uff09\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb\uff08central point distance\uff09\u548c\u9ad8\u5bbd\u6bd4\uff08aspect ratio\uff09 \uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e86\u5b8c\u5168 \\(IoU (CIoU)\\) \u635f\u5931\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u4f18\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5c06 \\(DIoU \u548c CIoU \u635f\u5931\\) \u7ed3\u5408\u5230\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0c\u4f8b\u5982 YOLO v3\u3001SSD \u548c Faster RCNN\uff0c\u6211\u4eec\u4e0d\u4ec5\u5728 IoU \u6307\u6807\u65b9\u9762\u800c\u4e14\u5728 GIoU \u6307\u6807\u65b9\u9762\u90fd\u83b7\u5f97\u4e86\u663e\u7740\u7684\u6027\u80fd\u63d0\u5347\u3002\u6b64\u5916\uff0cDIoU \u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u7528\u4e8e\u975e\u6700\u5927\u6291\u5236\uff08NMS\uff09\u4f5c\u4e3a\u6807\u51c6\uff0c\u8fdb\u4e00\u6b65\u4fc3\u8fdb\u6027\u80fd\u63d0\u5347\u3002 \u6ce8\u91ca:\u8fd9\u91ccIoU\u6307\u6807\u65b9\u9762\u548cGIoU\u6307\u6807\u65b9\u9762\u6307\u7684\u662f\u5728\uff1a\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u6d4b\u91cf(mAP\u503c ),IoU\u635f\u5931\u8ba1\u7b97\u7a33\u5b9a\u6027\u7b49\u4e00\u4e9b\u65b9\u9762\u3002 \u76ee\u6807\u68c0\u6d4b\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u95ee\u9898\u4e4b\u4e00 \uff0c\u51e0\u5341 \u5e74\u6765\u4e00\u76f4\u53d7\u5230\u4e86\u5e7f\u6cdb\u7684\u7814\u7a76\u5173\u6ce8 (Redmon et al. 2016; Redmon and Farhadi 2018; Ren et al. 2015; He et al. 2017; Yang et al. 2018; Wang et al. 2019; 2018). \u901a\u5e38\uff0c\u73b0\u6709\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u53ef\u4ee5\u5206\u4e3a\uff1a - \u5355\u9636\u6bb5-\u68c0\u6d4b\uff0c\u5982YOLO\u7cfb\u5217 (Redmon et al. 2016; Red- mon and Farhadi 2017; 2018) \u548cSSD (Liu et al. 2016; Fu et al. 2017), - \u4e24\u9636\u6bb5\u68c0\u6d4b\uff0c\u5982 R-CNN\u7cfb\u5217\u68c0\u6d4b (Girshick et al. 2014; Girshick 2015; Ren et al. 2015; He et al. 2017), - \u751a\u81f3\u662f\u591a\u9636\u6bb5\u7684\u68c0\u6d4b, \u50cfCascade R-CNN (Cai and Vasconcelos 2018). \u5c3d\u7ba1\u5b58\u5728\u8fd9\u4e9b\u4e0d \u540c\u7684\u68c0\u6d4b\u6846\u67b6\uff0c\u4f46\u8fb9\u754c\u6846\u56de\u5f52\u9884\u6d4b\u4e00\u4e2a\u77e9\u5f62\u6846\u6765\u5b9a\u4f4d\u76ee\u6807\u5bf9\u8c61\u4ecd\u7136\u662f\u5176\u4e2d\u5173\u952e\u6b65\u9aa4\u3002 \u524d\u8a00 \u672c\u6587\u4e3b\u8981\u662f\u7ed3\u5408\u8bba\u6587Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression( https://arxiv.org/pdf/1911.08287.pdf ) \u5bf9 IoU \u7684\u89e3\u6790\u5b66\u4e60\u3002 IoU IoU\u4ecb\u7ecd Intersection over Union (IoU) \u5728\u6307\u6807\u8bc4\u4f30\u6982\u8ff0\u7684\u5c0f\u8282\u6709\u4ecb\u7ecd\u8fc7IoU,\u5df2\u7ecf\u5bf9IoU\u6709\u4e86\u521d\u6b65\u7684\u8ba4\u8bc6(\u5176\u5b9e\u5728yolov5\u9879\u76ee\u4e2d\u5e76\u4e0d\u662f\u7b80\u5355\u7684\u4f7f\u7528\uff0c\u800c\u662f\u7528\u7684\u540e\u9762\u4ecb\u7ecd\u7684CIoU ) \u8ba1\u7b97\u516c\u5f0f\uff1a \\(\\Large{I o U=\\frac{\\left|B \\cap B^{g t}\\right|}{\\left|B \\cup B^{g t}\\right|} }\\) (1) \\(B^{g t}=\\left(x^{g t}, y^{g t}, w^{g t}, h^{g t}\\right)\\) \u662f\u771f\u5b9e\u56de\u5f52\u6846(gt:ground-truth), \\(B=(x, y, w, h)\\) \u662f\u9884\u6d4b\u56de\u5f52\u6846\u3002 IoU loss \u8ba1\u7b97\u516c\u5f0f: \\(\\Large\\mathcal{L}_{I o U}=1-\\frac{\\left|B \\cap B^{g t}\\right|}{\\left|B \\cup B^{g t}\\right|}\\) (2) IoU Loss \u4f18\u7f3a\u70b9\u5206\u6790 \u6709\u660e\u663e\u7684\u7f3a\u9677 IoU loss\u53ea\u5728\u8fb9\u754c\u6846\u6709\u91cd\u53e0\u65f6\u624d\u80fd\u5de5\u4f5c, \u5bf9\u4e8e\u4e0d\u91cd\u53e0\u7684\u60c5\u51b5\u4e0d\u4f1a\u63d0\u4f9b\u4efb\u4f55\u79fb\u52a8\u68af\u5ea6 (\u79fb\u52a8\u4ee3\u8868\u9884\u6d4b\u6846\u671d\u7740\u76ee\u6807\u6846\u91cd\u53e0\u7684\u65b9\u5411\u79fb\u52a8) \u3002\u79fb\u52a8\u68af\u5ea6\u8868\u793a\u65e0\u6cd5\u8861\u91cf\u5b8c\u5168\u4e0d\u76f8\u4ea4\u7684\u4e24\u4e2a\u6846\u6240\u4ea7\u751f\u7684\u7684\u635f\u5931\uff08iou\u56fa\u5b9a\u4e3a0\uff09\uff0c\u548c\u4e24\u4e2a\u4e0d\u540c\u5f62\u72b6\u7684\u9884\u6d4b\u6846\u53ef\u80fd\u4ea7\u751f\u76f8\u540c\u7684loss\uff08\u76f8\u540c\u7684iou\uff09\u5206\u522b\u5982\u4e0b\u56fe\u7684\u5de6\u8fb9\u548c\u53f3\u8fb9\u6240\u793a\u3002 GIoU GIoU\u4ecb\u7ecd GIoU\u7684\u8bbe\u8ba1\u521d\u8877\u5c31\u662f\u60f3\u89e3\u51b3IoU Loss\u5b58\u5728\u7684\u95ee\u9898\uff08\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u4e0d\u76f8\u4ea4\u65f6iou\u6052\u5b9a\u4e3a0\uff09\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957Generalized Intersection over Union Loss\u3002\u5728IoU\u7684\u57fa\u7840\u4e0a\uff0cGIoU\u8fd8\u9700\u8981\u627e\u5230\u9884\u6d4b\u6846\u548c\u771f\u5b9e\u6846\u7684\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\uff0c\u7136\u540e\u6c42\u51fa\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u51cf\u53bb\u4e24\u4e2a\u9884\u6d4b\u6846union\u7684\u9762\u79ef\uff0c\u5177\u4f53\u7b97\u6cd5\u6d41\u7a0b\u5982\u4e0b\uff1a GIoU loss \u8ba1\u7b97\u516c\u5f0f : \\(\\large\\mathcal{L}_{G I o U}=1-I o U+\\frac{\\left|C-B \\cup B^{g t}\\right|}{|C|}\\) (3) \u5176\u4e2d \\(C\\) \u662f\u8986\u76d6 \\(B\\) \u548c \\(B^{g t}\\) \u7684\u6700\u5c0f\u65b9\u6846 ,\u7531\u4e8e\u5f15\u5165\u4e86 \\(C\\) \uff0c\u5728\u4e0d\u91cd\u53e0\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u6846\u4e5f\u4f1a\u5411\u76ee\u6807\u6846\u79fb\u52a8\u3002 GIoU \u4f18\u7f3a\u70b9\u5206\u6790 GIoU Loss\u89e3\u51b3\u4e86IoU Loss\u5728\u4e0d\u76f8\u4ea4\u60c5\u51b5\u7684\u95ee\u9898\uff0c\u5728\u6240\u6709\u6027\u80fd\u6307\u6807\u4e2d\u90fd\u53ef\u4ee5\u4f5c\u4e3aIoU\u7684\u9002\u5f53\u66ff\u4ee3\u54c1\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\u80fd\u591f\u5f97\u5230\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002 \u7f3a\u70b9\uff1a\u867d\u7136GIoU\u53ef\u4ee5\u7f13\u89e3\u91cd\u53e0\u60c5\u51b5\u4e0b\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898,\u4f46\u5b83\u4ecd\u6709\u4e00\u4e9b\u5c40\u9650\u6027\u3002\u5373\u65e0\u6cd5\u8861\u91cf\u6709\u5305\u542b\u5173\u7cfb\u65f6\u7684\u6846\u56de\u5f52\u635f\u5931\uff0c\u5982\u4e0b\u56fe\uff0c\u4e09\u4e2a\u56de\u5f52\u6846\u5177\u6709\u76f8\u540c\u7684GIoU Loss\uff0c\u4f46\u662f\u663e\u7136\u7b2c\u4e09\u4e2a\u6846\u7684\u56de\u5f52\u6548\u679c\u66f4\u597d\u3002 IoU & GIoU \u5206\u6790 \u9996\u5148\uff0c\u5728\u672c\u6587\u4e0a\u90e8\u5206\u6211\u4eec\u5206\u6790\u4e86\u5173\u4e8e\u539f\u59cb\u7684IoU\u635f\u5931\u548cGIoU \u635f\u5931\u7684\u5c40\u9650\u6027\u3002\u4e0b\u9762\u5c06\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u7ed3\u679c\u5bf9\u8fb9\u754c\u6846\u56de\u5f52\u7684\u8fc7\u7a0b\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684\u89e3\u6790\u3002(\u8865\u5145\u8bf4\u660e: \u4e3a\u4ec0\u4e48\u8981\u8fdb\u884c\u6a21\u578b\u5b9e\u9a8c? \u56e0\u4e3a\u4ec5\u4ec5\u4ece\u68c0\u6d4b\u7ed3\u679c\u6765\u5206\u6790\u8fb9\u754c\u6846\u56de\u5f52\u7684\u8fc7\u7a0b\u5f88\u96be\uff0c\u56e0\u4e3a\u5728\u4e0d\u53d7\u63a7\u5236\u7684\u57fa\u51c6\u4e2d\u7684\u56de\u5f52\u60c5\u51b5\u5f80\u5f80\u4e0d\u5168\u9762\u6bd4\u5982\uff1a\u4e0d\u540c\u7684\u8ddd\u79bb(distances),\u4e0d\u540c\u7684\u5c3a\u5ea6(scales)\u548c\u4e0d\u540c\u7684\u957f\u5bbd\u6bd4(aspect ratios)\u3002 \u76f8\u53cd\uff0c\u8fdb\u884c\u6a21\u62df\u5b9e\u9a8c\uff0c\u5728\u5b9e\u9a8c\u4e2d\u7efc\u5408\u8003\u8651\u56de\u5f52\u60c5\u51b5\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5206\u6790\u7ed9\u5b9a\u635f\u5931\u51fd\u6570\u7684\u95ee\u9898\u3002) \u6a21\u62df\u5b9e\u9a8c \u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u8bd5\u56fe\u901a\u8fc7\u8ddd\u79bb(distances), \u5c3a\u5ea6 (scales)\u548c\u957f\u5bbd\u6bd4(aspect ratios)\u6765\u8986\u76d6\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5927\u90e8\u5206\u5173\u7cfb\uff0c\u5982\u56fe3(a).\u6240\u793a\u3002\u7279\u522b\u662f, \u6211\u4eec\u9009\u62e97\u4e2a\u5355\u4f4d\u6846 (\u5373\u6bcf\u4e2a\u6846\u7684\u9762\u79ef\u4e3a 1) \uff0c\u5177\u6709\u4e0d\u540c\u7684\u957f\u5bbd\u6bd4 (\u5373 \\(1: 4\u30011: 3\u30011: 2\u30011:1\u30012: 1\u30013:1 \u548c 4: 1\\) ) \u4f5c\u4e3a\u76ee\u6807\u6846\u3002\u5728\u4e0d\u5931\u4e00\u822c\u6027\u7684\u60c5\u51b5\u4e0b\uff0c7\u4e2a\u76ee\u6807\u6846\u7684\u4e2d\u5fc3\u70b9\u88ab\u56fa\u5b9a\u5728 \\((10,10)\\) \u3002\u951a\u6846\u5747\u5300\u5730\u5206\u6563\u57285000\u4e2a\u70b9\u4e0a\u3002 \\(({i})\\) \u8ddd\u79bb: \u5728\u4ee5\u534a\u5f84\u4e3a 3 \u7684 \\((10\u300110)\\) \u4e3a\u4e2d\u5fc3\u7684\u5706\u5f62\u533a\u57df\u5185, \u5747\u5300\u9009\u62e95000\u4e2a\u70b9, \u653e\u7f6e7\u4e2a\u5c3a\u5ea6\u30017\u4e2a\u957f\u5bbd\u6bd4\u7684\u951a \u6846\u3002\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\uff0c\u91cd\u53e0\u548c\u4e0d\u91cd\u53e0\u7684\u65b9\u6846\u90fd\u88ab\u5305\u62ec\u3002 \\(({ii})\\) \u5c3a\u5ea6:\u5bf9\u4e8e\u6bcf\u4e2a\u70b9, \u951a\u6846\u7684\u9762\u79ef\u5206\u522b\u8bbe\u7f6e\u4e3a \\(0.5 \u3001 0.67 \u3001 0.75 \u3001 1 \u3001 1.33 \u3001 1.5 \u548c 2\\) \u3002 \\(({iii})\\) \u957f\u5bbd\u6bd4: \u5bf9\u4e8e\u7ed9\u5b9a\u7684\u70b9\u548c\u5c3a\u5ea6, \u91c7\u7528 7 \u4e2a\u957f\u5bbd\u6bd4, \u5373\u4e0e\u76ee\u6807\u6846\u9075\u5faa\u76f8\u540c\u7684\u8bbe\u7f6e (\u5373 \\(1: 4 \u3001 1: 3 \u3001 1: 2 \u3001 1: 1 \u3001 2: 1 \u3001 3: 1 \u548c 4: 1\\) ) \u3002\u6240\u6709 \\(5000 \\times 7 \\times 7\\) \u951a\u7bb1\u90fd\u5bf9\u5e94\u5728\u6bcf\u4e2a\u76ee\u6807\u6846\u3002\u7efc \u4e0a\u6240\u8ff0\uff0c\u603b\u5171\u6709 \\(1,715,000 =7 \\times 7 \\times 7 \\times 5,000\\) \u4e2a\u56de\u5f52\u6848\u4f8b\u3002 \u56fe3: \u4eff\u771f\u5b9e\u9a8c: (a) \u901a\u8fc7\u8003\u8651\u4e0d\u540c\u7684\u8ddd\u79bb\u3001\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4, \u91c7\u7528\u4e86171.5\u4e07\u4e2a\u56de\u5f52\u6848\u4f8b\u3002(b)\u56de\u5f52\u8bef\u5dee\u548c\uff08\u5373: \\(\\sum_{n} \\mathbf{E}(t, n)\\) ) \u8fed\u4ee3\u6b21\u6570\u4e3a \\(\\mathrm{t}\\) \u65f6\u4e0d\u540c\u635f\u5931\u51fd\u6570\u7684\u66f2\u7ebf\u3002 \u7136\u540e\u901a\u8fc7\u7ed9\u5b9a\u635f\u5931\u51fd\u6570 \\(\\mathcal{L}\\) , \u6211\u4eec\u53ef\u4ee5\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u6765\u6a21\u62df\u6bcf\u79cd\u60c5\u51b5\u4e0b\u7684\u8fb9\u754c\u6846\u56de\u5f52\u8fc7\u7a0b\u3002\u5bf9\u4e8e\u9884\u6d4b\u6846 \\(B_{i}\\) , \u5f53\u524d\u7684\u9884\u6d4b\u53ef\u4ee5\u901a\u8fc7: \\(B_{i}^{t}=B_{i}^{t-1}+\\eta\\left(2-I o U_{i}^{t-1}\\right) \\nabla B_{i}^{t-1},\\) (4) \u5176\u4e2d \\(B_{i}^{t}\\) \u662f\u8fed\u4ee3 \\(t\\) \u65f6\u7684\u9884\u6d4b\u6846, \\(\\nabla B_{i}^{t-1}\\) \u8868\u793a\u635f\u5931\u7684\u68af\u5ea6\u3002 \\(\\eta\\) \u611f\u89c9\u53ef\u4ee5\u7406\u89e3\u4e3a\u5b66\u4e60\u7387\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6211\u4eec\u7684\u5b9e\u73b0\u4e2d\uff0c\u68af\u5ea6\u4e58\u4ee5 \\(2-I o U_{1}^{t-1}\\) \u53bb\u52a0\u901f\u6536\u655b\u3002 \u8fb9\u754c\u6846\u56de\u5f52\u7684\u6027\u80fd\u8bc4\u4f30\u901a\u8fc7\u4f7f\u7528 \\(\\ell_{1} -norm.\\) \u5bf9\u4e8e\u6bcf\u4e2a\u635f\u5931 \u51fd\u6570, \u4eff\u771f\u6a21\u62df\u5b9e\u9a8c\u5f53\u8fbe\u5230\u8fed\u4ee3 \\(T=200\\) \u65f6, \u8bef\u5dee\u66f2\u7ebf\u5982 \\(\u56fe3(b).\\) \u6240\u793a\u3002 IoU \u548c GIoU \u635f\u5931\u7684\u9650\u5236 \u5728\u56fe4\u4e2d\uff0c\u6211\u4eec\u53ef\u89c6\u5316\u8fed\u4ee3T\u65f6\u5bf95000\u4e2a\u5206\u6563\u70b9\u7684\u6700\u7ec8\u56de\u5f52\u8bef\u5dee\u3002 \u4ece\u56fe4(a)\u4e2d\u5f88\u5bb9\u6613\u770b\u51fa\uff0cIoU\u635f\u5931\u53ea\u9002\u7528\u4e8e\u4e0e\u76ee\u6807\u6846\u91cd\u53e0\u7684\u60c5\u51b5\u3002\u7531\u4e8e\u2207B\u603b\u662f0\uff0c\u6ca1\u6709\u91cd\u53e0\u7684\u951a\u6846\u5c06\u4e0d\u4f1a\u79fb\u52a8\u3002\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2a\u60e9\u7f5a\u9879\u89c1\u516c\u5f0f(3), GIoU \u635f\u5931\u80fd\u591f\u66f4\u597d\u7684\u7f13\u89e3\u975e\u91cd\u53e0 \u6848\u4f8b\u7684\u95ee\u9898\uff0c\u5982\u56fe\u6240\u793a4(b), \u4f46GIoU\u7684\u635f\u5931\u663e\u8457\u6269\u5927\u4e86\u76c6\u5730\uff0c\u5373GIoU\u7684\u5de5\u4f5c\u9762\u79ef\u3002\u4f46\u662f\uff0c\u5728\u6c34\u5e73\u65b9\u5411\u548c\u5782\u76f4\u65b9\u5411\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u7136\u5f88\u53ef\u80fd\u6709\u5f88\u5927\u7684\u8bef\u5dee\u3002\u8fd9\u662f\u56e0\u4e3aGIoU\u635f\u5931\u4e2d\u7684\u60e9\u7f5a\u9879\u662f\u7528\u6765\u6700\u5c0f\u5316|C\u2212A\u222aB|\uff0c\u4f46\u662fC\u2212A\u222aB\u7684\u9762\u79ef\u901a\u5e38\u5f88\u5c0f\u6216\u4e3a0\uff08\u5f53\u4e24\u4e2a\u76d2\u5b50\u6709\u5305\u542b\u5173\u7cfb\u65f6\uff09\uff0c\u7136\u540eGIoU\u51e0\u4e4e\u9000\u5316\u4e3aIoU\u635f\u5931\u3002\u53ea\u8981\u4ee5\u9002\u5f53\u7684\u5b66\u4e60\u901f\u7387\u8fd0\u884c\u8db3\u591f\u7684\u8fed\u4ee3GIoU \u635f\u5931\u80fd\u6536\u655b\u5230\u5f88\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u6536\u655b\u901f\u5ea6\u5374\u662f\u975e\u5e38\u6162\u3002\u4ece\u51e0\u4f55\u4e0a\u6765\u8bf4\uff0c\u4ece\u5982\u56fe1\u6240\u793a\u7684\u56de\u5f52\u6b65\u9aa4\u6765\u770b\uff0cGIoU\u5b9e\u9645\u4e0a\u589e\u5927\u4e86\u9884\u6d4b\u7684\u6846\u5927\u5c0f\uff0c\u7528\u6765\u548c\u76ee\u6807\u6846\u91cd\u53e0\uff0c\u7136\u540eIoU\u9879\u7528\u4e8e\u9884\u6d4b\u6846\u4e0e\u76ee\u6807\u6846\u5339\u914d\uff0c\u4ea7\u751f\u975e\u5e38\u7f13\u6162\u7684\u6536\u655b\u3002 \u7efc\u4e0a\u6240\u8ff0\uff0c\u5728\u975e\u91cd\u53e0\u60c5\u51b5\u4e0b\uff0cIoU\u635f\u5931\u6536\u655b\u662f\u7cdf\u7cd5\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u800cGIoU\u635f\u5931\u6536\u655b\u901f\u5ea6\u8f83\u6162\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u6846\u3002\u5728\u76ee\u6807\u68c0\u6d4b\u6d41\u7a0b\u4e2d\uff0cIoU\u548cGIoU\u7684\u635f\u5931\u90fd\u4e0d\u80fd\u4fdd\u8bc1\u56de\u5f52\u7684\u51c6\u786e\u6027\u3002 DIoU & CIoU \u901a\u8fc7\u524d\u9762\u7684IoU\u548cGIoU\u7684\u5206\u6790\u6211\u4eec\u5f88\u81ea\u7136\u4f1a\u95ee\u4ee5\u4e0b\u95ee\u9898\uff1a \u7b2c\u4e00\uff0c\u662f\u5426\u53ef\u4ee5\u76f4\u63a5\u6700\u5c0f\u5316\u9884\u6d4b\u6846\u548c\u76ee\u6807\u6846\u4e4b\u95f4\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\uff1f \u7b2c\u4e8c\uff0c\u5f53\u4e0e\u76ee\u6807\u6846\u6709\u91cd\u53e0\u751a\u81f3\u5305\u542b\u65f6\uff0c\u5982\u4f55\u4f7f\u56de\u5f52\u66f4\u51c6\u786e\u3001\u66f4\u5feb\uff1f DIoU loss Distance-IoU \u635f\u5931\uff1a\u66f4\u5feb\u66f4\u597d\u7684\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931,\u4e00\u822c\u6765\u8bf4, \\(IoU-based\\) \u635f\u5931\u53ef\u4ee5\u5b9a\u4e49\u4e3a \\(\\mathcal{L}=1-I o U+\\mathcal{R}\\left(B, B^{g t}\\right),\\) (5) \u5176\u4e2d \\(\\large\\mathcal{R}\\left(B, B^{g t}\\right)\\) \u662f \u9884\u6d4b\u6846 B \u548c\u76ee\u6807\u6846 \\(B^{g t}\\) \u7684\u60e9\u7f5a\u9879\u3002 \u901a\u8fc7\u8bbe\u8ba1\u9002\u5f53\u7684\u60e9\u7f5a\u9879, \u5728\u672c\u8282\u4e2d, \u6211\u4eec\u63d0\u51fa\u4e86 DIoU \u635f\u5931\u548cCIoU\u635f\u5931\u6765\u89e3\u7b54\u4e0a\u8ff0\u4e24\u4e2a\u95ee\u9898\u3002 \u4e3a\u4e86\u56de\u7b54\u7b2c\u4e00\u4e2a\u95ee\u9898, \u6211\u4eec\u63d0\u51fa\u5c06\u4e24\u4e2a\u8fb9\u754c\u6846\u7684\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u6807\u51c6\u5316\u8ddd\u79bb\u6700\u5c0f\u5316\uff0c\u60e9\u7f5a\u9879\u53ef\u4ee5\u5b9a\u4e49\u4e3a \\(\\large\\mathcal{R}_{D I o U}=\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}},\\) (6) \u5176\u4e2d \\(\\mathbf{b}\\) \u548c \\(\\mathbf{b}^{g t}\\) \u5206\u522b\u4ee3\u8868 B \u548c \\(B^{g t}\\) \u7684\u4e2d\u5fc3\u70b9\u3002 \\(\\rho(\\cdot)\\) \u4e3a\u6b27\u6c0f\u8ddd\u79bb, \\(\\mathrm{C}\\) \u662f\u8986\u76d6\u4e24\u4e2a\u76d2\u6846\u7684\u6700\u5c0f\u5c01\u95ed\u6846\u7684\u5bf9\u89d2\u7ebf\u957f\u5ea6\u3002 \\(DIoU\\) \u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a: \\(\\large\\mathcal{L}_{D I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}} .\\) (7) \u5982\u56fe5\u6240\u793a, \\(DIoU\\) \u635f\u5931\u7684\u60e9\u7f5a\u9879\u76f4\u63a5\u4f7f\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u6700\u5c0f\u5316, \u800c \\(\\mathrm{GIoU}\\) \u635f\u5931\u7684\u76ee\u7684\u662f\u51cf\u5c11 \\(C-B \\cup B^{g t}\\) \u7684\u9762\u79ef\u3002 DIoU \u548c IoU/GIoU \u635f\u5931\u6bd4\u8f83 \u65b0\u63d0\u51fa\u7684DIoU\u635f\u5931\u7ee7\u627fIoU\u548cGIoU\u635f\u5931\u7684\u4e00\u4e9b\u5c5e\u6027 DIoU\u635f\u5931\u5bf9\u56de\u5f52\u95ee\u9898\u7684\u5c3a\u5ea6\u4ecd\u7136\u662f\u4e0d\u53d8\u7684 \u4e0eGIoU\u635f\u5931\u7c7b\u4f3c, DIoU\u635f\u5931\u53ef\u4ee5\u5728\u4e0e\u76ee\u6807\u6846\u4e0d\u91cd\u53e0\u65f6\u4e3a\u8fb9\u754c\u6846\u63d0\u4f9b\u79fb\u52a8\u65b9\u5411\u3002 \u5f53\u4e24\u4e2a\u8fb9\u754c\u6846\u5b8c\u7f8e\u5339\u914d\u65f6, \\(\\mathcal{L}_{I o U}=\\mathcal{L}_{G I o U}=\\mathcal{L}_{D I o U}=0 .\\) \u5f53\u4e24\u4e2a\u6846\u90fd\u5f88\u8fdc\u65f6, \\(\\mathcal{L}_{G I o U}=\\mathcal{L}_{D I o U} \\rightarrow 2 .\\) DIoU\u635f\u5931\u6bd4IoU\u635f\u5931\u548cGIoU\u635f\u5931\u6709\u51e0\u4e2a\u4f18\u70b9, \u53ef\u4ee5\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u8fdb\u884c\u8bc4\u4f30\u3002 1. \u5982\u56fe1\u548c\u56fe3\u6240\u793a, \\(DIoU\u635f\u5931\\) \u53ef\u4ee5\u76f4\u63a5\u6700\u5c0f\u5316\u4e24\u4e2a\u6846\u7684\u8ddd\u79bb, \u56e0\u6b64\u6536\u655b\u901f\u5ea6\u6bd4 \\(GIoU\u635f\u5931\\) \u8981\u5feb\u5f97\u591a\u3002 2. \u5bf9\u4e8e\u4e24\u4e2a\u6846\u662f\u5305\u542b\u5173\u7cfb\u7684\u60c5\u51b5(\u56fe2), \u6216\u5728\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u60c5\u51b5(\u56fe6)\u4e0b, \\(DIoU\u635f\u77e2\\) \u53ef\u4ee5\u56de\u5f52\u975e\u5e38\u5feb, \u800c \\(\\mathrm{GIoU}\\) \u635f\u5931\u51e0\u4e4e\u9000\u5316\u4e3a \\(\\mathrm{IoU}\u635f\u5931\\) , \u5373 \\(|C-A \\cup B| \\rightarrow 0 .\\) Complete IoU Loss \u63a5\u7740\u6211\u4eec\u56de\u7b54\u4e86\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u8fb9\u754c\u6846\u56de\u5f52\u7684\u826f\u597d \u635f\u5931\u5e94\u8be5\u8981\u8003\u8651\u4e09\u4e2a\u91cd\u8981\u7684\u51e0\u4f55\u56e0\u7d20, \u5373 \u91cd\u53e0\u9762\u79ef\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u548c\u957f\u5bbd\u6bd4 \u3002\u901a\u8fc7\u7edf\u4e00\u5750\u6807, \\(IoU\u635f\u5931\\) \u8003\u8651\u4e86\u91cd\u53e0\u533a\u57df, \u800c \\(GIoU\u635f\u5931\\) \u4e25\u91cd\u4f9d\u8d56\u4e8e \\(IoU\u635f\u5931\\) \u3002\u6211\u4eec\u63d0\u51fa\u7684 \\(DIoU\u635f\u5931\\) \u65e8\u5728\u540c\u65f6\u8003\u8651\u8fb9\u754c\u6846\u7684\u91cd\u53e0\u9762\u79ef\u548c\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u3002\u7136\u800c, \u8fb9\u754c\u6846\u7684\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u4e5f\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u51e0\u4f55\u56e0\u7d20\u3002 \u56e0\u6b64\uff0c\u57fa\u4e8e \\(DIoU\u635f\u5931\\) \uff0c\u901a\u8fc7\u6dfb\u52a0\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u6765 \u63d0\u51fa \\(CIoU\u635f\u5931\\) : \\(\\large\\mathcal{R}_{C I o U}=\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v,\\) (8) \u5176\u4e2d \\(\\alpha\\) \u662f\u4e00\u4e2a\u6b63\u7684\u6743\u8861\u53c2\u6570, \\(v\\) \u8861\u91cf\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u3002 \\(\\large{v=\\frac{4}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right)^{2} .}\\) (9) \u5219\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a: \\(\\large\\mathcal{L}_{C I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v\\) (10) \\(\\large\\alpha=\\frac{v}{(1-I o U)+v}\\) (11) \u901a\u8fc7\u91cd\u53e0\u9762\u79ef\u56e0\u5b50\u7ed9\u4e88\u66f4\u9ad8\u7684\u4f18\u5148\u56de\u5f52, \u7279\u522b\u662f\u5bf9\u4e8e\u975e\u91cd\u53e0\u60c5\u51b5\u3002 \u6700\u7ec8, \\(CIoU\u635f\u5931\\) \u7684\u4f18\u5316\u4e0e \\(DIoU\u635f\u5931\\) \u7684\u4f18\u5316\u76f8\u540c, \u9664 \u4e86 \\(v w.r.t. w\\) \u7684\u68af\u5ea6\u5e94\u8be5\u6307\u5b9a \\(\\mathrm{w}\\) \u548c \\(h\\) \u3002 \\(\\large\\begin{array}{l} \\frac{\\partial v}{\\partial w}=\\frac{8}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right) \\times \\frac{h}{w^{2}+h^{2}}, \\\\ \\frac{\\partial v}{\\partial h}=-\\frac{8}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right) \\times \\frac{w}{w^{2}+h^{2}} . \\end{array}\\) (12) \u4e3b\u5bfc\u5668 \\(w^{2}+h^{2}\\) \u901a\u5e38\u662f\u4e00\u4e2a\u5f88\u5c0f\u7684\u503c\u5bf9\u4e8e \\(h\\) \u548c \\(w\\) \u7684\u8303 \u56f4\u5728 [0,1] , \u8fd9\u5f88\u53ef\u80fd\u4f1a\u4ea7\u751f\u68af\u5ea6\u7206\u70b8\u3002\u56e0\u6b64\u5728\u6211\u4eec\u7684\u5b9e\u73b0, \u4e3b\u5bfc\u5668 \\(w^{2}+h^{2}\\) \u88ab\u79fb\u9664, \u5c06\u6b65\u957f \\(\\frac{1} {w^{2}+h^{2}}\\) \u66ff\u6362\u4e3a \\(1\\) , \u68af\u5ea6\u65b9\u5411\u4ecd\u7136\u4e0e\u516c\u5f0f(12)\u4e00\u81f4\u3002 NMS(Non-Maximum Suppression) \u4ecb\u7ecd NMS\u662f\u5927\u591a\u6570\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u6700\u540e\u4e00\u6b65\uff0c\u5176\u4e2d\u5220\u9664\u4e86\u5197\u4f59\u7684\u68c0\u6d4b\u6846\u5f53\u5b83\u4e0e\u6700\u9ad8\u5206\u6846\u7684\u91cd\u53e0\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c\u3002 Soft-NMS (Bodla et al. 2017) \u7528\u8fde\u7eed\u51fd\u6570w.r.t.\u60e9\u7f5a\u76f8\u90bb\u6846\u7684\u68c0\u6d4b\u5206\u6570IoU\uff0c\u4ea7\u751f\u6bd4\u539f\u59cbNMS\u4ea7\u751f\u66f4\u67d4\u548c\u5927\u548c\u66f4\u5f3a\u5927\u7684\u6291\u5236\u3002IoU-Net (Jiang et al. 2018) \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u7f51\u7edc\u5206\u652f\u6765\u9884\u6d4b\u5b9a\u4f4d\u7f6e\u4fe1\u5ea6\u6765\u6307\u5bfcNMS\u3002\u6700\u8fd1\uff0c\u81ea\u9002\u5e94NMS\uff08Liu\uff0cHuang\uff0c\u548cWang 2019\uff09\u548cSofter-NMS\uff08He et al. 2019\uff09\u88ab\u63d0\u51fa\u5206\u522b\u7814\u7a76\u9002\u5f53\u7684\u9608\u503c\u7b56\u7565\u548c\u52a0\u6743\u5e73\u5747\u7b56\u7565\u3002 \u5728\u672c\u5de5\u4f5c\u4e2d\uff0c\u7b80\u5355\u5c06DIoU\u4f5c\u4e3a\u539f\u59cbNMS\u7684\u6807\u51c6, \u5728\u6291\u5236\u5197\u4f59\u6846\u65f6\uff0c\u540c\u65f6\u8003\u8651\u8fb9\u754c\u6846\u7684\u91cd\u53e0\u9762\u79ef\u548c\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002 DioU-NMS Non-Maximum Suppression using DIoU \u5728\u539f\u59cb\u7684NMS\u4e2d, IoU\u6307\u6807\u7528\u4e8e\u6291\u5236\u5415\u4f59\u7684\u68c0\u6d4b\u6846, \u5176 \u4e2d\u91cd\u53e0\u533a\u57df\u662f\u552f\u4e00\u7684\u56e0\u7d20, \u5bf9\u4e8e\u6709\u906e\u6321\u7684\u60c5\u51b5\uff0c\u5f80\u5f80\u4f1a \u4ea7\u751f\u9519\u8bef\u7684\u6291\u5236\u3002 \u6211\u4eec\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\u5efa\u8bae \\(DIoU\\) \u662f \\(NMS\\) \u7684\u66f4\u597d\u6807\u51c6\uff0c\u56e0\u4e3a\u5728\u6291\u5236\u6807\u51c6\u4e2d\u4e0d\u4ec5\u5e94\u8003\u8651\u91cd\u53e0 \\(DIoU-NMS\\) \u88ab\u6b63\u5f0f\u5b9a\u4e49\u4e3a: \\(s_{i}=\\left\\{\\begin{array}{l} s_{i}, I o U-\\mathcal{R}_{D I o U}\\left(\\mathcal{M}, B_{i}\\right)<\\varepsilon, \\\\ 0, \\quad I o U-\\mathcal{R}_{D I o U}\\left(\\mathcal{M}, B_{i}\\right) \\geq \\varepsilon, \\end{array}\\right.\\) (13) \u5176\u4e2d\u6846 \\(B_{i}\\) \u88ab\u53bb\u9664\u901a\u8fc7\u540c\u65f6\u5230\u8003\u8651 \\(IoU\\) \u548c\u4e24\u4e2a\u6846\u4e2d\u5fc3\u70b9 \u7684\u8ddd\u79bb\u3002 \\(s_{i}\\) \u662f\u5206\u7c7b\u5f97\u5206\u548c \\(\\varepsilon\\) \u662f \\(NMS\\) \u9608\u503c\u3002\u6211\u4eec\u8ba4\u4e3a\u4e24 \u4e2a\u4e2d\u5fc3\u70b9\u8f83\u8fdc\u7684\u6846\u53ef\u80fd\u4f1a\u5b9a\u4f4d\u4e0d\u540c\u7684\u7269\u4f53, \u800c\u4e0d\u5e94\u8be5\u88ab \u5220\u9664\u3002\u6b64\u5916 \\(DIoU-NMS\\) \u662f\u975e\u5e38\u7075\u6d3b, \u4ec5\u4ec5\u662f\u51e0\u884c\u7684\u4ee3\u7801\u5c31\u53ef\u4ee5\u96c6\u6210\u5230\u4efb\u4f55\u76ee\u6807\u68c0\u6d4b\u7ba1\u9053\u4e2d\u3002 \u5c0f\u7ed3 \u5728\u672c\u6587\u4e2d\uff0c\u4e3b\u8981\u7684\u4ecb\u7ecd\u7528\u4e8e\u8fb9\u754c\u6846\u56de\u5f52\u7684 \\(DIoU\u635f\u5931\\) \u548c \\(CIoU \u635f\u5931\\) \u548c \u7528\u4e8e\u6291\u5236\u5197\u4f59\u68c0\u6d4b\u6846\u7684 \\(DIoU-NMS\u3002\\) \u901a\u8fc7\u76f4\u63a5\u6700\u5c0f\u5316\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u7684\u5f52\u4e00\u5316\u7684\u8ddd\u79bb\uff0c \\(DIoU \u635f\u5931\\) \u53ef\u4ee5\u6bd4 \\(GIoU \u635f\u5931\\) \u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u3002 \u6b64\u5916 \\(CIoU\u635f\u5931\\) \u8003\u8651\u4e86\u4e09\u4e2a\u51e0\u4f55\u5c5e\u6027(\u5373 \u91cd\u53e0\u533a\u57df\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb \u548c \u957f\u5bbd\u6bd4),\u4fc3\u8fdb\u4e86 \u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u4f18\u7684\u6027\u80fd\u3002 \u53c2\u8003\u6587\u7ae0 https://github.com/Zzh-tju/DIoU/blob/master/README.md#introduction https://github.com/Zzh-tju/DIoU/blob/master/README.md#introduction IoU: https://arxiv.org/pdf/1608.01471.pdf GIoU: https://giou.stanford.edu/GIoU.pdf DIoU: https://arxiv.org/pdf/1911.08287.pdf","title":"5.2 IoU\u6df1\u5165\u89e3\u6790"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_1","text":"\u8fb9\u754c\u6846\u56de\u5f52\u662f\u76ee\u6807\u68c0\u6d4b\u7684\u5173\u952e\u6b65\u9aa4 \uff0c\u5728\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u867d\u7136 \\(\\ell_n\\) -norm loss \u88ab\u5e7f\u6cdb\u7528\u4e8e\u8fb9\u754c\u6846\u56de\u5f52\uff0c\u4f46\u5b83\u4e0d\u662f\u9488\u5bf9\u8bc4\u4f30\u6307\u6807\u91cf\u8eab\u5b9a\u5236\u7684\uff0c\u5373 Intersection over Union (IoU)\u3002\u6700\u8fd1\uff0c\u5df2\u7ecf\u63d0\u51fa\u4e86 IoU \u635f\u5931\u548cgeneralized IoU (GIoU) Loss\u4f5c\u4e3a\u8bc4\u4f30IoU\u7684\u6307\u6807 \uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u6536\u655b\u901f\u5ea6\u6162\u548c\u56de\u5f52\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u7ed3\u5408\u9884\u6d4b\u6846\u548c\u76ee\u6807\u6846\u4e4b\u95f4\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\u6765\u63d0\u51fa\u8ddd\u79bb-IoU (DIoU) Loss\uff0c\u5b83\u5728\u8bad\u7ec3\u4e2d\u7684\u6536\u655b\u901f\u5ea6\u6bd4 IoU \u548c GIoU Loss\u5feb\u5f97\u591a\u3002 \u6b64\u5916\uff0c\u672c\u6587\u603b\u7ed3\u4e86\u8fb9\u754c\u6846\u56de\u5f52\u4e2d\u7684\u4e09\u4e2a\u51e0\u4f55\u56e0\u7d20\uff0c\u5373 \u91cd\u53e0\u9762\u79ef\uff08overlap area\uff09\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb\uff08central point distance\uff09\u548c\u9ad8\u5bbd\u6bd4\uff08aspect ratio\uff09 \uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e86\u5b8c\u5168 \\(IoU (CIoU)\\) \u635f\u5931\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u4f18\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5c06 \\(DIoU \u548c CIoU \u635f\u5931\\) \u7ed3\u5408\u5230\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0c\u4f8b\u5982 YOLO v3\u3001SSD \u548c Faster RCNN\uff0c\u6211\u4eec\u4e0d\u4ec5\u5728 IoU \u6307\u6807\u65b9\u9762\u800c\u4e14\u5728 GIoU \u6307\u6807\u65b9\u9762\u90fd\u83b7\u5f97\u4e86\u663e\u7740\u7684\u6027\u80fd\u63d0\u5347\u3002\u6b64\u5916\uff0cDIoU \u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u7528\u4e8e\u975e\u6700\u5927\u6291\u5236\uff08NMS\uff09\u4f5c\u4e3a\u6807\u51c6\uff0c\u8fdb\u4e00\u6b65\u4fc3\u8fdb\u6027\u80fd\u63d0\u5347\u3002 \u6ce8\u91ca:\u8fd9\u91ccIoU\u6307\u6807\u65b9\u9762\u548cGIoU\u6307\u6807\u65b9\u9762\u6307\u7684\u662f\u5728\uff1a\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u6d4b\u91cf(mAP\u503c ),IoU\u635f\u5931\u8ba1\u7b97\u7a33\u5b9a\u6027\u7b49\u4e00\u4e9b\u65b9\u9762\u3002 \u76ee\u6807\u68c0\u6d4b\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u95ee\u9898\u4e4b\u4e00 \uff0c\u51e0\u5341 \u5e74\u6765\u4e00\u76f4\u53d7\u5230\u4e86\u5e7f\u6cdb\u7684\u7814\u7a76\u5173\u6ce8 (Redmon et al. 2016; Redmon and Farhadi 2018; Ren et al. 2015; He et al. 2017; Yang et al. 2018; Wang et al. 2019; 2018). \u901a\u5e38\uff0c\u73b0\u6709\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u53ef\u4ee5\u5206\u4e3a\uff1a - \u5355\u9636\u6bb5-\u68c0\u6d4b\uff0c\u5982YOLO\u7cfb\u5217 (Redmon et al. 2016; Red- mon and Farhadi 2017; 2018) \u548cSSD (Liu et al. 2016; Fu et al. 2017), - \u4e24\u9636\u6bb5\u68c0\u6d4b\uff0c\u5982 R-CNN\u7cfb\u5217\u68c0\u6d4b (Girshick et al. 2014; Girshick 2015; Ren et al. 2015; He et al. 2017), - \u751a\u81f3\u662f\u591a\u9636\u6bb5\u7684\u68c0\u6d4b, \u50cfCascade R-CNN (Cai and Vasconcelos 2018). \u5c3d\u7ba1\u5b58\u5728\u8fd9\u4e9b\u4e0d \u540c\u7684\u68c0\u6d4b\u6846\u67b6\uff0c\u4f46\u8fb9\u754c\u6846\u56de\u5f52\u9884\u6d4b\u4e00\u4e2a\u77e9\u5f62\u6846\u6765\u5b9a\u4f4d\u76ee\u6807\u5bf9\u8c61\u4ecd\u7136\u662f\u5176\u4e2d\u5173\u952e\u6b65\u9aa4\u3002","title":"\ud83d\udcd8\u6458\u8981"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_2","text":"\u672c\u6587\u4e3b\u8981\u662f\u7ed3\u5408\u8bba\u6587Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression( https://arxiv.org/pdf/1911.08287.pdf ) \u5bf9 IoU \u7684\u89e3\u6790\u5b66\u4e60\u3002","title":"\u524d\u8a00"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou","text":"","title":"IoU"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou_1","text":"Intersection over Union (IoU) \u5728\u6307\u6807\u8bc4\u4f30\u6982\u8ff0\u7684\u5c0f\u8282\u6709\u4ecb\u7ecd\u8fc7IoU,\u5df2\u7ecf\u5bf9IoU\u6709\u4e86\u521d\u6b65\u7684\u8ba4\u8bc6(\u5176\u5b9e\u5728yolov5\u9879\u76ee\u4e2d\u5e76\u4e0d\u662f\u7b80\u5355\u7684\u4f7f\u7528\uff0c\u800c\u662f\u7528\u7684\u540e\u9762\u4ecb\u7ecd\u7684CIoU ) \u8ba1\u7b97\u516c\u5f0f\uff1a \\(\\Large{I o U=\\frac{\\left|B \\cap B^{g t}\\right|}{\\left|B \\cup B^{g t}\\right|} }\\) (1) \\(B^{g t}=\\left(x^{g t}, y^{g t}, w^{g t}, h^{g t}\\right)\\) \u662f\u771f\u5b9e\u56de\u5f52\u6846(gt:ground-truth), \\(B=(x, y, w, h)\\) \u662f\u9884\u6d4b\u56de\u5f52\u6846\u3002","title":"IoU\u4ecb\u7ecd"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou-loss","text":"\u8ba1\u7b97\u516c\u5f0f: \\(\\Large\\mathcal{L}_{I o U}=1-\\frac{\\left|B \\cap B^{g t}\\right|}{\\left|B \\cup B^{g t}\\right|}\\) (2)","title":"IoU loss"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou-loss_1","text":"\u6709\u660e\u663e\u7684\u7f3a\u9677 IoU loss\u53ea\u5728\u8fb9\u754c\u6846\u6709\u91cd\u53e0\u65f6\u624d\u80fd\u5de5\u4f5c, \u5bf9\u4e8e\u4e0d\u91cd\u53e0\u7684\u60c5\u51b5\u4e0d\u4f1a\u63d0\u4f9b\u4efb\u4f55\u79fb\u52a8\u68af\u5ea6 (\u79fb\u52a8\u4ee3\u8868\u9884\u6d4b\u6846\u671d\u7740\u76ee\u6807\u6846\u91cd\u53e0\u7684\u65b9\u5411\u79fb\u52a8) \u3002\u79fb\u52a8\u68af\u5ea6\u8868\u793a\u65e0\u6cd5\u8861\u91cf\u5b8c\u5168\u4e0d\u76f8\u4ea4\u7684\u4e24\u4e2a\u6846\u6240\u4ea7\u751f\u7684\u7684\u635f\u5931\uff08iou\u56fa\u5b9a\u4e3a0\uff09\uff0c\u548c\u4e24\u4e2a\u4e0d\u540c\u5f62\u72b6\u7684\u9884\u6d4b\u6846\u53ef\u80fd\u4ea7\u751f\u76f8\u540c\u7684loss\uff08\u76f8\u540c\u7684iou\uff09\u5206\u522b\u5982\u4e0b\u56fe\u7684\u5de6\u8fb9\u548c\u53f3\u8fb9\u6240\u793a\u3002","title":"IoU Loss \u4f18\u7f3a\u70b9\u5206\u6790"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#giou","text":"","title":"GIoU"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#giou_1","text":"GIoU\u7684\u8bbe\u8ba1\u521d\u8877\u5c31\u662f\u60f3\u89e3\u51b3IoU Loss\u5b58\u5728\u7684\u95ee\u9898\uff08\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u4e0d\u76f8\u4ea4\u65f6iou\u6052\u5b9a\u4e3a0\uff09\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957Generalized Intersection over Union Loss\u3002\u5728IoU\u7684\u57fa\u7840\u4e0a\uff0cGIoU\u8fd8\u9700\u8981\u627e\u5230\u9884\u6d4b\u6846\u548c\u771f\u5b9e\u6846\u7684\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\uff0c\u7136\u540e\u6c42\u51fa\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u51cf\u53bb\u4e24\u4e2a\u9884\u6d4b\u6846union\u7684\u9762\u79ef\uff0c\u5177\u4f53\u7b97\u6cd5\u6d41\u7a0b\u5982\u4e0b\uff1a","title":"GIoU\u4ecb\u7ecd"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#giou-loss","text":"\u8ba1\u7b97\u516c\u5f0f : \\(\\large\\mathcal{L}_{G I o U}=1-I o U+\\frac{\\left|C-B \\cup B^{g t}\\right|}{|C|}\\) (3) \u5176\u4e2d \\(C\\) \u662f\u8986\u76d6 \\(B\\) \u548c \\(B^{g t}\\) \u7684\u6700\u5c0f\u65b9\u6846 ,\u7531\u4e8e\u5f15\u5165\u4e86 \\(C\\) \uff0c\u5728\u4e0d\u91cd\u53e0\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u6846\u4e5f\u4f1a\u5411\u76ee\u6807\u6846\u79fb\u52a8\u3002","title":"GIoU loss"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#giou_2","text":"GIoU Loss\u89e3\u51b3\u4e86IoU Loss\u5728\u4e0d\u76f8\u4ea4\u60c5\u51b5\u7684\u95ee\u9898\uff0c\u5728\u6240\u6709\u6027\u80fd\u6307\u6807\u4e2d\u90fd\u53ef\u4ee5\u4f5c\u4e3aIoU\u7684\u9002\u5f53\u66ff\u4ee3\u54c1\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\u80fd\u591f\u5f97\u5230\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002 \u7f3a\u70b9\uff1a\u867d\u7136GIoU\u53ef\u4ee5\u7f13\u89e3\u91cd\u53e0\u60c5\u51b5\u4e0b\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898,\u4f46\u5b83\u4ecd\u6709\u4e00\u4e9b\u5c40\u9650\u6027\u3002\u5373\u65e0\u6cd5\u8861\u91cf\u6709\u5305\u542b\u5173\u7cfb\u65f6\u7684\u6846\u56de\u5f52\u635f\u5931\uff0c\u5982\u4e0b\u56fe\uff0c\u4e09\u4e2a\u56de\u5f52\u6846\u5177\u6709\u76f8\u540c\u7684GIoU Loss\uff0c\u4f46\u662f\u663e\u7136\u7b2c\u4e09\u4e2a\u6846\u7684\u56de\u5f52\u6548\u679c\u66f4\u597d\u3002","title":"GIoU \u4f18\u7f3a\u70b9\u5206\u6790"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou-giou","text":"\u9996\u5148\uff0c\u5728\u672c\u6587\u4e0a\u90e8\u5206\u6211\u4eec\u5206\u6790\u4e86\u5173\u4e8e\u539f\u59cb\u7684IoU\u635f\u5931\u548cGIoU \u635f\u5931\u7684\u5c40\u9650\u6027\u3002\u4e0b\u9762\u5c06\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u7ed3\u679c\u5bf9\u8fb9\u754c\u6846\u56de\u5f52\u7684\u8fc7\u7a0b\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684\u89e3\u6790\u3002(\u8865\u5145\u8bf4\u660e: \u4e3a\u4ec0\u4e48\u8981\u8fdb\u884c\u6a21\u578b\u5b9e\u9a8c? \u56e0\u4e3a\u4ec5\u4ec5\u4ece\u68c0\u6d4b\u7ed3\u679c\u6765\u5206\u6790\u8fb9\u754c\u6846\u56de\u5f52\u7684\u8fc7\u7a0b\u5f88\u96be\uff0c\u56e0\u4e3a\u5728\u4e0d\u53d7\u63a7\u5236\u7684\u57fa\u51c6\u4e2d\u7684\u56de\u5f52\u60c5\u51b5\u5f80\u5f80\u4e0d\u5168\u9762\u6bd4\u5982\uff1a\u4e0d\u540c\u7684\u8ddd\u79bb(distances),\u4e0d\u540c\u7684\u5c3a\u5ea6(scales)\u548c\u4e0d\u540c\u7684\u957f\u5bbd\u6bd4(aspect ratios)\u3002 \u76f8\u53cd\uff0c\u8fdb\u884c\u6a21\u62df\u5b9e\u9a8c\uff0c\u5728\u5b9e\u9a8c\u4e2d\u7efc\u5408\u8003\u8651\u56de\u5f52\u60c5\u51b5\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5206\u6790\u7ed9\u5b9a\u635f\u5931\u51fd\u6570\u7684\u95ee\u9898\u3002)","title":"IoU &amp; GIoU \u5206\u6790"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_3","text":"\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u8bd5\u56fe\u901a\u8fc7\u8ddd\u79bb(distances), \u5c3a\u5ea6 (scales)\u548c\u957f\u5bbd\u6bd4(aspect ratios)\u6765\u8986\u76d6\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5927\u90e8\u5206\u5173\u7cfb\uff0c\u5982\u56fe3(a).\u6240\u793a\u3002\u7279\u522b\u662f, \u6211\u4eec\u9009\u62e97\u4e2a\u5355\u4f4d\u6846 (\u5373\u6bcf\u4e2a\u6846\u7684\u9762\u79ef\u4e3a 1) \uff0c\u5177\u6709\u4e0d\u540c\u7684\u957f\u5bbd\u6bd4 (\u5373 \\(1: 4\u30011: 3\u30011: 2\u30011:1\u30012: 1\u30013:1 \u548c 4: 1\\) ) \u4f5c\u4e3a\u76ee\u6807\u6846\u3002\u5728\u4e0d\u5931\u4e00\u822c\u6027\u7684\u60c5\u51b5\u4e0b\uff0c7\u4e2a\u76ee\u6807\u6846\u7684\u4e2d\u5fc3\u70b9\u88ab\u56fa\u5b9a\u5728 \\((10,10)\\) \u3002\u951a\u6846\u5747\u5300\u5730\u5206\u6563\u57285000\u4e2a\u70b9\u4e0a\u3002 \\(({i})\\) \u8ddd\u79bb: \u5728\u4ee5\u534a\u5f84\u4e3a 3 \u7684 \\((10\u300110)\\) \u4e3a\u4e2d\u5fc3\u7684\u5706\u5f62\u533a\u57df\u5185, \u5747\u5300\u9009\u62e95000\u4e2a\u70b9, \u653e\u7f6e7\u4e2a\u5c3a\u5ea6\u30017\u4e2a\u957f\u5bbd\u6bd4\u7684\u951a \u6846\u3002\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\uff0c\u91cd\u53e0\u548c\u4e0d\u91cd\u53e0\u7684\u65b9\u6846\u90fd\u88ab\u5305\u62ec\u3002 \\(({ii})\\) \u5c3a\u5ea6:\u5bf9\u4e8e\u6bcf\u4e2a\u70b9, \u951a\u6846\u7684\u9762\u79ef\u5206\u522b\u8bbe\u7f6e\u4e3a \\(0.5 \u3001 0.67 \u3001 0.75 \u3001 1 \u3001 1.33 \u3001 1.5 \u548c 2\\) \u3002 \\(({iii})\\) \u957f\u5bbd\u6bd4: \u5bf9\u4e8e\u7ed9\u5b9a\u7684\u70b9\u548c\u5c3a\u5ea6, \u91c7\u7528 7 \u4e2a\u957f\u5bbd\u6bd4, \u5373\u4e0e\u76ee\u6807\u6846\u9075\u5faa\u76f8\u540c\u7684\u8bbe\u7f6e (\u5373 \\(1: 4 \u3001 1: 3 \u3001 1: 2 \u3001 1: 1 \u3001 2: 1 \u3001 3: 1 \u548c 4: 1\\) ) \u3002\u6240\u6709 \\(5000 \\times 7 \\times 7\\) \u951a\u7bb1\u90fd\u5bf9\u5e94\u5728\u6bcf\u4e2a\u76ee\u6807\u6846\u3002\u7efc \u4e0a\u6240\u8ff0\uff0c\u603b\u5171\u6709 \\(1,715,000 =7 \\times 7 \\times 7 \\times 5,000\\) \u4e2a\u56de\u5f52\u6848\u4f8b\u3002 \u56fe3: \u4eff\u771f\u5b9e\u9a8c: (a) \u901a\u8fc7\u8003\u8651\u4e0d\u540c\u7684\u8ddd\u79bb\u3001\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4, \u91c7\u7528\u4e86171.5\u4e07\u4e2a\u56de\u5f52\u6848\u4f8b\u3002(b)\u56de\u5f52\u8bef\u5dee\u548c\uff08\u5373: \\(\\sum_{n} \\mathbf{E}(t, n)\\) ) \u8fed\u4ee3\u6b21\u6570\u4e3a \\(\\mathrm{t}\\) \u65f6\u4e0d\u540c\u635f\u5931\u51fd\u6570\u7684\u66f2\u7ebf\u3002 \u7136\u540e\u901a\u8fc7\u7ed9\u5b9a\u635f\u5931\u51fd\u6570 \\(\\mathcal{L}\\) , \u6211\u4eec\u53ef\u4ee5\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u6765\u6a21\u62df\u6bcf\u79cd\u60c5\u51b5\u4e0b\u7684\u8fb9\u754c\u6846\u56de\u5f52\u8fc7\u7a0b\u3002\u5bf9\u4e8e\u9884\u6d4b\u6846 \\(B_{i}\\) , \u5f53\u524d\u7684\u9884\u6d4b\u53ef\u4ee5\u901a\u8fc7: \\(B_{i}^{t}=B_{i}^{t-1}+\\eta\\left(2-I o U_{i}^{t-1}\\right) \\nabla B_{i}^{t-1},\\) (4) \u5176\u4e2d \\(B_{i}^{t}\\) \u662f\u8fed\u4ee3 \\(t\\) \u65f6\u7684\u9884\u6d4b\u6846, \\(\\nabla B_{i}^{t-1}\\) \u8868\u793a\u635f\u5931\u7684\u68af\u5ea6\u3002 \\(\\eta\\) \u611f\u89c9\u53ef\u4ee5\u7406\u89e3\u4e3a\u5b66\u4e60\u7387\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6211\u4eec\u7684\u5b9e\u73b0\u4e2d\uff0c\u68af\u5ea6\u4e58\u4ee5 \\(2-I o U_{1}^{t-1}\\) \u53bb\u52a0\u901f\u6536\u655b\u3002 \u8fb9\u754c\u6846\u56de\u5f52\u7684\u6027\u80fd\u8bc4\u4f30\u901a\u8fc7\u4f7f\u7528 \\(\\ell_{1} -norm.\\) \u5bf9\u4e8e\u6bcf\u4e2a\u635f\u5931 \u51fd\u6570, \u4eff\u771f\u6a21\u62df\u5b9e\u9a8c\u5f53\u8fbe\u5230\u8fed\u4ee3 \\(T=200\\) \u65f6, \u8bef\u5dee\u66f2\u7ebf\u5982 \\(\u56fe3(b).\\) \u6240\u793a\u3002","title":"\u6a21\u62df\u5b9e\u9a8c"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou-giou_1","text":"\u5728\u56fe4\u4e2d\uff0c\u6211\u4eec\u53ef\u89c6\u5316\u8fed\u4ee3T\u65f6\u5bf95000\u4e2a\u5206\u6563\u70b9\u7684\u6700\u7ec8\u56de\u5f52\u8bef\u5dee\u3002 \u4ece\u56fe4(a)\u4e2d\u5f88\u5bb9\u6613\u770b\u51fa\uff0cIoU\u635f\u5931\u53ea\u9002\u7528\u4e8e\u4e0e\u76ee\u6807\u6846\u91cd\u53e0\u7684\u60c5\u51b5\u3002\u7531\u4e8e\u2207B\u603b\u662f0\uff0c\u6ca1\u6709\u91cd\u53e0\u7684\u951a\u6846\u5c06\u4e0d\u4f1a\u79fb\u52a8\u3002\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2a\u60e9\u7f5a\u9879\u89c1\u516c\u5f0f(3), GIoU \u635f\u5931\u80fd\u591f\u66f4\u597d\u7684\u7f13\u89e3\u975e\u91cd\u53e0 \u6848\u4f8b\u7684\u95ee\u9898\uff0c\u5982\u56fe\u6240\u793a4(b), \u4f46GIoU\u7684\u635f\u5931\u663e\u8457\u6269\u5927\u4e86\u76c6\u5730\uff0c\u5373GIoU\u7684\u5de5\u4f5c\u9762\u79ef\u3002\u4f46\u662f\uff0c\u5728\u6c34\u5e73\u65b9\u5411\u548c\u5782\u76f4\u65b9\u5411\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u7136\u5f88\u53ef\u80fd\u6709\u5f88\u5927\u7684\u8bef\u5dee\u3002\u8fd9\u662f\u56e0\u4e3aGIoU\u635f\u5931\u4e2d\u7684\u60e9\u7f5a\u9879\u662f\u7528\u6765\u6700\u5c0f\u5316|C\u2212A\u222aB|\uff0c\u4f46\u662fC\u2212A\u222aB\u7684\u9762\u79ef\u901a\u5e38\u5f88\u5c0f\u6216\u4e3a0\uff08\u5f53\u4e24\u4e2a\u76d2\u5b50\u6709\u5305\u542b\u5173\u7cfb\u65f6\uff09\uff0c\u7136\u540eGIoU\u51e0\u4e4e\u9000\u5316\u4e3aIoU\u635f\u5931\u3002\u53ea\u8981\u4ee5\u9002\u5f53\u7684\u5b66\u4e60\u901f\u7387\u8fd0\u884c\u8db3\u591f\u7684\u8fed\u4ee3GIoU \u635f\u5931\u80fd\u6536\u655b\u5230\u5f88\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u6536\u655b\u901f\u5ea6\u5374\u662f\u975e\u5e38\u6162\u3002\u4ece\u51e0\u4f55\u4e0a\u6765\u8bf4\uff0c\u4ece\u5982\u56fe1\u6240\u793a\u7684\u56de\u5f52\u6b65\u9aa4\u6765\u770b\uff0cGIoU\u5b9e\u9645\u4e0a\u589e\u5927\u4e86\u9884\u6d4b\u7684\u6846\u5927\u5c0f\uff0c\u7528\u6765\u548c\u76ee\u6807\u6846\u91cd\u53e0\uff0c\u7136\u540eIoU\u9879\u7528\u4e8e\u9884\u6d4b\u6846\u4e0e\u76ee\u6807\u6846\u5339\u914d\uff0c\u4ea7\u751f\u975e\u5e38\u7f13\u6162\u7684\u6536\u655b\u3002 \u7efc\u4e0a\u6240\u8ff0\uff0c\u5728\u975e\u91cd\u53e0\u60c5\u51b5\u4e0b\uff0cIoU\u635f\u5931\u6536\u655b\u662f\u7cdf\u7cd5\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u800cGIoU\u635f\u5931\u6536\u655b\u901f\u5ea6\u8f83\u6162\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u6846\u3002\u5728\u76ee\u6807\u68c0\u6d4b\u6d41\u7a0b\u4e2d\uff0cIoU\u548cGIoU\u7684\u635f\u5931\u90fd\u4e0d\u80fd\u4fdd\u8bc1\u56de\u5f52\u7684\u51c6\u786e\u6027\u3002","title":"IoU \u548c GIoU \u635f\u5931\u7684\u9650\u5236"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#diou-ciou","text":"\u901a\u8fc7\u524d\u9762\u7684IoU\u548cGIoU\u7684\u5206\u6790\u6211\u4eec\u5f88\u81ea\u7136\u4f1a\u95ee\u4ee5\u4e0b\u95ee\u9898\uff1a \u7b2c\u4e00\uff0c\u662f\u5426\u53ef\u4ee5\u76f4\u63a5\u6700\u5c0f\u5316\u9884\u6d4b\u6846\u548c\u76ee\u6807\u6846\u4e4b\u95f4\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\uff1f \u7b2c\u4e8c\uff0c\u5f53\u4e0e\u76ee\u6807\u6846\u6709\u91cd\u53e0\u751a\u81f3\u5305\u542b\u65f6\uff0c\u5982\u4f55\u4f7f\u56de\u5f52\u66f4\u51c6\u786e\u3001\u66f4\u5feb\uff1f","title":"DIoU &amp; CIoU"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#diou-loss","text":"Distance-IoU \u635f\u5931\uff1a\u66f4\u5feb\u66f4\u597d\u7684\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931,\u4e00\u822c\u6765\u8bf4, \\(IoU-based\\) \u635f\u5931\u53ef\u4ee5\u5b9a\u4e49\u4e3a \\(\\mathcal{L}=1-I o U+\\mathcal{R}\\left(B, B^{g t}\\right),\\) (5) \u5176\u4e2d \\(\\large\\mathcal{R}\\left(B, B^{g t}\\right)\\) \u662f \u9884\u6d4b\u6846 B \u548c\u76ee\u6807\u6846 \\(B^{g t}\\) \u7684\u60e9\u7f5a\u9879\u3002 \u901a\u8fc7\u8bbe\u8ba1\u9002\u5f53\u7684\u60e9\u7f5a\u9879, \u5728\u672c\u8282\u4e2d, \u6211\u4eec\u63d0\u51fa\u4e86 DIoU \u635f\u5931\u548cCIoU\u635f\u5931\u6765\u89e3\u7b54\u4e0a\u8ff0\u4e24\u4e2a\u95ee\u9898\u3002 \u4e3a\u4e86\u56de\u7b54\u7b2c\u4e00\u4e2a\u95ee\u9898, \u6211\u4eec\u63d0\u51fa\u5c06\u4e24\u4e2a\u8fb9\u754c\u6846\u7684\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u6807\u51c6\u5316\u8ddd\u79bb\u6700\u5c0f\u5316\uff0c\u60e9\u7f5a\u9879\u53ef\u4ee5\u5b9a\u4e49\u4e3a \\(\\large\\mathcal{R}_{D I o U}=\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}},\\) (6) \u5176\u4e2d \\(\\mathbf{b}\\) \u548c \\(\\mathbf{b}^{g t}\\) \u5206\u522b\u4ee3\u8868 B \u548c \\(B^{g t}\\) \u7684\u4e2d\u5fc3\u70b9\u3002 \\(\\rho(\\cdot)\\) \u4e3a\u6b27\u6c0f\u8ddd\u79bb, \\(\\mathrm{C}\\) \u662f\u8986\u76d6\u4e24\u4e2a\u76d2\u6846\u7684\u6700\u5c0f\u5c01\u95ed\u6846\u7684\u5bf9\u89d2\u7ebf\u957f\u5ea6\u3002 \\(DIoU\\) \u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a: \\(\\large\\mathcal{L}_{D I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}} .\\) (7) \u5982\u56fe5\u6240\u793a, \\(DIoU\\) \u635f\u5931\u7684\u60e9\u7f5a\u9879\u76f4\u63a5\u4f7f\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u6700\u5c0f\u5316, \u800c \\(\\mathrm{GIoU}\\) \u635f\u5931\u7684\u76ee\u7684\u662f\u51cf\u5c11 \\(C-B \\cup B^{g t}\\) \u7684\u9762\u79ef\u3002","title":"DIoU loss"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#diou-iougiou","text":"\u65b0\u63d0\u51fa\u7684DIoU\u635f\u5931\u7ee7\u627fIoU\u548cGIoU\u635f\u5931\u7684\u4e00\u4e9b\u5c5e\u6027 DIoU\u635f\u5931\u5bf9\u56de\u5f52\u95ee\u9898\u7684\u5c3a\u5ea6\u4ecd\u7136\u662f\u4e0d\u53d8\u7684 \u4e0eGIoU\u635f\u5931\u7c7b\u4f3c, DIoU\u635f\u5931\u53ef\u4ee5\u5728\u4e0e\u76ee\u6807\u6846\u4e0d\u91cd\u53e0\u65f6\u4e3a\u8fb9\u754c\u6846\u63d0\u4f9b\u79fb\u52a8\u65b9\u5411\u3002 \u5f53\u4e24\u4e2a\u8fb9\u754c\u6846\u5b8c\u7f8e\u5339\u914d\u65f6, \\(\\mathcal{L}_{I o U}=\\mathcal{L}_{G I o U}=\\mathcal{L}_{D I o U}=0 .\\) \u5f53\u4e24\u4e2a\u6846\u90fd\u5f88\u8fdc\u65f6, \\(\\mathcal{L}_{G I o U}=\\mathcal{L}_{D I o U} \\rightarrow 2 .\\) DIoU\u635f\u5931\u6bd4IoU\u635f\u5931\u548cGIoU\u635f\u5931\u6709\u51e0\u4e2a\u4f18\u70b9, \u53ef\u4ee5\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u8fdb\u884c\u8bc4\u4f30\u3002 1. \u5982\u56fe1\u548c\u56fe3\u6240\u793a, \\(DIoU\u635f\u5931\\) \u53ef\u4ee5\u76f4\u63a5\u6700\u5c0f\u5316\u4e24\u4e2a\u6846\u7684\u8ddd\u79bb, \u56e0\u6b64\u6536\u655b\u901f\u5ea6\u6bd4 \\(GIoU\u635f\u5931\\) \u8981\u5feb\u5f97\u591a\u3002 2. \u5bf9\u4e8e\u4e24\u4e2a\u6846\u662f\u5305\u542b\u5173\u7cfb\u7684\u60c5\u51b5(\u56fe2), \u6216\u5728\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u60c5\u51b5(\u56fe6)\u4e0b, \\(DIoU\u635f\u77e2\\) \u53ef\u4ee5\u56de\u5f52\u975e\u5e38\u5feb, \u800c \\(\\mathrm{GIoU}\\) \u635f\u5931\u51e0\u4e4e\u9000\u5316\u4e3a \\(\\mathrm{IoU}\u635f\u5931\\) , \u5373 \\(|C-A \\cup B| \\rightarrow 0 .\\)","title":"DIoU \u548c IoU/GIoU \u635f\u5931\u6bd4\u8f83"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#complete-iou-loss","text":"\u63a5\u7740\u6211\u4eec\u56de\u7b54\u4e86\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u8fb9\u754c\u6846\u56de\u5f52\u7684\u826f\u597d \u635f\u5931\u5e94\u8be5\u8981\u8003\u8651\u4e09\u4e2a\u91cd\u8981\u7684\u51e0\u4f55\u56e0\u7d20, \u5373 \u91cd\u53e0\u9762\u79ef\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u548c\u957f\u5bbd\u6bd4 \u3002\u901a\u8fc7\u7edf\u4e00\u5750\u6807, \\(IoU\u635f\u5931\\) \u8003\u8651\u4e86\u91cd\u53e0\u533a\u57df, \u800c \\(GIoU\u635f\u5931\\) \u4e25\u91cd\u4f9d\u8d56\u4e8e \\(IoU\u635f\u5931\\) \u3002\u6211\u4eec\u63d0\u51fa\u7684 \\(DIoU\u635f\u5931\\) \u65e8\u5728\u540c\u65f6\u8003\u8651\u8fb9\u754c\u6846\u7684\u91cd\u53e0\u9762\u79ef\u548c\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u3002\u7136\u800c, \u8fb9\u754c\u6846\u7684\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u4e5f\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u51e0\u4f55\u56e0\u7d20\u3002 \u56e0\u6b64\uff0c\u57fa\u4e8e \\(DIoU\u635f\u5931\\) \uff0c\u901a\u8fc7\u6dfb\u52a0\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u6765 \u63d0\u51fa \\(CIoU\u635f\u5931\\) : \\(\\large\\mathcal{R}_{C I o U}=\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v,\\) (8) \u5176\u4e2d \\(\\alpha\\) \u662f\u4e00\u4e2a\u6b63\u7684\u6743\u8861\u53c2\u6570, \\(v\\) \u8861\u91cf\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u3002 \\(\\large{v=\\frac{4}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right)^{2} .}\\) (9) \u5219\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a: \\(\\large\\mathcal{L}_{C I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v\\) (10) \\(\\large\\alpha=\\frac{v}{(1-I o U)+v}\\) (11) \u901a\u8fc7\u91cd\u53e0\u9762\u79ef\u56e0\u5b50\u7ed9\u4e88\u66f4\u9ad8\u7684\u4f18\u5148\u56de\u5f52, \u7279\u522b\u662f\u5bf9\u4e8e\u975e\u91cd\u53e0\u60c5\u51b5\u3002 \u6700\u7ec8, \\(CIoU\u635f\u5931\\) \u7684\u4f18\u5316\u4e0e \\(DIoU\u635f\u5931\\) \u7684\u4f18\u5316\u76f8\u540c, \u9664 \u4e86 \\(v w.r.t. w\\) \u7684\u68af\u5ea6\u5e94\u8be5\u6307\u5b9a \\(\\mathrm{w}\\) \u548c \\(h\\) \u3002 \\(\\large\\begin{array}{l} \\frac{\\partial v}{\\partial w}=\\frac{8}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right) \\times \\frac{h}{w^{2}+h^{2}}, \\\\ \\frac{\\partial v}{\\partial h}=-\\frac{8}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right) \\times \\frac{w}{w^{2}+h^{2}} . \\end{array}\\) (12) \u4e3b\u5bfc\u5668 \\(w^{2}+h^{2}\\) \u901a\u5e38\u662f\u4e00\u4e2a\u5f88\u5c0f\u7684\u503c\u5bf9\u4e8e \\(h\\) \u548c \\(w\\) \u7684\u8303 \u56f4\u5728 [0,1] , \u8fd9\u5f88\u53ef\u80fd\u4f1a\u4ea7\u751f\u68af\u5ea6\u7206\u70b8\u3002\u56e0\u6b64\u5728\u6211\u4eec\u7684\u5b9e\u73b0, \u4e3b\u5bfc\u5668 \\(w^{2}+h^{2}\\) \u88ab\u79fb\u9664, \u5c06\u6b65\u957f \\(\\frac{1} {w^{2}+h^{2}}\\) \u66ff\u6362\u4e3a \\(1\\) , \u68af\u5ea6\u65b9\u5411\u4ecd\u7136\u4e0e\u516c\u5f0f(12)\u4e00\u81f4\u3002","title":"Complete IoU Loss"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#nmsnon-maximum-suppression","text":"","title":"NMS(Non-Maximum Suppression)"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_4","text":"NMS\u662f\u5927\u591a\u6570\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u6700\u540e\u4e00\u6b65\uff0c\u5176\u4e2d\u5220\u9664\u4e86\u5197\u4f59\u7684\u68c0\u6d4b\u6846\u5f53\u5b83\u4e0e\u6700\u9ad8\u5206\u6846\u7684\u91cd\u53e0\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c\u3002 Soft-NMS (Bodla et al. 2017) \u7528\u8fde\u7eed\u51fd\u6570w.r.t.\u60e9\u7f5a\u76f8\u90bb\u6846\u7684\u68c0\u6d4b\u5206\u6570IoU\uff0c\u4ea7\u751f\u6bd4\u539f\u59cbNMS\u4ea7\u751f\u66f4\u67d4\u548c\u5927\u548c\u66f4\u5f3a\u5927\u7684\u6291\u5236\u3002IoU-Net (Jiang et al. 2018) \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u7f51\u7edc\u5206\u652f\u6765\u9884\u6d4b\u5b9a\u4f4d\u7f6e\u4fe1\u5ea6\u6765\u6307\u5bfcNMS\u3002\u6700\u8fd1\uff0c\u81ea\u9002\u5e94NMS\uff08Liu\uff0cHuang\uff0c\u548cWang 2019\uff09\u548cSofter-NMS\uff08He et al. 2019\uff09\u88ab\u63d0\u51fa\u5206\u522b\u7814\u7a76\u9002\u5f53\u7684\u9608\u503c\u7b56\u7565\u548c\u52a0\u6743\u5e73\u5747\u7b56\u7565\u3002 \u5728\u672c\u5de5\u4f5c\u4e2d\uff0c\u7b80\u5355\u5c06DIoU\u4f5c\u4e3a\u539f\u59cbNMS\u7684\u6807\u51c6, \u5728\u6291\u5236\u5197\u4f59\u6846\u65f6\uff0c\u540c\u65f6\u8003\u8651\u8fb9\u754c\u6846\u7684\u91cd\u53e0\u9762\u79ef\u548c\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002","title":"\u4ecb\u7ecd"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#diou-nms","text":"Non-Maximum Suppression using DIoU \u5728\u539f\u59cb\u7684NMS\u4e2d, IoU\u6307\u6807\u7528\u4e8e\u6291\u5236\u5415\u4f59\u7684\u68c0\u6d4b\u6846, \u5176 \u4e2d\u91cd\u53e0\u533a\u57df\u662f\u552f\u4e00\u7684\u56e0\u7d20, \u5bf9\u4e8e\u6709\u906e\u6321\u7684\u60c5\u51b5\uff0c\u5f80\u5f80\u4f1a \u4ea7\u751f\u9519\u8bef\u7684\u6291\u5236\u3002 \u6211\u4eec\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\u5efa\u8bae \\(DIoU\\) \u662f \\(NMS\\) \u7684\u66f4\u597d\u6807\u51c6\uff0c\u56e0\u4e3a\u5728\u6291\u5236\u6807\u51c6\u4e2d\u4e0d\u4ec5\u5e94\u8003\u8651\u91cd\u53e0 \\(DIoU-NMS\\) \u88ab\u6b63\u5f0f\u5b9a\u4e49\u4e3a: \\(s_{i}=\\left\\{\\begin{array}{l} s_{i}, I o U-\\mathcal{R}_{D I o U}\\left(\\mathcal{M}, B_{i}\\right)<\\varepsilon, \\\\ 0, \\quad I o U-\\mathcal{R}_{D I o U}\\left(\\mathcal{M}, B_{i}\\right) \\geq \\varepsilon, \\end{array}\\right.\\) (13) \u5176\u4e2d\u6846 \\(B_{i}\\) \u88ab\u53bb\u9664\u901a\u8fc7\u540c\u65f6\u5230\u8003\u8651 \\(IoU\\) \u548c\u4e24\u4e2a\u6846\u4e2d\u5fc3\u70b9 \u7684\u8ddd\u79bb\u3002 \\(s_{i}\\) \u662f\u5206\u7c7b\u5f97\u5206\u548c \\(\\varepsilon\\) \u662f \\(NMS\\) \u9608\u503c\u3002\u6211\u4eec\u8ba4\u4e3a\u4e24 \u4e2a\u4e2d\u5fc3\u70b9\u8f83\u8fdc\u7684\u6846\u53ef\u80fd\u4f1a\u5b9a\u4f4d\u4e0d\u540c\u7684\u7269\u4f53, \u800c\u4e0d\u5e94\u8be5\u88ab \u5220\u9664\u3002\u6b64\u5916 \\(DIoU-NMS\\) \u662f\u975e\u5e38\u7075\u6d3b, \u4ec5\u4ec5\u662f\u51e0\u884c\u7684\u4ee3\u7801\u5c31\u53ef\u4ee5\u96c6\u6210\u5230\u4efb\u4f55\u76ee\u6807\u68c0\u6d4b\u7ba1\u9053\u4e2d\u3002","title":"DioU-NMS"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_5","text":"\u5728\u672c\u6587\u4e2d\uff0c\u4e3b\u8981\u7684\u4ecb\u7ecd\u7528\u4e8e\u8fb9\u754c\u6846\u56de\u5f52\u7684 \\(DIoU\u635f\u5931\\) \u548c \\(CIoU \u635f\u5931\\) \u548c \u7528\u4e8e\u6291\u5236\u5197\u4f59\u68c0\u6d4b\u6846\u7684 \\(DIoU-NMS\u3002\\) \u901a\u8fc7\u76f4\u63a5\u6700\u5c0f\u5316\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u7684\u5f52\u4e00\u5316\u7684\u8ddd\u79bb\uff0c \\(DIoU \u635f\u5931\\) \u53ef\u4ee5\u6bd4 \\(GIoU \u635f\u5931\\) \u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u3002 \u6b64\u5916 \\(CIoU\u635f\u5931\\) \u8003\u8651\u4e86\u4e09\u4e2a\u51e0\u4f55\u5c5e\u6027(\u5373 \u91cd\u53e0\u533a\u57df\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb \u548c \u957f\u5bbd\u6bd4),\u4fc3\u8fdb\u4e86 \u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u4f18\u7684\u6027\u80fd\u3002","title":"\u5c0f\u7ed3"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_6","text":"https://github.com/Zzh-tju/DIoU/blob/master/README.md#introduction https://github.com/Zzh-tju/DIoU/blob/master/README.md#introduction IoU: https://arxiv.org/pdf/1608.01471.pdf GIoU: https://giou.stanford.edu/GIoU.pdf DIoU: https://arxiv.org/pdf/1911.08287.pdf","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/05_chapter/map_analysis.html","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6307\u6807\u8bc4\u4f30(\u91cd\u8981\u7684\u4e00\u4e9b\u5b9a\u4e49) \ud83d\udcda IOU \\(IOU\\) ( Intersection Over Union ) \u57fa\u4e8e Jaccard \u7d22\u5f15\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e24\u4e2a\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u91cd\u53e0\u7a0b\u5ea6\u3002\u5b83\u9700\u8981\u4e00\u4e2a\u771f\u5b9e\u56de\u5f52\u6846 (a ground truth bounding box) \\(B_{gt}\\) \u548c\u4e00\u4e2a\u9884\u6d4b\u56de\u5f52\u6846(a predicted bounding box) \\(B_{p}\\) \u8ba1\u7b97\u5f97\u5230\u3002\u901a\u8fc7\u5e94\u7528 IOU \u6211\u4eec\u80fd\u591f\u5224\u65ad\u51fa\u9884\u6d4b\u7ed3\u679c\u662f\u6709\u6548(True Positive) \u6216\u8005 \u65e0\u6548(False Positive) \\(IOU\\) \u4e5f\u79f0\u91cd\u53e0\u5ea6 \u8868\u793a\u8ba1\u7b97\u9884\u6d4b\u56de\u5f52\u6846\u548c\u771f\u5b9e\u56de\u5f52\u6846\u7684\u4ea4\u5e76\u6bd4,\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b: \\(\\large{IOU=\\dfrac{area\\left( B_p\\cap B_{g t}\\right) }{area\\left( B_p\\cup B_{g t}\\right) } }\\) \u5176\u4e2d: \\(B_p:\u9884\u6d4b\u56de\u5f52\u6846\\) \uff0c \\(B_{g t}:\u771f\u5b9e\u56de\u5f52\u6846\\) \u4e0b\u56fe\u53ef\u89c6\u5316\u4e86\u771f\u5b9e\u56de\u5f52\u6846\uff08\u7eff\u8272\uff09\u548c \u9884\u6d4b\u56de\u5f52\u6846\uff08\u7ea2\u8272\uff09\u4e4b\u95f4\u7684IOU\u3002 \u56fe1.1 ; \\(IOU\\) \u7684\u8ba1\u7b97\u3002\u7eff\u8272: \\(B_{g t}\\) \uff0c \u7ea2\u8272: \\(B_{p}\\) TP&FP&FN&TN Positive Negative True TP TN False FP FN \u6307\u6807\u7684\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\uff1a TP\uff08True Postives\uff09\uff1a \u5206\u7c7b\u5668\u628a\u6b63\u4f8b\u6b63\u786e\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u6b63\u4f8b\u3002(IOU >= \u9608\u503c ) FN\uff08False Negatives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u6b63\u4f8b\u9519\u8bef\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u8d1f\u4f8b\u3002(IOU < \u9608\u503c ) FP\uff08False Postives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u8d1f\u4f8b\u9519\u8bef\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u6b63\u4f8b TN\uff08True Negatives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u8d1f\u4f8b\u6b63\u786e\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u8d1f\u4f8b\uff08 yolov5\u4e2d\u6ca1\u6709\u5e94\u7528\u5230 \uff09 yolov5\u4e2d\u6ca1\u6709\u5e94\u7528TN\u7684\u539f\u56e0: TN\u4ee3\u8868\u7684\u662f\u6240\u6709\u53ef\u80fd\u7684\u672a\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\u3002\u7136\u800c\u5728yolo\u5728\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u6bcf\u4e2a\u7f51\u683c\u4f1a\u751f\u6210\u5f88\u591a\u7684\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u6709\u8bb8\u591a\u7684\u9884\u6d4b\u8fb9\u754c\u6846\u662f\u6ca1\u6709\u76f8\u5e94\u7684\u771f\u5b9e\u6807\u7b7e\u6846\uff0c\u5bfc\u81f4\u672a\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\u6570\u91cf\u8fdc\u8fdc\u5927\u4e8e\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\uff0c\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u4e0d\u4f7f\u7528TN\u7684\u539f\u56e0\u3002 threshold: depending on the metric, it is usually set to 50%, 75% or 95%. Precision Precision \u5b9a\u4e49\uff1a\u6a21\u578b\u8bc6\u522b\u76f8\u5173\u76ee\u6807\u7684\u80fd\u529b\u3002\u5206\u7c7b\u6b63\u786e\u7684\u6837\u672c\u5728\u6240\u6709\u6837\u672c\u4e2d\u7684\u6570\u91cf\u6bd4\u4f8b\uff0c\u516c\u5f0f\u5982\u4e0b: \\(Precision =\\dfrac{TP}{TP+FP}=\\dfrac{TP}{all \\ detections}\\) Recall Recall \u5b9a\u4e49\uff1a\u662f\u6a21\u578b\u627e\u5230\u771f\u5b9e\u56de\u5f52\u6846( \u5373\u6807\u7b7e\u6807\u6ce8\u7684\u6846 )\u7684\u80fd\u529b\u3002\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a \\(Recall = \\dfrac{TP}{TP+FN}=\\dfrac{TP}{all \\ ground \\ truths}\\) mAP \u591a\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u56fe\u7247\u7684\u6807\u7b7e\u4e0d\u6b62\u4e00\u4e2a\uff0c\u56e0\u6b64\u8bc4\u4ef7\u4e0d\u80fd\u7528\u666e\u901a\u5355\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\u7684\u6807\u51c6\uff0c\u5373mean accuracy\uff0c\u8be5\u4efb\u52a1\u91c7\u7528\u7684\u662f\u548c\u4fe1\u606f\u68c0\u7d22\u4e2d\u7c7b\u4f3c\u7684\u65b9\u6cd5\u2014mAP\uff0c\u867d\u7136\u5176\u5b57\u9762\u610f\u601d\u548cmean average precision\u770b\u8d77\u6765\u5dee\u4e0d\u591a\uff0c\u4f46\u662f\u8ba1\u7b97\u65b9\u6cd5\u8981\u7e41\u7410\u5f97\u591a,mAP \u4f1a\u7edf\u8ba1\u6240\u6709 Confidence \u503c\u4e0b\u7684 PR\u503c\uff0c\u800c\u5b9e\u9645\u4f7f\u7528\u65f6\uff0c \u4f1a\u8bbe\u5b9a\u4e00\u4e2a Confidence \u9608\u503c\uff0c\u4f4e\u4e8e\u8be5\u9608\u503c\u7684\u76ee\u6807\u4f1a\u88ab\u4e22\u5f03\uff0c\u8fd9\u90e8\u5206\u76ee\u6807\u5728\u7edf\u8ba1 mAP \u65f6\u4e5f\u4f1a\u6709\u4e00\u5b9a\u7684\u8d21\u732e \u3002 Confidence (\u7f6e\u4fe1\u5ea6):\u5728\u7edf\u8ba1\u5b66\u4e2d\uff0c\u4e00\u4e2a\u6982\u7387\u6837\u672c\u7684\u7f6e\u4fe1\u533a\u95f4\uff08Confidence interval\uff09\u662f\u5bf9\u8fd9\u4e2a\u6837\u672c\u7684\u67d0\u4e2a\u603b\u4f53\u53c2\u6570\u7684\u533a\u95f4\u4f30\u8ba1\u3002\u7f6e\u4fe1\u533a\u95f4\u5c55\u73b0\u7684\u662f\u8fd9\u4e2a\u53c2\u6570\u7684\u771f\u5b9e\u503c\u6709\u4e00\u5b9a\u6982\u7387\u843d\u5728\u6d4b\u91cf\u7ed3\u679c\u7684\u5468\u56f4\u7684\u7a0b\u5ea6\u3002\u7f6e\u4fe1\u533a\u95f4\u7ed9\u51fa\u7684\u662f\u88ab\u6d4b\u91cf\u53c2\u6570\u6d4b\u91cf\u503c\u7684\u53ef\u4fe1\u7a0b\u5ea6\u8303\u56f4\uff0c\u5373\u524d\u9762\u6240\u8981\u6c42\u7684\u201c\u4e00\u5b9a\u6982\u7387\u201d\u3002\u8fd9\u4e2a\u6982\u7387\u4e5f\u88ab\u79f0\u4e3a\u7f6e\u4fe1\u6c34\u5e73\u3002 (\u7ea2\u8272\u66f2\u7ebf\u4ee3\u8868,\u4eba\u4e3a\u7684\u65b9\u5f0f\u5c06PR\u66f2\u7ebf\u53d8\u6210\u5355\u8c03\u9012\u51cf\uff0c\u4f7f\u5f97\u8ba1\u7b97\u9762\u79ef\u66f4\u5bb9\u6613\u3002) AP\uff08Average Percision\uff09\uff1aAP\u4e3a\u5e73\u5747\u7cbe\u5ea6\uff0c\u6307\u7684\u662f\u6240\u6709\u56fe\u7247\u5185\u7684\u5177\u4f53\u67d0\u4e00\u7c7b\u7684PR\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef(\u6a2a\u8f74\u4e3aRecall\uff0c\u7eb5\u8f74\u4e3aPrecision)\u3002 AP\u8861\u91cf\u7684\u662f\u5bf9\u4e00\u4e2a\u7c7b\u68c0\u6d4b\u597d\u574f\uff0cmAP\u5c31\u662f\u5bf9\u591a\u4e2a\u7c7b\u7684\u68c0\u6d4b\u597d\u574f\u3002\u5728\u591a\u7c7b\u591a\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u8ba1\u7b97\u51fa\u6bcf\u4e2a\u7c7b\u522b\u7684AP\u540e\uff0c\u518d\u9664\u4e8e\u7c7b\u522b\u603b\u6570\uff0c\u5373\u6240\u6709\u7c7b\u522bAP\u7684\u5e73\u5747\u503c\uff0c\u6bd4\u5982\u6709\u4e24\u7c7b\uff0c\u7c7bA\u7684AP\u503c\u662f0.5\uff0c\u7c7bB\u7684AP\u503c\u662f0.2\uff0c\u90a3\u4e48 \\(mAP\\) =\uff080.5+0.2\uff09/2=0.35\u3002 MAP: \u662f\u6307\u6240\u6709\u56fe\u7247\u5185\u7684\u6240\u6709\u7c7b\u522b\u7684AP\u7684\u5e73\u5747\u503c ,map\u8d8a\u9ad8\u4ee3\u8868\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u503c\u8d8a\u9ad8\u3002 \\(mAP@0.5\\) \uff1a \\(mAP\\) \u662f\u7528 \\(Precision\\) \u548c \\(Recall\\) \u4f5c\u4e3a\u4e24\u8f74\u4f5c\u56fe\u540e\u56f4\u6210\u7684\u9762\u79ef\uff0c \\(m\\) \u8868\u793a\u5e73\u5747\uff0c@\u540e\u9762\u7684\u6570\u8868\u793a\u5224\u5b9a\u6b63\u8d1f\u6837\u672c\u7684 \\(IOU\\) \u9608\u503c\uff0c\u5176\u4e2d @0.5\u8868\u793aIOU\u9608\u503c\u53d60.5\u3002 \\(mAP@0.5:0.95\\) \uff1a\u53ea\u4ee5 \\(IOU=0.5\\) \u7684\u9600\u503c\u7684\u65f6\u5019\u4e0d\u4e00\u5b9a\u5c31\u662f\u597d\u7684\u6a21\u578b\uff0c\u53ef\u80fd\u4ec5\u4ec5\u57280.5\u9600\u503c\u8868\u73b0\u7684\u5f88\u597d\uff0c\u57280.6,0.7...\u9600\u503c\u8868\u73b0\u7684\u5f88\u5dee\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u8bc4\u4f30\u6574\u4f53\u6a21\u578b\u7684\u51c6\u786e\u5ea6\uff0c\u56e0\u6b64\u8ba1\u7b97\u4e00\u4e2a\u6a21\u578b\u5728\u5404\u4e2aIOU\u503c\u7684AP(mAP)\u53d6\u5e73\u5747\u503c\u3002 \u65b9\u6cd5\u662f\uff1a\u8ba1\u7b97\u6bcf\u4e2a\u5206\u7c7b\u7684AP\uff0c\u6c42\u548c\u518d\u5e73\u5747\uff0c\u5f97\u5230\u7684\u5c31\u662fmAP,\u5b83\u662f\u76f4\u63a5\u628amAP\u5f53\u6210AP\uff0c\u7136\u540e\u518d\u628aIOU\u503c\u5927\u4e8e0.5\u7684 \\(AP(mAP)\\) \uff0c\u4ee50.05\u7684\u589e\u91cf,\u52300.95\uff0c\u4e5f\u5c31\u662f\u4ee5 \\((0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)\\) \\(IOU\u503c\\) \u7684 \\(AP(mAP)\\) \u7684\u5e73\u5747\u503c\u5f53\u6210 \\(AP(at IoU=.50:.05:.95)\\) \uff0c\u901a\u8fc7 \\(IOU\u589e\u91cf\\) \u7684\u65b9\u5f0f\u5f97\u5230 \\(mAP@0.5:0.95\\) \u7ed3\u679c\u3002 \u76ee\u6807\u68c0\u6d4b\u4e2d\u7684mAP\u8ba1\u7b97 yolov5\u8ba1\u7b97IOU\u6e90\u7801\u89e3\u6790 \u6e90\u4ee3\u7801\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L224-L261 # \u8ba1\u7b97\u4e24\u6846\u7684\u7279\u5b9aiou (DIou, DIou, CIou) def bbox_iou ( box1 , box2 , xywh = True , GIoU = False , DIoU = False , CIoU = False , eps = 1e-7 ): # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4) # Get the coordinates of bounding boxes \u4e0b\u9762\u6761\u4ef6\u8bed\u53e5\u4f5c\u7528\u662f:\u8fdb\u884c\u5750\u6807\u8f6c\u6362\u4ece\u800c\u83b7\u53d6yolo\u683c\u5f0f\u8fb9\u754c\u6846\u7684\u5750\u6807 if xywh : # transform from xywh to xyxy ( x1 , y1 , w1 , h1 ), ( x2 , y2 , w2 , h2 ) = box1 . chunk ( 4 , 1 ), box2 . chunk ( 4 , 1 ) w1_ , h1_ , w2_ , h2_ = w1 / 2 , h1 / 2 , w2 / 2 , h2 / 2 b1_x1 , b1_x2 , b1_y1 , b1_y2 = x1 - w1_ , x1 + w1_ , y1 - h1_ , y1 + h1_ b2_x1 , b2_x2 , b2_y1 , b2_y2 = x2 - w2_ , x2 + w2_ , y2 - h2_ , y2 + h2_ else : # x1, y1, x2, y2 = box1 b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 . chunk ( 4 , 1 ) b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 . chunk ( 4 , 1 ) w1 , h1 = b1_x2 - b1_x1 , b1_y2 - b1_y1 w2 , h2 = b2_x2 - b2_x1 , b2_y2 - b2_y1 # Intersection area \u83b7\u53d6\u4e24\u4e2a\u6846\u76f8\u4ea4\u7684\u9762\u79ef\u3002 \"\"\" left_line = max(b1_x1, b2_x1) reft_line = min(b1_x2, b2_x2) top_line = max(b1_y1, b2_y1) bottom_line = min(b1_y2, b2_y2) intersect = (reight_line - left_line) * (bottom_line - top_line) \"\"\" inter = ( torch . min ( b1_x2 , b2_x2 ) - torch . max ( b1_x1 , b2_x1 )) . clamp ( 0 ) * \\ ( torch . min ( b1_y2 , b2_y2 ) - torch . max ( b1_y1 , b2_y1 )) . clamp ( 0 ) # Union Area \u4e24\u4e2a\u6846\u5e76\u5230\u9762\u79ef union = w1 * h1 + w2 * h2 - inter + eps # IoU iou = inter / union if CIoU or DIoU or GIoU : cw = torch . max ( b1_x2 , b2_x2 ) - torch . min ( b1_x1 , b2_x1 ) # convex (smallest enclosing box) width ch = torch . max ( b1_y2 , b2_y2 ) - torch . min ( b1_y1 , b2_y1 ) # convex height if CIoU or DIoU : # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1 c2 = cw ** 2 + ch ** 2 + eps # convex diagonal squared rho2 = (( b2_x1 + b2_x2 - b1_x1 - b1_x2 ) ** 2 + ( b2_y1 + b2_y2 - b1_y1 - b1_y2 ) ** 2 ) / 4 # center dist ** 2 if CIoU : # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47 v = ( 4 / math . pi ** 2 ) * torch . pow ( torch . atan ( w2 / ( h2 + eps )) - torch . atan ( w1 / ( h1 + eps )), 2 ) with torch . no_grad (): alpha = v / ( v - iou + ( 1 + eps )) return iou - ( rho2 / c2 + v * alpha ) # CIoU return iou - rho2 / c2 # DIoU c_area = cw * ch + eps # convex area return iou - ( c_area - union ) / c_area # GIoU https://arxiv.org/pdf/1902.09630.pdf return iou # IoU yolov5\u8ba1\u7b97AP\u6e90\u7801\u9010\u884c\u89e3\u6790 \u6e90\u4ee3\u7801\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L96-L121 # \u6839\u636ePR\u66f2\u7ebf\u8ba1\u7b97AP def compute_ap ( recall , precision ): \"\"\" Compute the average precision, given the recall and precision curves # Arguments recall: The recall curve (list) precision: The precision curve (list) # Returns Average precision, precision curve, recall curve \"\"\" # Append sentinel values to beginning and end \u5c06\u5f00\u533a\u95f4\u7ed9\u8865\u4e0a\uff0c\u8865\u6210\u95ed\u5408\u7684\u533a\u95f4\u3002 mrec = np . concatenate (([ 0.0 ], recall , [ 1.0 ])) mpre = np . concatenate (([ 1.0 ], precision , [ 0.0 ])) # Compute the precision envelope \"\"\" \u4eba\u4e3a\u7684\u628aPR\u66f2\u7ebf\u53d8\u6210\u5355\u8c03\u9012\u51cf\u7684,\u4f8b\u5982: np.maximum(accumulate(np.array([21, 23, 18, 19, 20, 13, 12, 11]) ) => np.array([23, 23, 20, 20, 20, 13, 12, 11]) \"\"\" mpre = np . flip ( np . maximum . accumulate ( np . flip ( mpre ))) # Integrate area under curve method = 'interp' # methods: 'continuous', 'interp' if method == 'interp' : # \u9ed8\u8ba4\u91c7\u7528 interpolated-precision \u66f2\u7ebf\uff0c x = np . linspace ( 0 , 1 , 101 ) # 101-point interp (COCO) ap = np . trapz ( np . interp ( x , mrec , mpre ), x ) # integrate else : # 'continuous' i = np . where ( mrec [ 1 :] != mrec [: - 1 ])[ 0 ] # points where x axis (recall) changes ap = np . sum (( mrec [ i + 1 ] - mrec [ i ]) * mpre [ i + 1 ]) # area under curve return ap , mpre , mrec \u53c2\u8003\u6587\u7ae0 https://github.com/rafaelpadilla/Object-Detection-Metrics","title":"5.3 \u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30"},{"location":"tutorials/05_chapter/map_analysis.html#_1","text":"","title":"\u6307\u6807\u8bc4\u4f30(\u91cd\u8981\u7684\u4e00\u4e9b\u5b9a\u4e49)"},{"location":"tutorials/05_chapter/map_analysis.html#iou","text":"\\(IOU\\) ( Intersection Over Union ) \u57fa\u4e8e Jaccard \u7d22\u5f15\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e24\u4e2a\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u91cd\u53e0\u7a0b\u5ea6\u3002\u5b83\u9700\u8981\u4e00\u4e2a\u771f\u5b9e\u56de\u5f52\u6846 (a ground truth bounding box) \\(B_{gt}\\) \u548c\u4e00\u4e2a\u9884\u6d4b\u56de\u5f52\u6846(a predicted bounding box) \\(B_{p}\\) \u8ba1\u7b97\u5f97\u5230\u3002\u901a\u8fc7\u5e94\u7528 IOU \u6211\u4eec\u80fd\u591f\u5224\u65ad\u51fa\u9884\u6d4b\u7ed3\u679c\u662f\u6709\u6548(True Positive) \u6216\u8005 \u65e0\u6548(False Positive) \\(IOU\\) \u4e5f\u79f0\u91cd\u53e0\u5ea6 \u8868\u793a\u8ba1\u7b97\u9884\u6d4b\u56de\u5f52\u6846\u548c\u771f\u5b9e\u56de\u5f52\u6846\u7684\u4ea4\u5e76\u6bd4,\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b: \\(\\large{IOU=\\dfrac{area\\left( B_p\\cap B_{g t}\\right) }{area\\left( B_p\\cup B_{g t}\\right) } }\\) \u5176\u4e2d: \\(B_p:\u9884\u6d4b\u56de\u5f52\u6846\\) \uff0c \\(B_{g t}:\u771f\u5b9e\u56de\u5f52\u6846\\) \u4e0b\u56fe\u53ef\u89c6\u5316\u4e86\u771f\u5b9e\u56de\u5f52\u6846\uff08\u7eff\u8272\uff09\u548c \u9884\u6d4b\u56de\u5f52\u6846\uff08\u7ea2\u8272\uff09\u4e4b\u95f4\u7684IOU\u3002 \u56fe1.1 ; \\(IOU\\) \u7684\u8ba1\u7b97\u3002\u7eff\u8272: \\(B_{g t}\\) \uff0c \u7ea2\u8272: \\(B_{p}\\)","title":"\ud83d\udcda IOU"},{"location":"tutorials/05_chapter/map_analysis.html#tpfpfntn","text":"Positive Negative True TP TN False FP FN \u6307\u6807\u7684\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\uff1a TP\uff08True Postives\uff09\uff1a \u5206\u7c7b\u5668\u628a\u6b63\u4f8b\u6b63\u786e\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u6b63\u4f8b\u3002(IOU >= \u9608\u503c ) FN\uff08False Negatives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u6b63\u4f8b\u9519\u8bef\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u8d1f\u4f8b\u3002(IOU < \u9608\u503c ) FP\uff08False Postives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u8d1f\u4f8b\u9519\u8bef\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u6b63\u4f8b TN\uff08True Negatives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u8d1f\u4f8b\u6b63\u786e\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u8d1f\u4f8b\uff08 yolov5\u4e2d\u6ca1\u6709\u5e94\u7528\u5230 \uff09 yolov5\u4e2d\u6ca1\u6709\u5e94\u7528TN\u7684\u539f\u56e0: TN\u4ee3\u8868\u7684\u662f\u6240\u6709\u53ef\u80fd\u7684\u672a\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\u3002\u7136\u800c\u5728yolo\u5728\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u6bcf\u4e2a\u7f51\u683c\u4f1a\u751f\u6210\u5f88\u591a\u7684\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u6709\u8bb8\u591a\u7684\u9884\u6d4b\u8fb9\u754c\u6846\u662f\u6ca1\u6709\u76f8\u5e94\u7684\u771f\u5b9e\u6807\u7b7e\u6846\uff0c\u5bfc\u81f4\u672a\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\u6570\u91cf\u8fdc\u8fdc\u5927\u4e8e\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\uff0c\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u4e0d\u4f7f\u7528TN\u7684\u539f\u56e0\u3002 threshold: depending on the metric, it is usually set to 50%, 75% or 95%.","title":"TP&amp;FP&amp;FN&amp;TN"},{"location":"tutorials/05_chapter/map_analysis.html#precision","text":"Precision \u5b9a\u4e49\uff1a\u6a21\u578b\u8bc6\u522b\u76f8\u5173\u76ee\u6807\u7684\u80fd\u529b\u3002\u5206\u7c7b\u6b63\u786e\u7684\u6837\u672c\u5728\u6240\u6709\u6837\u672c\u4e2d\u7684\u6570\u91cf\u6bd4\u4f8b\uff0c\u516c\u5f0f\u5982\u4e0b: \\(Precision =\\dfrac{TP}{TP+FP}=\\dfrac{TP}{all \\ detections}\\)","title":"Precision"},{"location":"tutorials/05_chapter/map_analysis.html#recall","text":"Recall \u5b9a\u4e49\uff1a\u662f\u6a21\u578b\u627e\u5230\u771f\u5b9e\u56de\u5f52\u6846( \u5373\u6807\u7b7e\u6807\u6ce8\u7684\u6846 )\u7684\u80fd\u529b\u3002\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a \\(Recall = \\dfrac{TP}{TP+FN}=\\dfrac{TP}{all \\ ground \\ truths}\\)","title":"Recall"},{"location":"tutorials/05_chapter/map_analysis.html#map","text":"\u591a\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u56fe\u7247\u7684\u6807\u7b7e\u4e0d\u6b62\u4e00\u4e2a\uff0c\u56e0\u6b64\u8bc4\u4ef7\u4e0d\u80fd\u7528\u666e\u901a\u5355\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\u7684\u6807\u51c6\uff0c\u5373mean accuracy\uff0c\u8be5\u4efb\u52a1\u91c7\u7528\u7684\u662f\u548c\u4fe1\u606f\u68c0\u7d22\u4e2d\u7c7b\u4f3c\u7684\u65b9\u6cd5\u2014mAP\uff0c\u867d\u7136\u5176\u5b57\u9762\u610f\u601d\u548cmean average precision\u770b\u8d77\u6765\u5dee\u4e0d\u591a\uff0c\u4f46\u662f\u8ba1\u7b97\u65b9\u6cd5\u8981\u7e41\u7410\u5f97\u591a,mAP \u4f1a\u7edf\u8ba1\u6240\u6709 Confidence \u503c\u4e0b\u7684 PR\u503c\uff0c\u800c\u5b9e\u9645\u4f7f\u7528\u65f6\uff0c \u4f1a\u8bbe\u5b9a\u4e00\u4e2a Confidence \u9608\u503c\uff0c\u4f4e\u4e8e\u8be5\u9608\u503c\u7684\u76ee\u6807\u4f1a\u88ab\u4e22\u5f03\uff0c\u8fd9\u90e8\u5206\u76ee\u6807\u5728\u7edf\u8ba1 mAP \u65f6\u4e5f\u4f1a\u6709\u4e00\u5b9a\u7684\u8d21\u732e \u3002 Confidence (\u7f6e\u4fe1\u5ea6):\u5728\u7edf\u8ba1\u5b66\u4e2d\uff0c\u4e00\u4e2a\u6982\u7387\u6837\u672c\u7684\u7f6e\u4fe1\u533a\u95f4\uff08Confidence interval\uff09\u662f\u5bf9\u8fd9\u4e2a\u6837\u672c\u7684\u67d0\u4e2a\u603b\u4f53\u53c2\u6570\u7684\u533a\u95f4\u4f30\u8ba1\u3002\u7f6e\u4fe1\u533a\u95f4\u5c55\u73b0\u7684\u662f\u8fd9\u4e2a\u53c2\u6570\u7684\u771f\u5b9e\u503c\u6709\u4e00\u5b9a\u6982\u7387\u843d\u5728\u6d4b\u91cf\u7ed3\u679c\u7684\u5468\u56f4\u7684\u7a0b\u5ea6\u3002\u7f6e\u4fe1\u533a\u95f4\u7ed9\u51fa\u7684\u662f\u88ab\u6d4b\u91cf\u53c2\u6570\u6d4b\u91cf\u503c\u7684\u53ef\u4fe1\u7a0b\u5ea6\u8303\u56f4\uff0c\u5373\u524d\u9762\u6240\u8981\u6c42\u7684\u201c\u4e00\u5b9a\u6982\u7387\u201d\u3002\u8fd9\u4e2a\u6982\u7387\u4e5f\u88ab\u79f0\u4e3a\u7f6e\u4fe1\u6c34\u5e73\u3002 (\u7ea2\u8272\u66f2\u7ebf\u4ee3\u8868,\u4eba\u4e3a\u7684\u65b9\u5f0f\u5c06PR\u66f2\u7ebf\u53d8\u6210\u5355\u8c03\u9012\u51cf\uff0c\u4f7f\u5f97\u8ba1\u7b97\u9762\u79ef\u66f4\u5bb9\u6613\u3002) AP\uff08Average Percision\uff09\uff1aAP\u4e3a\u5e73\u5747\u7cbe\u5ea6\uff0c\u6307\u7684\u662f\u6240\u6709\u56fe\u7247\u5185\u7684\u5177\u4f53\u67d0\u4e00\u7c7b\u7684PR\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef(\u6a2a\u8f74\u4e3aRecall\uff0c\u7eb5\u8f74\u4e3aPrecision)\u3002 AP\u8861\u91cf\u7684\u662f\u5bf9\u4e00\u4e2a\u7c7b\u68c0\u6d4b\u597d\u574f\uff0cmAP\u5c31\u662f\u5bf9\u591a\u4e2a\u7c7b\u7684\u68c0\u6d4b\u597d\u574f\u3002\u5728\u591a\u7c7b\u591a\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u8ba1\u7b97\u51fa\u6bcf\u4e2a\u7c7b\u522b\u7684AP\u540e\uff0c\u518d\u9664\u4e8e\u7c7b\u522b\u603b\u6570\uff0c\u5373\u6240\u6709\u7c7b\u522bAP\u7684\u5e73\u5747\u503c\uff0c\u6bd4\u5982\u6709\u4e24\u7c7b\uff0c\u7c7bA\u7684AP\u503c\u662f0.5\uff0c\u7c7bB\u7684AP\u503c\u662f0.2\uff0c\u90a3\u4e48 \\(mAP\\) =\uff080.5+0.2\uff09/2=0.35\u3002 MAP: \u662f\u6307\u6240\u6709\u56fe\u7247\u5185\u7684\u6240\u6709\u7c7b\u522b\u7684AP\u7684\u5e73\u5747\u503c ,map\u8d8a\u9ad8\u4ee3\u8868\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u503c\u8d8a\u9ad8\u3002 \\(mAP@0.5\\) \uff1a \\(mAP\\) \u662f\u7528 \\(Precision\\) \u548c \\(Recall\\) \u4f5c\u4e3a\u4e24\u8f74\u4f5c\u56fe\u540e\u56f4\u6210\u7684\u9762\u79ef\uff0c \\(m\\) \u8868\u793a\u5e73\u5747\uff0c@\u540e\u9762\u7684\u6570\u8868\u793a\u5224\u5b9a\u6b63\u8d1f\u6837\u672c\u7684 \\(IOU\\) \u9608\u503c\uff0c\u5176\u4e2d @0.5\u8868\u793aIOU\u9608\u503c\u53d60.5\u3002 \\(mAP@0.5:0.95\\) \uff1a\u53ea\u4ee5 \\(IOU=0.5\\) \u7684\u9600\u503c\u7684\u65f6\u5019\u4e0d\u4e00\u5b9a\u5c31\u662f\u597d\u7684\u6a21\u578b\uff0c\u53ef\u80fd\u4ec5\u4ec5\u57280.5\u9600\u503c\u8868\u73b0\u7684\u5f88\u597d\uff0c\u57280.6,0.7...\u9600\u503c\u8868\u73b0\u7684\u5f88\u5dee\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u8bc4\u4f30\u6574\u4f53\u6a21\u578b\u7684\u51c6\u786e\u5ea6\uff0c\u56e0\u6b64\u8ba1\u7b97\u4e00\u4e2a\u6a21\u578b\u5728\u5404\u4e2aIOU\u503c\u7684AP(mAP)\u53d6\u5e73\u5747\u503c\u3002 \u65b9\u6cd5\u662f\uff1a\u8ba1\u7b97\u6bcf\u4e2a\u5206\u7c7b\u7684AP\uff0c\u6c42\u548c\u518d\u5e73\u5747\uff0c\u5f97\u5230\u7684\u5c31\u662fmAP,\u5b83\u662f\u76f4\u63a5\u628amAP\u5f53\u6210AP\uff0c\u7136\u540e\u518d\u628aIOU\u503c\u5927\u4e8e0.5\u7684 \\(AP(mAP)\\) \uff0c\u4ee50.05\u7684\u589e\u91cf,\u52300.95\uff0c\u4e5f\u5c31\u662f\u4ee5 \\((0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)\\) \\(IOU\u503c\\) \u7684 \\(AP(mAP)\\) \u7684\u5e73\u5747\u503c\u5f53\u6210 \\(AP(at IoU=.50:.05:.95)\\) \uff0c\u901a\u8fc7 \\(IOU\u589e\u91cf\\) \u7684\u65b9\u5f0f\u5f97\u5230 \\(mAP@0.5:0.95\\) \u7ed3\u679c\u3002","title":"mAP"},{"location":"tutorials/05_chapter/map_analysis.html#map_1","text":"","title":"\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684mAP\u8ba1\u7b97"},{"location":"tutorials/05_chapter/map_analysis.html#yolov5iou","text":"\u6e90\u4ee3\u7801\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L224-L261 # \u8ba1\u7b97\u4e24\u6846\u7684\u7279\u5b9aiou (DIou, DIou, CIou) def bbox_iou ( box1 , box2 , xywh = True , GIoU = False , DIoU = False , CIoU = False , eps = 1e-7 ): # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4) # Get the coordinates of bounding boxes \u4e0b\u9762\u6761\u4ef6\u8bed\u53e5\u4f5c\u7528\u662f:\u8fdb\u884c\u5750\u6807\u8f6c\u6362\u4ece\u800c\u83b7\u53d6yolo\u683c\u5f0f\u8fb9\u754c\u6846\u7684\u5750\u6807 if xywh : # transform from xywh to xyxy ( x1 , y1 , w1 , h1 ), ( x2 , y2 , w2 , h2 ) = box1 . chunk ( 4 , 1 ), box2 . chunk ( 4 , 1 ) w1_ , h1_ , w2_ , h2_ = w1 / 2 , h1 / 2 , w2 / 2 , h2 / 2 b1_x1 , b1_x2 , b1_y1 , b1_y2 = x1 - w1_ , x1 + w1_ , y1 - h1_ , y1 + h1_ b2_x1 , b2_x2 , b2_y1 , b2_y2 = x2 - w2_ , x2 + w2_ , y2 - h2_ , y2 + h2_ else : # x1, y1, x2, y2 = box1 b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 . chunk ( 4 , 1 ) b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 . chunk ( 4 , 1 ) w1 , h1 = b1_x2 - b1_x1 , b1_y2 - b1_y1 w2 , h2 = b2_x2 - b2_x1 , b2_y2 - b2_y1 # Intersection area \u83b7\u53d6\u4e24\u4e2a\u6846\u76f8\u4ea4\u7684\u9762\u79ef\u3002 \"\"\" left_line = max(b1_x1, b2_x1) reft_line = min(b1_x2, b2_x2) top_line = max(b1_y1, b2_y1) bottom_line = min(b1_y2, b2_y2) intersect = (reight_line - left_line) * (bottom_line - top_line) \"\"\" inter = ( torch . min ( b1_x2 , b2_x2 ) - torch . max ( b1_x1 , b2_x1 )) . clamp ( 0 ) * \\ ( torch . min ( b1_y2 , b2_y2 ) - torch . max ( b1_y1 , b2_y1 )) . clamp ( 0 ) # Union Area \u4e24\u4e2a\u6846\u5e76\u5230\u9762\u79ef union = w1 * h1 + w2 * h2 - inter + eps # IoU iou = inter / union if CIoU or DIoU or GIoU : cw = torch . max ( b1_x2 , b2_x2 ) - torch . min ( b1_x1 , b2_x1 ) # convex (smallest enclosing box) width ch = torch . max ( b1_y2 , b2_y2 ) - torch . min ( b1_y1 , b2_y1 ) # convex height if CIoU or DIoU : # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1 c2 = cw ** 2 + ch ** 2 + eps # convex diagonal squared rho2 = (( b2_x1 + b2_x2 - b1_x1 - b1_x2 ) ** 2 + ( b2_y1 + b2_y2 - b1_y1 - b1_y2 ) ** 2 ) / 4 # center dist ** 2 if CIoU : # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47 v = ( 4 / math . pi ** 2 ) * torch . pow ( torch . atan ( w2 / ( h2 + eps )) - torch . atan ( w1 / ( h1 + eps )), 2 ) with torch . no_grad (): alpha = v / ( v - iou + ( 1 + eps )) return iou - ( rho2 / c2 + v * alpha ) # CIoU return iou - rho2 / c2 # DIoU c_area = cw * ch + eps # convex area return iou - ( c_area - union ) / c_area # GIoU https://arxiv.org/pdf/1902.09630.pdf return iou # IoU","title":"yolov5\u8ba1\u7b97IOU\u6e90\u7801\u89e3\u6790"},{"location":"tutorials/05_chapter/map_analysis.html#yolov5ap","text":"\u6e90\u4ee3\u7801\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L96-L121 # \u6839\u636ePR\u66f2\u7ebf\u8ba1\u7b97AP def compute_ap ( recall , precision ): \"\"\" Compute the average precision, given the recall and precision curves # Arguments recall: The recall curve (list) precision: The precision curve (list) # Returns Average precision, precision curve, recall curve \"\"\" # Append sentinel values to beginning and end \u5c06\u5f00\u533a\u95f4\u7ed9\u8865\u4e0a\uff0c\u8865\u6210\u95ed\u5408\u7684\u533a\u95f4\u3002 mrec = np . concatenate (([ 0.0 ], recall , [ 1.0 ])) mpre = np . concatenate (([ 1.0 ], precision , [ 0.0 ])) # Compute the precision envelope \"\"\" \u4eba\u4e3a\u7684\u628aPR\u66f2\u7ebf\u53d8\u6210\u5355\u8c03\u9012\u51cf\u7684,\u4f8b\u5982: np.maximum(accumulate(np.array([21, 23, 18, 19, 20, 13, 12, 11]) ) => np.array([23, 23, 20, 20, 20, 13, 12, 11]) \"\"\" mpre = np . flip ( np . maximum . accumulate ( np . flip ( mpre ))) # Integrate area under curve method = 'interp' # methods: 'continuous', 'interp' if method == 'interp' : # \u9ed8\u8ba4\u91c7\u7528 interpolated-precision \u66f2\u7ebf\uff0c x = np . linspace ( 0 , 1 , 101 ) # 101-point interp (COCO) ap = np . trapz ( np . interp ( x , mrec , mpre ), x ) # integrate else : # 'continuous' i = np . where ( mrec [ 1 :] != mrec [: - 1 ])[ 0 ] # points where x axis (recall) changes ap = np . sum (( mrec [ i + 1 ] - mrec [ i ]) * mpre [ i + 1 ]) # area under curve return ap , mpre , mrec","title":"yolov5\u8ba1\u7b97AP\u6e90\u7801\u9010\u884c\u89e3\u6790"},{"location":"tutorials/05_chapter/map_analysis.html#_2","text":"https://github.com/rafaelpadilla/Object-Detection-Metrics","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/05_chapter/rectangular_reasoning.html","text":"\u77e9\u5f62\u63a8\u7406 \u4ecb\u7ecd \u5f53\u6211\u4eec\u628a\u4e00\u5e45\u56fe\u7247\u9001\u5165\u7f51\u7edc\uff0c\u8fd9\u5e45\u56fe\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e0e\u7f51\u7edc\u9700\u6c42\u7684\u4e0d\u4e00\u81f4\u7684\u65f6\u5019\uff0c\u6211\u4eec\u80af\u5b9a\u9700\u8981\u5bf9\u56fe\u7247\u505a\u51fa\u4e00\u4e9b\u6539\u53d8\u3002 \u4e00\u822c\u6765\u8bf4\u6709\u4e24\u79cd\u5e38\u7528\u7684\u9009\u62e9:(\u5047\u8bbe \u7f51\u7edc\u9700\u6c42\u7684\u56fe\u7247\u5927\u5c0f\u4e3a32\u7684\u500d\u6570,\u4f20\u5165\u7684\u56fe\u7247\u9ad8\u5bbd\u4e3a 200 x 416 ) 1. \u6b63\u65b9\u5f62\u63a8\u7406(square lnference) \u662f\u5c06\u56fe\u7247\u586b\u5145\u4e3a\u6b63\u65b9\u5f62,\u5982\u4e0b\u56fe\u5de6\u8fb9\u6240\u793a\u3002 2. \u77e9\u5f62\u63a8\u7406(Rectangular Inference) \u5982\u4e0b\u56fe\u53f3\u8fb9\u6240\u793a\u3002 \u5206\u6790: \u53ef\u4ee5\u770b\u5230\u4e0a\u56fe\u6b63\u65b9\u5f62\u63a8\u7406\u5b58\u5728\u5927\u91cf\u7684\u5197\u4f59\u90e8\u5206,\u800c\u53f3\u8fb9\u7684\u77e9\u5f62\u63a8\u7406\u660e\u663e\u5197\u4f59\u90e8\u5206\u5c11\u4e8e\u5de6\u8fb9\u5e76\u4e14\u5b9e\u9645\u8868\u73b0\u7684\u76f8\u6bd4\u6b63\u65b9\u5f62\u63a8\u7406\u80fd\u663e\u8457\u7684\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002 \u63a8\u7406\u8fc7\u7a0b\uff1a\u5c06\u8f83\u957f\u8fb9\u8bbe\u5b9a\u4e3a\u76ee\u6807\u5c3a\u5bf8 416,512\u2026 (\u5fc5\u987b\u662f32\u7684\u500d\u6570)\uff0c\u77ed\u8fb9\u6309\u6bd4\u4f8b\u7f29\u653e\uff0c\u518d\u5bf9\u77ed\u8fb9\u8fdb\u884c\u8f83\u5c11\u586b\u5145\u4f7f\u77ed\u8fb9\u6ee1\u8db332\u7684\u500d\u6570\uff0c\u8be6\u7ec6\u8fc7\u7a0b\u8be6\u89c1\u6e90\u7801\u89e3\u6790\u3002 \u62d3\u5c55 \u77e9\u5f62\u63a8\u7406\u6e90\u7801\u89e3\u6790 \u5bf9\u5e94\u4ed3\u5e93\u6587\u4ef6: https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/augmentations.py#L93-L131 # \u56fe\u7247\u7f29\u653e\uff1a\u4fdd\u6301\u56fe\u7247\u7684\u5bbd\u9ad8\u6bd4\u4f8b\uff0c\u5269\u4e0b\u7684\u90e8\u5206\u7528\u7070\u8272\u586b\u5145\u3002 def letterbox ( im , new_shape = ( 640 , 640 ), color = ( 114 , 114 , 114 ), auto = True , scaleFill = False , scaleup = True , stride = 32 ): \"\"\" \u5c06\u56fe\u7247\u7f29\u653e\u8c03\u6574\u5230\u6307\u5b9a\u5927\u5c0f @Param img: \u539f\u56fe @Param new_shape: \u7f29\u653e\u540e\u7684\u56fe\u7247\u5927\u5c0f @Param color: pad\u7684\u989c\u8272 @Param auto: True \u4fdd\u8bc1\u7f29\u653e\u540e\u7684\u56fe\u7247\u4fdd\u6301\u539f\u56fe\u7684\u6bd4\u4f8b \u5373 \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e\uff08\u4e0d\u4f1a\u5931\u771f\uff09 False \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e,\u6700\u540e\u5c06\u8f83\u77ed\u8fb9\u4e24\u8fb9pad\u64cd\u4f5c\u7f29\u653e\u5230\u6700\u957f\u8fb9\u5927\u5c0f\uff08\u4e0d\u4f1a\u5931\u771f\uff09 @Param scale_fill: True \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u539f\u56feresize\u5230\u6307\u5b9a\u7684\u5927\u5c0f \u76f8\u5f53\u4e8e\u5c31\u662fresize \u6ca1\u6709pad\u64cd\u4f5c\uff08\u5931\u771f\uff09 @Param scale_up: True \u5bf9\u4e8e\u5c0f\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5927\u4e8e\u7684\u4e0d\u53d8 False \u5bf9\u4e8e\u5927\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8e\u7684\u4e0d\u53d8 @return: img: letterbox\u540e\u7684\u56fe\u7247 ratio: wh ratios (dw, dh): w\u548ch\u7684pad \"\"\" # Resize and pad image while meeting stride-multiple constraints # \u53d6\u56fe\u7247\u7684\u9ad8\u5bbd shape = im . shape [: 2 ] # current shape [height, width] if isinstance ( new_shape , int ): new_shape = ( new_shape , new_shape ) # Scale ratio (new / old) \u8ba1\u7b97\u7f29\u653e\u56e0\u5b50 r = min ( new_shape [ 0 ] / shape [ 0 ], new_shape [ 1 ] / shape [ 1 ]) \"\"\" \u7f29\u653e(resize)\u5230\u8f93\u5165\u5927\u5c0fimg_size\u7684\u65f6\u5019,\u5982\u679c\u6ca1\u6709\u8bbe\u7f6e\u4e0a\u91c7\u6837\u7684\u8bdd,\u5219\u53ea\u8fdb\u884c\u4e0b\u91c7\u6837 \u56e0\u4e3a\u4e0a\u91c7\u6837\u56fe\u7247\u4f1a\u8ba9\u56fe\u7247\u6a21\u7cca,\u5bf9\u8bad\u7ec3\u4e0d\u53cb\u597d\u4e14\u5f71\u54cd\u6027\u80fd\u3002 \"\"\" if not scaleup : # only scale down, do not scale up (for better val mAP) r = min ( r , 1.0 ) # Compute padding \u8ba1\u7b97\u586b\u5145 ratio = r , r # width, height ratios # \u65b0\u7684\u672a\u586b\u5145\u5927\u5c0f, \u4fdd\u8bc1\u7f29\u653e\u540e\u56fe\u50cf\u6bd4\u4f8b\u4e0d\u53d8 new_unpad = int ( round ( shape [ 1 ] * r )), int ( round ( shape [ 0 ] * r )) dw , dh = new_shape [ 1 ] - new_unpad [ 0 ], new_shape [ 0 ] - new_unpad [ 1 ] # wh padding if auto : # minimum rectangle \u83b7\u53d6\u6700\u5c0f\u77e9\u5f62\u586b\u5145 # \u8fd9\u91cc\u7684\u53d6\u4f59\u64cd\u4f5c\u53ef\u4ee5\u4fdd\u8bc1padding\u540e\u7684\u56fe\u7247\u662f32\u7684\u6574\u6570\u500d(416x416)\uff0c\u5982\u679c\u662f(512x512)\u53ef\u4ee5\u4fdd\u8bc1\u662f64\u7684\u6574\u6570\u500d dw , dh = np . mod ( dw , stride ), np . mod ( dh , stride ) # wh padding # \u5982\u679cscaleFill = True,\u5219\u4e0d\u8fdb\u884c\u586b\u5145\uff0c\u76f4\u63a5resize\u6210img_size,\u4efb\u7531\u56fe\u7247\u8fdb\u884c\u62c9\u4f38\u548c\u538b\u7f29 elif scaleFill : # stretch dw , dh = 0.0 , 0.0 new_unpad = ( new_shape [ 1 ], new_shape [ 0 ]) ratio = new_shape [ 1 ] / shape [ 1 ], new_shape [ 0 ] / shape [ 0 ] # width, height ratios # \u8ba1\u7b97\u4e0a\u4e0b\u5de6\u53f3\u5230\u586b\u5145,\u5373\u5c06padding\u5206\u5230\u4e0a\u4e0b\uff0c\u5de6\u53f3\u4e24\u4fa7 dw /= 2 # divide padding into 2 sides dh /= 2 # \u5c06\u539f\u56feresize\u5230new_unpad if shape [:: - 1 ] != new_unpad : # resize im = cv2 . resize ( im , new_unpad , interpolation = cv2 . INTER_LINEAR ) # \u4e0b\u9762\u4e24\u884c\u8ba1\u7b97\u9700\u8981\u586b\u5145 padding top , bottom = int ( round ( dh - 0.1 )), int ( round ( dh + 0.1 )) # \u8ba1\u7b97\u4e0a\u4e0b\u4e24\u4fa7\u7684padding left , right = int ( round ( dw - 0.1 )), int ( round ( dw + 0.1 )) # \u8ba1\u7b97\u5de6\u53f3\u4e24\u4fa7\u7684padding # \u8c03\u7528cv2.copyMakeBorder\u51fd\u6570\u8fdb\u884c\u80cc\u666f\u586b\u5145\u3002 im = cv2 . copyMakeBorder ( im , top , bottom , left , right , cv2 . BORDER_CONSTANT , value = color ) # add border return im , ratio , ( dw , dh )","title":"5.1 \u77e9\u5f62\u63a8\u7406"},{"location":"tutorials/05_chapter/rectangular_reasoning.html#_1","text":"","title":"\u77e9\u5f62\u63a8\u7406"},{"location":"tutorials/05_chapter/rectangular_reasoning.html#_2","text":"\u5f53\u6211\u4eec\u628a\u4e00\u5e45\u56fe\u7247\u9001\u5165\u7f51\u7edc\uff0c\u8fd9\u5e45\u56fe\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e0e\u7f51\u7edc\u9700\u6c42\u7684\u4e0d\u4e00\u81f4\u7684\u65f6\u5019\uff0c\u6211\u4eec\u80af\u5b9a\u9700\u8981\u5bf9\u56fe\u7247\u505a\u51fa\u4e00\u4e9b\u6539\u53d8\u3002 \u4e00\u822c\u6765\u8bf4\u6709\u4e24\u79cd\u5e38\u7528\u7684\u9009\u62e9:(\u5047\u8bbe \u7f51\u7edc\u9700\u6c42\u7684\u56fe\u7247\u5927\u5c0f\u4e3a32\u7684\u500d\u6570,\u4f20\u5165\u7684\u56fe\u7247\u9ad8\u5bbd\u4e3a 200 x 416 ) 1. \u6b63\u65b9\u5f62\u63a8\u7406(square lnference) \u662f\u5c06\u56fe\u7247\u586b\u5145\u4e3a\u6b63\u65b9\u5f62,\u5982\u4e0b\u56fe\u5de6\u8fb9\u6240\u793a\u3002 2. \u77e9\u5f62\u63a8\u7406(Rectangular Inference) \u5982\u4e0b\u56fe\u53f3\u8fb9\u6240\u793a\u3002 \u5206\u6790: \u53ef\u4ee5\u770b\u5230\u4e0a\u56fe\u6b63\u65b9\u5f62\u63a8\u7406\u5b58\u5728\u5927\u91cf\u7684\u5197\u4f59\u90e8\u5206,\u800c\u53f3\u8fb9\u7684\u77e9\u5f62\u63a8\u7406\u660e\u663e\u5197\u4f59\u90e8\u5206\u5c11\u4e8e\u5de6\u8fb9\u5e76\u4e14\u5b9e\u9645\u8868\u73b0\u7684\u76f8\u6bd4\u6b63\u65b9\u5f62\u63a8\u7406\u80fd\u663e\u8457\u7684\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002 \u63a8\u7406\u8fc7\u7a0b\uff1a\u5c06\u8f83\u957f\u8fb9\u8bbe\u5b9a\u4e3a\u76ee\u6807\u5c3a\u5bf8 416,512\u2026 (\u5fc5\u987b\u662f32\u7684\u500d\u6570)\uff0c\u77ed\u8fb9\u6309\u6bd4\u4f8b\u7f29\u653e\uff0c\u518d\u5bf9\u77ed\u8fb9\u8fdb\u884c\u8f83\u5c11\u586b\u5145\u4f7f\u77ed\u8fb9\u6ee1\u8db332\u7684\u500d\u6570\uff0c\u8be6\u7ec6\u8fc7\u7a0b\u8be6\u89c1\u6e90\u7801\u89e3\u6790\u3002","title":"\u4ecb\u7ecd"},{"location":"tutorials/05_chapter/rectangular_reasoning.html#_3","text":"","title":"\u62d3\u5c55"},{"location":"tutorials/05_chapter/rectangular_reasoning.html#_4","text":"\u5bf9\u5e94\u4ed3\u5e93\u6587\u4ef6: https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/augmentations.py#L93-L131 # \u56fe\u7247\u7f29\u653e\uff1a\u4fdd\u6301\u56fe\u7247\u7684\u5bbd\u9ad8\u6bd4\u4f8b\uff0c\u5269\u4e0b\u7684\u90e8\u5206\u7528\u7070\u8272\u586b\u5145\u3002 def letterbox ( im , new_shape = ( 640 , 640 ), color = ( 114 , 114 , 114 ), auto = True , scaleFill = False , scaleup = True , stride = 32 ): \"\"\" \u5c06\u56fe\u7247\u7f29\u653e\u8c03\u6574\u5230\u6307\u5b9a\u5927\u5c0f @Param img: \u539f\u56fe @Param new_shape: \u7f29\u653e\u540e\u7684\u56fe\u7247\u5927\u5c0f @Param color: pad\u7684\u989c\u8272 @Param auto: True \u4fdd\u8bc1\u7f29\u653e\u540e\u7684\u56fe\u7247\u4fdd\u6301\u539f\u56fe\u7684\u6bd4\u4f8b \u5373 \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e\uff08\u4e0d\u4f1a\u5931\u771f\uff09 False \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e,\u6700\u540e\u5c06\u8f83\u77ed\u8fb9\u4e24\u8fb9pad\u64cd\u4f5c\u7f29\u653e\u5230\u6700\u957f\u8fb9\u5927\u5c0f\uff08\u4e0d\u4f1a\u5931\u771f\uff09 @Param scale_fill: True \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u539f\u56feresize\u5230\u6307\u5b9a\u7684\u5927\u5c0f \u76f8\u5f53\u4e8e\u5c31\u662fresize \u6ca1\u6709pad\u64cd\u4f5c\uff08\u5931\u771f\uff09 @Param scale_up: True \u5bf9\u4e8e\u5c0f\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5927\u4e8e\u7684\u4e0d\u53d8 False \u5bf9\u4e8e\u5927\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8e\u7684\u4e0d\u53d8 @return: img: letterbox\u540e\u7684\u56fe\u7247 ratio: wh ratios (dw, dh): w\u548ch\u7684pad \"\"\" # Resize and pad image while meeting stride-multiple constraints # \u53d6\u56fe\u7247\u7684\u9ad8\u5bbd shape = im . shape [: 2 ] # current shape [height, width] if isinstance ( new_shape , int ): new_shape = ( new_shape , new_shape ) # Scale ratio (new / old) \u8ba1\u7b97\u7f29\u653e\u56e0\u5b50 r = min ( new_shape [ 0 ] / shape [ 0 ], new_shape [ 1 ] / shape [ 1 ]) \"\"\" \u7f29\u653e(resize)\u5230\u8f93\u5165\u5927\u5c0fimg_size\u7684\u65f6\u5019,\u5982\u679c\u6ca1\u6709\u8bbe\u7f6e\u4e0a\u91c7\u6837\u7684\u8bdd,\u5219\u53ea\u8fdb\u884c\u4e0b\u91c7\u6837 \u56e0\u4e3a\u4e0a\u91c7\u6837\u56fe\u7247\u4f1a\u8ba9\u56fe\u7247\u6a21\u7cca,\u5bf9\u8bad\u7ec3\u4e0d\u53cb\u597d\u4e14\u5f71\u54cd\u6027\u80fd\u3002 \"\"\" if not scaleup : # only scale down, do not scale up (for better val mAP) r = min ( r , 1.0 ) # Compute padding \u8ba1\u7b97\u586b\u5145 ratio = r , r # width, height ratios # \u65b0\u7684\u672a\u586b\u5145\u5927\u5c0f, \u4fdd\u8bc1\u7f29\u653e\u540e\u56fe\u50cf\u6bd4\u4f8b\u4e0d\u53d8 new_unpad = int ( round ( shape [ 1 ] * r )), int ( round ( shape [ 0 ] * r )) dw , dh = new_shape [ 1 ] - new_unpad [ 0 ], new_shape [ 0 ] - new_unpad [ 1 ] # wh padding if auto : # minimum rectangle \u83b7\u53d6\u6700\u5c0f\u77e9\u5f62\u586b\u5145 # \u8fd9\u91cc\u7684\u53d6\u4f59\u64cd\u4f5c\u53ef\u4ee5\u4fdd\u8bc1padding\u540e\u7684\u56fe\u7247\u662f32\u7684\u6574\u6570\u500d(416x416)\uff0c\u5982\u679c\u662f(512x512)\u53ef\u4ee5\u4fdd\u8bc1\u662f64\u7684\u6574\u6570\u500d dw , dh = np . mod ( dw , stride ), np . mod ( dh , stride ) # wh padding # \u5982\u679cscaleFill = True,\u5219\u4e0d\u8fdb\u884c\u586b\u5145\uff0c\u76f4\u63a5resize\u6210img_size,\u4efb\u7531\u56fe\u7247\u8fdb\u884c\u62c9\u4f38\u548c\u538b\u7f29 elif scaleFill : # stretch dw , dh = 0.0 , 0.0 new_unpad = ( new_shape [ 1 ], new_shape [ 0 ]) ratio = new_shape [ 1 ] / shape [ 1 ], new_shape [ 0 ] / shape [ 0 ] # width, height ratios # \u8ba1\u7b97\u4e0a\u4e0b\u5de6\u53f3\u5230\u586b\u5145,\u5373\u5c06padding\u5206\u5230\u4e0a\u4e0b\uff0c\u5de6\u53f3\u4e24\u4fa7 dw /= 2 # divide padding into 2 sides dh /= 2 # \u5c06\u539f\u56feresize\u5230new_unpad if shape [:: - 1 ] != new_unpad : # resize im = cv2 . resize ( im , new_unpad , interpolation = cv2 . INTER_LINEAR ) # \u4e0b\u9762\u4e24\u884c\u8ba1\u7b97\u9700\u8981\u586b\u5145 padding top , bottom = int ( round ( dh - 0.1 )), int ( round ( dh + 0.1 )) # \u8ba1\u7b97\u4e0a\u4e0b\u4e24\u4fa7\u7684padding left , right = int ( round ( dw - 0.1 )), int ( round ( dw + 0.1 )) # \u8ba1\u7b97\u5de6\u53f3\u4e24\u4fa7\u7684padding # \u8c03\u7528cv2.copyMakeBorder\u51fd\u6570\u8fdb\u884c\u80cc\u666f\u586b\u5145\u3002 im = cv2 . copyMakeBorder ( im , top , bottom , left , right , cv2 . BORDER_CONSTANT , value = color ) # add border return im , ratio , ( dw , dh )","title":"\u77e9\u5f62\u63a8\u7406\u6e90\u7801\u89e3\u6790"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html","text":"\u6a21\u578b\u5bfc\u51fa \ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5982\u4f55\u5bfc\u51fa\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684 OneFlow YOLOv5 \u6a21\u578b \ud83d\ude80 \u5230 ONNX . \u5f00\u59cb\u4e4b\u524d \u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install \u683c\u5f0f YOLOv5\u652f\u6301\u591a\u79cd\u6a21\u578b\u683c\u5f0f\u7684\u5bfc\u51fa\uff0c\u5e76\u57fa\u4e8e\u7279\u5b9a\u6a21\u578b\u5bf9\u5e94\u7684\u6846\u67b6\u83b7\u5f97\u63a8\u7406\u52a0\u901f\u3002 Format export.py --include Model OneFlow - yolov5s_oneflow_model/ ONNX onnx yolov5s.onnx OpenVINO openvino yolov5s_openvino_model/ TensorRT engine yolov5s.engine TensorFlow SavedModel saved_model yolov5s_saved_model/ TensorFlow GraphDef pb yolov5s.pb TensorFlow Lite tflite yolov5s.tflite TensorFlow Edge TPU edgetpu yolov5s_edgetpu.tflite TensorFlow.js tfjs yolov5s_web_model/ \u5bfc\u51fa\u8bad\u7ec3\u597d\u7684 YOLOv5 \u6a21\u578b \u4e0b\u9762\u7684\u547d\u4ee4\u628a\u9884\u8bad\u7ec3\u7684 YOLOV5s \u6a21\u578b\u5bfc\u51fa\u4e3a ONNX \u683c\u5f0f\u3002 yolov5s \u662f\u5c0f\u6a21\u578b\uff0c\u662f\u53ef\u7528\u7684\u6a21\u578b\u91cc\u9762\u7b2c\u4e8c\u5c0f\u7684\u3002\u5176\u5b83\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5l \uff0c yolov5x \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u6211\u4eec\u7684 README python export.py --weights ../yolov5s/ --include onnx \ud83d\udca1 \u63d0\u793a: \u6dfb\u52a0 --half \u4ee5 FP16 \u534a\u7cbe\u5ea6\u5bfc\u51fa\u6a21\u578b\u4ee5\u5b9e\u73b0\u66f4\u5c0f\u7684\u6587\u4ef6\u5927\u5c0f\u3002 \u8f93\u51fa\uff1a export: data = data/coco128.yaml, weights =[ '../yolov5s/' ] , imgsz =[ 640 , 640 ] , batch_size = 1 , device = cpu, half = False, inplace = False, train = False, keras = False, optimize = False, int8 = False, dynamic = False, simplify = False, opset = 12 , verbose = False, workspace = 4 , nms = False, agnostic_nms = False, topk_per_class = 100 , topk_all = 100 , iou_thres = 0 .45, conf_thres = 0 .25, include =[ 'onnx' ] YOLOv5 \ud83d\ude80 270ac92 Python-3.8.11 oneflow-0.8.1+cu117.git.0c70a3f6be CPU Fusing layers... YOLOv5s summary: 157 layers, 7225885 parameters, 229245 gradients OneFlow: starting from ../yolov5s with output shape ( 1 , 25200 , 85 ) ( 112 .9 MB ) ONNX: starting export with onnx 1 .12.0... Converting model to onnx.... Using opset <onnx, 12 > Optimizing ONNX model After optimization: Const +17 ( 73 ->90 ) , Identity -1 ( 1 ->0 ) , Unsqueeze -60 ( 60 ->0 ) , output -1 ( 1 ->0 ) , variable -60 ( 127 ->67 ) Succeed converting model, save model to ../yolov5s.onnx <class 'tuple' > Comparing result between oneflow and onnx.... Compare succeed! ONNX: export success, saved as ../yolov5s.onnx ( 28 .0 MB ) Export complete ( 24 .02s ) Results saved to /home/zhangxiaoyu Detect: python detect.py --weights ../yolov5s.onnx Validate: python val.py --weights ../yolov5s.onnx OneFlow Hub: model = flow.hub.load ( 'OneFlow-Inc/one-yolov5' , 'custom' , '../yolov5s.onnx' ) Visualize: https://netron.app \u5bfc\u51fa\u7684 onnx \u6a21\u578b\u4f7f\u7528 Netron Viewer \u8fdb\u884c\u53ef\u89c6\u5316\u7684\u7ed3\u679c\u5982\u4e0b\uff1a \u5bfc\u51fa\u6a21\u578b\u7684\u793a\u4f8b\u7528\u6cd5 detect.py \u53ef\u4ee5\u5bf9\u5bfc\u51fa\u7684\u6a21\u578b\u8fdb\u884c\u63a8\u7406\uff1a python path / to / detect . py -- weights yolov5s / # OneFlow yolov5s . onnx # ONNX Runtime or OpenCV DNN with --dnn yolov5s . xml # OpenVINO yolov5s . engine # TensorRT yolov5s . mlmodel # CoreML (macOS only) yolov5s_saved_model # TensorFlow SavedModel yolov5s . pb # TensorFlow GraphDef yolov5s . tflite # TensorFlow Lite yolov5s_edgetpu . tflite # TensorFlow Edge TPU val.py \u53ef\u4ee5\u5bf9\u5bfc\u51fa\u7684\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\uff1a python path / to / val . py -- weights yolov5s / # OneFlow yolov5s . onnx # ONNX Runtime or OpenCV DNN with --dnn yolov5s . xml # OpenVINO yolov5s . engine # TensorRT yolov5s . mlmodel # CoreML (macOS only) yolov5s_saved_model # TensorFlow SavedModel yolov5s . pb # TensorFlow GraphDef yolov5s . tflite # TensorFlow Lite yolov5s_edgetpu . tflite # TensorFlow Edge TPU ONNX Runtime \u63a8\u7406 \u57fa\u4e8e onnx \u6a21\u578b\u4f7f\u7528 onnxruntime \u8fdb\u884c\u63a8\u7406\uff1a python3 detect.py --weights ../yolov5s/yolov5s.onnx \u8f93\u51fa\uff1a detect: weights=['../yolov5s/yolov5s.onnx'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 270ac92 Python-3.8.11 oneflow-0.8.1+cu117.git.0c70a3f6be Loading ../yolov5s/yolov5s.onnx for ONNX Runtime inference... detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/zhangxiaoyu/one-yolov5/data/images/bus.jpg: 640x640 4 persons, 1 bus, Done. (0.009s) image 2/2 /home/zhangxiaoyu/one-yolov5/data/images/zidane.jpg: 640x640 2 persons, 2 ties, Done. (0.011s) 0.5ms pre-process, 10.4ms inference, 4.8ms NMS per image at shape (1, 3, 640, 640) Results saved to runs/detect/exp14 \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/issues/251","title":"6.1 \u6a21\u578b\u5bfc\u51fa"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_1","text":"\ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5982\u4f55\u5bfc\u51fa\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684 OneFlow YOLOv5 \u6a21\u578b \ud83d\ude80 \u5230 ONNX .","title":"\u6a21\u578b\u5bfc\u51fa"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_2","text":"\u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install","title":"\u5f00\u59cb\u4e4b\u524d"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_3","text":"YOLOv5\u652f\u6301\u591a\u79cd\u6a21\u578b\u683c\u5f0f\u7684\u5bfc\u51fa\uff0c\u5e76\u57fa\u4e8e\u7279\u5b9a\u6a21\u578b\u5bf9\u5e94\u7684\u6846\u67b6\u83b7\u5f97\u63a8\u7406\u52a0\u901f\u3002 Format export.py --include Model OneFlow - yolov5s_oneflow_model/ ONNX onnx yolov5s.onnx OpenVINO openvino yolov5s_openvino_model/ TensorRT engine yolov5s.engine TensorFlow SavedModel saved_model yolov5s_saved_model/ TensorFlow GraphDef pb yolov5s.pb TensorFlow Lite tflite yolov5s.tflite TensorFlow Edge TPU edgetpu yolov5s_edgetpu.tflite TensorFlow.js tfjs yolov5s_web_model/","title":"\u683c\u5f0f"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#yolov5","text":"\u4e0b\u9762\u7684\u547d\u4ee4\u628a\u9884\u8bad\u7ec3\u7684 YOLOV5s \u6a21\u578b\u5bfc\u51fa\u4e3a ONNX \u683c\u5f0f\u3002 yolov5s \u662f\u5c0f\u6a21\u578b\uff0c\u662f\u53ef\u7528\u7684\u6a21\u578b\u91cc\u9762\u7b2c\u4e8c\u5c0f\u7684\u3002\u5176\u5b83\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5l \uff0c yolov5x \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u6211\u4eec\u7684 README python export.py --weights ../yolov5s/ --include onnx \ud83d\udca1 \u63d0\u793a: \u6dfb\u52a0 --half \u4ee5 FP16 \u534a\u7cbe\u5ea6\u5bfc\u51fa\u6a21\u578b\u4ee5\u5b9e\u73b0\u66f4\u5c0f\u7684\u6587\u4ef6\u5927\u5c0f\u3002 \u8f93\u51fa\uff1a export: data = data/coco128.yaml, weights =[ '../yolov5s/' ] , imgsz =[ 640 , 640 ] , batch_size = 1 , device = cpu, half = False, inplace = False, train = False, keras = False, optimize = False, int8 = False, dynamic = False, simplify = False, opset = 12 , verbose = False, workspace = 4 , nms = False, agnostic_nms = False, topk_per_class = 100 , topk_all = 100 , iou_thres = 0 .45, conf_thres = 0 .25, include =[ 'onnx' ] YOLOv5 \ud83d\ude80 270ac92 Python-3.8.11 oneflow-0.8.1+cu117.git.0c70a3f6be CPU Fusing layers... YOLOv5s summary: 157 layers, 7225885 parameters, 229245 gradients OneFlow: starting from ../yolov5s with output shape ( 1 , 25200 , 85 ) ( 112 .9 MB ) ONNX: starting export with onnx 1 .12.0... Converting model to onnx.... Using opset <onnx, 12 > Optimizing ONNX model After optimization: Const +17 ( 73 ->90 ) , Identity -1 ( 1 ->0 ) , Unsqueeze -60 ( 60 ->0 ) , output -1 ( 1 ->0 ) , variable -60 ( 127 ->67 ) Succeed converting model, save model to ../yolov5s.onnx <class 'tuple' > Comparing result between oneflow and onnx.... Compare succeed! ONNX: export success, saved as ../yolov5s.onnx ( 28 .0 MB ) Export complete ( 24 .02s ) Results saved to /home/zhangxiaoyu Detect: python detect.py --weights ../yolov5s.onnx Validate: python val.py --weights ../yolov5s.onnx OneFlow Hub: model = flow.hub.load ( 'OneFlow-Inc/one-yolov5' , 'custom' , '../yolov5s.onnx' ) Visualize: https://netron.app \u5bfc\u51fa\u7684 onnx \u6a21\u578b\u4f7f\u7528 Netron Viewer \u8fdb\u884c\u53ef\u89c6\u5316\u7684\u7ed3\u679c\u5982\u4e0b\uff1a","title":"\u5bfc\u51fa\u8bad\u7ec3\u597d\u7684 YOLOv5 \u6a21\u578b"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_4","text":"detect.py \u53ef\u4ee5\u5bf9\u5bfc\u51fa\u7684\u6a21\u578b\u8fdb\u884c\u63a8\u7406\uff1a python path / to / detect . py -- weights yolov5s / # OneFlow yolov5s . onnx # ONNX Runtime or OpenCV DNN with --dnn yolov5s . xml # OpenVINO yolov5s . engine # TensorRT yolov5s . mlmodel # CoreML (macOS only) yolov5s_saved_model # TensorFlow SavedModel yolov5s . pb # TensorFlow GraphDef yolov5s . tflite # TensorFlow Lite yolov5s_edgetpu . tflite # TensorFlow Edge TPU val.py \u53ef\u4ee5\u5bf9\u5bfc\u51fa\u7684\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\uff1a python path / to / val . py -- weights yolov5s / # OneFlow yolov5s . onnx # ONNX Runtime or OpenCV DNN with --dnn yolov5s . xml # OpenVINO yolov5s . engine # TensorRT yolov5s . mlmodel # CoreML (macOS only) yolov5s_saved_model # TensorFlow SavedModel yolov5s . pb # TensorFlow GraphDef yolov5s . tflite # TensorFlow Lite yolov5s_edgetpu . tflite # TensorFlow Edge TPU","title":"\u5bfc\u51fa\u6a21\u578b\u7684\u793a\u4f8b\u7528\u6cd5"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#onnx-runtime","text":"\u57fa\u4e8e onnx \u6a21\u578b\u4f7f\u7528 onnxruntime \u8fdb\u884c\u63a8\u7406\uff1a python3 detect.py --weights ../yolov5s/yolov5s.onnx \u8f93\u51fa\uff1a detect: weights=['../yolov5s/yolov5s.onnx'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 270ac92 Python-3.8.11 oneflow-0.8.1+cu117.git.0c70a3f6be Loading ../yolov5s/yolov5s.onnx for ONNX Runtime inference... detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/zhangxiaoyu/one-yolov5/data/images/bus.jpg: 640x640 4 persons, 1 bus, Done. (0.009s) image 2/2 /home/zhangxiaoyu/one-yolov5/data/images/zidane.jpg: 640x640 2 persons, 2 ties, Done. (0.011s) 0.5ms pre-process, 10.4ms inference, 4.8ms NMS per image at shape (1, 3, 640, 640) Results saved to runs/detect/exp14","title":"ONNX Runtime \u63a8\u7406"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_5","text":"https://github.com/ultralytics/yolov5/issues/251","title":"\u53c2\u8003\u6587\u7ae0"}]}