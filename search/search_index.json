{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"OneFlow-YOLOV5-Document What is one-yolov5\ud83e\udd14\ufe0f\uff1f one-yolov5 : \u662f\u4ee5 OneFlow \u4e3a\u540e\u7aef\u7684YOLOv5\u76ee\u6807\u68c0\u6d4b\u9879\u76ee\u76f8\u6bd4pytorch\u540e\u7aef\u66f4\u6709\u6548\u7f29\u77ed\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\u3002 \u66f4\u591a\u8bf7\u53c2\u9605 one-yolov5\u7279\u70b9\u89e3\u6790 \u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u5feb\u901f\u4e0a\u624b\uff0c\u8bf7\u70b9\u51fb \u300a\u5feb\u901f\u5f00\u59cb\u300b \u53d1\u5c55\u5386\u53f2\ud83d\ude80 https://github.com/Oneflow-Inc/one-yolov5/releases/tag/v1.0 FAQ \ud83d\udc98 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"\u9996\u9875\ud83c\udfe0"},{"location":"index.html#oneflow-yolov5-document","text":"","title":"OneFlow-YOLOV5-Document"},{"location":"index.html#what-is-one-yolov5","text":"one-yolov5 : \u662f\u4ee5 OneFlow \u4e3a\u540e\u7aef\u7684YOLOv5\u76ee\u6807\u68c0\u6d4b\u9879\u76ee\u76f8\u6bd4pytorch\u540e\u7aef\u66f4\u6709\u6548\u7f29\u77ed\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\u3002 \u66f4\u591a\u8bf7\u53c2\u9605 one-yolov5\u7279\u70b9\u89e3\u6790 \u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u5feb\u901f\u4e0a\u624b\uff0c\u8bf7\u70b9\u51fb \u300a\u5feb\u901f\u5f00\u59cb\u300b","title":"What is one-yolov5\ud83e\udd14\ufe0f\uff1f"},{"location":"index.html#_1","text":"https://github.com/Oneflow-Inc/one-yolov5/releases/tag/v1.0","title":"\u53d1\u5c55\u5386\u53f2\ud83d\ude80"},{"location":"index.html#faq","text":"\u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"FAQ \ud83d\udc98"},{"location":"source_code_interpretation/callbacks_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a callbacks.py \u8fd9\u4e2a\u6587\u4ef6\u662fyolov5\u7684Callback utils \u94a9\u5b50 hook(\u94a9\u5b50)\u662f\u4e00\u4e2a\u7f16\u7a0b\u673a\u5236\uff0c\u4e0e\u8bed\u8a00\u65e0\u5173\uff0c\u901a\u5e38\u7528\u4e8e\u5728\u4e0d\u4fee\u6539\u539f\u59cb\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\uff0c\u6355\u83b7\u6216\u66ff\u6362\u7a0b\u5e8f\u7684\u4e00\u4e9b\u51fd\u6570\u6216API\u8c03\u7528\u3002 \u4e2a\u4eba\u89c2\u70b9\uff1a\u94a9\u5b50\u662f\u6307\u5c06\u4ee3\u7801\u63d2\u5165\u5230\u5176\u4ed6\u4ee3\u7801\u7684\u6267\u884c\u6d41\u7a0b\u4e2d\u7684\u6280\u672f\uff0c\u4ece\u800c\u5b9e\u73b0\u5728\u6267\u884c\u539f\u6709\u4ee3\u7801\u4e4b\u524d\u6216\u4e4b\u540e\u6267\u884c\u989d\u5916\u4ee3\u7801\u7684\u76ee\u7684\uff0c\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355demo\u3002 def hook_function ( original_function ): # \u5b9a\u4e49\u94a9\u5b50\u51fd\u6570 def new_function ( * args , ** kwargs ): print ( \"Before original function\" ) result = original_function ( * args , ** kwargs ) print ( \"After original function\" ) return result return new_function @hook_function def original_function (): # @hook_function (python\u8bed\u6cd5) \u7b49\u4ef7\u4e8e hook_function(original_function) print ( \"Original function\" ) if __name__ == \"__main__\" : original_function () \u8f93\u51fa Before original function Original function After original function \u56de\u8c03\u51fd\u6570 \u6765\u6e90\u7f51\u7edc\u7684\u4f8b\u5b50\uff0c\u6709\u4e00\u5bb6\u65c5\u9986\u63d0\u4f9b\u53eb\u9192\u670d\u52a1\uff0c\u4f46\u662f\u8981\u6c42\u65c5\u5ba2\u81ea\u5df1\u51b3\u5b9a\u53eb\u9192\u7684\u65b9\u6cd5\u3002\u53ef\u4ee5\u662f\u6253\u5ba2\u623f\u7535\u8bdd\uff0c\u4e5f\u53ef\u4ee5\u662f\u6d3e\u670d\u52a1\u5458\u53bb\u6572\u95e8\uff0c\u7761\u5f97\u6b7b\u6015\u803d\u8bef\u4e8b\u7684\uff0c\u8fd8\u53ef\u4ee5\u8981\u6c42\u5f80\u81ea\u5df1\u5934\u4e0a\u6d47\u76c6\u6c34\u3002\u8fd9\u91cc\uff0c\u201c\u53eb\u9192\u201d\u8fd9\u4e2a\u884c\u4e3a\u662f\u65c5\u9986\u63d0\u4f9b\u7684\uff0c\u76f8\u5f53\u4e8e\u5e93\u51fd\u6570\uff0c\u4f46\u662f\u53eb\u9192\u7684\u65b9\u5f0f\u662f\u7531\u65c5\u5ba2\u51b3\u5b9a\u5e76\u544a\u8bc9\u65c5\u9986\u7684\uff0c\u4e5f\u5c31\u662f\u56de\u8c03\u51fd\u6570\u3002\u800c\u65c5\u5ba2\u544a\u8bc9\u65c5\u9986\u600e\u4e48\u53eb\u9192\u81ea\u5df1\u7684\u52a8\u4f5c\uff0c\u4e5f\u5c31\u662f\u628a\u56de\u8c03\u51fd\u6570\u4f20\u5165\u5e93\u51fd\u6570\u7684\u52a8\u4f5c\uff0c\u79f0\u4e3a\u767b\u8bb0\u56de\u8c03\u51fd\u6570\uff08to register a callback function\uff09\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff08\u56fe\u7247\u6765\u6e90\uff1a\u7ef4\u57fa\u767e\u79d1\uff09\uff1a \u4ece\u4e0a\u56fe\u53ef\u4ee5\u770b\u5230\uff0c\u56de\u8c03\u51fd\u6570\u901a\u5e38\u548c\u5e94\u7528\u5904\u4e8e\u540c\u4e00\u62bd\u8c61\u5c42\uff08\u56e0\u4e3a\u4f20\u5165\u4ec0\u4e48\u6837\u7684\u56de\u8c03\u51fd\u6570\u662f\u5728\u5e94\u7528\u7ea7\u522b\u51b3\u5b9a\u7684\uff09\u3002\u800c\u56de\u8c03\u5c31\u6210\u4e86\u4e00\u4e2a\u9ad8\u5c42\u8c03\u7528\u5e95\u5c42\uff0c\u5e95\u5c42\u518d\u56de\u8fc7\u5934\u6765\u8c03\u7528\u9ad8\u5c42\u7684\u8fc7\u7a0b\u3002 \u7b80\u5355\u6765\u8bf4\uff1a - \u4e00\u822c\u51fd\u6570\uff1afunction a(int a, String b)\uff0c\u63a5\u6536\u7684\u53c2\u6570\u662f\u4e00\u822c\u7c7b\u578b\u3002 - \u7279\u6b8a\u51fd\u6570\uff1afunction b(function c)\uff0c\u63a5\u6536\u7684\u53c2\u6570\u662f\u4e00\u4e2a\u51fd\u6570\uff0cc\u8fd9\u4e2a\u51fd\u6570\u5c31\u53eb \u56de\u8c03\u51fd\u6570 \u3002 \u4e2a\u4eba\u89c2\u70b9\uff1a\u56de\u8c03\u51fd\u6570\u662f\u6307\u5728\u4ee3\u7801\u4e2d\u88ab\u8c03\u7528\u7684\u4e00\u4e2a\u51fd\u6570\uff0c\u5b83\u4f1a\u5bf9\u5176\u4ed6\u4ee3\u7801\u7684\u6267\u884c\u9020\u6210\u5f71\u54cd\uff0c\u5e76\u5728\u9002\u5f53\u7684\u65f6\u95f4\u8fdb\u884c\u56de\u8c03\uff0c\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355demo\u3002 def callback_function ( input_data ): # \u5728\u56de\u8c03\u51fd\u6570\u4e2d\u5904\u7406\u8f93\u5165\u6570\u636e print ( \"Input data:\" , input_data ) def main ( callback ): # \u8c03\u7528\u56de\u8c03\u51fd\u6570 callback ( \"Hello World\" ) if __name__ == \"__main__\" : main ( callback_function ) \u8f93\u51fa Input data: Hello World \u603b\u4e4b\uff0c\u94a9\u5b50\u548c\u56de\u8c03\u51fd\u6570\u662f\u5b9e\u73b0\u4ee3\u7801\u95f4\u901a\u4fe1\u548c\u534f\u4f5c\u7684\u4e0d\u540c\u6280\u672f\uff0c\u5b83\u4eec\u90fd\u53ef\u4ee5\u7528\u4e8e\u5b9e\u73b0\u4ee3\u7801\u7ea7\u522b\u7684\u81ea\u5b9a\u4e49\u884c\u4e3a\uff0c\u53ea\u662f\u51fd\u6570\u7684\u89e6\u53d1\u65f6\u673a\u6709\u5dee\u5f02\u3002 hook\u5b9e\u73b0\u4f8b\u5b50 hook\u51fd\u6570\u662f\u7a0b\u5e8f\u4e2d\u9884\u5b9a\u4e49\u597d\u7684\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u5904\u4e8e\u539f\u6709\u7a0b\u5e8f\u6d41\u7a0b\u5f53\u4e2d\uff08\u66b4\u9732\u4e00\u4e2a\u94a9\u5b50\u51fa\u6765\uff09\u3002 \u6211\u4eec\u9700\u8981\u518d\u5728\u6709\u6d41\u7a0b\u4e2d\u94a9\u5b50\u5b9a\u4e49\u7684\u51fd\u6570\u5757\u4e2d\u5b9e\u73b0\u67d0\u4e2a\u5177\u4f53\u7684\u7ec6\u8282\uff0c\u9700\u8981\u628a\u6211\u4eec\u7684\u5b9e\u73b0\uff0c\u6302\u63a5\u6216\u8005\u6ce8\u518c\uff08register\uff09\u5230\u94a9\u5b50\u91cc\uff0c\u4f7f\u5f97hook\u51fd\u6570\u5bf9\u76ee\u6807\u53ef\u7528\u3002 hook\u51fd\u6570\u6700\u5e38\u4f7f\u7528\u5728\u67d0\u79cd\u6d41\u7a0b\u5904\u7406\u5f53\u4e2d\u3002\u8fd9\u4e2a\u6d41\u7a0b\u5f80\u5f80\u6709\u5f88\u591a\u6b65\u9aa4\u3002hook\u51fd\u6570\u5e38\u5e38\u6302\u8f7d\u5728\u8fd9\u4e9b\u6b65\u9aa4\u4e2d\uff0c\u4e3a\u589e\u52a0\u989d\u5916\u7684\u4e00\u4e9b\u64cd\u4f5c\uff0c\u63d0\u4f9b\u7075\u6d3b\u6027\u3002 \u4e0b\u9762\u4e3e\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff0c\u8fd9\u4e2a\u4f8b\u5b50\u7684\u76ee\u7684\u662f\u5b9e\u73b0\u4e00\u4e2a\u901a\u8fc7\u94a9\u5b50\u8c03\u7528\u51fd\u6570\u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u662f\"good\" # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license \"\"\" Callback utils \"\"\" class Callbacks : \"\"\" \" Handles all registered callbacks for YOLOv5 Hooks \"\"\" def __init__ ( self ): # Define the available callbacks self . _callbacks = { \"on_pretrain_routine_start\" : [], } self . stop_training = False # set True to interrupt training def register_action ( self , hook , name = \"\" , callback = None ): \"\"\" Register a new action to a callback hook Args: hook: The callback hook name to register the action to \u8981\u5411\u5176\u6ce8\u518c\u64cd\u4f5c\u7684\u56de\u8c03\u94a9\u5b50\u540d\u79f0 name: The name of the action for later reference \u52a8\u4f5c\u7684\u540d\u79f0\uff0c\u4f9b\u4ee5\u540e\u53c2\u8003 callback: The callback to fire \u5bf9fire\u7684\u56de\u8c03 \"\"\" assert hook in self . _callbacks , f \"hook ' { hook } ' not found in callbacks { self . _callbacks } \" assert callable ( callback ), f \"callback ' { callback } ' is not callable\" self . _callbacks [ hook ] . append ({ \"name\" : name , \"callback\" : callback }) def get_registered_actions ( self , hook = None ): \"\"\" \" Returns all the registered actions by callback hook Args: hook: The name of the hook to check, defaults to all \"\"\" return self . _callbacks [ hook ] if hook else self . _callbacks def run ( self , hook , * args , ** kwargs ): \"\"\" Loop through the registered actions and fire all callbacks Args: hook: The name of the hook to check, defaults to all args: Arguments to receive from YOLOv5 kwargs: Keyword Arguments to receive from YOLOv5 \"\"\" assert hook in self . _callbacks , f \"hook ' { hook } ' not found in callbacks { self . _callbacks } \" for logger in self . _callbacks [ hook ]: logger [ \"callback\" ]( * args , ** kwargs ) def on_pretrain_routine_start ( good : str ): if good == \"good\" : print ( \"is good!\" ) else : print ( \"is bad!\" ) # \u521d\u59cb\u5316 Callbacks \u5bf9\u8c61 callbacks = Callbacks () # \u8981\u5411\u5176\u6ce8\u518c\u64cd\u4f5c\u7684\u56de\u8c03\u94a9\u5b50\u540d\u79f0 callbacks . register_action ( hook = \"on_pretrain_routine_start\" , name = \"ss\" , callback = on_pretrain_routine_start ) # \u8c03\u7528hook callbacks . run ( \"on_pretrain_routine_start\" , \"good\" ) # \u6253\u5370hook\u4fe1\u606f callbacks . get_registered_actions ( \"on_pretrain_routine_start\" ) is good [{'name': 'ss', 'callback': <function __main__.on_pretrain_routine_start(good: str)>}] yolov5\u9879\u76ee\u4e2d \u5728yolov5\u8bad\u7ec3\u6d41\u7a0b\u4e2d\uff0chook\u51fd\u6570\u4f53\u73b0\u5728 \u4e00\u4e2a\u8bad\u7ec3\u8fc7\u7a0b(\u4e0d\u5305\u62ec\u6570\u636e\u51c6\u5907)\uff0c\u4f1a\u8f6e\u8be2\u591a\u6b21\u8bad\u7ec3\u96c6\uff0c\u6bcf\u6b21\u79f0\u4e3a\u4e00\u4e2aepoch\uff0c\u6bcf\u4e2aepoch\u53c8\u5206\u4e3a\u591a\u4e2abatch\u6765\u8bad\u7ec3\u3002 \u6d41\u7a0b\u5148\u540e\u62c6\u89e3\u6210: - \u5f00\u59cb\u8bad\u7ec3 - \u8bad\u7ec3\u4e00\u4e2aepoch\u524d - \u8bad\u7ec3\u4e00\u4e2abatch\u524d - \u8bad\u7ec3\u4e00\u4e2abatch\u540e - \u8bad\u7ec3\u4e00\u4e2aepoch\u540e\u3002 - \u8bc4\u4f30\u9a8c\u8bc1\u96c6 - \u7ed3\u675f\u8bad\u7ec3 \u8fd9\u4e9b\u6b65\u9aa4\u662f\u7a7f\u63d2\u5728\u8bad\u7ec3\u4e00\u4e2abatch\u6570\u636e\u7684\u8fc7\u7a0b\u4e2d\uff0c\u8fd9\u4e9b\u53ef\u4ee5\u7406\u89e3\u6210\u662f\u94a9\u5b50\u51fd\u6570\uff0c\u6211\u4eec\u53ef\u80fd\u9700\u8981\u5728\u8fd9\u4e9b\u94a9\u5b50\u51fd\u6570\u4e2d\u5b9e\u73b0\u4e00\u4e9b\u5b9a\u5236\u5316\u7684\u4e1c\u897f\uff0c\u6bd4\u5982\u5728\u8bad\u7ec3\u4e00\u4e2aepoch\u540e\u6211\u4eec\u8981\u4fdd\u5b58\u4e0b\u8bad\u7ec3\u7684\u635f\u5931\u3002 # \u5728train.py\u4e2dhook\u6ce8\u518c\u64cd\u4f5c\u4ee3\u7801 # Register actions for k in methods ( loggers ): callbacks . register_action ( k , callback = getattr ( loggers , k )) # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license \"\"\" Callback utils \"\"\" class Callbacks : \"\"\" \" Handles all registered callbacks for YOLOv5 Hooks \"\"\" def __init__ ( self ): # Define the available callbacks # \u5b9a\u4e49\u4e9b\u56de\u8c03\u51fd\u6570\uff0c\u51fd\u6570\u5b9e\u73b0\u5728utils/loggers/__init__.py # github\u94fe\u63a5: https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/loggers/__init__.py self . _callbacks = { \"on_pretrain_routine_start\" : [], # https://github.com/Oneflow-Inc/one-yolov5/blob/88864544cd9fa9ddcbe35a28a0bcf2c674daeb97/utils/loggers/__init__.py#L118 \"on_pretrain_routine_end\" : [], \"on_train_start\" : [], \"on_train_epoch_start\" : [], \"on_train_batch_start\" : [], \"optimizer_step\" : [], \"on_before_zero_grad\" : [], \"on_train_batch_end\" : [], \"on_train_epoch_end\" : [], \"on_val_start\" : [], \"on_val_batch_start\" : [], \"on_val_image_end\" : [], \"on_val_batch_end\" : [], \"on_val_end\" : [], \"on_fit_epoch_end\" : [], # fit = train + val \"on_model_save\" : [], \"on_train_end\" : [], \"on_params_update\" : [], \"teardown\" : [], } self . stop_training = False # set True to interrupt training def register_action ( self , hook , name = \"\" , callback = None ): \"\"\" Register a new action to a callback hook Args: hook: The callback hook name to register the action to name: The name of the action for later reference callback: The callback to fire \"\"\" assert hook in self . _callbacks , f \"hook ' { hook } ' not found in callbacks { self . _callbacks } \" assert callable ( callback ), f \"callback ' { callback } ' is not callable\" self . _callbacks [ hook ] . append ({ \"name\" : name , \"callback\" : callback }) def get_registered_actions ( self , hook = None ): \"\"\" \" Returns all the registered actions by callback hook Args: hook: The name of the hook to check, defaults to all \"\"\" return self . _callbacks [ hook ] if hook else self . _callbacks def run ( self , hook , * args , ** kwargs ): \"\"\" Loop through the registered actions and fire all callbacks Args: hook: The name of the hook to check, defaults to all args: Arguments to receive from YOLOv5 kwargs: Keyword Arguments to receive from YOLOv5 \"\"\" assert hook in self . _callbacks , f \"hook ' { hook } ' not found in callbacks { self . _callbacks } \" for logger in self . _callbacks [ hook ]: logger [ \"callback\" ]( * args , ** kwargs )","title":"callbacks.py"},{"location":"source_code_interpretation/callbacks_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a callbacks.py \u8fd9\u4e2a\u6587\u4ef6\u662fyolov5\u7684Callback utils","title":"\u524d\u8a00"},{"location":"source_code_interpretation/callbacks_py.html#_2","text":"hook(\u94a9\u5b50)\u662f\u4e00\u4e2a\u7f16\u7a0b\u673a\u5236\uff0c\u4e0e\u8bed\u8a00\u65e0\u5173\uff0c\u901a\u5e38\u7528\u4e8e\u5728\u4e0d\u4fee\u6539\u539f\u59cb\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\uff0c\u6355\u83b7\u6216\u66ff\u6362\u7a0b\u5e8f\u7684\u4e00\u4e9b\u51fd\u6570\u6216API\u8c03\u7528\u3002 \u4e2a\u4eba\u89c2\u70b9\uff1a\u94a9\u5b50\u662f\u6307\u5c06\u4ee3\u7801\u63d2\u5165\u5230\u5176\u4ed6\u4ee3\u7801\u7684\u6267\u884c\u6d41\u7a0b\u4e2d\u7684\u6280\u672f\uff0c\u4ece\u800c\u5b9e\u73b0\u5728\u6267\u884c\u539f\u6709\u4ee3\u7801\u4e4b\u524d\u6216\u4e4b\u540e\u6267\u884c\u989d\u5916\u4ee3\u7801\u7684\u76ee\u7684\uff0c\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355demo\u3002 def hook_function ( original_function ): # \u5b9a\u4e49\u94a9\u5b50\u51fd\u6570 def new_function ( * args , ** kwargs ): print ( \"Before original function\" ) result = original_function ( * args , ** kwargs ) print ( \"After original function\" ) return result return new_function @hook_function def original_function (): # @hook_function (python\u8bed\u6cd5) \u7b49\u4ef7\u4e8e hook_function(original_function) print ( \"Original function\" ) if __name__ == \"__main__\" : original_function () \u8f93\u51fa Before original function Original function After original function","title":"\u94a9\u5b50"},{"location":"source_code_interpretation/callbacks_py.html#_3","text":"\u6765\u6e90\u7f51\u7edc\u7684\u4f8b\u5b50\uff0c\u6709\u4e00\u5bb6\u65c5\u9986\u63d0\u4f9b\u53eb\u9192\u670d\u52a1\uff0c\u4f46\u662f\u8981\u6c42\u65c5\u5ba2\u81ea\u5df1\u51b3\u5b9a\u53eb\u9192\u7684\u65b9\u6cd5\u3002\u53ef\u4ee5\u662f\u6253\u5ba2\u623f\u7535\u8bdd\uff0c\u4e5f\u53ef\u4ee5\u662f\u6d3e\u670d\u52a1\u5458\u53bb\u6572\u95e8\uff0c\u7761\u5f97\u6b7b\u6015\u803d\u8bef\u4e8b\u7684\uff0c\u8fd8\u53ef\u4ee5\u8981\u6c42\u5f80\u81ea\u5df1\u5934\u4e0a\u6d47\u76c6\u6c34\u3002\u8fd9\u91cc\uff0c\u201c\u53eb\u9192\u201d\u8fd9\u4e2a\u884c\u4e3a\u662f\u65c5\u9986\u63d0\u4f9b\u7684\uff0c\u76f8\u5f53\u4e8e\u5e93\u51fd\u6570\uff0c\u4f46\u662f\u53eb\u9192\u7684\u65b9\u5f0f\u662f\u7531\u65c5\u5ba2\u51b3\u5b9a\u5e76\u544a\u8bc9\u65c5\u9986\u7684\uff0c\u4e5f\u5c31\u662f\u56de\u8c03\u51fd\u6570\u3002\u800c\u65c5\u5ba2\u544a\u8bc9\u65c5\u9986\u600e\u4e48\u53eb\u9192\u81ea\u5df1\u7684\u52a8\u4f5c\uff0c\u4e5f\u5c31\u662f\u628a\u56de\u8c03\u51fd\u6570\u4f20\u5165\u5e93\u51fd\u6570\u7684\u52a8\u4f5c\uff0c\u79f0\u4e3a\u767b\u8bb0\u56de\u8c03\u51fd\u6570\uff08to register a callback function\uff09\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff08\u56fe\u7247\u6765\u6e90\uff1a\u7ef4\u57fa\u767e\u79d1\uff09\uff1a \u4ece\u4e0a\u56fe\u53ef\u4ee5\u770b\u5230\uff0c\u56de\u8c03\u51fd\u6570\u901a\u5e38\u548c\u5e94\u7528\u5904\u4e8e\u540c\u4e00\u62bd\u8c61\u5c42\uff08\u56e0\u4e3a\u4f20\u5165\u4ec0\u4e48\u6837\u7684\u56de\u8c03\u51fd\u6570\u662f\u5728\u5e94\u7528\u7ea7\u522b\u51b3\u5b9a\u7684\uff09\u3002\u800c\u56de\u8c03\u5c31\u6210\u4e86\u4e00\u4e2a\u9ad8\u5c42\u8c03\u7528\u5e95\u5c42\uff0c\u5e95\u5c42\u518d\u56de\u8fc7\u5934\u6765\u8c03\u7528\u9ad8\u5c42\u7684\u8fc7\u7a0b\u3002 \u7b80\u5355\u6765\u8bf4\uff1a - \u4e00\u822c\u51fd\u6570\uff1afunction a(int a, String b)\uff0c\u63a5\u6536\u7684\u53c2\u6570\u662f\u4e00\u822c\u7c7b\u578b\u3002 - \u7279\u6b8a\u51fd\u6570\uff1afunction b(function c)\uff0c\u63a5\u6536\u7684\u53c2\u6570\u662f\u4e00\u4e2a\u51fd\u6570\uff0cc\u8fd9\u4e2a\u51fd\u6570\u5c31\u53eb \u56de\u8c03\u51fd\u6570 \u3002 \u4e2a\u4eba\u89c2\u70b9\uff1a\u56de\u8c03\u51fd\u6570\u662f\u6307\u5728\u4ee3\u7801\u4e2d\u88ab\u8c03\u7528\u7684\u4e00\u4e2a\u51fd\u6570\uff0c\u5b83\u4f1a\u5bf9\u5176\u4ed6\u4ee3\u7801\u7684\u6267\u884c\u9020\u6210\u5f71\u54cd\uff0c\u5e76\u5728\u9002\u5f53\u7684\u65f6\u95f4\u8fdb\u884c\u56de\u8c03\uff0c\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355demo\u3002 def callback_function ( input_data ): # \u5728\u56de\u8c03\u51fd\u6570\u4e2d\u5904\u7406\u8f93\u5165\u6570\u636e print ( \"Input data:\" , input_data ) def main ( callback ): # \u8c03\u7528\u56de\u8c03\u51fd\u6570 callback ( \"Hello World\" ) if __name__ == \"__main__\" : main ( callback_function ) \u8f93\u51fa Input data: Hello World \u603b\u4e4b\uff0c\u94a9\u5b50\u548c\u56de\u8c03\u51fd\u6570\u662f\u5b9e\u73b0\u4ee3\u7801\u95f4\u901a\u4fe1\u548c\u534f\u4f5c\u7684\u4e0d\u540c\u6280\u672f\uff0c\u5b83\u4eec\u90fd\u53ef\u4ee5\u7528\u4e8e\u5b9e\u73b0\u4ee3\u7801\u7ea7\u522b\u7684\u81ea\u5b9a\u4e49\u884c\u4e3a\uff0c\u53ea\u662f\u51fd\u6570\u7684\u89e6\u53d1\u65f6\u673a\u6709\u5dee\u5f02\u3002","title":"\u56de\u8c03\u51fd\u6570"},{"location":"source_code_interpretation/callbacks_py.html#hook","text":"hook\u51fd\u6570\u662f\u7a0b\u5e8f\u4e2d\u9884\u5b9a\u4e49\u597d\u7684\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u5904\u4e8e\u539f\u6709\u7a0b\u5e8f\u6d41\u7a0b\u5f53\u4e2d\uff08\u66b4\u9732\u4e00\u4e2a\u94a9\u5b50\u51fa\u6765\uff09\u3002 \u6211\u4eec\u9700\u8981\u518d\u5728\u6709\u6d41\u7a0b\u4e2d\u94a9\u5b50\u5b9a\u4e49\u7684\u51fd\u6570\u5757\u4e2d\u5b9e\u73b0\u67d0\u4e2a\u5177\u4f53\u7684\u7ec6\u8282\uff0c\u9700\u8981\u628a\u6211\u4eec\u7684\u5b9e\u73b0\uff0c\u6302\u63a5\u6216\u8005\u6ce8\u518c\uff08register\uff09\u5230\u94a9\u5b50\u91cc\uff0c\u4f7f\u5f97hook\u51fd\u6570\u5bf9\u76ee\u6807\u53ef\u7528\u3002 hook\u51fd\u6570\u6700\u5e38\u4f7f\u7528\u5728\u67d0\u79cd\u6d41\u7a0b\u5904\u7406\u5f53\u4e2d\u3002\u8fd9\u4e2a\u6d41\u7a0b\u5f80\u5f80\u6709\u5f88\u591a\u6b65\u9aa4\u3002hook\u51fd\u6570\u5e38\u5e38\u6302\u8f7d\u5728\u8fd9\u4e9b\u6b65\u9aa4\u4e2d\uff0c\u4e3a\u589e\u52a0\u989d\u5916\u7684\u4e00\u4e9b\u64cd\u4f5c\uff0c\u63d0\u4f9b\u7075\u6d3b\u6027\u3002 \u4e0b\u9762\u4e3e\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff0c\u8fd9\u4e2a\u4f8b\u5b50\u7684\u76ee\u7684\u662f\u5b9e\u73b0\u4e00\u4e2a\u901a\u8fc7\u94a9\u5b50\u8c03\u7528\u51fd\u6570\u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u662f\"good\" # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license \"\"\" Callback utils \"\"\" class Callbacks : \"\"\" \" Handles all registered callbacks for YOLOv5 Hooks \"\"\" def __init__ ( self ): # Define the available callbacks self . _callbacks = { \"on_pretrain_routine_start\" : [], } self . stop_training = False # set True to interrupt training def register_action ( self , hook , name = \"\" , callback = None ): \"\"\" Register a new action to a callback hook Args: hook: The callback hook name to register the action to \u8981\u5411\u5176\u6ce8\u518c\u64cd\u4f5c\u7684\u56de\u8c03\u94a9\u5b50\u540d\u79f0 name: The name of the action for later reference \u52a8\u4f5c\u7684\u540d\u79f0\uff0c\u4f9b\u4ee5\u540e\u53c2\u8003 callback: The callback to fire \u5bf9fire\u7684\u56de\u8c03 \"\"\" assert hook in self . _callbacks , f \"hook ' { hook } ' not found in callbacks { self . _callbacks } \" assert callable ( callback ), f \"callback ' { callback } ' is not callable\" self . _callbacks [ hook ] . append ({ \"name\" : name , \"callback\" : callback }) def get_registered_actions ( self , hook = None ): \"\"\" \" Returns all the registered actions by callback hook Args: hook: The name of the hook to check, defaults to all \"\"\" return self . _callbacks [ hook ] if hook else self . _callbacks def run ( self , hook , * args , ** kwargs ): \"\"\" Loop through the registered actions and fire all callbacks Args: hook: The name of the hook to check, defaults to all args: Arguments to receive from YOLOv5 kwargs: Keyword Arguments to receive from YOLOv5 \"\"\" assert hook in self . _callbacks , f \"hook ' { hook } ' not found in callbacks { self . _callbacks } \" for logger in self . _callbacks [ hook ]: logger [ \"callback\" ]( * args , ** kwargs ) def on_pretrain_routine_start ( good : str ): if good == \"good\" : print ( \"is good!\" ) else : print ( \"is bad!\" ) # \u521d\u59cb\u5316 Callbacks \u5bf9\u8c61 callbacks = Callbacks () # \u8981\u5411\u5176\u6ce8\u518c\u64cd\u4f5c\u7684\u56de\u8c03\u94a9\u5b50\u540d\u79f0 callbacks . register_action ( hook = \"on_pretrain_routine_start\" , name = \"ss\" , callback = on_pretrain_routine_start ) # \u8c03\u7528hook callbacks . run ( \"on_pretrain_routine_start\" , \"good\" ) # \u6253\u5370hook\u4fe1\u606f callbacks . get_registered_actions ( \"on_pretrain_routine_start\" ) is good [{'name': 'ss', 'callback': <function __main__.on_pretrain_routine_start(good: str)>}]","title":"hook\u5b9e\u73b0\u4f8b\u5b50"},{"location":"source_code_interpretation/callbacks_py.html#yolov5","text":"\u5728yolov5\u8bad\u7ec3\u6d41\u7a0b\u4e2d\uff0chook\u51fd\u6570\u4f53\u73b0\u5728 \u4e00\u4e2a\u8bad\u7ec3\u8fc7\u7a0b(\u4e0d\u5305\u62ec\u6570\u636e\u51c6\u5907)\uff0c\u4f1a\u8f6e\u8be2\u591a\u6b21\u8bad\u7ec3\u96c6\uff0c\u6bcf\u6b21\u79f0\u4e3a\u4e00\u4e2aepoch\uff0c\u6bcf\u4e2aepoch\u53c8\u5206\u4e3a\u591a\u4e2abatch\u6765\u8bad\u7ec3\u3002 \u6d41\u7a0b\u5148\u540e\u62c6\u89e3\u6210: - \u5f00\u59cb\u8bad\u7ec3 - \u8bad\u7ec3\u4e00\u4e2aepoch\u524d - \u8bad\u7ec3\u4e00\u4e2abatch\u524d - \u8bad\u7ec3\u4e00\u4e2abatch\u540e - \u8bad\u7ec3\u4e00\u4e2aepoch\u540e\u3002 - \u8bc4\u4f30\u9a8c\u8bc1\u96c6 - \u7ed3\u675f\u8bad\u7ec3 \u8fd9\u4e9b\u6b65\u9aa4\u662f\u7a7f\u63d2\u5728\u8bad\u7ec3\u4e00\u4e2abatch\u6570\u636e\u7684\u8fc7\u7a0b\u4e2d\uff0c\u8fd9\u4e9b\u53ef\u4ee5\u7406\u89e3\u6210\u662f\u94a9\u5b50\u51fd\u6570\uff0c\u6211\u4eec\u53ef\u80fd\u9700\u8981\u5728\u8fd9\u4e9b\u94a9\u5b50\u51fd\u6570\u4e2d\u5b9e\u73b0\u4e00\u4e9b\u5b9a\u5236\u5316\u7684\u4e1c\u897f\uff0c\u6bd4\u5982\u5728\u8bad\u7ec3\u4e00\u4e2aepoch\u540e\u6211\u4eec\u8981\u4fdd\u5b58\u4e0b\u8bad\u7ec3\u7684\u635f\u5931\u3002 # \u5728train.py\u4e2dhook\u6ce8\u518c\u64cd\u4f5c\u4ee3\u7801 # Register actions for k in methods ( loggers ): callbacks . register_action ( k , callback = getattr ( loggers , k )) # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license \"\"\" Callback utils \"\"\" class Callbacks : \"\"\" \" Handles all registered callbacks for YOLOv5 Hooks \"\"\" def __init__ ( self ): # Define the available callbacks # \u5b9a\u4e49\u4e9b\u56de\u8c03\u51fd\u6570\uff0c\u51fd\u6570\u5b9e\u73b0\u5728utils/loggers/__init__.py # github\u94fe\u63a5: https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/loggers/__init__.py self . _callbacks = { \"on_pretrain_routine_start\" : [], # https://github.com/Oneflow-Inc/one-yolov5/blob/88864544cd9fa9ddcbe35a28a0bcf2c674daeb97/utils/loggers/__init__.py#L118 \"on_pretrain_routine_end\" : [], \"on_train_start\" : [], \"on_train_epoch_start\" : [], \"on_train_batch_start\" : [], \"optimizer_step\" : [], \"on_before_zero_grad\" : [], \"on_train_batch_end\" : [], \"on_train_epoch_end\" : [], \"on_val_start\" : [], \"on_val_batch_start\" : [], \"on_val_image_end\" : [], \"on_val_batch_end\" : [], \"on_val_end\" : [], \"on_fit_epoch_end\" : [], # fit = train + val \"on_model_save\" : [], \"on_train_end\" : [], \"on_params_update\" : [], \"teardown\" : [], } self . stop_training = False # set True to interrupt training def register_action ( self , hook , name = \"\" , callback = None ): \"\"\" Register a new action to a callback hook Args: hook: The callback hook name to register the action to name: The name of the action for later reference callback: The callback to fire \"\"\" assert hook in self . _callbacks , f \"hook ' { hook } ' not found in callbacks { self . _callbacks } \" assert callable ( callback ), f \"callback ' { callback } ' is not callable\" self . _callbacks [ hook ] . append ({ \"name\" : name , \"callback\" : callback }) def get_registered_actions ( self , hook = None ): \"\"\" \" Returns all the registered actions by callback hook Args: hook: The name of the hook to check, defaults to all \"\"\" return self . _callbacks [ hook ] if hook else self . _callbacks def run ( self , hook , * args , ** kwargs ): \"\"\" Loop through the registered actions and fire all callbacks Args: hook: The name of the hook to check, defaults to all args: Arguments to receive from YOLOv5 kwargs: Keyword Arguments to receive from YOLOv5 \"\"\" assert hook in self . _callbacks , f \"hook ' { hook } ' not found in callbacks { self . _callbacks } \" for logger in self . _callbacks [ hook ]: logger [ \"callback\" ]( * args , ** kwargs )","title":"yolov5\u9879\u76ee\u4e2d"},{"location":"source_code_interpretation/train_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a train.py \u8fd9\u4e2a\u6587\u4ef6\u662fyolov5\u7684\u8bad\u7ec3\u811a\u672c\u3002 \u603b\u4f53\u4ee3\u7801\u6d41\u7a0b\uff1a \u51c6\u5907\u5de5\u4f5c\uff1a \u6570\u636e + \u6a21\u578b + \u5b66\u4e60\u7387 + \u4f18\u5316\u5668 \u8bad\u7ec3\u8fc7\u7a0b: \u4e00\u4e2a\u8bad\u7ec3\u8fc7\u7a0b(\u4e0d\u5305\u62ec\u6570\u636e\u51c6\u5907)\uff0c\u4f1a\u8f6e\u8be2\u591a\u6b21\u8bad\u7ec3\u96c6\uff0c\u6bcf\u6b21\u79f0\u4e3a\u4e00\u4e2aepoch\uff0c\u6bcf\u4e2aepoch\u53c8\u5206\u4e3a\u591a\u4e2abatch\u6765\u8bad\u7ec3\u3002 \u6d41\u7a0b\u5148\u540e\u62c6\u89e3\u6210: \u5f00\u59cb\u8bad\u7ec3 \u8bad\u7ec3\u4e00\u4e2aepoch\u524d \u8bad\u7ec3\u4e00\u4e2abatch\u524d \u8bad\u7ec3\u4e00\u4e2abatch\u540e \u8bad\u7ec3\u4e00\u4e2aepoch\u540e\u3002 \u8bc4\u4f30\u9a8c\u8bc1\u96c6 \u7ed3\u675f\u8bad\u7ec3 1. \u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e import argparse # \u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570\u6a21\u5757 import math # \u6570\u5b66\u516c\u5f0f\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 \u5305\u542b\u6587\u4ef6\u8def\u5f84\u64cd\u4f5c\u548c\u89e3\u6790 import random # \u751f\u6210\u968f\u673a\u6570\u7684\u6a21\u5757 import sys # sys\u7cfb\u7edf\u6a21\u5757 \u5305\u542b\u4e86\u4e0ePython\u89e3\u91ca\u5668\u548c\u5b83\u7684\u73af\u5883\u6709\u5173\u7684\u51fd\u6570 import time # \u65f6\u95f4\u6a21\u5757 \u66f4\u5e95\u5c42 from copy import deepcopy # \u6df1\u62f7\u8d1d\u6a21\u5757 from datetime import datetime # \u57fa\u672c\u65e5\u671f\u548c\u65f6\u95f4\u7c7b\u578b\u6a21\u5757 from pathlib import Path # Path\u6a21\u5757\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c import numpy as np # numpy\u6570\u7ec4\u64cd\u4f5c\u6a21\u5757 import oneflow as flow # OneFlow\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 import oneflow.distributed as dist # \u5206\u5e03\u5f0f\u8bad\u7ec3\u6a21\u5757 import oneflow.nn as nn # \u5bf9oneflow.nn.functional\u7684\u7c7b\u7684\u5c01\u88c5 \u6709\u5f88\u591a\u548coneflow.nn.functional\u76f8\u540c\u7684\u51fd\u6570 import yaml # \u64cd\u4f5cyaml\u6587\u4ef6\u6a21\u5757 from oneflow.optim import lr_scheduler # \u5b66\u4e60\u7387\u6a21\u5757 from tqdm import tqdm # \u8fdb\u5ea6\u6761\u6a21\u5757 import val # \u5bfc\u5165val.py, for end-of-epoch mAP from models.experimental import attempt_load # \u5bfc\u5165\u5728\u7ebf\u4e0b\u8f7d\u6a21\u5757 from models.yolo import Model # \u5bfc\u5165YOLOv5\u7684\u6a21\u578b\u5b9a\u4e49 from utils.autoanchor import check_anchors # \u5bfc\u5165\u68c0\u67e5anchors\u5408\u6cd5\u6027\u7684\u51fd\u6570 # Callbacks https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/callbacks_py.html from utils.callbacks import Callbacks # \u548c\u65e5\u5fd7\u76f8\u5173\u7684\u56de\u8c03\u51fd\u6570 # dataloaders https://github.com/Oneflow-Inc/oneflow-yolo-doc/blob/master/docs/source_code_interpretation/utils/dataladers_py.md from utils.dataloaders import create_dataloader # \u52a0\u8f7d\u6570\u636e\u96c6\u7684\u51fd\u6570 # downloads https://github.com/Oneflow-Inc/oneflow-yolo-doc/blob/master/docs/source_code_interpretation/utils/downloads_py.md from utils.downloads import is_url # \u5224\u65ad\u5f53\u524d\u5b57\u7b26\u4e32\u662f\u5426\u662f\u94fe\u63a5 # general https://github.com/Oneflow-Inc/oneflow-yolo-doc/blob/master/docs/source_code_interpretation/utils/general_py.md from utils.general import check_img_size # check_suffix, from utils.general import ( LOGGER , check_dataset , check_file , check_git_status , check_requirements , check_yaml , colorstr , get_latest_run , increment_path , init_seeds , intersect_dicts , labels_to_class_weights , labels_to_image_weights , methods , one_cycle , print_args , print_mutation , strip_optimizer , yaml_save , model_save , ) from utils.loggers import Loggers # \u5bfc\u5165\u65e5\u5fd7\u7ba1\u7406\u6a21\u5757 from utils.loggers.wandb.wandb_utils import check_wandb_resume from utils.loss import ComputeLoss # \u5bfc\u5165\u8ba1\u7b97Loss\u7684\u6a21\u5757 # \u5728YOLOv5\u4e2d\uff0cfitness\u51fd\u6570\u5b9e\u73b0\u5bf9 [P, R, mAP@.5, mAP@.5-.95] \u6307\u6807\u8fdb\u884c\u52a0\u6743 from utils.metrics import fitness from utils.oneflow_utils import EarlyStopping , ModelEMA , de_parallel , select_device , smart_DDP , smart_optimizer , smart_resume # \u5bfc\u5165\u65e9\u505c\u673a\u5236\u6a21\u5757\uff0c\u6a21\u578b\u6ed1\u52a8\u5e73\u5747\u66f4\u65b0\u6a21\u5757\uff0c\u89e3\u5206\u5e03\u5f0f\u6a21\u5757\uff0c\u667a\u80fd\u9009\u62e9\u8bbe\u5907\uff0c\u667a\u80fd\u4f18\u5316\u5668\u4ee5\u53ca\u667a\u80fd\u65ad\u70b9\u7eed\u8bad\u6a21\u5757\u7b49 from utils.plots import plot_evolve , plot_labels # LOCAL_RANK\uff1a\u5f53\u524d\u8fdb\u7a0b\u5bf9\u5e94\u7684GPU\u53f7\u3002 LOCAL_RANK = int ( os . getenv ( \"LOCAL_RANK\" , - 1 )) # https://pytorch.org/docs/stable/elastic/run.html # RANK\uff1a\u5f53\u524d\u8fdb\u7a0b\u7684\u5e8f\u53f7\uff0c\u7528\u4e8e\u8fdb\u7a0b\u95f4\u901a\u8baf\uff0crank = 0 \u7684\u4e3b\u673a\u4e3a master \u8282\u70b9\u3002 RANK = int ( os . getenv ( \"RANK\" , - 1 )) # WORLD_SIZE\uff1a\u603b\u7684\u8fdb\u7a0b\u6570\u91cf (\u539f\u5219\u4e0a\u7b2c\u4e00\u4e2aprocess\u5360\u7528\u4e00\u4e2aGPU\u662f\u8f83\u4f18\u7684)\u3002 WORLD_SIZE = int ( os . getenv ( \"WORLD_SIZE\" , 1 )) # Linux \u4e0b\uff1a # FILE = 'path/to/one-yolov5/train.py' # \u5c06'path/to/one-yolov5'\u52a0\u5165\u7cfb\u7edf\u7684\u73af\u5883\u53d8\u91cf \u8be5\u811a\u672c\u7ed3\u675f\u540e\u5931\u6548\u3002 FILE = Path ( __file__ ) . resolve () ROOT = FILE . parents [ 0 ] # YOLOv5 root directory if str ( ROOT ) not in sys . path : sys . path . append ( str ( ROOT )) # add ROOT to PATH ROOT = Path ( os . path . relpath ( ROOT , Path . cwd ())) # relative 2. parse_opt \u51fd\u6570 \u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u8bbe\u7f6eopt\u53c2\u6570 weights: \u6743\u91cd\u6587\u4ef6 cfg: \u6a21\u578b\u914d\u7f6e\u6587\u4ef6 \u5305\u62ecnc\u3001depth_multiple\u3001width_multiple\u3001anchors\u3001backbone\u3001head\u7b49 data: \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6 \u5305\u62ecpath\u3001train\u3001val\u3001test\u3001nc\u3001names\u3001download\u7b49 hyp: \u521d\u59cb\u8d85\u53c2\u6587\u4ef6 epochs: \u8bad\u7ec3\u8f6e\u6b21 batch-size: \u8bad\u7ec3\u6279\u6b21\u5927\u5c0f img-size: \u8f93\u5165\u7f51\u7edc\u7684\u56fe\u7247\u5206\u8fa8\u7387\u5927\u5c0f resume: \u65ad\u70b9\u7eed\u8bad, \u4ece\u4e0a\u6b21\u6253\u65ad\u7684\u8bad\u7ec3\u7ed3\u679c\u5904\u63a5\u7740\u8bad\u7ec3 \u9ed8\u8ba4False nosave: \u4e0d\u4fdd\u5b58\u6a21\u578b \u9ed8\u8ba4False(\u4fdd\u5b58) True: only test final epoch notest: \u662f\u5426\u53ea\u6d4b\u8bd5\u6700\u540e\u4e00\u8f6e \u9ed8\u8ba4False True: \u53ea\u6d4b\u8bd5\u6700\u540e\u4e00\u8f6e False: \u6bcf\u8f6e\u8bad\u7ec3\u5b8c\u90fd\u6d4b\u8bd5mAP workers: dataloader\u4e2d\u7684\u6700\u5927work\u6570\uff08\u7ebf\u7a0b\u4e2a\u6570\uff09 device: \u8bad\u7ec3\u7684\u8bbe\u5907 single-cls: \u6570\u636e\u96c6\u662f\u5426\u53ea\u6709\u4e00\u4e2a\u7c7b\u522b \u9ed8\u8ba4False rect: \u8bad\u7ec3\u96c6\u662f\u5426\u91c7\u7528\u77e9\u5f62\u8bad\u7ec3 \u9ed8\u8ba4False \u53ef\u4ee5\u53c2\u8003\uff1ahttps://start.oneflow.org/oneflow-yolo-doc/tutorials/05_chapter/rectangular_reasoning.html noautoanchor: \u4e0d\u81ea\u52a8\u8c03\u6574anchor \u9ed8\u8ba4False(\u81ea\u52a8\u8c03\u6574anchor) evolve: \u662f\u5426\u8fdb\u884c\u8d85\u53c2\u8fdb\u5316 \u9ed8\u8ba4False multi-scale: \u662f\u5426\u4f7f\u7528\u591a\u5c3a\u5ea6\u8bad\u7ec3 \u9ed8\u8ba4False label-smoothing: \u6807\u7b7e\u5e73\u6ed1\u589e\u5f3a \u9ed8\u8ba40.0\u4e0d\u589e\u5f3a \u8981\u589e\u5f3a\u4e00\u822c\u5c31\u8bbe\u4e3a0.1 adam: \u662f\u5426\u4f7f\u7528adam\u4f18\u5316\u5668 \u9ed8\u8ba4False(\u4f7f\u7528SGD) sync-bn: \u662f\u5426\u4f7f\u7528\u8de8\u5361\u540c\u6b65BN\u64cd\u4f5c, \u5728DDP\u4e2d\u4f7f\u7528 \u9ed8\u8ba4False linear-lr: \u662f\u5426\u4f7f\u7528linear lr \u7ebf\u6027\u5b66\u4e60\u7387 \u9ed8\u8ba4False \u4f7f\u7528cosine lr cache-image: \u662f\u5426\u63d0\u524d\u7f13\u5b58\u56fe\u7247\u5230\u5185\u5b58cache,\u4ee5\u52a0\u901f\u8bad\u7ec3 \u9ed8\u8ba4False image-weights: \u662f\u5426\u4f7f\u7528\u56fe\u7247\u52a0\u6743\u9009\u62e9\u7b56\u7565(selection img to training by class weights) \u9ed8\u8ba4False \u4e0d\u4f7f\u7528 bucket: \u8c37\u6b4c\u4e91\u76d8bucket \u4e00\u822c\u7528\u4e0d\u5230 project: \u8bad\u7ec3\u7ed3\u679c\u4fdd\u5b58\u7684\u6839\u76ee\u5f55 \u9ed8\u8ba4\u662f runs/train name: \u8bad\u7ec3\u7ed3\u679c\u4fdd\u5b58\u7684\u76ee\u5f55 \u9ed8\u8ba4\u662fexp \u6700\u7ec8: runs/train/exp exist-ok: \u5982\u679c\u6587\u4ef6\u5b58\u5728\u5c31ok\u4e0d\u5b58\u5728\u5c31\u65b0\u5efa\u6216increment name \u9ed8\u8ba4False(\u9ed8\u8ba4\u6587\u4ef6\u90fd\u662f\u4e0d\u5b58\u5728\u7684) quad: dataloader\u53d6\u6570\u636e\u65f6, \u662f\u5426\u4f7f\u7528collate_fn4\u4ee3\u66ffcollate_fn \u9ed8\u8ba4False save_period: Log model after every \"save_period\" epoch, \u9ed8\u8ba4-1 \u4e0d\u9700\u8981log model \u4fe1\u606f artifact_alias: which version of dataset artifact to be stripped \u9ed8\u8ba4lastest \u8c8c\u4f3c\u6ca1\u7528\u5230\u8fd9\u4e2a\u53c2\u6570\uff1f local_rank: \u5f53\u524d\u8fdb\u7a0b\u5bf9\u5e94\u7684GPU\u53f7\u3002 -1\u4e14gpu=1\u65f6\u4e0d\u8fdb\u884c\u5206\u5e03\u5f0f entity: wandb entity \u9ed8\u8ba4None upload_dataset: \u662f\u5426\u4e0a\u4f20dataset\u5230wandb tabel(\u5c06\u6570\u636e\u96c6\u4f5c\u4e3a\u4ea4\u4e92\u5f0f dsviz\u8868 \u5728\u6d4f\u89c8\u5668\u4e2d\u67e5\u770b\u3001\u67e5\u8be2\u3001\u7b5b\u9009\u548c\u5206\u6790\u6570\u636e\u96c6) \u9ed8\u8ba4False bbox_interval: \u8bbe\u7f6e\u5e26\u8fb9\u754c\u6846\u56fe\u50cf\u8bb0\u5f55\u95f4\u9694 Set bounding-box image logging interval for W&B \u9ed8\u8ba4-1 opt.epochs // 10 bbox_iou_optim: \u8fd9\u4e2a\u53c2\u6570\u4ee3\u8868\u542f\u7528oneflow\u9488\u5bf9bbox_iou\u90e8\u5206\u7684\u4f18\u5316\uff0c\u4f7f\u5f97\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb \u66f4\u591a\u7ec6\u8282 \u8bf7\u70b9\u8fd9 3 main\u51fd\u6570 3.1 Checks def main ( opt , callbacks = Callbacks ()): # Checks if RANK in { - 1 , 0 }: # \u8f93\u51fa\u6240\u6709\u8bad\u7ec3opt\u53c2\u6570 train: ... print_args ( vars ( opt )) # \u68c0\u67e5\u4ee3\u7801\u7248\u672c\u662f\u5426\u662f\u6700\u65b0\u7684 github: ... check_git_status () # \u68c0\u67e5requirements.txt\u6240\u9700\u5305\u662f\u5426\u90fd\u6ee1\u8db3 requirements: ... check_requirements ( exclude = [ \"thop\" ]) 3.2 Resume \u5224\u65ad\u662f\u5426\u4f7f\u7528\u65ad\u70b9\u7eed\u8badresume, \u8bfb\u53d6\u53c2\u6570 \u4f7f\u7528\u65ad\u70b9\u7eed\u8bad \u5c31\u4ece path/to/last \u6a21\u578b\u6587\u4ef6\u5939\u4e2d\u8bfb\u53d6\u76f8\u5173\u53c2\u6570\uff1b\u4e0d\u4f7f\u7528\u65ad\u70b9\u7eed\u8bad \u5c31\u4ece\u6587\u4ef6\u4e2d\u8bfb\u53d6\u76f8\u5173\u53c2\u6570 # 2\u3001\u5224\u65ad\u662f\u5426\u4f7f\u7528\u65ad\u70b9\u7eed\u8badresume, \u8bfb\u53d6\u53c2\u6570 if opt . resume and not ( check_wandb_resume ( opt ) or opt . evolve ): # resume from specified or most recent last # \u4f7f\u7528\u65ad\u70b9\u7eed\u8bad \u5c31\u4ecelast\u6a21\u578b\u6587\u4ef6\u5939\u4e2d\u8bfb\u53d6\u76f8\u5173\u53c2\u6570 # \u5982\u679cresume\u662fstr\uff0c\u5219\u8868\u793a\u4f20\u5165\u7684\u662f\u6a21\u578b\u7684\u8def\u5f84\u5730\u5740 # \u5982\u679cresume\u662fTrue\uff0c\u5219\u901a\u8fc7get_lastest_run()\u51fd\u6570\u627e\u5230runs\u6587\u4ef6\u5939\u4e2d\u6700\u8fd1\u7684\u6743\u91cd\u6587\u4ef6last last = Path ( check_file ( opt . resume ) if isinstance ( opt . resume , str ) else get_latest_run ()) opt_yaml = last . parent . parent / \"opt.yaml\" # train options yaml opt_data = opt . data # original dataset if opt_yaml . is_file (): # \u76f8\u5173\u7684opt\u53c2\u6570\u4e5f\u8981\u66ff\u6362\u6210last\u4e2d\u7684opt\u53c2\u6570 with open ( opt_yaml , errors = \"ignore\" ) as f : d = yaml . safe_load ( f ) else : d = flow . load ( last , map_location = \"cpu\" )[ \"opt\" ] opt = argparse . Namespace ( ** d ) # replace opt . cfg , opt . weights , opt . resume = \"\" , str ( last ), True # reinstate if is_url ( opt_data ): opt . data = check_file ( opt_data ) # avoid HUB resume auth timeout else : # \u4e0d\u4f7f\u7528\u65ad\u70b9\u7eed\u8bad \u5c31\u4ece\u6587\u4ef6\u4e2d\u8bfb\u53d6\u76f8\u5173\u53c2\u6570 # opt.hyp = opt.hyp or ('hyp.finetune.yaml' if opt.weights else 'hyp.scratch.yaml') opt . data , opt . cfg , opt . hyp , opt . weights , opt . project = ( check_file ( opt . data ), check_yaml ( opt . cfg ), check_yaml ( opt . hyp ), str ( opt . weights ), str ( opt . project ), ) # checks assert len ( opt . cfg ) or len ( opt . weights ), \"either --cfg or --weights must be specified\" if opt . evolve : if opt . project == str ( ROOT / \"runs/train\" ): # if default project name, rename to runs/evolve opt . project = str ( ROOT / \"runs/evolve\" ) opt . exist_ok , opt . resume = ( opt . resume , False , ) # pass resume to exist_ok and disable resume if opt . name == \"cfg\" : opt . name = Path ( opt . cfg ) . stem # use model.yaml as name # \u6839\u636eopt.project\u751f\u6210\u76ee\u5f55 \u5982: runs/train/exp18 opt . save_dir = str ( increment_path ( Path ( opt . project ) / opt . name , exist_ok = opt . exist_ok )) 3.3 DDP mode DDP mode\u8bbe\u7f6e # 3\u3001DDP\u6a21\u5f0f\u7684\u8bbe\u7f6e \"\"\"select_device select_device \u51fd\u6570\uff1a \u8bbe\u7f6e\u5f53\u524d\u811a\u672c\u7684device\uff1acpu\u6216\u8005cuda\u3002 \u5e76\u4e14\u5f53\u4e14\u4ec5\u5f53\u4f7f\u7528cuda\u65f6\u5e76\u4e14\u6709\u591a\u5757gpu\u65f6\u53ef\u4ee5\u4f7f\u7528ddp\u6a21\u5f0f\uff0c\u5426\u5219\u629b\u51fa\u62a5\u9519\u4fe1\u606f\u3002batch_size\u9700\u8981\u6574\u9664\u603b\u7684\u8fdb\u7a0b\u6570\u91cf\u3002 \u53e6\u5916DDP\u6a21\u5f0f\u4e0d\u652f\u6301AutoBatch\u529f\u80fd\uff0c\u4f7f\u7528DDP\u6a21\u5f0f\u5fc5\u987b\u624b\u52a8\u6307\u5b9abatch size\u3002 \"\"\" device = select_device ( opt . device , batch_size = opt . batch_size ) if LOCAL_RANK != - 1 : msg = \"is not compatible with YOLOv5 Multi-GPU DDP training\" assert not opt . image_weights , f \"--image-weights { msg } \" assert not opt . evolve , f \"--evolve { msg } \" assert opt . batch_size != - 1 , f \"AutoBatch with --batch-size -1 { msg } , please pass a valid --batch-size\" assert opt . batch_size % WORLD_SIZE == 0 , f \"--batch-size { opt . batch_size } must be multiple of WORLD_SIZE\" assert flow . cuda . device_count () > LOCAL_RANK , \"insufficient CUDA devices for DDP command\" flow . cuda . set_device ( LOCAL_RANK ) device = flow . device ( \"cuda\" , LOCAL_RANK ) 3.4Train \u4e0d\u4f7f\u7528 \u8fdb\u5316\u7b97\u6cd5 \u6b63\u5e38Train # Train if not opt . evolve : # \u5982\u679c\u4e0d\u8fdb\u884c\u8d85\u53c2\u8fdb\u5316 \u90a3\u4e48\u5c31\u76f4\u63a5\u8c03\u7528train()\u51fd\u6570\uff0c\u5f00\u59cb\u8bad\u7ec3 train ( opt . hyp , opt , device , callbacks ) 3.5 Evolve hyperparameters (optional) \u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\uff0c\u5148\u8fdb\u5316\u51fa\u6700\u4f73\u8d85\u53c2\u540e\u8bad\u7ec3 # \u5426\u5219\u4f7f\u7528\u8d85\u53c2\u8fdb\u5316\u7b97\u6cd5(\u9057\u4f20\u7b97\u6cd5) \u6c42\u51fa\u6700\u4f73\u8d85\u53c2 \u518d\u8fdb\u884c\u8bad\u7ec3 else : # Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit) # \u8d85\u53c2\u8fdb\u5316\u5217\u8868 (\u7a81\u53d8\u89c4\u6a21, \u6700\u5c0f\u503c, \u6700\u5927\u503c) meta = { \"lr0\" : ( 1 , 1e-5 , 1e-1 ), # initial learning rate (SGD=1E-2, Adam=1E-3) \"lrf\" : ( 1 , 0.01 , 1.0 ), # final OneCycleLR learning rate (lr0 * lrf) \"momentum\" : ( 0.3 , 0.6 , 0.98 ), # SGD momentum/Adam beta1 \"weight_decay\" : ( 1 , 0.0 , 0.001 ), # optimizer weight decay \"warmup_epochs\" : ( 1 , 0.0 , 5.0 ), # warmup epochs (fractions ok) \"warmup_momentum\" : ( 1 , 0.0 , 0.95 ), # warmup initial momentum \"warmup_bias_lr\" : ( 1 , 0.0 , 0.2 ), # warmup initial bias lr \"box\" : ( 1 , 0.02 , 0.2 ), # box loss gain \"cls\" : ( 1 , 0.2 , 4.0 ), # cls loss gain \"cls_pw\" : ( 1 , 0.5 , 2.0 ), # cls BCELoss positive_weight \"obj\" : ( 1 , 0.2 , 4.0 ), # obj loss gain (scale with pixels) \"obj_pw\" : ( 1 , 0.5 , 2.0 ), # obj BCELoss positive_weight \"iou_t\" : ( 0 , 0.1 , 0.7 ), # IoU training threshold \"anchor_t\" : ( 1 , 2.0 , 8.0 ), # anchor-multiple threshold \"anchors\" : ( 2 , 2.0 , 10.0 ), # anchors per output grid (0 to ignore) \"fl_gamma\" : ( 0 , 0.0 , 2.0 ), # focal loss gamma (efficientDet default gamma=1.5) \"hsv_h\" : ( 1 , 0.0 , 0.1 ), # image HSV-Hue augmentation (fraction) \"hsv_s\" : ( 1 , 0.0 , 0.9 ), # image HSV-Saturation augmentation (fraction) \"hsv_v\" : ( 1 , 0.0 , 0.9 ), # image HSV-Value augmentation (fraction) \"degrees\" : ( 1 , 0.0 , 45.0 ), # image rotation (+/- deg) \"translate\" : ( 1 , 0.0 , 0.9 ), # image translation (+/- fraction) \"scale\" : ( 1 , 0.0 , 0.9 ), # image scale (+/- gain) \"shear\" : ( 1 , 0.0 , 10.0 ), # image shear (+/- deg) \"perspective\" : ( 0 , 0.0 , 0.001 ), # image perspective (+/- fraction), range 0-0.001 \"flipud\" : ( 1 , 0.0 , 1.0 ), # image flip up-down (probability) \"fliplr\" : ( 0 , 0.0 , 1.0 ), # image flip left-right (probability) \"mosaic\" : ( 1 , 0.0 , 1.0 ), # image mixup (probability) \"mixup\" : ( 1 , 0.0 , 1.0 ), # image mixup (probability) \"copy_paste\" : ( 1 , 0.0 , 1.0 ), } # segment copy-paste (probability) with open ( opt . hyp , errors = \"ignore\" ) as f : # \u8f7d\u5165\u521d\u59cb\u8d85\u53c2 hyp = yaml . safe_load ( f ) # load hyps dict if \"anchors\" not in hyp : # anchors commented in hyp.yaml hyp [ \"anchors\" ] = 3 opt . noval , opt . nosave , save_dir = ( True , True , Path ( opt . save_dir ), ) # only val/save final epoch # ei = [isinstance(x, (int, float)) for x in hyp.values()] # evolvable indices # evolve_yaml \u8d85\u53c2\u8fdb\u5316\u540e\u6587\u4ef6\u4fdd\u5b58\u5730\u5740 evolve_yaml , evolve_csv = save_dir / \"hyp_evolve.yaml\" , save_dir / \"evolve.csv\" if opt . bucket : os . system ( f \"gsutil cp gs:// { opt . bucket } /evolve.csv { evolve_csv } \" ) # download evolve.csv if exists \"\"\" \u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u53c2\u6570\u8fdb\u5316 \u9ed8\u8ba4\u662f\u8fdb\u5316300\u4ee3 \u8fd9\u91cc\u7684\u8fdb\u5316\u7b97\u6cd5\u539f\u7406\u4e3a\uff1a\u6839\u636e\u4e4b\u524d\u8bad\u7ec3\u65f6\u7684hyp\u6765\u786e\u5b9a\u4e00\u4e2abase hyp\u518d\u8fdb\u884c\u7a81\u53d8\uff0c\u5177\u4f53\u662f\u901a\u8fc7\u4e4b\u524d\u6bcf\u6b21\u8fdb\u5316\u5f97\u5230\u7684results\u6765\u786e\u5b9a\u4e4b\u524d\u6bcf\u4e2ahyp\u7684\u6743\u91cd\uff0c\u6709\u4e86\u6bcf\u4e2ahyp\u548c\u6bcf\u4e2ahyp\u7684\u6743\u91cd\u4e4b\u540e\u6709\u4e24\u79cd\u8fdb\u5316\u65b9\u5f0f\uff1b 1.\u6839\u636e\u6bcf\u4e2ahyp\u7684\u6743\u91cd\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u4e4b\u524d\u7684hyp\u4f5c\u4e3abase hyp\uff0crandom.choices(range(n), weights=w) 2.\u6839\u636e\u6bcf\u4e2ahyp\u7684\u6743\u91cd\u5bf9\u4e4b\u524d\u6240\u6709\u7684hyp\u8fdb\u884c\u878d\u5408\u83b7\u5f97\u4e00\u4e2abase hyp\uff0c(x * w.reshape(n, 1)).sum(0) / w.sum() evolve.txt\u4f1a\u8bb0\u5f55\u6bcf\u6b21\u8fdb\u5316\u4e4b\u540e\u7684results+hyp \u6bcf\u6b21\u8fdb\u5316\u65f6\uff0chyp\u4f1a\u6839\u636e\u4e4b\u524d\u7684results\u8fdb\u884c\u4ece\u5927\u5230\u5c0f\u7684\u6392\u5e8f\uff1b \u518d\u6839\u636efitness\u51fd\u6570\u8ba1\u7b97\u4e4b\u524d\u6bcf\u6b21\u8fdb\u5316\u5f97\u5230\u7684hyp\u7684\u6743\u91cd (\u5176\u4e2dfitness\u662f\u6211\u4eec\u5bfb\u6c42\u6700\u5927\u5316\u7684\u503c\u3002\u5728YOLOv5\u4e2d\uff0cfitness\u51fd\u6570\u5b9e\u73b0\u5bf9 [P, R, mAP@.5, mAP@.5-.95] \u6307\u6807\u8fdb\u884c\u52a0\u6743\u3002) \u518d\u786e\u5b9a\u54ea\u4e00\u79cd\u8fdb\u5316\u65b9\u5f0f\uff0c\u4ece\u800c\u8fdb\u884c\u8fdb\u5316\u3002 \u8fd9\u90e8\u5206\u4ee3\u7801\u5176\u5b9e\u4e0d\u662f\u5f88\u91cd\u8981\u5e76\u4e14\u4e5f\u6bd4\u8f83\u96be\u7406\u89e3\uff0c\u5927\u5bb6\u5982\u679c\u6ca1\u6709\u7279\u6b8a\u5fc5\u8981\u7684\u8bdd\u53ef\u4ee5\u5ffd\u7565\uff0c\u56e0\u4e3a\u6b63\u5e38\u8bad\u7ec3\u4e5f\u4e0d\u4f1a\u7528\u5230\u8d85\u53c2\u6570\u8fdb\u5316\u3002 \"\"\" for _ in range ( opt . evolve ): # generations to evolve if evolve_csv . exists (): # if evolve.csv exists: select best hyps and mutate # Select parent(s) parent = \"single\" # parent selection method: 'single' or 'weighted' x = np . loadtxt ( evolve_csv , ndmin = 2 , delimiter = \",\" , skiprows = 1 ) n = min ( 5 , len ( x )) # number of previous results to consider # fitness\u662f\u6211\u4eec\u5bfb\u6c42\u6700\u5927\u5316\u7684\u503c\u3002\u5728YOLOv5\u4e2d\uff0cfitness\u51fd\u6570\u5b9e\u73b0\u5bf9 [P, R, mAP@.5, mAP@.5-.95] \u6307\u6807\u8fdb\u884c\u52a0\u6743 x = x [ np . argsort ( - fitness ( x ))][: n ] # top n mutations w = fitness ( x ) - fitness ( x ) . min () + 1e-6 # weights (sum > 0) if parent == \"single\" or len ( x ) == 1 : # x = x[random.randint(0, n - 1)] # random selection x = x [ random . choices ( range ( n ), weights = w )[ 0 ]] # weighted selection elif parent == \"weighted\" : x = ( x * w . reshape ( n , 1 )) . sum ( 0 ) / w . sum () # weighted combination # Mutate mp , s = 0.8 , 0.2 # mutation probability, sigma npr = np . random npr . seed ( int ( time . time ())) g = np . array ([ meta [ k ][ 0 ] for k in hyp . keys ()]) # gains 0-1 ng = len ( meta ) v = np . ones ( ng ) while all ( v == 1 ): # mutate until a change occurs (prevent duplicates) v = ( g * ( npr . random ( ng ) < mp ) * npr . randn ( ng ) * npr . random () * s + 1 ) . clip ( 0.3 , 3.0 ) for i , k in enumerate ( hyp . keys ()): # plt.hist(v.ravel(), 300) hyp [ k ] = float ( x [ i + 7 ] * v [ i ]) # mutate # Constrain to limits for k , v in meta . items (): hyp [ k ] = max ( hyp [ k ], v [ 1 ]) # lower limit hyp [ k ] = min ( hyp [ k ], v [ 2 ]) # upper limit hyp [ k ] = round ( hyp [ k ], 5 ) # significant digits # Train mutation results = train ( hyp . copy (), opt , device , callbacks ) # callbacks https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/callbacks_py.html callbacks = Callbacks () # Write mutation results print_mutation ( results , hyp . copy (), save_dir , opt . bucket ) # Plot results plot_evolve ( evolve_csv ) LOGGER . info ( f \"Hyperparameter evolution finished { opt . evolve } generations \\n \" f \"Results saved to { colorstr ( 'bold' , save_dir ) } \\n \" f \"Usage example: $ python train.py --hyp { evolve_yaml } \" ) 4 def train(hyp, opt, device, callbacks): 4.1 \u8f7d\u5165\u53c2\u6570 \"\"\" :params hyp: data/hyps/hyp.scratch.yaml hyp dictionary :params opt: main\u4e2dopt\u53c2\u6570 :params device: \u5f53\u524d\u8bbe\u5907 :params callbacks: \u548c\u65e5\u5fd7\u76f8\u5173\u7684\u56de\u8c03\u51fd\u6570https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/callbacks_py.html \"\"\" def train ( hyp , opt , device , callbacks ): # hyp is path/to/hyp.yaml or hyp dictionary ( save_dir , epochs , batch_size , weights , single_cls , evolve , data , cfg , resume , noval , nosave , workers , freeze , bbox_iou_optim ) = ( Path ( opt . save_dir ), opt . epochs , opt . batch_size , opt . weights , opt . single_cls , opt . evolve , opt . data , opt . cfg , opt . resume , opt . noval , opt . nosave , opt . workers , opt . freeze , opt . bbox_iou_optim , ) 4.2 \u521d\u59cb\u5316\u53c2\u6570\u548c\u914d\u7f6e\u4fe1\u606f \u4e0b\u9762\u8f93\u51fa\u8d85\u53c2\u6570\u7684\u65f6\u5019\u622a\u56fe\u5982\u4e0b\uff1a # \u548c\u65e5\u5fd7\u76f8\u5173\u7684\u56de\u8c03\u51fd\u6570\uff0c\u8bb0\u5f55\u5f53\u524d\u4ee3\u7801\u6267\u884c\u7684\u9636\u6bb5 callbacks . run ( \"on_pretrain_routine_start\" ) # \u4fdd\u5b58\u6743\u91cd\u8def\u5f84 \u5982runs/train/exp18/weights w = save_dir / \"weights\" # weights dir ( w . parent if evolve else w ) . mkdir ( parents = True , exist_ok = True ) # make dir last , best = w / \"last\" , w / \"best\" # Hyperparameters \u8d85\u53c2 if isinstance ( hyp , str ): with open ( hyp , errors = \"ignore\" ) as f : # load hyps dict \u52a0\u8f7d\u8d85\u53c2\u4fe1\u606f hyp = yaml . safe_load ( f ) # load hyps dict # \u65e5\u5fd7\u8f93\u51fa\u8d85\u53c2\u4fe1\u606f hyperparameters: ... LOGGER . info ( colorstr ( \"hyperparameters: \" ) + \", \" . join ( f \" { k } = { v } \" for k , v in hyp . items ())) opt . hyp = hyp . copy () # for saving hyps to checkpoints # \u4fdd\u5b58\u8fd0\u884c\u65f6\u7684\u53c2\u6570\u914d\u7f6e if not evolve : yaml_save ( save_dir / \"hyp.yaml\" , hyp ) yaml_save ( save_dir / \"opt.yaml\" , vars ( opt )) # Loggers data_dict = None if RANK in { - 1 , 0 }: # \u521d\u59cb\u5316 Loggers \u5bf9\u8c61 # def __init__(self, save_dir=None, weights=None, opt=None, hyp=None, logger=None, include=LOGGERS): loggers = Loggers ( save_dir , weights , opt , hyp , LOGGER ) # loggers instance # Register actions for k in methods ( loggers ): # \u6ce8\u518c\u94a9\u5b50 https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/callbacks.py callbacks . register_action ( k , callback = getattr ( loggers , k )) # Config # \u662f\u5426\u9700\u8981\u753b\u56fe\uff1a \u6240\u6709\u7684labels\u4fe1\u606f\u3001\u8fed\u4ee3\u7684epochs\u3001\u8bad\u7ec3\u7ed3\u679c\u7b49 plots = not evolve and not opt . noplots # create plots cuda = device . type != \"cpu\" # \u521d\u59cb\u5316\u968f\u673a\u6570\u79cd\u5b50 init_seeds ( opt . seed + 1 + RANK , deterministic = True ) data_dict = data_dict or check_dataset ( data ) # check if None train_path , val_path = data_dict [ \"train\" ], data_dict [ \"val\" ] # nc: number of classes \u6570\u636e\u96c6\u6709\u591a\u5c11\u79cd\u7c7b\u522b nc = 1 if single_cls else int ( data_dict [ \"nc\" ]) # number of classes # \u5982\u679c\u53ea\u6709\u4e00\u4e2a\u7c7b\u522b\u5e76\u4e14data_dict\u91cc\u6ca1\u6709names\u8fd9\u4e2akey\u7684\u8bdd\uff0c\u6211\u4eec\u5c06names\u8bbe\u7f6e\u4e3a[\"item\"]\u4ee3\u8868\u76ee\u6807 names = [ \"item\" ] if single_cls and len ( data_dict [ \"names\" ]) != 1 else data_dict [ \"names\" ] # class names assert len ( names ) == nc , f \" { len ( names ) } names found for nc= { nc } dataset in { data } \" # check # \u5f53\u524d\u6570\u636e\u96c6\u662f\u5426\u662fcoco\u6570\u636e\u96c6(80\u4e2a\u7c7b\u522b) is_coco = isinstance ( val_path , str ) and val_path . endswith ( \"coco/val2017.txt\" ) # COCO dataset 4.3 model # \u68c0\u67e5\u6743\u91cd\u547d\u540d\u5408\u6cd5\u6027\uff1a # \u5408\u6cd5\uff1apretrained = True ; # \u4e0d\u5408\u6cd5: pretrained = False ; pretrained = check_wights ( weights ) # \u8f7d\u5165\u6a21\u578b if pretrained : # \u4f7f\u7528\u9884\u8bad\u7ec3 # ---------------------------------------------------------# # \u52a0\u8f7d\u6a21\u578b\u53ca\u53c2\u6570 ckpt = flow . load ( weights , map_location = \"cpu\" ) # load checkpoint to CPU to avoid CUDA memory leak # \u8fd9\u91cc\u52a0\u8f7d\u6a21\u578b\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u901a\u8fc7opt.cfg \u53e6\u4e00\u79cd\u662f\u901a\u8fc7ckpt['model'].yaml # \u533a\u522b\u5728\u4e8e\u662f\u5426\u4f7f\u7528resume \u5982\u679c\u4f7f\u7528resume\u4f1a\u5c06opt.cfg\u8bbe\u4e3a\u7a7a\uff0c\u6309\u7167ckpt['model'].yaml\u6765\u521b\u5efa\u6a21\u578b # \u8fd9\u4e5f\u5f71\u54cd\u4e86\u4e0b\u9762\u662f\u5426\u9664\u53bbanchor\u7684key(\u4e5f\u5c31\u662f\u4e0d\u52a0\u8f7danchor), \u5982\u679cresume\u5219\u4e0d\u52a0\u8f7danchor # \u539f\u56e0: \u4fdd\u5b58\u7684\u6a21\u578b\u4f1a\u4fdd\u5b58anchors\uff0c\u6709\u65f6\u5019\u7528\u6237\u81ea\u5b9a\u4e49\u4e86anchor\u4e4b\u540e\uff0c\u518dresume\uff0c\u5219\u539f\u6765\u57fa\u4e8ecoco\u6570\u636e\u96c6\u7684anchor\u4f1a\u81ea\u5df1\u8986\u76d6\u81ea\u5df1\u8bbe\u5b9a\u7684anchor # \u8be6\u60c5\u53c2\u8003: https://github.com/ultralytics/yolov5/issues/459 # \u6240\u4ee5\u4e0b\u9762\u8bbe\u7f6eintersect_dicts()\u5c31\u662f\u5ffd\u7565exclude model = Model ( cfg or ckpt [ \"model\" ] . yaml , ch = 3 , nc = nc , anchors = hyp . get ( \"anchors\" )) . to ( device ) # create exclude = [ \"anchor\" ] if ( cfg or hyp . get ( \"anchors\" )) and not resume else [] # exclude keys csd = ckpt [ \"model\" ] . float () . state_dict () # checkpoint state_dict as FP32 # \u7b5b\u9009\u5b57\u5178\u4e2d\u7684\u952e\u503c\u5bf9 \u628aexclude\u5220\u9664 csd = intersect_dicts ( csd , model . state_dict (), exclude = exclude ) # intersect # \u8f7d\u5165\u6a21\u578b\u6743\u91cd model . load_state_dict ( csd , strict = False ) # load LOGGER . info ( f \"Transferred { len ( csd ) } / { len ( model . state_dict ()) } items from { weights } \" ) # report else : # \u4e0d\u4f7f\u7528\u9884\u8bad\u7ec3 model = Model ( cfg , ch = 3 , nc = nc , anchors = hyp . get ( \"anchors\" )) . to ( device ) # create # \u6ce8\u610f\u4e00\u4e0b\uff1a one-yolov5\u7684amp\u8bad\u7ec3\u8fd8\u5728\u5f00\u53d1\u8c03\u8bd5\u4e2d\uff0c\u6682\u65f6\u5173\u95ed\uff0c\u540e\u7eed\u652f\u6301\u540e\u6253\u5f00\u3002\u4f46half\u7684\u63a8\u7406\u76ee\u524d\u6211\u4eec\u662f\u652f\u6301\u7684 # amp = check_amp(model) # check AMP amp = False # Freeze # \u51bb\u7ed3\u6743\u91cd\u5c42 # \u8fd9\u91cc\u53ea\u662f\u7ed9\u4e86\u51bb\u7ed3\u6743\u91cd\u5c42\u7684\u4e00\u4e2a\u4f8b\u5b50, \u4f46\u662f\u4f5c\u8005\u5e76\u4e0d\u5efa\u8bae\u51bb\u7ed3\u6743\u91cd\u5c42, \u8bad\u7ec3\u5168\u90e8\u5c42\u53c2\u6570, \u53ef\u4ee5\u5f97\u5230\u66f4\u597d\u7684\u6027\u80fd, \u4e0d\u8fc7\u4e5f\u4f1a\u66f4\u6162 freeze = [ f \"model. { x } .\" for x in ( freeze if len ( freeze ) > 1 else range ( freeze [ 0 ]))] # layers to freeze for k , v in model . named_parameters (): v . requires_grad = True # train all layers # NaN to 0 (commented for erratic training results) # v.register_hook(lambda x: torch.nan_to_num(x)) if any ( x in k for x in freeze ): LOGGER . info ( f \"freezing { k } \" ) v . requires_grad = False 4.4 Optimizer \u9009\u62e9\u4f18\u5316\u5668 # Optimizer nbs = 64 # nominal batch size accumulate = max ( round ( nbs / batch_size ), 1 ) # accumulate loss before optimizing hyp [ \"weight_decay\" ] *= batch_size * accumulate / nbs # scale weight_decay optimizer = smart_optimizer ( model , opt . optimizer , hyp [ \"lr0\" ], hyp [ \"momentum\" ], hyp [ \"weight_decay\" ]) 4.5 \u5b66\u4e60\u7387 # Scheduler if opt . cos_lr : # \u4f7f\u7528one cycle \u5b66\u4e60\u7387 https://arxiv.org/pdf/1803.09820.pdf lf = one_cycle ( 1 , hyp [ \"lrf\" ], epochs ) # cosine 1->hyp['lrf'] else : # \u4f7f\u7528\u7ebf\u6027\u5b66\u4e60\u7387 def f ( x ): return ( 1 - x / epochs ) * ( 1.0 - hyp [ \"lrf\" ]) + hyp [ \"lrf\" ] lf = f # linear # \u5b9e\u4f8b\u5316 scheduler scheduler = lr_scheduler . LambdaLR ( optimizer , lr_lambda = lf ) # plot_lr_scheduler(optimizer, scheduler, epochs) 4.6 EMA \u5355\u5361\u8bad\u7ec3: \u4f7f\u7528EMA\uff08\u6307\u6570\u79fb\u52a8\u5e73\u5747\uff09\u5bf9\u6a21\u578b\u7684\u53c2\u6570\u505a\u5e73\u5747, \u4e00\u79cd\u7ed9\u4e88\u8fd1\u671f\u6570\u636e\u66f4\u9ad8\u6743\u91cd\u7684\u5e73\u5747\u65b9\u6cd5, \u4ee5\u6c42\u63d0\u9ad8\u6d4b\u8bd5\u6307\u6807\u5e76\u589e\u52a0\u6a21\u578b\u9c81\u68d2\u3002 # EMA ema = ModelEMA ( model ) if RANK in { - 1 , 0 } else None 4.7 Resume \u65ad\u70b9\u7eed\u8bad # Resume best_fitness , start_epoch = 0.0 , 0 if pretrained : if resume : best_fitness , start_epoch , epochs = smart_resume ( ckpt , optimizer , ema , weights , epochs , resume ) del ckpt , csd 4.8 SyncBatchNorm SyncBatchNorm \u53ef\u4ee5\u63d0\u9ad8\u591agpu\u8bad\u7ec3\u7684\u51c6\u786e\u6027\uff0c\u4f46\u4f1a\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u901f\u5ea6\u3002\u5b83\u4ec5\u9002\u7528\u4e8e\u591aGPU DistributedDataParallel \u8bad\u7ec3\u3002 # SyncBatchNorm if opt . sync_bn and cuda and RANK != - 1 : model = flow . nn . SyncBatchNorm . convert_sync_batchnorm ( model ) . to ( device ) LOGGER . info ( \"Using SyncBatchNorm()\" ) 4.9 \u6570\u636e\u52a0\u8f7d # Trainloader https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/utils/dataladers_py.html train_loader , dataset = create_dataloader ( train_path , imgsz , batch_size // WORLD_SIZE , gs , single_cls , hyp = hyp , augment = True , cache = None if opt . cache == \"val\" else opt . cache , rect = opt . rect , rank = LOCAL_RANK , workers = workers , image_weights = opt . image_weights , quad = opt . quad , prefix = colorstr ( \"train: \" ), shuffle = True , ) labels = np . concatenate ( dataset . labels , 0 ) # \u83b7\u53d6\u6807\u7b7e\u4e2d\u6700\u5927\u7c7b\u522b\u503c\uff0c\u4e0e\u7c7b\u522b\u6570\u4f5c\u6bd4\u8f83\uff0c\u5982\u679c\u5927\u4e8e\u7b49\u4e8e\u7c7b\u522b\u6570\u5219\u8868\u793a\u6709\u95ee\u9898 mlc = int ( labels [:, 0 ] . max ()) # max label class assert mlc < nc , f \"Label class { mlc } exceeds nc= { nc } in { data } . Possible class labels are 0- { nc - 1 } \" # Process 0 if RANK in { - 1 , 0 }: val_loader = create_dataloader ( val_path , imgsz , batch_size // WORLD_SIZE * 2 , gs , single_cls , hyp = hyp , cache = None if noval else opt . cache , rect = True , rank =- 1 , workers = workers * 2 , pad = 0.5 , prefix = colorstr ( \"val: \" ), )[ 0 ] # \u5982\u679c\u4e0d\u4f7f\u7528\u65ad\u70b9\u7eed\u8bad if not resume : if plots : plot_labels ( labels , names , save_dir ) # Anchors # \u8ba1\u7b97\u9ed8\u8ba4\u951a\u6846anchor\u4e0e\u6570\u636e\u96c6\u6807\u7b7e\u6846\u7684\u9ad8\u5bbd\u6bd4 # \u6807\u7b7e\u7684\u9ad8h\u5bbdw\u4e0eanchor\u7684\u9ad8h_a\u5bbdh_b\u7684\u6bd4\u503c \u5373h/h_a, w/w_a\u90fd\u8981\u5728(1/hyp['anchor_t'], hyp['anchor_t'])\u662f\u53ef\u4ee5\u63a5\u53d7\u7684 # \u5982\u679cbpr\u5c0f\u4e8e98%\uff0c\u5219\u6839\u636ek-mean\u7b97\u6cd5\u805a\u7c7b\u65b0\u7684\u951a\u6846 if not opt . noautoanchor : # check_anchors : \u8fd9\u4e2a\u51fd\u6570\u662f\u901a\u8fc7\u8ba1\u7b97bpr\u786e\u5b9a\u662f\u5426\u9700\u8981\u6539\u53d8anchors \u9700\u8981\u5c31\u8c03\u7528k-means\u91cd\u65b0\u8ba1\u7b97anchors\u3002 # bpr(best possible recall): \u6700\u591a\u80fd\u88ab\u53ec\u56de\u7684ground truth\u6846\u6570\u91cf / \u6240\u6709ground truth\u6846\u6570\u91cf \u6700\u5927\u503c\u4e3a1 \u8d8a\u5927\u8d8a\u597d # \u5c0f\u4e8e0.98\u5c31\u9700\u8981\u4f7f\u7528k-means + \u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\u9009\u62e9\u51fa\u4e0e\u6570\u636e\u96c6\u66f4\u5339\u914d\u7684anchor boxes\u6846\u3002 check_anchors ( dataset , model = model , thr = hyp [ \"anchor_t\" ], imgsz = imgsz ) model . half () . float () # pre-reduce anchor precision callbacks . run ( \"on_pretrain_routine_end\" ) 4.10 DDP mode # DDP mode if cuda and RANK != - 1 : model = smart_DDP ( model ) 4.11 \u9644\u52a0model attributes # Model attributes nl = de_parallel ( model ) . model [ - 1 ] . nl # number of detection layers (to scale hyps) hyp [ \"box\" ] *= 3 / nl # scale to layers hyp [ \"cls\" ] *= nc / 80 * 3 / nl # scale to classes and layers hyp [ \"obj\" ] *= ( imgsz / 640 ) ** 2 * 3 / nl # scale to image size and layers hyp [ \"label_smoothing\" ] = opt . label_smoothing model . nc = nc # attach number of classes to model model . hyp = hyp # attach hyperparameters to model # \u4ece\u8bad\u7ec3\u6837\u672c\u6807\u7b7e\u5f97\u5230\u7c7b\u522b\u6743\u91cd\uff08\u548c\u7c7b\u522b\u4e2d\u7684\u76ee\u6807\u6570\u5373\u7c7b\u522b\u9891\u7387\u6210\u53cd\u6bd4\uff09 model . class_weights = labels_to_class_weights ( dataset . labels , nc ) . to ( device ) * nc # attach class weights model . names = names # \u83b7\u53d6\u7c7b\u522b\u540d 4.12 Start training # Start training t0 = time . time () nb = len ( train_loader ) # number of batches # \u83b7\u53d6\u9884\u70ed\u8fed\u4ee3\u7684\u6b21\u6570iterations # number of warmup iterations, max(3 epochs, 1k iterations) nw = max ( round ( hyp [ \"warmup_epochs\" ] * nb ), 100 ) # number of warmup iterations, max(3 epochs, 100 iterations) # nw = min(nw, (epochs - start_epoch) / 2 * nb) # limit warmup to < 1/2 of training last_opt_step = - 1 # \u521d\u59cb\u5316maps(\u6bcf\u4e2a\u7c7b\u522b\u7684map)\u548cresults maps = np . zeros ( nc ) # mAP per class results = ( 0 , 0 , 0 , 0 , 0 , 0 , 0 ) # P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls) # \u8bbe\u7f6e\u5b66\u4e60\u7387\u8870\u51cf\u6240\u8fdb\u884c\u5230\u7684\u8f6e\u6b21\uff0c\u5373\u4f7f\u6253\u65ad\u8bad\u7ec3\uff0c\u4f7f\u7528resume\u63a5\u7740\u8bad\u7ec3\u4e5f\u80fd\u6b63\u5e38\u8854\u63a5\u4e4b\u524d\u7684\u8bad\u7ec3\u8fdb\u884c\u5b66\u4e60\u7387\u8870\u51cf scheduler . last_epoch = start_epoch - 1 # do not move # scaler = flow.cuda.amp.GradScaler(enabled=amp) \u8fd9\u4e2a\u662f\u548camp\u76f8\u5173\u7684loss\u7f29\u653e\u6a21\u5757\uff0c\u540e\u7eedone-yolv5\u652f\u6301\u597damp\u8bad\u7ec3\u540e\u4f1a\u6253\u5f00 stopper , _ = EarlyStopping ( patience = opt . patience ), False # \u521d\u59cb\u5316\u635f\u5931\u51fd\u6570 # \u8fd9\u91cc\u7684bbox_iou_optim\u662fone-yolov5\u6269\u5c55\u7684\u4e00\u4e2a\u53c2\u6570\uff0c\u53ef\u4ee5\u542f\u7528\u66f4\u5feb\u7684bbox_iou\u51fd\u6570\uff0c\u6a21\u578b\u8bad\u7ec3\u901f\u5ea6\u6bd4PyTorch\u66f4\u5feb\u3002 compute_loss = ComputeLoss ( model , bbox_iou_optim = bbox_iou_optim ) # init loss class callbacks . run ( \"on_train_start\" ) # \u6253\u5370\u65e5\u5fd7\u4fe1\u606f LOGGER . info ( f \"Image sizes { imgsz } train, { imgsz } val \\n \" f \"Using { train_loader . num_workers * WORLD_SIZE } dataloader workers \\n \" f \"Logging results to { colorstr ( 'bold' , save_dir ) } \\n \" f \"Starting training for { epochs } epochs...\" ) for epoch in range ( start_epoch , epochs ): # epoch ------------------------------------------------------------------ callbacks . run ( \"on_train_epoch_start\" ) model . train () # Update image weights (optional, single-GPU only) # Update image weights (optional) \u5e76\u4e0d\u4e00\u5b9a\u597d \u9ed8\u8ba4\u662fFalse\u7684 # \u5982\u679c\u4e3aTrue \u8fdb\u884c\u56fe\u7247\u91c7\u6837\u7b56\u7565(\u6309\u6570\u636e\u96c6\u5404\u7c7b\u522b\u6743\u91cd\u91c7\u6837) if opt . image_weights : # \u6839\u636e\u524d\u9762\u521d\u59cb\u5316\u7684\u56fe\u7247\u91c7\u6837\u6743\u91cdmodel.class_weights\uff08\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd \u9891\u7387\u9ad8\u7684\u6743\u91cd\u5c0f\uff09\u4ee5\u53camaps\u914d\u5408\u6bcf\u5f20\u56fe\u7247\u5305\u542b\u7684\u7c7b\u522b\u6570 # \u901a\u8fc7rando.choices\u751f\u6210\u56fe\u7247\u7d22\u5f15indices\u4ece\u800c\u8fdb\u884c\u91c7\u7528 \uff08\u4f5c\u8005\u81ea\u5df1\u5199\u7684\u91c7\u6837\u7b56\u7565\uff0c\u6548\u679c\u4e0d\u4e00\u5b9aok\uff09 cw = model . class_weights . cpu () . numpy () * ( 1 - maps ) ** 2 / nc # class weights # labels_to_image_weights: \u8fd9\u4e2a\u51fd\u6570\u662f\u5229\u7528\u6bcf\u5f20\u56fe\u7247\u771f\u5b9egt\u6846\u7684\u771f\u5b9e\u6807\u7b7elabels\u548c\u5f00\u59cb\u8bad\u7ec3\u524d\u901a\u8fc7 labels_to_class_weights\u51fd\u6570 # \u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd\u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6bcf\u5f20\u56fe\u7247\u5bf9\u5e94\u7684\u6743\u91cd\u3002 # https://github.com/Oneflow-Inc/oneflow-yolo-doc/blob/master/docs/source_code_interpretation/utils/general_py.md#192-labels_to_image_weights iw = labels_to_image_weights ( dataset . labels , nc = nc , class_weights = cw ) # image weights dataset . indices = random . choices ( range ( dataset . n ), weights = iw , k = dataset . n ) # rand weighted idx # \u521d\u59cb\u5316\u8bad\u7ec3\u65f6\u6253\u5370\u7684\u5e73\u5747\u635f\u5931\u4fe1\u606f mloss = flow . zeros ( 3 , device = device ) # mean losses if RANK != - 1 : # DDP\u6a21\u5f0f\u6253\u4e71\u6570\u636e\uff0c\u5e76\u4e14ddp.sampler\u7684\u968f\u673a\u91c7\u6837\u6570\u636e\u662f\u57fa\u4e8eepoch+seed\u4f5c\u4e3a\u968f\u673a\u79cd\u5b50\uff0c\u6bcf\u6b21epoch\u4e0d\u540c\uff0c\u968f\u673a\u79cd\u5b50\u4e0d\u540c train_loader . sampler . set_epoch ( epoch ) # \u8fdb\u5ea6\u6761\uff0c\u65b9\u4fbf\u5c55\u793a\u4fe1\u606f pbar = enumerate ( train_loader ) LOGGER . info (( ' \\n ' + ' %11s ' * 7 ) % ( 'Epoch' , 'GPU_mem' , 'box_loss' , 'obj_loss' , 'cls_loss' , 'Instances' , 'Size' )) if RANK in { - 1 , 0 }: # \u521b\u5efa\u8fdb\u5ea6\u6761 pbar = tqdm ( pbar , total = nb , bar_format = \" {l_bar}{bar:10}{r_bar}{bar:-10b} \" ) # progress bar # \u68af\u5ea6\u6e05\u96f6 optimizer . zero_grad () for i , ( imgs , targets , paths , _ , ) in pbar : # batch ------------------------------------------------------------- callbacks . run ( \"on_train_batch_start\" ) # ni: \u8ba1\u7b97\u5f53\u524d\u8fed\u4ee3\u6b21\u6570 iteration ni = i + nb * epoch # number integrated batches (since train start) imgs = imgs . to ( device ) . float () / 255 # uint8 to float32, 0-255 to 0.0-1.0 # Warmup # \u9884\u70ed\u8bad\u7ec3\uff08\u524dnw\u6b21\u8fed\u4ee3\uff09\u70ed\u8eab\u8bad\u7ec3\u8fed\u4ee3\u7684\u6b21\u6570iteration\u8303\u56f4[1:nw] \u9009\u53d6\u8f83\u5c0f\u7684accumulate\uff0c\u5b66\u4e60\u7387\u4ee5\u53camomentum,\u6162\u6162\u7684\u8bad\u7ec3 if ni <= nw : xi = [ 0 , nw ] # x interp # compute_loss.gr = np.interp(ni, xi, [0.0, 1.0]) # iou loss ratio (obj_loss = 1.0 or iou) accumulate = max ( 1 , np . interp ( ni , xi , [ 1 , nbs / batch_size ]) . round ()) for j , x in enumerate ( optimizer . param_groups ): # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0 x [ \"lr\" ] = np . interp ( ni , xi , [ hyp [ \"warmup_bias_lr\" ] if j == 0 else 0.0 , x [ \"initial_lr\" ] * lf ( epoch )], ) if \"momentum\" in x : x [ \"momentum\" ] = np . interp ( ni , xi , [ hyp [ \"warmup_momentum\" ], hyp [ \"momentum\" ]]) # Multi-scale \u9ed8\u8ba4\u5173\u95ed # Multi-scale \u591a\u5c3a\u5ea6\u8bad\u7ec3 \u4ece[imgsz*0.5, imgsz*1.5+gs]\u95f4\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u5c3a\u5bf8(32\u7684\u500d\u6570)\u4f5c\u4e3a\u5f53\u524dbatch\u7684\u5c3a\u5bf8\u9001\u5165\u6a21\u578b\u5f00\u59cb\u8bad\u7ec3 # imgsz: \u9ed8\u8ba4\u8bad\u7ec3\u5c3a\u5bf8 gs: \u6a21\u578b\u6700\u5927stride=32 [32 16 8] if opt . multi_scale : sz = random . randrange ( imgsz * 0.5 , imgsz * 1.5 + gs ) // gs * gs # size sf = sz / max ( imgs . shape [ 2 :]) # scale factor if sf != 1 : ns = [ math . ceil ( x * sf / gs ) * gs for x in imgs . shape [ 2 :]] # new shape (stretched to gs-multiple) # \u4e0b\u91c7\u6837 imgs = nn . functional . interpolate ( imgs , size = ns , mode = \"bilinear\" , align_corners = False ) # Forward pred = model ( imgs ) # forward loss , loss_items = compute_loss ( pred , targets . to ( device )) # loss scaled by batch_size if RANK != - 1 : loss *= WORLD_SIZE # gradient averaged between devices in DDP mode if opt . quad : loss *= 4.0 # Backward # scaler.scale(loss).backward() # Backward \u53cd\u5411\u4f20\u64ad loss . backward () # Optimize - https://pytorch.org/docs/master/notes/amp_examples.html # \u6a21\u578b\u53cd\u5411\u4f20\u64adaccumulate\u6b21\uff08iterations\uff09\u540e\u518d\u6839\u636e\u7d2f\u8ba1\u7684\u68af\u5ea6\u66f4\u65b0\u4e00\u6b21\u53c2\u6570 if ni - last_opt_step >= accumulate : # optimizer.step \u53c2\u6570\u66f4\u65b0 optimizer . step () # \u68af\u5ea6\u6e05\u96f6 optimizer . zero_grad () if ema : # \u5f53\u524depoch\u8bad\u7ec3\u7ed3\u675f \u66f4\u65b0ema ema . update ( model ) last_opt_step = ni # Log # \u6253\u5370Print\u4e00\u4e9b\u4fe1\u606f \u5305\u62ec\u5f53\u524depoch\u3001\u663e\u5b58\u3001\u635f\u5931(box\u3001obj\u3001cls\u3001total)\u3001\u5f53\u524dbatch\u7684target\u7684\u6570\u91cf\u548c\u56fe\u7247\u7684size\u7b49\u4fe1\u606f if RANK in { - 1 , 0 }: mloss = ( mloss * i + loss_items ) / ( i + 1 ) # update mean losses pbar . set_description (( \" %11s \" + \" %11.4g \" * 5 ) % ( f \" { epoch } / { epochs - 1 } \" , * mloss , targets . shape [ 0 ], imgs . shape [ - 1 ])) # end batch ---------------------------------------------------------------- # Scheduler lr = [ x [ \"lr\" ] for x in optimizer . param_groups ] # for loggers scheduler . step () if RANK in { - 1 , 0 }: # mAP callbacks . run ( \"on_train_epoch_end\" , epoch = epoch ) ema . update_attr ( model , include = [ \"yaml\" , \"nc\" , \"hyp\" , \"names\" , \"stride\" , \"class_weights\" ]) final_epoch = ( epoch + 1 == epochs ) or stopper . possible_stop if not noval or final_epoch : # Calculate mAP # \u6d4b\u8bd5\u4f7f\u7528\u7684\u662fema\uff08\u6307\u6570\u79fb\u52a8\u5e73\u5747 \u5bf9\u6a21\u578b\u7684\u53c2\u6570\u505a\u5e73\u5747\uff09\u7684\u6a21\u578b # results: [1] Precision \u6240\u6709\u7c7b\u522b\u7684\u5e73\u5747precision(\u6700\u5927f1\u65f6) # [1] Recall \u6240\u6709\u7c7b\u522b\u7684\u5e73\u5747recall # [1] map@0.5 \u6240\u6709\u7c7b\u522b\u7684\u5e73\u5747mAP@0.5 # [1] map@0.5:0.95 \u6240\u6709\u7c7b\u522b\u7684\u5e73\u5747mAP@0.5:0.95 # [1] box_loss \u9a8c\u8bc1\u96c6\u56de\u5f52\u635f\u5931, obj_loss \u9a8c\u8bc1\u96c6\u7f6e\u4fe1\u5ea6\u635f\u5931, cls_loss \u9a8c\u8bc1\u96c6\u5206\u7c7b\u635f\u5931 # maps: [80] \u8bb0\u5f55\u6bcf\u4e00\u4e2a\u7c7b\u522b\u7684ap\u503c results , maps , _ = val . run ( data_dict , batch_size = batch_size // WORLD_SIZE * 2 , imgsz = imgsz , half = amp , model = ema . ema , single_cls = single_cls , dataloader = val_loader , save_dir = save_dir , plots = False , callbacks = callbacks , compute_loss = compute_loss , ) # Update best mAP # fi \u662f\u6211\u4eec\u5bfb\u6c42\u6700\u5927\u5316\u7684\u503c\u3002\u5728YOLOv5\u4e2d\uff0cfitness\u51fd\u6570\u5b9e\u73b0\u5bf9 [P, R, mAP@.5, mAP@.5-.95] \u6307\u6807\u8fdb\u884c\u52a0\u6743\u3002 fi = fitness ( np . array ( results ) . reshape ( 1 , - 1 )) # weighted combination of [P, R, mAP@.5, mAP@.5-.95] # stop = stopper(epoch=epoch, fitness=fi) # early stop check if fi > best_fitness : best_fitness = fi log_vals = list ( mloss ) + list ( results ) + lr callbacks . run ( \"on_fit_epoch_end\" , log_vals , epoch , best_fitness , fi ) # Save model if ( not nosave ) or ( final_epoch and not evolve ): # if save ckpt = { \"epoch\" : epoch , \"best_fitness\" : best_fitness , \"model\" : deepcopy ( de_parallel ( model )) . half (), \"ema\" : deepcopy ( ema . ema ) . half (), \"updates\" : ema . updates , \"optimizer\" : optimizer . state_dict (), \"wandb_id\" : loggers . wandb . wandb_run . id if loggers . wandb else None , \"opt\" : vars ( opt ), \"date\" : datetime . now () . isoformat (), } # Save last, best and delete model_save ( ckpt , last ) # flow.save(ckpt, last) if best_fitness == fi : model_save ( ckpt , best ) # flow.save(ckpt, best) if opt . save_period > 0 and epoch % opt . save_period == 0 : print ( \"is ok\" ) model_save ( ckpt , w / f \"epoch { epoch } \" ) # flow.save(ckpt, w / f\"epoch{epoch}\") del ckpt # Write \u5c06\u6d4b\u8bd5\u7ed3\u679c\u5199\u5165result.txt\u4e2d callbacks . run ( \"on_model_save\" , last , epoch , final_epoch , best_fitness , fi ) # end epoch -------------------------------------------------------------------------- # end training --------------------------------------------------------------------------- 4.13 End \u6253\u5370\u4e00\u4e9b\u4fe1\u606f \u65e5\u5fd7: \u6253\u5370\u8bad\u7ec3\u65f6\u95f4\u3001plots\u53ef\u89c6\u5316\u8bad\u7ec3\u7ed3\u679cresults1.png\u3001confusion_matrix.png \u4ee5\u53ca(\u2018F1\u2019, \u2018PR\u2019, \u2018P\u2019, \u2018R\u2019)\u66f2\u7ebf\u53d8\u5316 \u3001\u65e5\u5fd7\u4fe1\u606f \u901a\u8fc7\u8c03\u7528val.run() \u65b9\u6cd5\u9a8c\u8bc1\u5728 coco\u6570\u636e\u96c6\u4e0a \u6a21\u578b\u51c6\u786e\u6027 + \u91ca\u653e\u663e\u5b58 Validate a model's accuracy on COCO val or test-dev datasets. Note that pycocotools metrics may be ~1% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation. if RANK in { - 1 , 0 }: LOGGER . info ( f \" \\n { epoch - start_epoch + 1 } epochs completed in { ( time . time () - t0 ) / 3600 : .3f } hours\" ) for f in last , best : if f . exists (): strip_optimizer ( f ) # strip optimizers if f is best : LOGGER . info ( f \" \\n Validating { f } ...\" ) results , _ , _ = val . run ( data_dict , batch_size = batch_size // WORLD_SIZE * 2 , imgsz = imgsz , model = attempt_load ( f , device ) . half (), iou_thres = 0.65 if is_coco else 0.60 , # best pycocotools results at 0.65 single_cls = single_cls , dataloader = val_loader , save_dir = save_dir , save_json = is_coco , verbose = True , plots = plots , callbacks = callbacks , compute_loss = compute_loss , ) # val best model with plots callbacks . run ( \"on_train_end\" , last , best , plots , epoch , results ) flow . cuda . empty_cache () return 5 run\u51fd\u6570 \u5c01\u88c5train\u63a5\u53e3 \u652f\u6301\u51fd\u6570\u8c03\u7528\u6267\u884c\u8fd9\u4e2atrain.py\u811a\u672c def run ( ** kwargs ): # Usage: import train; train.run(data='coco128.yaml', imgsz=320, weights='yolov5m') opt = parse_opt ( True ) for k , v in kwargs . items (): setattr ( opt , k , v ) # \u7ed9opt\u6dfb\u52a0\u5c5e\u6027 main ( opt ) return opt 6 \u542f\u52a8\u8bad\u7ec3\u65f6\u6548\u679c\u5c55\u793a 7 \u53c2\u8003 \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011train.py Github: Laughing-q/yolov5_annotations CSDN Liaojiajia-2020: YOLOv5\u4ee3\u7801\u8be6\u89e3\uff08train.py\u90e8\u5206\uff09","title":"train.py"},{"location":"source_code_interpretation/train_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a train.py \u8fd9\u4e2a\u6587\u4ef6\u662fyolov5\u7684\u8bad\u7ec3\u811a\u672c\u3002 \u603b\u4f53\u4ee3\u7801\u6d41\u7a0b\uff1a \u51c6\u5907\u5de5\u4f5c\uff1a \u6570\u636e + \u6a21\u578b + \u5b66\u4e60\u7387 + \u4f18\u5316\u5668 \u8bad\u7ec3\u8fc7\u7a0b: \u4e00\u4e2a\u8bad\u7ec3\u8fc7\u7a0b(\u4e0d\u5305\u62ec\u6570\u636e\u51c6\u5907)\uff0c\u4f1a\u8f6e\u8be2\u591a\u6b21\u8bad\u7ec3\u96c6\uff0c\u6bcf\u6b21\u79f0\u4e3a\u4e00\u4e2aepoch\uff0c\u6bcf\u4e2aepoch\u53c8\u5206\u4e3a\u591a\u4e2abatch\u6765\u8bad\u7ec3\u3002 \u6d41\u7a0b\u5148\u540e\u62c6\u89e3\u6210: \u5f00\u59cb\u8bad\u7ec3 \u8bad\u7ec3\u4e00\u4e2aepoch\u524d \u8bad\u7ec3\u4e00\u4e2abatch\u524d \u8bad\u7ec3\u4e00\u4e2abatch\u540e \u8bad\u7ec3\u4e00\u4e2aepoch\u540e\u3002 \u8bc4\u4f30\u9a8c\u8bc1\u96c6 \u7ed3\u675f\u8bad\u7ec3","title":"\u524d\u8a00"},{"location":"source_code_interpretation/train_py.html#1","text":"import argparse # \u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570\u6a21\u5757 import math # \u6570\u5b66\u516c\u5f0f\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 \u5305\u542b\u6587\u4ef6\u8def\u5f84\u64cd\u4f5c\u548c\u89e3\u6790 import random # \u751f\u6210\u968f\u673a\u6570\u7684\u6a21\u5757 import sys # sys\u7cfb\u7edf\u6a21\u5757 \u5305\u542b\u4e86\u4e0ePython\u89e3\u91ca\u5668\u548c\u5b83\u7684\u73af\u5883\u6709\u5173\u7684\u51fd\u6570 import time # \u65f6\u95f4\u6a21\u5757 \u66f4\u5e95\u5c42 from copy import deepcopy # \u6df1\u62f7\u8d1d\u6a21\u5757 from datetime import datetime # \u57fa\u672c\u65e5\u671f\u548c\u65f6\u95f4\u7c7b\u578b\u6a21\u5757 from pathlib import Path # Path\u6a21\u5757\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c import numpy as np # numpy\u6570\u7ec4\u64cd\u4f5c\u6a21\u5757 import oneflow as flow # OneFlow\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 import oneflow.distributed as dist # \u5206\u5e03\u5f0f\u8bad\u7ec3\u6a21\u5757 import oneflow.nn as nn # \u5bf9oneflow.nn.functional\u7684\u7c7b\u7684\u5c01\u88c5 \u6709\u5f88\u591a\u548coneflow.nn.functional\u76f8\u540c\u7684\u51fd\u6570 import yaml # \u64cd\u4f5cyaml\u6587\u4ef6\u6a21\u5757 from oneflow.optim import lr_scheduler # \u5b66\u4e60\u7387\u6a21\u5757 from tqdm import tqdm # \u8fdb\u5ea6\u6761\u6a21\u5757 import val # \u5bfc\u5165val.py, for end-of-epoch mAP from models.experimental import attempt_load # \u5bfc\u5165\u5728\u7ebf\u4e0b\u8f7d\u6a21\u5757 from models.yolo import Model # \u5bfc\u5165YOLOv5\u7684\u6a21\u578b\u5b9a\u4e49 from utils.autoanchor import check_anchors # \u5bfc\u5165\u68c0\u67e5anchors\u5408\u6cd5\u6027\u7684\u51fd\u6570 # Callbacks https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/callbacks_py.html from utils.callbacks import Callbacks # \u548c\u65e5\u5fd7\u76f8\u5173\u7684\u56de\u8c03\u51fd\u6570 # dataloaders https://github.com/Oneflow-Inc/oneflow-yolo-doc/blob/master/docs/source_code_interpretation/utils/dataladers_py.md from utils.dataloaders import create_dataloader # \u52a0\u8f7d\u6570\u636e\u96c6\u7684\u51fd\u6570 # downloads https://github.com/Oneflow-Inc/oneflow-yolo-doc/blob/master/docs/source_code_interpretation/utils/downloads_py.md from utils.downloads import is_url # \u5224\u65ad\u5f53\u524d\u5b57\u7b26\u4e32\u662f\u5426\u662f\u94fe\u63a5 # general https://github.com/Oneflow-Inc/oneflow-yolo-doc/blob/master/docs/source_code_interpretation/utils/general_py.md from utils.general import check_img_size # check_suffix, from utils.general import ( LOGGER , check_dataset , check_file , check_git_status , check_requirements , check_yaml , colorstr , get_latest_run , increment_path , init_seeds , intersect_dicts , labels_to_class_weights , labels_to_image_weights , methods , one_cycle , print_args , print_mutation , strip_optimizer , yaml_save , model_save , ) from utils.loggers import Loggers # \u5bfc\u5165\u65e5\u5fd7\u7ba1\u7406\u6a21\u5757 from utils.loggers.wandb.wandb_utils import check_wandb_resume from utils.loss import ComputeLoss # \u5bfc\u5165\u8ba1\u7b97Loss\u7684\u6a21\u5757 # \u5728YOLOv5\u4e2d\uff0cfitness\u51fd\u6570\u5b9e\u73b0\u5bf9 [P, R, mAP@.5, mAP@.5-.95] \u6307\u6807\u8fdb\u884c\u52a0\u6743 from utils.metrics import fitness from utils.oneflow_utils import EarlyStopping , ModelEMA , de_parallel , select_device , smart_DDP , smart_optimizer , smart_resume # \u5bfc\u5165\u65e9\u505c\u673a\u5236\u6a21\u5757\uff0c\u6a21\u578b\u6ed1\u52a8\u5e73\u5747\u66f4\u65b0\u6a21\u5757\uff0c\u89e3\u5206\u5e03\u5f0f\u6a21\u5757\uff0c\u667a\u80fd\u9009\u62e9\u8bbe\u5907\uff0c\u667a\u80fd\u4f18\u5316\u5668\u4ee5\u53ca\u667a\u80fd\u65ad\u70b9\u7eed\u8bad\u6a21\u5757\u7b49 from utils.plots import plot_evolve , plot_labels # LOCAL_RANK\uff1a\u5f53\u524d\u8fdb\u7a0b\u5bf9\u5e94\u7684GPU\u53f7\u3002 LOCAL_RANK = int ( os . getenv ( \"LOCAL_RANK\" , - 1 )) # https://pytorch.org/docs/stable/elastic/run.html # RANK\uff1a\u5f53\u524d\u8fdb\u7a0b\u7684\u5e8f\u53f7\uff0c\u7528\u4e8e\u8fdb\u7a0b\u95f4\u901a\u8baf\uff0crank = 0 \u7684\u4e3b\u673a\u4e3a master \u8282\u70b9\u3002 RANK = int ( os . getenv ( \"RANK\" , - 1 )) # WORLD_SIZE\uff1a\u603b\u7684\u8fdb\u7a0b\u6570\u91cf (\u539f\u5219\u4e0a\u7b2c\u4e00\u4e2aprocess\u5360\u7528\u4e00\u4e2aGPU\u662f\u8f83\u4f18\u7684)\u3002 WORLD_SIZE = int ( os . getenv ( \"WORLD_SIZE\" , 1 )) # Linux \u4e0b\uff1a # FILE = 'path/to/one-yolov5/train.py' # \u5c06'path/to/one-yolov5'\u52a0\u5165\u7cfb\u7edf\u7684\u73af\u5883\u53d8\u91cf \u8be5\u811a\u672c\u7ed3\u675f\u540e\u5931\u6548\u3002 FILE = Path ( __file__ ) . resolve () ROOT = FILE . parents [ 0 ] # YOLOv5 root directory if str ( ROOT ) not in sys . path : sys . path . append ( str ( ROOT )) # add ROOT to PATH ROOT = Path ( os . path . relpath ( ROOT , Path . cwd ())) # relative","title":"1. \u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e"},{"location":"source_code_interpretation/train_py.html#2-parse_opt","text":"\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u8bbe\u7f6eopt\u53c2\u6570 weights: \u6743\u91cd\u6587\u4ef6 cfg: \u6a21\u578b\u914d\u7f6e\u6587\u4ef6 \u5305\u62ecnc\u3001depth_multiple\u3001width_multiple\u3001anchors\u3001backbone\u3001head\u7b49 data: \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6 \u5305\u62ecpath\u3001train\u3001val\u3001test\u3001nc\u3001names\u3001download\u7b49 hyp: \u521d\u59cb\u8d85\u53c2\u6587\u4ef6 epochs: \u8bad\u7ec3\u8f6e\u6b21 batch-size: \u8bad\u7ec3\u6279\u6b21\u5927\u5c0f img-size: \u8f93\u5165\u7f51\u7edc\u7684\u56fe\u7247\u5206\u8fa8\u7387\u5927\u5c0f resume: \u65ad\u70b9\u7eed\u8bad, \u4ece\u4e0a\u6b21\u6253\u65ad\u7684\u8bad\u7ec3\u7ed3\u679c\u5904\u63a5\u7740\u8bad\u7ec3 \u9ed8\u8ba4False nosave: \u4e0d\u4fdd\u5b58\u6a21\u578b \u9ed8\u8ba4False(\u4fdd\u5b58) True: only test final epoch notest: \u662f\u5426\u53ea\u6d4b\u8bd5\u6700\u540e\u4e00\u8f6e \u9ed8\u8ba4False True: \u53ea\u6d4b\u8bd5\u6700\u540e\u4e00\u8f6e False: \u6bcf\u8f6e\u8bad\u7ec3\u5b8c\u90fd\u6d4b\u8bd5mAP workers: dataloader\u4e2d\u7684\u6700\u5927work\u6570\uff08\u7ebf\u7a0b\u4e2a\u6570\uff09 device: \u8bad\u7ec3\u7684\u8bbe\u5907 single-cls: \u6570\u636e\u96c6\u662f\u5426\u53ea\u6709\u4e00\u4e2a\u7c7b\u522b \u9ed8\u8ba4False rect: \u8bad\u7ec3\u96c6\u662f\u5426\u91c7\u7528\u77e9\u5f62\u8bad\u7ec3 \u9ed8\u8ba4False \u53ef\u4ee5\u53c2\u8003\uff1ahttps://start.oneflow.org/oneflow-yolo-doc/tutorials/05_chapter/rectangular_reasoning.html noautoanchor: \u4e0d\u81ea\u52a8\u8c03\u6574anchor \u9ed8\u8ba4False(\u81ea\u52a8\u8c03\u6574anchor) evolve: \u662f\u5426\u8fdb\u884c\u8d85\u53c2\u8fdb\u5316 \u9ed8\u8ba4False multi-scale: \u662f\u5426\u4f7f\u7528\u591a\u5c3a\u5ea6\u8bad\u7ec3 \u9ed8\u8ba4False label-smoothing: \u6807\u7b7e\u5e73\u6ed1\u589e\u5f3a \u9ed8\u8ba40.0\u4e0d\u589e\u5f3a \u8981\u589e\u5f3a\u4e00\u822c\u5c31\u8bbe\u4e3a0.1 adam: \u662f\u5426\u4f7f\u7528adam\u4f18\u5316\u5668 \u9ed8\u8ba4False(\u4f7f\u7528SGD) sync-bn: \u662f\u5426\u4f7f\u7528\u8de8\u5361\u540c\u6b65BN\u64cd\u4f5c, \u5728DDP\u4e2d\u4f7f\u7528 \u9ed8\u8ba4False linear-lr: \u662f\u5426\u4f7f\u7528linear lr \u7ebf\u6027\u5b66\u4e60\u7387 \u9ed8\u8ba4False \u4f7f\u7528cosine lr cache-image: \u662f\u5426\u63d0\u524d\u7f13\u5b58\u56fe\u7247\u5230\u5185\u5b58cache,\u4ee5\u52a0\u901f\u8bad\u7ec3 \u9ed8\u8ba4False image-weights: \u662f\u5426\u4f7f\u7528\u56fe\u7247\u52a0\u6743\u9009\u62e9\u7b56\u7565(selection img to training by class weights) \u9ed8\u8ba4False \u4e0d\u4f7f\u7528 bucket: \u8c37\u6b4c\u4e91\u76d8bucket \u4e00\u822c\u7528\u4e0d\u5230 project: \u8bad\u7ec3\u7ed3\u679c\u4fdd\u5b58\u7684\u6839\u76ee\u5f55 \u9ed8\u8ba4\u662f runs/train name: \u8bad\u7ec3\u7ed3\u679c\u4fdd\u5b58\u7684\u76ee\u5f55 \u9ed8\u8ba4\u662fexp \u6700\u7ec8: runs/train/exp exist-ok: \u5982\u679c\u6587\u4ef6\u5b58\u5728\u5c31ok\u4e0d\u5b58\u5728\u5c31\u65b0\u5efa\u6216increment name \u9ed8\u8ba4False(\u9ed8\u8ba4\u6587\u4ef6\u90fd\u662f\u4e0d\u5b58\u5728\u7684) quad: dataloader\u53d6\u6570\u636e\u65f6, \u662f\u5426\u4f7f\u7528collate_fn4\u4ee3\u66ffcollate_fn \u9ed8\u8ba4False save_period: Log model after every \"save_period\" epoch, \u9ed8\u8ba4-1 \u4e0d\u9700\u8981log model \u4fe1\u606f artifact_alias: which version of dataset artifact to be stripped \u9ed8\u8ba4lastest \u8c8c\u4f3c\u6ca1\u7528\u5230\u8fd9\u4e2a\u53c2\u6570\uff1f local_rank: \u5f53\u524d\u8fdb\u7a0b\u5bf9\u5e94\u7684GPU\u53f7\u3002 -1\u4e14gpu=1\u65f6\u4e0d\u8fdb\u884c\u5206\u5e03\u5f0f entity: wandb entity \u9ed8\u8ba4None upload_dataset: \u662f\u5426\u4e0a\u4f20dataset\u5230wandb tabel(\u5c06\u6570\u636e\u96c6\u4f5c\u4e3a\u4ea4\u4e92\u5f0f dsviz\u8868 \u5728\u6d4f\u89c8\u5668\u4e2d\u67e5\u770b\u3001\u67e5\u8be2\u3001\u7b5b\u9009\u548c\u5206\u6790\u6570\u636e\u96c6) \u9ed8\u8ba4False bbox_interval: \u8bbe\u7f6e\u5e26\u8fb9\u754c\u6846\u56fe\u50cf\u8bb0\u5f55\u95f4\u9694 Set bounding-box image logging interval for W&B \u9ed8\u8ba4-1 opt.epochs // 10 bbox_iou_optim: \u8fd9\u4e2a\u53c2\u6570\u4ee3\u8868\u542f\u7528oneflow\u9488\u5bf9bbox_iou\u90e8\u5206\u7684\u4f18\u5316\uff0c\u4f7f\u5f97\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb \u66f4\u591a\u7ec6\u8282 \u8bf7\u70b9\u8fd9","title":"2. parse_opt \u51fd\u6570"},{"location":"source_code_interpretation/train_py.html#3-main","text":"","title":"3 main\u51fd\u6570"},{"location":"source_code_interpretation/train_py.html#31-checks","text":"def main ( opt , callbacks = Callbacks ()): # Checks if RANK in { - 1 , 0 }: # \u8f93\u51fa\u6240\u6709\u8bad\u7ec3opt\u53c2\u6570 train: ... print_args ( vars ( opt )) # \u68c0\u67e5\u4ee3\u7801\u7248\u672c\u662f\u5426\u662f\u6700\u65b0\u7684 github: ... check_git_status () # \u68c0\u67e5requirements.txt\u6240\u9700\u5305\u662f\u5426\u90fd\u6ee1\u8db3 requirements: ... check_requirements ( exclude = [ \"thop\" ])","title":"3.1 Checks"},{"location":"source_code_interpretation/train_py.html#32-resume","text":"\u5224\u65ad\u662f\u5426\u4f7f\u7528\u65ad\u70b9\u7eed\u8badresume, \u8bfb\u53d6\u53c2\u6570 \u4f7f\u7528\u65ad\u70b9\u7eed\u8bad \u5c31\u4ece path/to/last \u6a21\u578b\u6587\u4ef6\u5939\u4e2d\u8bfb\u53d6\u76f8\u5173\u53c2\u6570\uff1b\u4e0d\u4f7f\u7528\u65ad\u70b9\u7eed\u8bad \u5c31\u4ece\u6587\u4ef6\u4e2d\u8bfb\u53d6\u76f8\u5173\u53c2\u6570 # 2\u3001\u5224\u65ad\u662f\u5426\u4f7f\u7528\u65ad\u70b9\u7eed\u8badresume, \u8bfb\u53d6\u53c2\u6570 if opt . resume and not ( check_wandb_resume ( opt ) or opt . evolve ): # resume from specified or most recent last # \u4f7f\u7528\u65ad\u70b9\u7eed\u8bad \u5c31\u4ecelast\u6a21\u578b\u6587\u4ef6\u5939\u4e2d\u8bfb\u53d6\u76f8\u5173\u53c2\u6570 # \u5982\u679cresume\u662fstr\uff0c\u5219\u8868\u793a\u4f20\u5165\u7684\u662f\u6a21\u578b\u7684\u8def\u5f84\u5730\u5740 # \u5982\u679cresume\u662fTrue\uff0c\u5219\u901a\u8fc7get_lastest_run()\u51fd\u6570\u627e\u5230runs\u6587\u4ef6\u5939\u4e2d\u6700\u8fd1\u7684\u6743\u91cd\u6587\u4ef6last last = Path ( check_file ( opt . resume ) if isinstance ( opt . resume , str ) else get_latest_run ()) opt_yaml = last . parent . parent / \"opt.yaml\" # train options yaml opt_data = opt . data # original dataset if opt_yaml . is_file (): # \u76f8\u5173\u7684opt\u53c2\u6570\u4e5f\u8981\u66ff\u6362\u6210last\u4e2d\u7684opt\u53c2\u6570 with open ( opt_yaml , errors = \"ignore\" ) as f : d = yaml . safe_load ( f ) else : d = flow . load ( last , map_location = \"cpu\" )[ \"opt\" ] opt = argparse . Namespace ( ** d ) # replace opt . cfg , opt . weights , opt . resume = \"\" , str ( last ), True # reinstate if is_url ( opt_data ): opt . data = check_file ( opt_data ) # avoid HUB resume auth timeout else : # \u4e0d\u4f7f\u7528\u65ad\u70b9\u7eed\u8bad \u5c31\u4ece\u6587\u4ef6\u4e2d\u8bfb\u53d6\u76f8\u5173\u53c2\u6570 # opt.hyp = opt.hyp or ('hyp.finetune.yaml' if opt.weights else 'hyp.scratch.yaml') opt . data , opt . cfg , opt . hyp , opt . weights , opt . project = ( check_file ( opt . data ), check_yaml ( opt . cfg ), check_yaml ( opt . hyp ), str ( opt . weights ), str ( opt . project ), ) # checks assert len ( opt . cfg ) or len ( opt . weights ), \"either --cfg or --weights must be specified\" if opt . evolve : if opt . project == str ( ROOT / \"runs/train\" ): # if default project name, rename to runs/evolve opt . project = str ( ROOT / \"runs/evolve\" ) opt . exist_ok , opt . resume = ( opt . resume , False , ) # pass resume to exist_ok and disable resume if opt . name == \"cfg\" : opt . name = Path ( opt . cfg ) . stem # use model.yaml as name # \u6839\u636eopt.project\u751f\u6210\u76ee\u5f55 \u5982: runs/train/exp18 opt . save_dir = str ( increment_path ( Path ( opt . project ) / opt . name , exist_ok = opt . exist_ok ))","title":"3.2 Resume"},{"location":"source_code_interpretation/train_py.html#33-ddp-mode","text":"DDP mode\u8bbe\u7f6e # 3\u3001DDP\u6a21\u5f0f\u7684\u8bbe\u7f6e \"\"\"select_device select_device \u51fd\u6570\uff1a \u8bbe\u7f6e\u5f53\u524d\u811a\u672c\u7684device\uff1acpu\u6216\u8005cuda\u3002 \u5e76\u4e14\u5f53\u4e14\u4ec5\u5f53\u4f7f\u7528cuda\u65f6\u5e76\u4e14\u6709\u591a\u5757gpu\u65f6\u53ef\u4ee5\u4f7f\u7528ddp\u6a21\u5f0f\uff0c\u5426\u5219\u629b\u51fa\u62a5\u9519\u4fe1\u606f\u3002batch_size\u9700\u8981\u6574\u9664\u603b\u7684\u8fdb\u7a0b\u6570\u91cf\u3002 \u53e6\u5916DDP\u6a21\u5f0f\u4e0d\u652f\u6301AutoBatch\u529f\u80fd\uff0c\u4f7f\u7528DDP\u6a21\u5f0f\u5fc5\u987b\u624b\u52a8\u6307\u5b9abatch size\u3002 \"\"\" device = select_device ( opt . device , batch_size = opt . batch_size ) if LOCAL_RANK != - 1 : msg = \"is not compatible with YOLOv5 Multi-GPU DDP training\" assert not opt . image_weights , f \"--image-weights { msg } \" assert not opt . evolve , f \"--evolve { msg } \" assert opt . batch_size != - 1 , f \"AutoBatch with --batch-size -1 { msg } , please pass a valid --batch-size\" assert opt . batch_size % WORLD_SIZE == 0 , f \"--batch-size { opt . batch_size } must be multiple of WORLD_SIZE\" assert flow . cuda . device_count () > LOCAL_RANK , \"insufficient CUDA devices for DDP command\" flow . cuda . set_device ( LOCAL_RANK ) device = flow . device ( \"cuda\" , LOCAL_RANK )","title":"3.3  DDP mode"},{"location":"source_code_interpretation/train_py.html#34train","text":"\u4e0d\u4f7f\u7528 \u8fdb\u5316\u7b97\u6cd5 \u6b63\u5e38Train # Train if not opt . evolve : # \u5982\u679c\u4e0d\u8fdb\u884c\u8d85\u53c2\u8fdb\u5316 \u90a3\u4e48\u5c31\u76f4\u63a5\u8c03\u7528train()\u51fd\u6570\uff0c\u5f00\u59cb\u8bad\u7ec3 train ( opt . hyp , opt , device , callbacks )","title":"3.4Train"},{"location":"source_code_interpretation/train_py.html#35-evolve-hyperparameters-optional","text":"\u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\uff0c\u5148\u8fdb\u5316\u51fa\u6700\u4f73\u8d85\u53c2\u540e\u8bad\u7ec3 # \u5426\u5219\u4f7f\u7528\u8d85\u53c2\u8fdb\u5316\u7b97\u6cd5(\u9057\u4f20\u7b97\u6cd5) \u6c42\u51fa\u6700\u4f73\u8d85\u53c2 \u518d\u8fdb\u884c\u8bad\u7ec3 else : # Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit) # \u8d85\u53c2\u8fdb\u5316\u5217\u8868 (\u7a81\u53d8\u89c4\u6a21, \u6700\u5c0f\u503c, \u6700\u5927\u503c) meta = { \"lr0\" : ( 1 , 1e-5 , 1e-1 ), # initial learning rate (SGD=1E-2, Adam=1E-3) \"lrf\" : ( 1 , 0.01 , 1.0 ), # final OneCycleLR learning rate (lr0 * lrf) \"momentum\" : ( 0.3 , 0.6 , 0.98 ), # SGD momentum/Adam beta1 \"weight_decay\" : ( 1 , 0.0 , 0.001 ), # optimizer weight decay \"warmup_epochs\" : ( 1 , 0.0 , 5.0 ), # warmup epochs (fractions ok) \"warmup_momentum\" : ( 1 , 0.0 , 0.95 ), # warmup initial momentum \"warmup_bias_lr\" : ( 1 , 0.0 , 0.2 ), # warmup initial bias lr \"box\" : ( 1 , 0.02 , 0.2 ), # box loss gain \"cls\" : ( 1 , 0.2 , 4.0 ), # cls loss gain \"cls_pw\" : ( 1 , 0.5 , 2.0 ), # cls BCELoss positive_weight \"obj\" : ( 1 , 0.2 , 4.0 ), # obj loss gain (scale with pixels) \"obj_pw\" : ( 1 , 0.5 , 2.0 ), # obj BCELoss positive_weight \"iou_t\" : ( 0 , 0.1 , 0.7 ), # IoU training threshold \"anchor_t\" : ( 1 , 2.0 , 8.0 ), # anchor-multiple threshold \"anchors\" : ( 2 , 2.0 , 10.0 ), # anchors per output grid (0 to ignore) \"fl_gamma\" : ( 0 , 0.0 , 2.0 ), # focal loss gamma (efficientDet default gamma=1.5) \"hsv_h\" : ( 1 , 0.0 , 0.1 ), # image HSV-Hue augmentation (fraction) \"hsv_s\" : ( 1 , 0.0 , 0.9 ), # image HSV-Saturation augmentation (fraction) \"hsv_v\" : ( 1 , 0.0 , 0.9 ), # image HSV-Value augmentation (fraction) \"degrees\" : ( 1 , 0.0 , 45.0 ), # image rotation (+/- deg) \"translate\" : ( 1 , 0.0 , 0.9 ), # image translation (+/- fraction) \"scale\" : ( 1 , 0.0 , 0.9 ), # image scale (+/- gain) \"shear\" : ( 1 , 0.0 , 10.0 ), # image shear (+/- deg) \"perspective\" : ( 0 , 0.0 , 0.001 ), # image perspective (+/- fraction), range 0-0.001 \"flipud\" : ( 1 , 0.0 , 1.0 ), # image flip up-down (probability) \"fliplr\" : ( 0 , 0.0 , 1.0 ), # image flip left-right (probability) \"mosaic\" : ( 1 , 0.0 , 1.0 ), # image mixup (probability) \"mixup\" : ( 1 , 0.0 , 1.0 ), # image mixup (probability) \"copy_paste\" : ( 1 , 0.0 , 1.0 ), } # segment copy-paste (probability) with open ( opt . hyp , errors = \"ignore\" ) as f : # \u8f7d\u5165\u521d\u59cb\u8d85\u53c2 hyp = yaml . safe_load ( f ) # load hyps dict if \"anchors\" not in hyp : # anchors commented in hyp.yaml hyp [ \"anchors\" ] = 3 opt . noval , opt . nosave , save_dir = ( True , True , Path ( opt . save_dir ), ) # only val/save final epoch # ei = [isinstance(x, (int, float)) for x in hyp.values()] # evolvable indices # evolve_yaml \u8d85\u53c2\u8fdb\u5316\u540e\u6587\u4ef6\u4fdd\u5b58\u5730\u5740 evolve_yaml , evolve_csv = save_dir / \"hyp_evolve.yaml\" , save_dir / \"evolve.csv\" if opt . bucket : os . system ( f \"gsutil cp gs:// { opt . bucket } /evolve.csv { evolve_csv } \" ) # download evolve.csv if exists \"\"\" \u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u53c2\u6570\u8fdb\u5316 \u9ed8\u8ba4\u662f\u8fdb\u5316300\u4ee3 \u8fd9\u91cc\u7684\u8fdb\u5316\u7b97\u6cd5\u539f\u7406\u4e3a\uff1a\u6839\u636e\u4e4b\u524d\u8bad\u7ec3\u65f6\u7684hyp\u6765\u786e\u5b9a\u4e00\u4e2abase hyp\u518d\u8fdb\u884c\u7a81\u53d8\uff0c\u5177\u4f53\u662f\u901a\u8fc7\u4e4b\u524d\u6bcf\u6b21\u8fdb\u5316\u5f97\u5230\u7684results\u6765\u786e\u5b9a\u4e4b\u524d\u6bcf\u4e2ahyp\u7684\u6743\u91cd\uff0c\u6709\u4e86\u6bcf\u4e2ahyp\u548c\u6bcf\u4e2ahyp\u7684\u6743\u91cd\u4e4b\u540e\u6709\u4e24\u79cd\u8fdb\u5316\u65b9\u5f0f\uff1b 1.\u6839\u636e\u6bcf\u4e2ahyp\u7684\u6743\u91cd\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u4e4b\u524d\u7684hyp\u4f5c\u4e3abase hyp\uff0crandom.choices(range(n), weights=w) 2.\u6839\u636e\u6bcf\u4e2ahyp\u7684\u6743\u91cd\u5bf9\u4e4b\u524d\u6240\u6709\u7684hyp\u8fdb\u884c\u878d\u5408\u83b7\u5f97\u4e00\u4e2abase hyp\uff0c(x * w.reshape(n, 1)).sum(0) / w.sum() evolve.txt\u4f1a\u8bb0\u5f55\u6bcf\u6b21\u8fdb\u5316\u4e4b\u540e\u7684results+hyp \u6bcf\u6b21\u8fdb\u5316\u65f6\uff0chyp\u4f1a\u6839\u636e\u4e4b\u524d\u7684results\u8fdb\u884c\u4ece\u5927\u5230\u5c0f\u7684\u6392\u5e8f\uff1b \u518d\u6839\u636efitness\u51fd\u6570\u8ba1\u7b97\u4e4b\u524d\u6bcf\u6b21\u8fdb\u5316\u5f97\u5230\u7684hyp\u7684\u6743\u91cd (\u5176\u4e2dfitness\u662f\u6211\u4eec\u5bfb\u6c42\u6700\u5927\u5316\u7684\u503c\u3002\u5728YOLOv5\u4e2d\uff0cfitness\u51fd\u6570\u5b9e\u73b0\u5bf9 [P, R, mAP@.5, mAP@.5-.95] \u6307\u6807\u8fdb\u884c\u52a0\u6743\u3002) \u518d\u786e\u5b9a\u54ea\u4e00\u79cd\u8fdb\u5316\u65b9\u5f0f\uff0c\u4ece\u800c\u8fdb\u884c\u8fdb\u5316\u3002 \u8fd9\u90e8\u5206\u4ee3\u7801\u5176\u5b9e\u4e0d\u662f\u5f88\u91cd\u8981\u5e76\u4e14\u4e5f\u6bd4\u8f83\u96be\u7406\u89e3\uff0c\u5927\u5bb6\u5982\u679c\u6ca1\u6709\u7279\u6b8a\u5fc5\u8981\u7684\u8bdd\u53ef\u4ee5\u5ffd\u7565\uff0c\u56e0\u4e3a\u6b63\u5e38\u8bad\u7ec3\u4e5f\u4e0d\u4f1a\u7528\u5230\u8d85\u53c2\u6570\u8fdb\u5316\u3002 \"\"\" for _ in range ( opt . evolve ): # generations to evolve if evolve_csv . exists (): # if evolve.csv exists: select best hyps and mutate # Select parent(s) parent = \"single\" # parent selection method: 'single' or 'weighted' x = np . loadtxt ( evolve_csv , ndmin = 2 , delimiter = \",\" , skiprows = 1 ) n = min ( 5 , len ( x )) # number of previous results to consider # fitness\u662f\u6211\u4eec\u5bfb\u6c42\u6700\u5927\u5316\u7684\u503c\u3002\u5728YOLOv5\u4e2d\uff0cfitness\u51fd\u6570\u5b9e\u73b0\u5bf9 [P, R, mAP@.5, mAP@.5-.95] \u6307\u6807\u8fdb\u884c\u52a0\u6743 x = x [ np . argsort ( - fitness ( x ))][: n ] # top n mutations w = fitness ( x ) - fitness ( x ) . min () + 1e-6 # weights (sum > 0) if parent == \"single\" or len ( x ) == 1 : # x = x[random.randint(0, n - 1)] # random selection x = x [ random . choices ( range ( n ), weights = w )[ 0 ]] # weighted selection elif parent == \"weighted\" : x = ( x * w . reshape ( n , 1 )) . sum ( 0 ) / w . sum () # weighted combination # Mutate mp , s = 0.8 , 0.2 # mutation probability, sigma npr = np . random npr . seed ( int ( time . time ())) g = np . array ([ meta [ k ][ 0 ] for k in hyp . keys ()]) # gains 0-1 ng = len ( meta ) v = np . ones ( ng ) while all ( v == 1 ): # mutate until a change occurs (prevent duplicates) v = ( g * ( npr . random ( ng ) < mp ) * npr . randn ( ng ) * npr . random () * s + 1 ) . clip ( 0.3 , 3.0 ) for i , k in enumerate ( hyp . keys ()): # plt.hist(v.ravel(), 300) hyp [ k ] = float ( x [ i + 7 ] * v [ i ]) # mutate # Constrain to limits for k , v in meta . items (): hyp [ k ] = max ( hyp [ k ], v [ 1 ]) # lower limit hyp [ k ] = min ( hyp [ k ], v [ 2 ]) # upper limit hyp [ k ] = round ( hyp [ k ], 5 ) # significant digits # Train mutation results = train ( hyp . copy (), opt , device , callbacks ) # callbacks https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/callbacks_py.html callbacks = Callbacks () # Write mutation results print_mutation ( results , hyp . copy (), save_dir , opt . bucket ) # Plot results plot_evolve ( evolve_csv ) LOGGER . info ( f \"Hyperparameter evolution finished { opt . evolve } generations \\n \" f \"Results saved to { colorstr ( 'bold' , save_dir ) } \\n \" f \"Usage example: $ python train.py --hyp { evolve_yaml } \" )","title":"3.5 Evolve hyperparameters (optional)"},{"location":"source_code_interpretation/train_py.html#4-def-trainhyp-opt-device-callbacks","text":"","title":"4 def train(hyp, opt, device, callbacks):"},{"location":"source_code_interpretation/train_py.html#41","text":"\"\"\" :params hyp: data/hyps/hyp.scratch.yaml hyp dictionary :params opt: main\u4e2dopt\u53c2\u6570 :params device: \u5f53\u524d\u8bbe\u5907 :params callbacks: \u548c\u65e5\u5fd7\u76f8\u5173\u7684\u56de\u8c03\u51fd\u6570https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/callbacks_py.html \"\"\" def train ( hyp , opt , device , callbacks ): # hyp is path/to/hyp.yaml or hyp dictionary ( save_dir , epochs , batch_size , weights , single_cls , evolve , data , cfg , resume , noval , nosave , workers , freeze , bbox_iou_optim ) = ( Path ( opt . save_dir ), opt . epochs , opt . batch_size , opt . weights , opt . single_cls , opt . evolve , opt . data , opt . cfg , opt . resume , opt . noval , opt . nosave , opt . workers , opt . freeze , opt . bbox_iou_optim , )","title":"4.1 \u8f7d\u5165\u53c2\u6570"},{"location":"source_code_interpretation/train_py.html#42","text":"\u4e0b\u9762\u8f93\u51fa\u8d85\u53c2\u6570\u7684\u65f6\u5019\u622a\u56fe\u5982\u4e0b\uff1a # \u548c\u65e5\u5fd7\u76f8\u5173\u7684\u56de\u8c03\u51fd\u6570\uff0c\u8bb0\u5f55\u5f53\u524d\u4ee3\u7801\u6267\u884c\u7684\u9636\u6bb5 callbacks . run ( \"on_pretrain_routine_start\" ) # \u4fdd\u5b58\u6743\u91cd\u8def\u5f84 \u5982runs/train/exp18/weights w = save_dir / \"weights\" # weights dir ( w . parent if evolve else w ) . mkdir ( parents = True , exist_ok = True ) # make dir last , best = w / \"last\" , w / \"best\" # Hyperparameters \u8d85\u53c2 if isinstance ( hyp , str ): with open ( hyp , errors = \"ignore\" ) as f : # load hyps dict \u52a0\u8f7d\u8d85\u53c2\u4fe1\u606f hyp = yaml . safe_load ( f ) # load hyps dict # \u65e5\u5fd7\u8f93\u51fa\u8d85\u53c2\u4fe1\u606f hyperparameters: ... LOGGER . info ( colorstr ( \"hyperparameters: \" ) + \", \" . join ( f \" { k } = { v } \" for k , v in hyp . items ())) opt . hyp = hyp . copy () # for saving hyps to checkpoints # \u4fdd\u5b58\u8fd0\u884c\u65f6\u7684\u53c2\u6570\u914d\u7f6e if not evolve : yaml_save ( save_dir / \"hyp.yaml\" , hyp ) yaml_save ( save_dir / \"opt.yaml\" , vars ( opt )) # Loggers data_dict = None if RANK in { - 1 , 0 }: # \u521d\u59cb\u5316 Loggers \u5bf9\u8c61 # def __init__(self, save_dir=None, weights=None, opt=None, hyp=None, logger=None, include=LOGGERS): loggers = Loggers ( save_dir , weights , opt , hyp , LOGGER ) # loggers instance # Register actions for k in methods ( loggers ): # \u6ce8\u518c\u94a9\u5b50 https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/callbacks.py callbacks . register_action ( k , callback = getattr ( loggers , k )) # Config # \u662f\u5426\u9700\u8981\u753b\u56fe\uff1a \u6240\u6709\u7684labels\u4fe1\u606f\u3001\u8fed\u4ee3\u7684epochs\u3001\u8bad\u7ec3\u7ed3\u679c\u7b49 plots = not evolve and not opt . noplots # create plots cuda = device . type != \"cpu\" # \u521d\u59cb\u5316\u968f\u673a\u6570\u79cd\u5b50 init_seeds ( opt . seed + 1 + RANK , deterministic = True ) data_dict = data_dict or check_dataset ( data ) # check if None train_path , val_path = data_dict [ \"train\" ], data_dict [ \"val\" ] # nc: number of classes \u6570\u636e\u96c6\u6709\u591a\u5c11\u79cd\u7c7b\u522b nc = 1 if single_cls else int ( data_dict [ \"nc\" ]) # number of classes # \u5982\u679c\u53ea\u6709\u4e00\u4e2a\u7c7b\u522b\u5e76\u4e14data_dict\u91cc\u6ca1\u6709names\u8fd9\u4e2akey\u7684\u8bdd\uff0c\u6211\u4eec\u5c06names\u8bbe\u7f6e\u4e3a[\"item\"]\u4ee3\u8868\u76ee\u6807 names = [ \"item\" ] if single_cls and len ( data_dict [ \"names\" ]) != 1 else data_dict [ \"names\" ] # class names assert len ( names ) == nc , f \" { len ( names ) } names found for nc= { nc } dataset in { data } \" # check # \u5f53\u524d\u6570\u636e\u96c6\u662f\u5426\u662fcoco\u6570\u636e\u96c6(80\u4e2a\u7c7b\u522b) is_coco = isinstance ( val_path , str ) and val_path . endswith ( \"coco/val2017.txt\" ) # COCO dataset","title":"4.2 \u521d\u59cb\u5316\u53c2\u6570\u548c\u914d\u7f6e\u4fe1\u606f"},{"location":"source_code_interpretation/train_py.html#43-model","text":"# \u68c0\u67e5\u6743\u91cd\u547d\u540d\u5408\u6cd5\u6027\uff1a # \u5408\u6cd5\uff1apretrained = True ; # \u4e0d\u5408\u6cd5: pretrained = False ; pretrained = check_wights ( weights ) # \u8f7d\u5165\u6a21\u578b if pretrained : # \u4f7f\u7528\u9884\u8bad\u7ec3 # ---------------------------------------------------------# # \u52a0\u8f7d\u6a21\u578b\u53ca\u53c2\u6570 ckpt = flow . load ( weights , map_location = \"cpu\" ) # load checkpoint to CPU to avoid CUDA memory leak # \u8fd9\u91cc\u52a0\u8f7d\u6a21\u578b\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u79cd\u662f\u901a\u8fc7opt.cfg \u53e6\u4e00\u79cd\u662f\u901a\u8fc7ckpt['model'].yaml # \u533a\u522b\u5728\u4e8e\u662f\u5426\u4f7f\u7528resume \u5982\u679c\u4f7f\u7528resume\u4f1a\u5c06opt.cfg\u8bbe\u4e3a\u7a7a\uff0c\u6309\u7167ckpt['model'].yaml\u6765\u521b\u5efa\u6a21\u578b # \u8fd9\u4e5f\u5f71\u54cd\u4e86\u4e0b\u9762\u662f\u5426\u9664\u53bbanchor\u7684key(\u4e5f\u5c31\u662f\u4e0d\u52a0\u8f7danchor), \u5982\u679cresume\u5219\u4e0d\u52a0\u8f7danchor # \u539f\u56e0: \u4fdd\u5b58\u7684\u6a21\u578b\u4f1a\u4fdd\u5b58anchors\uff0c\u6709\u65f6\u5019\u7528\u6237\u81ea\u5b9a\u4e49\u4e86anchor\u4e4b\u540e\uff0c\u518dresume\uff0c\u5219\u539f\u6765\u57fa\u4e8ecoco\u6570\u636e\u96c6\u7684anchor\u4f1a\u81ea\u5df1\u8986\u76d6\u81ea\u5df1\u8bbe\u5b9a\u7684anchor # \u8be6\u60c5\u53c2\u8003: https://github.com/ultralytics/yolov5/issues/459 # \u6240\u4ee5\u4e0b\u9762\u8bbe\u7f6eintersect_dicts()\u5c31\u662f\u5ffd\u7565exclude model = Model ( cfg or ckpt [ \"model\" ] . yaml , ch = 3 , nc = nc , anchors = hyp . get ( \"anchors\" )) . to ( device ) # create exclude = [ \"anchor\" ] if ( cfg or hyp . get ( \"anchors\" )) and not resume else [] # exclude keys csd = ckpt [ \"model\" ] . float () . state_dict () # checkpoint state_dict as FP32 # \u7b5b\u9009\u5b57\u5178\u4e2d\u7684\u952e\u503c\u5bf9 \u628aexclude\u5220\u9664 csd = intersect_dicts ( csd , model . state_dict (), exclude = exclude ) # intersect # \u8f7d\u5165\u6a21\u578b\u6743\u91cd model . load_state_dict ( csd , strict = False ) # load LOGGER . info ( f \"Transferred { len ( csd ) } / { len ( model . state_dict ()) } items from { weights } \" ) # report else : # \u4e0d\u4f7f\u7528\u9884\u8bad\u7ec3 model = Model ( cfg , ch = 3 , nc = nc , anchors = hyp . get ( \"anchors\" )) . to ( device ) # create # \u6ce8\u610f\u4e00\u4e0b\uff1a one-yolov5\u7684amp\u8bad\u7ec3\u8fd8\u5728\u5f00\u53d1\u8c03\u8bd5\u4e2d\uff0c\u6682\u65f6\u5173\u95ed\uff0c\u540e\u7eed\u652f\u6301\u540e\u6253\u5f00\u3002\u4f46half\u7684\u63a8\u7406\u76ee\u524d\u6211\u4eec\u662f\u652f\u6301\u7684 # amp = check_amp(model) # check AMP amp = False # Freeze # \u51bb\u7ed3\u6743\u91cd\u5c42 # \u8fd9\u91cc\u53ea\u662f\u7ed9\u4e86\u51bb\u7ed3\u6743\u91cd\u5c42\u7684\u4e00\u4e2a\u4f8b\u5b50, \u4f46\u662f\u4f5c\u8005\u5e76\u4e0d\u5efa\u8bae\u51bb\u7ed3\u6743\u91cd\u5c42, \u8bad\u7ec3\u5168\u90e8\u5c42\u53c2\u6570, \u53ef\u4ee5\u5f97\u5230\u66f4\u597d\u7684\u6027\u80fd, \u4e0d\u8fc7\u4e5f\u4f1a\u66f4\u6162 freeze = [ f \"model. { x } .\" for x in ( freeze if len ( freeze ) > 1 else range ( freeze [ 0 ]))] # layers to freeze for k , v in model . named_parameters (): v . requires_grad = True # train all layers # NaN to 0 (commented for erratic training results) # v.register_hook(lambda x: torch.nan_to_num(x)) if any ( x in k for x in freeze ): LOGGER . info ( f \"freezing { k } \" ) v . requires_grad = False","title":"4.3 model"},{"location":"source_code_interpretation/train_py.html#44-optimizer","text":"\u9009\u62e9\u4f18\u5316\u5668 # Optimizer nbs = 64 # nominal batch size accumulate = max ( round ( nbs / batch_size ), 1 ) # accumulate loss before optimizing hyp [ \"weight_decay\" ] *= batch_size * accumulate / nbs # scale weight_decay optimizer = smart_optimizer ( model , opt . optimizer , hyp [ \"lr0\" ], hyp [ \"momentum\" ], hyp [ \"weight_decay\" ])","title":"4.4 Optimizer"},{"location":"source_code_interpretation/train_py.html#45","text":"# Scheduler if opt . cos_lr : # \u4f7f\u7528one cycle \u5b66\u4e60\u7387 https://arxiv.org/pdf/1803.09820.pdf lf = one_cycle ( 1 , hyp [ \"lrf\" ], epochs ) # cosine 1->hyp['lrf'] else : # \u4f7f\u7528\u7ebf\u6027\u5b66\u4e60\u7387 def f ( x ): return ( 1 - x / epochs ) * ( 1.0 - hyp [ \"lrf\" ]) + hyp [ \"lrf\" ] lf = f # linear # \u5b9e\u4f8b\u5316 scheduler scheduler = lr_scheduler . LambdaLR ( optimizer , lr_lambda = lf ) # plot_lr_scheduler(optimizer, scheduler, epochs)","title":"4.5 \u5b66\u4e60\u7387"},{"location":"source_code_interpretation/train_py.html#46-ema","text":"\u5355\u5361\u8bad\u7ec3: \u4f7f\u7528EMA\uff08\u6307\u6570\u79fb\u52a8\u5e73\u5747\uff09\u5bf9\u6a21\u578b\u7684\u53c2\u6570\u505a\u5e73\u5747, \u4e00\u79cd\u7ed9\u4e88\u8fd1\u671f\u6570\u636e\u66f4\u9ad8\u6743\u91cd\u7684\u5e73\u5747\u65b9\u6cd5, \u4ee5\u6c42\u63d0\u9ad8\u6d4b\u8bd5\u6307\u6807\u5e76\u589e\u52a0\u6a21\u578b\u9c81\u68d2\u3002 # EMA ema = ModelEMA ( model ) if RANK in { - 1 , 0 } else None","title":"4.6 EMA"},{"location":"source_code_interpretation/train_py.html#47-resume","text":"\u65ad\u70b9\u7eed\u8bad # Resume best_fitness , start_epoch = 0.0 , 0 if pretrained : if resume : best_fitness , start_epoch , epochs = smart_resume ( ckpt , optimizer , ema , weights , epochs , resume ) del ckpt , csd","title":"4.7 Resume"},{"location":"source_code_interpretation/train_py.html#48-syncbatchnorm","text":"SyncBatchNorm \u53ef\u4ee5\u63d0\u9ad8\u591agpu\u8bad\u7ec3\u7684\u51c6\u786e\u6027\uff0c\u4f46\u4f1a\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u901f\u5ea6\u3002\u5b83\u4ec5\u9002\u7528\u4e8e\u591aGPU DistributedDataParallel \u8bad\u7ec3\u3002 # SyncBatchNorm if opt . sync_bn and cuda and RANK != - 1 : model = flow . nn . SyncBatchNorm . convert_sync_batchnorm ( model ) . to ( device ) LOGGER . info ( \"Using SyncBatchNorm()\" )","title":"4.8 SyncBatchNorm"},{"location":"source_code_interpretation/train_py.html#49","text":"# Trainloader https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/utils/dataladers_py.html train_loader , dataset = create_dataloader ( train_path , imgsz , batch_size // WORLD_SIZE , gs , single_cls , hyp = hyp , augment = True , cache = None if opt . cache == \"val\" else opt . cache , rect = opt . rect , rank = LOCAL_RANK , workers = workers , image_weights = opt . image_weights , quad = opt . quad , prefix = colorstr ( \"train: \" ), shuffle = True , ) labels = np . concatenate ( dataset . labels , 0 ) # \u83b7\u53d6\u6807\u7b7e\u4e2d\u6700\u5927\u7c7b\u522b\u503c\uff0c\u4e0e\u7c7b\u522b\u6570\u4f5c\u6bd4\u8f83\uff0c\u5982\u679c\u5927\u4e8e\u7b49\u4e8e\u7c7b\u522b\u6570\u5219\u8868\u793a\u6709\u95ee\u9898 mlc = int ( labels [:, 0 ] . max ()) # max label class assert mlc < nc , f \"Label class { mlc } exceeds nc= { nc } in { data } . Possible class labels are 0- { nc - 1 } \" # Process 0 if RANK in { - 1 , 0 }: val_loader = create_dataloader ( val_path , imgsz , batch_size // WORLD_SIZE * 2 , gs , single_cls , hyp = hyp , cache = None if noval else opt . cache , rect = True , rank =- 1 , workers = workers * 2 , pad = 0.5 , prefix = colorstr ( \"val: \" ), )[ 0 ] # \u5982\u679c\u4e0d\u4f7f\u7528\u65ad\u70b9\u7eed\u8bad if not resume : if plots : plot_labels ( labels , names , save_dir ) # Anchors # \u8ba1\u7b97\u9ed8\u8ba4\u951a\u6846anchor\u4e0e\u6570\u636e\u96c6\u6807\u7b7e\u6846\u7684\u9ad8\u5bbd\u6bd4 # \u6807\u7b7e\u7684\u9ad8h\u5bbdw\u4e0eanchor\u7684\u9ad8h_a\u5bbdh_b\u7684\u6bd4\u503c \u5373h/h_a, w/w_a\u90fd\u8981\u5728(1/hyp['anchor_t'], hyp['anchor_t'])\u662f\u53ef\u4ee5\u63a5\u53d7\u7684 # \u5982\u679cbpr\u5c0f\u4e8e98%\uff0c\u5219\u6839\u636ek-mean\u7b97\u6cd5\u805a\u7c7b\u65b0\u7684\u951a\u6846 if not opt . noautoanchor : # check_anchors : \u8fd9\u4e2a\u51fd\u6570\u662f\u901a\u8fc7\u8ba1\u7b97bpr\u786e\u5b9a\u662f\u5426\u9700\u8981\u6539\u53d8anchors \u9700\u8981\u5c31\u8c03\u7528k-means\u91cd\u65b0\u8ba1\u7b97anchors\u3002 # bpr(best possible recall): \u6700\u591a\u80fd\u88ab\u53ec\u56de\u7684ground truth\u6846\u6570\u91cf / \u6240\u6709ground truth\u6846\u6570\u91cf \u6700\u5927\u503c\u4e3a1 \u8d8a\u5927\u8d8a\u597d # \u5c0f\u4e8e0.98\u5c31\u9700\u8981\u4f7f\u7528k-means + \u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\u9009\u62e9\u51fa\u4e0e\u6570\u636e\u96c6\u66f4\u5339\u914d\u7684anchor boxes\u6846\u3002 check_anchors ( dataset , model = model , thr = hyp [ \"anchor_t\" ], imgsz = imgsz ) model . half () . float () # pre-reduce anchor precision callbacks . run ( \"on_pretrain_routine_end\" )","title":"4.9 \u6570\u636e\u52a0\u8f7d"},{"location":"source_code_interpretation/train_py.html#410-ddp-mode","text":"# DDP mode if cuda and RANK != - 1 : model = smart_DDP ( model )","title":"4.10 DDP mode"},{"location":"source_code_interpretation/train_py.html#411-model-attributes","text":"# Model attributes nl = de_parallel ( model ) . model [ - 1 ] . nl # number of detection layers (to scale hyps) hyp [ \"box\" ] *= 3 / nl # scale to layers hyp [ \"cls\" ] *= nc / 80 * 3 / nl # scale to classes and layers hyp [ \"obj\" ] *= ( imgsz / 640 ) ** 2 * 3 / nl # scale to image size and layers hyp [ \"label_smoothing\" ] = opt . label_smoothing model . nc = nc # attach number of classes to model model . hyp = hyp # attach hyperparameters to model # \u4ece\u8bad\u7ec3\u6837\u672c\u6807\u7b7e\u5f97\u5230\u7c7b\u522b\u6743\u91cd\uff08\u548c\u7c7b\u522b\u4e2d\u7684\u76ee\u6807\u6570\u5373\u7c7b\u522b\u9891\u7387\u6210\u53cd\u6bd4\uff09 model . class_weights = labels_to_class_weights ( dataset . labels , nc ) . to ( device ) * nc # attach class weights model . names = names # \u83b7\u53d6\u7c7b\u522b\u540d","title":"4.11 \u9644\u52a0model attributes"},{"location":"source_code_interpretation/train_py.html#412-start-training","text":"# Start training t0 = time . time () nb = len ( train_loader ) # number of batches # \u83b7\u53d6\u9884\u70ed\u8fed\u4ee3\u7684\u6b21\u6570iterations # number of warmup iterations, max(3 epochs, 1k iterations) nw = max ( round ( hyp [ \"warmup_epochs\" ] * nb ), 100 ) # number of warmup iterations, max(3 epochs, 100 iterations) # nw = min(nw, (epochs - start_epoch) / 2 * nb) # limit warmup to < 1/2 of training last_opt_step = - 1 # \u521d\u59cb\u5316maps(\u6bcf\u4e2a\u7c7b\u522b\u7684map)\u548cresults maps = np . zeros ( nc ) # mAP per class results = ( 0 , 0 , 0 , 0 , 0 , 0 , 0 ) # P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls) # \u8bbe\u7f6e\u5b66\u4e60\u7387\u8870\u51cf\u6240\u8fdb\u884c\u5230\u7684\u8f6e\u6b21\uff0c\u5373\u4f7f\u6253\u65ad\u8bad\u7ec3\uff0c\u4f7f\u7528resume\u63a5\u7740\u8bad\u7ec3\u4e5f\u80fd\u6b63\u5e38\u8854\u63a5\u4e4b\u524d\u7684\u8bad\u7ec3\u8fdb\u884c\u5b66\u4e60\u7387\u8870\u51cf scheduler . last_epoch = start_epoch - 1 # do not move # scaler = flow.cuda.amp.GradScaler(enabled=amp) \u8fd9\u4e2a\u662f\u548camp\u76f8\u5173\u7684loss\u7f29\u653e\u6a21\u5757\uff0c\u540e\u7eedone-yolv5\u652f\u6301\u597damp\u8bad\u7ec3\u540e\u4f1a\u6253\u5f00 stopper , _ = EarlyStopping ( patience = opt . patience ), False # \u521d\u59cb\u5316\u635f\u5931\u51fd\u6570 # \u8fd9\u91cc\u7684bbox_iou_optim\u662fone-yolov5\u6269\u5c55\u7684\u4e00\u4e2a\u53c2\u6570\uff0c\u53ef\u4ee5\u542f\u7528\u66f4\u5feb\u7684bbox_iou\u51fd\u6570\uff0c\u6a21\u578b\u8bad\u7ec3\u901f\u5ea6\u6bd4PyTorch\u66f4\u5feb\u3002 compute_loss = ComputeLoss ( model , bbox_iou_optim = bbox_iou_optim ) # init loss class callbacks . run ( \"on_train_start\" ) # \u6253\u5370\u65e5\u5fd7\u4fe1\u606f LOGGER . info ( f \"Image sizes { imgsz } train, { imgsz } val \\n \" f \"Using { train_loader . num_workers * WORLD_SIZE } dataloader workers \\n \" f \"Logging results to { colorstr ( 'bold' , save_dir ) } \\n \" f \"Starting training for { epochs } epochs...\" ) for epoch in range ( start_epoch , epochs ): # epoch ------------------------------------------------------------------ callbacks . run ( \"on_train_epoch_start\" ) model . train () # Update image weights (optional, single-GPU only) # Update image weights (optional) \u5e76\u4e0d\u4e00\u5b9a\u597d \u9ed8\u8ba4\u662fFalse\u7684 # \u5982\u679c\u4e3aTrue \u8fdb\u884c\u56fe\u7247\u91c7\u6837\u7b56\u7565(\u6309\u6570\u636e\u96c6\u5404\u7c7b\u522b\u6743\u91cd\u91c7\u6837) if opt . image_weights : # \u6839\u636e\u524d\u9762\u521d\u59cb\u5316\u7684\u56fe\u7247\u91c7\u6837\u6743\u91cdmodel.class_weights\uff08\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd \u9891\u7387\u9ad8\u7684\u6743\u91cd\u5c0f\uff09\u4ee5\u53camaps\u914d\u5408\u6bcf\u5f20\u56fe\u7247\u5305\u542b\u7684\u7c7b\u522b\u6570 # \u901a\u8fc7rando.choices\u751f\u6210\u56fe\u7247\u7d22\u5f15indices\u4ece\u800c\u8fdb\u884c\u91c7\u7528 \uff08\u4f5c\u8005\u81ea\u5df1\u5199\u7684\u91c7\u6837\u7b56\u7565\uff0c\u6548\u679c\u4e0d\u4e00\u5b9aok\uff09 cw = model . class_weights . cpu () . numpy () * ( 1 - maps ) ** 2 / nc # class weights # labels_to_image_weights: \u8fd9\u4e2a\u51fd\u6570\u662f\u5229\u7528\u6bcf\u5f20\u56fe\u7247\u771f\u5b9egt\u6846\u7684\u771f\u5b9e\u6807\u7b7elabels\u548c\u5f00\u59cb\u8bad\u7ec3\u524d\u901a\u8fc7 labels_to_class_weights\u51fd\u6570 # \u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd\u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6bcf\u5f20\u56fe\u7247\u5bf9\u5e94\u7684\u6743\u91cd\u3002 # https://github.com/Oneflow-Inc/oneflow-yolo-doc/blob/master/docs/source_code_interpretation/utils/general_py.md#192-labels_to_image_weights iw = labels_to_image_weights ( dataset . labels , nc = nc , class_weights = cw ) # image weights dataset . indices = random . choices ( range ( dataset . n ), weights = iw , k = dataset . n ) # rand weighted idx # \u521d\u59cb\u5316\u8bad\u7ec3\u65f6\u6253\u5370\u7684\u5e73\u5747\u635f\u5931\u4fe1\u606f mloss = flow . zeros ( 3 , device = device ) # mean losses if RANK != - 1 : # DDP\u6a21\u5f0f\u6253\u4e71\u6570\u636e\uff0c\u5e76\u4e14ddp.sampler\u7684\u968f\u673a\u91c7\u6837\u6570\u636e\u662f\u57fa\u4e8eepoch+seed\u4f5c\u4e3a\u968f\u673a\u79cd\u5b50\uff0c\u6bcf\u6b21epoch\u4e0d\u540c\uff0c\u968f\u673a\u79cd\u5b50\u4e0d\u540c train_loader . sampler . set_epoch ( epoch ) # \u8fdb\u5ea6\u6761\uff0c\u65b9\u4fbf\u5c55\u793a\u4fe1\u606f pbar = enumerate ( train_loader ) LOGGER . info (( ' \\n ' + ' %11s ' * 7 ) % ( 'Epoch' , 'GPU_mem' , 'box_loss' , 'obj_loss' , 'cls_loss' , 'Instances' , 'Size' )) if RANK in { - 1 , 0 }: # \u521b\u5efa\u8fdb\u5ea6\u6761 pbar = tqdm ( pbar , total = nb , bar_format = \" {l_bar}{bar:10}{r_bar}{bar:-10b} \" ) # progress bar # \u68af\u5ea6\u6e05\u96f6 optimizer . zero_grad () for i , ( imgs , targets , paths , _ , ) in pbar : # batch ------------------------------------------------------------- callbacks . run ( \"on_train_batch_start\" ) # ni: \u8ba1\u7b97\u5f53\u524d\u8fed\u4ee3\u6b21\u6570 iteration ni = i + nb * epoch # number integrated batches (since train start) imgs = imgs . to ( device ) . float () / 255 # uint8 to float32, 0-255 to 0.0-1.0 # Warmup # \u9884\u70ed\u8bad\u7ec3\uff08\u524dnw\u6b21\u8fed\u4ee3\uff09\u70ed\u8eab\u8bad\u7ec3\u8fed\u4ee3\u7684\u6b21\u6570iteration\u8303\u56f4[1:nw] \u9009\u53d6\u8f83\u5c0f\u7684accumulate\uff0c\u5b66\u4e60\u7387\u4ee5\u53camomentum,\u6162\u6162\u7684\u8bad\u7ec3 if ni <= nw : xi = [ 0 , nw ] # x interp # compute_loss.gr = np.interp(ni, xi, [0.0, 1.0]) # iou loss ratio (obj_loss = 1.0 or iou) accumulate = max ( 1 , np . interp ( ni , xi , [ 1 , nbs / batch_size ]) . round ()) for j , x in enumerate ( optimizer . param_groups ): # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0 x [ \"lr\" ] = np . interp ( ni , xi , [ hyp [ \"warmup_bias_lr\" ] if j == 0 else 0.0 , x [ \"initial_lr\" ] * lf ( epoch )], ) if \"momentum\" in x : x [ \"momentum\" ] = np . interp ( ni , xi , [ hyp [ \"warmup_momentum\" ], hyp [ \"momentum\" ]]) # Multi-scale \u9ed8\u8ba4\u5173\u95ed # Multi-scale \u591a\u5c3a\u5ea6\u8bad\u7ec3 \u4ece[imgsz*0.5, imgsz*1.5+gs]\u95f4\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u5c3a\u5bf8(32\u7684\u500d\u6570)\u4f5c\u4e3a\u5f53\u524dbatch\u7684\u5c3a\u5bf8\u9001\u5165\u6a21\u578b\u5f00\u59cb\u8bad\u7ec3 # imgsz: \u9ed8\u8ba4\u8bad\u7ec3\u5c3a\u5bf8 gs: \u6a21\u578b\u6700\u5927stride=32 [32 16 8] if opt . multi_scale : sz = random . randrange ( imgsz * 0.5 , imgsz * 1.5 + gs ) // gs * gs # size sf = sz / max ( imgs . shape [ 2 :]) # scale factor if sf != 1 : ns = [ math . ceil ( x * sf / gs ) * gs for x in imgs . shape [ 2 :]] # new shape (stretched to gs-multiple) # \u4e0b\u91c7\u6837 imgs = nn . functional . interpolate ( imgs , size = ns , mode = \"bilinear\" , align_corners = False ) # Forward pred = model ( imgs ) # forward loss , loss_items = compute_loss ( pred , targets . to ( device )) # loss scaled by batch_size if RANK != - 1 : loss *= WORLD_SIZE # gradient averaged between devices in DDP mode if opt . quad : loss *= 4.0 # Backward # scaler.scale(loss).backward() # Backward \u53cd\u5411\u4f20\u64ad loss . backward () # Optimize - https://pytorch.org/docs/master/notes/amp_examples.html # \u6a21\u578b\u53cd\u5411\u4f20\u64adaccumulate\u6b21\uff08iterations\uff09\u540e\u518d\u6839\u636e\u7d2f\u8ba1\u7684\u68af\u5ea6\u66f4\u65b0\u4e00\u6b21\u53c2\u6570 if ni - last_opt_step >= accumulate : # optimizer.step \u53c2\u6570\u66f4\u65b0 optimizer . step () # \u68af\u5ea6\u6e05\u96f6 optimizer . zero_grad () if ema : # \u5f53\u524depoch\u8bad\u7ec3\u7ed3\u675f \u66f4\u65b0ema ema . update ( model ) last_opt_step = ni # Log # \u6253\u5370Print\u4e00\u4e9b\u4fe1\u606f \u5305\u62ec\u5f53\u524depoch\u3001\u663e\u5b58\u3001\u635f\u5931(box\u3001obj\u3001cls\u3001total)\u3001\u5f53\u524dbatch\u7684target\u7684\u6570\u91cf\u548c\u56fe\u7247\u7684size\u7b49\u4fe1\u606f if RANK in { - 1 , 0 }: mloss = ( mloss * i + loss_items ) / ( i + 1 ) # update mean losses pbar . set_description (( \" %11s \" + \" %11.4g \" * 5 ) % ( f \" { epoch } / { epochs - 1 } \" , * mloss , targets . shape [ 0 ], imgs . shape [ - 1 ])) # end batch ---------------------------------------------------------------- # Scheduler lr = [ x [ \"lr\" ] for x in optimizer . param_groups ] # for loggers scheduler . step () if RANK in { - 1 , 0 }: # mAP callbacks . run ( \"on_train_epoch_end\" , epoch = epoch ) ema . update_attr ( model , include = [ \"yaml\" , \"nc\" , \"hyp\" , \"names\" , \"stride\" , \"class_weights\" ]) final_epoch = ( epoch + 1 == epochs ) or stopper . possible_stop if not noval or final_epoch : # Calculate mAP # \u6d4b\u8bd5\u4f7f\u7528\u7684\u662fema\uff08\u6307\u6570\u79fb\u52a8\u5e73\u5747 \u5bf9\u6a21\u578b\u7684\u53c2\u6570\u505a\u5e73\u5747\uff09\u7684\u6a21\u578b # results: [1] Precision \u6240\u6709\u7c7b\u522b\u7684\u5e73\u5747precision(\u6700\u5927f1\u65f6) # [1] Recall \u6240\u6709\u7c7b\u522b\u7684\u5e73\u5747recall # [1] map@0.5 \u6240\u6709\u7c7b\u522b\u7684\u5e73\u5747mAP@0.5 # [1] map@0.5:0.95 \u6240\u6709\u7c7b\u522b\u7684\u5e73\u5747mAP@0.5:0.95 # [1] box_loss \u9a8c\u8bc1\u96c6\u56de\u5f52\u635f\u5931, obj_loss \u9a8c\u8bc1\u96c6\u7f6e\u4fe1\u5ea6\u635f\u5931, cls_loss \u9a8c\u8bc1\u96c6\u5206\u7c7b\u635f\u5931 # maps: [80] \u8bb0\u5f55\u6bcf\u4e00\u4e2a\u7c7b\u522b\u7684ap\u503c results , maps , _ = val . run ( data_dict , batch_size = batch_size // WORLD_SIZE * 2 , imgsz = imgsz , half = amp , model = ema . ema , single_cls = single_cls , dataloader = val_loader , save_dir = save_dir , plots = False , callbacks = callbacks , compute_loss = compute_loss , ) # Update best mAP # fi \u662f\u6211\u4eec\u5bfb\u6c42\u6700\u5927\u5316\u7684\u503c\u3002\u5728YOLOv5\u4e2d\uff0cfitness\u51fd\u6570\u5b9e\u73b0\u5bf9 [P, R, mAP@.5, mAP@.5-.95] \u6307\u6807\u8fdb\u884c\u52a0\u6743\u3002 fi = fitness ( np . array ( results ) . reshape ( 1 , - 1 )) # weighted combination of [P, R, mAP@.5, mAP@.5-.95] # stop = stopper(epoch=epoch, fitness=fi) # early stop check if fi > best_fitness : best_fitness = fi log_vals = list ( mloss ) + list ( results ) + lr callbacks . run ( \"on_fit_epoch_end\" , log_vals , epoch , best_fitness , fi ) # Save model if ( not nosave ) or ( final_epoch and not evolve ): # if save ckpt = { \"epoch\" : epoch , \"best_fitness\" : best_fitness , \"model\" : deepcopy ( de_parallel ( model )) . half (), \"ema\" : deepcopy ( ema . ema ) . half (), \"updates\" : ema . updates , \"optimizer\" : optimizer . state_dict (), \"wandb_id\" : loggers . wandb . wandb_run . id if loggers . wandb else None , \"opt\" : vars ( opt ), \"date\" : datetime . now () . isoformat (), } # Save last, best and delete model_save ( ckpt , last ) # flow.save(ckpt, last) if best_fitness == fi : model_save ( ckpt , best ) # flow.save(ckpt, best) if opt . save_period > 0 and epoch % opt . save_period == 0 : print ( \"is ok\" ) model_save ( ckpt , w / f \"epoch { epoch } \" ) # flow.save(ckpt, w / f\"epoch{epoch}\") del ckpt # Write \u5c06\u6d4b\u8bd5\u7ed3\u679c\u5199\u5165result.txt\u4e2d callbacks . run ( \"on_model_save\" , last , epoch , final_epoch , best_fitness , fi ) # end epoch -------------------------------------------------------------------------- # end training ---------------------------------------------------------------------------","title":"4.12 Start training"},{"location":"source_code_interpretation/train_py.html#413-end","text":"\u6253\u5370\u4e00\u4e9b\u4fe1\u606f \u65e5\u5fd7: \u6253\u5370\u8bad\u7ec3\u65f6\u95f4\u3001plots\u53ef\u89c6\u5316\u8bad\u7ec3\u7ed3\u679cresults1.png\u3001confusion_matrix.png \u4ee5\u53ca(\u2018F1\u2019, \u2018PR\u2019, \u2018P\u2019, \u2018R\u2019)\u66f2\u7ebf\u53d8\u5316 \u3001\u65e5\u5fd7\u4fe1\u606f \u901a\u8fc7\u8c03\u7528val.run() \u65b9\u6cd5\u9a8c\u8bc1\u5728 coco\u6570\u636e\u96c6\u4e0a \u6a21\u578b\u51c6\u786e\u6027 + \u91ca\u653e\u663e\u5b58 Validate a model's accuracy on COCO val or test-dev datasets. Note that pycocotools metrics may be ~1% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation. if RANK in { - 1 , 0 }: LOGGER . info ( f \" \\n { epoch - start_epoch + 1 } epochs completed in { ( time . time () - t0 ) / 3600 : .3f } hours\" ) for f in last , best : if f . exists (): strip_optimizer ( f ) # strip optimizers if f is best : LOGGER . info ( f \" \\n Validating { f } ...\" ) results , _ , _ = val . run ( data_dict , batch_size = batch_size // WORLD_SIZE * 2 , imgsz = imgsz , model = attempt_load ( f , device ) . half (), iou_thres = 0.65 if is_coco else 0.60 , # best pycocotools results at 0.65 single_cls = single_cls , dataloader = val_loader , save_dir = save_dir , save_json = is_coco , verbose = True , plots = plots , callbacks = callbacks , compute_loss = compute_loss , ) # val best model with plots callbacks . run ( \"on_train_end\" , last , best , plots , epoch , results ) flow . cuda . empty_cache () return","title":"4.13 End"},{"location":"source_code_interpretation/train_py.html#5-run","text":"\u5c01\u88c5train\u63a5\u53e3 \u652f\u6301\u51fd\u6570\u8c03\u7528\u6267\u884c\u8fd9\u4e2atrain.py\u811a\u672c def run ( ** kwargs ): # Usage: import train; train.run(data='coco128.yaml', imgsz=320, weights='yolov5m') opt = parse_opt ( True ) for k , v in kwargs . items (): setattr ( opt , k , v ) # \u7ed9opt\u6dfb\u52a0\u5c5e\u6027 main ( opt ) return opt","title":"5 run\u51fd\u6570"},{"location":"source_code_interpretation/train_py.html#6","text":"","title":"6 \u542f\u52a8\u8bad\u7ec3\u65f6\u6548\u679c\u5c55\u793a"},{"location":"source_code_interpretation/train_py.html#7","text":"\u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011train.py Github: Laughing-q/yolov5_annotations CSDN Liaojiajia-2020: YOLOv5\u4ee3\u7801\u8be6\u89e3\uff08train.py\u90e8\u5206\uff09","title":"7 \u53c2\u8003"},{"location":"source_code_interpretation/val_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a val.py Ultralytics \u5b98\u65b9\u7ed9\u7684\u4ecb\u7ecd Validate a model's accuracy on COCO val or test-dev datasets. Models are downloaded automatically from the latest YOLOv5 release . To show results by class use the --verbose flag. Note that pycocotools metrics may be ~1% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation. 1.\u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e import argparse # \u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570\u6a21\u5757 import json # \u5b57\u5178\u5217\u8868\u548cJSON\u5b57\u7b26\u4e32\u4e4b\u95f4\u7684\u76f8\u4e92\u89e3\u6790\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 \u5305\u542b\u6587\u4ef6\u8def\u5f84\u64cd\u4f5c\u548c\u89e3\u6790 import sys # sys\u7cfb\u7edf\u6a21\u5757 \u5305\u542b\u4e86\u4e0ePython\u89e3\u91ca\u5668\u548c\u5b83\u7684\u73af\u5883\u6709\u5173\u7684\u51fd\u6570 from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 import numpy as np # NumPy\uff08Numerical Python\uff09\u662fPython\u7684\u4e00\u79cd\u5f00\u6e90\u7684\u6570\u503c\u8ba1\u7b97\u6269\u5c55 import oneflow as flow # OneFlow \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 from tqdm import tqdm # \u8fdb\u5ea6\u6761\u6a21\u5757 from models.common import DetectMultiBackend from utils.callbacks import Callbacks from utils.dataloaders import create_dataloader from utils.general import ( LOGGER , check_dataset , check_img_size , check_requirements , check_yaml , coco80_to_coco91_class , colorstr , increment_path , non_max_suppression , print_args , scale_coords , xywh2xyxy , xyxy2xywh , ) from utils.metrics import ConfusionMatrix , ap_per_class , box_iou from utils.oneflow_utils import select_device , time_sync from utils.plots import output_to_target , plot_images , plot_val_study 2.opt\u53c2\u6570\u8be6\u89e3 \u53c2\u6570 \u89e3\u6790 data dataset.yaml path \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6\u5730\u5740 \u5305\u542b\u6570\u636e\u96c6\u7684\u8def\u5f84\u3001\u7c7b\u522b\u4e2a\u6570\u3001\u7c7b\u540d\u3001\u4e0b\u8f7d\u5730\u5740\u7b49\u4fe1\u606f weights model weights path(s) \u6a21\u578b\u7684\u6743\u91cd\u6587\u4ef6\u5730\u5740 weights/yolov5s batch-size batch size \u8ba1\u7b97\u6837\u672c\u7684\u6279\u6b21\u5927\u5c0f \u9ed8\u8ba432 imgsz inference size (pixels) \u8f93\u5165\u7f51\u7edc\u7684\u56fe\u7247\u5206\u8fa8\u7387 \u9ed8\u8ba4640 conf-thres confidence threshold object\u7f6e\u4fe1\u5ea6\u9608\u503c \u9ed8\u8ba40.001 iou-thres NMS IoU threshold \u8fdb\u884cNMS\u65f6IOU\u7684\u9608\u503c \u9ed8\u8ba40.6 task train, val, test, speed or study \u8bbe\u7f6e\u6d4b\u8bd5\u7684\u7c7b\u578b \u6709train, val, test, speed or study\u51e0\u79cd \u9ed8\u8ba4val device cuda device, i.e. 0 or 0,1,2,3 or cpu \u6d4b\u8bd5\u7684\u8bbe\u5907 workers max dataloader workers (per RANK in DDP mode) \u52a0\u8f7d\u6570\u636e\u4f7f\u7528\u7684 dataloader workers single-cls treat as single-class dataset \u6570\u636e\u96c6\u662f\u5426\u53ea\u7528\u4e00\u4e2a\u7c7b\u522b \u9ed8\u8ba4False augment augmented inference \u6d4b\u8bd5\u662f\u5426\u4f7f\u7528TTA Test Time Augment \u9ed8\u8ba4False verbose report mAP by class \u662f\u5426\u6253\u5370\u51fa\u6bcf\u4e2a\u7c7b\u522b\u7684mAP \u9ed8\u8ba4False save-hybrid save label+prediction hybrid results to *.txt \u4fdd\u5b58label+prediction hybrid \u5230\u5bf9\u5e94.txt \u9ed8\u8ba4False save-conf save confidences in --save-txt labels save-json save a COCO-JSON results file \u662f\u5426\u6309\u7167coco\u7684json\u683c\u5f0f\u4fdd\u5b58\u7ed3\u679c \u9ed8\u8ba4False project save to project/name \u6d4b\u8bd5\u4fdd\u5b58\u7684\u6e90\u6587\u4ef6 \u9ed8\u8ba4 runs/val name save to project/name \u6d4b\u8bd5\u4fdd\u5b58\u7684\u6587\u4ef6\u5730\u5740\u540d \u9ed8\u8ba4 exp \u4fdd\u5b58\u5728 runs/val/exp \u4e0b exist-ok existing project/name ok, do not increment \u5426\u5b58\u5728\u5f53\u524d\u6587\u4ef6 \u9ed8\u8ba4False half use FP16 half-precision inference \u662f\u5426\u4f7f\u7528\u534a\u7cbe\u5ea6\u63a8\u7406 \u9ed8\u8ba4False dnn use OpenCV DNN for ONNX inference \u662f\u5426\u4f7f\u7528 OpenCV DNN \u5bf9\u4e8e ONNX \u63a8\u7406 3. main\u51fd\u6570 \u6839\u636e\u89e3\u6790\u7684opt\u53c2\u6570\uff0c\u8c03\u7528run\u51fd\u6570 def main ( opt ): # \u68c0\u6d4brequirements\u6587\u4ef6\u4e2d\u9700\u8981\u7684\u5305\u662f\u5426\u5b89\u88c5\u597d\u4e86 check_requirements ( requirements = ROOT / \"requirements.txt\" , exclude = ( \"tensorboard\" , \"thop\" )) if opt . task in ( \"train\" , \"val\" , \"test\" ): # run normally if opt . conf_thres > 0.001 : # \u66f4\u591a\u8bf7\u89c1 https://github.com/ultralytics/yolov5/issues/1466 LOGGER . info ( f \"WARNING: confidence threshold { opt . conf_thres } > 0.001 produces invalid results\" ) run ( ** vars ( opt )) else : weights = opt . weights if isinstance ( opt . weights , list ) else [ opt . weights ] opt . half = True # FP16 for fastest results if opt . task == \"speed\" : # speed benchmarks # python val.py --task speed --data coco.yaml # --batch 1 --weights yolov5n.pt yolov5s.pt... opt . conf_thres , opt . iou_thres , opt . save_json = 0.25 , 0.45 , False for opt . weights in weights : run ( ** vars ( opt ), plots = False ) elif opt . task == \"study\" : # speed vs mAP benchmarks # python val.py --task study --data coco.yaml # --iou 0.7 --weights yolov5n.pt yolov5s.pt... for opt . weights in weights : f = f \"study_ { Path ( opt . data ) . stem } _ { Path ( opt . weights ) . stem } .txt\" x , y = ( list ( range ( 256 , 1536 + 128 , 128 )), [], ) # x axis (image sizes), y axis # \"study\": \u6a21\u578b\u5728\u5404\u4e2a\u5c3a\u5ea6\u4e0b\u7684\u6307\u6807\u5e76\u53ef\u89c6\u5316\uff0c # \u4e0a\u9762list(range(256, 1536 + 128, 128)),\u4ee3\u8868 img-size \u7684\u5404\u4e2a\u5c3a\u5ea6, \u5177\u4f53\u4ee3\u7801\u5982\u4e0b\uff1a for opt . imgsz in x : # img-size LOGGER . info ( f \" \\n Running { f } --imgsz { opt . imgsz } ...\" ) r , _ , t = run ( ** vars ( opt ), plots = False ) y . append ( r + t ) # results and times np . savetxt ( f , y , fmt = \" %10.4g \" ) # save os . system ( \"zip -r study.zip study_*.txt\" ) # \u53ef\u89c6\u5316\u5404\u4e2a\u6307\u6807 plot_val_study ( x = x ) # plot 3. run\u51fd\u6570 https://github.com/Oneflow-Inc/one-yolov5/blob/bf8c66e011fcf5b8885068074ffc6b56c113a20c/val.py#L112-L383 3.1 \u8f7d\u5165\u53c2\u6570 # \u4e0d\u53c2\u4e0e\u53cd\u5411\u4f20\u64ad @flow . no_grad () def run ( data , weights = None , # model.pt path(s) batch_size = 32 , # batch size imgsz = 640 , # inference size (pixels) conf_thres = 0.001 , # confidence threshold iou_thres = 0.6 , # NMS IoU threshold task = \"val\" , # train, val, test, speed or study device = \"\" , # cuda device, i.e. 0 or 0,1,2,3 or cpu workers = 8 , # max dataloader workers (per RANK in DDP mode) single_cls = False , # treat as single-class dataset augment = False , # augmented inference verbose = False , # verbose output save_txt = False , # save results to *.txt save_hybrid = False , # save label+prediction hybrid results to *.txt save_conf = False , # save confidences in --save-txt labels save_json = False , # save a COCO-JSON results file project = ROOT / \"runs/val\" , # save to project/name name = \"exp\" , # save to project/name exist_ok = False , # existing project/name ok, do not increment half = True , # use FP16 half-precision inference dnn = False , # use OpenCV DNN for ONNX inference model = None , # \u6a21\u578b \u5982\u679c\u6267\u884cval.py\u5c31\u4e3aNone \u5982\u679c\u6267\u884ctrain.py\u5c31\u4f1a\u4f20\u5165( model=attempt_load(f, device).half() ) dataloader = None , # \u6570\u636e\u52a0\u8f7d\u5668 \u5982\u679c\u6267\u884cval.py\u5c31\u4e3aNone \u5982\u679c\u6267\u884ctrain.py\u5c31\u4f1a\u4f20\u5165testloader save_dir = Path ( \"\" ), # \u6587\u4ef6\u4fdd\u5b58\u8def\u5f84 \u5982\u679c\u6267\u884cval.py\u5c31\u4e3a\u2018\u2019 , \u5982\u679c\u6267\u884ctrain.py\u5c31\u4f1a\u4f20\u5165save_dir(runs/train/expn) plots = True , # \u662f\u5426\u53ef\u89c6\u5316 \u8fd0\u884cval.py\u4f20\u5165\u9ed8\u8ba4True callbacks = Callbacks (), compute_loss = None , # \u635f\u5931\u51fd\u6570 \u8fd0\u884cval.py\u4f20\u5165\u9ed8\u8ba4None \u8fd0\u884ctrain.py\u5219\u4f20\u5165compute_loss(train) ): 3.2 Initialize/load model and set device if training : # called by train.py \u901a\u8fc7train.py\u8c03\u7528\u7684run\u51fd\u6570 device , of , engine = ( next ( model . parameters ()) . device , True , False , ) # get model device, PyTorch model half &= device . type != \"cpu\" # half precision only supported on CUDA model . half () if half else model . float () else : # called directly \u901a\u8fc7val.py \u8c03\u7528\u7684run\u51fd\u6570 device = select_device ( device , batch_size = batch_size ) # Directories \u751f\u6210save_dir\u6587\u4ef6\u8def\u5f84 run/test/expn save_dir = increment_path ( Path ( project ) / name , exist_ok = exist_ok ) # increment run ( save_dir / \"labels\" if save_txt else save_dir ) . mkdir ( parents = True , exist_ok = True ) # make dir # Load model \u52a0\u8f7d\u6a21\u578b model = DetectMultiBackend ( weights , device = device , dnn = dnn , data = data , fp16 = half ) stride , of , engine = model . stride , model . of , model . engine # \u68c0\u6d4b\u8f93\u5165\u56fe\u7247\u7684\u5206\u8fa8\u7387imgsz\u662f\u5426\u80fd\u88abgs\u6574\u9664 imgsz = check_img_size ( imgsz , s = stride ) # check image size half = model . fp16 # FP16 supported on limited backends with CUDA if engine : batch_size = model . batch_size else : device = model . device if not of : batch_size = 1 # export.py models default to batch-size 1 LOGGER . info ( f \"Forcing --batch-size 1 inference (1,3, { imgsz } , { imgsz } ) for non-OneFlow models\" ) # Data data = check_dataset ( data ) # check 3.3 Configure # \u914d\u7f6e model . eval () # \u542f\u52a8\u6a21\u578b\u9a8c\u8bc1\u6a21\u5f0f cuda = device . type != \"cpu\" is_coco = isinstance ( data . get ( \"val\" ), str ) and data [ \"val\" ] . endswith ( f \"coco { os . sep } val2017.txt\" ) # COCO dataset nc = 1 if single_cls else int ( data [ \"nc\" ]) # number of classes # iouv: [0.50000, 0.55000, 0.60000, 0.65000, 0.70000, 0.75000, 0.80000, 0.85000, 0.90000, 0.95000] iouv = flow . linspace ( 0.5 , 0.95 , 10 , device = device ) # iou vector for mAP@0.5:0.95 niou = iouv . numel () # \u793a\u4f8b mAP@0.5:0.95 iou\u4e2a\u6570=10\u4e2a 3.4 Dataloader \u901a\u8fc7train.py\u8c03\u7528run\u51fd\u6570\u4f1a\u4f20\u5165\u4e00\u4e2aDataloader\uff0c\u800c\u901a\u8fc7val.py\u9700\u8981\u52a0\u8f7d\u6d4b\u8bd5\u6570\u636e\u96c6 # Dataloader if not training : # \u52a0\u8f7dval\u6570\u636e\u96c6 if of and not single_cls : # check --weights are trained on --data ncm = model . model . nc assert ncm == nc , ( f \" { weights } ( { ncm } classes) trained on different --data than what you passed ( { nc } \" f \"classes). Pass correct combination of\" f \" --weights and --data that are trained together.\" ) model . warmup ( imgsz = ( 1 if of else batch_size , 3 , imgsz , imgsz )) # warmup pad = 0.0 if task in ( \"speed\" , \"benchmark\" ) else 0.5 rect = False if task == \"benchmark\" else of # square inference for benchmarks task = task if task in ( \"train\" , \"val\" , \"test\" ) else \"val\" # path to train/val/test images # \u521b\u5efadataloader \u8fd9\u91cc\u7684rect\u9ed8\u8ba4\u4e3aTrue \u77e9\u5f62\u63a8\u7406\u7528\u4e8e\u6d4b\u8bd5\u96c6 \u5728\u4e0d\u5f71\u54cdmAP\u7684\u60c5\u51b5\u4e0b\u53ef\u4ee5\u5927\u5927\u63d0\u5347\u63a8\u7406\u901f\u5ea6 dataloader = create_dataloader ( data [ task ], imgsz , batch_size , stride , single_cls , pad = pad , rect = rect , workers = workers , prefix = colorstr ( f \" { task } : \" ), )[ 0 ] 3.5 \u521d\u59cb\u5316 # \u521d\u59cb\u5316\u9a8c\u8bc1\u7684\u56fe\u7247\u7684\u6570\u91cf seen = 0 # \u521d\u59cb\u5316\u6df7\u6dc6\u77e9\u9635 confusion_matrix = ConfusionMatrix ( nc = nc ) # \u83b7\u53d6\u6570\u636e\u96c6\u6240\u6709\u7c7b\u522b\u7684\u7c7b\u540d names = dict ( enumerate ( model . names if hasattr ( model , \"names\" ) else model . module . names )) # coco80_to_coco91_class : converts 80-index (val2014) to 91-index (paper) # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/ class_map = coco80_to_coco91_class () if is_coco else list ( range ( 1000 )) # \u8bbe\u7f6e\u8fdb\u5ea6\u6761\u6a21\u5757\u663e\u793a\u4fe1\u606f s = ( \" %20s \" + \" %11s \" * 6 ) % ( \"Class\" , \"Images\" , \"Labels\" , \"P\" , \"R\" , \"mAP@.5\" , \"mAP@.5:.95\" , ) # \u521d\u59cb\u5316\u65f6\u95f4dt[t0, t1, t2] \u548c p, r, f1, mp, mr, map50, map\u6307\u6807 dt , p , r , f1 , mp , mr , map50 , map = ( [ 0.0 , 0.0 , 0.0 ], 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , ) # \u521d\u59cb\u5316\u9a8c\u8bc1\u96c6\u7684\u635f\u5931 loss = flow . zeros ( 3 , device = device ) # \u521d\u59cb\u5316json\u6587\u4ef6\u4e2d\u7684\u5b57\u5178 \u7edf\u8ba1\u4fe1\u606f ap ap_class jdict , stats , ap , ap_class = [], [], [], [] callbacks . run ( \"on_val_start\" ) # \u521d\u59cb\u5316tqdm \u8fdb\u5ea6\u6761\u6a21\u5757 pbar = tqdm ( dataloader , desc = s , bar_format = \" {l_bar}{bar:10}{r_bar}{bar:-10b} \" ) \u793a\u4f8b\u8f93\u51fa val : data = data / coco . yaml , weights = [ 'yolov5x' ], batch_size = 32 , imgsz = 640 , conf_thres = 0.001 , iou_thres = 0.6 , task = val , device = , workers = 8 , single_cls = False , augment = False , verbose = False , save_txt = False , save_hybrid = False , save_conf = False , save_json = True , project = runs / val , name = exp , exist_ok = False , half = True , dnn = False YOLOv5 \ud83d\ude80 v1 .0 - 8 - g94ec5c4 Python - 3.8.13 oneflow - 0.8.1 . dev20221018 + cu112 Fusing layers ... Model summary : 322 layers , 86705005 parameters , 571965 gradients val : Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels ... 4952 found , 48 missing , 0 empty , 0 corrupt : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP @ .5 mAP @ .5 : .95 : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 / 157 [ 01 : 55 < 00 : 00 , 1.36 it / all 5000 36335 0.743 0.627 0.685 0.503 Speed : 0.1 ms pre - process , 7.5 ms inference , 2.1 ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP ... saving runs / val / exp3 / yolov5x_predictions . json ... ... Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0.50 | area = all | maxDets = 100 ] = 0.689 Average Precision ( AP ) @ [ IoU = 0.75 | area = all | maxDets = 100 ] = 0.545 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.339 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.557 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.650 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 1 ] = 0.382 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 10 ] = 0.628 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.523 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.730 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.826 3.6 \u5f00\u59cb\u9a8c\u8bc1 for batch_i , ( im , targets , paths , shapes ) in enumerate ( pbar ): \"\"\" https://github.com/Oneflow-Inc/one-yolov5/blob/bf8c66e011fcf5b8885068074ffc6b56c113a20c/utils/dataloaders.py#L735 im : flow.from_numpy(img); targets : labels_out paths: self.im_files[index] shapes : shapes \"\"\" 3.6.1 \u9a8c\u8bc1\u5f00\u59cb\u524d\u7684\u9884\u5904\u7406 callbacks . run ( \"on_val_batch_start\" ) t1 = time_sync () if cuda : im = im . to ( device ) targets = targets . to ( device ) im = im . half () if half else im . float () # uint8 to fp16/32 im /= 255 # 0 - 255 to 0.0 - 1.0 nb , _ , height , width = im . shape # batch size, channels, height, width t2 = time_sync () dt [ 0 ] += t2 - t1 3.6.2 \u63a8\u7406 # Inference out , train_out = model ( im ) if training else model ( im , augment = augment , val = True ) # \u8f93\u51fa\u4e3a\uff1a\u63a8\u7406\u7ed3\u679c\u3001\u635f\u5931\u503c dt [ 1 ] += time_sync () - t2 3.6.3 \u8ba1\u7b97\u635f\u5931 # Loss \"\"\" \u5206\u7c7b\u635f\u5931(cls_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u5224\u65ad\u6a21\u578b\u662f\u5426\u80fd\u591f\u51c6\u786e\u5730\u8bc6\u522b\u51fa\u56fe\u50cf\u4e2d\u7684\u5bf9\u8c61\uff0c\u5e76\u5c06\u5176\u5206\u7c7b\u5230\u6b63\u786e\u7684\u7c7b\u522b\u4e2d\u3002 \u7f6e\u4fe1\u5ea6\u635f\u5931(obj_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u7684\u6846\uff08\u5373\u5305\u542b\u5bf9\u8c61\u7684\u77e9\u5f62\uff09\u4e0e\u771f\u5b9e\u6846\u4e4b\u95f4\u7684\u5dee\u5f02\u3002 \u8fb9\u754c\u6846\u635f\u5931(box_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4e0e\u771f\u5b9e\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u8fd9\u6709\u52a9\u4e8e\u786e\u4fdd\u6a21\u578b\u80fd\u591f\u51c6\u786e\u5730\u5b9a\u4f4d\u5bf9\u8c61\u3002 \"\"\" if compute_loss : loss += compute_loss ([ x . float () for x in train_out ], targets )[ 1 ] # box, obj, cls 3.6.4 Run NMS # NMS # \u5c06\u771f\u5b9e\u6846target\u7684xywh(\u56e0\u4e3atarget\u662f\u5728labelimg\u4e2d\u505a\u4e86\u5f52\u4e00\u5316\u7684)\u6620\u5c04\u5230img(test)\u5c3a\u5bf8 targets [:, 2 :] *= flow . tensor (( width , height , width , height ), device = device ) # to pixels # \u5bf9\u5e94 lb = [ targets [ targets [:, 0 ] == i , 1 :] for i in range ( nb )] if save_hybrid else [] # for autolabelling t3 = time_sync () \"\"\"non_max_suppression (\u975e\u6700\u5927\u503c\u6291\u5236) Non-Maximum Suppression (NMS) on inference results to reject overlapping bounding boxes \u8be5\u7b97\u6cd5\u7684\u539f\u7406\uff1a \u5148\u5047\u8bbe\u67096\u4e2a\u77e9\u5f62\u6846\uff0c\u6839\u636e\u5206\u7c7b\u5668\u7684\u7c7b\u522b\u5206\u7c7b\u6982\u7387\u5927\u5c0f\u6392\u5e8f\uff0c\u5047\u8bbe\u4ece\u5c0f\u5230\u5927\u5c5e\u4e8e\u8f66\u8f86(\u88ab\u68c0\u6d4b\u7684\u76ee\u6807)\u7684\u6982\u7387\u5206\u522b\u4e3a\uff1aA\u3001B\u3001C\u3001D\u3001E\u3001F \uff081\uff09\u4ece\u6700\u5927\u6982\u7387 \u77e9\u5f62\u6846F\u5f00\u59cb\uff0c\u5206\u522b\u5224\u65adA~E\u4e0eF\u7684\u91cd\u53e0\u5ea6IOU\u662f\u5426\u5927\u4e8e\u67d0\u4e2a\u6307\u5b9a\u7684\u9600\u503c\uff1b \uff082\uff09\u5047\u8bbeB\u3001D\u4e0eF\u7684\u91cd\u53e0\u5ea6\u5927\u4e8e\u6307\u5b9a\u7684\u9600\u503c\uff0c\u5219\u4e22\u5f03B\u3001D\uff0c\u5e76\u6807\u8bb0\u7b2c\u4e00\u4e2a\u77e9\u5f62\u6846 F\uff0c\u4f7f\u6211\u4eec\u8981\u4fdd\u7559\u7684 \uff083\uff09\u4ece\u5269\u4e0b\u7684\u77e9\u5f62\u6846A\u3001C\u3001E\u4e2d\uff0c\u9009\u62e9\u6700\u5927\u6982\u7387\uff0c\u5047\u8bbe\u4e3aE\uff0c\u7136\u540e\u5224\u65adA\u3001C\u4e0eE\u7684\u91cd\u53e0\u5ea6\u662f\u5426\u5927\u4e8e\u6307\u5b9a\u7684\u9600\u503c\uff0c \u5047\u5982\u5927\u4e8e\u5c31\u4e22\u5f03A\u3001C\uff0c\u5e76\u6807\u8bb0E\uff0c\u662f\u6211\u4eec\u4fdd\u7559\u4e0b\u6765\u7684\u7b2c\u4e8c\u4e2a\u77e9\u5f62\u6846 \u4e00\u76f4\u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\uff0c\u627e\u5230\u6240\u6709\u88ab\u4fdd\u7559\u7684\u77e9\u5f62\u6846 Returns: list of detections, on (n,6) tensor per image [xyxy, conf, cls] \"\"\" out = non_max_suppression ( out , conf_thres , iou_thres , labels = lb , multi_label = True , agnostic = single_cls ) # \u83b7\u53d6NMS\u65f6\u95f4 dt [ 2 ] += time_sync () - t3 3.6.5 \u7edf\u8ba1\u6bcf\u5f20\u56fe\u7247\u7684\u771f\u5b9e\u6846\u3001\u9884\u6d4b\u6846\u4fe1\u606f # Metrics for si , pred in enumerate ( out ): labels = targets [ targets [:, 0 ] == si , 1 :] nl , npr = labels . shape [ 0 ], pred . shape [ 0 ] # number of labels, predictions path , shape = Path ( paths [ si ]), shapes [ si ][ 0 ] correct = flow . zeros ( npr , niou , dtype = flow . bool , device = device ) # init seen += 1 # \u56fe\u7247\u6570\u91cf +1 if npr == 0 : # \u5982\u679c\u9884\u6d4b\u4e3a\u7a7a\uff0c\u5219\u6dfb\u52a0\u7a7a\u7684\u4fe1\u606f\u5230stats\u91cc if nl : stats . append (( correct , * flow . zeros (( 2 , 0 ), device = device ), labels [:, 0 ])) if plots : confusion_matrix . process_batch ( detections = None , labels = labels [:, 0 ]) continue # Predictions if single_cls : pred [:, 5 ] = 0 predn = pred . clone () # \u5c06\u9884\u6d4b\u5750\u6807\u6620\u5c04\u5230\u539f\u56feimg\u4e2d scale_coords ( im [ si ] . shape [ 1 :], predn [:, : 4 ], shape , shapes [ si ][ 1 ]) # native-space pred # Evaluate if nl : tbox = xywh2xyxy ( labels [:, 1 : 5 ]) # target boxes scale_coords ( im [ si ] . shape [ 1 :], tbox , shape , shapes [ si ][ 1 ]) # native-space labels labelsn = flow . cat (( labels [:, 0 : 1 ], tbox ), 1 ) # native-space labels correct = process_batch ( predn , labelsn , iouv ) if plots : confusion_matrix . process_batch ( predn , labelsn ) stats . append (( correct , pred [:, 4 ], pred [:, 5 ], labels [:, 0 ])) # (correct, conf, pcls, tcls) # Save/log if save_txt : save_one_txt ( predn , save_conf , shape , file = save_dir / \"labels\" / f \" { path . stem } .txt\" , ) if save_json : save_one_json ( predn , jdict , path , class_map ) # append to COCO-JSON dictionary callbacks . run ( \"on_val_image_end\" , pred , predn , path , names , im [ si ]) 3.6.6 \u753b\u51fa\u524d\u4e09\u4e2abatch\u56fe\u7247\u7684gt\u548cpred\u6846 gt : \u771f\u5b9e\u6846\uff0cGround truth box, \u662f\u4eba\u5de5\u6807\u6ce8\u7684\u4f4d\u7f6e\uff0c\u5b58\u653e\u5728\u6807\u6ce8\u6587\u4ef6\u4e2d pred : \u9884\u6d4b\u6846\uff0cPrediction box\uff0c \u662f\u7531\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u8ba1\u7b97\u8f93\u51fa\u7684\u6846 # Plot images if plots and batch_i < 3 : plot_images ( im , targets , paths , save_dir / f \"val_batch { batch_i } _labels.jpg\" , names ) # labels plot_images ( im , output_to_target ( out ), paths , save_dir / f \"val_batch { batch_i } _pred.jpg\" , names , ) # pred callbacks . run ( \"on_val_batch_end\" ) 3.7 \u8ba1\u7b97\u6307\u6807 \u6307\u6807\u540d\u5b57\u5728\u4ee3\u7801\u4e2d\u4f53\u73b0 # Compute metrics stats = [ flow . cat ( x , 0 ) . cpu () . numpy () for x in zip ( * stats )] # to numpy if len ( stats ) and stats [ 0 ] . any (): tp , fp , p , r , f1 , ap , ap_class = ap_per_class ( * stats , plot = plots , save_dir = save_dir , names = names ) ap50 , ap = ap [:, 0 ], ap . mean ( 1 ) # AP@0.5, AP@0.5:0.95 mp , mr , map50 , map = p . mean (), r . mean (), ap50 . mean (), ap . mean () nt = np . bincount ( stats [ 3 ] . astype ( int ), minlength = nc ) # number of targets per class 3.8 \u6253\u5370\u65e5\u5fd7 # Print results per class if ( verbose or ( nc < 50 and not training )) and nc > 1 and len ( stats ): for i , c in enumerate ( ap_class ): LOGGER . info ( pf % ( names [ c ], seen , nt [ c ], p [ i ], r [ i ], ap50 [ i ], ap [ i ])) # Print speeds t = tuple ( x / seen * 1e3 for x in dt ) # speeds per image if not training : shape = ( batch_size , 3 , imgsz , imgsz ) LOGGER . info ( f \"Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape { shape } \" % t ) 3.9\u4fdd\u5b58\u9a8c\u8bc1\u7ed3\u679c # Plots if plots : confusion_matrix . plot ( save_dir = save_dir , names = list ( names . values ())) callbacks . run ( \"on_val_end\" ) # Save JSON if save_json and len ( jdict ): w = Path ( weights [ 0 ] if isinstance ( weights , list ) else weights ) . stem if weights is not None else \"\" # weights anno_json = str ( Path ( data . get ( \"path\" , \"../coco\" )) / \"annotations/instances_val2017.json\" ) # annotations json pred_json = str ( save_dir / f \" { w } _predictions.json\" ) # predictions json LOGGER . info ( f \" \\n Evaluating pycocotools mAP... saving { pred_json } ...\" ) with open ( pred_json , \"w\" ) as f : json . dump ( jdict , f ) # try-catch\uff0c\u4f1a\u6709\u54ea\u4e9berror \"\"\" pycocotools\u4ecb\u7ecd: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb \u5c1d\u8bd5: \u4f7f\u7528pycocotools\u5de5\u5177\u8ba1\u7b97loss COCO API - http://cocodataset.org/ \u5931\u8d25error: \u76f4\u63a5\u6253\u5370\u629b\u51fa\u7684\u5f02\u5e38 1. \u53ef\u80fd\u6ca1\u6709\u5b89\u88c5 pycocotools\uff0c\u4f46\u662f\u7f51\u7edc\u6709\u95ee\u9898\uff0c\u65e0\u6cd5\u5b9e\u73b0\u81ea\u52a8\u4e0b\u8f7d\u3002 2. pycocotools\u5305\u7248\u672c\u6709\u95ee\u9898 \"\"\" try : # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb check_requirements ([ \"pycocotools\" ]) from pycocotools.coco import COCO from pycocotools.cocoeval import COCOeval anno = COCO ( anno_json ) # init annotations api pred = anno . loadRes ( pred_json ) # init predictions api eval = COCOeval ( anno , pred , \"bbox\" ) if is_coco : eval . params . imgIds = [ int ( Path ( x ) . stem ) for x in dataloader . dataset . im_files ] # image IDs to evaluate eval . evaluate () eval . accumulate () eval . summarize () map , map50 = eval . stats [: 2 ] # update results (mAP@0.5:0.95, mAP@0.5) except Exception as e : LOGGER . info ( f \"pycocotools unable to run: { e } \" ) 3.10 \u8fd4\u56de\u7ed3\u679c # Return results model . float () # for training if not training : s = f \" \\n { len ( list ( save_dir . glob ( 'labels/*.txt' ))) } labels saved to { save_dir / 'labels' } \" if save_txt else \"\" LOGGER . info ( f \"Results saved to { colorstr ( 'bold' , save_dir ) }{ s } \" ) maps = np . zeros ( nc ) + map for i , c in enumerate ( ap_class ): maps [ c ] = ap [ i ] return ( mp , mr , map50 , map , * ( loss . cpu () / len ( dataloader )) . tolist ()), maps , t Reference \u3010\u4ec0\u4e48\u662fepoch\u3001batch\u3001batchsize\u3001iteration\uff1f\u4ec0\u4e48\u662f\u771f\u5b9e\u6846\u3001\u9884\u6d4b\u6846\u548c\u951a\u6846\u3011 \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011val.py","title":"val.py"},{"location":"source_code_interpretation/val_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a val.py Ultralytics \u5b98\u65b9\u7ed9\u7684\u4ecb\u7ecd Validate a model's accuracy on COCO val or test-dev datasets. Models are downloaded automatically from the latest YOLOv5 release . To show results by class use the --verbose flag. Note that pycocotools metrics may be ~1% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation.","title":"\u524d\u8a00"},{"location":"source_code_interpretation/val_py.html#1","text":"import argparse # \u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570\u6a21\u5757 import json # \u5b57\u5178\u5217\u8868\u548cJSON\u5b57\u7b26\u4e32\u4e4b\u95f4\u7684\u76f8\u4e92\u89e3\u6790\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 \u5305\u542b\u6587\u4ef6\u8def\u5f84\u64cd\u4f5c\u548c\u89e3\u6790 import sys # sys\u7cfb\u7edf\u6a21\u5757 \u5305\u542b\u4e86\u4e0ePython\u89e3\u91ca\u5668\u548c\u5b83\u7684\u73af\u5883\u6709\u5173\u7684\u51fd\u6570 from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 import numpy as np # NumPy\uff08Numerical Python\uff09\u662fPython\u7684\u4e00\u79cd\u5f00\u6e90\u7684\u6570\u503c\u8ba1\u7b97\u6269\u5c55 import oneflow as flow # OneFlow \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 from tqdm import tqdm # \u8fdb\u5ea6\u6761\u6a21\u5757 from models.common import DetectMultiBackend from utils.callbacks import Callbacks from utils.dataloaders import create_dataloader from utils.general import ( LOGGER , check_dataset , check_img_size , check_requirements , check_yaml , coco80_to_coco91_class , colorstr , increment_path , non_max_suppression , print_args , scale_coords , xywh2xyxy , xyxy2xywh , ) from utils.metrics import ConfusionMatrix , ap_per_class , box_iou from utils.oneflow_utils import select_device , time_sync from utils.plots import output_to_target , plot_images , plot_val_study","title":"1.\u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e"},{"location":"source_code_interpretation/val_py.html#2opt","text":"\u53c2\u6570 \u89e3\u6790 data dataset.yaml path \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6\u5730\u5740 \u5305\u542b\u6570\u636e\u96c6\u7684\u8def\u5f84\u3001\u7c7b\u522b\u4e2a\u6570\u3001\u7c7b\u540d\u3001\u4e0b\u8f7d\u5730\u5740\u7b49\u4fe1\u606f weights model weights path(s) \u6a21\u578b\u7684\u6743\u91cd\u6587\u4ef6\u5730\u5740 weights/yolov5s batch-size batch size \u8ba1\u7b97\u6837\u672c\u7684\u6279\u6b21\u5927\u5c0f \u9ed8\u8ba432 imgsz inference size (pixels) \u8f93\u5165\u7f51\u7edc\u7684\u56fe\u7247\u5206\u8fa8\u7387 \u9ed8\u8ba4640 conf-thres confidence threshold object\u7f6e\u4fe1\u5ea6\u9608\u503c \u9ed8\u8ba40.001 iou-thres NMS IoU threshold \u8fdb\u884cNMS\u65f6IOU\u7684\u9608\u503c \u9ed8\u8ba40.6 task train, val, test, speed or study \u8bbe\u7f6e\u6d4b\u8bd5\u7684\u7c7b\u578b \u6709train, val, test, speed or study\u51e0\u79cd \u9ed8\u8ba4val device cuda device, i.e. 0 or 0,1,2,3 or cpu \u6d4b\u8bd5\u7684\u8bbe\u5907 workers max dataloader workers (per RANK in DDP mode) \u52a0\u8f7d\u6570\u636e\u4f7f\u7528\u7684 dataloader workers single-cls treat as single-class dataset \u6570\u636e\u96c6\u662f\u5426\u53ea\u7528\u4e00\u4e2a\u7c7b\u522b \u9ed8\u8ba4False augment augmented inference \u6d4b\u8bd5\u662f\u5426\u4f7f\u7528TTA Test Time Augment \u9ed8\u8ba4False verbose report mAP by class \u662f\u5426\u6253\u5370\u51fa\u6bcf\u4e2a\u7c7b\u522b\u7684mAP \u9ed8\u8ba4False save-hybrid save label+prediction hybrid results to *.txt \u4fdd\u5b58label+prediction hybrid \u5230\u5bf9\u5e94.txt \u9ed8\u8ba4False save-conf save confidences in --save-txt labels save-json save a COCO-JSON results file \u662f\u5426\u6309\u7167coco\u7684json\u683c\u5f0f\u4fdd\u5b58\u7ed3\u679c \u9ed8\u8ba4False project save to project/name \u6d4b\u8bd5\u4fdd\u5b58\u7684\u6e90\u6587\u4ef6 \u9ed8\u8ba4 runs/val name save to project/name \u6d4b\u8bd5\u4fdd\u5b58\u7684\u6587\u4ef6\u5730\u5740\u540d \u9ed8\u8ba4 exp \u4fdd\u5b58\u5728 runs/val/exp \u4e0b exist-ok existing project/name ok, do not increment \u5426\u5b58\u5728\u5f53\u524d\u6587\u4ef6 \u9ed8\u8ba4False half use FP16 half-precision inference \u662f\u5426\u4f7f\u7528\u534a\u7cbe\u5ea6\u63a8\u7406 \u9ed8\u8ba4False dnn use OpenCV DNN for ONNX inference \u662f\u5426\u4f7f\u7528 OpenCV DNN \u5bf9\u4e8e ONNX \u63a8\u7406","title":"2.opt\u53c2\u6570\u8be6\u89e3"},{"location":"source_code_interpretation/val_py.html#3main","text":"\u6839\u636e\u89e3\u6790\u7684opt\u53c2\u6570\uff0c\u8c03\u7528run\u51fd\u6570 def main ( opt ): # \u68c0\u6d4brequirements\u6587\u4ef6\u4e2d\u9700\u8981\u7684\u5305\u662f\u5426\u5b89\u88c5\u597d\u4e86 check_requirements ( requirements = ROOT / \"requirements.txt\" , exclude = ( \"tensorboard\" , \"thop\" )) if opt . task in ( \"train\" , \"val\" , \"test\" ): # run normally if opt . conf_thres > 0.001 : # \u66f4\u591a\u8bf7\u89c1 https://github.com/ultralytics/yolov5/issues/1466 LOGGER . info ( f \"WARNING: confidence threshold { opt . conf_thres } > 0.001 produces invalid results\" ) run ( ** vars ( opt )) else : weights = opt . weights if isinstance ( opt . weights , list ) else [ opt . weights ] opt . half = True # FP16 for fastest results if opt . task == \"speed\" : # speed benchmarks # python val.py --task speed --data coco.yaml # --batch 1 --weights yolov5n.pt yolov5s.pt... opt . conf_thres , opt . iou_thres , opt . save_json = 0.25 , 0.45 , False for opt . weights in weights : run ( ** vars ( opt ), plots = False ) elif opt . task == \"study\" : # speed vs mAP benchmarks # python val.py --task study --data coco.yaml # --iou 0.7 --weights yolov5n.pt yolov5s.pt... for opt . weights in weights : f = f \"study_ { Path ( opt . data ) . stem } _ { Path ( opt . weights ) . stem } .txt\" x , y = ( list ( range ( 256 , 1536 + 128 , 128 )), [], ) # x axis (image sizes), y axis # \"study\": \u6a21\u578b\u5728\u5404\u4e2a\u5c3a\u5ea6\u4e0b\u7684\u6307\u6807\u5e76\u53ef\u89c6\u5316\uff0c # \u4e0a\u9762list(range(256, 1536 + 128, 128)),\u4ee3\u8868 img-size \u7684\u5404\u4e2a\u5c3a\u5ea6, \u5177\u4f53\u4ee3\u7801\u5982\u4e0b\uff1a for opt . imgsz in x : # img-size LOGGER . info ( f \" \\n Running { f } --imgsz { opt . imgsz } ...\" ) r , _ , t = run ( ** vars ( opt ), plots = False ) y . append ( r + t ) # results and times np . savetxt ( f , y , fmt = \" %10.4g \" ) # save os . system ( \"zip -r study.zip study_*.txt\" ) # \u53ef\u89c6\u5316\u5404\u4e2a\u6307\u6807 plot_val_study ( x = x ) # plot","title":"3.main\u51fd\u6570"},{"location":"source_code_interpretation/val_py.html#3-run","text":"https://github.com/Oneflow-Inc/one-yolov5/blob/bf8c66e011fcf5b8885068074ffc6b56c113a20c/val.py#L112-L383","title":"3. run\u51fd\u6570"},{"location":"source_code_interpretation/val_py.html#31","text":"# \u4e0d\u53c2\u4e0e\u53cd\u5411\u4f20\u64ad @flow . no_grad () def run ( data , weights = None , # model.pt path(s) batch_size = 32 , # batch size imgsz = 640 , # inference size (pixels) conf_thres = 0.001 , # confidence threshold iou_thres = 0.6 , # NMS IoU threshold task = \"val\" , # train, val, test, speed or study device = \"\" , # cuda device, i.e. 0 or 0,1,2,3 or cpu workers = 8 , # max dataloader workers (per RANK in DDP mode) single_cls = False , # treat as single-class dataset augment = False , # augmented inference verbose = False , # verbose output save_txt = False , # save results to *.txt save_hybrid = False , # save label+prediction hybrid results to *.txt save_conf = False , # save confidences in --save-txt labels save_json = False , # save a COCO-JSON results file project = ROOT / \"runs/val\" , # save to project/name name = \"exp\" , # save to project/name exist_ok = False , # existing project/name ok, do not increment half = True , # use FP16 half-precision inference dnn = False , # use OpenCV DNN for ONNX inference model = None , # \u6a21\u578b \u5982\u679c\u6267\u884cval.py\u5c31\u4e3aNone \u5982\u679c\u6267\u884ctrain.py\u5c31\u4f1a\u4f20\u5165( model=attempt_load(f, device).half() ) dataloader = None , # \u6570\u636e\u52a0\u8f7d\u5668 \u5982\u679c\u6267\u884cval.py\u5c31\u4e3aNone \u5982\u679c\u6267\u884ctrain.py\u5c31\u4f1a\u4f20\u5165testloader save_dir = Path ( \"\" ), # \u6587\u4ef6\u4fdd\u5b58\u8def\u5f84 \u5982\u679c\u6267\u884cval.py\u5c31\u4e3a\u2018\u2019 , \u5982\u679c\u6267\u884ctrain.py\u5c31\u4f1a\u4f20\u5165save_dir(runs/train/expn) plots = True , # \u662f\u5426\u53ef\u89c6\u5316 \u8fd0\u884cval.py\u4f20\u5165\u9ed8\u8ba4True callbacks = Callbacks (), compute_loss = None , # \u635f\u5931\u51fd\u6570 \u8fd0\u884cval.py\u4f20\u5165\u9ed8\u8ba4None \u8fd0\u884ctrain.py\u5219\u4f20\u5165compute_loss(train) ):","title":"3.1 \u8f7d\u5165\u53c2\u6570"},{"location":"source_code_interpretation/val_py.html#32-initializeload-model-and-set-device","text":"if training : # called by train.py \u901a\u8fc7train.py\u8c03\u7528\u7684run\u51fd\u6570 device , of , engine = ( next ( model . parameters ()) . device , True , False , ) # get model device, PyTorch model half &= device . type != \"cpu\" # half precision only supported on CUDA model . half () if half else model . float () else : # called directly \u901a\u8fc7val.py \u8c03\u7528\u7684run\u51fd\u6570 device = select_device ( device , batch_size = batch_size ) # Directories \u751f\u6210save_dir\u6587\u4ef6\u8def\u5f84 run/test/expn save_dir = increment_path ( Path ( project ) / name , exist_ok = exist_ok ) # increment run ( save_dir / \"labels\" if save_txt else save_dir ) . mkdir ( parents = True , exist_ok = True ) # make dir # Load model \u52a0\u8f7d\u6a21\u578b model = DetectMultiBackend ( weights , device = device , dnn = dnn , data = data , fp16 = half ) stride , of , engine = model . stride , model . of , model . engine # \u68c0\u6d4b\u8f93\u5165\u56fe\u7247\u7684\u5206\u8fa8\u7387imgsz\u662f\u5426\u80fd\u88abgs\u6574\u9664 imgsz = check_img_size ( imgsz , s = stride ) # check image size half = model . fp16 # FP16 supported on limited backends with CUDA if engine : batch_size = model . batch_size else : device = model . device if not of : batch_size = 1 # export.py models default to batch-size 1 LOGGER . info ( f \"Forcing --batch-size 1 inference (1,3, { imgsz } , { imgsz } ) for non-OneFlow models\" ) # Data data = check_dataset ( data ) # check","title":"3.2 Initialize/load model and set device"},{"location":"source_code_interpretation/val_py.html#33-configure","text":"# \u914d\u7f6e model . eval () # \u542f\u52a8\u6a21\u578b\u9a8c\u8bc1\u6a21\u5f0f cuda = device . type != \"cpu\" is_coco = isinstance ( data . get ( \"val\" ), str ) and data [ \"val\" ] . endswith ( f \"coco { os . sep } val2017.txt\" ) # COCO dataset nc = 1 if single_cls else int ( data [ \"nc\" ]) # number of classes # iouv: [0.50000, 0.55000, 0.60000, 0.65000, 0.70000, 0.75000, 0.80000, 0.85000, 0.90000, 0.95000] iouv = flow . linspace ( 0.5 , 0.95 , 10 , device = device ) # iou vector for mAP@0.5:0.95 niou = iouv . numel () # \u793a\u4f8b mAP@0.5:0.95 iou\u4e2a\u6570=10\u4e2a","title":"3.3 Configure"},{"location":"source_code_interpretation/val_py.html#34-dataloader","text":"\u901a\u8fc7train.py\u8c03\u7528run\u51fd\u6570\u4f1a\u4f20\u5165\u4e00\u4e2aDataloader\uff0c\u800c\u901a\u8fc7val.py\u9700\u8981\u52a0\u8f7d\u6d4b\u8bd5\u6570\u636e\u96c6 # Dataloader if not training : # \u52a0\u8f7dval\u6570\u636e\u96c6 if of and not single_cls : # check --weights are trained on --data ncm = model . model . nc assert ncm == nc , ( f \" { weights } ( { ncm } classes) trained on different --data than what you passed ( { nc } \" f \"classes). Pass correct combination of\" f \" --weights and --data that are trained together.\" ) model . warmup ( imgsz = ( 1 if of else batch_size , 3 , imgsz , imgsz )) # warmup pad = 0.0 if task in ( \"speed\" , \"benchmark\" ) else 0.5 rect = False if task == \"benchmark\" else of # square inference for benchmarks task = task if task in ( \"train\" , \"val\" , \"test\" ) else \"val\" # path to train/val/test images # \u521b\u5efadataloader \u8fd9\u91cc\u7684rect\u9ed8\u8ba4\u4e3aTrue \u77e9\u5f62\u63a8\u7406\u7528\u4e8e\u6d4b\u8bd5\u96c6 \u5728\u4e0d\u5f71\u54cdmAP\u7684\u60c5\u51b5\u4e0b\u53ef\u4ee5\u5927\u5927\u63d0\u5347\u63a8\u7406\u901f\u5ea6 dataloader = create_dataloader ( data [ task ], imgsz , batch_size , stride , single_cls , pad = pad , rect = rect , workers = workers , prefix = colorstr ( f \" { task } : \" ), )[ 0 ]","title":"3.4 Dataloader"},{"location":"source_code_interpretation/val_py.html#35","text":"# \u521d\u59cb\u5316\u9a8c\u8bc1\u7684\u56fe\u7247\u7684\u6570\u91cf seen = 0 # \u521d\u59cb\u5316\u6df7\u6dc6\u77e9\u9635 confusion_matrix = ConfusionMatrix ( nc = nc ) # \u83b7\u53d6\u6570\u636e\u96c6\u6240\u6709\u7c7b\u522b\u7684\u7c7b\u540d names = dict ( enumerate ( model . names if hasattr ( model , \"names\" ) else model . module . names )) # coco80_to_coco91_class : converts 80-index (val2014) to 91-index (paper) # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/ class_map = coco80_to_coco91_class () if is_coco else list ( range ( 1000 )) # \u8bbe\u7f6e\u8fdb\u5ea6\u6761\u6a21\u5757\u663e\u793a\u4fe1\u606f s = ( \" %20s \" + \" %11s \" * 6 ) % ( \"Class\" , \"Images\" , \"Labels\" , \"P\" , \"R\" , \"mAP@.5\" , \"mAP@.5:.95\" , ) # \u521d\u59cb\u5316\u65f6\u95f4dt[t0, t1, t2] \u548c p, r, f1, mp, mr, map50, map\u6307\u6807 dt , p , r , f1 , mp , mr , map50 , map = ( [ 0.0 , 0.0 , 0.0 ], 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , ) # \u521d\u59cb\u5316\u9a8c\u8bc1\u96c6\u7684\u635f\u5931 loss = flow . zeros ( 3 , device = device ) # \u521d\u59cb\u5316json\u6587\u4ef6\u4e2d\u7684\u5b57\u5178 \u7edf\u8ba1\u4fe1\u606f ap ap_class jdict , stats , ap , ap_class = [], [], [], [] callbacks . run ( \"on_val_start\" ) # \u521d\u59cb\u5316tqdm \u8fdb\u5ea6\u6761\u6a21\u5757 pbar = tqdm ( dataloader , desc = s , bar_format = \" {l_bar}{bar:10}{r_bar}{bar:-10b} \" ) \u793a\u4f8b\u8f93\u51fa val : data = data / coco . yaml , weights = [ 'yolov5x' ], batch_size = 32 , imgsz = 640 , conf_thres = 0.001 , iou_thres = 0.6 , task = val , device = , workers = 8 , single_cls = False , augment = False , verbose = False , save_txt = False , save_hybrid = False , save_conf = False , save_json = True , project = runs / val , name = exp , exist_ok = False , half = True , dnn = False YOLOv5 \ud83d\ude80 v1 .0 - 8 - g94ec5c4 Python - 3.8.13 oneflow - 0.8.1 . dev20221018 + cu112 Fusing layers ... Model summary : 322 layers , 86705005 parameters , 571965 gradients val : Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels ... 4952 found , 48 missing , 0 empty , 0 corrupt : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP @ .5 mAP @ .5 : .95 : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 / 157 [ 01 : 55 < 00 : 00 , 1.36 it / all 5000 36335 0.743 0.627 0.685 0.503 Speed : 0.1 ms pre - process , 7.5 ms inference , 2.1 ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP ... saving runs / val / exp3 / yolov5x_predictions . json ... ... Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0.50 | area = all | maxDets = 100 ] = 0.689 Average Precision ( AP ) @ [ IoU = 0.75 | area = all | maxDets = 100 ] = 0.545 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.339 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.557 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.650 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 1 ] = 0.382 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 10 ] = 0.628 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.523 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.730 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.826","title":"3.5 \u521d\u59cb\u5316"},{"location":"source_code_interpretation/val_py.html#36","text":"for batch_i , ( im , targets , paths , shapes ) in enumerate ( pbar ): \"\"\" https://github.com/Oneflow-Inc/one-yolov5/blob/bf8c66e011fcf5b8885068074ffc6b56c113a20c/utils/dataloaders.py#L735 im : flow.from_numpy(img); targets : labels_out paths: self.im_files[index] shapes : shapes \"\"\"","title":"3.6 \u5f00\u59cb\u9a8c\u8bc1"},{"location":"source_code_interpretation/val_py.html#361","text":"callbacks . run ( \"on_val_batch_start\" ) t1 = time_sync () if cuda : im = im . to ( device ) targets = targets . to ( device ) im = im . half () if half else im . float () # uint8 to fp16/32 im /= 255 # 0 - 255 to 0.0 - 1.0 nb , _ , height , width = im . shape # batch size, channels, height, width t2 = time_sync () dt [ 0 ] += t2 - t1","title":"3.6.1 \u9a8c\u8bc1\u5f00\u59cb\u524d\u7684\u9884\u5904\u7406"},{"location":"source_code_interpretation/val_py.html#362","text":"# Inference out , train_out = model ( im ) if training else model ( im , augment = augment , val = True ) # \u8f93\u51fa\u4e3a\uff1a\u63a8\u7406\u7ed3\u679c\u3001\u635f\u5931\u503c dt [ 1 ] += time_sync () - t2","title":"3.6.2 \u63a8\u7406"},{"location":"source_code_interpretation/val_py.html#363","text":"# Loss \"\"\" \u5206\u7c7b\u635f\u5931(cls_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u5224\u65ad\u6a21\u578b\u662f\u5426\u80fd\u591f\u51c6\u786e\u5730\u8bc6\u522b\u51fa\u56fe\u50cf\u4e2d\u7684\u5bf9\u8c61\uff0c\u5e76\u5c06\u5176\u5206\u7c7b\u5230\u6b63\u786e\u7684\u7c7b\u522b\u4e2d\u3002 \u7f6e\u4fe1\u5ea6\u635f\u5931(obj_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u7684\u6846\uff08\u5373\u5305\u542b\u5bf9\u8c61\u7684\u77e9\u5f62\uff09\u4e0e\u771f\u5b9e\u6846\u4e4b\u95f4\u7684\u5dee\u5f02\u3002 \u8fb9\u754c\u6846\u635f\u5931(box_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4e0e\u771f\u5b9e\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u8fd9\u6709\u52a9\u4e8e\u786e\u4fdd\u6a21\u578b\u80fd\u591f\u51c6\u786e\u5730\u5b9a\u4f4d\u5bf9\u8c61\u3002 \"\"\" if compute_loss : loss += compute_loss ([ x . float () for x in train_out ], targets )[ 1 ] # box, obj, cls","title":"3.6.3 \u8ba1\u7b97\u635f\u5931"},{"location":"source_code_interpretation/val_py.html#364-run-nms","text":"# NMS # \u5c06\u771f\u5b9e\u6846target\u7684xywh(\u56e0\u4e3atarget\u662f\u5728labelimg\u4e2d\u505a\u4e86\u5f52\u4e00\u5316\u7684)\u6620\u5c04\u5230img(test)\u5c3a\u5bf8 targets [:, 2 :] *= flow . tensor (( width , height , width , height ), device = device ) # to pixels # \u5bf9\u5e94 lb = [ targets [ targets [:, 0 ] == i , 1 :] for i in range ( nb )] if save_hybrid else [] # for autolabelling t3 = time_sync () \"\"\"non_max_suppression (\u975e\u6700\u5927\u503c\u6291\u5236) Non-Maximum Suppression (NMS) on inference results to reject overlapping bounding boxes \u8be5\u7b97\u6cd5\u7684\u539f\u7406\uff1a \u5148\u5047\u8bbe\u67096\u4e2a\u77e9\u5f62\u6846\uff0c\u6839\u636e\u5206\u7c7b\u5668\u7684\u7c7b\u522b\u5206\u7c7b\u6982\u7387\u5927\u5c0f\u6392\u5e8f\uff0c\u5047\u8bbe\u4ece\u5c0f\u5230\u5927\u5c5e\u4e8e\u8f66\u8f86(\u88ab\u68c0\u6d4b\u7684\u76ee\u6807)\u7684\u6982\u7387\u5206\u522b\u4e3a\uff1aA\u3001B\u3001C\u3001D\u3001E\u3001F \uff081\uff09\u4ece\u6700\u5927\u6982\u7387 \u77e9\u5f62\u6846F\u5f00\u59cb\uff0c\u5206\u522b\u5224\u65adA~E\u4e0eF\u7684\u91cd\u53e0\u5ea6IOU\u662f\u5426\u5927\u4e8e\u67d0\u4e2a\u6307\u5b9a\u7684\u9600\u503c\uff1b \uff082\uff09\u5047\u8bbeB\u3001D\u4e0eF\u7684\u91cd\u53e0\u5ea6\u5927\u4e8e\u6307\u5b9a\u7684\u9600\u503c\uff0c\u5219\u4e22\u5f03B\u3001D\uff0c\u5e76\u6807\u8bb0\u7b2c\u4e00\u4e2a\u77e9\u5f62\u6846 F\uff0c\u4f7f\u6211\u4eec\u8981\u4fdd\u7559\u7684 \uff083\uff09\u4ece\u5269\u4e0b\u7684\u77e9\u5f62\u6846A\u3001C\u3001E\u4e2d\uff0c\u9009\u62e9\u6700\u5927\u6982\u7387\uff0c\u5047\u8bbe\u4e3aE\uff0c\u7136\u540e\u5224\u65adA\u3001C\u4e0eE\u7684\u91cd\u53e0\u5ea6\u662f\u5426\u5927\u4e8e\u6307\u5b9a\u7684\u9600\u503c\uff0c \u5047\u5982\u5927\u4e8e\u5c31\u4e22\u5f03A\u3001C\uff0c\u5e76\u6807\u8bb0E\uff0c\u662f\u6211\u4eec\u4fdd\u7559\u4e0b\u6765\u7684\u7b2c\u4e8c\u4e2a\u77e9\u5f62\u6846 \u4e00\u76f4\u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\uff0c\u627e\u5230\u6240\u6709\u88ab\u4fdd\u7559\u7684\u77e9\u5f62\u6846 Returns: list of detections, on (n,6) tensor per image [xyxy, conf, cls] \"\"\" out = non_max_suppression ( out , conf_thres , iou_thres , labels = lb , multi_label = True , agnostic = single_cls ) # \u83b7\u53d6NMS\u65f6\u95f4 dt [ 2 ] += time_sync () - t3","title":"3.6.4 Run NMS"},{"location":"source_code_interpretation/val_py.html#365","text":"# Metrics for si , pred in enumerate ( out ): labels = targets [ targets [:, 0 ] == si , 1 :] nl , npr = labels . shape [ 0 ], pred . shape [ 0 ] # number of labels, predictions path , shape = Path ( paths [ si ]), shapes [ si ][ 0 ] correct = flow . zeros ( npr , niou , dtype = flow . bool , device = device ) # init seen += 1 # \u56fe\u7247\u6570\u91cf +1 if npr == 0 : # \u5982\u679c\u9884\u6d4b\u4e3a\u7a7a\uff0c\u5219\u6dfb\u52a0\u7a7a\u7684\u4fe1\u606f\u5230stats\u91cc if nl : stats . append (( correct , * flow . zeros (( 2 , 0 ), device = device ), labels [:, 0 ])) if plots : confusion_matrix . process_batch ( detections = None , labels = labels [:, 0 ]) continue # Predictions if single_cls : pred [:, 5 ] = 0 predn = pred . clone () # \u5c06\u9884\u6d4b\u5750\u6807\u6620\u5c04\u5230\u539f\u56feimg\u4e2d scale_coords ( im [ si ] . shape [ 1 :], predn [:, : 4 ], shape , shapes [ si ][ 1 ]) # native-space pred # Evaluate if nl : tbox = xywh2xyxy ( labels [:, 1 : 5 ]) # target boxes scale_coords ( im [ si ] . shape [ 1 :], tbox , shape , shapes [ si ][ 1 ]) # native-space labels labelsn = flow . cat (( labels [:, 0 : 1 ], tbox ), 1 ) # native-space labels correct = process_batch ( predn , labelsn , iouv ) if plots : confusion_matrix . process_batch ( predn , labelsn ) stats . append (( correct , pred [:, 4 ], pred [:, 5 ], labels [:, 0 ])) # (correct, conf, pcls, tcls) # Save/log if save_txt : save_one_txt ( predn , save_conf , shape , file = save_dir / \"labels\" / f \" { path . stem } .txt\" , ) if save_json : save_one_json ( predn , jdict , path , class_map ) # append to COCO-JSON dictionary callbacks . run ( \"on_val_image_end\" , pred , predn , path , names , im [ si ])","title":"3.6.5 \u7edf\u8ba1\u6bcf\u5f20\u56fe\u7247\u7684\u771f\u5b9e\u6846\u3001\u9884\u6d4b\u6846\u4fe1\u606f"},{"location":"source_code_interpretation/val_py.html#366-batchgtpred","text":"gt : \u771f\u5b9e\u6846\uff0cGround truth box, \u662f\u4eba\u5de5\u6807\u6ce8\u7684\u4f4d\u7f6e\uff0c\u5b58\u653e\u5728\u6807\u6ce8\u6587\u4ef6\u4e2d pred : \u9884\u6d4b\u6846\uff0cPrediction box\uff0c \u662f\u7531\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u8ba1\u7b97\u8f93\u51fa\u7684\u6846 # Plot images if plots and batch_i < 3 : plot_images ( im , targets , paths , save_dir / f \"val_batch { batch_i } _labels.jpg\" , names ) # labels plot_images ( im , output_to_target ( out ), paths , save_dir / f \"val_batch { batch_i } _pred.jpg\" , names , ) # pred callbacks . run ( \"on_val_batch_end\" )","title":"3.6.6 \u753b\u51fa\u524d\u4e09\u4e2abatch\u56fe\u7247\u7684gt\u548cpred\u6846"},{"location":"source_code_interpretation/val_py.html#37","text":"\u6307\u6807\u540d\u5b57\u5728\u4ee3\u7801\u4e2d\u4f53\u73b0 # Compute metrics stats = [ flow . cat ( x , 0 ) . cpu () . numpy () for x in zip ( * stats )] # to numpy if len ( stats ) and stats [ 0 ] . any (): tp , fp , p , r , f1 , ap , ap_class = ap_per_class ( * stats , plot = plots , save_dir = save_dir , names = names ) ap50 , ap = ap [:, 0 ], ap . mean ( 1 ) # AP@0.5, AP@0.5:0.95 mp , mr , map50 , map = p . mean (), r . mean (), ap50 . mean (), ap . mean () nt = np . bincount ( stats [ 3 ] . astype ( int ), minlength = nc ) # number of targets per class","title":"3.7 \u8ba1\u7b97\u6307\u6807"},{"location":"source_code_interpretation/val_py.html#38","text":"# Print results per class if ( verbose or ( nc < 50 and not training )) and nc > 1 and len ( stats ): for i , c in enumerate ( ap_class ): LOGGER . info ( pf % ( names [ c ], seen , nt [ c ], p [ i ], r [ i ], ap50 [ i ], ap [ i ])) # Print speeds t = tuple ( x / seen * 1e3 for x in dt ) # speeds per image if not training : shape = ( batch_size , 3 , imgsz , imgsz ) LOGGER . info ( f \"Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape { shape } \" % t )","title":"3.8 \u6253\u5370\u65e5\u5fd7"},{"location":"source_code_interpretation/val_py.html#39","text":"# Plots if plots : confusion_matrix . plot ( save_dir = save_dir , names = list ( names . values ())) callbacks . run ( \"on_val_end\" ) # Save JSON if save_json and len ( jdict ): w = Path ( weights [ 0 ] if isinstance ( weights , list ) else weights ) . stem if weights is not None else \"\" # weights anno_json = str ( Path ( data . get ( \"path\" , \"../coco\" )) / \"annotations/instances_val2017.json\" ) # annotations json pred_json = str ( save_dir / f \" { w } _predictions.json\" ) # predictions json LOGGER . info ( f \" \\n Evaluating pycocotools mAP... saving { pred_json } ...\" ) with open ( pred_json , \"w\" ) as f : json . dump ( jdict , f ) # try-catch\uff0c\u4f1a\u6709\u54ea\u4e9berror \"\"\" pycocotools\u4ecb\u7ecd: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb \u5c1d\u8bd5: \u4f7f\u7528pycocotools\u5de5\u5177\u8ba1\u7b97loss COCO API - http://cocodataset.org/ \u5931\u8d25error: \u76f4\u63a5\u6253\u5370\u629b\u51fa\u7684\u5f02\u5e38 1. \u53ef\u80fd\u6ca1\u6709\u5b89\u88c5 pycocotools\uff0c\u4f46\u662f\u7f51\u7edc\u6709\u95ee\u9898\uff0c\u65e0\u6cd5\u5b9e\u73b0\u81ea\u52a8\u4e0b\u8f7d\u3002 2. pycocotools\u5305\u7248\u672c\u6709\u95ee\u9898 \"\"\" try : # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb check_requirements ([ \"pycocotools\" ]) from pycocotools.coco import COCO from pycocotools.cocoeval import COCOeval anno = COCO ( anno_json ) # init annotations api pred = anno . loadRes ( pred_json ) # init predictions api eval = COCOeval ( anno , pred , \"bbox\" ) if is_coco : eval . params . imgIds = [ int ( Path ( x ) . stem ) for x in dataloader . dataset . im_files ] # image IDs to evaluate eval . evaluate () eval . accumulate () eval . summarize () map , map50 = eval . stats [: 2 ] # update results (mAP@0.5:0.95, mAP@0.5) except Exception as e : LOGGER . info ( f \"pycocotools unable to run: { e } \" )","title":"3.9\u4fdd\u5b58\u9a8c\u8bc1\u7ed3\u679c"},{"location":"source_code_interpretation/val_py.html#310","text":"# Return results model . float () # for training if not training : s = f \" \\n { len ( list ( save_dir . glob ( 'labels/*.txt' ))) } labels saved to { save_dir / 'labels' } \" if save_txt else \"\" LOGGER . info ( f \"Results saved to { colorstr ( 'bold' , save_dir ) }{ s } \" ) maps = np . zeros ( nc ) + map for i , c in enumerate ( ap_class ): maps [ c ] = ap [ i ] return ( mp , mr , map50 , map , * ( loss . cpu () / len ( dataloader )) . tolist ()), maps , t","title":"3.10 \u8fd4\u56de\u7ed3\u679c"},{"location":"source_code_interpretation/val_py.html#reference","text":"\u3010\u4ec0\u4e48\u662fepoch\u3001batch\u3001batchsize\u3001iteration\uff1f\u4ec0\u4e48\u662f\u771f\u5b9e\u6846\u3001\u9884\u6d4b\u6846\u548c\u951a\u6846\u3011 \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011val.py","title":"Reference"},{"location":"source_code_interpretation/utils/augmentations_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/augmentations.py 1. random_perspective \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c \u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size\u3002 \u4eff\u5c04\u53d8\u6362\u5305\u542b\uff1a \u5e73\u79fb\u3001\u65cb\u8f6c\u3001\u653e\u7f29\u3001\u526a\u5207\u3001\u53cd\u5c04 \u4eff\u5c04\u53d8\u6362\u5305\u62ec\u5982\u4e0b\u6240\u6709\u53d8\u6362\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d8\u6362\u4efb\u610f\u6b21\u5e8f\u6b21\u6570\u7684\u7ec4\u5408\uff1a \u56fe\u7247\u6765\u6e90\u4e8e: https://www.cnblogs.com/shine-lee/p/10950963.html \u5e73\u79fb \uff08translation\uff09\u548c \u65cb\u8f6c \uff08rotation\uff09\u987e\u540d\u601d\u4e49\uff0c\u4e24\u8005\u7684\u7ec4\u5408\u79f0\u4e4b\u4e3a\u6b27\u5f0f\u53d8\u6362\uff08Euclidean transformation\uff09\u6216\u521a\u4f53\u53d8\u6362\uff08rigid transformation\uff09\uff1b \u653e\u7f29 \uff08scaling\uff09\u53ef\u8fdb\u4e00\u6b65\u5206\u4e3auniform scaling\u548cnon-uniform scaling\uff0c\u524d\u8005\u6bcf\u4e2a\u5750\u6807\u8f74\u653e\u7f29\u7cfb\u6570\u76f8\u540c\uff08\u5404\u5411\u540c\u6027\uff09\uff0c\u540e\u8005\u4e0d\u540c\uff1b\u5982\u679c\u653e\u7f29\u7cfb\u6570\u4e3a\u8d1f\uff0c\u5219\u4f1a\u53e0\u52a0\u4e0a\u53cd\u5c04\uff08reflection\uff09\u2014\u2014reflection\u53ef\u4ee5\u770b\u6210\u662f\u7279\u6b8a\u7684scaling\uff1b \u521a\u4f53\u53d8\u6362+uniform scaling \u79f0\u4e4b\u4e3a\uff0c\u76f8\u4f3c\u53d8\u6362\uff08similarity transformation\uff09\uff0c\u5373\u5e73\u79fb+\u65cb\u8f6c+\u5404\u5411\u540c\u6027\u7684\u653e\u7f29\uff1b \u526a\u5207\u53d8\u6362 \uff08shear mapping\uff09\u5c06\u6240\u6709\u70b9\u6cbf\u67d0\u4e00\u6307\u5b9a\u65b9\u5411\u6210\u6bd4\u4f8b\u5730\u5e73\u79fb\uff0c\u8bed\u8a00\u63cf\u8ff0\u4e0d\u5982\u4e0a\u9762\u56fe\u793a\u76f4\u89c2\u3002 random_perspective\u51fd\u6570\u4ee3\u7801\uff1a def random_perspective ( img , targets = (), segments = (), degrees = 10 , translate = 0.1 , scale = 0.1 , shear = 10 , perspective = 0.0 , border = ( 0 , 0 ), ): \"\"\"\u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u4e8eload_mosaic\u4e2d\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e \u968f\u673a\u900f\u89c6\u53d8\u6362 \u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size :params img: mosaic\u6574\u5408\u540e\u7684\u56fe\u7247img4 [2*img_size, 2*img_size] \u5982\u679cmosaic\u540e\u7684\u56fe\u7247\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e segments\u4e3a\u7a7a \u5982\u679c\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e\u5219 segments\u4e0d\u4e3a\u7a7a\u3002 :params targets: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u6b63\u5e38label\u6807\u7b7elabels4(\u4e0d\u6b63\u5e38\u7684\u4f1a\u901a\u8fc7segments2boxes\u5c06\u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u6b63\u5e38\u6807\u7b7e) [N, cls+xyxy] :params segments: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u4e0d\u6b63\u5e38label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62\u4e5f\u5305\u542b\u6b63\u5e38gt) [m, x1y1....] :params degrees: \u65cb\u8f6c\u548c\u7f29\u653e\u77e9\u9635\u53c2\u6570 :params translate: \u5e73\u79fb\u77e9\u9635\u53c2\u6570 :params scale: \u7f29\u653e\u77e9\u9635\u53c2\u6570 :params shear: \u526a\u5207\u77e9\u9635\u53c2\u6570 :params perspective: \u900f\u89c6\u53d8\u6362\u53c2\u6570 :params border: \u7528\u4e8e\u786e\u5b9a\u6700\u540e\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f \u4e00\u822c\u7b49\u4e8e[-img_size//2, -img_size//2] \u90a3\u4e48\u6700\u540e\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f\u4e3a [img_size, img_size] :return img: \u901a\u8fc7\u900f\u89c6\u53d8\u6362/\u4eff\u5c04\u53d8\u6362\u540e\u7684img [img_size, img_size] :return targets: \u901a\u8fc7\u900f\u89c6\u53d8\u6362/\u4eff\u5c04\u53d8\u6362\u540e\u7684img\u5bf9\u5e94\u7684\u6807\u7b7e [n, cls+x1y1x2y2] (\u901a\u8fc7\u7b5b\u9009\u540e\u7684) OpenCV\u4e2d\u7684\u5750\u6807\u7cfb\u5b9a\u4e49\uff0c\u5982\u4e0b\u56fe\u6240\u793a: (0,0)o_________width______________x | | height | | | | | | | y____________________________o(w,h) \"\"\" # \u8bbe\u5b9a\u8f93\u51fa\u56fe\u7247\u7684 H W # border=-s // 2 \u6240\u4ee5\u6700\u540e\u56fe\u7247\u7684\u5927\u5c0f\u76f4\u63a5\u51cf\u534a [img_size, img_size, 3] # \u56fe\u7247\u9ad8\u5bbd\uff08\u52a0\u4e0aborder\u8fb9\u6846\uff09 height = img . shape [ 0 ] + border [ 0 ] * 2 # # \u6700\u7ec8\u8f93\u51fa\u56fe\u50cf\u7684H width = img . shape [ 1 ] + border [ 1 ] * 2 # \u6700\u7ec8\u8f93\u51fa\u56fe\u50cf\u7684W # ============================ \u5f00\u59cb\u53d8\u6362 ============================= # \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5176\u5b9eopencv\u662f\u5b9e\u73b0\u4e86\u4eff\u5c04\u53d8\u6362\u7684, \u4e0d\u8fc7\u6211\u4eec\u8981\u5148\u751f\u6210\u4eff\u5c04\u53d8\u6362\u77e9\u9635M # Center \u8ba1\u7b97\u4e2d\u5fc3\u70b9 C = np . eye ( 3 ) # \u751f\u62103*3\u7684\u5bf9\u89d2\u4e3a1\u7684\u5bf9\u89d2\u77e9\u9635 # x \u65b9\u5411\u7684\u4e2d\u5fc3 C [ 0 , 2 ] = - img . shape [ 1 ] / 2 # x translation (pixels) # y \u65b9\u5411\u7684\u4e2d\u5fc3 C [ 1 , 2 ] = - img . shape [ 0 ] / 2 # y translation (pixels) # Perspective \u8bbe\u7f6e\u900f\u89c6\u53d8\u6362\u77e9\u9635 P = np . eye ( 3 ) # \u751f\u62103*3\u7684\u5bf9\u89d2\u4e3a1\u7684\u5bf9\u89d2\u77e9\u9635 # \u968f\u673a\u751f\u6210x\uff0cy\u65b9\u5411\u4e0a\u7684\u900f\u89c6\u503c P [ 2 , 0 ] = random . uniform ( - perspective , perspective ) # x perspective (about y) P [ 2 , 1 ] = random . uniform ( - perspective , perspective ) # y perspective (about x) # Rotation and Scale # \u65cb\u8f6c\u548c\u7f29\u653e R = np . eye ( 3 ) # \u521d\u59cb\u5316R = [[1,0,0], [0,1,0], [0,0,1]] (3, 3) # a: \u968f\u673a\u751f\u6210\u65cb\u8f6c\u89d2\u5ea6 \u8303\u56f4\u5728(-degrees, degrees) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations a = random . uniform ( - degrees , degrees ) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations # s: \u968f\u673a\u751f\u6210\u65cb\u8f6c\u540e\u56fe\u50cf\u7684\u7f29\u653e\u6bd4\u4f8b \u8303\u56f4\u5728(1 - scale, 1 + scale) # s = 2 ** random.uniform(-scale, scale) # \u968f\u673a\u751f\u6210\u7f29\u653e\u6bd4\u4f8b s = random . uniform ( 1 - scale , 1 + scale ) # s = 2 ** random.uniform(-scale, scale) # cv2.getRotationMatrix2D: \u4e8c\u7ef4\u65cb\u8f6c\u7f29\u653e\u51fd\u6570 # \u53c2\u6570 angle:\u65cb\u8f6c\u89d2\u5ea6 center: \u65cb\u8f6c\u4e2d\u5fc3(\u9ed8\u8ba4\u5c31\u662f\u56fe\u50cf\u7684\u4e2d\u5fc3) scale: \u65cb\u8f6c\u540e\u56fe\u50cf\u7684\u7f29\u653e\u6bd4\u4f8b R [: 2 ] = cv2 . getRotationMatrix2D ( angle = a , center = ( 0 , 0 ), scale = s ) # Shear \u8bbe\u7f6e\u526a\u5207\u77e9\u9635 # \u5f2f\u66f2\u89d2\u5ea6 S = np . eye ( 3 ) # \u521d\u59cb\u5316T = [[1,0,0], [0,1,0], [0,0,1]] S [ 0 , 1 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # x shear (deg) S [ 1 , 0 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # y shear (deg) # Translation \u8bbe\u7f6e\u5e73\u79fb\u77e9\u9635 T = np . eye ( 3 ) # \u521d\u59cb\u5316T = [[1,0,0], [0,1,0], [0,0,1]] (3, 3) T [ 0 , 2 ] = ( random . uniform ( 0.5 - translate , 0.5 + translate ) * width ) # x translation (pixels) T [ 1 , 2 ] = ( random . uniform ( 0.5 - translate , 0.5 + translate ) * height ) # y translation (pixels) # Combined rotation matrix @ \u8868\u793a\u77e9\u9635\u4e58\u6cd5 \u751f\u6210\u4eff\u5c04\u53d8\u6362\u77e9\u9635M M = T @ S @ R @ P @ C # order of operations (right to left) is IMPORTANT # \u5c06\u4eff\u5c04\u53d8\u6362\u77e9\u9635M\u4f5c\u7528\u5728\u56fe\u7247\u4e0a if ( border [ 0 ] != 0 ) or ( border [ 1 ] != 0 ) or ( M != np . eye ( 3 )) . any (): # image changed if perspective : # \u900f\u89c6\u53d8\u6362\u51fd\u6570 \u5b9e\u73b0\u65cb\u8f6c\u5e73\u79fb\u7f29\u653e\u53d8\u6362\u540e\u7684\u5e73\u884c\u7ebf\u4e0d\u518d\u5e73\u884c # \u53c2\u6570\u548c\u4e0b\u9762warpAffine\u7c7b\u4f3c img = cv2 . warpPerspective ( img , M , dsize = ( width , height ), borderValue = ( 114 , 114 , 114 ) ) else : # \u4eff\u5c04\u53d8\u6362\u51fd\u6570 \u5b9e\u73b0\u65cb\u8f6c\u5e73\u79fb\u7f29\u653e\u53d8\u6362\u540e\u7684\u5e73\u884c\u7ebf\u4f9d\u65e7\u5e73\u884c # image changed img [1472, 1472, 3] => [736, 736, 3] # cv2.warpAffine: opencv\u5b9e\u73b0\u7684\u4eff\u5c04\u53d8\u6362\u51fd\u6570 # \u53c2\u6570\uff1a img: \u9700\u8981\u53d8\u5316\u7684\u56fe\u50cf M: \u53d8\u6362\u77e9\u9635 dsize: \u8f93\u51fa\u56fe\u50cf\u7684\u5927\u5c0f flags: \u63d2\u503c\u65b9\u6cd5\u7684\u7ec4\u5408\uff08int \u7c7b\u578b\uff01\uff09 # borderValue: \uff08\u91cd\u70b9\uff01\uff09\u8fb9\u754c\u586b\u5145\u503c \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5b83\u4e3a0\u3002 img = cv2 . warpAffine ( img , M [: 2 ], dsize = ( width , height ), borderValue = ( 114 , 114 , 114 ) ) # Visualize \u53ef\u89c6\u5316 # import matplotlib.pyplot as plt # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel() # ax[0].imshow(img[:, :, ::-1]) # base # ax[1].imshow(img2[:, :, ::-1]) # warped # Transform label coordinates # \u540c\u6837\u9700\u8981\u8c03\u6574\u6807\u7b7e\u4fe1\u606f n = len ( targets ) if n : # \u5224\u65ad\u662f\u5426\u53ef\u4ee5\u4f7f\u7528segment\u6807\u7b7e: \u53ea\u6709segments\u4e0d\u4e3a\u7a7a\u65f6\u5373\u6570\u636e\u96c6\u4e2d\u6709\u591a\u8fb9\u5f62gt\u4e5f\u6709\u6b63\u5e38gt\u65f6\u624d\u80fd\u4f7f\u7528segment\u6807\u7b7e use_segments=True # \u5426\u5219\u5982\u679c\u53ea\u6709\u6b63\u5e38gt\u65f6segments\u4e3a\u7a7a use_segments=False use_segments = any ( x . any () for x in segments ) new = np . zeros (( n , 4 )) # [n, 0+0+0+0] # \u5982\u679c\u4f7f\u7528\u7684\u662fsegments\u6807\u7b7e(\u6807\u7b7e\u4e2d\u542b\u6709\u591a\u8fb9\u5f62gt) if use_segments : # warp segments # \u5148\u5bf9segment\u6807\u7b7e\u8fdb\u884c\u91cd\u91c7\u6837 # \u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000) # [n, x1y2...x99y100] \u6269\u589e\u5750\u6807-> [n, 500, 2] # \u7531\u4e8e\u6709\u65cb\u8f6c\uff0c\u900f\u89c6\u53d8\u6362\u7b49\u64cd\u4f5c\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u591a\u8fb9\u5f62\u6240\u6709\u89d2\u70b9\u90fd\u8fdb\u884c\u53d8\u6362 segments = resample_segments ( segments ) for i , segment in enumerate ( segments ): # segment: [500, 2] \u591a\u8fb9\u5f62\u7684500\u4e2a\u70b9\u5750\u6807xy xy = np . ones (( len ( segment ), 3 )) # [1, 1+1+1] xy [:, : 2 ] = segment # [500, 2] # \u5bf9\u8be5\u6807\u7b7e\u591a\u8fb9\u5f62\u7684\u6240\u6709\u9876\u70b9\u5750\u6807\u8fdb\u884c\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362 xy = xy @ M . T # transform @\u8868\u793a\u77e9\u9635\u4e58\u6cd5\u8fd0\u7b97 xy = ( xy [:, : 2 ] / xy [:, 2 : 3 ] if perspective else xy [:, : 2 ] ) # perspective rescale or affine # \u6839\u636esegment\u7684\u5750\u6807\uff0c\u53d6xy\u5750\u6807\u7684\u6700\u5927\u6700\u5c0f\u503c\uff0c\u5f97\u5230\u8fb9\u6846\u7684\u5750\u6807 clip new [ i ] = segment2box ( xy , width , height ) # xy [500, 2] # \u4e0d\u4f7f\u7528segments\u6807\u7b7e \u4f7f\u7528\u6b63\u5e38\u7684\u77e9\u5f62\u7684\u6807\u7b7etargets else : # warp boxes # \u76f4\u63a5\u5bf9box\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362 # \u7531\u4e8e\u6709\u65cb\u8f6c\uff0c\u900f\u89c6\u53d8\u6362\u7b49\u64cd\u4f5c\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u56db\u4e2a\u89d2\u70b9\u90fd\u8fdb\u884c\u53d8\u6362 xy = np . ones (( n * 4 , 3 )) xy [:, : 2 ] = targets [:, [ 1 , 2 , 3 , 4 , 1 , 4 , 3 , 2 ]] . reshape ( n * 4 , 2 ) # x1y1, x2y2, x1y2, x2y1 xy = xy @ M . T # transform \u6bcf\u4e2a\u89d2\u70b9\u7684\u5750\u6807 xy = ( xy [:, : 2 ] / xy [:, 2 : 3 ] if perspective else xy [:, : 2 ]) . reshape ( n , 8 ) # perspective rescale or affine # create new boxes x = xy [:, [ 0 , 2 , 4 , 6 ]] y = xy [:, [ 1 , 3 , 5 , 7 ]] new = ( np . concatenate (( x . min ( 1 ), y . min ( 1 ), x . max ( 1 ), y . max ( 1 ))) . reshape ( 4 , n ) . T ) # clip \u53bb\u9664\u592a\u5c0f\u7684target(target\u5927\u90e8\u5206\u8dd1\u5230\u56fe\u5916\u53bb\u4e86) new [:, [ 0 , 2 ]] = new [:, [ 0 , 2 ]] . clip ( 0 , width ) new [:, [ 1 , 3 ]] = new [:, [ 1 , 3 ]] . clip ( 0 , height ) # filter candidates \u8fc7\u6ee4target \u7b5b\u9009box # \u8ba1\u7b97\u5019\u9009\u6846\u5e76\u8fd4\u56de # \u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20 \u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236 # \u7b5b\u9009\u7ed3\u679c [n] \u5168\u662fTrue\u6216False \u4f7f\u7528\u6bd4\u5982: box1[i]\u5373\u53ef\u5f97\u5230i\u4e2d\u6240\u6709\u7b49\u4e8eTrue\u7684\u77e9\u5f62\u6846 False\u7684\u77e9\u5f62\u6846\u5168\u90e8\u5220\u9664 i = box_candidates ( box1 = targets [:, 1 : 5 ] . T * s , box2 = new . T , area_thr = 0.01 if use_segments else 0.10 , ) # \u5f97\u5230\u6240\u6709\u6ee1\u8db3\u6761\u4ef6\u7684targets targets = targets [ i ] targets [:, 1 : 5 ] = new [ i ] return img , targets \u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u4e8eload_mosaic\u4e2d\u7684mosaic\u64cd\u4f5c\u4e4b\u540e\u8fdb\u884c\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362\uff1a \u8fd9\u4e2a\u51fd\u6570\u7684\u53c2\u6570\u6765\u81ea hyp.yaml \u4e2d\u7684\u4e0b\u97625\u4e2a\u53c2\u6570\uff1a 2. box_candidates \u5b98\u65b9\u4f5c\u8005\u4ecb\u7ecd Question about function box_candidates() in datasets.py \u2003\u8fd9\u4e2a\u51fd\u6570\u7528\u5728random_perspective\u4e2d\uff0c\u662f\u5bf9\u900f\u89c6\u53d8\u6362\u540e\u7684\u56fe\u7247label\u8fdb\u884c\u7b5b\u9009\uff0c\u53bb\u9664\u88ab\u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u5e76\u4e14\u4fdd\u7559\u4e0b\u6765\u7684\u6846\u7684\u957f\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20\uff0c\u4e14\u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u3002 box_candidates \u51fd\u6570\u4ee3\u7801\uff1a def box_candidates ( box1 , box2 , wh_thr = 2 , ar_thr = 20 , area_thr = 0.1 , eps = 1e-16 ): \"\"\"box_candidates() is used to filter the labels and reject poor label candidates: \u7528\u5728random_perspective\u4e2d \u5bf9\u900f\u89c6\u53d8\u6362\u540e\u7684\u56fe\u7247label\u8fdb\u884c\u7b5b\u9009 \u53bb\u9664\u88ab\u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u8fd8\u6709\u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20\uff0c\u4e14\u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236 Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio :params box1: [4, n] :params box2: [4, n] :params wh_thr: \u7b5b\u9009\u6761\u4ef6 \u5bbd\u9ad8\u9608\u503c :params ar_thr: \u7b5b\u9009\u6761\u4ef6 \u5bbd\u9ad8\u6bd4\u3001\u9ad8\u5bbd\u6bd4\u6700\u5927\u503c\u9608\u503c :params area_thr: \u7b5b\u9009\u6761\u4ef6 \u9762\u79ef\u9608\u503c :params eps: 1e-16 \u63a5\u8fd10\u7684\u6570 \u9632\u6b62\u5206\u6bcd\u4e3a0 :return i: \u7b5b\u9009\u7ed3\u679c [n] \u5168\u662fTrue\u6216False \u4f7f\u7528\u6bd4\u5982: box1[i]\u5373\u53ef\u5f97\u5230i\u4e2d\u6240\u6709\u7b49\u4e8eTrue\u7684\u77e9\u5f62\u6846 False\u7684\u77e9\u5f62\u6846\u5168\u90e8\u5220\u9664 \"\"\" w1 , h1 = box1 [ 2 ] - box1 [ 0 ], box1 [ 3 ] - box1 [ 1 ] # \u6c42\u51fa\u6240\u6709box1\u77e9\u5f62\u6846\u7684\u5bbd\u548c\u9ad8 [n] [n] w2 , h2 = box2 [ 2 ] - box2 [ 0 ], box2 [ 3 ] - box2 [ 1 ] # \u6c42\u51fa\u6240\u6709box2\u77e9\u5f62\u6846\u7684\u5bbd\u548c\u9ad8 [n] [n] ar = np . maximum ( w2 / ( h2 + eps ), h2 / ( w2 + eps )) # \u6c42\u51fa\u6240\u6709box2\u77e9\u5f62\u6846\u7684\u5bbd\u9ad8\u6bd4\u548c\u9ad8\u5bbd\u6bd4\u7684\u8f83\u5927\u8005 [n, 1] # \u7b5b\u9009\u6761\u4ef6: \u589e\u5f3a\u540ew\u3001h\u8981\u5927\u4e8e2 \u589e\u5f3a\u540e\u56fe\u50cf\u4e0e\u589e\u5f3a\u524d\u56fe\u50cf\u9762\u79ef\u6bd4\u503c\u5927\u4e8earea_thr \u5bbd\u9ad8\u6bd4\u5927\u4e8ear_thr return ( ( w2 > wh_thr ) & ( h2 > wh_thr ) & ( w2 * h2 / ( w1 * h1 + eps ) > area_thr ) & ( ar < ar_thr ) ) # candidates 3. replicate \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408\u3002\u53ef\u4ee5\u7528\u5728load_mosaic\u91cc\u7684mosaic\u64cd\u4f5c\u4e4b\u540e \u4ee5\u53carandom_perspective\u64cd\u4f5c\u4e4b\u524d\uff0c \u4f5c\u8005\u9ed8\u8ba4\u662f\u5173\u95ed\u7684\uff0c \u81ea\u5df1\u53ef\u4ee5\u5b9e\u9a8c\u4e00\u4e0b\u6548\u679c\u3002 replicate\u6a21\u5757\u4ee3\u7801\uff1a def replicate ( img , labels ): \"\"\"\u53ef\u4ee5\u7528\u5728load_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d \u4f5c\u8005\u9ed8\u8ba4\u662f\u5173\u95ed\u7684 \u81ea\u5df1\u53ef\u4ee5\u5b9e\u9a8c\u4e00\u4e0b\u6548\u679c \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408 Replicate labels :params img: img4 \u56e0\u4e3a\u662f\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e \u6240\u4ee5size=[2*img_size, 2*img_size] :params labels: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u6b63\u5e38label\u6807\u7b7elabels4(\u4e0d\u6b63\u5e38\u7684\u4f1a\u901a\u8fc7segments2boxes\u5c06\u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u6b63\u5e38\u6807\u7b7e) [N, cls+xyxy] :return img: img4 size=[2*img_size, 2*img_size] \u4e0d\u8fc7\u56fe\u7247\u4e2d\u591a\u4e86\u4e00\u534a\u7684\u8f83\u5c0fgt\u4e2a\u6570 :params labels: labels4 \u4e0d\u8fc7\u53e6\u5916\u589e\u52a0\u4e86\u4e00\u534a\u7684\u8f83\u5c0flabel [3/2N, cls+xyxy] \"\"\" h , w = img . shape [: 2 ] # \u5f97\u5230\u56fe\u7247\u7684\u9ad8\u548c\u5bbd boxes = labels [:, 1 :] . astype ( int ) # \u5f97\u5230\u6240\u6709gt\u6846\u7684\u77e9\u5f62\u5750\u6807 xyxy [N, xyxy] x1 , y1 , x2 , y2 = boxes . T # \u5de6\u4e0a\u89d2: x1 y1 \u53f3\u4e0b\u89d2: x2 y2 [N] s = ( ( x2 - x1 ) + ( y2 - y1 ) ) / 2 # side length (pixels) [N] \u5f97\u5230N\u4e2agt\u7684 (w+h)/2 \u7528\u6765\u8861\u91cfgt\u6846\u7684\u5927\u5c0f # \u751f\u6210\u539f\u6807\u7b7e\u4e2a\u6570\u4e00\u534a\u7684\u65b0\u6807\u7b7e s.size\u8fd4\u56dendarray\u7684\u5143\u7d20\u6570\u91cf for i in s . argsort ()[: round ( s . size * 0.5 )]: # \u8fd4\u56de\u8f83\u5c0f(s\u8f83\u5c0f)\u7684\u4e00\u534agt\u6846\u7684index\u4fe1\u606f x1b , y1b , x2b , y2b = boxes [ i ] # \u5f97\u5230\u8fd9\u4e00\u534a\u8f83\u5c0fgt\u6846\u7684\u5750\u6807\u4fe1\u606f \u5de6\u4e0a\u89d2x1b y1b \u53f3\u4e0b\u89d2x2b y2b bh , bw = y2b - y1b , x2b - x1b # \u5f97\u5230\u8fd9\u4e00\u822c\u8f83\u5c0fgt\u6846\u7684\u9ad8\u5bbd\u4fe1\u606f # \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\u70b9 y\u8303\u56f4\u5728[0, \u56fe\u7247\u9ad8-gt\u6846\u9ad8] x\u8303\u56f4\u5728[0, \u56fe\u7247\u5bbd-gt\u6846\u5bbd] yc , xc = int ( random . uniform ( 0 , h - bh )), int ( random . uniform ( 0 , w - bw ) ) # offset x, y # \u91cd\u65b0\u751f\u6210\u8fd9\u4e00\u534a\u7684gt\u6846\u5750\u6807\u4fe1\u606f(\u504f\u79fb\u540e) x1a , y1a , x2a , y2a = [ xc , yc , xc + bw , yc + bh ] # \u5c06\u56fe\u7247\u4e2d\u771f\u5b9e\u7684gt\u6846\u504f\u79fb\u5230\u5bf9\u5e94\u751f\u6210\u7684\u5750\u6807(\u4e00\u534a\u8f83\u5c0f\u7684\u504f\u79fb \u8f83\u5927\u7684\u4e0d\u504f\u79fb) img [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] # append \u539f\u6765\u7684labels\u6807\u7b7e + \u504f\u79fb\u4e86\u7684\u6807\u7b7e labels = np . append ( labels , [[ labels [ i , 0 ], x1a , y1a , x2a , y2a ]], axis = 0 ) return img , labels \u4f1a\u7528\u5728load_mosaicload_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d\uff08\u4e00\u822c\u4f1a\u5173\u95ed \u5177\u4f53\u8fd8\u8981\u770b\u4e2a\u4eba\u5b9e\u9a8c\uff09 4. letterbox YOLOV5\u4e2d\u7684\u81ea\u9002\u5e94\u56fe\u7247\u7f29\u653e letterbox \u4fdd\u6301\u56fe\u7247\u7684\u5bbd\u9ad8\u6bd4\u4f8b\uff0c\u5269\u4e0b\u7684\u90e8\u5206\u7528\u7070\u8272\u586b\u5145\u3002 letterbox \u7684img\u8f6c\u6362\u90e8\u5206 \u2003\u6b64\u65f6\uff1aauto=False\uff08\u9700\u8981pad\uff09, scale_fill=False, scale_up=False\u3002 \u2003\u663e\u7136\uff0c\u8fd9\u90e8\u5206\u9700\u8981\u7f29\u653e\uff0c\u56e0\u4e3a\u5728\u8fd9\u4e4b\u524d\u7684load_image\u90e8\u5206\u5df2\u7ecf\u7f29\u653e\u8fc7\u4e86\uff08\u6700\u957f\u8fb9\u7b49\u4e8e\u6307\u5b9a\u5927\u5c0f\uff0c\u8f83\u77ed\u8fb9\u7b49\u6bd4\u4f8b\u7f29\u653e\uff09\uff0c \u90a3\u4e48\u5728letterbox\u53ea\u9700\u8981\u8ba1\u7b97\u51fa\u8f83\u5c0f\u8fb9\u9700\u8981\u586b\u5145\u7684pad, \u518d\u5c06\u8f83\u5c0f\u8fb9\u4e24\u8fb9pad\u5230\u76f8\u5e94\u5927\u5c0f\uff08\u6bcf\u4e2abatch\u9700\u8981\u6bcf\u5f20\u56fe\u7247\u7684\u5927\u5c0f\uff0c\u8fd9\u4e2a \u5927\u5c0f\u662f\u4e0d\u76f8\u540c\u7684\uff09\u5373\u53ef\u3002 \u4e5f\u53ef\u4ee5\u7ed3\u5408\u4e0b\u9762\u753b\u7684\u6d41\u7a0b\u56fe\u6765\u7406\u89e3\u4e0b\u9762\u7684letterbox\u4ee3\u7801\uff1a \u56fe\u7247\u6765\u6e90\u4e8e: https://blog.csdn.net/qq_38253797/article/details/119904518 def letterbox ( img , new_shape = ( 640 , 640 ), color = ( 114 , 114 , 114 ), auto = True , scaleFill = False , scaleup = True , stride = 32 , ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u53ea\u5728val\u65f6\u624d\u4f1a\u4f7f\u7528 \u5c06\u56fe\u7247\u7f29\u653e\u8c03\u6574\u5230\u6307\u5b9a\u5927\u5c0f Resize and pad image while meeting stride-multiple constraints https://github.com/ultralytics/yolov3/issues/232 :param img: \u539f\u56fe hwc (\u5f62\u72b6\u662f (h,w,c) \u9ad8\u3001\u5bbd\u3001\u901a\u9053\uff08RGB\uff09 \u50cf\u7d20\u503c\u8303\u56f4\u662f0-255 ) :param new_shape: \u7f29\u653e\u540e\u7684\u6700\u957f\u8fb9\u5927\u5c0f :param color: pad\u7684\u989c\u8272 :param auto: True \u4fdd\u8bc1\u7f29\u653e\u540e\u7684\u56fe\u7247\u4fdd\u6301\u539f\u56fe\u7684\u6bd4\u4f8b \u5373 \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e\uff08\u4e0d\u4f1a\u5931\u771f\uff09 False \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e,\u6700\u540e\u5c06\u8f83\u77ed\u8fb9\u4e24\u8fb9pad\u64cd\u4f5c\u7f29\u653e\u5230\u6700\u957f\u8fb9\u5927\u5c0f\uff08\u4e0d\u4f1a\u5931\u771f\uff09 :param scale_fill: True \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u539f\u56feresize\u5230\u6307\u5b9a\u7684\u5927\u5c0f \u76f8\u5f53\u4e8e\u5c31\u662fresize \u6ca1\u6709pad\u64cd\u4f5c\uff08\u5931\u771f\uff09 :param scale_up: True \u5bf9\u4e8e\u5c0f\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5927\u4e8e\u7684\u4e0d\u53d8 False \u5bf9\u4e8e\u5927\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8e\u7684\u4e0d\u53d8 :return: img: letterbox\u540e\u7684\u56fe\u7247 hwc ratio: wh ratios (dw, dh): w\u548ch\u7684pad \"\"\" shape = img . shape [: 2 ] # \u7b2c\u4e00\u5c42resize\u540e\u56fe\u7247\u5927\u5c0f[h, w] = [343, 512] if isinstance ( new_shape , int ): new_shape = ( new_shape , new_shape ) # (512, 512) # scale ratio (new / old) 1.024 new_shape=(384, 512) r = min ( new_shape [ 0 ] / shape [ 0 ], new_shape [ 1 ] / shape [ 1 ]) # r=1 # \u53ea\u8fdb\u884c\u4e0b\u91c7\u6837 \u56e0\u4e3a\u4e0a\u91c7\u6837\u4f1a\u8ba9\u56fe\u7247\u6a21\u7cca # (for better test mAP) scale_up = False \u5bf9\u4e8e\u5927\u4e8enew_shape\uff08r<1\uff09\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8enew_shape\uff08r>1\uff09\u7684\u4e0d\u53d8 if not scaleup : # only scale down, do not scale up (for better test mAP) r = min ( r , 1.0 ) # Compute padding ratio = r , r # width, height ratios (1, 1) new_unpad = int ( round ( shape [ 1 ] * r )), int ( round ( shape [ 0 ] * r ) ) # wh(512, 343) \u4fdd\u8bc1\u7f29\u653e\u540e\u56fe\u50cf\u6bd4\u4f8b\u4e0d\u53d8 dw , dh = ( new_shape [ 1 ] - new_unpad [ 0 ], new_shape [ 0 ] - new_unpad [ 1 ], ) # wh padding dw=0 dh=41 if auto : # minimum rectangle \u4fdd\u8bc1\u539f\u56fe\u6bd4\u4f8b\u4e0d\u53d8\uff0c\u5c06\u56fe\u50cf\u6700\u5927\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f # \u8fd9\u91cc\u7684\u53d6\u4f59\u64cd\u4f5c\u53ef\u4ee5\u4fdd\u8bc1padding\u540e\u7684\u56fe\u7247\u662f32\u7684\u6574\u6570\u500d(416x416)\uff0c\u5982\u679c\u662f(512x512)\u53ef\u4ee5\u4fdd\u8bc1\u662f64\u7684\u6574\u6570\u500d dw , dh = np . mod ( dw , stride ), np . mod ( dh , stride ) # wh padding dw=0 dh=0 elif scaleFill : # stretch \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u56fe\u7247\u7f29\u653e\u5230\u6307\u5b9a\u5c3a\u5bf8 dw , dh = 0.0 , 0.0 new_unpad = ( new_shape [ 1 ], new_shape [ 0 ]) ratio = new_shape [ 1 ] / shape [ 1 ], new_shape [ 0 ] / shape [ 0 ] # width, height ratios # \u5728\u8f83\u5c0f\u8fb9\u7684\u4e24\u4fa7\u8fdb\u884cpad, \u800c\u4e0d\u662f\u5728\u4e00\u4fa7pad dw /= 2 # divide padding into 2 sides \u5c06padding\u5206\u5230\u4e0a\u4e0b\uff0c\u5de6\u53f3\u4e24\u4fa7 dw=0 dh /= 2 # dh=20.5 # shape:[h, w] new_unpad:[w, h] if shape [:: - 1 ] != new_unpad : # resize \u5c06\u539f\u56feresize\u5230new_unpad\uff08\u957f\u8fb9\u76f8\u540c\uff0c\u6bd4\u4f8b\u76f8\u540c\u7684\u65b0\u56fe\uff09 img = cv2 . resize ( img , new_unpad , interpolation = cv2 . INTER_LINEAR ) top , bottom = int ( round ( dh - 0.1 )), int ( round ( dh + 0.1 ) ) # \u8ba1\u7b97\u4e0a\u4e0b\u4e24\u4fa7\u7684padding # top=20 bottom=21 left , right = int ( round ( dw - 0.1 )), int ( round ( dw + 0.1 ) ) # \u8ba1\u7b97\u5de6\u53f3\u4e24\u4fa7\u7684padding # left=0 right=0 # add border/pad img = cv2 . copyMakeBorder ( img , top , bottom , left , right , cv2 . BORDER_CONSTANT , value = color ) # add border # img: (384, 512, 3) ratio=(1.0,1.0) \u8fd9\u91cc\u6ca1\u6709\u7f29\u653e\u64cd\u4f5c (dw,dh)=(0.0, 20.5) return img , ratio , ( dw , dh ) \u603b\u7ed3\u4e0b\u5728val.py\u6570\u636e\u52a0\u8f7d\u90e8\u5206\u4e3b\u8981\u662f\u505a\u4e86\u4e09\u4ef6\u4e8b\uff1a load_image\u5c06\u56fe\u7247\u4ece\u6587\u4ef6\u4e2d\u52a0\u8f7d\u51fa\u6765\uff0c\u5e76resize\u5230\u76f8\u5e94\u7684\u5c3a\u5bf8\uff08\u6700\u957f\u8fb9\u7b49\u4e8e\u6211\u4eec\u9700\u8981\u7684\u5c3a\u5bf8\uff0c\u6700\u77ed\u8fb9\u7b49\u6bd4\u4f8b\u7f29\u653e\uff09\uff1b letterbox\u5c06\u4e4b\u524dresize\u540e\u7684\u56fe\u7247\u518dpad\u5230\u6211\u4eec\u6240\u9700\u8981\u7684\u653e\u5230dataloader\u4e2d\uff08collate_fn\u51fd\u6570\uff09\u7684\u5c3a\u5bf8\uff08\u77e9\u5f62\u8bad\u7ec3\u8981\u6c42\u540c\u4e00\u4e2a batch\u4e2d\u7684\u56fe\u7247\u7684\u5c3a\u5bf8\u5fc5\u987b\u4fdd\u6301\u4e00\u81f4\uff09\uff1b \u5c06label\u4ece\u76f8\u5bf9\u539f\u56fe\u5c3a\u5bf8\uff08\u539f\u6587\u4ef6\u4e2d\u56fe\u7247\u5c3a\u5bf8\uff09\u7f29\u653e\u5230\u76f8\u5bf9letterbox pad\u540e\u7684\u56fe\u7247\u5c3a\u5bf8\u3002\u56e0\u4e3a\u524d\u4e24\u90e8\u5206\u7684\u56fe\u7247\u5c3a\u5bf8\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u540c\u6837\u7684\u6211\u4eec\u7684label\u4e5f\u9700\u8981\u53d1\u751f\u76f8\u5e94\u7684\u53d8\u5316\u3002 5. cutout \u56fe\u7247\u4e0a\u7684\u968f\u673a\u88c1\u526a\u50cf\u7d20\u5757 \u2003 cutout\u6570\u636e\u589e\u5f3a\uff0c\u7ed9\u56fe\u7247\u968f\u673a\u6dfb\u52a0\u968f\u673a\u5927\u5c0f\u7684\u65b9\u5757\u566a\u58f0 \uff0c\u76ee\u7684\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002\u6e90\u81ea\u8bba\u6587\uff1a Improved Regularization of Convolutional Neural Networks with Cutout \u3002 \u2003\u66f4\u591a\u539f\u7406\u7ec6\u8282\u8bf7\u53c2\u9605\uff1a mosaic \u89e3\u8bfb , \u3010YOLO v4\u3011\u3010trick 8\u3011Data augmentation: MixUp\u3001Random Erasing\u3001CutOut\u3001CutMix\u3001Mosic\u3002 \u793a\u4f8b: image_path = \"one-yolo/data/images/bus.jpg\" img = cv2 . imread ( str ( image_path )) h , w = img . shape [: 2 ] labels = np . array ([[ 0 , 0 , 0 , 800 , 800 ]]) print ( \"\u539f\u56fe\u5bbd\u9ad8: \\n w1= {} \\n h1= {} \" . format ( w , h )) # 810, 1800 lb = cutout ( im = img , labels = labels , p = 1000.0 ) cv2 . imwrite ( \"./00.jpg\" , img ) cutout\u6a21\u5757\u4ee3\u7801\uff1a def cutout ( image , labels ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884ccutout\u589e\u5f3a v5\u6e90\u7801\u4f5c\u8005\u9ed8\u8ba4\u662f\u6ca1\u7528\u7528\u8fd9\u4e2a\u7684 \u611f\u5174\u8da3\u7684\u53ef\u4ee5\u6d4b\u8bd5\u4e00\u4e0b cutout\u6570\u636e\u589e\u5f3a, \u7ed9\u56fe\u7247\u968f\u673a\u6dfb\u52a0\u968f\u673a\u5927\u5c0f\u7684\u65b9\u5757\u566a\u58f0 \u76ee\u7684\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027 \u5b9e\u73b0\uff1a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u6b63\u65b9\u5f62\u533a\u57df\uff0c\u7136\u540e\u91c7\u7528\u51680\u586b\u5145\u5c31OK\u4e86\uff0c\u5f53\u7136\u4e3a\u4e86\u907f\u514d\u586b\u51450\u503c\u5bf9\u8bad\u7ec3\u7684\u5f71\u54cd\uff0c\u5e94\u8be5\u8981\u5bf9\u6570\u636e\u8fdb\u884c\u4e2d\u5fc3\u5f52\u4e00\u5316\u64cd\u4f5c\uff0cnorm\u52300\u3002 \u8bba\u6587: https://arxiv.org/abs/1708.04552 :params image: \u4e00\u5f20\u56fe\u7247 [640, 640, 3] numpy :params labels: \u8fd9\u5f20\u56fe\u7247\u7684\u6807\u7b7e [N, 5]=[N, cls+x1y1x2y2] :return labels: \u7b5b\u9009\u540e\u7684\u8fd9\u5f20\u56fe\u7247\u7684\u6807\u7b7e [M, 5]=[M, cls+x1y1x2y2] M<N \u7b5b\u9009: \u5982\u679c\u968f\u673a\u751f\u6210\u7684\u566a\u58f0\u548c\u539f\u59cbF\u7684gt\u6846\u76f8\u4ea4\u533a\u57df\u5360gt\u6846\u592a\u5927 \u5c31\u7b5b\u51fa\u8fd9\u4e2agt\u6846label \"\"\" h , w = image . shape [: 2 ] # \u83b7\u53d6\u56fe\u7247\u9ad8\u548c\u5bbd def bbox_ioa ( box1 , box2 ): \"\"\"\u7528\u5728cutout\u4e2d \u8ba1\u7b97box1\u548cbox2\u76f8\u4ea4\u9762\u79ef\u4e0ebox2\u9762\u79ef\u7684\u6bd4\u4f8b Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2 :params box1: \u4f20\u5165\u968f\u673a\u751f\u6210\u566a\u58f0 box [4] = [x1y1x2y2] :params box2: \u4f20\u5165\u56fe\u7247\u539f\u59cb\u7684label\u4fe1\u606f [n, 4] = [n, x1y1x2y2] :return [n, 1] \u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u7684\u566a\u58f0box\u4e0en\u4e2a\u539f\u59cblabel\u7684\u76f8\u4ea4\u9762\u79ef\u4e0eb\u539f\u59cblabel\u7684\u6bd4\u503c \"\"\" box2 = box2 . transpose () # Get the coordinates of bounding boxes b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 [ 0 ], box1 [ 1 ], box1 [ 2 ], box1 [ 3 ] b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 [ 0 ], box2 [ 1 ], box2 [ 2 ], box2 [ 3 ] # \u6c42box1\u548cbox2\u7684\u76f8\u4ea4\u9762\u79ef inter_area = ( np . minimum ( b1_x2 , b2_x2 ) - np . maximum ( b1_x1 , b2_x1 )) . clip ( 0 ) * \\ ( np . minimum ( b1_y2 , b2_y2 ) - np . maximum ( b1_y1 , b2_y1 )) . clip ( 0 ) # box\u9762\u79ef box2_area = ( b2_x2 - b2_x1 ) * ( b2_y2 - b2_y1 ) + 1e-16 # \u8fd4\u56debox1\u548cbox2\u76f8\u4ea4\u9762\u79ef \u4e0e box2\u9762\u79ef\u4e4b\u6bd4 return inter_area / box2_area # \u8bbe\u7f6ecutout\u6dfb\u52a0\u566a\u58f0\u7684scale create random masks scales = [ 0.5 ] * 1 + [ 0.25 ] * 2 + [ 0.125 ] * 4 + [ 0.0625 ] * 8 + [ 0.03125 ] * 16 # image size fraction for s in scales : # \u968f\u673a\u751f\u6210\u566a\u58f0 \u5bbd\u9ad8 mask_h = random . randint ( 1 , int ( h * s )) mask_w = random . randint ( 1 , int ( w * s )) # \u968f\u673a\u751f\u6210\u566a\u58f0 box xmin = max ( 0 , random . randint ( 0 , w ) - mask_w // 2 ) ymin = max ( 0 , random . randint ( 0 , h ) - mask_h // 2 ) xmax = min ( w , xmin + mask_w ) ymax = min ( h , ymin + mask_h ) # \u6dfb\u52a0\u968f\u673a\u989c\u8272\u7684\u566a\u58f0 apply random color mask image [ ymin : ymax , xmin : xmax ] = [ random . randint ( 64 , 191 ) for _ in range ( 3 )] # \u8fd4\u56de\u6ca1\u6709\u566a\u58f0\u7684label return unobscured labels if len ( labels ) and s > 0.03 : box = np . array ([ xmin , ymin , xmax , ymax ], dtype = np . float32 ) # \u968f\u673a\u751f\u6210\u7684\u566a\u58f0box # \u8ba1\u7b97\u751f\u6210\u7684\u4e00\u4e2a\u566a\u58f0box\u4e0e\u8fd9\u5f20\u56fe\u7247\u4e2d\u6240\u6709gt\u7684box\u505a\u8ba1\u7b97 inter_area/label_area [n, 1] ioa = bbox_ioa ( box , labels [:, 1 : 5 ]) # remove>60% obscured labels \u4e0d\u80fd\u5207\u7684\u592a\u5927 ioa < 0.60 \u4fdd\u7559cutout\u566a\u58f0\u906e\u6321\u5c0f\u4e8e60%\u7684\u6807\u7b7e labels = labels [ ioa < 0.60 ] return labels \u6ce8\u610f\uff1a \u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884ccutout\u589e\u5f3a\uff1a 6. mixup \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u8fdb\u884cmixup\u6570\u636e\u589e\u5f3a\uff1a\u6309\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247\u3002\u8bba\u6587\uff1a https://arxiv.org/pdf/1710.09412.pdf \u3002 \u2003\u66f4\u591a\u539f\u7406\u7ec6\u8282\u8bf7\u770b\u535a\u5ba2\uff1a \u3010YOLO v4\u3011\u3010trick 8\u3011Data augmentation: MixUp\u3001Random Erasing\u3001CutOut\u3001CutMix\u3001Mosic \u793a\u4f8b: img1 = cv2 . imread ( \"one-yolo/data/images/bus.jpg\" ) img2 = cv2 . imread ( \"one-yolo/data/images/zidane.jpg\" ) img2 = cv2 . resize ( img2 ,( 810 , 1080 )) labels1 = np . array ([[ 0 , 0 , 0 , 800 , 800 ]]) labels2 = np . array ([[ 0 , 800 , 800 , 1080 , 810 ]]) img , labels = mixup ( img1 , labels1 , img2 , labels2 ) cv2 . imwrite ( \"./00.jpg\" , img ) mixup\u6a21\u5757\u4ee3\u7801\uff1a def mixup ( im , labels , im2 , labels2 ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884cmixup\u589e\u5f3a mixup\u6570\u636e\u589e\u5f3a, \u6309\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247 Applies MixUp augmentation \u8bba\u6587: https://arxiv.org/pdf/1710.09412.pdf :params im:\u56fe\u72471 numpy (640, 640, 3) :params labels:[N, 5]=[N, cls+x1y1x2y2] :params im2:\u56fe\u72472 (640, 640, 3) :params labels2:[M, 5]=[M, cls+x1y1x2y2] :return img: \u4e24\u5f20\u56fe\u7247mixup\u589e\u5f3a\u540e\u7684\u56fe\u7247 (640, 640, 3) :return labels: \u4e24\u5f20\u56fe\u7247mixup\u589e\u5f3a\u540e\u7684label\u6807\u7b7e [M+N, cls+x1y1x2y2] \"\"\" # \u968f\u673a\u4ecebeta\u5206\u5e03\u4e2d\u83b7\u53d6\u6bd4\u4f8b,range[0, 1] r = np . random . beta ( 32.0 , 32.0 ) # mixup ratio, alpha=beta=32.0 # \u6309\u7167\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247 im = ( im * r + im2 * ( 1 - r )) . astype ( np . uint8 ) # \u5c06\u4e24\u5f20\u56fe\u7247\u6807\u7b7e\u62fc\u63a5\u5230\u4e00\u8d77 labels = np . concatenate (( labels , labels2 ), 0 ) return im , labels \u6ce8\u610f: \u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884cmixup\u589e\u5f3a\u3002 mixup\u589e\u5f3a\u7531\u8d85\u53c2hyp[\u2018mixup\u2019]\u63a7\u5236\uff0c0\u5219\u5173\u95ed \u9ed8\u8ba4\u4e3a1(\u8868\u793a100%\u6253\u5f00)\u3002 7. hist_equalize \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u4e8e\u5bf9\u56fe\u7247\u8fdb\u884c\u76f4\u65b9\u56fe\u5747\u8861\u5316\u5904\u7406\uff0c\u4f46\u662f\u5728yolov5\u4e2d\u5e76\u6ca1\u6709\u7528\u5230\u8fd9\u4e2a\u51fd\u6570\uff0c\u5b66\u4e60\u4e86\u89e3\u4e0b\u5c31\u597d\uff0c\u4e0d\u662f\u91cd\u70b9\u3002 hist_equalize\u6a21\u5757\u4ee3\u7801: def hist_equalize ( img , clahe = True , bgr = False ): \"\"\"yolov5\u5e76\u6ca1\u6709\u4f7f\u7528\u76f4\u65b9\u56fe\u5747\u8861\u5316\u7684\u589e\u5f3a\u64cd\u4f5c \u53ef\u4ee5\u81ea\u5df1\u8bd5\u8bd5 \u76f4\u65b9\u56fe\u5747\u8861\u5316\u589e\u5f3a\u64cd\u4f5c Equalize histogram on BGR image 'img' with img.shape(n,m,3) and range 0-255 :params img: \u8981\u8fdb\u884c\u76f4\u65b9\u56fe\u5747\u8861\u5316\u7684\u539f\u56fe :params clahe: \u662f\u5426\u8981\u751f\u6210\u81ea\u9002\u5e94\u5747\u8861\u5316\u56fe\u7247 \u9ed8\u8ba4True \u5982\u679c\u662fFalse\u5c31\u751f\u6210\u5168\u5c40\u5747\u8861\u5316\u56fe\u7247 :params bgr: \u4f20\u5165\u7684img\u56fe\u50cf\u662f\u5426\u662fbgr\u56fe\u7247 \u9ed8\u8ba4False :return img: \u5747\u8861\u5316\u4e4b\u540e\u7684\u56fe\u7247 \u5927\u5c0f\u4e0d\u53d8 \u683c\u5f0fRGB \"\"\" # \u56fe\u7247BGR/RGB\u683c\u5f0f -> YUV\u683c\u5f0f yuv = cv2 . cvtColor ( img , cv2 . COLOR_BGR2YUV if bgr else cv2 . COLOR_RGB2YUV ) if clahe : # cv2.createCLAHE\u751f\u6210\u81ea\u9002\u5e94\u5747\u8861\u5316\u56fe\u50cf c = cv2 . createCLAHE ( clipLimit = 2.0 , tileGridSize = ( 8 , 8 )) yuv [:, :, 0 ] = c . apply ( yuv [:, :, 0 ]) else : # \u5168\u5c40\u5747\u8861\u5316 yuv [:, :, 0 ] = cv2 . equalizeHist ( yuv [:, :, 0 ]) # equalize Y channel histogram return cv2 . cvtColor ( yuv , cv2 . COLOR_YUV2BGR if bgr else cv2 . COLOR_YUV2RGB ) # convert YUV image to RGB Reference Question about function box_candidates() in datasets.py \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011 datasets.py yolov5\u6570\u636e\u589e\u5f3a\u5f15\u53d1\u7684\u601d\u8003\u2014\u2014\u900f\u89c6\u53d8\u6362\u77e9\u9635\u7684\u521b\u5efa \u4eff\u5c04\u53d8\u6362\u53ca\u5176\u53d8\u6362\u77e9\u9635\u7684\u7406\u89e3","title":"augmentations.py"},{"location":"source_code_interpretation/utils/augmentations_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/augmentations.py","title":"\u524d\u8a00"},{"location":"source_code_interpretation/utils/augmentations_py.html#1-random_perspective","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c \u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size\u3002 \u4eff\u5c04\u53d8\u6362\u5305\u542b\uff1a \u5e73\u79fb\u3001\u65cb\u8f6c\u3001\u653e\u7f29\u3001\u526a\u5207\u3001\u53cd\u5c04 \u4eff\u5c04\u53d8\u6362\u5305\u62ec\u5982\u4e0b\u6240\u6709\u53d8\u6362\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d8\u6362\u4efb\u610f\u6b21\u5e8f\u6b21\u6570\u7684\u7ec4\u5408\uff1a \u56fe\u7247\u6765\u6e90\u4e8e: https://www.cnblogs.com/shine-lee/p/10950963.html \u5e73\u79fb \uff08translation\uff09\u548c \u65cb\u8f6c \uff08rotation\uff09\u987e\u540d\u601d\u4e49\uff0c\u4e24\u8005\u7684\u7ec4\u5408\u79f0\u4e4b\u4e3a\u6b27\u5f0f\u53d8\u6362\uff08Euclidean transformation\uff09\u6216\u521a\u4f53\u53d8\u6362\uff08rigid transformation\uff09\uff1b \u653e\u7f29 \uff08scaling\uff09\u53ef\u8fdb\u4e00\u6b65\u5206\u4e3auniform scaling\u548cnon-uniform scaling\uff0c\u524d\u8005\u6bcf\u4e2a\u5750\u6807\u8f74\u653e\u7f29\u7cfb\u6570\u76f8\u540c\uff08\u5404\u5411\u540c\u6027\uff09\uff0c\u540e\u8005\u4e0d\u540c\uff1b\u5982\u679c\u653e\u7f29\u7cfb\u6570\u4e3a\u8d1f\uff0c\u5219\u4f1a\u53e0\u52a0\u4e0a\u53cd\u5c04\uff08reflection\uff09\u2014\u2014reflection\u53ef\u4ee5\u770b\u6210\u662f\u7279\u6b8a\u7684scaling\uff1b \u521a\u4f53\u53d8\u6362+uniform scaling \u79f0\u4e4b\u4e3a\uff0c\u76f8\u4f3c\u53d8\u6362\uff08similarity transformation\uff09\uff0c\u5373\u5e73\u79fb+\u65cb\u8f6c+\u5404\u5411\u540c\u6027\u7684\u653e\u7f29\uff1b \u526a\u5207\u53d8\u6362 \uff08shear mapping\uff09\u5c06\u6240\u6709\u70b9\u6cbf\u67d0\u4e00\u6307\u5b9a\u65b9\u5411\u6210\u6bd4\u4f8b\u5730\u5e73\u79fb\uff0c\u8bed\u8a00\u63cf\u8ff0\u4e0d\u5982\u4e0a\u9762\u56fe\u793a\u76f4\u89c2\u3002 random_perspective\u51fd\u6570\u4ee3\u7801\uff1a def random_perspective ( img , targets = (), segments = (), degrees = 10 , translate = 0.1 , scale = 0.1 , shear = 10 , perspective = 0.0 , border = ( 0 , 0 ), ): \"\"\"\u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u4e8eload_mosaic\u4e2d\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e \u968f\u673a\u900f\u89c6\u53d8\u6362 \u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size :params img: mosaic\u6574\u5408\u540e\u7684\u56fe\u7247img4 [2*img_size, 2*img_size] \u5982\u679cmosaic\u540e\u7684\u56fe\u7247\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e segments\u4e3a\u7a7a \u5982\u679c\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e\u5219 segments\u4e0d\u4e3a\u7a7a\u3002 :params targets: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u6b63\u5e38label\u6807\u7b7elabels4(\u4e0d\u6b63\u5e38\u7684\u4f1a\u901a\u8fc7segments2boxes\u5c06\u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u6b63\u5e38\u6807\u7b7e) [N, cls+xyxy] :params segments: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u4e0d\u6b63\u5e38label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62\u4e5f\u5305\u542b\u6b63\u5e38gt) [m, x1y1....] :params degrees: \u65cb\u8f6c\u548c\u7f29\u653e\u77e9\u9635\u53c2\u6570 :params translate: \u5e73\u79fb\u77e9\u9635\u53c2\u6570 :params scale: \u7f29\u653e\u77e9\u9635\u53c2\u6570 :params shear: \u526a\u5207\u77e9\u9635\u53c2\u6570 :params perspective: \u900f\u89c6\u53d8\u6362\u53c2\u6570 :params border: \u7528\u4e8e\u786e\u5b9a\u6700\u540e\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f \u4e00\u822c\u7b49\u4e8e[-img_size//2, -img_size//2] \u90a3\u4e48\u6700\u540e\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f\u4e3a [img_size, img_size] :return img: \u901a\u8fc7\u900f\u89c6\u53d8\u6362/\u4eff\u5c04\u53d8\u6362\u540e\u7684img [img_size, img_size] :return targets: \u901a\u8fc7\u900f\u89c6\u53d8\u6362/\u4eff\u5c04\u53d8\u6362\u540e\u7684img\u5bf9\u5e94\u7684\u6807\u7b7e [n, cls+x1y1x2y2] (\u901a\u8fc7\u7b5b\u9009\u540e\u7684) OpenCV\u4e2d\u7684\u5750\u6807\u7cfb\u5b9a\u4e49\uff0c\u5982\u4e0b\u56fe\u6240\u793a: (0,0)o_________width______________x | | height | | | | | | | y____________________________o(w,h) \"\"\" # \u8bbe\u5b9a\u8f93\u51fa\u56fe\u7247\u7684 H W # border=-s // 2 \u6240\u4ee5\u6700\u540e\u56fe\u7247\u7684\u5927\u5c0f\u76f4\u63a5\u51cf\u534a [img_size, img_size, 3] # \u56fe\u7247\u9ad8\u5bbd\uff08\u52a0\u4e0aborder\u8fb9\u6846\uff09 height = img . shape [ 0 ] + border [ 0 ] * 2 # # \u6700\u7ec8\u8f93\u51fa\u56fe\u50cf\u7684H width = img . shape [ 1 ] + border [ 1 ] * 2 # \u6700\u7ec8\u8f93\u51fa\u56fe\u50cf\u7684W # ============================ \u5f00\u59cb\u53d8\u6362 ============================= # \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5176\u5b9eopencv\u662f\u5b9e\u73b0\u4e86\u4eff\u5c04\u53d8\u6362\u7684, \u4e0d\u8fc7\u6211\u4eec\u8981\u5148\u751f\u6210\u4eff\u5c04\u53d8\u6362\u77e9\u9635M # Center \u8ba1\u7b97\u4e2d\u5fc3\u70b9 C = np . eye ( 3 ) # \u751f\u62103*3\u7684\u5bf9\u89d2\u4e3a1\u7684\u5bf9\u89d2\u77e9\u9635 # x \u65b9\u5411\u7684\u4e2d\u5fc3 C [ 0 , 2 ] = - img . shape [ 1 ] / 2 # x translation (pixels) # y \u65b9\u5411\u7684\u4e2d\u5fc3 C [ 1 , 2 ] = - img . shape [ 0 ] / 2 # y translation (pixels) # Perspective \u8bbe\u7f6e\u900f\u89c6\u53d8\u6362\u77e9\u9635 P = np . eye ( 3 ) # \u751f\u62103*3\u7684\u5bf9\u89d2\u4e3a1\u7684\u5bf9\u89d2\u77e9\u9635 # \u968f\u673a\u751f\u6210x\uff0cy\u65b9\u5411\u4e0a\u7684\u900f\u89c6\u503c P [ 2 , 0 ] = random . uniform ( - perspective , perspective ) # x perspective (about y) P [ 2 , 1 ] = random . uniform ( - perspective , perspective ) # y perspective (about x) # Rotation and Scale # \u65cb\u8f6c\u548c\u7f29\u653e R = np . eye ( 3 ) # \u521d\u59cb\u5316R = [[1,0,0], [0,1,0], [0,0,1]] (3, 3) # a: \u968f\u673a\u751f\u6210\u65cb\u8f6c\u89d2\u5ea6 \u8303\u56f4\u5728(-degrees, degrees) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations a = random . uniform ( - degrees , degrees ) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations # s: \u968f\u673a\u751f\u6210\u65cb\u8f6c\u540e\u56fe\u50cf\u7684\u7f29\u653e\u6bd4\u4f8b \u8303\u56f4\u5728(1 - scale, 1 + scale) # s = 2 ** random.uniform(-scale, scale) # \u968f\u673a\u751f\u6210\u7f29\u653e\u6bd4\u4f8b s = random . uniform ( 1 - scale , 1 + scale ) # s = 2 ** random.uniform(-scale, scale) # cv2.getRotationMatrix2D: \u4e8c\u7ef4\u65cb\u8f6c\u7f29\u653e\u51fd\u6570 # \u53c2\u6570 angle:\u65cb\u8f6c\u89d2\u5ea6 center: \u65cb\u8f6c\u4e2d\u5fc3(\u9ed8\u8ba4\u5c31\u662f\u56fe\u50cf\u7684\u4e2d\u5fc3) scale: \u65cb\u8f6c\u540e\u56fe\u50cf\u7684\u7f29\u653e\u6bd4\u4f8b R [: 2 ] = cv2 . getRotationMatrix2D ( angle = a , center = ( 0 , 0 ), scale = s ) # Shear \u8bbe\u7f6e\u526a\u5207\u77e9\u9635 # \u5f2f\u66f2\u89d2\u5ea6 S = np . eye ( 3 ) # \u521d\u59cb\u5316T = [[1,0,0], [0,1,0], [0,0,1]] S [ 0 , 1 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # x shear (deg) S [ 1 , 0 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # y shear (deg) # Translation \u8bbe\u7f6e\u5e73\u79fb\u77e9\u9635 T = np . eye ( 3 ) # \u521d\u59cb\u5316T = [[1,0,0], [0,1,0], [0,0,1]] (3, 3) T [ 0 , 2 ] = ( random . uniform ( 0.5 - translate , 0.5 + translate ) * width ) # x translation (pixels) T [ 1 , 2 ] = ( random . uniform ( 0.5 - translate , 0.5 + translate ) * height ) # y translation (pixels) # Combined rotation matrix @ \u8868\u793a\u77e9\u9635\u4e58\u6cd5 \u751f\u6210\u4eff\u5c04\u53d8\u6362\u77e9\u9635M M = T @ S @ R @ P @ C # order of operations (right to left) is IMPORTANT # \u5c06\u4eff\u5c04\u53d8\u6362\u77e9\u9635M\u4f5c\u7528\u5728\u56fe\u7247\u4e0a if ( border [ 0 ] != 0 ) or ( border [ 1 ] != 0 ) or ( M != np . eye ( 3 )) . any (): # image changed if perspective : # \u900f\u89c6\u53d8\u6362\u51fd\u6570 \u5b9e\u73b0\u65cb\u8f6c\u5e73\u79fb\u7f29\u653e\u53d8\u6362\u540e\u7684\u5e73\u884c\u7ebf\u4e0d\u518d\u5e73\u884c # \u53c2\u6570\u548c\u4e0b\u9762warpAffine\u7c7b\u4f3c img = cv2 . warpPerspective ( img , M , dsize = ( width , height ), borderValue = ( 114 , 114 , 114 ) ) else : # \u4eff\u5c04\u53d8\u6362\u51fd\u6570 \u5b9e\u73b0\u65cb\u8f6c\u5e73\u79fb\u7f29\u653e\u53d8\u6362\u540e\u7684\u5e73\u884c\u7ebf\u4f9d\u65e7\u5e73\u884c # image changed img [1472, 1472, 3] => [736, 736, 3] # cv2.warpAffine: opencv\u5b9e\u73b0\u7684\u4eff\u5c04\u53d8\u6362\u51fd\u6570 # \u53c2\u6570\uff1a img: \u9700\u8981\u53d8\u5316\u7684\u56fe\u50cf M: \u53d8\u6362\u77e9\u9635 dsize: \u8f93\u51fa\u56fe\u50cf\u7684\u5927\u5c0f flags: \u63d2\u503c\u65b9\u6cd5\u7684\u7ec4\u5408\uff08int \u7c7b\u578b\uff01\uff09 # borderValue: \uff08\u91cd\u70b9\uff01\uff09\u8fb9\u754c\u586b\u5145\u503c \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5b83\u4e3a0\u3002 img = cv2 . warpAffine ( img , M [: 2 ], dsize = ( width , height ), borderValue = ( 114 , 114 , 114 ) ) # Visualize \u53ef\u89c6\u5316 # import matplotlib.pyplot as plt # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel() # ax[0].imshow(img[:, :, ::-1]) # base # ax[1].imshow(img2[:, :, ::-1]) # warped # Transform label coordinates # \u540c\u6837\u9700\u8981\u8c03\u6574\u6807\u7b7e\u4fe1\u606f n = len ( targets ) if n : # \u5224\u65ad\u662f\u5426\u53ef\u4ee5\u4f7f\u7528segment\u6807\u7b7e: \u53ea\u6709segments\u4e0d\u4e3a\u7a7a\u65f6\u5373\u6570\u636e\u96c6\u4e2d\u6709\u591a\u8fb9\u5f62gt\u4e5f\u6709\u6b63\u5e38gt\u65f6\u624d\u80fd\u4f7f\u7528segment\u6807\u7b7e use_segments=True # \u5426\u5219\u5982\u679c\u53ea\u6709\u6b63\u5e38gt\u65f6segments\u4e3a\u7a7a use_segments=False use_segments = any ( x . any () for x in segments ) new = np . zeros (( n , 4 )) # [n, 0+0+0+0] # \u5982\u679c\u4f7f\u7528\u7684\u662fsegments\u6807\u7b7e(\u6807\u7b7e\u4e2d\u542b\u6709\u591a\u8fb9\u5f62gt) if use_segments : # warp segments # \u5148\u5bf9segment\u6807\u7b7e\u8fdb\u884c\u91cd\u91c7\u6837 # \u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000) # [n, x1y2...x99y100] \u6269\u589e\u5750\u6807-> [n, 500, 2] # \u7531\u4e8e\u6709\u65cb\u8f6c\uff0c\u900f\u89c6\u53d8\u6362\u7b49\u64cd\u4f5c\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u591a\u8fb9\u5f62\u6240\u6709\u89d2\u70b9\u90fd\u8fdb\u884c\u53d8\u6362 segments = resample_segments ( segments ) for i , segment in enumerate ( segments ): # segment: [500, 2] \u591a\u8fb9\u5f62\u7684500\u4e2a\u70b9\u5750\u6807xy xy = np . ones (( len ( segment ), 3 )) # [1, 1+1+1] xy [:, : 2 ] = segment # [500, 2] # \u5bf9\u8be5\u6807\u7b7e\u591a\u8fb9\u5f62\u7684\u6240\u6709\u9876\u70b9\u5750\u6807\u8fdb\u884c\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362 xy = xy @ M . T # transform @\u8868\u793a\u77e9\u9635\u4e58\u6cd5\u8fd0\u7b97 xy = ( xy [:, : 2 ] / xy [:, 2 : 3 ] if perspective else xy [:, : 2 ] ) # perspective rescale or affine # \u6839\u636esegment\u7684\u5750\u6807\uff0c\u53d6xy\u5750\u6807\u7684\u6700\u5927\u6700\u5c0f\u503c\uff0c\u5f97\u5230\u8fb9\u6846\u7684\u5750\u6807 clip new [ i ] = segment2box ( xy , width , height ) # xy [500, 2] # \u4e0d\u4f7f\u7528segments\u6807\u7b7e \u4f7f\u7528\u6b63\u5e38\u7684\u77e9\u5f62\u7684\u6807\u7b7etargets else : # warp boxes # \u76f4\u63a5\u5bf9box\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362 # \u7531\u4e8e\u6709\u65cb\u8f6c\uff0c\u900f\u89c6\u53d8\u6362\u7b49\u64cd\u4f5c\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u56db\u4e2a\u89d2\u70b9\u90fd\u8fdb\u884c\u53d8\u6362 xy = np . ones (( n * 4 , 3 )) xy [:, : 2 ] = targets [:, [ 1 , 2 , 3 , 4 , 1 , 4 , 3 , 2 ]] . reshape ( n * 4 , 2 ) # x1y1, x2y2, x1y2, x2y1 xy = xy @ M . T # transform \u6bcf\u4e2a\u89d2\u70b9\u7684\u5750\u6807 xy = ( xy [:, : 2 ] / xy [:, 2 : 3 ] if perspective else xy [:, : 2 ]) . reshape ( n , 8 ) # perspective rescale or affine # create new boxes x = xy [:, [ 0 , 2 , 4 , 6 ]] y = xy [:, [ 1 , 3 , 5 , 7 ]] new = ( np . concatenate (( x . min ( 1 ), y . min ( 1 ), x . max ( 1 ), y . max ( 1 ))) . reshape ( 4 , n ) . T ) # clip \u53bb\u9664\u592a\u5c0f\u7684target(target\u5927\u90e8\u5206\u8dd1\u5230\u56fe\u5916\u53bb\u4e86) new [:, [ 0 , 2 ]] = new [:, [ 0 , 2 ]] . clip ( 0 , width ) new [:, [ 1 , 3 ]] = new [:, [ 1 , 3 ]] . clip ( 0 , height ) # filter candidates \u8fc7\u6ee4target \u7b5b\u9009box # \u8ba1\u7b97\u5019\u9009\u6846\u5e76\u8fd4\u56de # \u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20 \u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236 # \u7b5b\u9009\u7ed3\u679c [n] \u5168\u662fTrue\u6216False \u4f7f\u7528\u6bd4\u5982: box1[i]\u5373\u53ef\u5f97\u5230i\u4e2d\u6240\u6709\u7b49\u4e8eTrue\u7684\u77e9\u5f62\u6846 False\u7684\u77e9\u5f62\u6846\u5168\u90e8\u5220\u9664 i = box_candidates ( box1 = targets [:, 1 : 5 ] . T * s , box2 = new . T , area_thr = 0.01 if use_segments else 0.10 , ) # \u5f97\u5230\u6240\u6709\u6ee1\u8db3\u6761\u4ef6\u7684targets targets = targets [ i ] targets [:, 1 : 5 ] = new [ i ] return img , targets \u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u4e8eload_mosaic\u4e2d\u7684mosaic\u64cd\u4f5c\u4e4b\u540e\u8fdb\u884c\u900f\u89c6\u53d8\u6362 \u6216 \u4eff\u5c04\u53d8\u6362\uff1a \u8fd9\u4e2a\u51fd\u6570\u7684\u53c2\u6570\u6765\u81ea hyp.yaml \u4e2d\u7684\u4e0b\u97625\u4e2a\u53c2\u6570\uff1a","title":"1. random_perspective"},{"location":"source_code_interpretation/utils/augmentations_py.html#2-box_candidates","text":"\u5b98\u65b9\u4f5c\u8005\u4ecb\u7ecd Question about function box_candidates() in datasets.py \u2003\u8fd9\u4e2a\u51fd\u6570\u7528\u5728random_perspective\u4e2d\uff0c\u662f\u5bf9\u900f\u89c6\u53d8\u6362\u540e\u7684\u56fe\u7247label\u8fdb\u884c\u7b5b\u9009\uff0c\u53bb\u9664\u88ab\u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u5e76\u4e14\u4fdd\u7559\u4e0b\u6765\u7684\u6846\u7684\u957f\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20\uff0c\u4e14\u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u3002 box_candidates \u51fd\u6570\u4ee3\u7801\uff1a def box_candidates ( box1 , box2 , wh_thr = 2 , ar_thr = 20 , area_thr = 0.1 , eps = 1e-16 ): \"\"\"box_candidates() is used to filter the labels and reject poor label candidates: \u7528\u5728random_perspective\u4e2d \u5bf9\u900f\u89c6\u53d8\u6362\u540e\u7684\u56fe\u7247label\u8fdb\u884c\u7b5b\u9009 \u53bb\u9664\u88ab\u88c1\u526a\u8fc7\u5c0f\u7684\u6846(\u9762\u79ef\u5c0f\u4e8e\u88c1\u526a\u524d\u7684area_thr) \u8fd8\u6709\u957f\u548c\u5bbd\u5fc5\u987b\u5927\u4e8ewh_thr\u4e2a\u50cf\u7d20\uff0c\u4e14\u957f\u5bbd\u6bd4\u8303\u56f4\u5728(1/ar_thr, ar_thr)\u4e4b\u95f4\u7684\u9650\u5236 Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio :params box1: [4, n] :params box2: [4, n] :params wh_thr: \u7b5b\u9009\u6761\u4ef6 \u5bbd\u9ad8\u9608\u503c :params ar_thr: \u7b5b\u9009\u6761\u4ef6 \u5bbd\u9ad8\u6bd4\u3001\u9ad8\u5bbd\u6bd4\u6700\u5927\u503c\u9608\u503c :params area_thr: \u7b5b\u9009\u6761\u4ef6 \u9762\u79ef\u9608\u503c :params eps: 1e-16 \u63a5\u8fd10\u7684\u6570 \u9632\u6b62\u5206\u6bcd\u4e3a0 :return i: \u7b5b\u9009\u7ed3\u679c [n] \u5168\u662fTrue\u6216False \u4f7f\u7528\u6bd4\u5982: box1[i]\u5373\u53ef\u5f97\u5230i\u4e2d\u6240\u6709\u7b49\u4e8eTrue\u7684\u77e9\u5f62\u6846 False\u7684\u77e9\u5f62\u6846\u5168\u90e8\u5220\u9664 \"\"\" w1 , h1 = box1 [ 2 ] - box1 [ 0 ], box1 [ 3 ] - box1 [ 1 ] # \u6c42\u51fa\u6240\u6709box1\u77e9\u5f62\u6846\u7684\u5bbd\u548c\u9ad8 [n] [n] w2 , h2 = box2 [ 2 ] - box2 [ 0 ], box2 [ 3 ] - box2 [ 1 ] # \u6c42\u51fa\u6240\u6709box2\u77e9\u5f62\u6846\u7684\u5bbd\u548c\u9ad8 [n] [n] ar = np . maximum ( w2 / ( h2 + eps ), h2 / ( w2 + eps )) # \u6c42\u51fa\u6240\u6709box2\u77e9\u5f62\u6846\u7684\u5bbd\u9ad8\u6bd4\u548c\u9ad8\u5bbd\u6bd4\u7684\u8f83\u5927\u8005 [n, 1] # \u7b5b\u9009\u6761\u4ef6: \u589e\u5f3a\u540ew\u3001h\u8981\u5927\u4e8e2 \u589e\u5f3a\u540e\u56fe\u50cf\u4e0e\u589e\u5f3a\u524d\u56fe\u50cf\u9762\u79ef\u6bd4\u503c\u5927\u4e8earea_thr \u5bbd\u9ad8\u6bd4\u5927\u4e8ear_thr return ( ( w2 > wh_thr ) & ( h2 > wh_thr ) & ( w2 * h2 / ( w1 * h1 + eps ) > area_thr ) & ( ar < ar_thr ) ) # candidates","title":"2. box_candidates"},{"location":"source_code_interpretation/utils/augmentations_py.html#3-replicate","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408\u3002\u53ef\u4ee5\u7528\u5728load_mosaic\u91cc\u7684mosaic\u64cd\u4f5c\u4e4b\u540e \u4ee5\u53carandom_perspective\u64cd\u4f5c\u4e4b\u524d\uff0c \u4f5c\u8005\u9ed8\u8ba4\u662f\u5173\u95ed\u7684\uff0c \u81ea\u5df1\u53ef\u4ee5\u5b9e\u9a8c\u4e00\u4e0b\u6548\u679c\u3002 replicate\u6a21\u5757\u4ee3\u7801\uff1a def replicate ( img , labels ): \"\"\"\u53ef\u4ee5\u7528\u5728load_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d \u4f5c\u8005\u9ed8\u8ba4\u662f\u5173\u95ed\u7684 \u81ea\u5df1\u53ef\u4ee5\u5b9e\u9a8c\u4e00\u4e0b\u6548\u679c \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408 Replicate labels :params img: img4 \u56e0\u4e3a\u662f\u7528\u5728mosaic\u64cd\u4f5c\u4e4b\u540e \u6240\u4ee5size=[2*img_size, 2*img_size] :params labels: mosaic\u6574\u5408\u540e\u56fe\u7247\u7684\u6240\u6709\u6b63\u5e38label\u6807\u7b7elabels4(\u4e0d\u6b63\u5e38\u7684\u4f1a\u901a\u8fc7segments2boxes\u5c06\u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u6b63\u5e38\u6807\u7b7e) [N, cls+xyxy] :return img: img4 size=[2*img_size, 2*img_size] \u4e0d\u8fc7\u56fe\u7247\u4e2d\u591a\u4e86\u4e00\u534a\u7684\u8f83\u5c0fgt\u4e2a\u6570 :params labels: labels4 \u4e0d\u8fc7\u53e6\u5916\u589e\u52a0\u4e86\u4e00\u534a\u7684\u8f83\u5c0flabel [3/2N, cls+xyxy] \"\"\" h , w = img . shape [: 2 ] # \u5f97\u5230\u56fe\u7247\u7684\u9ad8\u548c\u5bbd boxes = labels [:, 1 :] . astype ( int ) # \u5f97\u5230\u6240\u6709gt\u6846\u7684\u77e9\u5f62\u5750\u6807 xyxy [N, xyxy] x1 , y1 , x2 , y2 = boxes . T # \u5de6\u4e0a\u89d2: x1 y1 \u53f3\u4e0b\u89d2: x2 y2 [N] s = ( ( x2 - x1 ) + ( y2 - y1 ) ) / 2 # side length (pixels) [N] \u5f97\u5230N\u4e2agt\u7684 (w+h)/2 \u7528\u6765\u8861\u91cfgt\u6846\u7684\u5927\u5c0f # \u751f\u6210\u539f\u6807\u7b7e\u4e2a\u6570\u4e00\u534a\u7684\u65b0\u6807\u7b7e s.size\u8fd4\u56dendarray\u7684\u5143\u7d20\u6570\u91cf for i in s . argsort ()[: round ( s . size * 0.5 )]: # \u8fd4\u56de\u8f83\u5c0f(s\u8f83\u5c0f)\u7684\u4e00\u534agt\u6846\u7684index\u4fe1\u606f x1b , y1b , x2b , y2b = boxes [ i ] # \u5f97\u5230\u8fd9\u4e00\u534a\u8f83\u5c0fgt\u6846\u7684\u5750\u6807\u4fe1\u606f \u5de6\u4e0a\u89d2x1b y1b \u53f3\u4e0b\u89d2x2b y2b bh , bw = y2b - y1b , x2b - x1b # \u5f97\u5230\u8fd9\u4e00\u822c\u8f83\u5c0fgt\u6846\u7684\u9ad8\u5bbd\u4fe1\u606f # \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\u70b9 y\u8303\u56f4\u5728[0, \u56fe\u7247\u9ad8-gt\u6846\u9ad8] x\u8303\u56f4\u5728[0, \u56fe\u7247\u5bbd-gt\u6846\u5bbd] yc , xc = int ( random . uniform ( 0 , h - bh )), int ( random . uniform ( 0 , w - bw ) ) # offset x, y # \u91cd\u65b0\u751f\u6210\u8fd9\u4e00\u534a\u7684gt\u6846\u5750\u6807\u4fe1\u606f(\u504f\u79fb\u540e) x1a , y1a , x2a , y2a = [ xc , yc , xc + bw , yc + bh ] # \u5c06\u56fe\u7247\u4e2d\u771f\u5b9e\u7684gt\u6846\u504f\u79fb\u5230\u5bf9\u5e94\u751f\u6210\u7684\u5750\u6807(\u4e00\u534a\u8f83\u5c0f\u7684\u504f\u79fb \u8f83\u5927\u7684\u4e0d\u504f\u79fb) img [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] # append \u539f\u6765\u7684labels\u6807\u7b7e + \u504f\u79fb\u4e86\u7684\u6807\u7b7e labels = np . append ( labels , [[ labels [ i , 0 ], x1a , y1a , x2a , y2a ]], axis = 0 ) return img , labels \u4f1a\u7528\u5728load_mosaicload_mosaic\u91cc\u5728mosaic\u64cd\u4f5c\u4e4b\u540e random_perspective\u64cd\u4f5c\u4e4b\u524d\uff08\u4e00\u822c\u4f1a\u5173\u95ed \u5177\u4f53\u8fd8\u8981\u770b\u4e2a\u4eba\u5b9e\u9a8c\uff09","title":"3. replicate"},{"location":"source_code_interpretation/utils/augmentations_py.html#4-letterbox","text":"YOLOV5\u4e2d\u7684\u81ea\u9002\u5e94\u56fe\u7247\u7f29\u653e letterbox \u4fdd\u6301\u56fe\u7247\u7684\u5bbd\u9ad8\u6bd4\u4f8b\uff0c\u5269\u4e0b\u7684\u90e8\u5206\u7528\u7070\u8272\u586b\u5145\u3002 letterbox \u7684img\u8f6c\u6362\u90e8\u5206 \u2003\u6b64\u65f6\uff1aauto=False\uff08\u9700\u8981pad\uff09, scale_fill=False, scale_up=False\u3002 \u2003\u663e\u7136\uff0c\u8fd9\u90e8\u5206\u9700\u8981\u7f29\u653e\uff0c\u56e0\u4e3a\u5728\u8fd9\u4e4b\u524d\u7684load_image\u90e8\u5206\u5df2\u7ecf\u7f29\u653e\u8fc7\u4e86\uff08\u6700\u957f\u8fb9\u7b49\u4e8e\u6307\u5b9a\u5927\u5c0f\uff0c\u8f83\u77ed\u8fb9\u7b49\u6bd4\u4f8b\u7f29\u653e\uff09\uff0c \u90a3\u4e48\u5728letterbox\u53ea\u9700\u8981\u8ba1\u7b97\u51fa\u8f83\u5c0f\u8fb9\u9700\u8981\u586b\u5145\u7684pad, \u518d\u5c06\u8f83\u5c0f\u8fb9\u4e24\u8fb9pad\u5230\u76f8\u5e94\u5927\u5c0f\uff08\u6bcf\u4e2abatch\u9700\u8981\u6bcf\u5f20\u56fe\u7247\u7684\u5927\u5c0f\uff0c\u8fd9\u4e2a \u5927\u5c0f\u662f\u4e0d\u76f8\u540c\u7684\uff09\u5373\u53ef\u3002 \u4e5f\u53ef\u4ee5\u7ed3\u5408\u4e0b\u9762\u753b\u7684\u6d41\u7a0b\u56fe\u6765\u7406\u89e3\u4e0b\u9762\u7684letterbox\u4ee3\u7801\uff1a \u56fe\u7247\u6765\u6e90\u4e8e: https://blog.csdn.net/qq_38253797/article/details/119904518 def letterbox ( img , new_shape = ( 640 , 640 ), color = ( 114 , 114 , 114 ), auto = True , scaleFill = False , scaleup = True , stride = 32 , ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u53ea\u5728val\u65f6\u624d\u4f1a\u4f7f\u7528 \u5c06\u56fe\u7247\u7f29\u653e\u8c03\u6574\u5230\u6307\u5b9a\u5927\u5c0f Resize and pad image while meeting stride-multiple constraints https://github.com/ultralytics/yolov3/issues/232 :param img: \u539f\u56fe hwc (\u5f62\u72b6\u662f (h,w,c) \u9ad8\u3001\u5bbd\u3001\u901a\u9053\uff08RGB\uff09 \u50cf\u7d20\u503c\u8303\u56f4\u662f0-255 ) :param new_shape: \u7f29\u653e\u540e\u7684\u6700\u957f\u8fb9\u5927\u5c0f :param color: pad\u7684\u989c\u8272 :param auto: True \u4fdd\u8bc1\u7f29\u653e\u540e\u7684\u56fe\u7247\u4fdd\u6301\u539f\u56fe\u7684\u6bd4\u4f8b \u5373 \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e\uff08\u4e0d\u4f1a\u5931\u771f\uff09 False \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e,\u6700\u540e\u5c06\u8f83\u77ed\u8fb9\u4e24\u8fb9pad\u64cd\u4f5c\u7f29\u653e\u5230\u6700\u957f\u8fb9\u5927\u5c0f\uff08\u4e0d\u4f1a\u5931\u771f\uff09 :param scale_fill: True \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u539f\u56feresize\u5230\u6307\u5b9a\u7684\u5927\u5c0f \u76f8\u5f53\u4e8e\u5c31\u662fresize \u6ca1\u6709pad\u64cd\u4f5c\uff08\u5931\u771f\uff09 :param scale_up: True \u5bf9\u4e8e\u5c0f\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5927\u4e8e\u7684\u4e0d\u53d8 False \u5bf9\u4e8e\u5927\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8e\u7684\u4e0d\u53d8 :return: img: letterbox\u540e\u7684\u56fe\u7247 hwc ratio: wh ratios (dw, dh): w\u548ch\u7684pad \"\"\" shape = img . shape [: 2 ] # \u7b2c\u4e00\u5c42resize\u540e\u56fe\u7247\u5927\u5c0f[h, w] = [343, 512] if isinstance ( new_shape , int ): new_shape = ( new_shape , new_shape ) # (512, 512) # scale ratio (new / old) 1.024 new_shape=(384, 512) r = min ( new_shape [ 0 ] / shape [ 0 ], new_shape [ 1 ] / shape [ 1 ]) # r=1 # \u53ea\u8fdb\u884c\u4e0b\u91c7\u6837 \u56e0\u4e3a\u4e0a\u91c7\u6837\u4f1a\u8ba9\u56fe\u7247\u6a21\u7cca # (for better test mAP) scale_up = False \u5bf9\u4e8e\u5927\u4e8enew_shape\uff08r<1\uff09\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8enew_shape\uff08r>1\uff09\u7684\u4e0d\u53d8 if not scaleup : # only scale down, do not scale up (for better test mAP) r = min ( r , 1.0 ) # Compute padding ratio = r , r # width, height ratios (1, 1) new_unpad = int ( round ( shape [ 1 ] * r )), int ( round ( shape [ 0 ] * r ) ) # wh(512, 343) \u4fdd\u8bc1\u7f29\u653e\u540e\u56fe\u50cf\u6bd4\u4f8b\u4e0d\u53d8 dw , dh = ( new_shape [ 1 ] - new_unpad [ 0 ], new_shape [ 0 ] - new_unpad [ 1 ], ) # wh padding dw=0 dh=41 if auto : # minimum rectangle \u4fdd\u8bc1\u539f\u56fe\u6bd4\u4f8b\u4e0d\u53d8\uff0c\u5c06\u56fe\u50cf\u6700\u5927\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f # \u8fd9\u91cc\u7684\u53d6\u4f59\u64cd\u4f5c\u53ef\u4ee5\u4fdd\u8bc1padding\u540e\u7684\u56fe\u7247\u662f32\u7684\u6574\u6570\u500d(416x416)\uff0c\u5982\u679c\u662f(512x512)\u53ef\u4ee5\u4fdd\u8bc1\u662f64\u7684\u6574\u6570\u500d dw , dh = np . mod ( dw , stride ), np . mod ( dh , stride ) # wh padding dw=0 dh=0 elif scaleFill : # stretch \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u56fe\u7247\u7f29\u653e\u5230\u6307\u5b9a\u5c3a\u5bf8 dw , dh = 0.0 , 0.0 new_unpad = ( new_shape [ 1 ], new_shape [ 0 ]) ratio = new_shape [ 1 ] / shape [ 1 ], new_shape [ 0 ] / shape [ 0 ] # width, height ratios # \u5728\u8f83\u5c0f\u8fb9\u7684\u4e24\u4fa7\u8fdb\u884cpad, \u800c\u4e0d\u662f\u5728\u4e00\u4fa7pad dw /= 2 # divide padding into 2 sides \u5c06padding\u5206\u5230\u4e0a\u4e0b\uff0c\u5de6\u53f3\u4e24\u4fa7 dw=0 dh /= 2 # dh=20.5 # shape:[h, w] new_unpad:[w, h] if shape [:: - 1 ] != new_unpad : # resize \u5c06\u539f\u56feresize\u5230new_unpad\uff08\u957f\u8fb9\u76f8\u540c\uff0c\u6bd4\u4f8b\u76f8\u540c\u7684\u65b0\u56fe\uff09 img = cv2 . resize ( img , new_unpad , interpolation = cv2 . INTER_LINEAR ) top , bottom = int ( round ( dh - 0.1 )), int ( round ( dh + 0.1 ) ) # \u8ba1\u7b97\u4e0a\u4e0b\u4e24\u4fa7\u7684padding # top=20 bottom=21 left , right = int ( round ( dw - 0.1 )), int ( round ( dw + 0.1 ) ) # \u8ba1\u7b97\u5de6\u53f3\u4e24\u4fa7\u7684padding # left=0 right=0 # add border/pad img = cv2 . copyMakeBorder ( img , top , bottom , left , right , cv2 . BORDER_CONSTANT , value = color ) # add border # img: (384, 512, 3) ratio=(1.0,1.0) \u8fd9\u91cc\u6ca1\u6709\u7f29\u653e\u64cd\u4f5c (dw,dh)=(0.0, 20.5) return img , ratio , ( dw , dh ) \u603b\u7ed3\u4e0b\u5728val.py\u6570\u636e\u52a0\u8f7d\u90e8\u5206\u4e3b\u8981\u662f\u505a\u4e86\u4e09\u4ef6\u4e8b\uff1a load_image\u5c06\u56fe\u7247\u4ece\u6587\u4ef6\u4e2d\u52a0\u8f7d\u51fa\u6765\uff0c\u5e76resize\u5230\u76f8\u5e94\u7684\u5c3a\u5bf8\uff08\u6700\u957f\u8fb9\u7b49\u4e8e\u6211\u4eec\u9700\u8981\u7684\u5c3a\u5bf8\uff0c\u6700\u77ed\u8fb9\u7b49\u6bd4\u4f8b\u7f29\u653e\uff09\uff1b letterbox\u5c06\u4e4b\u524dresize\u540e\u7684\u56fe\u7247\u518dpad\u5230\u6211\u4eec\u6240\u9700\u8981\u7684\u653e\u5230dataloader\u4e2d\uff08collate_fn\u51fd\u6570\uff09\u7684\u5c3a\u5bf8\uff08\u77e9\u5f62\u8bad\u7ec3\u8981\u6c42\u540c\u4e00\u4e2a batch\u4e2d\u7684\u56fe\u7247\u7684\u5c3a\u5bf8\u5fc5\u987b\u4fdd\u6301\u4e00\u81f4\uff09\uff1b \u5c06label\u4ece\u76f8\u5bf9\u539f\u56fe\u5c3a\u5bf8\uff08\u539f\u6587\u4ef6\u4e2d\u56fe\u7247\u5c3a\u5bf8\uff09\u7f29\u653e\u5230\u76f8\u5bf9letterbox pad\u540e\u7684\u56fe\u7247\u5c3a\u5bf8\u3002\u56e0\u4e3a\u524d\u4e24\u90e8\u5206\u7684\u56fe\u7247\u5c3a\u5bf8\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u540c\u6837\u7684\u6211\u4eec\u7684label\u4e5f\u9700\u8981\u53d1\u751f\u76f8\u5e94\u7684\u53d8\u5316\u3002","title":"4. letterbox"},{"location":"source_code_interpretation/utils/augmentations_py.html#5-cutout","text":"\u56fe\u7247\u4e0a\u7684\u968f\u673a\u88c1\u526a\u50cf\u7d20\u5757 \u2003 cutout\u6570\u636e\u589e\u5f3a\uff0c\u7ed9\u56fe\u7247\u968f\u673a\u6dfb\u52a0\u968f\u673a\u5927\u5c0f\u7684\u65b9\u5757\u566a\u58f0 \uff0c\u76ee\u7684\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002\u6e90\u81ea\u8bba\u6587\uff1a Improved Regularization of Convolutional Neural Networks with Cutout \u3002 \u2003\u66f4\u591a\u539f\u7406\u7ec6\u8282\u8bf7\u53c2\u9605\uff1a mosaic \u89e3\u8bfb , \u3010YOLO v4\u3011\u3010trick 8\u3011Data augmentation: MixUp\u3001Random Erasing\u3001CutOut\u3001CutMix\u3001Mosic\u3002 \u793a\u4f8b: image_path = \"one-yolo/data/images/bus.jpg\" img = cv2 . imread ( str ( image_path )) h , w = img . shape [: 2 ] labels = np . array ([[ 0 , 0 , 0 , 800 , 800 ]]) print ( \"\u539f\u56fe\u5bbd\u9ad8: \\n w1= {} \\n h1= {} \" . format ( w , h )) # 810, 1800 lb = cutout ( im = img , labels = labels , p = 1000.0 ) cv2 . imwrite ( \"./00.jpg\" , img ) cutout\u6a21\u5757\u4ee3\u7801\uff1a def cutout ( image , labels ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884ccutout\u589e\u5f3a v5\u6e90\u7801\u4f5c\u8005\u9ed8\u8ba4\u662f\u6ca1\u7528\u7528\u8fd9\u4e2a\u7684 \u611f\u5174\u8da3\u7684\u53ef\u4ee5\u6d4b\u8bd5\u4e00\u4e0b cutout\u6570\u636e\u589e\u5f3a, \u7ed9\u56fe\u7247\u968f\u673a\u6dfb\u52a0\u968f\u673a\u5927\u5c0f\u7684\u65b9\u5757\u566a\u58f0 \u76ee\u7684\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027 \u5b9e\u73b0\uff1a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u6b63\u65b9\u5f62\u533a\u57df\uff0c\u7136\u540e\u91c7\u7528\u51680\u586b\u5145\u5c31OK\u4e86\uff0c\u5f53\u7136\u4e3a\u4e86\u907f\u514d\u586b\u51450\u503c\u5bf9\u8bad\u7ec3\u7684\u5f71\u54cd\uff0c\u5e94\u8be5\u8981\u5bf9\u6570\u636e\u8fdb\u884c\u4e2d\u5fc3\u5f52\u4e00\u5316\u64cd\u4f5c\uff0cnorm\u52300\u3002 \u8bba\u6587: https://arxiv.org/abs/1708.04552 :params image: \u4e00\u5f20\u56fe\u7247 [640, 640, 3] numpy :params labels: \u8fd9\u5f20\u56fe\u7247\u7684\u6807\u7b7e [N, 5]=[N, cls+x1y1x2y2] :return labels: \u7b5b\u9009\u540e\u7684\u8fd9\u5f20\u56fe\u7247\u7684\u6807\u7b7e [M, 5]=[M, cls+x1y1x2y2] M<N \u7b5b\u9009: \u5982\u679c\u968f\u673a\u751f\u6210\u7684\u566a\u58f0\u548c\u539f\u59cbF\u7684gt\u6846\u76f8\u4ea4\u533a\u57df\u5360gt\u6846\u592a\u5927 \u5c31\u7b5b\u51fa\u8fd9\u4e2agt\u6846label \"\"\" h , w = image . shape [: 2 ] # \u83b7\u53d6\u56fe\u7247\u9ad8\u548c\u5bbd def bbox_ioa ( box1 , box2 ): \"\"\"\u7528\u5728cutout\u4e2d \u8ba1\u7b97box1\u548cbox2\u76f8\u4ea4\u9762\u79ef\u4e0ebox2\u9762\u79ef\u7684\u6bd4\u4f8b Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2 :params box1: \u4f20\u5165\u968f\u673a\u751f\u6210\u566a\u58f0 box [4] = [x1y1x2y2] :params box2: \u4f20\u5165\u56fe\u7247\u539f\u59cb\u7684label\u4fe1\u606f [n, 4] = [n, x1y1x2y2] :return [n, 1] \u8fd4\u56de\u4e00\u4e2a\u751f\u6210\u7684\u566a\u58f0box\u4e0en\u4e2a\u539f\u59cblabel\u7684\u76f8\u4ea4\u9762\u79ef\u4e0eb\u539f\u59cblabel\u7684\u6bd4\u503c \"\"\" box2 = box2 . transpose () # Get the coordinates of bounding boxes b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 [ 0 ], box1 [ 1 ], box1 [ 2 ], box1 [ 3 ] b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 [ 0 ], box2 [ 1 ], box2 [ 2 ], box2 [ 3 ] # \u6c42box1\u548cbox2\u7684\u76f8\u4ea4\u9762\u79ef inter_area = ( np . minimum ( b1_x2 , b2_x2 ) - np . maximum ( b1_x1 , b2_x1 )) . clip ( 0 ) * \\ ( np . minimum ( b1_y2 , b2_y2 ) - np . maximum ( b1_y1 , b2_y1 )) . clip ( 0 ) # box\u9762\u79ef box2_area = ( b2_x2 - b2_x1 ) * ( b2_y2 - b2_y1 ) + 1e-16 # \u8fd4\u56debox1\u548cbox2\u76f8\u4ea4\u9762\u79ef \u4e0e box2\u9762\u79ef\u4e4b\u6bd4 return inter_area / box2_area # \u8bbe\u7f6ecutout\u6dfb\u52a0\u566a\u58f0\u7684scale create random masks scales = [ 0.5 ] * 1 + [ 0.25 ] * 2 + [ 0.125 ] * 4 + [ 0.0625 ] * 8 + [ 0.03125 ] * 16 # image size fraction for s in scales : # \u968f\u673a\u751f\u6210\u566a\u58f0 \u5bbd\u9ad8 mask_h = random . randint ( 1 , int ( h * s )) mask_w = random . randint ( 1 , int ( w * s )) # \u968f\u673a\u751f\u6210\u566a\u58f0 box xmin = max ( 0 , random . randint ( 0 , w ) - mask_w // 2 ) ymin = max ( 0 , random . randint ( 0 , h ) - mask_h // 2 ) xmax = min ( w , xmin + mask_w ) ymax = min ( h , ymin + mask_h ) # \u6dfb\u52a0\u968f\u673a\u989c\u8272\u7684\u566a\u58f0 apply random color mask image [ ymin : ymax , xmin : xmax ] = [ random . randint ( 64 , 191 ) for _ in range ( 3 )] # \u8fd4\u56de\u6ca1\u6709\u566a\u58f0\u7684label return unobscured labels if len ( labels ) and s > 0.03 : box = np . array ([ xmin , ymin , xmax , ymax ], dtype = np . float32 ) # \u968f\u673a\u751f\u6210\u7684\u566a\u58f0box # \u8ba1\u7b97\u751f\u6210\u7684\u4e00\u4e2a\u566a\u58f0box\u4e0e\u8fd9\u5f20\u56fe\u7247\u4e2d\u6240\u6709gt\u7684box\u505a\u8ba1\u7b97 inter_area/label_area [n, 1] ioa = bbox_ioa ( box , labels [:, 1 : 5 ]) # remove>60% obscured labels \u4e0d\u80fd\u5207\u7684\u592a\u5927 ioa < 0.60 \u4fdd\u7559cutout\u566a\u58f0\u906e\u6321\u5c0f\u4e8e60%\u7684\u6807\u7b7e labels = labels [ ioa < 0.60 ] return labels \u6ce8\u610f\uff1a \u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884ccutout\u589e\u5f3a\uff1a","title":"5. cutout"},{"location":"source_code_interpretation/utils/augmentations_py.html#6-mixup","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u8fdb\u884cmixup\u6570\u636e\u589e\u5f3a\uff1a\u6309\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247\u3002\u8bba\u6587\uff1a https://arxiv.org/pdf/1710.09412.pdf \u3002 \u2003\u66f4\u591a\u539f\u7406\u7ec6\u8282\u8bf7\u770b\u535a\u5ba2\uff1a \u3010YOLO v4\u3011\u3010trick 8\u3011Data augmentation: MixUp\u3001Random Erasing\u3001CutOut\u3001CutMix\u3001Mosic \u793a\u4f8b: img1 = cv2 . imread ( \"one-yolo/data/images/bus.jpg\" ) img2 = cv2 . imread ( \"one-yolo/data/images/zidane.jpg\" ) img2 = cv2 . resize ( img2 ,( 810 , 1080 )) labels1 = np . array ([[ 0 , 0 , 0 , 800 , 800 ]]) labels2 = np . array ([[ 0 , 800 , 800 , 1080 , 810 ]]) img , labels = mixup ( img1 , labels1 , img2 , labels2 ) cv2 . imwrite ( \"./00.jpg\" , img ) mixup\u6a21\u5757\u4ee3\u7801\uff1a def mixup ( im , labels , im2 , labels2 ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884cmixup\u589e\u5f3a mixup\u6570\u636e\u589e\u5f3a, \u6309\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247 Applies MixUp augmentation \u8bba\u6587: https://arxiv.org/pdf/1710.09412.pdf :params im:\u56fe\u72471 numpy (640, 640, 3) :params labels:[N, 5]=[N, cls+x1y1x2y2] :params im2:\u56fe\u72472 (640, 640, 3) :params labels2:[M, 5]=[M, cls+x1y1x2y2] :return img: \u4e24\u5f20\u56fe\u7247mixup\u589e\u5f3a\u540e\u7684\u56fe\u7247 (640, 640, 3) :return labels: \u4e24\u5f20\u56fe\u7247mixup\u589e\u5f3a\u540e\u7684label\u6807\u7b7e [M+N, cls+x1y1x2y2] \"\"\" # \u968f\u673a\u4ecebeta\u5206\u5e03\u4e2d\u83b7\u53d6\u6bd4\u4f8b,range[0, 1] r = np . random . beta ( 32.0 , 32.0 ) # mixup ratio, alpha=beta=32.0 # \u6309\u7167\u6bd4\u4f8b\u878d\u5408\u4e24\u5f20\u56fe\u7247 im = ( im * r + im2 * ( 1 - r )) . astype ( np . uint8 ) # \u5c06\u4e24\u5f20\u56fe\u7247\u6807\u7b7e\u62fc\u63a5\u5230\u4e00\u8d77 labels = np . concatenate (( labels , labels2 ), 0 ) return im , labels \u6ce8\u610f: \u5728LoadImagesAndLabels\u6a21\u5757\u4e2d\u7684__getitem__\u51fd\u6570\u8fdb\u884cmixup\u589e\u5f3a\u3002 mixup\u589e\u5f3a\u7531\u8d85\u53c2hyp[\u2018mixup\u2019]\u63a7\u5236\uff0c0\u5219\u5173\u95ed \u9ed8\u8ba4\u4e3a1(\u8868\u793a100%\u6253\u5f00)\u3002","title":"6. mixup"},{"location":"source_code_interpretation/utils/augmentations_py.html#7-hist_equalize","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u4e8e\u5bf9\u56fe\u7247\u8fdb\u884c\u76f4\u65b9\u56fe\u5747\u8861\u5316\u5904\u7406\uff0c\u4f46\u662f\u5728yolov5\u4e2d\u5e76\u6ca1\u6709\u7528\u5230\u8fd9\u4e2a\u51fd\u6570\uff0c\u5b66\u4e60\u4e86\u89e3\u4e0b\u5c31\u597d\uff0c\u4e0d\u662f\u91cd\u70b9\u3002 hist_equalize\u6a21\u5757\u4ee3\u7801: def hist_equalize ( img , clahe = True , bgr = False ): \"\"\"yolov5\u5e76\u6ca1\u6709\u4f7f\u7528\u76f4\u65b9\u56fe\u5747\u8861\u5316\u7684\u589e\u5f3a\u64cd\u4f5c \u53ef\u4ee5\u81ea\u5df1\u8bd5\u8bd5 \u76f4\u65b9\u56fe\u5747\u8861\u5316\u589e\u5f3a\u64cd\u4f5c Equalize histogram on BGR image 'img' with img.shape(n,m,3) and range 0-255 :params img: \u8981\u8fdb\u884c\u76f4\u65b9\u56fe\u5747\u8861\u5316\u7684\u539f\u56fe :params clahe: \u662f\u5426\u8981\u751f\u6210\u81ea\u9002\u5e94\u5747\u8861\u5316\u56fe\u7247 \u9ed8\u8ba4True \u5982\u679c\u662fFalse\u5c31\u751f\u6210\u5168\u5c40\u5747\u8861\u5316\u56fe\u7247 :params bgr: \u4f20\u5165\u7684img\u56fe\u50cf\u662f\u5426\u662fbgr\u56fe\u7247 \u9ed8\u8ba4False :return img: \u5747\u8861\u5316\u4e4b\u540e\u7684\u56fe\u7247 \u5927\u5c0f\u4e0d\u53d8 \u683c\u5f0fRGB \"\"\" # \u56fe\u7247BGR/RGB\u683c\u5f0f -> YUV\u683c\u5f0f yuv = cv2 . cvtColor ( img , cv2 . COLOR_BGR2YUV if bgr else cv2 . COLOR_RGB2YUV ) if clahe : # cv2.createCLAHE\u751f\u6210\u81ea\u9002\u5e94\u5747\u8861\u5316\u56fe\u50cf c = cv2 . createCLAHE ( clipLimit = 2.0 , tileGridSize = ( 8 , 8 )) yuv [:, :, 0 ] = c . apply ( yuv [:, :, 0 ]) else : # \u5168\u5c40\u5747\u8861\u5316 yuv [:, :, 0 ] = cv2 . equalizeHist ( yuv [:, :, 0 ]) # equalize Y channel histogram return cv2 . cvtColor ( yuv , cv2 . COLOR_YUV2BGR if bgr else cv2 . COLOR_YUV2RGB ) # convert YUV image to RGB","title":"7. hist_equalize"},{"location":"source_code_interpretation/utils/augmentations_py.html#reference","text":"Question about function box_candidates() in datasets.py \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011 datasets.py yolov5\u6570\u636e\u589e\u5f3a\u5f15\u53d1\u7684\u601d\u8003\u2014\u2014\u900f\u89c6\u53d8\u6362\u77e9\u9635\u7684\u521b\u5efa \u4eff\u5c04\u53d8\u6362\u53ca\u5176\u53d8\u6362\u77e9\u9635\u7684\u7406\u89e3","title":"Reference"},{"location":"source_code_interpretation/utils/autoanchor_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/autoanchor.py \u6458\u8981 \u7ef4\u5ea6\u805a\u7c7b \uff08Dimension Clusters\uff09\u3002\u5f53\u628a YOLO \u7ed3\u5408 anchor boxes \u4f7f\u7528\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u4e24\u4e2a\u95ee\u9898\uff1a \u9996\u5148 anchor boxes \u7684\u5c3a\u5bf8\u662f\u624b\u5de5\u6311\u9009\u7684\u3002\u867d\u7136\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u9002\u5f53\u5730\u8c03\u6574 anchor boxes \u5f62\u72b6\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u4ece\u4e00\u5f00\u59cb\u5c31\u4e3a\u7f51\u7edc\u9009\u62e9\u66f4\u597d\u7684 anchor boxes \uff0c\u5c31\u53ef\u4ee5\u8ba9\u7f51\u7edc\u66f4\u5bb9\u6613\u5b66\u4e60\u5e76\u83b7\u5f97\u66f4\u597d\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u56fe1\uff1aVOC \u548c COCO \u4e0a\u7684\u805a\u7c7b\u6846\u5c3a\u5bf8\u3002\u6211\u4eec\u5728\u8fb9\u754c\u6846\u7684\u7ef4\u5ea6(dimensions of bounding boxes) \u4e0a\u8fd0\u884c K-means\u805a\u7c7b\uff0c\u4ee5\u83b7\u5f97\u6211\u4eec\u6a21\u578b\u826f\u597d\u7684\u521d\u59cb anchor boxes \u3002\u5de6\u56fe\u663e\u793a\u4e86\u6211\u4eec\u901a\u8fc7 k \u7684\u5404\u79cd\u9009\u62e9\u83b7\u5f97\u7684 Avg IoU \u3002\u6211\u4eec\u53d1\u73b0 k = 5 \u4e3a\u53ec\u56de\u4e0e\u6a21\u578b\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6298\u4e2d\u3002 \u53f3\u56fe\u663e\u793a\u4e86\u5728 VOC \u548c COCO \u4e0a\u805a\u7c7b\u7c07\u7684\u76f8\u5bf9\u4e2d\u5fc3, \u5e76\u4e14\u8fd9\u4e24\u79cd\u4e0d\u540c\u7684 k \u5bf9\u5e94\u65b9\u6848\u90fd\u559c\u6b22\u66f4\u7a00\u758f\u7684\uff0c\u66f4\u9ad8\u7684\u6846\uff0c\u6b64\u5916\u5728 COCO \u7684\u5c3a\u5bf8\u7684\u53d8\u5316\u6bd4 VOC \u66f4\u5927\u3002 \u6211\u4eec\u4e0d\u7528\u624b\u5de5\u9009\u62e9 anchor boxes\uff0c\u800c\u662f\u5728\u8bad\u7ec3\u96c6\u7684\u8fb9\u754c\u6846\u4e0a\u7684\u7ef4\u5ea6\u4e0a\u8fd0\u884c K-means \u805a\u7c7b\u7b97\u6cd5\uff0c\u81ea\u52a8\u627e\u5230\u826f\u597d\u7684 anchor boxes \u3002 \u5982\u679c\u6211\u4eec\u4f7f\u7528\u5177\u6709\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u6807\u51c6 K-means\uff0c\u90a3\u4e48\u8f83\u5927\u7684\u6846\u4f1a\u6bd4\u8f83\u5c0f\u7684\u6846\u4ea7\u751f\u66f4\u591a\u7684\u8bef\u5dee\u3002 \u4f46\u6211\u4eec\u771f\u6b63\u60f3\u8981\u7684\u662f\u72ec\u7acb\u4e8e\u6846\u7684\u5927\u5c0f\u7684\uff0c\u80fd\u83b7\u5f97\u826f\u597d\u7684 IoU \u5206\u6570\u7684 anchor boxes \u3002 \u56e0\u6b64\u5bf9\u4e8e\u8ddd\u79bb\u7684\u5ea6\u91cf\u65b9\u5f0f\u6211\u4eec\u4f7f\u7528: \\(d(\\text { box, centroid }) = 1-\\operatorname{IoU}(\\text { box }, \\text { centroid })\\) \u6211\u4eec\u7528\u4e0d\u540c\u7684 \\(k\\) \u503c\u8fd0\u884c K-means\u7b97\u6cd5\uff0c\u5e76\u7ed8\u5236\u6700\u63a5\u8fd1\u805a\u7c7b\u4e2d\u5fc3\u7684\u5e73\u5747 Avg IoU\uff08\u89c1\u56fe1\uff09\u3002\u4e3a\u4e86\u5728\u6a21\u578b\u590d\u6742\u5ea6\u548c\u9ad8\u53ec\u56de\u7387\u4e4b\u95f4\u7684\u826f\u597d\u6298\u4e2d\uff0c\u6211\u4eec\u9009\u62e9 k = 5 \uff08\u4e5f\u5c31\u662f5\u79cdanchor boxes\uff09\u7c07\u7684\u76f8\u5bf9\u4e2d\u5fc3 \u4e0e\u624b\u5de5\u9009\u53d6\u7684 anchor boxes \u663e\u7740\u4e0d\u540c\uff0c\u5b83\u6709\u66f4\u5c11\u7684\u77ed\u4e14\u5bbd\u7684\u6846\uff0c\u5e76\u4e14\u6709\u66f4\u591a\u65e2\u957f\u53c8\u7a84\u7684\u6846\u3002 \u88681\u4e2d\uff0c\u6211\u4eec\u5c06\u805a\u7c7b\u7b56\u7565\u5f97\u5230\u7684 anchor boxes \u548c\u624b\u5de5\u9009\u53d6\u7684 anchor boxes \u5728\u6700\u63a5\u8fd1\u7684 Avg IoU \u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002\u901a\u8fc7\u805a\u7c7b\u7b56\u7565\u5f97\u5230\u7684\u4ec55\u79cd anchor boxes \u7684 Avg IoU \u4e3a61.0\uff0c\u5176\u6027\u80fd\u7c7b\u4f3c\u4e8e9\u4e2a\u901a\u8fc7\u7f51\u7edc\u5b66\u4e60\u7684 anchor boxes \u768460.9 ( \u5373Avg IoU\u5df2\u7ecf\u8fbe\u5230\u4e86Faster RCNN\u7684\u6c34\u5e73 )\u3002 \u800c\u4e14\u4f7f\u75289\u79cd anchor boxes \u4f1a\u5f97\u5230\u66f4\u9ad8\u7684 Avg IoU \u3002\u8fd9\u8868\u660e\u4f7f\u7528 K-means\u751f\u6210 anchor boxes \u53ef\u4ee5\u66f4\u597d\u5730\u8868\u793a\u6a21\u578b\u5e76\u4f7f\u5176\u66f4\u5bb9\u6613\u5b66\u4e60\u3002 \\(\\begin{array}{lcc} \\text { Box Generation } & \\# & \\text { Avg IoU } \\\\ \\hline \\text { Cluster SSE } & 5 & 58.7 \\\\ \\text { Cluster IoU } & 5 & 61.0 \\\\ \\text { Anchor Boxes [15] } & 9 & 60.9 \\\\ \\text { Cluster IoU } & 9 & 67.2 \\end{array}\\) \u88681\uff1a VOC 2007 \u4e0a\u805a\u7c7b\u5f97\u7ed3\u679c\u6bd4\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684 anchor boxes \u7ed3\u679c\u8981\u597d\u5f97\u591a\u3002 \u4ec0\u4e48\u662fK-means? K-means\u662f\u975e\u5e38\u7ecf\u5178\u4e14\u6709\u6548\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u6837\u672c\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u76f8\u4f3c\u7a0b\u5ea6\uff09\u5c06\u8f83\u8fd1\u7684\u6837\u672c\u805a\u4e3a\u540c\u4e00\u7c7b\u522b\uff08\u7c07\uff09\u3002 \u5728 yolov5/one-yolov5 \u9879\u76ee\u4e2d\u4f7f\u7528 K-means \u5fc5\u987b\u6ee1\u8db3\u4e0b\u9762\u7684\u6761\u4ef6\uff1a 1. train.py\u7684parse_opt\u4e0b\u7684\u53c2\u6570noautoanchor\u5fc5\u987b\u4e3aFalse 2. hpy.scratch.yaml\u4e0b\u7684anchors\u53c2\u6570\u6ce8\u91ca\u6389\u3002 \u4f7f\u7528K-means\u65f6\u4e3b\u8981\u5173\u6ce8\u4e24\u70b9 \u5982\u4f55\u8868\u793a\u6837\u672c\u4e0e\u6837\u672c\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u6838\u5fc3\u95ee\u9898\uff09\uff0c\u8fd9\u4e2a\u4e00\u822c\u9700\u8981\u6839\u636e\u5177\u4f53\u573a\u666f\u53bb\u8bbe\u8ba1\uff0c\u4e0d\u540c\u7684\u65b9\u6cd5\u805a\u7c7b\u6548\u679c\u4e5f\u4e0d\u540c\uff0c\u6700\u5e38\u89c1\u7684\u5c31\u662f\u6b27\u5f0f\u8ddd\u79bb\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u5e38\u89c1\u7684\u662fIoU\u3002 \u5206\u4e3a\u51e0\u7c7b\uff0c\u8fd9\u4e2a\u4e5f\u662f\u9700\u8981\u6839\u636e\u5e94\u7528\u573a\u666f\u53d6\u9009\u62e9\u7684\uff0c\u4e5f\u662f\u4e00\u4e2a\u8d85\u53c2\u6570\u3002 K-means\u7b97\u6cd5\u4e3b\u8981\u6d41\u7a0b \u624b\u52a8\u8bbe\u5b9a\u7c07\u7684\u4e2a\u6570k\uff0c\u5047\u8bbek=2\uff1b \u5728\u6240\u6709\u6837\u672c\u4e2d\u968f\u673a\u9009\u53d6k\u4e2a\u6837\u672c\u4f5c\u4e3a\u7c07\u7684\u521d\u59cb\u4e2d\u5fc3\uff0c\u5982\u4e0b\u56fe\uff08random clusters\uff09\u4e2d\u4e24\u4e2a\u9ec4\u8272\u7684\u5c0f\u661f\u661f\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\u7684\u4e24\u4e2a\u7c07\u4e2d\u5fc3\uff1b \u8ba1\u7b97\u6bcf\u4e2a\u6837\u672c\u79bb\u6bcf\u4e2a\u7c07\u4e2d\u5fc3\u7684\u8ddd\u79bb\uff08\u8fd9\u91cc\u4ee5\u6b27\u5f0f\u8ddd\u79bb\u4e3a\u4f8b\uff09\uff0c\u7136\u540e\u5c06\u6837\u672c\u5212\u5206\u5230\u79bb\u5b83\u6700\u8fd1\u7684\u7c07\u4e2d\u3002\u5982\u4e0b\u56fe\uff08step 0\uff09\u7528\u4e0d\u540c\u7684\u989c\u8272\u533a\u5206\u4e0d\u540c\u7684\u7c07\uff1b \u66f4\u65b0\u7c07\u7684\u4e2d\u5fc3\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u7c07\u4e2d\u6240\u6709\u6837\u672c\u7684\u5747\u503c\uff08\u65b9\u6cd5\u4e0d\u552f\u4e00\uff09\u4f5c\u4e3a\u65b0\u7684\u7c07\u4e2d\u5fc3\u3002\u5982\u4e0b\u56fe\uff08step 1\uff09\u6240\u793a\uff0c\u4e24\u4e2a\u9ec4\u8272\u7684\u5c0f\u661f\u661f\u5df2\u7ecf\u79fb\u52a8\u5230\u5bf9\u5e94\u7c07\u7684\u4e2d\u5fc3\uff1b \u91cd\u590d\u7b2c3\u6b65\u5230\u7b2c4\u6b65\u76f4\u5230\u7c07\u4e2d\u5fc3\u4e0d\u5728\u53d8\u5316\u6216\u8005\u7c07\u4e2d\u5fc3\u53d8\u5316\u5f88\u5c0f\u6ee1\u8db3\u7ed9\u5b9a\u7ec8\u6b62\u6761\u4ef6\u3002\u5982\u4e0b\u56fe\uff08step2\uff09\u6240\u793a\uff0c\u6700\u7ec8\u805a\u7c7b\u7ed3\u679c\u3002 \u4ec0\u4e48\u662fBPR? BPR\uff08BPR best possible recall\u6765\u6e90\u4e8e\u8bba\u6587: FCOS . \u539f\u8bba\u6587\u89e3\u91ca\uff1a BPR is defined as the ratio of the number of ground-truth boxes a detector can recall at the most divided by all ground-truth boxes. A ground-truth box is considered being recalled if the box is assigned to at least one sample (i.e., a location in FCOS or an anchor box in anchor-based detectors) during training. BPR (best possible recall): \u6700\u591a\u80fd\u88ab\u53ec\u56de\u7684 ground truth \u6846\u6570\u91cf / \u6240\u6709 ground truth \u6846\u6570\u91cf\u3002\u6700\u5927\u503c\u4e3a1 \u8d8a\u5927\u8d8a\u597d \u5c0f\u4e8e0.98\u5c31\u9700\u8981\u4f7f\u7528K-means + \u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\u9009\u62e9\u51fa\u4e0e\u6570\u636e\u96c6\u66f4\u5339\u914d\u7684anchor boxes\u6846\u3002 \u4ec0\u4e48\u662f\u767d\u5316\u64cd\u4f5cwhiten\uff1f \u767d\u5316\u7684\u76ee\u7684\u662f\u53bb\u9664\u8f93\u5165\u6570\u636e\u7684\u5197\u4f59\u4fe1\u606f\u3002\u5047\u8bbe\u8bad\u7ec3\u6570\u636e\u662f\u56fe\u50cf\uff0c\u7531\u4e8e\u56fe\u50cf\u4e2d\u76f8\u90bb\u50cf\u7d20\u4e4b\u95f4\u5177\u6709\u5f88\u5f3a\u7684\u76f8\u5173\u6027\uff0c\u6240\u4ee5\u7528\u4e8e\u8bad\u7ec3\u65f6\u8f93\u5165\u662f\u5197\u4f59\u7684\uff1b\u767d\u5316\u7684\u76ee\u7684\u5c31\u662f\u964d\u4f4e\u8f93\u5165\u7684\u5197\u4f59\u6027\u3002 \u8f93\u5165\u6570\u636e\u96c6X\uff0c\u7ecf\u8fc7\u767d\u5316\u5904\u7406\u540e\uff0c\u65b0\u7684\u6570\u636eX\u2019\u6ee1\u8db3\u4e24\u4e2a\u6027\u8d28\uff1a \u7279\u5f81\u4e4b\u95f4\u76f8\u5173\u6027\u8f83\u4f4e\uff1b \u6240\u6709\u7279\u5f81\u5177\u6709\u76f8\u540c\u7684\u65b9\u5dee=1 \u5e38\u89c1\u7684\u4f5c\u6cd5\u662f\uff1a\u5bf9\u6bcf\u4e00\u4e2a\u6570\u636e\u505a\u4e00\u4e2a\u6807\u51c6\u5dee\u5f52\u4e00\u5316\u5904\u7406\uff08\u9664\u4ee5\u6807\u51c6\u5dee\uff09\u3002scipy.cluster.vq.kmeans() \u51fd\u6570\u8f93\u5165\u7684\u6570\u636e\u5c31\u662f\u5fc5\u987b\u662f\u767d\u5316\u540e\u7684\u6570\u636e\u3002\u76f8\u5e94\u8f93\u51fa\u7684 anchor boxes \u4e5f\u662f\u767d\u5316\u540e\u7684anchor\uff0c\u6240\u4ee5\u9700\u8981\u5c06anchor boxes \u90fd\u4e58\u4ee5\u6807\u51c6\u5dee\u6062\u590d\u5230\u539f\u59cb\u56fe\u50cf\u5c3a\u5ea6\u3002 YOLOv5 \u4e2d\u7684 autoanchor.py \u4ee3\u7801\u89e3\u6790 1. \u5bfc\u5165\u9700\u8981\u7684\u5305 import numpy as np # numpy\u77e9\u9635\u64cd\u4f5c\u6a21\u5757 import oneflow as flow # OneFlow\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757 import yaml # \u64cd\u4f5cyaml\u6587\u4ef6\u6a21\u5757 from tqdm import tqdm # Python\u8fdb\u5ea6\u6761\u6a21\u5757 from utils.general import LOGGER , colorstr # \u65e5\u5fd7\u6a21\u5757 PREFIX = colorstr ( \"AutoAnchor: \" ) 2.check_anchor_order \u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u786e\u8ba4\u5f53\u524danchors\u548cstride\u7684\u987a\u5e8f\u662f\u5426\u662f\u4e00\u81f4\u7684\uff0c\u56e0\u4e3a\u6211\u4eec\u7684m.anchors\u662f\u76f8\u5bf9\u5404\u4e2afeature map \uff08\u6bcf\u4e2afeature map\u7684\u611f\u53d7\u91ce\u4e0d\u540c \u68c0\u6d4b\u7684\u76ee\u6807\u5927\u5c0f\u4e5f\u4e0d\u540c \u9002\u5408\u7684anchor\u5927\u5c0f\u4e5f\u4e0d\u540c\uff09\u6240\u4ee5\u5fc5\u987b\u8981\u987a\u5e8f\u4e00\u81f4 \u5426\u5219\u6548\u679c\u4f1a\u5f88\u4e0d\u597d\u3002 \u8fd9\u4e2a\u51fd\u6570\u4e00\u822c\u7528\u4e8echeck_anchors\u6700\u540e\u9636\u6bb5\u3002 def check_anchor_order ( m ): \"\"\"\u7528\u5728check_anchors\u51fd\u6570\u7684\u6700\u540e \u786e\u5b9a anchors \u548c stride \u7684\u987a\u5e8f\u662f\u4e00\u81f4\u7684 Check anchor order against stride order for YOLOv5 Detect() module m, and correct if necessary :params m: model\u4e2d\u7684\u6700\u540e\u4e00\u5c42 Detect\u5c42 \"\"\" # Check anchor order against stride order for YOLOv5 Detect() module m, and correct if necessary # \u8ba1\u7b97anchor\u7684\u9762\u79ef anchor area [9] a = m . anchors . prod ( - 1 ) . mean ( - 1 ) . view ( - 1 ) # mean anchor area per output layer # \u8ba1\u7b97\u6700\u5927anchor\u4e0e\u6700\u5c0fanchor\u9762\u79ef\u5dee da = a [ - 1 ] - a [ 0 ] # delta a # \u8ba1\u7b97\u6700\u5927stride\u4e0e\u6700\u5c0fstride\u5dee # m.stride: model strides # https://github.com/Oneflow-Inc/one-yolov5/blob/bf8c66e011fcf5b8885068074ffc6b56c113a20c/models/yolo.py#L144-L152 ds = m . stride [ - 1 ] - m . stride [ 0 ] # delta s # flow.sign(x):\u5f53x\u5927\u4e8e/\u5c0f\u4e8e0\u65f6\uff0c\u8fd4\u56de1/-1 # \u5982\u679c\u8fd9\u91ccanchor\u4e0estride\u987a\u5e8f\u4e0d\u4e00\u81f4\uff0c\u5219\u91cd\u65b0\u8c03\u6574\u987a\u5e8f\uff0c\u4f46\u6ce8\u610f\u8fd9\u91cc\u8981\u629b\u51fawarning if da and ( da . sign () != ds . sign ()): # same order LOGGER . info ( f \" { PREFIX } Reversing anchor order\" ) m . anchors [:] = m . anchors . flip ( 0 ) 3. kmean_anchors \u8fd9\u4e2a\u51fd\u6570\u624d\u662f\u8fd9\u4e2a\u8fd9\u4e2a\u6587\u4ef6\u7684\u6838\u5fc3\u51fd\u6570\u3002\u529f\u80fd\uff1a\u4f7f\u7528 K-means + \u9057\u4f20\u7b97\u6cd5 \u7b97\u51fa\u66f4\u7b26\u5408\u5f53\u524d\u6570\u636e\u96c6\u7684anchors\u3002 \u8fd9\u91cc\u4e0d\u4ec5\u4ec5\u4f7f\u7528\u4e86 K-means \u805a\u7c7b\uff0c\u8fd8\u4f7f\u7528\u4e86 Genetic Algorithm \u9057\u4f20\u7b97\u6cd5\uff0c\u5728 K-means \u805a\u7c7b\u7684\u7ed3\u679c\u4e0a\u8fdb\u884c mutation\uff08\u53d8\u5f02\uff09\u3002\u63a5\u4e0b\u6765\u7b80\u5355\u4ecb\u7ecd\u4e0b\u4ee3\u7801\u6d41\u7a0b\uff1a \u8f7d\u5165\u6570\u636e\u96c6\uff0c\u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709\u6570\u636e\u7684wh \u5c06\u6bcf\u5f20\u56fe\u7247\u4e2dwh\u7684\u6700\u5927\u503c\u7b49\u6bd4\u4f8b\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0fimg_size\uff0c\u8f83\u5c0f\u8fb9\u4e5f\u76f8\u5e94\u7f29\u653e \u5c06bboxes\u4ece\u76f8\u5bf9\u5750\u6807\u6539\u6210\u7edd\u5bf9\u5750\u6807\uff08\u4e58\u4ee5\u7f29\u653e\u540e\u7684wh\uff09 \u7b5b\u9009bboxes\uff0c\u4fdd\u7559wh\u90fd\u5927\u4e8e\u7b49\u4e8e\u4e24\u4e2a\u50cf\u7d20\u7684bboxes \u4f7f\u7528K-means\u805a\u7c7b\u5f97\u5230n\u4e2aanchors\uff08\u8c03\u7528K-means\u5305 \u6d89\u53ca\u4e00\u4e2a\u767d\u5316\u64cd\u4f5c\uff09 \u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u968f\u673a\u5bf9anchors\u7684wh\u8fdb\u884c\u53d8\u5f02\uff0c\u5982\u679c\u53d8\u5f02\u540e\u6548\u679c\u53d8\u5f97\u66f4\u597d\uff08\u4f7f\u7528anchor_fitness\u65b9\u6cd5\u8ba1\u7b97\u5f97\u5230\u7684fitness\uff08\u9002\u5e94\u5ea6\uff09\u8fdb\u884c\u8bc4\u4f30\uff09\u5c31\u5c06\u53d8\u5f02\u540e\u7684\u7ed3\u679c\u8d4b\u503c\u7ed9anchors\uff0c\u5982\u679c\u53d8\u5f02\u540e\u6548\u679c\u53d8\u5dee\u5c31\u8df3\u8fc7\uff0c\u9ed8\u8ba4\u53d8\u5f021000\u6b21 \u4e0d\u77e5\u9053\u4ec0\u4e48\u662f\u9057\u4f20\u7b97\u6cd5\uff0c\u53ef\u4ee5\u770b\u770b\u8fd9\u4e24\u4e2ab\u7ad9\u89c6\u9891\uff1a \u4f20\u7b97\u6cd5\u8d85\u7ec6\u81f4+\u900f\u5f7b\u7406\u89e3 \u548c \u9739\u96f3\u5427\u5566Wz def kmean_anchors ( path = './data/coco128.yaml' , n = 9 , img_size = 640 , thr = 4.0 , gen = 1000 , verbose = True ): \"\"\"\u5728check_anchors\u4e2d\u8c03\u7528 \u4f7f\u7528K-means + \u9057\u4f20\u7b97\u6cd5 \u7b97\u51fa\u66f4\u7b26\u5408\u5f53\u524d\u6570\u636e\u96c6\u7684anchors Creates kmeans-evolved anchors from training dataset :params path: \u6570\u636e\u96c6\u7684\u8def\u5f84/\u6570\u636e\u96c6\u672c\u8eab :params n: anchors \u7684\u4e2a\u6570 :params img_size: \u6570\u636e\u96c6\u56fe\u7247\u7ea6\u5b9a\u7684\u5927\u5c0f :params thr: \u9608\u503c \u7531 hyp['anchor_t'] \u53c2\u6570\u63a7\u5236 :params gen: \u9057\u4f20\u7b97\u6cd5\u8fdb\u5316\u8fed\u4ee3\u7684\u6b21\u6570(\u7a81\u53d8 + \u9009\u62e9) :params verbose: \u662f\u5426\u6253\u5370\u6240\u6709\u7684\u8fdb\u5316(\u6210\u529f\u7684)\u7ed3\u679c \u9ed8\u8ba4\u4f20\u5165\u662fFalse, \u53ea\u6253\u5370\u6700\u4f73\u7684\u8fdb\u5316\u7ed3\u679c :return k: K-means + \u9057\u4f20\u7b97\u6cd5\u8fdb\u5316\u540e\u7684anchors \"\"\" from scipy.cluster.vq import kmeans # \u6ce8\u610f\u4e00\u4e0b\u4e0b\u9762\u7684thr\u4e0d\u662f\u4f20\u5165\u7684thr\uff0c\u800c\u662f1/thr, \u6240\u4ee5\u5728\u8ba1\u7b97\u6307\u6807\u8fd9\u65b9\u9762\u8fd8\u662f\u548ccheck_anchor\u4e00\u6837 thr = 1. / thr # 0.25 prefix = colorstr ( 'autoanchor: ' ) def metric ( k , wh ): # compute metrics \"\"\"\u7528\u4e8e print_results \u51fd\u6570\u548c anchor_fitness \u51fd\u6570 \u8ba1\u7b97ratio metric: \u6574\u4e2a\u6570\u636e\u96c6\u7684 ground truth \u6846\u4e0e anchor \u5bf9\u5e94\u5bbd\u6bd4\u548c\u9ad8\u6bd4\u5373:gt_w/k_w,gt_h/k_h + x + best_x \u7528\u4e8e\u540e\u7eed\u8ba1\u7b97BPR+aat \u6ce8\u610f\u6211\u4eec\u8fd9\u91cc\u9009\u62e9\u7684metric\u662f ground truth \u6846\u4e0eanchor\u5bf9\u5e94\u5bbd\u6bd4\u548c\u9ad8\u6bd4 \u800c\u4e0d\u662f\u5e38\u7528\u7684iou \u8fd9\u70b9\u4e5f\u4e0enms\u7684\u7b5b\u9009\u6761\u4ef6\u5bf9\u5e94 \u662fyolov5\u4e2d\u4f7f\u7528\u7684\u65b0\u65b9\u6cd5 :params k: anchor\u6846 :params wh: \u6574\u4e2a\u6570\u636e\u96c6\u7684 wh [N, 2] :return x: [N, 9] N \u4e2a ground truth \u6846\u4e0e\u6240\u6709 anchor \u6846\u7684\u5bbd\u6bd4\u6216\u9ad8\u6bd4(\u4e24\u8005\u4e4b\u4e2d\u8f83\u5c0f\u8005) :return x.max(1)[0]: [N] N\u4e2a ground truth \u6846\u4e0e\u6240\u6709 anchor \u6846\u4e2d\u7684\u6700\u5927\u5bbd\u6bd4\u6216\u9ad8\u6bd4(\u4e24\u8005\u4e4b\u4e2d\u8f83\u5c0f\u8005) \"\"\" # [N, 1, 2] / [1, 9, 2] = [N, 9, 2] N\u4e2agt_wh\u548c9\u4e2aanchor\u7684k_wh\u5bbd\u6bd4\u548c\u9ad8\u6bd4 # \u4e24\u8005\u7684\u91cd\u5408\u7a0b\u5ea6\u8d8a\u9ad8 \u5c31\u8d8a\u8d8b\u8fd1\u4e8e1 \u8fdc\u79bb1(<1 \u6216 >1)\u91cd\u5408\u7a0b\u5ea6\u90fd\u8d8a\u4f4e r = wh [:, None ] / k [ None ] # r=gt_height/anchor_height gt_width / anchor_width \u6709\u53ef\u80fd\u5927\u4e8e1\uff0c\u4e5f\u53ef\u80fd\u5c0f\u4e8e\u7b49\u4e8e1 # flow.min(r, 1. / r): [N, 9, 2] \u5c06\u6240\u6709\u7684\u5bbd\u6bd4\u548c\u9ad8\u6bd4\u7edf\u4e00\u5230 <=1 # .min(2): value=[N, 9] \u9009\u51fa\u6bcf\u4e2a ground truth \u4e2a\u548c anchor \u7684\u5bbd\u6bd4\u548c\u9ad8\u6bd4\u6700\u5c0f\u7684\u503c index: [N, 9] \u8fd9\u4e2a\u6700\u5c0f\u503c\u662f\u5bbd\u6bd4(0)\u8fd8\u662f\u9ad8\u6bd4(1) # [0] \u8fd4\u56de value [N, 9] \u6bcf\u4e2a ground truth \u4e2a\u548c anchor \u7684\u5bbd\u6bd4\u548c\u9ad8\u6bd4\u6700\u5c0f\u7684\u503c \u5c31\u662f\u6240\u6709 ground truth \u4e0e anchor \u91cd\u5408\u7a0b\u5ea6\u6700\u4f4e\u7684 x = flow . min ( r , 1. / r ) . min ( 2 )[ 0 ] # ratio metric # x = wh_iou(wh, flow.tensor(k)) # IoU metric # x.max(1)[0]: [N] \u8fd4\u56de\u6bcf\u4e2a ground truth \u548c\u6240\u6709 anchor(9\u4e2a) \u4e2d\u5bbd\u6bd4/\u9ad8\u6bd4\u6700\u5927\u7684\u503c return x , x . max ( 1 )[ 0 ] # x, best_x def anchor_fitness ( k ): # mutation fitness \"\"\"\u7528\u4e8e kmean_anchors \u51fd\u6570 \u9002\u5e94\u5ea6\u8ba1\u7b97 \u4f18\u80dc\u52a3\u6c70 \u7528\u4e8e\u9057\u4f20\u7b97\u6cd5\u4e2d\u8861\u91cf\u7a81\u53d8\u662f\u5426\u6709\u6548\u7684\u6807\u6ce8 \u5982\u679c\u6709\u6548\u5c31\u8fdb\u884c\u9009\u62e9\u64cd\u4f5c\uff0c\u65e0\u6548\u5c31\u7ee7\u7eed\u4e0b\u4e00\u8f6e\u7684\u7a81\u53d8 :params k: [9, 2] K-means\u751f\u6210\u7684 9 \u4e2aanchors wh: [N, 2]: \u6570\u636e\u96c6\u7684\u6240\u6709 ground truth \u6846\u7684\u5bbd\u9ad8 :return (best * (best > thr).float()).mean()=\u9002\u5e94\u5ea6\u8ba1\u7b97\u516c\u5f0f [1] \u6ce8\u610f\u548cBPR\u6709\u533a\u522b \u8fd9\u91cc\u662f\u81ea\u5b9a\u4e49\u7684\u4e00\u79cd\u9002\u5e94\u5ea6\u516c\u5f0f \u8fd4\u56de\u7684\u662f\u8f93\u5165\u6b64\u65f6anchor k \u5bf9\u5e94\u7684\u9002\u5e94\u5ea6 \"\"\" _ , best = metric ( flow . tensor ( k , dtype = flow . float32 ), wh ) return ( best * ( best > thr ) . float ()) . mean () # fitness def print_results ( k ): \"\"\"\u7528\u4e8e kmean_anchors \u51fd\u6570\u4e2d\u6253\u5370K-means\u8ba1\u7b97\u76f8\u5173\u4fe1\u606f \u8ba1\u7b97BPR\u3001aat=>\u6253\u5370\u4fe1\u606f: \u9608\u503c+BPR+aat anchor\u4e2a\u6570+\u56fe\u7247\u5927\u5c0f+metric_all+best_mean+past_mean+Kmeans\u805a\u7c7b\u51fa\u6765\u7684anchor\u6846(\u56db\u820d\u4e94\u5165) :params k: K-means\u5f97\u5230\u7684anchor k :return k: input \"\"\" # \u5c06K-means\u5f97\u5230\u7684anchor k\u6309\u9762\u79ef\u4ece\u5c0f\u5230\u5927\u6392\u5e8f k = k [ np . argsort ( k . prod ( 1 ))] # x: [N, 9] N\u4e2a ground truth \u6846\u4e0e\u6240\u6709anchor\u6846\u7684\u5bbd\u6bd4\u6216\u9ad8\u6bd4(\u4e24\u8005\u4e4b\u4e2d\u8f83\u5c0f\u8005) # best: [N] N\u4e2a ground truth \u6846\u4e0e\u6240\u6709anchor\u6846\u4e2d\u7684\u6700\u5927\u5bbd\u6bd4\u6216\u9ad8\u6bd4(\u4e24\u8005\u4e4b\u4e2d\u8f83\u5c0f\u8005) x , best = metric ( k , wh0 ) # (best > thr).float(): True=>1. False->0. .mean(): \u6c42\u5747\u503c # BPR(best possible recall): \u6700\u591a\u80fd\u88ab\u53ec\u56de(\u901a\u8fc7thr)\u7684 ground truth \u6846\u6570\u91cf / \u6240\u6709 ground truth \u6846\u6570\u91cf [1] 0.96223 \u5c0f\u4e8e0.98 \u624d\u4f1a\u7528K-means\u8ba1\u7b97anchor # aat(anchors above threshold): [1] 3.54360 \u6bcf\u4e2atarget\u5e73\u5747\u6709\u591a\u5c11\u4e2aanchors BPR , aat = ( best > thr ) . float () . mean (), ( x > thr ) . float () . mean () * n # best possible recall, anch > thr f = anchor_fitness ( k ) # print(f'{prefix}thr={thr:.2f}: {BPR:.4f} best possible recall, {aat:.2f} anchors past thr') # print(f'{prefix}n={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, ' # f'past_thr={x[x > thr].mean():.3f}-mean: ', end='') print ( f \"aat: { aat : .5f } , fitness: { f : .5f } , best possible recall: { BPR : .5f } \" ) for i , x in enumerate ( k ): print ( ' %i , %i ' % ( round ( x [ 0 ]), round ( x [ 1 ])), end = ', ' if i < len ( k ) - 1 else ' \\n ' ) # use in *.cfg return k # \u8f7d\u5165\u6570\u636e\u96c6 if isinstance ( path , str ): # *.yaml file with open ( path ) as f : data_dict = yaml . safe_load ( f ) # model dict from utils.datasets import LoadImagesAndLabels dataset = LoadImagesAndLabels ( data_dict [ 'train' ], augment = True , rect = True ) else : dataset = path # dataset # \u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709\u6570\u636e\u7684 wh # \u5c06\u6570\u636e\u96c6\u56fe\u7247\u7684\u6700\u957f\u8fb9\u7f29\u653e\u5230 img_size, \u8f83\u5c0f\u8fb9\u76f8\u5e94\u7f29\u653e shapes = img_size * dataset . shapes / dataset . shapes . max ( 1 , keepdims = True ) # \u5c06\u539f\u672c\u6570\u636e\u96c6\u4e2dgt boxes\u5f52\u4e00\u5316\u7684wh\u7f29\u653e\u5230shapes\u5c3a\u5ea6 wh0 = np . concatenate ([ l [:, 3 : 5 ] * s for s , l in zip ( shapes , dataset . labels )]) # \u7edf\u8ba1gt boxes\u4e2d\u5bbd\u6216\u8005\u9ad8\u5c0f\u4e8e 3 \u4e2a\u50cf\u7d20\u7684\u4e2a\u6570, \u76ee\u6807\u592a\u5c0f \u53d1\u51fa\u8b66\u544a i = ( wh0 < 3.0 ) . any ( 1 ) . sum () if i : print ( f ' { prefix } WARNING: Extremely small objects found. { i } of { len ( wh0 ) } labels are < 3 pixels in size.' ) # \u7b5b\u9009\u51fa label \u5927\u4e8e 2 \u4e2a\u50cf\u7d20\u7684\u6846\u62ff\u6765\u805a\u7c7b, [...]\u5185\u7684\u76f8\u5f53\u4e8e\u4e00\u4e2a\u7b5b\u9009\u5668, \u4e3aTrue\u7684\u7559\u4e0b wh = wh0 [( wh0 >= 2.0 ) . any ( 1 )] # filter > 2 pixels # wh = wh * (np.random.rand(wh.shape[0], 1) * 0.9 + 0.1) # multiply by random scale 0-1 # Kmeans\u805a\u7c7b\u65b9\u6cd5: \u4f7f\u7528\u6b27\u5f0f\u8ddd\u79bb\u6765\u8fdb\u884c\u805a\u7c7b print ( f ' { prefix } Running kmeans for { n } anchors on { len ( wh ) } gt boxes...' ) # \u8ba1\u7b97\u5bbd\u548c\u9ad8\u7684\u6807\u51c6\u5dee->[w_std,h_std] s = wh . std ( 0 ) # sigmas for whitening # \u5f00\u59cb\u805a\u7c7b,\u4ecd\u7136\u662f\u805a\u6210 n \u7c7b,\u8fd4\u56de\u805a\u7c7b\u540e\u7684anchors k(\u8fd9\u4e2aanchors k\u662f\u767d\u5316\u540e\u6570\u636e\u7684anchor\u6846s) # \u53e6\u5916\u8fd8\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u91cc\u7684kmeans\u4f7f\u7528\u6b27\u5f0f\u8ddd\u79bb\u6765\u8ba1\u7b97\u7684 # \u8fd0\u884cK-means\u7684\u6b21\u6570\u4e3a30\u6b21 obs: \u4f20\u5165\u7684\u6570\u636e\u5fc5\u987b\u5148\u767d\u5316\u5904\u7406 'whiten operation' # \u767d\u5316\u5904\u7406: \u65b0\u6570\u636e\u7684\u6807\u51c6\u5dee=1 \u964d\u4f4e\u6570\u636e\u4e4b\u95f4\u7684\u76f8\u5173\u5ea6\uff0c\u4e0d\u540c\u6570\u636e\u6240\u8574\u542b\u7684\u4fe1\u606f\u4e4b\u95f4\u7684\u91cd\u590d\u6027\u5c31\u4f1a\u964d\u4f4e\uff0c\u7f51\u7edc\u7684\u8bad\u7ec3\u6548\u7387\u5c31\u4f1a\u63d0\u9ad8 # \u767d\u5316\u64cd\u4f5c\u53c2\u8003\u535a\u5ba2: https://blog.csdn.net/weixin_37872766/article/details/102957235 k , dist = kmeans ( wh / s , n , iter = 30 ) # points, mean distance assert len ( k ) == n , print ( f ' { prefix } ERROR: scipy.cluster.vq.kmeans requested { n } points but returned only { len ( k ) } ' ) k *= s # k*s \u5f97\u5230\u539f\u6765\u6570\u636e(\u767d\u5316\u524d)\u7684 anchor \u6846 wh = flow . tensor ( wh , dtype = flow . float32 ) # filtered wh wh0 = flow . tensor ( wh0 , dtype = flow . float32 ) # unfiltered wh0 # \u8f93\u51fa\u65b0\u7b97\u7684anchors k \u76f8\u5173\u7684\u4fe1\u606f k = print_results ( k ) # Plot wh # k, d = [None] * 20, [None] * 20 # for i in tqdm(range(1, 21)): # k[i-1], d[i-1] = kmeans(wh / s, i) # points, mean distance # fig, ax = plt.subplots(1, 2, figsize=(14, 7), tight_layout=True) # ax = ax.ravel() # ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.') # fig, ax = plt.subplots(1, 2, figsize=(14, 7)) # plot wh # ax[0].hist(wh[wh[:, 0]<100, 0], 400) # ax[1].hist(wh[wh[:, 1]<100, 1], 400) # fig.savefig('wh.png', dpi=200) # Evolve \u7c7b\u4f3c\u9057\u4f20/\u8fdb\u5316\u7b97\u6cd5 \u53d8\u5f02\u64cd\u4f5c npr = np . random # \u968f\u673a\u5de5\u5177 # f: fitness 0.62690 # sh: (9,2) # mp: \u7a81\u53d8\u6bd4\u4f8bmutation prob=0.9 s: sigma=0.1 f , sh , mp , s = anchor_fitness ( k ), k . shape , 0.9 , 0.1 # fitness, generations, mutation prob, sigma pbar = tqdm ( range ( gen ), desc = f ' { prefix } Evolving anchors with Genetic Algorithm:' ) # progress bar # \u6839\u636e\u805a\u7c7b\u51fa\u6765\u7684n\u4e2a\u70b9\u91c7\u7528\u9057\u4f20\u7b97\u6cd5\u751f\u6210\u65b0\u7684anchor for _ in pbar : # \u91cd\u590d1000\u6b21\u7a81\u53d8+\u9009\u62e9 \u9009\u62e9\u51fa1000\u6b21\u7a81\u53d8\u91cc\u7684\u6700\u4f73anchor k\u548c\u6700\u4f73\u9002\u5e94\u5ea6f v = np . ones ( sh ) # v [9, 2] \u5168\u662f1 while ( v == 1 ) . all (): # \u4ea7\u751f\u53d8\u5f02\u89c4\u5219 mutate until a change occurs (prevent duplicates) # npr.random(sh) < mp: \u8ba9v\u4ee590%\u7684\u6bd4\u4f8b\u8fdb\u884c\u53d8\u5f02 \u9009\u5230\u53d8\u5f02\u7684\u5c31\u4e3a1 \u6ca1\u6709\u9009\u5230\u53d8\u5f02\u7684\u5c31\u4e3a0 v = (( npr . random ( sh ) < mp ) * npr . random () * npr . randn ( * sh ) * s + 1 ) . clip ( 0.3 , 3.0 ) # \u53d8\u5f02(\u6539\u53d8\u8fd9\u4e00\u65f6\u523b\u4e4b\u524d\u7684\u6700\u4f73\u9002\u5e94\u5ea6\u5bf9\u5e94\u7684anchor k) kg = ( k . copy () * v ) . clip ( min = 2.0 ) # \u8ba1\u7b97\u53d8\u5f02\u540e\u7684anchor kg\u7684\u9002\u5e94\u5ea6 fg = anchor_fitness ( kg ) # \u5982\u679c\u53d8\u5f02\u540e\u7684anchor kg\u7684\u9002\u5e94\u5ea6>\u6700\u4f73\u9002\u5e94\u5ea6k \u5c31\u8fdb\u884c\u9009\u62e9\u64cd\u4f5c if fg > f : # \u9009\u62e9\u53d8\u5f02\u540e\u7684anchor kg\u4e3a\u6700\u4f73\u7684anchor k \u53d8\u5f02\u540e\u7684\u9002\u5e94\u5ea6fg\u4e3a\u6700\u4f73\u9002\u5e94\u5ea6f f , k = fg , kg . copy () # \u6253\u5370\u4fe1\u606f pbar . desc = f ' { prefix } Evolving anchors with Genetic Algorithm: fitness = { f : .4f } ' if verbose : print_results ( k ) return print_results ( k ) 4. check_anchors \u8fd9\u4e2a\u51fd\u6570\u662f\u901a\u8fc7\u8ba1\u7b97BPR\u786e\u5b9a\u662f\u5426\u9700\u8981\u6539\u53d8anchors \u9700\u8981\u5c31\u8c03\u7528K-means\u91cd\u65b0\u8ba1\u7b97anchors\u3002 def check_anchors ( dataset , model , thr = 4.0 , imgsz = 640 ): # Check anchor fit to data, recompute if necessary \"\"\"\u7528\u4e8etrain.py\u4e2d \u901a\u8fc7BPR\u786e\u5b9a\u662f\u5426\u9700\u8981\u6539\u53d8anchors \u9700\u8981\u5c31\u8c03\u7528K-means\u91cd\u65b0\u8ba1\u7b97anchors Check anchor fit to data, recompute if necessary :params dataset: \u81ea\u5b9a\u4e49\u6570\u636e\u96c6LoadImagesAndLabels\u8fd4\u56de\u7684\u6570\u636e\u96c6 :params model: \u521d\u59cb\u5316\u7684\u6a21\u578b :params thr: \u8d85\u53c2\u4e2d\u5f97\u5230 \u754c\u5b9aanchor\u4e0elabel\u5339\u914d\u7a0b\u5ea6\u7684\u9608\u503c :params imgsz: \u56fe\u7247\u5c3a\u5bf8 \u9ed8\u8ba4640 \"\"\" # \u4ecemodel\u4e2d\u53d6\u51fa\u6700\u540e\u4e00\u5c42(Detect) m = model . module . model [ - 1 ] if hasattr ( model , \"module\" ) else model . model [ - 1 ] # Detect() # dataset.shapes.max(1, keepdims=True) = \u6bcf\u5f20\u56fe\u7247\u7684\u8f83\u957f\u8fb9 # shapes: \u5c06\u6570\u636e\u96c6\u56fe\u7247\u7684\u6700\u957f\u8fb9\u7f29\u653e\u5230img_size, \u8f83\u5c0f\u8fb9\u76f8\u5e94\u7f29\u653e \u5f97\u5230\u65b0\u7684\u6240\u6709\u6570\u636e\u96c6\u56fe\u7247\u7684\u5bbd\u9ad8 [N, 2] shapes = imgsz * dataset . shapes / dataset . shapes . max ( 1 , keepdims = True ) # \u4ea7\u751f\u968f\u673a\u6570scale [img_size, 1] scale = np . random . uniform ( 0.9 , 1.1 , size = ( shapes . shape [ 0 ], 1 )) # augment scale # [6301, 2] \u6240\u6709target(6301\u4e2a)\u7684wh \u57fa\u4e8e\u539f\u56fe\u5927\u5c0f shapes * scale: \u968f\u673a\u5316\u5c3a\u5ea6\u53d8\u5316 wh = flow . tensor ( np . concatenate ([ l [:, 3 : 5 ] * s for s , l in zip ( shapes * scale , dataset . labels )])) . float () # wh def metric ( k ): # compute metric \"\"\"\u7528\u5728check_anchors\u51fd\u6570\u4e2d compute metric \u6839\u636e\u6570\u636e\u96c6\u7684\u6240\u6709\u56fe\u7247\u7684wh\u548c\u5f53\u524d\u6240\u6709anchors k\u8ba1\u7b97 BPR(best possible recall) \u548c aat(anchors above threshold) :params k: anchors [9, 2] wh: [N, 2] :return BPR: best possible recall \u6700\u591a\u80fd\u88ab\u53ec\u56de(\u901a\u8fc7thr)\u7684 ground truth \u6846\u6570\u91cf / \u6240\u6709 ground truth \u6846\u6570\u91cf\u5c0f\u4e8e0.98 \u624d\u4f1a\u7528K-means\u8ba1\u7b97anchor :return aat: anchors above threshold \u6bcf\u4e2atarget\u5e73\u5747\u6709\u591a\u5c11\u4e2aanchors \"\"\" # None\u6dfb\u52a0\u7ef4\u5ea6 \u6240\u6709target(gt)\u7684wh wh[:, None] [6301, 2]->[6301, 1, 2] # \u6240\u6709anchor\u7684wh k[None] [9, 2]->[1, 9, 2] # r: target\u7684\u9ad8h\u5bbdw\u4e0eanchor\u7684\u9ad8h_a\u5bbdw_a\u7684\u6bd4\u503c\uff0c\u5373h/h_a, w/w_a [6301, 9, 2] \u6709\u53ef\u80fd\u5927\u4e8e1\uff0c\u4e5f\u53ef\u80fd\u5c0f\u4e8e\u7b49\u4e8e1 r = wh [:, None ] / k [ None ] # x \u9ad8\u5bbd\u6bd4\u548c\u5bbd\u9ad8\u6bd4\u7684\u6700\u5c0f\u503c \u65e0\u8bbar\u5927\u4e8e1\uff0c\u8fd8\u662f\u5c0f\u4e8e\u7b49\u4e8e1\u6700\u540e\u7edf\u4e00\u7ed3\u679c\u90fd\u8981\u5c0f\u4e8e1 [6301, 9] x = flow . min ( r , 1 / r ) . min ( 2 )[ 0 ] # ratio metric # best [6301] \u4e3a\u6bcf\u4e2a ground truth \u6846\u9009\u62e9\u5339\u914d\u6240\u6709anchors\u5bbd\u9ad8\u6bd4\u4f8b\u503c\u6700\u597d\u7684\u90a3\u4e00\u4e2a\u6bd4\u503c best = x . max ( 1 )[ 0 ] # best_x # aat(anchors above threshold) \u6bcf\u4e2atarget\u5e73\u5747\u6709\u591a\u5c11\u4e2aanchors aat = ( x > 1 / thr ) . float () . sum ( 1 ) . mean () # anchors above threshold # BPR(best possible recall) = \u6700\u591a\u80fd\u88ab\u53ec\u56de(\u901a\u8fc7thr)\u7684 ground truth \u6846\u6570\u91cf / \u6240\u6709 ground truth \u6846\u6570\u91cf \u5c0f\u4e8e0.98 \u624d\u4f1a\u7528K-means\u8ba1\u7b97anchor BPR = ( best > 1 / thr ) . float () . mean () # best possible recall return BPR , aat stride = m . stride . to ( m . anchors . device ) . view ( - 1 , 1 , 1 ) # model strides # anchors: [N,2] \u6240\u6709anchors\u7684\u5bbd\u9ad8 \u57fa\u4e8e\u7f29\u653e\u540e\u7684\u56fe\u7247\u5927\u5c0f(\u8f83\u957f\u8fb9\u4e3a640 \u8f83\u5c0f\u8fb9\u76f8\u5e94\u7f29\u653e) anchors = m . anchors . clone () * stride # current anchors BPR , aat = metric ( anchors . cpu () . view ( - 1 , 2 )) s = f \" \\n { PREFIX }{ aat : .2f } anchors/target, { BPR : .3f } Best Possible Recall (BPR). \" # \u8003\u8651\u8fd99\u7c7banchor\u7684\u5bbd\u9ad8\u548c ground truth \u6846\u7684\u5bbd\u9ad8\u4e4b\u95f4\u7684\u5dee\u8ddd, \u5982\u679cBPR<0.98(\u8bf4\u660e\u5f53\u524danchor\u4e0d\u80fd\u5f88\u597d\u7684\u5339\u914d\u6570\u636e\u96c6 ground truth \u6846)\u5c31\u4f1a\u6839\u636eK-means\u7b97\u6cd5\u91cd\u65b0\u805a\u7c7b\u65b0\u7684anchor if BPR > 0.98 : # threshold to recompute LOGGER . info ( f \" { s } Current anchors are a good fit to dataset \u2705\" ) else : LOGGER . info ( f \" { s } Anchors are a poor fit to dataset \u26a0\ufe0f, attempting to improve...\" ) na = m . anchors . numel () // 2 # number of anchors try : # \u5982\u679cBPR<0.98(\u6700\u5927\u4e3a1 \u8d8a\u5927\u8d8a\u597d) \u4f7f\u7528K-means + \u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\u9009\u62e9\u51fa\u4e0e\u6570\u636e\u96c6\u66f4\u5339\u914d\u7684anchors\u6846 [9, 2] anchors = kmean_anchors ( dataset , n = na , img_size = imgsz , thr = thr , gen = 1000 , verbose = False ) except Exception as e : LOGGER . info ( f \" { PREFIX } ERROR: { e } \" ) # \u8ba1\u7b97\u65b0\u7684anchors\u7684new_BPR new_BPR = metric ( anchors )[ 0 ] # \u6bd4\u8f83 K-means + \u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\u8fdb\u5316\u540e\u7684anchors\u7684new_BPR\u548c\u539f\u59cbanchors\u7684BPR # \u6ce8\u610f: \u8fd9\u91cc\u5e76\u4e0d\u4e00\u5b9a\u8fdb\u5316\u540e\u7684BPR\u5fc5\u5927\u4e8e\u539f\u59cbanchors\u7684BPR, \u56e0\u4e3a\u4e24\u8005\u7684\u8861\u91cf\u6807\u6ce8\u662f\u4e0d\u4e00\u6837\u7684 \u8fdb\u5316\u7b97\u6cd5\u7684\u8861\u91cf\u6807\u51c6\u662f\u9002\u5e94\u5ea6 \u800c\u8fd9\u91cc\u6bd4\u7684\u662fBPR if new_BPR > BPR : # replace anchors anchors = flow . tensor ( anchors , device = m . anchors . device ) . type_as ( m . anchors ) # \u66ff\u6362m\u7684anchor_grid [9, 2] -> [3, 1, 3, 1, 1, 2] m . anchors [:] = anchors . clone () . view_as ( m . anchors ) # \u68c0\u67e5anchor\u987a\u5e8f\u548cstride\u987a\u5e8f\u662f\u5426\u4e00\u81f4 \u4e0d\u4e00\u81f4\u5c31\u8c03\u6574 # \u56e0\u4e3a\u6211\u4eec\u7684m.anchors\u662f\u76f8\u5bf9\u5404\u4e2a feature map \u6240\u4ee5\u5fc5\u987b\u8981\u987a\u5e8f\u4e00\u81f4 \u5426\u5219\u6548\u679c\u4f1a\u5f88\u4e0d\u597d check_anchor_order ( m ) # must be in pixel-space (not grid-space) m . anchors /= stride s = f \" { PREFIX } Done \u2705 (optional: update model *.yaml to use these anchors in the future)\" else : s = f \" { PREFIX } Done \u26a0\ufe0f (original anchors better than new anchors, proceeding with original anchors)\" LOGGER . info ( s ) \u8fd9\u4e2a\u51fd\u6570\u4f1a\u5728 train.py\u4e2d\u8c03\u7528\uff1a \u603b\u7ed3 K-means\u662f\u975e\u5e38\u7ecf\u5178\u4e14\u6709\u6548\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u6837\u672c\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u76f8\u4f3c\u7a0b\u5ea6\uff09\u5c06\u8f83\u8fd1\u7684\u6837\u672c\u805a\u4e3a\u540c\u4e00\u7c7b\u522b\uff08\u7c07\uff09\u3002 Reference YOLO9000:Better, Faster, Stronger \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011[autoanchor.py] https://blog.csdn.net/qq_38253797/article/details/119713706 CSDN \u9739\u96f3\u5427\u5566Wz : \u4f7f\u7528K-means\u805a\u7c7banchors Bilibili \u9739\u96f3\u5427\u5566Wz : \u5982\u4f55\u4f7f\u7528K-means\u805a\u7c7b\u5f97\u5230anchors\u4ee5\u53ca\u9700\u8981\u6ce8\u610f\u7684\u5751. CSDN \u6069\u6cfd\u541b : YOLOV3\u4e2dK-means\u805a\u7c7b\u83b7\u5f97anchor boxes\u8fc7\u7a0b\u8be6\u89e3. Github \u6069\u6cfd\u541b: Laughing-q/yolov5_annotations. CSDN \u660c\u5c71\u5c0f\u5c4b: \u3010\u73a9\u8f6cyolov5\u3011 \u8bf7\u770b\u4ee3\u7801\u4e4b\u81ea\u52a8anchor\u8ba1\u7b97. CSDN TheOldManAndTheSea: \u76ee\u6807\u68c0\u6d4b YOLOv5 anchor\u8bbe\u7f6e Bilibili \u6211\u5bb6\u516c\u5b50Q: \u9057\u4f20\u7b97\u6cd5\u8d85\u7ec6\u81f4+\u900f\u5f7b\u7406\u89e3","title":"autoanchor.py"},{"location":"source_code_interpretation/utils/autoanchor_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/autoanchor.py","title":"\u524d\u8a00"},{"location":"source_code_interpretation/utils/autoanchor_py.html#_2","text":"\u7ef4\u5ea6\u805a\u7c7b \uff08Dimension Clusters\uff09\u3002\u5f53\u628a YOLO \u7ed3\u5408 anchor boxes \u4f7f\u7528\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u4e24\u4e2a\u95ee\u9898\uff1a \u9996\u5148 anchor boxes \u7684\u5c3a\u5bf8\u662f\u624b\u5de5\u6311\u9009\u7684\u3002\u867d\u7136\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u9002\u5f53\u5730\u8c03\u6574 anchor boxes \u5f62\u72b6\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u4ece\u4e00\u5f00\u59cb\u5c31\u4e3a\u7f51\u7edc\u9009\u62e9\u66f4\u597d\u7684 anchor boxes \uff0c\u5c31\u53ef\u4ee5\u8ba9\u7f51\u7edc\u66f4\u5bb9\u6613\u5b66\u4e60\u5e76\u83b7\u5f97\u66f4\u597d\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u56fe1\uff1aVOC \u548c COCO \u4e0a\u7684\u805a\u7c7b\u6846\u5c3a\u5bf8\u3002\u6211\u4eec\u5728\u8fb9\u754c\u6846\u7684\u7ef4\u5ea6(dimensions of bounding boxes) \u4e0a\u8fd0\u884c K-means\u805a\u7c7b\uff0c\u4ee5\u83b7\u5f97\u6211\u4eec\u6a21\u578b\u826f\u597d\u7684\u521d\u59cb anchor boxes \u3002\u5de6\u56fe\u663e\u793a\u4e86\u6211\u4eec\u901a\u8fc7 k \u7684\u5404\u79cd\u9009\u62e9\u83b7\u5f97\u7684 Avg IoU \u3002\u6211\u4eec\u53d1\u73b0 k = 5 \u4e3a\u53ec\u56de\u4e0e\u6a21\u578b\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6298\u4e2d\u3002 \u53f3\u56fe\u663e\u793a\u4e86\u5728 VOC \u548c COCO \u4e0a\u805a\u7c7b\u7c07\u7684\u76f8\u5bf9\u4e2d\u5fc3, \u5e76\u4e14\u8fd9\u4e24\u79cd\u4e0d\u540c\u7684 k \u5bf9\u5e94\u65b9\u6848\u90fd\u559c\u6b22\u66f4\u7a00\u758f\u7684\uff0c\u66f4\u9ad8\u7684\u6846\uff0c\u6b64\u5916\u5728 COCO \u7684\u5c3a\u5bf8\u7684\u53d8\u5316\u6bd4 VOC \u66f4\u5927\u3002 \u6211\u4eec\u4e0d\u7528\u624b\u5de5\u9009\u62e9 anchor boxes\uff0c\u800c\u662f\u5728\u8bad\u7ec3\u96c6\u7684\u8fb9\u754c\u6846\u4e0a\u7684\u7ef4\u5ea6\u4e0a\u8fd0\u884c K-means \u805a\u7c7b\u7b97\u6cd5\uff0c\u81ea\u52a8\u627e\u5230\u826f\u597d\u7684 anchor boxes \u3002 \u5982\u679c\u6211\u4eec\u4f7f\u7528\u5177\u6709\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u6807\u51c6 K-means\uff0c\u90a3\u4e48\u8f83\u5927\u7684\u6846\u4f1a\u6bd4\u8f83\u5c0f\u7684\u6846\u4ea7\u751f\u66f4\u591a\u7684\u8bef\u5dee\u3002 \u4f46\u6211\u4eec\u771f\u6b63\u60f3\u8981\u7684\u662f\u72ec\u7acb\u4e8e\u6846\u7684\u5927\u5c0f\u7684\uff0c\u80fd\u83b7\u5f97\u826f\u597d\u7684 IoU \u5206\u6570\u7684 anchor boxes \u3002 \u56e0\u6b64\u5bf9\u4e8e\u8ddd\u79bb\u7684\u5ea6\u91cf\u65b9\u5f0f\u6211\u4eec\u4f7f\u7528: \\(d(\\text { box, centroid }) = 1-\\operatorname{IoU}(\\text { box }, \\text { centroid })\\) \u6211\u4eec\u7528\u4e0d\u540c\u7684 \\(k\\) \u503c\u8fd0\u884c K-means\u7b97\u6cd5\uff0c\u5e76\u7ed8\u5236\u6700\u63a5\u8fd1\u805a\u7c7b\u4e2d\u5fc3\u7684\u5e73\u5747 Avg IoU\uff08\u89c1\u56fe1\uff09\u3002\u4e3a\u4e86\u5728\u6a21\u578b\u590d\u6742\u5ea6\u548c\u9ad8\u53ec\u56de\u7387\u4e4b\u95f4\u7684\u826f\u597d\u6298\u4e2d\uff0c\u6211\u4eec\u9009\u62e9 k = 5 \uff08\u4e5f\u5c31\u662f5\u79cdanchor boxes\uff09\u7c07\u7684\u76f8\u5bf9\u4e2d\u5fc3 \u4e0e\u624b\u5de5\u9009\u53d6\u7684 anchor boxes \u663e\u7740\u4e0d\u540c\uff0c\u5b83\u6709\u66f4\u5c11\u7684\u77ed\u4e14\u5bbd\u7684\u6846\uff0c\u5e76\u4e14\u6709\u66f4\u591a\u65e2\u957f\u53c8\u7a84\u7684\u6846\u3002 \u88681\u4e2d\uff0c\u6211\u4eec\u5c06\u805a\u7c7b\u7b56\u7565\u5f97\u5230\u7684 anchor boxes \u548c\u624b\u5de5\u9009\u53d6\u7684 anchor boxes \u5728\u6700\u63a5\u8fd1\u7684 Avg IoU \u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002\u901a\u8fc7\u805a\u7c7b\u7b56\u7565\u5f97\u5230\u7684\u4ec55\u79cd anchor boxes \u7684 Avg IoU \u4e3a61.0\uff0c\u5176\u6027\u80fd\u7c7b\u4f3c\u4e8e9\u4e2a\u901a\u8fc7\u7f51\u7edc\u5b66\u4e60\u7684 anchor boxes \u768460.9 ( \u5373Avg IoU\u5df2\u7ecf\u8fbe\u5230\u4e86Faster RCNN\u7684\u6c34\u5e73 )\u3002 \u800c\u4e14\u4f7f\u75289\u79cd anchor boxes \u4f1a\u5f97\u5230\u66f4\u9ad8\u7684 Avg IoU \u3002\u8fd9\u8868\u660e\u4f7f\u7528 K-means\u751f\u6210 anchor boxes \u53ef\u4ee5\u66f4\u597d\u5730\u8868\u793a\u6a21\u578b\u5e76\u4f7f\u5176\u66f4\u5bb9\u6613\u5b66\u4e60\u3002 \\(\\begin{array}{lcc} \\text { Box Generation } & \\# & \\text { Avg IoU } \\\\ \\hline \\text { Cluster SSE } & 5 & 58.7 \\\\ \\text { Cluster IoU } & 5 & 61.0 \\\\ \\text { Anchor Boxes [15] } & 9 & 60.9 \\\\ \\text { Cluster IoU } & 9 & 67.2 \\end{array}\\) \u88681\uff1a VOC 2007 \u4e0a\u805a\u7c7b\u5f97\u7ed3\u679c\u6bd4\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684 anchor boxes \u7ed3\u679c\u8981\u597d\u5f97\u591a\u3002","title":"\u6458\u8981"},{"location":"source_code_interpretation/utils/autoanchor_py.html#k-means","text":"K-means\u662f\u975e\u5e38\u7ecf\u5178\u4e14\u6709\u6548\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u6837\u672c\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u76f8\u4f3c\u7a0b\u5ea6\uff09\u5c06\u8f83\u8fd1\u7684\u6837\u672c\u805a\u4e3a\u540c\u4e00\u7c7b\u522b\uff08\u7c07\uff09\u3002 \u5728 yolov5/one-yolov5 \u9879\u76ee\u4e2d\u4f7f\u7528 K-means \u5fc5\u987b\u6ee1\u8db3\u4e0b\u9762\u7684\u6761\u4ef6\uff1a 1. train.py\u7684parse_opt\u4e0b\u7684\u53c2\u6570noautoanchor\u5fc5\u987b\u4e3aFalse 2. hpy.scratch.yaml\u4e0b\u7684anchors\u53c2\u6570\u6ce8\u91ca\u6389\u3002","title":"\u4ec0\u4e48\u662fK-means?"},{"location":"source_code_interpretation/utils/autoanchor_py.html#k-means_1","text":"\u5982\u4f55\u8868\u793a\u6837\u672c\u4e0e\u6837\u672c\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u6838\u5fc3\u95ee\u9898\uff09\uff0c\u8fd9\u4e2a\u4e00\u822c\u9700\u8981\u6839\u636e\u5177\u4f53\u573a\u666f\u53bb\u8bbe\u8ba1\uff0c\u4e0d\u540c\u7684\u65b9\u6cd5\u805a\u7c7b\u6548\u679c\u4e5f\u4e0d\u540c\uff0c\u6700\u5e38\u89c1\u7684\u5c31\u662f\u6b27\u5f0f\u8ddd\u79bb\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u5e38\u89c1\u7684\u662fIoU\u3002 \u5206\u4e3a\u51e0\u7c7b\uff0c\u8fd9\u4e2a\u4e5f\u662f\u9700\u8981\u6839\u636e\u5e94\u7528\u573a\u666f\u53d6\u9009\u62e9\u7684\uff0c\u4e5f\u662f\u4e00\u4e2a\u8d85\u53c2\u6570\u3002","title":"\u4f7f\u7528K-means\u65f6\u4e3b\u8981\u5173\u6ce8\u4e24\u70b9"},{"location":"source_code_interpretation/utils/autoanchor_py.html#k-means_2","text":"\u624b\u52a8\u8bbe\u5b9a\u7c07\u7684\u4e2a\u6570k\uff0c\u5047\u8bbek=2\uff1b \u5728\u6240\u6709\u6837\u672c\u4e2d\u968f\u673a\u9009\u53d6k\u4e2a\u6837\u672c\u4f5c\u4e3a\u7c07\u7684\u521d\u59cb\u4e2d\u5fc3\uff0c\u5982\u4e0b\u56fe\uff08random clusters\uff09\u4e2d\u4e24\u4e2a\u9ec4\u8272\u7684\u5c0f\u661f\u661f\u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\u7684\u4e24\u4e2a\u7c07\u4e2d\u5fc3\uff1b \u8ba1\u7b97\u6bcf\u4e2a\u6837\u672c\u79bb\u6bcf\u4e2a\u7c07\u4e2d\u5fc3\u7684\u8ddd\u79bb\uff08\u8fd9\u91cc\u4ee5\u6b27\u5f0f\u8ddd\u79bb\u4e3a\u4f8b\uff09\uff0c\u7136\u540e\u5c06\u6837\u672c\u5212\u5206\u5230\u79bb\u5b83\u6700\u8fd1\u7684\u7c07\u4e2d\u3002\u5982\u4e0b\u56fe\uff08step 0\uff09\u7528\u4e0d\u540c\u7684\u989c\u8272\u533a\u5206\u4e0d\u540c\u7684\u7c07\uff1b \u66f4\u65b0\u7c07\u7684\u4e2d\u5fc3\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u7c07\u4e2d\u6240\u6709\u6837\u672c\u7684\u5747\u503c\uff08\u65b9\u6cd5\u4e0d\u552f\u4e00\uff09\u4f5c\u4e3a\u65b0\u7684\u7c07\u4e2d\u5fc3\u3002\u5982\u4e0b\u56fe\uff08step 1\uff09\u6240\u793a\uff0c\u4e24\u4e2a\u9ec4\u8272\u7684\u5c0f\u661f\u661f\u5df2\u7ecf\u79fb\u52a8\u5230\u5bf9\u5e94\u7c07\u7684\u4e2d\u5fc3\uff1b \u91cd\u590d\u7b2c3\u6b65\u5230\u7b2c4\u6b65\u76f4\u5230\u7c07\u4e2d\u5fc3\u4e0d\u5728\u53d8\u5316\u6216\u8005\u7c07\u4e2d\u5fc3\u53d8\u5316\u5f88\u5c0f\u6ee1\u8db3\u7ed9\u5b9a\u7ec8\u6b62\u6761\u4ef6\u3002\u5982\u4e0b\u56fe\uff08step2\uff09\u6240\u793a\uff0c\u6700\u7ec8\u805a\u7c7b\u7ed3\u679c\u3002","title":"K-means\u7b97\u6cd5\u4e3b\u8981\u6d41\u7a0b"},{"location":"source_code_interpretation/utils/autoanchor_py.html#bpr","text":"BPR\uff08BPR best possible recall\u6765\u6e90\u4e8e\u8bba\u6587: FCOS . \u539f\u8bba\u6587\u89e3\u91ca\uff1a BPR is defined as the ratio of the number of ground-truth boxes a detector can recall at the most divided by all ground-truth boxes. A ground-truth box is considered being recalled if the box is assigned to at least one sample (i.e., a location in FCOS or an anchor box in anchor-based detectors) during training. BPR (best possible recall): \u6700\u591a\u80fd\u88ab\u53ec\u56de\u7684 ground truth \u6846\u6570\u91cf / \u6240\u6709 ground truth \u6846\u6570\u91cf\u3002\u6700\u5927\u503c\u4e3a1 \u8d8a\u5927\u8d8a\u597d \u5c0f\u4e8e0.98\u5c31\u9700\u8981\u4f7f\u7528K-means + \u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\u9009\u62e9\u51fa\u4e0e\u6570\u636e\u96c6\u66f4\u5339\u914d\u7684anchor boxes\u6846\u3002","title":"\u4ec0\u4e48\u662fBPR?"},{"location":"source_code_interpretation/utils/autoanchor_py.html#whiten","text":"\u767d\u5316\u7684\u76ee\u7684\u662f\u53bb\u9664\u8f93\u5165\u6570\u636e\u7684\u5197\u4f59\u4fe1\u606f\u3002\u5047\u8bbe\u8bad\u7ec3\u6570\u636e\u662f\u56fe\u50cf\uff0c\u7531\u4e8e\u56fe\u50cf\u4e2d\u76f8\u90bb\u50cf\u7d20\u4e4b\u95f4\u5177\u6709\u5f88\u5f3a\u7684\u76f8\u5173\u6027\uff0c\u6240\u4ee5\u7528\u4e8e\u8bad\u7ec3\u65f6\u8f93\u5165\u662f\u5197\u4f59\u7684\uff1b\u767d\u5316\u7684\u76ee\u7684\u5c31\u662f\u964d\u4f4e\u8f93\u5165\u7684\u5197\u4f59\u6027\u3002 \u8f93\u5165\u6570\u636e\u96c6X\uff0c\u7ecf\u8fc7\u767d\u5316\u5904\u7406\u540e\uff0c\u65b0\u7684\u6570\u636eX\u2019\u6ee1\u8db3\u4e24\u4e2a\u6027\u8d28\uff1a \u7279\u5f81\u4e4b\u95f4\u76f8\u5173\u6027\u8f83\u4f4e\uff1b \u6240\u6709\u7279\u5f81\u5177\u6709\u76f8\u540c\u7684\u65b9\u5dee=1 \u5e38\u89c1\u7684\u4f5c\u6cd5\u662f\uff1a\u5bf9\u6bcf\u4e00\u4e2a\u6570\u636e\u505a\u4e00\u4e2a\u6807\u51c6\u5dee\u5f52\u4e00\u5316\u5904\u7406\uff08\u9664\u4ee5\u6807\u51c6\u5dee\uff09\u3002scipy.cluster.vq.kmeans() \u51fd\u6570\u8f93\u5165\u7684\u6570\u636e\u5c31\u662f\u5fc5\u987b\u662f\u767d\u5316\u540e\u7684\u6570\u636e\u3002\u76f8\u5e94\u8f93\u51fa\u7684 anchor boxes \u4e5f\u662f\u767d\u5316\u540e\u7684anchor\uff0c\u6240\u4ee5\u9700\u8981\u5c06anchor boxes \u90fd\u4e58\u4ee5\u6807\u51c6\u5dee\u6062\u590d\u5230\u539f\u59cb\u56fe\u50cf\u5c3a\u5ea6\u3002","title":"\u4ec0\u4e48\u662f\u767d\u5316\u64cd\u4f5cwhiten\uff1f"},{"location":"source_code_interpretation/utils/autoanchor_py.html#yolov5-autoanchorpy","text":"","title":"YOLOv5 \u4e2d\u7684 autoanchor.py \u4ee3\u7801\u89e3\u6790"},{"location":"source_code_interpretation/utils/autoanchor_py.html#1","text":"import numpy as np # numpy\u77e9\u9635\u64cd\u4f5c\u6a21\u5757 import oneflow as flow # OneFlow\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757 import yaml # \u64cd\u4f5cyaml\u6587\u4ef6\u6a21\u5757 from tqdm import tqdm # Python\u8fdb\u5ea6\u6761\u6a21\u5757 from utils.general import LOGGER , colorstr # \u65e5\u5fd7\u6a21\u5757 PREFIX = colorstr ( \"AutoAnchor: \" )","title":"1. \u5bfc\u5165\u9700\u8981\u7684\u5305"},{"location":"source_code_interpretation/utils/autoanchor_py.html#2check_anchor_order","text":"\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u786e\u8ba4\u5f53\u524danchors\u548cstride\u7684\u987a\u5e8f\u662f\u5426\u662f\u4e00\u81f4\u7684\uff0c\u56e0\u4e3a\u6211\u4eec\u7684m.anchors\u662f\u76f8\u5bf9\u5404\u4e2afeature map \uff08\u6bcf\u4e2afeature map\u7684\u611f\u53d7\u91ce\u4e0d\u540c \u68c0\u6d4b\u7684\u76ee\u6807\u5927\u5c0f\u4e5f\u4e0d\u540c \u9002\u5408\u7684anchor\u5927\u5c0f\u4e5f\u4e0d\u540c\uff09\u6240\u4ee5\u5fc5\u987b\u8981\u987a\u5e8f\u4e00\u81f4 \u5426\u5219\u6548\u679c\u4f1a\u5f88\u4e0d\u597d\u3002 \u8fd9\u4e2a\u51fd\u6570\u4e00\u822c\u7528\u4e8echeck_anchors\u6700\u540e\u9636\u6bb5\u3002 def check_anchor_order ( m ): \"\"\"\u7528\u5728check_anchors\u51fd\u6570\u7684\u6700\u540e \u786e\u5b9a anchors \u548c stride \u7684\u987a\u5e8f\u662f\u4e00\u81f4\u7684 Check anchor order against stride order for YOLOv5 Detect() module m, and correct if necessary :params m: model\u4e2d\u7684\u6700\u540e\u4e00\u5c42 Detect\u5c42 \"\"\" # Check anchor order against stride order for YOLOv5 Detect() module m, and correct if necessary # \u8ba1\u7b97anchor\u7684\u9762\u79ef anchor area [9] a = m . anchors . prod ( - 1 ) . mean ( - 1 ) . view ( - 1 ) # mean anchor area per output layer # \u8ba1\u7b97\u6700\u5927anchor\u4e0e\u6700\u5c0fanchor\u9762\u79ef\u5dee da = a [ - 1 ] - a [ 0 ] # delta a # \u8ba1\u7b97\u6700\u5927stride\u4e0e\u6700\u5c0fstride\u5dee # m.stride: model strides # https://github.com/Oneflow-Inc/one-yolov5/blob/bf8c66e011fcf5b8885068074ffc6b56c113a20c/models/yolo.py#L144-L152 ds = m . stride [ - 1 ] - m . stride [ 0 ] # delta s # flow.sign(x):\u5f53x\u5927\u4e8e/\u5c0f\u4e8e0\u65f6\uff0c\u8fd4\u56de1/-1 # \u5982\u679c\u8fd9\u91ccanchor\u4e0estride\u987a\u5e8f\u4e0d\u4e00\u81f4\uff0c\u5219\u91cd\u65b0\u8c03\u6574\u987a\u5e8f\uff0c\u4f46\u6ce8\u610f\u8fd9\u91cc\u8981\u629b\u51fawarning if da and ( da . sign () != ds . sign ()): # same order LOGGER . info ( f \" { PREFIX } Reversing anchor order\" ) m . anchors [:] = m . anchors . flip ( 0 )","title":"2.check_anchor_order"},{"location":"source_code_interpretation/utils/autoanchor_py.html#3-kmean_anchors","text":"\u8fd9\u4e2a\u51fd\u6570\u624d\u662f\u8fd9\u4e2a\u8fd9\u4e2a\u6587\u4ef6\u7684\u6838\u5fc3\u51fd\u6570\u3002\u529f\u80fd\uff1a\u4f7f\u7528 K-means + \u9057\u4f20\u7b97\u6cd5 \u7b97\u51fa\u66f4\u7b26\u5408\u5f53\u524d\u6570\u636e\u96c6\u7684anchors\u3002 \u8fd9\u91cc\u4e0d\u4ec5\u4ec5\u4f7f\u7528\u4e86 K-means \u805a\u7c7b\uff0c\u8fd8\u4f7f\u7528\u4e86 Genetic Algorithm \u9057\u4f20\u7b97\u6cd5\uff0c\u5728 K-means \u805a\u7c7b\u7684\u7ed3\u679c\u4e0a\u8fdb\u884c mutation\uff08\u53d8\u5f02\uff09\u3002\u63a5\u4e0b\u6765\u7b80\u5355\u4ecb\u7ecd\u4e0b\u4ee3\u7801\u6d41\u7a0b\uff1a \u8f7d\u5165\u6570\u636e\u96c6\uff0c\u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709\u6570\u636e\u7684wh \u5c06\u6bcf\u5f20\u56fe\u7247\u4e2dwh\u7684\u6700\u5927\u503c\u7b49\u6bd4\u4f8b\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0fimg_size\uff0c\u8f83\u5c0f\u8fb9\u4e5f\u76f8\u5e94\u7f29\u653e \u5c06bboxes\u4ece\u76f8\u5bf9\u5750\u6807\u6539\u6210\u7edd\u5bf9\u5750\u6807\uff08\u4e58\u4ee5\u7f29\u653e\u540e\u7684wh\uff09 \u7b5b\u9009bboxes\uff0c\u4fdd\u7559wh\u90fd\u5927\u4e8e\u7b49\u4e8e\u4e24\u4e2a\u50cf\u7d20\u7684bboxes \u4f7f\u7528K-means\u805a\u7c7b\u5f97\u5230n\u4e2aanchors\uff08\u8c03\u7528K-means\u5305 \u6d89\u53ca\u4e00\u4e2a\u767d\u5316\u64cd\u4f5c\uff09 \u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u968f\u673a\u5bf9anchors\u7684wh\u8fdb\u884c\u53d8\u5f02\uff0c\u5982\u679c\u53d8\u5f02\u540e\u6548\u679c\u53d8\u5f97\u66f4\u597d\uff08\u4f7f\u7528anchor_fitness\u65b9\u6cd5\u8ba1\u7b97\u5f97\u5230\u7684fitness\uff08\u9002\u5e94\u5ea6\uff09\u8fdb\u884c\u8bc4\u4f30\uff09\u5c31\u5c06\u53d8\u5f02\u540e\u7684\u7ed3\u679c\u8d4b\u503c\u7ed9anchors\uff0c\u5982\u679c\u53d8\u5f02\u540e\u6548\u679c\u53d8\u5dee\u5c31\u8df3\u8fc7\uff0c\u9ed8\u8ba4\u53d8\u5f021000\u6b21 \u4e0d\u77e5\u9053\u4ec0\u4e48\u662f\u9057\u4f20\u7b97\u6cd5\uff0c\u53ef\u4ee5\u770b\u770b\u8fd9\u4e24\u4e2ab\u7ad9\u89c6\u9891\uff1a \u4f20\u7b97\u6cd5\u8d85\u7ec6\u81f4+\u900f\u5f7b\u7406\u89e3 \u548c \u9739\u96f3\u5427\u5566Wz def kmean_anchors ( path = './data/coco128.yaml' , n = 9 , img_size = 640 , thr = 4.0 , gen = 1000 , verbose = True ): \"\"\"\u5728check_anchors\u4e2d\u8c03\u7528 \u4f7f\u7528K-means + \u9057\u4f20\u7b97\u6cd5 \u7b97\u51fa\u66f4\u7b26\u5408\u5f53\u524d\u6570\u636e\u96c6\u7684anchors Creates kmeans-evolved anchors from training dataset :params path: \u6570\u636e\u96c6\u7684\u8def\u5f84/\u6570\u636e\u96c6\u672c\u8eab :params n: anchors \u7684\u4e2a\u6570 :params img_size: \u6570\u636e\u96c6\u56fe\u7247\u7ea6\u5b9a\u7684\u5927\u5c0f :params thr: \u9608\u503c \u7531 hyp['anchor_t'] \u53c2\u6570\u63a7\u5236 :params gen: \u9057\u4f20\u7b97\u6cd5\u8fdb\u5316\u8fed\u4ee3\u7684\u6b21\u6570(\u7a81\u53d8 + \u9009\u62e9) :params verbose: \u662f\u5426\u6253\u5370\u6240\u6709\u7684\u8fdb\u5316(\u6210\u529f\u7684)\u7ed3\u679c \u9ed8\u8ba4\u4f20\u5165\u662fFalse, \u53ea\u6253\u5370\u6700\u4f73\u7684\u8fdb\u5316\u7ed3\u679c :return k: K-means + \u9057\u4f20\u7b97\u6cd5\u8fdb\u5316\u540e\u7684anchors \"\"\" from scipy.cluster.vq import kmeans # \u6ce8\u610f\u4e00\u4e0b\u4e0b\u9762\u7684thr\u4e0d\u662f\u4f20\u5165\u7684thr\uff0c\u800c\u662f1/thr, \u6240\u4ee5\u5728\u8ba1\u7b97\u6307\u6807\u8fd9\u65b9\u9762\u8fd8\u662f\u548ccheck_anchor\u4e00\u6837 thr = 1. / thr # 0.25 prefix = colorstr ( 'autoanchor: ' ) def metric ( k , wh ): # compute metrics \"\"\"\u7528\u4e8e print_results \u51fd\u6570\u548c anchor_fitness \u51fd\u6570 \u8ba1\u7b97ratio metric: \u6574\u4e2a\u6570\u636e\u96c6\u7684 ground truth \u6846\u4e0e anchor \u5bf9\u5e94\u5bbd\u6bd4\u548c\u9ad8\u6bd4\u5373:gt_w/k_w,gt_h/k_h + x + best_x \u7528\u4e8e\u540e\u7eed\u8ba1\u7b97BPR+aat \u6ce8\u610f\u6211\u4eec\u8fd9\u91cc\u9009\u62e9\u7684metric\u662f ground truth \u6846\u4e0eanchor\u5bf9\u5e94\u5bbd\u6bd4\u548c\u9ad8\u6bd4 \u800c\u4e0d\u662f\u5e38\u7528\u7684iou \u8fd9\u70b9\u4e5f\u4e0enms\u7684\u7b5b\u9009\u6761\u4ef6\u5bf9\u5e94 \u662fyolov5\u4e2d\u4f7f\u7528\u7684\u65b0\u65b9\u6cd5 :params k: anchor\u6846 :params wh: \u6574\u4e2a\u6570\u636e\u96c6\u7684 wh [N, 2] :return x: [N, 9] N \u4e2a ground truth \u6846\u4e0e\u6240\u6709 anchor \u6846\u7684\u5bbd\u6bd4\u6216\u9ad8\u6bd4(\u4e24\u8005\u4e4b\u4e2d\u8f83\u5c0f\u8005) :return x.max(1)[0]: [N] N\u4e2a ground truth \u6846\u4e0e\u6240\u6709 anchor \u6846\u4e2d\u7684\u6700\u5927\u5bbd\u6bd4\u6216\u9ad8\u6bd4(\u4e24\u8005\u4e4b\u4e2d\u8f83\u5c0f\u8005) \"\"\" # [N, 1, 2] / [1, 9, 2] = [N, 9, 2] N\u4e2agt_wh\u548c9\u4e2aanchor\u7684k_wh\u5bbd\u6bd4\u548c\u9ad8\u6bd4 # \u4e24\u8005\u7684\u91cd\u5408\u7a0b\u5ea6\u8d8a\u9ad8 \u5c31\u8d8a\u8d8b\u8fd1\u4e8e1 \u8fdc\u79bb1(<1 \u6216 >1)\u91cd\u5408\u7a0b\u5ea6\u90fd\u8d8a\u4f4e r = wh [:, None ] / k [ None ] # r=gt_height/anchor_height gt_width / anchor_width \u6709\u53ef\u80fd\u5927\u4e8e1\uff0c\u4e5f\u53ef\u80fd\u5c0f\u4e8e\u7b49\u4e8e1 # flow.min(r, 1. / r): [N, 9, 2] \u5c06\u6240\u6709\u7684\u5bbd\u6bd4\u548c\u9ad8\u6bd4\u7edf\u4e00\u5230 <=1 # .min(2): value=[N, 9] \u9009\u51fa\u6bcf\u4e2a ground truth \u4e2a\u548c anchor \u7684\u5bbd\u6bd4\u548c\u9ad8\u6bd4\u6700\u5c0f\u7684\u503c index: [N, 9] \u8fd9\u4e2a\u6700\u5c0f\u503c\u662f\u5bbd\u6bd4(0)\u8fd8\u662f\u9ad8\u6bd4(1) # [0] \u8fd4\u56de value [N, 9] \u6bcf\u4e2a ground truth \u4e2a\u548c anchor \u7684\u5bbd\u6bd4\u548c\u9ad8\u6bd4\u6700\u5c0f\u7684\u503c \u5c31\u662f\u6240\u6709 ground truth \u4e0e anchor \u91cd\u5408\u7a0b\u5ea6\u6700\u4f4e\u7684 x = flow . min ( r , 1. / r ) . min ( 2 )[ 0 ] # ratio metric # x = wh_iou(wh, flow.tensor(k)) # IoU metric # x.max(1)[0]: [N] \u8fd4\u56de\u6bcf\u4e2a ground truth \u548c\u6240\u6709 anchor(9\u4e2a) \u4e2d\u5bbd\u6bd4/\u9ad8\u6bd4\u6700\u5927\u7684\u503c return x , x . max ( 1 )[ 0 ] # x, best_x def anchor_fitness ( k ): # mutation fitness \"\"\"\u7528\u4e8e kmean_anchors \u51fd\u6570 \u9002\u5e94\u5ea6\u8ba1\u7b97 \u4f18\u80dc\u52a3\u6c70 \u7528\u4e8e\u9057\u4f20\u7b97\u6cd5\u4e2d\u8861\u91cf\u7a81\u53d8\u662f\u5426\u6709\u6548\u7684\u6807\u6ce8 \u5982\u679c\u6709\u6548\u5c31\u8fdb\u884c\u9009\u62e9\u64cd\u4f5c\uff0c\u65e0\u6548\u5c31\u7ee7\u7eed\u4e0b\u4e00\u8f6e\u7684\u7a81\u53d8 :params k: [9, 2] K-means\u751f\u6210\u7684 9 \u4e2aanchors wh: [N, 2]: \u6570\u636e\u96c6\u7684\u6240\u6709 ground truth \u6846\u7684\u5bbd\u9ad8 :return (best * (best > thr).float()).mean()=\u9002\u5e94\u5ea6\u8ba1\u7b97\u516c\u5f0f [1] \u6ce8\u610f\u548cBPR\u6709\u533a\u522b \u8fd9\u91cc\u662f\u81ea\u5b9a\u4e49\u7684\u4e00\u79cd\u9002\u5e94\u5ea6\u516c\u5f0f \u8fd4\u56de\u7684\u662f\u8f93\u5165\u6b64\u65f6anchor k \u5bf9\u5e94\u7684\u9002\u5e94\u5ea6 \"\"\" _ , best = metric ( flow . tensor ( k , dtype = flow . float32 ), wh ) return ( best * ( best > thr ) . float ()) . mean () # fitness def print_results ( k ): \"\"\"\u7528\u4e8e kmean_anchors \u51fd\u6570\u4e2d\u6253\u5370K-means\u8ba1\u7b97\u76f8\u5173\u4fe1\u606f \u8ba1\u7b97BPR\u3001aat=>\u6253\u5370\u4fe1\u606f: \u9608\u503c+BPR+aat anchor\u4e2a\u6570+\u56fe\u7247\u5927\u5c0f+metric_all+best_mean+past_mean+Kmeans\u805a\u7c7b\u51fa\u6765\u7684anchor\u6846(\u56db\u820d\u4e94\u5165) :params k: K-means\u5f97\u5230\u7684anchor k :return k: input \"\"\" # \u5c06K-means\u5f97\u5230\u7684anchor k\u6309\u9762\u79ef\u4ece\u5c0f\u5230\u5927\u6392\u5e8f k = k [ np . argsort ( k . prod ( 1 ))] # x: [N, 9] N\u4e2a ground truth \u6846\u4e0e\u6240\u6709anchor\u6846\u7684\u5bbd\u6bd4\u6216\u9ad8\u6bd4(\u4e24\u8005\u4e4b\u4e2d\u8f83\u5c0f\u8005) # best: [N] N\u4e2a ground truth \u6846\u4e0e\u6240\u6709anchor\u6846\u4e2d\u7684\u6700\u5927\u5bbd\u6bd4\u6216\u9ad8\u6bd4(\u4e24\u8005\u4e4b\u4e2d\u8f83\u5c0f\u8005) x , best = metric ( k , wh0 ) # (best > thr).float(): True=>1. False->0. .mean(): \u6c42\u5747\u503c # BPR(best possible recall): \u6700\u591a\u80fd\u88ab\u53ec\u56de(\u901a\u8fc7thr)\u7684 ground truth \u6846\u6570\u91cf / \u6240\u6709 ground truth \u6846\u6570\u91cf [1] 0.96223 \u5c0f\u4e8e0.98 \u624d\u4f1a\u7528K-means\u8ba1\u7b97anchor # aat(anchors above threshold): [1] 3.54360 \u6bcf\u4e2atarget\u5e73\u5747\u6709\u591a\u5c11\u4e2aanchors BPR , aat = ( best > thr ) . float () . mean (), ( x > thr ) . float () . mean () * n # best possible recall, anch > thr f = anchor_fitness ( k ) # print(f'{prefix}thr={thr:.2f}: {BPR:.4f} best possible recall, {aat:.2f} anchors past thr') # print(f'{prefix}n={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, ' # f'past_thr={x[x > thr].mean():.3f}-mean: ', end='') print ( f \"aat: { aat : .5f } , fitness: { f : .5f } , best possible recall: { BPR : .5f } \" ) for i , x in enumerate ( k ): print ( ' %i , %i ' % ( round ( x [ 0 ]), round ( x [ 1 ])), end = ', ' if i < len ( k ) - 1 else ' \\n ' ) # use in *.cfg return k # \u8f7d\u5165\u6570\u636e\u96c6 if isinstance ( path , str ): # *.yaml file with open ( path ) as f : data_dict = yaml . safe_load ( f ) # model dict from utils.datasets import LoadImagesAndLabels dataset = LoadImagesAndLabels ( data_dict [ 'train' ], augment = True , rect = True ) else : dataset = path # dataset # \u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709\u6570\u636e\u7684 wh # \u5c06\u6570\u636e\u96c6\u56fe\u7247\u7684\u6700\u957f\u8fb9\u7f29\u653e\u5230 img_size, \u8f83\u5c0f\u8fb9\u76f8\u5e94\u7f29\u653e shapes = img_size * dataset . shapes / dataset . shapes . max ( 1 , keepdims = True ) # \u5c06\u539f\u672c\u6570\u636e\u96c6\u4e2dgt boxes\u5f52\u4e00\u5316\u7684wh\u7f29\u653e\u5230shapes\u5c3a\u5ea6 wh0 = np . concatenate ([ l [:, 3 : 5 ] * s for s , l in zip ( shapes , dataset . labels )]) # \u7edf\u8ba1gt boxes\u4e2d\u5bbd\u6216\u8005\u9ad8\u5c0f\u4e8e 3 \u4e2a\u50cf\u7d20\u7684\u4e2a\u6570, \u76ee\u6807\u592a\u5c0f \u53d1\u51fa\u8b66\u544a i = ( wh0 < 3.0 ) . any ( 1 ) . sum () if i : print ( f ' { prefix } WARNING: Extremely small objects found. { i } of { len ( wh0 ) } labels are < 3 pixels in size.' ) # \u7b5b\u9009\u51fa label \u5927\u4e8e 2 \u4e2a\u50cf\u7d20\u7684\u6846\u62ff\u6765\u805a\u7c7b, [...]\u5185\u7684\u76f8\u5f53\u4e8e\u4e00\u4e2a\u7b5b\u9009\u5668, \u4e3aTrue\u7684\u7559\u4e0b wh = wh0 [( wh0 >= 2.0 ) . any ( 1 )] # filter > 2 pixels # wh = wh * (np.random.rand(wh.shape[0], 1) * 0.9 + 0.1) # multiply by random scale 0-1 # Kmeans\u805a\u7c7b\u65b9\u6cd5: \u4f7f\u7528\u6b27\u5f0f\u8ddd\u79bb\u6765\u8fdb\u884c\u805a\u7c7b print ( f ' { prefix } Running kmeans for { n } anchors on { len ( wh ) } gt boxes...' ) # \u8ba1\u7b97\u5bbd\u548c\u9ad8\u7684\u6807\u51c6\u5dee->[w_std,h_std] s = wh . std ( 0 ) # sigmas for whitening # \u5f00\u59cb\u805a\u7c7b,\u4ecd\u7136\u662f\u805a\u6210 n \u7c7b,\u8fd4\u56de\u805a\u7c7b\u540e\u7684anchors k(\u8fd9\u4e2aanchors k\u662f\u767d\u5316\u540e\u6570\u636e\u7684anchor\u6846s) # \u53e6\u5916\u8fd8\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u91cc\u7684kmeans\u4f7f\u7528\u6b27\u5f0f\u8ddd\u79bb\u6765\u8ba1\u7b97\u7684 # \u8fd0\u884cK-means\u7684\u6b21\u6570\u4e3a30\u6b21 obs: \u4f20\u5165\u7684\u6570\u636e\u5fc5\u987b\u5148\u767d\u5316\u5904\u7406 'whiten operation' # \u767d\u5316\u5904\u7406: \u65b0\u6570\u636e\u7684\u6807\u51c6\u5dee=1 \u964d\u4f4e\u6570\u636e\u4e4b\u95f4\u7684\u76f8\u5173\u5ea6\uff0c\u4e0d\u540c\u6570\u636e\u6240\u8574\u542b\u7684\u4fe1\u606f\u4e4b\u95f4\u7684\u91cd\u590d\u6027\u5c31\u4f1a\u964d\u4f4e\uff0c\u7f51\u7edc\u7684\u8bad\u7ec3\u6548\u7387\u5c31\u4f1a\u63d0\u9ad8 # \u767d\u5316\u64cd\u4f5c\u53c2\u8003\u535a\u5ba2: https://blog.csdn.net/weixin_37872766/article/details/102957235 k , dist = kmeans ( wh / s , n , iter = 30 ) # points, mean distance assert len ( k ) == n , print ( f ' { prefix } ERROR: scipy.cluster.vq.kmeans requested { n } points but returned only { len ( k ) } ' ) k *= s # k*s \u5f97\u5230\u539f\u6765\u6570\u636e(\u767d\u5316\u524d)\u7684 anchor \u6846 wh = flow . tensor ( wh , dtype = flow . float32 ) # filtered wh wh0 = flow . tensor ( wh0 , dtype = flow . float32 ) # unfiltered wh0 # \u8f93\u51fa\u65b0\u7b97\u7684anchors k \u76f8\u5173\u7684\u4fe1\u606f k = print_results ( k ) # Plot wh # k, d = [None] * 20, [None] * 20 # for i in tqdm(range(1, 21)): # k[i-1], d[i-1] = kmeans(wh / s, i) # points, mean distance # fig, ax = plt.subplots(1, 2, figsize=(14, 7), tight_layout=True) # ax = ax.ravel() # ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.') # fig, ax = plt.subplots(1, 2, figsize=(14, 7)) # plot wh # ax[0].hist(wh[wh[:, 0]<100, 0], 400) # ax[1].hist(wh[wh[:, 1]<100, 1], 400) # fig.savefig('wh.png', dpi=200) # Evolve \u7c7b\u4f3c\u9057\u4f20/\u8fdb\u5316\u7b97\u6cd5 \u53d8\u5f02\u64cd\u4f5c npr = np . random # \u968f\u673a\u5de5\u5177 # f: fitness 0.62690 # sh: (9,2) # mp: \u7a81\u53d8\u6bd4\u4f8bmutation prob=0.9 s: sigma=0.1 f , sh , mp , s = anchor_fitness ( k ), k . shape , 0.9 , 0.1 # fitness, generations, mutation prob, sigma pbar = tqdm ( range ( gen ), desc = f ' { prefix } Evolving anchors with Genetic Algorithm:' ) # progress bar # \u6839\u636e\u805a\u7c7b\u51fa\u6765\u7684n\u4e2a\u70b9\u91c7\u7528\u9057\u4f20\u7b97\u6cd5\u751f\u6210\u65b0\u7684anchor for _ in pbar : # \u91cd\u590d1000\u6b21\u7a81\u53d8+\u9009\u62e9 \u9009\u62e9\u51fa1000\u6b21\u7a81\u53d8\u91cc\u7684\u6700\u4f73anchor k\u548c\u6700\u4f73\u9002\u5e94\u5ea6f v = np . ones ( sh ) # v [9, 2] \u5168\u662f1 while ( v == 1 ) . all (): # \u4ea7\u751f\u53d8\u5f02\u89c4\u5219 mutate until a change occurs (prevent duplicates) # npr.random(sh) < mp: \u8ba9v\u4ee590%\u7684\u6bd4\u4f8b\u8fdb\u884c\u53d8\u5f02 \u9009\u5230\u53d8\u5f02\u7684\u5c31\u4e3a1 \u6ca1\u6709\u9009\u5230\u53d8\u5f02\u7684\u5c31\u4e3a0 v = (( npr . random ( sh ) < mp ) * npr . random () * npr . randn ( * sh ) * s + 1 ) . clip ( 0.3 , 3.0 ) # \u53d8\u5f02(\u6539\u53d8\u8fd9\u4e00\u65f6\u523b\u4e4b\u524d\u7684\u6700\u4f73\u9002\u5e94\u5ea6\u5bf9\u5e94\u7684anchor k) kg = ( k . copy () * v ) . clip ( min = 2.0 ) # \u8ba1\u7b97\u53d8\u5f02\u540e\u7684anchor kg\u7684\u9002\u5e94\u5ea6 fg = anchor_fitness ( kg ) # \u5982\u679c\u53d8\u5f02\u540e\u7684anchor kg\u7684\u9002\u5e94\u5ea6>\u6700\u4f73\u9002\u5e94\u5ea6k \u5c31\u8fdb\u884c\u9009\u62e9\u64cd\u4f5c if fg > f : # \u9009\u62e9\u53d8\u5f02\u540e\u7684anchor kg\u4e3a\u6700\u4f73\u7684anchor k \u53d8\u5f02\u540e\u7684\u9002\u5e94\u5ea6fg\u4e3a\u6700\u4f73\u9002\u5e94\u5ea6f f , k = fg , kg . copy () # \u6253\u5370\u4fe1\u606f pbar . desc = f ' { prefix } Evolving anchors with Genetic Algorithm: fitness = { f : .4f } ' if verbose : print_results ( k ) return print_results ( k )","title":"3. kmean_anchors"},{"location":"source_code_interpretation/utils/autoanchor_py.html#4-check_anchors","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u901a\u8fc7\u8ba1\u7b97BPR\u786e\u5b9a\u662f\u5426\u9700\u8981\u6539\u53d8anchors \u9700\u8981\u5c31\u8c03\u7528K-means\u91cd\u65b0\u8ba1\u7b97anchors\u3002 def check_anchors ( dataset , model , thr = 4.0 , imgsz = 640 ): # Check anchor fit to data, recompute if necessary \"\"\"\u7528\u4e8etrain.py\u4e2d \u901a\u8fc7BPR\u786e\u5b9a\u662f\u5426\u9700\u8981\u6539\u53d8anchors \u9700\u8981\u5c31\u8c03\u7528K-means\u91cd\u65b0\u8ba1\u7b97anchors Check anchor fit to data, recompute if necessary :params dataset: \u81ea\u5b9a\u4e49\u6570\u636e\u96c6LoadImagesAndLabels\u8fd4\u56de\u7684\u6570\u636e\u96c6 :params model: \u521d\u59cb\u5316\u7684\u6a21\u578b :params thr: \u8d85\u53c2\u4e2d\u5f97\u5230 \u754c\u5b9aanchor\u4e0elabel\u5339\u914d\u7a0b\u5ea6\u7684\u9608\u503c :params imgsz: \u56fe\u7247\u5c3a\u5bf8 \u9ed8\u8ba4640 \"\"\" # \u4ecemodel\u4e2d\u53d6\u51fa\u6700\u540e\u4e00\u5c42(Detect) m = model . module . model [ - 1 ] if hasattr ( model , \"module\" ) else model . model [ - 1 ] # Detect() # dataset.shapes.max(1, keepdims=True) = \u6bcf\u5f20\u56fe\u7247\u7684\u8f83\u957f\u8fb9 # shapes: \u5c06\u6570\u636e\u96c6\u56fe\u7247\u7684\u6700\u957f\u8fb9\u7f29\u653e\u5230img_size, \u8f83\u5c0f\u8fb9\u76f8\u5e94\u7f29\u653e \u5f97\u5230\u65b0\u7684\u6240\u6709\u6570\u636e\u96c6\u56fe\u7247\u7684\u5bbd\u9ad8 [N, 2] shapes = imgsz * dataset . shapes / dataset . shapes . max ( 1 , keepdims = True ) # \u4ea7\u751f\u968f\u673a\u6570scale [img_size, 1] scale = np . random . uniform ( 0.9 , 1.1 , size = ( shapes . shape [ 0 ], 1 )) # augment scale # [6301, 2] \u6240\u6709target(6301\u4e2a)\u7684wh \u57fa\u4e8e\u539f\u56fe\u5927\u5c0f shapes * scale: \u968f\u673a\u5316\u5c3a\u5ea6\u53d8\u5316 wh = flow . tensor ( np . concatenate ([ l [:, 3 : 5 ] * s for s , l in zip ( shapes * scale , dataset . labels )])) . float () # wh def metric ( k ): # compute metric \"\"\"\u7528\u5728check_anchors\u51fd\u6570\u4e2d compute metric \u6839\u636e\u6570\u636e\u96c6\u7684\u6240\u6709\u56fe\u7247\u7684wh\u548c\u5f53\u524d\u6240\u6709anchors k\u8ba1\u7b97 BPR(best possible recall) \u548c aat(anchors above threshold) :params k: anchors [9, 2] wh: [N, 2] :return BPR: best possible recall \u6700\u591a\u80fd\u88ab\u53ec\u56de(\u901a\u8fc7thr)\u7684 ground truth \u6846\u6570\u91cf / \u6240\u6709 ground truth \u6846\u6570\u91cf\u5c0f\u4e8e0.98 \u624d\u4f1a\u7528K-means\u8ba1\u7b97anchor :return aat: anchors above threshold \u6bcf\u4e2atarget\u5e73\u5747\u6709\u591a\u5c11\u4e2aanchors \"\"\" # None\u6dfb\u52a0\u7ef4\u5ea6 \u6240\u6709target(gt)\u7684wh wh[:, None] [6301, 2]->[6301, 1, 2] # \u6240\u6709anchor\u7684wh k[None] [9, 2]->[1, 9, 2] # r: target\u7684\u9ad8h\u5bbdw\u4e0eanchor\u7684\u9ad8h_a\u5bbdw_a\u7684\u6bd4\u503c\uff0c\u5373h/h_a, w/w_a [6301, 9, 2] \u6709\u53ef\u80fd\u5927\u4e8e1\uff0c\u4e5f\u53ef\u80fd\u5c0f\u4e8e\u7b49\u4e8e1 r = wh [:, None ] / k [ None ] # x \u9ad8\u5bbd\u6bd4\u548c\u5bbd\u9ad8\u6bd4\u7684\u6700\u5c0f\u503c \u65e0\u8bbar\u5927\u4e8e1\uff0c\u8fd8\u662f\u5c0f\u4e8e\u7b49\u4e8e1\u6700\u540e\u7edf\u4e00\u7ed3\u679c\u90fd\u8981\u5c0f\u4e8e1 [6301, 9] x = flow . min ( r , 1 / r ) . min ( 2 )[ 0 ] # ratio metric # best [6301] \u4e3a\u6bcf\u4e2a ground truth \u6846\u9009\u62e9\u5339\u914d\u6240\u6709anchors\u5bbd\u9ad8\u6bd4\u4f8b\u503c\u6700\u597d\u7684\u90a3\u4e00\u4e2a\u6bd4\u503c best = x . max ( 1 )[ 0 ] # best_x # aat(anchors above threshold) \u6bcf\u4e2atarget\u5e73\u5747\u6709\u591a\u5c11\u4e2aanchors aat = ( x > 1 / thr ) . float () . sum ( 1 ) . mean () # anchors above threshold # BPR(best possible recall) = \u6700\u591a\u80fd\u88ab\u53ec\u56de(\u901a\u8fc7thr)\u7684 ground truth \u6846\u6570\u91cf / \u6240\u6709 ground truth \u6846\u6570\u91cf \u5c0f\u4e8e0.98 \u624d\u4f1a\u7528K-means\u8ba1\u7b97anchor BPR = ( best > 1 / thr ) . float () . mean () # best possible recall return BPR , aat stride = m . stride . to ( m . anchors . device ) . view ( - 1 , 1 , 1 ) # model strides # anchors: [N,2] \u6240\u6709anchors\u7684\u5bbd\u9ad8 \u57fa\u4e8e\u7f29\u653e\u540e\u7684\u56fe\u7247\u5927\u5c0f(\u8f83\u957f\u8fb9\u4e3a640 \u8f83\u5c0f\u8fb9\u76f8\u5e94\u7f29\u653e) anchors = m . anchors . clone () * stride # current anchors BPR , aat = metric ( anchors . cpu () . view ( - 1 , 2 )) s = f \" \\n { PREFIX }{ aat : .2f } anchors/target, { BPR : .3f } Best Possible Recall (BPR). \" # \u8003\u8651\u8fd99\u7c7banchor\u7684\u5bbd\u9ad8\u548c ground truth \u6846\u7684\u5bbd\u9ad8\u4e4b\u95f4\u7684\u5dee\u8ddd, \u5982\u679cBPR<0.98(\u8bf4\u660e\u5f53\u524danchor\u4e0d\u80fd\u5f88\u597d\u7684\u5339\u914d\u6570\u636e\u96c6 ground truth \u6846)\u5c31\u4f1a\u6839\u636eK-means\u7b97\u6cd5\u91cd\u65b0\u805a\u7c7b\u65b0\u7684anchor if BPR > 0.98 : # threshold to recompute LOGGER . info ( f \" { s } Current anchors are a good fit to dataset \u2705\" ) else : LOGGER . info ( f \" { s } Anchors are a poor fit to dataset \u26a0\ufe0f, attempting to improve...\" ) na = m . anchors . numel () // 2 # number of anchors try : # \u5982\u679cBPR<0.98(\u6700\u5927\u4e3a1 \u8d8a\u5927\u8d8a\u597d) \u4f7f\u7528K-means + \u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\u9009\u62e9\u51fa\u4e0e\u6570\u636e\u96c6\u66f4\u5339\u914d\u7684anchors\u6846 [9, 2] anchors = kmean_anchors ( dataset , n = na , img_size = imgsz , thr = thr , gen = 1000 , verbose = False ) except Exception as e : LOGGER . info ( f \" { PREFIX } ERROR: { e } \" ) # \u8ba1\u7b97\u65b0\u7684anchors\u7684new_BPR new_BPR = metric ( anchors )[ 0 ] # \u6bd4\u8f83 K-means + \u9057\u4f20\u8fdb\u5316\u7b97\u6cd5\u8fdb\u5316\u540e\u7684anchors\u7684new_BPR\u548c\u539f\u59cbanchors\u7684BPR # \u6ce8\u610f: \u8fd9\u91cc\u5e76\u4e0d\u4e00\u5b9a\u8fdb\u5316\u540e\u7684BPR\u5fc5\u5927\u4e8e\u539f\u59cbanchors\u7684BPR, \u56e0\u4e3a\u4e24\u8005\u7684\u8861\u91cf\u6807\u6ce8\u662f\u4e0d\u4e00\u6837\u7684 \u8fdb\u5316\u7b97\u6cd5\u7684\u8861\u91cf\u6807\u51c6\u662f\u9002\u5e94\u5ea6 \u800c\u8fd9\u91cc\u6bd4\u7684\u662fBPR if new_BPR > BPR : # replace anchors anchors = flow . tensor ( anchors , device = m . anchors . device ) . type_as ( m . anchors ) # \u66ff\u6362m\u7684anchor_grid [9, 2] -> [3, 1, 3, 1, 1, 2] m . anchors [:] = anchors . clone () . view_as ( m . anchors ) # \u68c0\u67e5anchor\u987a\u5e8f\u548cstride\u987a\u5e8f\u662f\u5426\u4e00\u81f4 \u4e0d\u4e00\u81f4\u5c31\u8c03\u6574 # \u56e0\u4e3a\u6211\u4eec\u7684m.anchors\u662f\u76f8\u5bf9\u5404\u4e2a feature map \u6240\u4ee5\u5fc5\u987b\u8981\u987a\u5e8f\u4e00\u81f4 \u5426\u5219\u6548\u679c\u4f1a\u5f88\u4e0d\u597d check_anchor_order ( m ) # must be in pixel-space (not grid-space) m . anchors /= stride s = f \" { PREFIX } Done \u2705 (optional: update model *.yaml to use these anchors in the future)\" else : s = f \" { PREFIX } Done \u26a0\ufe0f (original anchors better than new anchors, proceeding with original anchors)\" LOGGER . info ( s ) \u8fd9\u4e2a\u51fd\u6570\u4f1a\u5728 train.py\u4e2d\u8c03\u7528\uff1a","title":"4. check_anchors"},{"location":"source_code_interpretation/utils/autoanchor_py.html#_3","text":"K-means\u662f\u975e\u5e38\u7ecf\u5178\u4e14\u6709\u6548\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u6837\u672c\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u76f8\u4f3c\u7a0b\u5ea6\uff09\u5c06\u8f83\u8fd1\u7684\u6837\u672c\u805a\u4e3a\u540c\u4e00\u7c7b\u522b\uff08\u7c07\uff09\u3002","title":"\u603b\u7ed3"},{"location":"source_code_interpretation/utils/autoanchor_py.html#reference","text":"YOLO9000:Better, Faster, Stronger \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011[autoanchor.py] https://blog.csdn.net/qq_38253797/article/details/119713706 CSDN \u9739\u96f3\u5427\u5566Wz : \u4f7f\u7528K-means\u805a\u7c7banchors Bilibili \u9739\u96f3\u5427\u5566Wz : \u5982\u4f55\u4f7f\u7528K-means\u805a\u7c7b\u5f97\u5230anchors\u4ee5\u53ca\u9700\u8981\u6ce8\u610f\u7684\u5751. CSDN \u6069\u6cfd\u541b : YOLOV3\u4e2dK-means\u805a\u7c7b\u83b7\u5f97anchor boxes\u8fc7\u7a0b\u8be6\u89e3. Github \u6069\u6cfd\u541b: Laughing-q/yolov5_annotations. CSDN \u660c\u5c71\u5c0f\u5c4b: \u3010\u73a9\u8f6cyolov5\u3011 \u8bf7\u770b\u4ee3\u7801\u4e4b\u81ea\u52a8anchor\u8ba1\u7b97. CSDN TheOldManAndTheSea: \u76ee\u6807\u68c0\u6d4b YOLOv5 anchor\u8bbe\u7f6e Bilibili \u6211\u5bb6\u516c\u5b50Q: \u9057\u4f20\u7b97\u6cd5\u8d85\u7ec6\u81f4+\u900f\u5f7b\u7406\u89e3","title":"Reference"},{"location":"source_code_interpretation/utils/dataloaders_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/dataloaders.py 1. \u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license \"\"\" Dataloaders and dataset utils \"\"\" import contextlib import glob # python\u81ea\u5df1\u5e26\u7684\u4e00\u4e2a\u6587\u4ef6\u64cd\u4f5c\u76f8\u5173\u6a21\u5757 \u67e5\u627e\u7b26\u5408\u81ea\u5df1\u76ee\u7684\u7684\u6587\u4ef6(\u5982\u6a21\u7cca\u5339\u914d) import hashlib # \u54c8\u5e0c\u6a21\u5757 \u63d0\u4f9b\u4e86\u591a\u79cd\u5b89\u5168\u65b9\u4fbf\u7684hash\u65b9\u6cd5 import json # json\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 import math # \u6570\u5b66\u516c\u5f0f\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 \u5305\u542b\u6587\u4ef6\u8def\u5f84\u64cd\u4f5c\u548c\u89e3\u6790 import random # \u751f\u6210\u968f\u673a\u6570\u6a21\u5757 import shutil # \u6587\u4ef6\u5939\u3001\u538b\u7f29\u5305\u5904\u7406\u6a21\u5757 import time # \u65f6\u95f4\u6a21\u5757 \u66f4\u5e95\u5c42 from itertools import repeat # \u590d\u5236\u6a21\u5757 from multiprocessing.pool import Pool , ThreadPool # \u591a\u7ebf\u7a0b\u6a21\u5757 \u7ebf\u7a0b\u6c60 from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 from threading import Thread # \u591a\u7ebf\u7a0b\u64cd\u4f5c\u6a21\u5757 from urllib.parse import urlparse from zipfile import ZipFile import numpy as np # numpy\u77e9\u9635\u64cd\u4f5c\u6a21\u5757 import oneflow as flow # OneFlow\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757 import oneflow.nn.functional as F # OneFlow\u51fd\u6570\u63a5\u53e3 \u5c01\u88c5\u4e86\u5f88\u591a\u5377\u79ef\u3001\u6c60\u5316\u7b49\u51fd\u6570 import yaml # yaml\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 from oneflow.utils.data import DataLoader , Dataset , dataloader , distributed from PIL import ExifTags , Image , ImageOps # \u56fe\u7247\u3001\u76f8\u673a\u64cd\u4f5c\u6a21\u5757 from tqdm import tqdm # \u8fdb\u5ea6\u6761\u6a21\u5757 # augmentations.py\u6e90\u7801\u89e3\u8bfb: https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/utils/augmentations_py.html from utils.augmentations import Albumentations , augment_hsv , copy_paste , letterbox , mixup , random_perspective from utils.general import ( DATASETS_DIR , LOGGER , NUM_THREADS , check_dataset , check_requirements , check_yaml , clean_str , cv2 , is_colab , is_kaggle , segments2boxes , xyn2xy , xywh2xyxy , xywhn2xyxy , xyxy2xywhn , ) # Parameters HELP_URL = \"https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\" IMG_FORMATS = ( \"bmp\" , \"dng\" , \"jpeg\" , \"jpg\" , \"mpo\" , \"png\" , \"tif\" , \"tiff\" , \"webp\" , ) # include image suffixes VID_FORMATS = ( \"asf\" , \"avi\" , \"gif\" , \"m4v\" , \"mkv\" , \"mov\" , \"mp4\" , \"mpeg\" , \"mpg\" , \"ts\" , \"wmv\" , ) # include video suffixes BAR_FORMAT = \" {l_bar}{bar:10}{r_bar}{bar:-10b} \" # tqdm bar format LOCAL_RANK = int ( os . getenv ( \"LOCAL_RANK\" , - 1 )) # https://oneflow.readthedocs.io/en/master/distributed.html?highlight=launch#launching-distributed-training RANK = int ( os . getenv ( \"RANK\" , - 1 )) 2. \u76f8\u673a\u8bbe\u7f6e \u2003\u8fd9\u90e8\u5206\u662f\u76f8\u673a\u76f8\u5173\u8bbe\u7f6e\uff0c\u5f53\u4f7f\u7528\u76f8\u673a\u91c7\u6837\u65f6\u624d\u4f1a\u4f7f\u7528\u3002 # \u76f8\u673a\u8bbe\u7f6e # Get orientation exif tag # \u4e13\u95e8\u4e3a\u6570\u7801\u76f8\u673a\u7684\u7167\u7247\u800c\u8bbe\u5b9a \u53ef\u4ee5\u8bb0\u5f55\u6570\u7801\u7167\u7247\u7684\u5c5e\u6027\u4fe1\u606f\u548c\u62cd\u6444\u6570\u636e for orientation in ExifTags . TAGS . keys (): if ExifTags . TAGS [ orientation ] == \"Orientation\" : break def get_hash ( paths ): # \u8fd4\u56de\u6587\u4ef6\u5217\u8868\u7684hash\u503c # Returns a single hash value of a list of paths (files or dirs) size = sum ( os . path . getsize ( p ) for p in paths if os . path . exists ( p )) # sizes h = hashlib . md5 ( str ( size ) . encode ()) # hash sizes h . update ( \"\" . join ( paths ) . encode ()) # hash paths return h . hexdigest () # return hash def exif_size ( img ): # \u83b7\u53d6\u6570\u7801\u76f8\u673a\u7684\u56fe\u7247\u5bbd\u9ad8\u4fe1\u606f \u5e76\u4e14\u5224\u65ad\u662f\u5426\u9700\u8981\u65cb\u8f6c\uff08\u6570\u7801\u76f8\u673a\u53ef\u4ee5\u591a\u89d2\u5ea6\u62cd\u6444\uff09 # Returns exif-corrected PIL size s = img . size # (width, height) with contextlib . suppress ( Exception ): rotation = dict ( img . _getexif () . items ())[ orientation ] if rotation in [ 6 , 8 ]: # rotation 270 or 90 s = ( s [ 1 ], s [ 0 ]) return s def exif_transpose ( image ): \"\"\" \u5982\u679c\u6709EXIF\u65b9\u5411\u6807\u8bb0\uff0c\u5219\u76f8\u5e94\u8c03\u6362PIL\u56fe\u50cf\u3002 Transpose a PIL image accordingly if it has an EXIF Orientation tag. Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose() :param image: The image to transpose. :return: An image. \"\"\" exif = image . getexif () orientation = exif . get ( 0x0112 , 1 ) # default 1 if orientation > 1 : method = { 2 : Image . FLIP_LEFT_RIGHT , 3 : Image . ROTATE_180 , 4 : Image . FLIP_TOP_BOTTOM , 5 : Image . TRANSPOSE , 6 : Image . ROTATE_270 , 7 : Image . TRANSVERSE , 8 : Image . ROTATE_90 , } . get ( orientation ) if method is not None : image = image . transpose ( method ) del exif [ 0x0112 ] image . info [ \"exif\" ] = exif . tobytes () return image def seed_worker ( worker_id ): # Set dataloader worker seed # https://oneflow.readthedocs.io/en/master/utils.data.html?highlight=randomness#platform-specific-behaviors worker_seed = flow . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) def create_dataloader ( path , # path: \u56fe\u7247\u6570\u636e\u52a0\u8f7d\u8def\u5f84 train/test \u5982: ../datasets/coco/images/train2017 imgsz , # train/test\u56fe\u7247\u5c3a\u5bf8\uff08\u6570\u636e\u589e\u5f3a\u540e\u5927\u5c0f\uff09 640 batch_size , # batch size \u5927\u5c0f 8/16/32 stride , # \u6a21\u578b\u6700\u5927stride=32 [32 16 8] single_cls = False , # \u6570\u636e\u96c6\u662f\u5426\u662f\u5355\u7c7b\u522b \u9ed8\u8ba4False hyp = None , # \u8d85\u53c2\u5217\u8868dict \u7f51\u7edc\u8bad\u7ec3\u65f6\u7684\u4e00\u4e9b\u8d85\u53c2\u6570\uff0c\u5305\u62ec\u5b66\u4e60\u7387\u7b49\uff0c\u8fd9\u91cc\u4e3b\u8981\u7528\u5230\u91cc\u9762\u4e00\u4e9b\u5173\u4e8e\u6570\u636e\u589e\u5f3a(\u65cb\u8f6c\u3001\u5e73\u79fb\u7b49)\u7684\u7cfb\u6570 augment = False , # \u662f\u5426\u8981\u8fdb\u884c\u6570\u636e\u589e\u5f3a True cache = False , # \u662f\u5426cache_images False pad = 0.0 , # \u8bbe\u7f6e\u77e9\u5f62\u8bad\u7ec3\u7684shape\u65f6\u8fdb\u884c\u7684\u586b\u5145 \u9ed8\u8ba40.0 rect = False , # \u662f\u5426\u5f00\u542f\u77e9\u5f62train/test \u9ed8\u8ba4\u8bad\u7ec3\u96c6\u5173\u95ed \u9a8c\u8bc1\u96c6\u5f00\u542f rank =- 1 , # \u591a\u5361\u8bad\u7ec3\u65f6\u7684\u8fdb\u7a0b\u7f16\u53f7 rank\u4e3a\u8fdb\u7a0b\u7f16\u53f7 -1\u4e14gpu=1\u65f6\u4e0d\u8fdb\u884c\u5206\u5e03\u5f0f -1\u4e14\u591a\u5757gpu\u4f7f\u7528DataParallel\u6a21\u5f0f \u9ed8\u8ba4-1 workers = 8 , # dataloader\u7684num_works \u52a0\u8f7d\u6570\u636e\u65f6\u7684cpu\u8fdb\u7a0b\u6570 image_weights = False , # \u8bad\u7ec3\u65f6\u662f\u5426\u6839\u636e\u56fe\u7247\u6837\u672c\u771f\u5b9e\u6846\u5206\u5e03\u6743\u91cd\u6765\u9009\u62e9\u56fe\u7247 \u9ed8\u8ba4False quad = False , # dataloader\u53d6\u6570\u636e\u65f6, \u662f\u5426\u4f7f\u7528collate_fn4\u4ee3\u66ffcollate_fn \u9ed8\u8ba4False prefix = \"\" , # \u663e\u793a\u4fe1\u606f \u4e00\u4e2a\u6807\u5fd7\uff0c\u591a\u4e3atrain/val\uff0c\u5904\u7406\u6807\u7b7e\u65f6\u4fdd\u5b58cache\u6587\u4ef6\u4f1a\u7528\u5230 shuffle = False , # \u5bf9\u8bad\u7ec3\u6570\u636e\u662f\u5426\u968f\u673a\u6253\u4e71\u3002 ): \"\"\"\u5728train.py\u4e2d\u88ab\u8c03\u7528\uff0c\u7528\u4e8e\u751f\u6210Trainloader, dataset\uff0ctestloader \u81ea\u5b9a\u4e49dataloader\u51fd\u6570: \u8c03\u7528LoadImagesAndLabels\u83b7\u53d6\u6570\u636e\u96c6(\u5305\u62ec\u6570\u636e\u589e\u5f3a) + \u8c03\u7528\u5206\u5e03\u5f0f\u91c7\u6837\u5668DistributedSampler + \u81ea\u5b9a\u4e49InfiniteDataLoader \u8fdb\u884c\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e \"\"\" if rect and shuffle : LOGGER . warning ( \"WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\" ) shuffle = False # \u8f7d\u5165\u6587\u4ef6\u6570\u636e(\u589e\u5f3a\u6570\u636e\u96c6) dataset = LoadImagesAndLabels ( path , imgsz , batch_size , augment = augment , # augmentation hyp = hyp , # hyperparameters rect = rect , # rectangular batches cache_images = cache , single_cls = single_cls , stride = int ( stride ), pad = pad , image_weights = image_weights , prefix = prefix , ) batch_size = min ( batch_size , len ( dataset )) nd = flow . cuda . device_count () # number of CUDA devices nw = min ([ os . cpu_count () // max ( nd , 1 ), batch_size if batch_size > 1 else 0 , workers ]) # number of workers # \u5206\u5e03\u5f0f\u91c7\u6837\u5668DistributedSampler sampler = None if rank == - 1 else distributed . DistributedSampler ( dataset , shuffle = shuffle ) # \u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u6765\u5bf9DataLoader\u8fdb\u884c\u5c01\u88c5, \u4ee3\u66ff\u539f\u5148\u7684DataLoader, \u80fd\u591f\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e loader = DataLoader if image_weights else InfiniteDataLoader # only DataLoader allows for attribute updates # \u968f\u673a\u6570\u751f\u6210\u5668 https://oneflow.readthedocs.io/en/master/generated/oneflow.randint.html?highlight=flow.Generator#oneflow.randint generator = flow . Generator () generator . manual_seed ( 6148914691236517205 + RANK ) return ( loader ( dataset , batch_size = batch_size , shuffle = shuffle and sampler is None , num_workers = nw , sampler = sampler , pin_memory = True , collate_fn = LoadImagesAndLabels . collate_fn4 if quad else LoadImagesAndLabels . collate_fn , worker_init_fn = seed_worker , generator = generator , ), dataset , ) 3.\u81ea\u5b9a\u4e49DataLoader \u2003\u5f53image_weights=False\u65f6\uff08\u4e0d\u6839\u636e\u56fe\u7247\u6837\u672c\u771f\u5b9e\u6846\u5206\u5e03\u6743\u91cd\u6765\u9009\u62e9\u56fe\u7247\uff09\u5c31\u4f1a\u8c03\u7528\u8fd9\u4e24\u4e2a\u51fd\u6570 \u8fdb\u884c\u81ea\u5b9a\u4e49DataLoader\uff0c\u8fdb\u884c\u6301\u7eed\u6027\u91c7\u6837\u3002\u5728\u4e0a\u9762\u7684create_dataloade\u51fd\u6570\u4e2d\u88ab\u8c03\u7528\u3002 class InfiniteDataLoader ( dataloader . DataLoader ): \"\"\"Dataloader that reuses workers \u5f53image_weights=False\u65f6\u5c31\u4f1a\u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u8fd9\u4e24\u4e2a\u7c7b\u5b9e\u73b0\u81ea\u5b9a\u4e49DataLoader \u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u6765\u5bf9DataLoader\u8fdb\u884c\u5c01\u88c5, \u4ee3\u66ff\u539f\u5148\u7684DataLoader, \u80fd\u591f\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e Uses same syntax as vanilla DataLoader \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) # \u8c03\u7528_RepeatSampler\u8fdb\u884c\u6301\u7eed\u91c7\u6837 object . __setattr__ ( self , \"batch_sampler\" , _RepeatSampler ( self . batch_sampler )) self . iterator = super () . __iter__ () def __len__ ( self ): return len ( self . batch_sampler . sampler ) def __iter__ ( self ): for _ in range ( len ( self )): yield next ( self . iterator ) class _RepeatSampler : \"\"\"Sampler that repeats forever \u8fd9\u90e8\u5206\u662f\u8fdb\u884c\u6301\u7eed\u91c7\u6837 Args: sampler (Sampler) \"\"\" def __init__ ( self , sampler ): self . sampler = sampler def __iter__ ( self ): while True : yield from iter ( self . sampler ) 4. LoadImagesAndLabels \u2003\u8fd9\u4e2a\u90e8\u5206\u662f\u6570\u636e\u8f7d\u5165\uff08\u6570\u636e\u589e\u5f3a\uff09\u90e8\u5206\uff0c \u4e5f\u5c31\u662f\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u90e8\u5206\uff0c\u7ee7\u627f\u81eaDataset\uff0c\u9700\u8981\u91cd\u5199__init__,__getitem()__\u7b49\u62bd\u8c61\u65b9\u6cd5\uff0c \u53e6\u5916\u76ee\u6807\u68c0\u6d4b\u4e00\u822c\u8fd8\u9700\u8981\u91cd\u5199collate_fn\u51fd\u6570\u3002\u6240\u4ee5\uff0c\u7406\u89e3\u8fd9\u4e09\u4e2a\u51fd\u6570\u662f\u7406\u89e3\u6570\u636e\u589e\u5f3a\uff08\u6570\u636e\u8f7d\u5165\uff09\u7684\u91cd\u4e2d\u4e4b\u91cd\u3002 4.1 init \u8fd9\u4e2a\u51fd\u6570\u7684\u5165\u53e3\u662f\u4e0a\u9762\u7684create_dataloader\u51fd\u6570\uff1a init \u4e3b\u8981\u5e72\u4e86\u4e00\u4e0b\u51e0\u4ef6\u4e8b\uff1a \u8d4b\u503c\u4e00\u4e9b\u57fa\u7840\u7684self\u53d8\u91cf \u7528\u4e8e\u540e\u9762\u5728__getitem__\u4e2d\u8c03\u7528 \u5f97\u5230path\u8def\u5f84\u4e0b\u7684\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84self.img_files \u6839\u636eimgs\u8def\u5f84\u627e\u5230labels\u7684\u8def\u5f84self.label_files cache label Read cache \u751f\u6210self.labels\u3001self.shapes\u3001self.img_files\u3001self.label_files\u3001self.batch\u3001self.n\u3001self.indices\u7b49\u53d8\u91cf \u4e3aRectangular Training\u4f5c\u51c6\u5907: \u751f\u6210self.batch_shapes \u662f\u5426\u9700\u8981cache image(\u4e00\u822c\u4e0d\u9700\u8981\uff0c\u592a\u5927\u4e86) __init__\u51fd\u6570\u4ee3\u7801\uff1a class LoadImagesAndLabels ( Dataset ): def __init__ ( self , path , img_size = 640 , batch_size = 16 , augment = False , hyp = None , rect = False , image_weights = False , cache_images = False , single_cls = False , stride = 32 , pad = 0.0 , prefix = \"\" , ): \"\"\" \u521d\u59cb\u5316\u8fc7\u7a0b\u5e76\u6ca1\u6709\u4ec0\u4e48\u5b9e\u8d28\u6027\u7684\u64cd\u4f5c,\u66f4\u591a\u662f\u4e00\u4e2a\u5b9a\u4e49\u53c2\u6570\u7684\u8fc7\u7a0b\uff08self\u53c2\u6570\uff09,\u4ee5\u4fbf\u5728__getitem()__\u4e2d\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u64cd\u4f5c,\u6240\u4ee5\u8fd9\u90e8\u5206\u4ee3\u7801\u53ea\u9700\u8981\u6293\u4f4fself\u4e2d\u7684\u5404\u4e2a\u53d8\u91cf\u7684\u542b\u4e49\u5c31\u7b97\u5dee\u4e0d\u591a\u4e86 self.img_files: {list: N} \u5b58\u653e\u7740\u6574\u4e2a\u6570\u636e\u96c6\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84 self.label_files: {list: N} \u5b58\u653e\u7740\u6574\u4e2a\u6570\u636e\u96c6\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84 cache label -> verify_image_label self.labels: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label labels\u5b58\u50a8\u7684label\u5c31\u90fd\u662f\u539f\u59cblabel(\u90fd\u662f\u6b63\u5e38\u7684\u77e9\u5f62label) \u5426\u5219\u5c06\u6240\u6709\u56fe\u7247\u6b63\u5e38gt\u7684label\u5b58\u5165labels \u4e0d\u6b63\u5e38gt(\u5b58\u5728\u4e00\u4e2a\u591a\u8fb9\u5f62)\u7ecf\u8fc7segments2boxes\u8f6c\u6362\u4e3a\u6b63\u5e38\u7684\u77e9\u5f62label self.shapes: \u6240\u6709\u56fe\u7247\u7684shape self.segments: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label self.segments=None \u5426\u5219\u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u6240\u6709\u5b58\u5728\u591a\u8fb9\u5f62gt\u7684\u56fe\u7247\u7684\u6240\u6709\u539f\u59cblabel(\u80af\u5b9a\u6709\u591a\u8fb9\u5f62label \u4e5f\u53ef\u80fd\u6709\u77e9\u5f62\u6b63\u5e38label \u672a\u77e5\u6570) self.batch: \u8bb0\u8f7d\u7740\u6bcf\u5f20\u56fe\u7247\u5c5e\u4e8e\u54ea\u4e2abatch self.n: \u6570\u636e\u96c6\u4e2d\u6240\u6709\u56fe\u7247\u7684\u6570\u91cf self.indices: \u8bb0\u8f7d\u7740\u6240\u6709\u56fe\u7247\u7684index self.rect=True\u65f6self.batch_shapes\u8bb0\u8f7d\u6bcf\u4e2abatch\u7684shape(\u540c\u4e00\u4e2abatch\u7684\u56fe\u7247shape\u76f8\u540c) \"\"\" # 1\u3001\u8d4b\u503c\u4e00\u4e9b\u57fa\u7840\u7684self\u53d8\u91cf \u7528\u4e8e\u540e\u9762\u5728__getitem__\u4e2d\u8c03\u7528 self . img_size = img_size # \u7ecf\u8fc7\u6570\u636e\u589e\u5f3a\u540e\u7684\u6570\u636e\u56fe\u7247\u7684\u5927\u5c0f self . augment = augment # \u662f\u5426\u542f\u52a8\u6570\u636e\u589e\u5f3a \u4e00\u822c\u8bad\u7ec3\u65f6\u6253\u5f00 \u9a8c\u8bc1\u65f6\u5173\u95ed self . hyp = hyp # \u8d85\u53c2\u5217\u8868 # \u56fe\u7247\u6309\u6743\u91cd\u91c7\u6837 True\u5c31\u53ef\u4ee5\u6839\u636e\u7c7b\u522b\u9891\u7387(\u9891\u7387\u9ad8\u7684\u6743\u91cd\u5c0f,\u53cd\u6b63\u5927)\u6765\u8fdb\u884c\u91c7\u6837 \u9ed8\u8ba4False: \u4e0d\u4f5c\u7c7b\u522b\u533a\u5206 self . image_weights = image_weights self . rect = False if image_weights else rect # \u662f\u5426\u542f\u52a8\u77e9\u5f62\u8bad\u7ec3 \u4e00\u822c\u8bad\u7ec3\u65f6\u5173\u95ed \u9a8c\u8bc1\u65f6\u6253\u5f00 \u53ef\u4ee5\u52a0\u901f self . mosaic = self . augment and not self . rect # load 4 images at a time into a mosaic (only during training) # mosaic\u589e\u5f3a\u7684\u8fb9\u754c\u503c [-320, -320] self . mosaic_border = [ - img_size // 2 , - img_size // 2 ] self . stride = stride # \u6700\u5927\u4e0b\u91c7\u6837\u7387 32 self . path = path # \u56fe\u7247\u8def\u5f84 self . albumentations = Albumentations () if augment else None # 2\u3001\u5f97\u5230path\u8def\u5f84\u4e0b\u7684\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84self.img_files \u8fd9\u91cc\u9700\u8981\u81ea\u5df1debug\u4e00\u4e0b \u4e0d\u4f1a\u592a\u96be try : f = [] # image files for p in path if isinstance ( path , list ) else [ path ]: # \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84path\uff0c\u5305\u542b\u56fe\u7247\u8def\u5f84\u7684txt\u6587\u4ef6\u6216\u8005\u5305\u542b\u56fe\u7247\u7684\u6587\u4ef6\u5939\u8def\u5f84 # \u4f7f\u7528pathlib.Path\u751f\u6210\u4e0e\u64cd\u4f5c\u7cfb\u7edf\u65e0\u5173\u7684\u8def\u5f84\uff0c\u56e0\u4e3a\u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf\u8def\u5f84\u7684\u2018/\u2019\u4f1a\u6709\u6240\u4e0d\u540c p = Path ( p ) # os-agnostic # \u5982\u679c\u8def\u5f84path\u4e3a\u5305\u542b\u56fe\u7247\u7684\u6587\u4ef6\u5939\u8def\u5f84 if p . is_dir (): # dir # glob.glab: \u8fd4\u56de\u6240\u6709\u5339\u914d\u7684\u6587\u4ef6\u8def\u5f84\u5217\u8868 \u9012\u5f52\u83b7\u53d6p\u8def\u5f84\u4e0b\u6240\u6709\u6587\u4ef6 f += glob . glob ( str ( p / '**' / '*.*' ), recursive = True ) # f = list(p.rglob('**/*.*')) # pathlib # \u5982\u679c\u8def\u5f84path\u4e3a\u5305\u542b\u56fe\u7247\u8def\u5f84\u7684txt\u6587\u4ef6 elif p . is_file (): # file with open ( p , 'r' ) as t : t = t . read () . strip () . splitlines () # \u83b7\u53d6\u56fe\u7247\u8def\u5f84\uff0c\u66f4\u6362\u76f8\u5bf9\u8def\u5f84 # \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84\u7684\u4e0a\u7ea7\u7236\u76ee\u5f55 os.sep\u4e3a\u8def\u5f84\u91cc\u7684\u5206\u9694\u7b26\uff08\u4e0d\u540c\u8def\u5f84\u7684\u5206\u9694\u7b26\u4e0d\u540c\uff0cos.sep\u53ef\u4ee5\u6839\u636e\u7cfb\u7edf\u81ea\u9002\u5e94\uff09 parent = str ( p . parent ) + os . sep f += [ x . replace ( './' , parent ) if x . startswith ( './' ) else x for x in t ] # local to global path # f += [p.parent / x.lstrip(os.sep) for x in t] # local to global path (pathlib) else : raise Exception ( f ' { prefix }{ p } does not exist' ) # \u7834\u6298\u53f7\u66ff\u6362\u4e3aos.sep\uff0cos.path.splitext(x)\u5c06\u6587\u4ef6\u540d\u4e0e\u6269\u5c55\u540d\u5206\u5f00\u5e76\u8fd4\u56de\u4e00\u4e2a\u5217\u8868 # \u7b5b\u9009f\u4e2d\u6240\u6709\u7684\u56fe\u7247\u6587\u4ef6 self . im_files = sorted ( x . replace ( \"/\" , os . sep ) for x in f if x . split ( \".\" )[ - 1 ] . lower () in IMG_FORMATS ) # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS]) # pathlib assert self . im_files , f \" { prefix } No images found\" except Exception as e : raise Exception ( f \" { prefix } Error loading data from { path } : { e } \\n See { HELP_URL } \" ) # Check cache 3\u6839\u636eimgs\u8def\u5f84\u627e\u5230labels\u7684\u8def\u5f84self.label_files self . label_files = img2label_paths ( self . im_files ) # labels # 4\u3001cache label \u4e0b\u6b21\u8fd0\u884c\u8fd9\u4e2a\u811a\u672c\u7684\u65f6\u5019\u76f4\u63a5\u4ececache\u4e2d\u53d6label\u800c\u4e0d\u662f\u53bb\u6587\u4ef6\u4e2d\u53d6label \u901f\u5ea6\u66f4\u5feb cache_path = ( p if p . is_file () else Path ( self . label_files [ 0 ]) . parent ) . with_suffix ( \".cache\" ) try : # \u5982\u679c\u6709cache\u6587\u4ef6\uff0c\u76f4\u63a5\u52a0\u8f7d exists=True: \u662f\u5426\u5df2\u4ececache\u6587\u4ef6\u4e2d\u8bfb\u51fa\u4e86nf, nm, ne, nc, n\u7b49\u4fe1\u606f cache , exists = np . load ( cache_path , allow_pickle = True ) . item (), True # load dict assert cache [ \"version\" ] == self . cache_version # matches current version assert cache [ \"hash\" ] == get_hash ( self . label_files + self . im_files ) # identical hash except Exception : # \u5982\u679c\u56fe\u7247\u7248\u672c\u4fe1\u606f\u6216\u8005\u6587\u4ef6\u5217\u8868\u7684hash\u503c\u5bf9\u4e0d\u4e0a\u53f7 \u8bf4\u660e\u672c\u5730\u6570\u636e\u96c6\u56fe\u7247\u548clabel\u53ef\u80fd\u53d1\u751f\u4e86\u53d8\u5316 \u5c31\u91cd\u65b0cache label\u6587\u4ef6 cache , exists = self . cache_labels ( cache_path , prefix ), False # run cache ops # Display cache # \u6253\u5370cache\u7684\u7ed3\u679c nf nm ne nc n = \u627e\u5230\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u6f0f\u6389\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u7a7a\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u635f\u574f\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u603b\u7684\u6807\u7b7e\u6570\u91cf nf , nm , ne , nc , n = cache . pop ( \"results\" ) # found, missing, empty, corrupt, total # \u5982\u679c\u5df2\u7ecf\u4ececache\u6587\u4ef6\u8bfb\u51fa\u4e86nf nm ne nc n\u7b49\u4fe1\u606f\uff0c\u76f4\u63a5\u663e\u793a\u6807\u7b7e\u4fe1\u606f msgs\u4fe1\u606f\u7b49 if exists and LOCAL_RANK in { - 1 , 0 }: d = f \"Scanning ' { cache_path } ' images and labels... { nf } found, { nm } missing, { ne } empty, { nc } corrupt\" tqdm ( None , desc = prefix + d , total = n , initial = n , bar_format = BAR_FORMAT ) # display cache results if cache [ \"msgs\" ]: LOGGER . info ( \" \\n \" . join ( cache [ \"msgs\" ])) # display warnings # \u6570\u636e\u96c6\u6ca1\u6709\u6807\u7b7e\u4fe1\u606f \u5c31\u53d1\u51fa\u8b66\u544a\u5e76\u663e\u793a\u6807\u7b7elabel\u4e0b\u8f7d\u5730\u5740help_url assert nf > 0 or not augment , f \" { prefix } No labels in { cache_path } . Can not train without labels. See { HELP_URL } \" # 5\u3001Read cache \u4ececache\u4e2d\u8bfb\u51fa\u6700\u65b0\u53d8\u91cf\u8d4b\u7ed9self \u65b9\u4fbf\u7ed9forward\u4e2d\u4f7f\u7528 # cache\u4e2d\u7684\u952e\u503c\u5bf9\u6700\u521d\u6709: cache[img_file]=[l, shape, segments] cache[hash] cache[results] cache[msg] cache[version] # \u5148\u4ececache\u4e2d\u53bb\u9664cache\u6587\u4ef6\u4e2d\u5176\u4ed6\u65e0\u5173\u952e\u503c\u5982:'hash', 'version', 'msgs'\u7b49\u90fd\u5220\u9664 [ cache . pop ( k ) for k in ( 'hash' , 'version' , 'msgs' )] # remove items # pop\u6389results\u3001hash\u3001version\u3001msgs\u540e\u53ea\u5269\u4e0bcache[img_file]=[l, shape, segments] # cache.values(): \u53d6cache\u4e2d\u6240\u6709\u503c \u5bf9\u5e94\u6240\u6709l, shape, segments # labels: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label labels\u5b58\u50a8\u7684label\u5c31\u90fd\u662f\u539f\u59cblabel(\u90fd\u662f\u6b63\u5e38\u7684\u77e9\u5f62label) # \u5426\u5219\u5c06\u6240\u6709\u56fe\u7247\u6b63\u5e38gt\u7684label\u5b58\u5165labels \u4e0d\u6b63\u5e38gt(\u5b58\u5728\u4e00\u4e2a\u591a\u8fb9\u5f62)\u7ecf\u8fc7segments2boxes\u8f6c\u6362\u4e3a\u6b63\u5e38\u7684\u77e9\u5f62label # shapes: \u6240\u6709\u56fe\u7247\u7684shape # self.segments: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label self.segments=None # \u5426\u5219\u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u6240\u6709\u5b58\u5728\u591a\u8fb9\u5f62gt\u7684\u56fe\u7247\u7684\u6240\u6709\u539f\u59cblabel(\u80af\u5b9a\u6709\u591a\u8fb9\u5f62label \u4e5f\u53ef\u80fd\u6709\u77e9\u5f62\u6b63\u5e38label \u672a\u77e5\u6570) # zip \u662f\u56e0\u4e3acache\u4e2d\u6240\u6709labels\u3001shapes\u3001segments\u4fe1\u606f\u90fd\u662f\u6309\u6bcf\u5f20img\u5206\u5f00\u5b58\u50a8\u7684, zip\u662f\u5c06\u6240\u6709\u56fe\u7247\u5bf9\u5e94\u7684\u4fe1\u606f\u53e0\u5728\u4e00\u8d77 labels , shapes , self . segments = zip ( * cache . values ()) # segments: \u90fd\u662f[] self . labels = list ( labels ) self . shapes = np . array ( shapes ) self . im_files = list ( cache . keys ()) # update self . label_files = img2label_paths ( cache . keys ()) # update \u66f4\u65b0\u6240\u6709\u56fe\u7247\u7684label_files\u4fe1\u606f(\u56e0\u4e3aimg_files\u4fe1\u606f\u53ef\u80fd\u53d1\u751f\u4e86\u53d8\u5316) n = len ( shapes ) # number of images bi = np . floor ( np . arange ( n ) / batch_size ) . astype ( np . int ) # batch index nb = bi [ - 1 ] + 1 # number of batches self . batch = bi # batch index of image \u6240\u6709\u56fe\u7247\u7684index self . n = n self . indices = range ( n ) # Update labels include_class = [] # filter labels to include only these classes (optional) include_class_array = np . array ( include_class ) . reshape ( 1 , - 1 ) for i , ( label , segment ) in enumerate ( zip ( self . labels , self . segments )): if include_class : j = ( label [:, 0 : 1 ] == include_class_array ) . any ( 1 ) self . labels [ i ] = label [ j ] if segment : self . segments [ i ] = segment [ j ] if single_cls : # single-class training, merge all classes into 0 self . labels [ i ][:, 0 ] = 0 if segment : self . segments [ i ][:, 0 ] = 0 # Rectangular Training # 6\u3001\u4e3aRectangular Training\u4f5c\u51c6\u5907 # \u8fd9\u91cc\u4e3b\u8981\u662f\u6ce8\u610fshapes\u7684\u751f\u6210 \u8fd9\u4e00\u6b65\u5f88\u91cd\u8981 \u56e0\u4e3a\u5982\u679c\u91c7\u6837\u77e9\u5f62\u8bad\u7ec3\u90a3\u4e48\u6574\u4e2abatch\u7684\u5f62\u72b6\u8981\u4e00\u6837 \u5c31\u8981\u8ba1\u7b97\u8fd9\u4e2a\u7b26\u5408\u6574\u4e2abatch\u7684shape # \u800c\u4e14\u8fd8\u8981\u5bf9\u6570\u636e\u96c6\u6309\u7167\u9ad8\u5bbd\u6bd4\u8fdb\u884c\u6392\u5e8f \u8fd9\u6837\u624d\u80fd\u4fdd\u8bc1\u540c\u4e00\u4e2abatch\u7684\u56fe\u7247\u7684\u5f62\u72b6\u5dee\u4e0d\u591a\u76f8\u540c \u518d\u9009\u5219\u4e00\u4e2a\u5171\u540c\u7684shape\u4ee3\u4ef7\u4e5f\u6bd4\u8f83\u5c0f if self . rect : # Sort by aspect ratio s = self . shapes # wh ar = s [:, 1 ] / s [:, 0 ] # aspect ratio irect = ar . argsort () # \u6839\u636e\u9ad8\u5bbd\u6bd4\u6392\u5e8f self . img_files = [ self . img_files [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684img_files self . label_files = [ self . label_files [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684label_files self . labels = [ self . labels [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684labels self . shapes = s [ irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684wh ar = ar [ irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684aspect ratio # \u8ba1\u7b97\u6bcf\u4e2abatch\u91c7\u7528\u7684\u7edf\u4e00\u5c3a\u5ea6 Set training image shapes shapes = [[ 1 , 1 ]] * nb # nb: number of batches for i in range ( nb ): ari = ar [ bi == i ] # bi: batch index mini , maxi = ari . min (), ari . max () # \u83b7\u53d6\u7b2ci\u4e2abatch\u4e2d\uff0c\u6700\u5c0f\u548c\u6700\u5927\u9ad8\u5bbd\u6bd4 # \u5982\u679c\u9ad8/\u5bbd\u5c0f\u4e8e1(w > h)\uff0c\u5c06w\u8bbe\u4e3aimg_size\uff08\u4fdd\u8bc1\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0d\u53d8\u8fdb\u884c\u7f29\u653e\uff09 if maxi < 1 : shapes [ i ] = [ maxi , 1 ] # maxi: h\u76f8\u5bf9\u6307\u5b9a\u5c3a\u5ea6\u7684\u6bd4\u4f8b 1: w\u76f8\u5bf9\u6307\u5b9a\u5c3a\u5ea6\u7684\u6bd4\u4f8b # \u5982\u679c\u9ad8/\u5bbd\u5927\u4e8e1(w < h)\uff0c\u5c06h\u8bbe\u7f6e\u4e3aimg_size\uff08\u4fdd\u8bc1\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0d\u53d8\u8fdb\u884c\u7f29\u653e\uff09 elif mini > 1 : shapes [ i ] = [ 1 , 1 / mini ] # \u8ba1\u7b97\u6bcf\u4e2abatch\u8f93\u5165\u7f51\u7edc\u7684shape\u503c(\u5411\u4e0a\u8bbe\u7f6e\u4e3a32\u7684\u6574\u6570\u500d) # \u8981\u6c42\u6bcf\u4e2abatch_shapes\u7684\u9ad8\u5bbd\u90fd\u662f32\u7684\u6574\u6570\u500d\uff0c\u6240\u4ee5\u8981\u5148\u9664\u4ee532\uff0c\u53d6\u6574\u518d\u4e58\u4ee532\uff08\u4e0d\u8fc7img_size\u5982\u679c\u662f32\u500d\u6570\u8fd9\u91cc\u5c31\u6ca1\u5fc5\u8981\u4e86\uff09 self . batch_shapes = np . ceil ( np . array ( shapes ) * img_size / stride + pad ) . astype ( np . int ) * stride # 7\u3001\u662f\u5426\u9700\u8981cache image \u4e00\u822c\u662fFalse \u56e0\u4e3aRAM\u4f1a\u4e0d\u8db3 cache label\u8fd8\u53ef\u4ee5 \u4f46\u662fcache image\u5c31\u592a\u5927\u4e86 \u6240\u4ee5\u4e00\u822c\u4e0d\u7528 # Cache images into RAM/disk for faster training (WARNING: large datasets may exceed system resources) self . ims = [ None ] * n self . npy_files = [ Path ( f ) . with_suffix ( \".npy\" ) for f in self . im_files ] if cache_images : gb = 0 # Gigabytes of cached images self . im_hw0 , self . im_hw = [ None ] * n , [ None ] * n fcn = self . cache_images_to_disk if cache_images == \"disk\" else self . load_image results = ThreadPool ( NUM_THREADS ) . imap ( fcn , range ( n )) pbar = tqdm ( enumerate ( results ), total = n , bar_format = BAR_FORMAT , disable = LOCAL_RANK > 0 ) for i , x in pbar : if cache_images == \"disk\" : gb += self . npy_files [ i ] . stat () . st_size else : # 'ram' ( self . ims [ i ], self . im_hw0 [ i ], self . im_hw [ i ], ) = x # im, hw_orig, hw_resized = load_image(self, i) gb += self . ims [ i ] . nbytes pbar . desc = f \" { prefix } Caching images ( { gb / 1E9 : .1f } GB { cache_images } )\" pbar . close () 4.2 cache_labels \u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u52a0\u8f7d\u6587\u4ef6\u8def\u5f84\u4e2d\u7684label\u4fe1\u606f\u751f\u6210cache\u6587\u4ef6\u3002cache\u6587\u4ef6\u4e2d\u5305\u62ec\u7684\u4fe1\u606f\u6709\uff1aim_file, l, shape, segments, hash, results, msgs, version\u7b49\uff0c\u5177\u4f53\u770b\u4ee3\u7801\u6ce8\u91ca\u3002 def cache_labels ( self , path = Path ( './labels.cache' ), prefix = '' ): \"\"\"\u7528\u5728__init__\u51fd\u6570\u4e2d cache\u6570\u636e\u96c6label \u52a0\u8f7dlabel\u4fe1\u606f\u751f\u6210cache\u6587\u4ef6 Cache dataset labels, check images and read shapes :params path: cache\u6587\u4ef6\u4fdd\u5b58\u5730\u5740 :params prefix: \u65e5\u5fd7\u5934\u90e8\u4fe1\u606f(\u5f69\u6253\u9ad8\u4eae\u90e8\u5206) :return x: cache\u4e2d\u4fdd\u5b58\u7684\u5b57\u5178 \u5305\u62ec\u7684\u4fe1\u606f\u6709: x[im_file] = [l, shape, segments] \u4e00\u5f20\u56fe\u7247\u4e00\u4e2alabel\u76f8\u5bf9\u5e94\u7684\u4fdd\u5b58\u5230x, \u6700\u7ec8x\u4f1a\u4fdd\u5b58\u6240\u6709\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84\u3001gt\u6846\u7684\u4fe1\u606f\u3001\u5f62\u72b6shape\u3001\u6240\u6709\u7684\u591a\u8fb9\u5f62gt\u4fe1\u606f im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 l: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, cls+xywh(normalized)] shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape segments: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u6240\u6709gt\u7684label\u4fe1\u606f(\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] hash: \u5f53\u524d\u56fe\u7247\u548clabel\u6587\u4ef6\u7684hash\u503c 1 results: \u627e\u5230\u7684label\u4e2a\u6570nf, \u4e22\u5931label\u4e2a\u6570nm, \u7a7alabel\u4e2a\u6570ne, \u7834\u635flabel\u4e2a\u6570nc, \u603bimg/label\u4e2a\u6570len(self.img_files) msgs: \u6240\u6709\u6570\u636e\u96c6\u7684msgs\u4fe1\u606f version: \u5f53\u524dcache version \"\"\" x = {} # \u521d\u59cb\u5316\u6700\u7ec8cache\u4e2d\u4fdd\u5b58\u7684\u5b57\u5178dict # \u521d\u59cb\u5316number missing, found, empty, corrupt, messages # \u521d\u59cb\u5316\u6574\u4e2a\u6570\u636e\u96c6: \u6f0f\u6389\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u627e\u5230\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u7a7a\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u9519\u8bef\u6807\u7b7e(label)\u603b\u6570\u91cf, \u6240\u6709\u9519\u8bef\u4fe1\u606f nm , nf , ne , nc , msgs = 0 , 0 , 0 , 0 , [] desc = f \" { prefix } Scanning ' { path . parent / path . stem } ' images and labels...\" # \u65e5\u5fd7 # \u591a\u8fdb\u7a0b\u8c03\u7528verify_image_label\u51fd\u6570 with Pool ( num_threads ) as pool : # \u5b9a\u4e49pbar\u8fdb\u5ea6\u6761 # pool.imap_unordered: \u5bf9\u5927\u91cf\u6570\u636e\u904d\u5386\u591a\u8fdb\u7a0b\u8ba1\u7b97 \u8fd4\u56de\u4e00\u4e2a\u8fed\u4ee3\u5668 # \u628aself.img_files, self.label_files, repeat(prefix) list\u4e2d\u7684\u503c\u4f5c\u4e3a\u53c2\u6570\u4f9d\u6b21\u9001\u5165(\u4e00\u6b21\u9001\u4e00\u4e2a)verify_image_label\u51fd\u6570 pbar = tqdm ( pool . imap_unordered ( verify_image_label , zip ( self . img_files , self . label_files , repeat ( prefix ))), desc = desc , total = len ( self . img_files )) # im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 # l: [gt_num, cls+xywh(normalized)] # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u539flabel(\u5168\u90e8\u662f\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e) # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u7ecf\u8fc7segments2boxes\u5904\u7406\u597d\u7684\u6807\u7b7e(\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e\u4e0d\u5904\u7406 \u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u77e9\u5f62\u6807\u7b7e) # shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape # segments: \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5b58\u50a8None # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5c31\u628a\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709label\u5b58\u50a8\u5230segments\u4e2d(\u82e5\u5e72\u4e2a\u6b63\u5e38gt \u82e5\u5e72\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] # nm_f(nm): number missing \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u4e22\u5931 \u4e22\u5931=1 \u5b58\u5728=0 # nf_f(nf): number found \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u5b58\u5728 \u5b58\u5728=1 \u4e22\u5931=0 # ne_f(ne): number empty \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u662f\u7a7a\u7684 \u7a7a\u7684=1 \u6ca1\u7a7a=0 # nc_f(nc): number corrupt \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u6587\u4ef6\u662f\u5426\u662f\u7834\u635f\u7684 \u7834\u635f\u7684=1 \u6ca1\u7834\u635f=0 # msg: \u8fd4\u56de\u7684msg\u4fe1\u606f label\u6587\u4ef6\u5b8c\u597d=\u2018\u2019 label\u6587\u4ef6\u7834\u635f=warning\u4fe1\u606f for im_file , l , shape , segments , nm_f , nf_f , ne_f , nc_f , msg in pbar : nm += nm_f # \u7d2f\u52a0\u603bnumber missing label nf += nf_f # \u7d2f\u52a0\u603bnumber found label ne += ne_f # \u7d2f\u52a0\u603bnumber empty label nc += nc_f # \u7d2f\u52a0\u603bnumber corrupt label if im_file : x [ im_file ] = [ l , shape , segments ] # \u4fe1\u606f\u5b58\u5165\u5b57\u5178 key=im_file value=[l, shape, segments] if msg : msgs . append ( msg ) # \u5c06msg\u52a0\u5165\u603bmsg pbar . desc = f \" { desc }{ nf } found, { nm } missing, { ne } empty, { nc } corrupted\" # \u65e5\u5fd7 pbar . close () # \u5173\u95ed\u8fdb\u5ea6\u6761 # \u65e5\u5fd7\u6253\u5370\u6240\u6709msg\u4fe1\u606f if msgs : logging . info ( ' \\n ' . join ( msgs )) # \u4e00\u5f20label\u90fd\u6ca1\u627e\u5230 \u65e5\u5fd7\u6253\u5370help_url\u4e0b\u8f7d\u5730\u5740 if nf == 0 : logging . info ( f ' { prefix } WARNING: No labels found in { path } . See { help_url } ' ) x [ 'hash' ] = get_hash ( self . label_files + self . img_files ) # \u5c06\u5f53\u524d\u56fe\u7247\u548clabel\u6587\u4ef6\u7684hash\u503c\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'results' ] = nf , nm , ne , nc , len ( self . img_files ) # \u5c06nf, nm, ne, nc, len(self.img_files)\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'msgs' ] = msgs # \u5c06\u6240\u6709\u6570\u636e\u96c6\u7684msgs\u4fe1\u606f\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'version' ] = 0.3 # \u5c06\u5f53\u524dcache version\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist try : torch . save ( x , path ) # save cache to path logging . info ( f ' { prefix } New cache created: { path } ' ) except Exception as e : logging . info ( f ' { prefix } WARNING: Cache directory { path . parent } is not writeable: { e } ' ) # path not writeable return x 4.3 getitem \u2003\u8fd9\u90e8\u5206\u662f\u6570\u636e\u589e\u5f3a\u51fd\u6570\uff0c\u4e00\u822c\u4e00\u6b21\u6027\u6267\u884cbatch_size\u6b21\u3002 def __getitem__ ( self , index ): \"\"\" \u8fd9\u90e8\u5206\u662f\u6570\u636e\u589e\u5f3a\u51fd\u6570\uff0c\u4e00\u822c\u4e00\u6b21\u6027\u6267\u884cbatch_size\u6b21\u3002 \u8bad\u7ec3 \u6570\u636e\u589e\u5f3a: mosaic(random_perspective) + hsv + \u4e0a\u4e0b\u5de6\u53f3\u7ffb\u8f6c \u6d4b\u8bd5 \u6570\u636e\u589e\u5f3a: letterbox :return torch.from_numpy(img): \u8fd9\u4e2aindex\u7684\u56fe\u7247\u6570\u636e(\u589e\u5f3a\u540e) [3, 640, 640] :return labels_out: \u8fd9\u4e2aindex\u56fe\u7247\u7684gt label [6, 6] = [gt_num, 0+class+xywh(normalized)] :return self.img_files[index]: \u8fd9\u4e2aindex\u56fe\u7247\u7684\u8def\u5f84\u5730\u5740 :return shapes: \u8fd9\u4e2abatch\u7684\u56fe\u7247\u7684shapes \u6d4b\u8bd5\u65f6(\u77e9\u5f62\u8bad\u7ec3)\u624d\u6709 \u9a8c\u8bc1\u65f6\u4e3aNone for COCO mAP rescaling \"\"\" # \u8fd9\u91cc\u53ef\u4ee5\u901a\u8fc7\u4e09\u79cd\u5f62\u5f0f\u83b7\u53d6\u8981\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u56fe\u7247index linear, shuffled, or image_weights index = self . indices [ index ] # linear, shuffled, or image_weights hyp = self . hyp # \u8d85\u53c2 \u5305\u542b\u4f17\u591a\u6570\u636e\u589e\u5f3a\u8d85\u53c2 mosaic = self . mosaic and random . random () < hyp [ \"mosaic\" ] # mosaic\u589e\u5f3a \u5bf9\u56fe\u50cf\u8fdb\u884c4\u5f20\u56fe\u62fc\u63a5\u8bad\u7ec3 \u4e00\u822c\u8bad\u7ec3\u65f6\u8fd0\u884c # mosaic + MixUp if mosaic : # Load mosaic img , labels = self . load_mosaic ( index ) shapes = None # MixUp augmentation if random . random () < hyp [ \"mixup\" ]: img , labels = mixup ( img , labels , * self . load_mosaic ( random . randint ( 0 , self . n - 1 ))) else : # Load image # \u8f7d\u5165\u56fe\u7247 \u8f7d\u5165\u56fe\u7247\u540e\u8fd8\u4f1a\u8fdb\u884c\u4e00\u6b21resize \u5c06\u5f53\u524d\u56fe\u7247\u7684\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u7684\u5927\u5c0f(512), \u8f83\u5c0f\u8fb9\u540c\u6bd4\u4f8b\u7f29\u653e # load image img=(343, 512, 3)=(h, w, c) (h0, w0)=(335, 500) numpy index=4 # img: resize\u540e\u7684\u56fe\u7247 (h0, w0): \u539f\u59cb\u56fe\u7247\u7684hw (h, w): resize\u540e\u7684\u56fe\u7247\u7684hw # \u8fd9\u4e00\u6b65\u662f\u5c06(335, 500, 3) resize-> (343, 512, 3) img , ( h0 , w0 ), ( h , w ) = self . load_image ( index ) # Letterbox # letterbox\u4e4b\u524d\u786e\u5b9a\u8fd9\u5f20\u5f53\u524d\u56fe\u7247letterbox\u4e4b\u540e\u7684shape # \u5982\u679c\u4e0d\u7528self.rect\u77e9\u5f62\u8bad\u7ec3shape\u5c31\u662fself.img_size # \u5982\u679c\u4f7f\u7528self.rect\u77e9\u5f62\u8bad\u7ec3shape\u5c31\u662f\u5f53\u524dbatch\u7684shape # \u56e0\u4e3a\u77e9\u5f62\u8bad\u7ec3\u7684\u8bdd\u6211\u4eec\u6574\u4e2abatch\u7684shape\u5fc5\u987b\u7edf\u4e00(\u5728__init__\u51fd\u6570\u7b2c6\u8282\u5185\u5bb9) shape = self . batch_shapes [ self . batch [ index ]] if self . rect else self . img_size # final letterboxed shape img , ratio , pad = letterbox ( img , shape , auto = False , scaleup = self . augment ) shapes = ( h0 , w0 ), (( h / h0 , w / w0 ), pad ) # for COCO mAP rescaling labels = self . labels [ index ] . copy () if labels . size : # normalized xywh to pixel xyxy format labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], ratio [ 0 ] * w , ratio [ 1 ] * h , padw = pad [ 0 ], padh = pad [ 1 ]) if self . augment : # random_perspective\u589e\u5f3a: \u968f\u673a\u5bf9\u56fe\u7247\u8fdb\u884c\u65cb\u8f6c\uff0c\u5e73\u79fb\uff0c\u7f29\u653e\uff0c\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362 img , labels = random_perspective ( img , labels , degrees = hyp [ \"degrees\" ], translate = hyp [ \"translate\" ], scale = hyp [ \"scale\" ], shear = hyp [ \"shear\" ], perspective = hyp [ \"perspective\" ], ) nl = len ( labels ) # number of labels if nl : labels [:, 1 : 5 ] = xyxy2xywhn ( labels [:, 1 : 5 ], w = img . shape [ 1 ], h = img . shape [ 0 ], clip = True , eps = 1e-3 ) if self . augment : # Albumentations img , labels = self . albumentations ( img , labels ) nl = len ( labels ) # update after albumentations # HSV color-space \u8272\u57df\u7a7a\u95f4\u589e\u5f3aAugment colorspace augment_hsv ( img , hgain = hyp [ \"hsv_h\" ], sgain = hyp [ \"hsv_s\" ], vgain = hyp [ \"hsv_v\" ]) # Flip up-down if random . random () < hyp [ \"flipud\" ]: img = np . flipud ( img ) if nl : labels [:, 2 ] = 1 - labels [:, 2 ] # Flip left-right \u968f\u673a\u5de6\u53f3\u7ffb\u8f6c if random . random () < hyp [ \"fliplr\" ]: img = np . fliplr ( img ) if nl : labels [:, 1 ] = 1 - labels [:, 1 ] # Cutouts # labels = cutout(img, labels, p=0.5) # nl = len(labels) # update after cutout # 6\u4e2a\u503c\u7684tensor \u521d\u59cb\u5316\u6807\u7b7e\u6846\u5bf9\u5e94\u7684\u56fe\u7247\u5e8f\u53f7, \u914d\u5408\u4e0b\u9762\u7684collate_fn\u4f7f\u7528 labels_out = flow . zeros (( nl , 6 )) if nl : labels_out [:, 1 :] = flow . from_numpy ( labels ) # Convert img = img . transpose (( 2 , 0 , 1 ))[:: - 1 ] # HWC to CHW, BGR to RGB img = np . ascontiguousarray ( img ) # img\u53d8\u6210\u5185\u5b58\u8fde\u7eed\u7684\u6570\u636e \u52a0\u5feb\u8fd0\u7b97 return flow . from_numpy ( img ), labels_out , self . im_files [ index ], shapes 4.4 collate_fn \u2003collate_fn \u4e00\u822c\u4e5f\u53ef\u4ee5\u53eb\u8c03\u6574\u51fd\u6570,\u5f88\u591a\u4eba\u4ee5\u4e3a\u5199\u5b8c init \u548c getitem \u51fd\u6570\u6570\u636e\u589e\u5f3a\u5c31\u505a\u5b8c\u4e86\uff0c\u6211\u4eec\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u786e\u5199\u5b8c\u8fd9\u4e24\u4e2a\u51fd\u6570\u5c31\u53ef\u4ee5\u4e86\uff0c\u56e0\u4e3a\u7cfb\u7edf\u4e2d\u662f\u7ed9\u6211\u4eec\u5199\u597d\u4e86\u4e00\u4e2acollate_fn\u51fd\u6570\u7684\uff0c\u4f46\u662f\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u6211\u4eec\u5374\u9700\u8981\u91cd\u5199collate_fn\u51fd\u6570\uff0c\u4e0b\u9762\u6211\u4f1a\u4ed4\u7ec6\u7684\u8bb2\u89e3\u8fd9\u6837\u505a\u7684\u539f\u56e0\uff08\u4ee3\u7801\u4e2d\u6ce8\u91ca\uff09\u3002 \u540c\u6837\u5728create_dataloader\u4e2d\u751f\u6210dataloader\u65f6\u8c03\u7528\uff1a @staticmethod def collate_fn4 ( batch ): \"\"\"\u540c\u6837\u5728create_dataloader\u4e2d\u751f\u6210dataloader\u65f6\u8c03\u7528\uff1a \u8fd9\u91cc\u662fyolo-v5\u4f5c\u8005\u5b9e\u9a8c\u6027\u7684\u4e00\u4e2a\u4ee3\u7801 quad-collate function \u5f53train.py\u7684opt\u53c2\u6570quad=True \u5219\u8c03\u7528collate_fn4\u4ee3\u66ffcollate_fn \u4f5c\u7528: \u5982\u4e4b\u524d\u7528collate_fn\u53ef\u4ee5\u8fd4\u56de\u56fe\u7247[16, 3, 640, 640] \u7ecf\u8fc7collate_fn4\u5219\u8fd4\u56de\u56fe\u7247[4, 3, 1280, 1280] \u5c064\u5f20mosaic\u56fe\u7247[1, 3, 640, 640]\u5408\u6210\u4e00\u5f20\u5927\u7684mosaic\u56fe\u7247[1, 3, 1280, 1280] \u5c06\u4e00\u4e2abatch\u7684\u56fe\u7247\u6bcf\u56db\u5f20\u5904\u7406, 0.5\u7684\u6982\u7387\u5c06\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5230\u4e00\u5f20\u5927\u56fe\u4e0a\u8bad\u7ec3, 0.5\u6982\u7387\u76f4\u63a5\u5c06\u67d0\u5f20\u56fe\u7247\u4e0a\u91c7\u6837\u4e24\u500d\u8bad\u7ec3 \"\"\" # img: \u6574\u4e2abatch\u7684\u56fe\u7247 [16, 3, 640, 640] # label: \u6574\u4e2abatch\u7684label\u6807\u7b7e [num_target, img_index+class_index+xywh(normalized)] # path: \u6574\u4e2abatch\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84 # shapes: (h0, w0), ((h / h0, w / w0), pad) for COCO mAP rescaling img , label , path , shapes = zip ( * batch ) # transposed n = len ( shapes ) // 4 # collate_fn4\u5904\u7406\u540e\u8fd9\u4e2abatch\u4e2d\u56fe\u7247\u7684\u4e2a\u6570 im4 , label4 , path4 , shapes4 = [], [], path [: n ], shapes [: n ] # \u521d\u59cb\u5316 ho = flow . tensor ([[ 0.0 , 0 , 0 , 1 , 0 , 0 ]]) wo = flow . tensor ([[ 0.0 , 0 , 1 , 0 , 0 , 0 ]]) s = flow . tensor ([[ 1 , 1 , 0.5 , 0.5 , 0.5 , 0.5 ]]) # scale for i in range ( n ): # zidane flow.zeros(16,3,720,1280) # BCHW i *= 4 # \u91c7\u6837 [0, 4, 8, 16] if random . random () < 0.5 : # \u968f\u673a\u6570\u5c0f\u4e8e0.5\u5c31\u76f4\u63a5\u5c06\u67d0\u5f20\u56fe\u7247\u4e0a\u91c7\u6837\u4e24\u500d\u8bad\u7ec3 im = F . interpolate ( img [ i ] . unsqueeze ( 0 ) . float (), scale_factor = 2.0 , mode = \"bilinear\" , align_corners = False ,)[ 0 ] . type ( img [ i ] . type ()) lb = label [ i ] else : # \u968f\u673a\u6570\u5927\u4e8e0.5\u5c31\u5c06\u56db\u5f20\u56fe\u7247(mosaic\u540e\u7684)\u62fc\u63a5\u5230\u4e00\u5f20\u5927\u56fe\u4e0a\u8bad\u7ec3 im = flow . cat ( ( flow . cat (( img [ i ], img [ i + 1 ]), 1 ), flow . cat (( img [ i + 2 ], img [ i + 3 ]), 1 ), ), 2 , ) lb = flow . cat (( label [ i ], label [ i + 1 ] + ho , label [ i + 2 ] + wo , label [ i + 3 ] + ho + wo ), 0 ) * s im4 . append ( im ) label4 . append ( lb ) # \u540e\u9762\u8fd4\u56de\u7684\u90e8\u5206\u548ccollate_fn\u5c31\u5dee\u4e0d\u591a\u4e86 \u539f\u56e0\u548c\u89e3\u91ca\u90fd\u5199\u5728\u4e0a\u4e00\u4e2a\u51fd\u6570\u4e86 \u81ea\u5df1debug\u770b\u4e00\u4e0b\u5427 for i , lb in enumerate ( label4 ): lb [:, 0 ] = i # add target image index for build_targets() return flow . stack ( im4 , 0 ), flow . cat ( label4 , 0 ), path4 , shapes4 5. img2label_paths \u2003\u8fd9\u4e2a\u6587\u4ef6\u662f\u6839\u636e\u6570\u636e\u96c6\u4e2d\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709labels\u5bf9\u5e94\u7684\u8def\u5f84\u3002 \u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__init__\u51fd\u6570\u4e2d\u3002 def img2label_paths ( img_paths ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__init__\u51fd\u6570\u4e2d \u6839\u636eimgs\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u5bf9\u5e94labels\u7684\u8def\u5f84 Define label paths as a function of image paths :params img_paths: {list: 50} \u6574\u4e2a\u6570\u636e\u96c6\u7684\u56fe\u7247\u76f8\u5bf9\u8def\u5f84 \u4f8b\u5982: '..\\\\datasets\\\\VOC\\\\images\\\\train2007\\\\000012.jpg' => '..\\\\datasets\\\\VOC\\\\labels\\\\train2007\\\\000012.jpg' \"\"\" # \u56e0\u4e3apython\u662f\u8de8\u5e73\u53f0\u7684,\u5728Windows\u4e0a,\u6587\u4ef6\u7684\u8def\u5f84\u5206\u9694\u7b26\u662f'\\',\u5728Linux\u4e0a\u662f'/' # \u4e3a\u4e86\u8ba9\u4ee3\u7801\u5728\u4e0d\u540c\u7684\u5e73\u53f0\u4e0a\u90fd\u80fd\u8fd0\u884c\uff0c\u90a3\u4e48\u8def\u5f84\u5e94\u8be5\u5199'\\'\u8fd8\u662f'/'\u5462\uff1f os.sep\u6839\u636e\u4f60\u6240\u5904\u7684\u5e73\u53f0, \u81ea\u52a8\u91c7\u7528\u76f8\u5e94\u7684\u5206\u9694\u7b26\u53f7 # sa: '\\\\images\\\\' sb: '\\\\labels\\\\' sa , sb = os . sep + 'images' + os . sep , os . sep + 'labels' + os . sep # /images/, /labels/ substrings # \u628aimg_paths\u4e2d\u6240\u4ee5\u56fe\u7247\u8def\u5f84\u4e2d\u7684images\u66ff\u6362\u4e3alabels return [ sb . join ( x . rsplit ( sa , 1 )) . rsplit ( '.' , 1 )[ 0 ] + '.txt' for x in img_paths ] 6. verify_image_label \u2003\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u68c0\u67e5\u6bcf\u4e00\u5f20\u56fe\u7247\u548c\u6bcf\u4e00\u5f20label\u6587\u4ef6\u662f\u5426\u5b8c\u597d\u3002 \u2003 \u56fe\u7247\u6587\u4ef6: \u68c0\u67e5\u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027 \u2003 label\u6587\u4ef6: \u68c0\u67e5\u6bcf\u4e2agt\u5fc5\u987b\u662f\u77e9\u5f62(\u6bcf\u884c\u90fd\u5f97\u662f5\u4e2a\u6570 class+xywh) + \u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 + \u6807\u7b7e\u5750\u6807xywh\u662f\u5426\u5f52\u4e00\u5316 + \u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 verify_image_label\u51fd\u6570\u4ee3\u7801\uff1a def verify_image_label ( args ): \"\"\"\u7528\u5728cache_labels\u51fd\u6570\u4e2d \u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u6bcf\u5f20\u56fe\u7247\u548c\u6bcf\u5f20laebl\u662f\u5426\u5b8c\u597d \u56fe\u7247\u6587\u4ef6: \u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027 label\u6587\u4ef6: \u6bcf\u4e2agt\u5fc5\u987b\u662f\u77e9\u5f62(\u6bcf\u884c\u90fd\u5f97\u662f5\u4e2a\u6570 class+xywh) + \u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 + \u6807\u7b7e\u5750\u6807xywh\u662f\u5426\u5f52\u4e00\u5316 + \u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 :params im_file: \u6570\u636e\u96c6\u4e2d\u4e00\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 :params lb_file: \u6570\u636e\u96c6\u4e2d\u4e00\u5f20\u56fe\u7247\u7684label\u76f8\u5bf9\u8def\u5f84 :params prefix: \u65e5\u5fd7\u5934\u90e8\u4fe1\u606f(\u5f69\u6253\u9ad8\u4eae\u90e8\u5206) :return im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 :return l: [gt_num, cls+xywh(normalized)] \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u539flabel(\u5168\u90e8\u662f\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e) \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u7ecf\u8fc7segments2boxes\u5904\u7406\u597d\u7684\u6807\u7b7e(\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e\u4e0d\u5904\u7406 \u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u77e9\u5f62\u6807\u7b7e) :return shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape :return segments: \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5b58\u50a8None \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5c31\u628a\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709label\u5b58\u50a8\u5230segments\u4e2d(\u82e5\u5e72\u4e2a\u6b63\u5e38gt \u82e5\u5e72\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] :return nm: number missing \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u4e22\u5931 \u4e22\u5931=1 \u5b58\u5728=0 :return nf: number found \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u5b58\u5728 \u5b58\u5728=1 \u4e22\u5931=0 :return ne: number empty \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u662f\u7a7a\u7684 \u7a7a\u7684=1 \u6ca1\u7a7a=0 :return nc: number corrupt \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u6587\u4ef6\u662f\u5426\u662f\u7834\u635f\u7684 \u7834\u635f\u7684=1 \u6ca1\u7834\u635f=0 :return msg: \u8fd4\u56de\u7684msg\u4fe1\u606f label\u6587\u4ef6\u5b8c\u597d=\u2018\u2019 label\u6587\u4ef6\u7834\u635f=warning\u4fe1\u606f \"\"\" # Verify one image-label pair im_file , lb_file , prefix = args nm , nf , ne , nc , msg , segments = ( 0 , 0 , 0 , 0 , \"\" , [], ) # number (missing, found, empty, corrupt), message, segments try : # verify images \u68c0\u67e5\u8fd9\u5f20\u56fe\u7247(\u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027) verify images im = Image . open ( im_file ) # \u6253\u5f00\u56fe\u7247\u6587\u4ef6 im . verify () # PIL verify \u68c0\u67e5\u56fe\u7247\u5185\u5bb9\u548c\u683c\u5f0f\u662f\u5426\u6b63\u5e38 shape = exif_size ( im ) # image size \u5f53\u524d\u56fe\u7247\u7684\u5927\u5c0f image size # \u56fe\u7247\u5927\u5c0f\u5fc5\u987b\u5927\u4e8e9\u4e2apixels assert ( shape [ 0 ] > 9 ) & ( shape [ 1 ] > 9 ), f \"image size { shape } <10 pixels\" # \u56fe\u7247\u683c\u5f0f\u5fc5\u987b\u5728img_format\u4e2d assert im . format . lower () in IMG_FORMATS , f \"invalid image format { im . format } \" if im . format . lower () in ( \"jpg\" , \"jpeg\" ): # \u68c0\u67e5jpg\u683c\u5f0f\u6587\u4ef6 with open ( im_file , \"rb\" ) as f : # f.seek: -2 \u504f\u79fb\u91cf \u5411\u6587\u4ef6\u5934\u65b9\u5411\u4e2d\u79fb\u52a8\u7684\u5b57\u8282\u6570 2 \u76f8\u5bf9\u4f4d\u7f6e \u4ece\u6587\u4ef6\u5c3e\u5f00\u59cb\u504f\u79fb f . seek ( - 2 , 2 ) # f.read(): \u8bfb\u53d6\u56fe\u7247\u6587\u4ef6 \u6307\u4ee4: \\xff\\xd9 \u68c0\u6d4b\u6574\u5f20\u56fe\u7247\u662f\u5426\u5b8c\u6574 \u5982\u679c\u4e0d\u5b8c\u6574\u5c31\u8fd4\u56decorrupted JPEG if f . read () != b \" \\xff\\xd9 \" : # corrupt JPEG ImageOps . exif_transpose ( Image . open ( im_file )) . save ( im_file , \"JPEG\" , subsampling = 0 , quality = 100 ) msg = f \" { prefix } WARNING: { im_file } : corrupt JPEG restored and saved\" # verify labels if os . path . isfile ( lb_file ): nf = 1 # label found with open ( lb_file ) as f : # \u8bfb\u53d6\u5f53\u524dlabel\u6587\u4ef6\u7684\u6bcf\u4e00\u884c: \u6bcf\u4e00\u884c\u90fd\u662f\u5f53\u524d\u56fe\u7247\u7684\u4e00\u4e2agt lb = [ x . split () for x in f . read () . strip () . splitlines () if len ( x )] # any() \u51fd\u6570\u7528\u4e8e\u5224\u65ad\u7ed9\u5b9a\u7684\u53ef\u8fed\u4ee3\u53c2\u6570 \u662f\u5426\u5168\u90e8\u4e3aFalse,\u5219\u8fd4\u56de False; \u5982\u679c\u6709\u4e00\u4e2a\u4e3a True,\u5219\u8fd4\u56deTrue # \u5982\u679c\u5f53\u524d\u56fe\u7247\u7684label\u6587\u4ef6\u67d0\u4e00\u5217\u6570\u5927\u4e8e8, \u5219\u8ba4\u4e3alabel\u662f\u5b58\u5728segment\u7684polygon\u70b9(\u591a\u8fb9\u5f62) # \u5c31\u4e0d\u662f\u77e9\u9635 \u5219\u5c06label\u4fe1\u606f\u5b58\u5165segment\u4e2d if any ( len ( x ) > 6 for x in lb ): # is segment # \u5f53\u524d\u56fe\u7247\u4e2d\u6240\u6709gt\u6846\u7684\u7c7b\u522b classes = np . array ([ x [ 0 ] for x in lb ], dtype = np . float32 ) # \u83b7\u5f97\u8fd9\u5f20\u56fe\u4e2d\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) # \u56e0\u4e3asegment\u6807\u7b7e\u53ef\u4ee5\u662f\u4e0d\u540c\u957f\u5ea6\uff0c\u6240\u4ee5\u8fd9\u91ccsegments\u662f\u4e00\u4e2a\u5217\u8868 [gt_num, xy1...(normalized)] segments = [ np . array ( x [ 1 :], dtype = np . float32 ) . reshape ( - 1 , 2 ) for x in lb ] # (cls, xy1...) # \u83b7\u5f97\u8fd9\u5f20\u56fe\u4e2d\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) # segments(\u591a\u8fb9\u5f62) -> bbox(\u6b63\u65b9\u5f62), \u5f97\u5230\u65b0\u6807\u7b7e [gt_num, cls+xywh(normalized)] lb = np . concatenate (( classes . reshape ( - 1 , 1 ), segments2boxes ( segments )), 1 ) # (cls, xywh) lb = np . array ( lb , dtype = np . float32 ) nl = len ( lb ) if nl : # \u5224\u65ad\u6807\u7b7e\u662f\u5426\u6709\u4e94\u5217 assert lb . shape [ 1 ] == 5 , f \"labels require 5 columns, { lb . shape [ 1 ] } columns detected\" # \u5224\u65ad\u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 assert ( lb >= 0 ) . all (), f \"negative label values { lb [ lb < 0 ] } \" # \u5224\u65ad\u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 assert ( lb [:, 1 :] <= 1 ) . all (), f \"non-normalized or out of bounds coordinates { lb [:, 1 :][ lb [:, 1 :] > 1 ] } \" _ , i = np . unique ( lb , axis = 0 , return_index = True ) if len ( i ) < nl : # duplicate row check lb = lb [ i ] # remove duplicates if segments : segments = segments [ i ] msg = f \" { prefix } WARNING: { im_file } : { nl - len ( i ) } duplicate labels removed\" else : ne = 1 # label empty l.shape[0] == 0\u5219\u4e3a\u7a7a\u7684\u6807\u7b7e\uff0cne=1 lb = np . zeros (( 0 , 5 ), dtype = np . float32 ) else : nm = 1 # label missing lb = np . zeros (( 0 , 5 ), dtype = np . float32 ) return im_file , lb , shape , segments , nm , nf , ne , nc , msg except Exception as e : nc = 1 msg = f \" { prefix } WARNING: { im_file } : ignoring corrupt image/label: { e } \" return [ None , None , None , None , nm , nf , ne , nc , msg ] 7. load_image \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u6839\u636e\u56fe\u7247index\uff0c\u4eceself\u6216\u8005\u4ece\u5bf9\u5e94\u56fe\u7247\u8def\u5f84\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247 \u5e76\u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55\u3002 \u4f1a\u88ab\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u548cload_mosaic\u6a21\u5757\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247\uff1a load_image\u51fd\u6570\u4ee3\u7801\uff1a def load_image ( self , i ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u548cload_mosaic\u6a21\u5757\u4e2d \u4eceself\u6216\u8005\u4ece\u5bf9\u5e94\u56fe\u7247\u8def\u5f84\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247 \u5e76\u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55 loads 1 image from dataset, returns img, original hw, resized hw :params self: \u4e00\u822c\u662f\u5bfc\u5165LoadImagesAndLabels\u4e2d\u7684self :param index: \u5f53\u524d\u56fe\u7247\u7684index :return: img: resize\u540e\u7684\u56fe\u7247 (h0, w0): hw_original \u539f\u56fe\u7684hw img.shape[:2]: hw_resized resize\u540e\u7684\u56fe\u7247hw(hw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55) \"\"\" im , f , fn = ( self . ims [ i ], self . im_files [ i ], self . npy_files [ i ], ) if im is None : # not cached in RAM if fn . exists (): # load npy im = np . load ( fn ) else : # read image im = cv2 . imread ( f ) # BGR assert im is not None , f \"Image Not Found { f } \" h0 , w0 = im . shape [: 2 ] # orig hw r = self . img_size / max ( h0 , w0 ) # ratio if r != 1 : # if sizes are not equal # cv2.INTER_AREA: \u57fa\u4e8e\u533a\u57df\u50cf\u7d20\u5173\u7cfb\u7684\u4e00\u79cd\u91cd\u91c7\u6837\u6216\u8005\u63d2\u503c\u65b9\u5f0f.\u8be5\u65b9\u6cd5\u662f\u56fe\u50cf\u62bd\u53d6\u7684\u9996\u9009\u65b9\u6cd5, \u5b83\u53ef\u4ee5\u4ea7\u751f\u66f4\u5c11\u7684\u6ce2\u7eb9 # cv2.INTER_LINEAR: \u53cc\u7ebf\u6027\u63d2\u503c,\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4f7f\u7528\u8be5\u65b9\u5f0f\u8fdb\u884c\u63d2\u503c \u6839\u636eratio\u9009\u62e9\u4e0d\u540c\u7684\u63d2\u503c\u65b9\u5f0f # \u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55 interp = cv2 . INTER_LINEAR if ( self . augment or r > 1 ) else cv2 . INTER_AREA im = cv2 . resize ( im , ( int ( w0 * r ), int ( h0 * r )), interpolation = interp ) return im , ( h0 , w0 ), im . shape [: 2 ] # im, hw_original, hw_resized return self . ims [ i ], self . im_hw0 [ i ], self . im_hw [ i ] # im, hw_original, hw_resized 8. augment_hsv \u2003\u8fd9\u4e2a\u51fd\u6570\u662f\u5173\u4e8e\u56fe\u7247\u7684\u8272\u57df\u589e\u5f3a\u6a21\u5757\uff0c\u56fe\u7247\u5e76\u4e0d\u53d1\u751f\u79fb\u52a8\uff0c\u6240\u6709\u4e0d\u9700\u8981\u6539\u53d8label\uff0c\u53ea\u9700\u8981 img \u589e\u5f3a\u5373\u53ef\u3002 augment_hsv\u6a21\u5757\u4ee3\u7801\uff1a def augment_hsv ( img , hgain = 0.5 , sgain = 0.5 , vgain = 0.5 ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 hsv\u8272\u57df\u589e\u5f3a \u5904\u7406\u56fe\u50cfhsv\uff0c\u4e0d\u5bf9label\u8fdb\u884c\u4efb\u4f55\u5904\u7406 :param img: \u5f85\u5904\u7406\u56fe\u7247 BGR [736, 736] :param hgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684h\u901a\u9053 :param sgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684s\u901a\u9053 :param vgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684v\u901a\u9053 :return: \u8fd4\u56dehsv\u589e\u5f3a\u540e\u7684\u56fe\u7247 img \"\"\" if hgain or sgain or vgain : # \u968f\u673a\u53d6-1\u52301\u4e09\u4e2a\u5b9e\u6570\uff0c\u4e58\u4ee5hyp\u4e2d\u7684hsv\u4e09\u901a\u9053\u7684\u7cfb\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684hsv\u901a\u9053 r = np . random . uniform ( - 1 , 1 , 3 ) * [ hgain , sgain , vgain ] + 1 # random gains hue , sat , val = cv2 . split ( cv2 . cvtColor ( img , cv2 . COLOR_BGR2HSV )) # \u56fe\u50cf\u7684\u901a\u9053\u62c6\u5206 h s v dtype = img . dtype # uint8 x = np . arange ( 0 , 256 , dtype = r . dtype ) lut_hue = (( x * r [ 0 ]) % 180 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684h\u901a\u9053 lut_sat = np . clip ( x * r [ 1 ], 0 , 255 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684s\u901a\u9053 lut_val = np . clip ( x * r [ 2 ], 0 , 255 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684v\u901a\u9053 # \u56fe\u50cf\u7684\u901a\u9053\u5408\u5e76 img_hsv=h+s+v \u968f\u673a\u8c03\u6574hsv\u4e4b\u540e\u91cd\u65b0\u7ec4\u5408hsv\u901a\u9053 # cv2.LUT(hue, lut_hue) \u901a\u9053\u8272\u57df\u53d8\u6362 \u8f93\u5165\u53d8\u6362\u524d\u901a\u9053hue \u548c\u53d8\u6362\u540e\u901a\u9053lut_hue img_hsv = cv2 . merge (( cv2 . LUT ( hue , lut_hue ), cv2 . LUT ( sat , lut_sat ), cv2 . LUT ( val , lut_val ))) # no return needed dst:\u8f93\u51fa\u56fe\u50cf cv2 . cvtColor ( img_hsv , cv2 . COLOR_HSV2BGR , dst = img ) # no return needed hsv->bgr \u8fd8\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e2ahsv\u589e\u5f3a\u662f\u968f\u673a\u751f\u6210\u5404\u4e2a\u8272\u57df\u53c2\u6570\u7684\uff0c\u6240\u4ee5\u6bcf\u6b21\u589e\u5f3a\u7684\u6548\u679c\u90fd\u662f\u4e0d\u540c\u7684\uff1a \u8fd9\u4e2a\u51fd\u6570\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u4e2d\uff1a \u53e6\u5916\uff0c\u8fd9\u91cc\u6d89\u53ca\u5230\u7684\u4e09\u4e2a\u53d8\u91cf\u6765\u81eahyp.yaml\u8d85\u53c2\u6587\u4ef6\uff1a 9. load_mosaic\u3001load_mosaic9 \u2003\u8fd9\u4e24\u4e2a\u51fd\u6570\u90fd\u662fmosaic\u6570\u636e\u589e\u5f3a\uff0c\u53ea\u4e0d\u8fc7load_mosaic\u51fd\u6570\u662f\u62fc\u63a5\u56db\u5f20\u56fe\uff0c\u800cload_mosaic9\u51fd\u6570\u662f\u62fc\u63a5\u4e5d\u5f20\u56fe\u3002 \u66f4\u591a\u8bf7\u53c2\u9605 \u300amosaic \u89e3\u8bfb\u300b 9.1 load_mosaic \u2003\u8fd9\u4e2a\u6a21\u5757\u5c31\u662f\u5f88\u6709\u540d\u7684mosaic\u589e\u5f3a\u6a21\u5757\uff0c\u51e0\u4e4e\u8bad\u7ec3\u7684\u65f6\u5019\u90fd\u4f1a\u7528\u5b83\uff0c\u53ef\u4ee5\u663e\u8457\u7684\u63d0\u9ad8\u5c0f\u6837\u672c\u7684mAP\u3002 \u4ee3\u7801\u662f\u6570\u636e\u589e\u5f3a\u91cc\u9762\u6700\u96be\u7684, \u4e5f\u662f\u6700\u6709\u4ef7\u503c\u7684\uff0cmosaic\u662f\u975e\u5e38\u975e\u5e38\u6709\u7528\u7684\u6570\u636e\u589e\u5f3atrick, \u4e00\u5b9a\u8981\u719f\u7ec3\u638c\u63e1\u3002 load_mosaic\u6a21\u5757\u4ee3\u7801\uff1a def load_mosaic ( self , index ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u8fdb\u884cmosaic\u6570\u636e\u589e\u5f3a \u5c06\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d loads images in a 4-mosaic :param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 :return: img4: mosaic\u548c\u968f\u673a\u900f\u89c6\u53d8\u6362\u540e\u7684\u4e00\u5f20\u56fe\u7247 numpy(640, 640, 3) labels4: img4\u5bf9\u5e94\u7684target [M, cls+x1y1x2y2] \"\"\" # labels4: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff084\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegments\u591a\u8fb9\u5f62) # segments4: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff084\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62) labels4 , segments4 = [], [] s = self . img_size # \u4e00\u822c\u7684\u56fe\u7247\u5927\u5c0f # \u968f\u673a\u521d\u59cb\u5316\u62fc\u63a5\u56fe\u50cf\u7684\u4e2d\u5fc3\u70b9\u5750\u6807 [0, s*2]\u4e4b\u95f4\u968f\u673a\u53d62\u4e2a\u6570\u4f5c\u4e3a\u62fc\u63a5\u56fe\u50cf\u7684\u4e2d\u5fc3\u5750\u6807 yc , xc = [ int ( random . uniform ( - x , 2 * s + x )) for x in self . mosaic_border ] # mosaic center x, y # \u4ecedataset\u4e2d\u968f\u673a\u5bfb\u627e\u989d\u5916\u7684\u4e09\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 [14, 26, 2, 16] \u518d\u968f\u673a\u9009\u4e09\u5f20\u56fe\u7247\u7684index indices = [ index ] + random . choices ( self . indices , k = 3 ) # 3 additional image indices # \u904d\u5386\u56db\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 4\u5f20\u4e0d\u540c\u5927\u5c0f\u7684\u56fe\u50cf => 1\u5f20[1472, 1472, 3]\u7684\u56fe\u50cf for i , index in enumerate ( indices ): # load image \u6bcf\u6b21\u62ff\u4e00\u5f20\u56fe\u7247 \u5e76\u5c06\u8fd9\u5f20\u56fe\u7247resize\u5230self.size(h,w) img , _ , ( h , w ) = load_image ( self , index ) # place img in img4 if i == 0 : # top left \u539f\u56fe[375, 500, 3] load_image->[552, 736, 3] hwc # \u521b\u5efa\u9a6c\u8d5b\u514b\u56fe\u50cf [1472, 1472, 3]=[h, w, c] img4 = np . full (( s * 2 , s * 2 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) w=736 h = 552 \u9a6c\u8d5b\u514b\u56fe\u50cf\uff1a(x1a,y1a)\u5de6\u4e0a\u89d2 (x2a,y2a)\u53f3\u4e0b\u89d2 x1a , y1a , x2a , y2a = max ( xc - w , 0 ), max ( yc - h , 0 ), xc , yc # xmin, ymin, xmax, ymax (large image) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e00\u5f20\u56fe\u50cf\u7684\u53f3\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) \u56fe\u50cf\uff1a(x1b,y1b)\u5de6\u4e0a\u89d2 (x2b,y2b)\u53f3\u4e0b\u89d2 x1b , y1b , x2b , y2b = w - ( x2a - x1a ), h - ( y2a - y1a ), w , h # xmin, ymin, xmax, ymax (small image) elif i == 1 : # top right # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = xc , max ( yc - h , 0 ), min ( xc + w , s * 2 ), yc # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e8c\u5f20\u56fe\u50cf\u7684\u5de6\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = 0 , h - ( y2a - y1a ), min ( w , x2a - x1a ), h elif i == 2 : # bottom left # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = max ( xc - w , 0 ), yc , xc , min ( s * 2 , yc + h ) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e09\u5f20\u56fe\u50cf\u7684\u53f3\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = w - ( x2a - x1a ), 0 , w , min ( y2a - y1a , h ) elif i == 3 : # bottom right # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = xc , yc , min ( xc + w , s * 2 ), min ( s * 2 , yc + h ) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u56db\u5f20\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = 0 , 0 , min ( w , x2a - x1a ), min ( y2a - y1a , h ) # \u5c06\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u7684\u76f8\u5e94\u4f4d\u7f6e img4[h, w, c] # \u5c06\u56fe\u50cfimg\u7684\u3010(x1b,y1b)\u5de6\u4e0a\u89d2 (x2b,y2b)\u53f3\u4e0b\u89d2\u3011\u533a\u57df\u622a\u53d6\u51fa\u6765\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u7684\u3010(x1a,y1a)\u5de6\u4e0a\u89d2 (x2a,y2a)\u53f3\u4e0b\u89d2\u3011\u533a\u57df img4 [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] # \u8ba1\u7b97pad(\u5f53\u524d\u56fe\u50cf\u8fb9\u754c\u4e0e\u9a6c\u8d5b\u514b\u8fb9\u754c\u7684\u8ddd\u79bb\uff0c\u8d8a\u754c\u7684\u60c5\u51b5padw/padh\u4e3a\u8d1f\u503c) \u7528\u4e8e\u540e\u9762\u7684label\u6620\u5c04 padw = x1a - x1b # \u5f53\u524d\u56fe\u50cf\u4e0e\u9a6c\u8d5b\u514b\u56fe\u50cf\u5728w\u7ef4\u5ea6\u4e0a\u76f8\u5dee\u591a\u5c11 padh = y1a - y1b # \u5f53\u524d\u56fe\u50cf\u4e0e\u9a6c\u8d5b\u514b\u56fe\u50cf\u5728h\u7ef4\u5ea6\u4e0a\u76f8\u5dee\u591a\u5c11 # labels: \u83b7\u53d6\u5bf9\u5e94\u62fc\u63a5\u56fe\u50cf\u7684\u6240\u6709\u6b63\u5e38label\u4fe1\u606f(\u5982\u679c\u6709segments\u591a\u8fb9\u5f62\u4f1a\u88ab\u8f6c\u5316\u4e3a\u77e9\u5f62label) # segments: \u83b7\u53d6\u5bf9\u5e94\u62fc\u63a5\u56fe\u50cf\u7684\u6240\u6709\u4e0d\u6b63\u5e38label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62\u4e5f\u5305\u542b\u6b63\u5e38gt) labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : # normalized xywh normalized to pixel xyxy format labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padw , padh ) segments = [ xyn2xy ( x , w , h , padw , padh ) for x in segments ] labels4 . append ( labels ) # \u66f4\u65b0labels4 segments4 . extend ( segments ) # \u66f4\u65b0segments4 # Concat/clip labels4 \u628alabels4\uff08[(2, 5), (1, 5), (3, 5), (1, 5)] => (7, 5)\uff09\u538b\u7f29\u5230\u4e00\u8d77 labels4 = np . concatenate ( labels4 , 0 ) # \u9632\u6b62\u8d8a\u754c label[:, 1:]\u4e2d\u7684\u6240\u6709\u5143\u7d20\u7684\u503c\uff08\u4f4d\u7f6e\u4fe1\u606f\uff09\u5fc5\u987b\u5728[0, 2*s]\u4e4b\u95f4,\u5c0f\u4e8e0\u5c31\u4ee4\u5176\u7b49\u4e8e0,\u5927\u4e8e2*s\u5c31\u7b49\u4e8e2*s out: \u8fd4\u56de for x in ( labels4 [:, 1 :], * segments4 ): np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5\u524d\u9762\u7684mosaic\u6548\u679c # cv2.imshow(\"mosaic\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (1280, 1280, 3) # \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408 replicate # img4, labels4 = replicate(img4, labels4) # # # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5replicate\u6548\u679c # cv2.imshow(\"replicate\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (1280, 1280, 3) # Augment # random_perspective Augment \u968f\u673a\u900f\u89c6\u53d8\u6362 [1280, 1280, 3] => [640, 640, 3] # \u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5mosaic + random_perspective\u968f\u673a\u4eff\u5c04\u53d8\u6362\u6548\u679c # cv2.imshow(\"random_perspective\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (640, 640, 3) return img4 , labels4 9.2 load_mosaic9 \u2003\u8fd9\u4e2a\u6a21\u5757\u662f\u4f5c\u8005\u7684\u5b9e\u9a8c\u6a21\u5757\uff0c\u5c06\u4e5d\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u3002\u603b\u4f53\u4ee3\u7801\u6d41\u7a0b\u548cload_mosaic4\u51e0\u4e4e\u4e00\u6837\uff0c\u770b\u61c2\u4e86load_mosaic4\u518d\u770b\u8fd9\u4e2a\u5c31\u5f88\u7b80\u5355\u4e86\u3001 load_mosaic9\u6a21\u5757\u4ee3\u7801\uff1a def load_mosaic9 ( self , index ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u66ff\u6362mosaic\u6570\u636e\u589e\u5f3a \u5c06\u4e5d\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d loads images in a 9-mosaic :param self: :param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 :return: img9: mosaic\u548c\u4eff\u5c04\u589e\u5f3a\u540e\u7684\u4e00\u5f20\u56fe\u7247 labels9: img9\u5bf9\u5e94\u7684target \"\"\" # labels9: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff089\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegments\u591a\u8fb9\u5f62) # segments9: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff089\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62) labels9 , segments9 = [], [] s = self . img_size # \u4e00\u822c\u7684\u56fe\u7247\u5927\u5c0f(\u4e5f\u662f\u6700\u7ec8\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f) # \u4ecedataset\u4e2d\u968f\u673a\u5bfb\u627e\u989d\u5916\u7684\u4e09\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 [14, 26, 2, 16] \u518d\u968f\u673a\u9009\u4e09\u5f20\u56fe\u7247\u7684index indices = [ index ] + random . choices ( self . indices , k = 8 ) # 8 additional image indices for i , index in enumerate ( indices ): # Load image \u6bcf\u6b21\u62ff\u4e00\u5f20\u56fe\u7247 \u5e76\u5c06\u8fd9\u5f20\u56fe\u7247resize\u5230self.size(h,w) img , _ , ( h , w ) = load_image ( self , index ) # \u8fd9\u91cc\u548c\u4e0a\u9762load_mosaic\u51fd\u6570\u7684\u64cd\u4f5c\u7c7b\u4f3c \u5c31\u662f\u5c06\u53d6\u51fa\u7684img\u56fe\u7247\u5d4c\u5230img9\u4e2d(\u4e0d\u662f\u771f\u7684\u5d4c\u5165 \u800c\u662f\u627e\u5230\u5bf9\u5e94\u7684\u4f4d\u7f6e) # place img in img9 if i == 0 : # center img9 = np . full (( s * 3 , s * 3 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles h0 , w0 = h , w c = s , s , s + w , s + h # xmin, ymin, xmax, ymax (base) coordinates elif i == 1 : # top c = s , s - h , s + w , s elif i == 2 : # top right c = s + wp , s - h , s + wp + w , s elif i == 3 : # right c = s + w0 , s , s + w0 + w , s + h elif i == 4 : # bottom right c = s + w0 , s + hp , s + w0 + w , s + hp + h elif i == 5 : # bottom c = s + w0 - w , s + h0 , s + w0 , s + h0 + h elif i == 6 : # bottom left c = s + w0 - wp - w , s + h0 , s + w0 - wp , s + h0 + h elif i == 7 : # left c = s - w , s + h0 - h , s , s + h0 elif i == 8 : # top left c = s - w , s + h0 - hp - h , s , s + h0 - hp padx , pady = c [: 2 ] x1 , y1 , x2 , y2 = [ max ( x , 0 ) for x in c ] # allocate coords # \u548c\u4e0a\u9762load_mosaic\u51fd\u6570\u7684\u64cd\u4f5c\u7c7b\u4f3c \u627e\u5230mosaic9\u589e\u5f3a\u540e\u7684labels9\u548csegments9 labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padx , pady ) # normalized xywh to pixel xyxy format segments = [ xyn2xy ( x , w , h , padx , pady ) for x in segments ] labels9 . append ( labels ) segments9 . extend ( segments ) # \u751f\u6210\u5bf9\u5e94\u7684img9\u56fe\u7247(\u5c06\u5bf9\u5e94\u4f4d\u7f6e\u7684\u56fe\u7247\u5d4c\u5165img9\u4e2d) img9 [ y1 : y2 , x1 : x2 ] = img [ y1 - pady :, x1 - padx :] # img9[ymin:ymax, xmin:xmax] hp , wp = h , w # height, width previous # Offset yc , xc = [ int ( random . uniform ( 0 , s )) for _ in self . mosaic_border ] # mosaic center x, y img9 = img9 [ yc : yc + 2 * s , xc : xc + 2 * s ] # Concat/clip labels labels9 = np . concatenate ( labels9 , 0 ) labels9 [:, [ 1 , 3 ]] -= xc labels9 [:, [ 2 , 4 ]] -= yc c = np . array ([ xc , yc ]) # centers segments9 = [ x - c for x in segments9 ] for x in ( labels9 [:, 1 :], * segments9 ): np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img9, labels9 = replicate(img9, labels9) # replicate # Augment \u540c\u6837\u8fdb\u884c \u968f\u673a\u900f\u89c6\u53d8\u6362 img9 , labels9 = random_perspective ( img9 , labels9 , segments9 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove return img9 , labels9 \u7528\u6cd5\u548cmosaic\u4e00\u6837\uff0c\u4f7f\u7528\u76f4\u63a5\u5c06class LoadImagesAndLabels(Dataset): \u4e2d getitem \u7684load_mosaic\u76f4\u63a5 \u76f4\u63a5\u66ff\u6362\u6210load_mosaic9\u5373\u53ef\uff1a 10. LoadImages & LoadStreams & LoadWebcam load \u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247/\u89c6\u9891 + \u7528\u5230\u5f88\u5c11 load web\u7f51\u9875\u4e2d\u7684\u6570\u636e\u3002 \u5168\u90e8\u4ee3\u7801\uff1a class LoadImages : # for inference \"\"\"\u5728detect.py\u4e2d\u4f7f\u7528 load \u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247/\u89c6\u9891 \u5b9a\u4e49\u8fed\u4ee3\u5668 \u7528\u4e8edetect.py \"\"\" def __init__ ( self , path , img_size = 640 , stride = 32 ): p = str ( Path ( path ) . absolute ()) # os-agnostic absolute path # glob.glab: \u8fd4\u56de\u6240\u6709\u5339\u914d\u7684\u6587\u4ef6\u8def\u5f84\u5217\u8868 files: \u63d0\u53d6\u56fe\u7247\u6240\u6709\u8def\u5f84 if \"*\" in p : # \u5982\u679cp\u662f\u91c7\u6837\u6b63\u5219\u5316\u8868\u8fbe\u5f0f\u63d0\u53d6\u56fe\u7247/\u89c6\u9891, \u53ef\u4ee5\u4f7f\u7528glob\u83b7\u53d6\u6587\u4ef6\u8def\u5f84 files = sorted ( glob . glob ( p , recursive = True )) # glob elif os . path . isdir ( p ): # \u5982\u679cp\u662f\u4e00\u4e2a\u6587\u4ef6\u5939\uff0c\u4f7f\u7528glob\u83b7\u53d6\u5168\u90e8\u6587\u4ef6\u8def\u5f84 files = sorted ( glob . glob ( os . path . join ( p , \"*.*\" ))) # dir elif os . path . isfile ( p ): # \u5982\u679cp\u662f\u6587\u4ef6\u5219\u76f4\u63a5\u83b7\u53d6 files = [ p ] # files else : raise Exception ( f \"ERROR: { p } does not exist\" ) # images: \u76ee\u5f55\u4e0b\u6240\u6709\u56fe\u7247\u7684\u56fe\u7247\u540d videos: \u76ee\u5f55\u4e0b\u6240\u6709\u89c6\u9891\u7684\u89c6\u9891\u540d images = [ x for x in files if x . split ( \".\" )[ - 1 ] . lower () in img_formats ] videos = [ x for x in files if x . split ( \".\" )[ - 1 ] . lower () in vid_formats ] # \u56fe\u7247\u4e0e\u89c6\u9891\u6570\u91cf ni , nv = len ( images ), len ( videos ) self . img_size = img_size self . stride = stride # \u6700\u5927\u7684\u4e0b\u91c7\u6837\u7387 self . files = images + videos # \u6574\u5408\u56fe\u7247\u548c\u89c6\u9891\u8def\u5f84\u5230\u4e00\u4e2a\u5217\u8868 self . nf = ni + nv # number of files self . video_flag = [ False ] * ni + [ True ] * nv # \u662f\u4e0d\u662fvideo self . mode = \"image\" # \u9ed8\u8ba4\u662f\u8bfbimage\u6a21\u5f0f if any ( videos ): # \u5224\u65ad\u6709\u6ca1\u6709video\u6587\u4ef6 \u5982\u679c\u5305\u542bvideo\u6587\u4ef6\uff0c\u5219\u521d\u59cb\u5316opencv\u4e2d\u7684\u89c6\u9891\u6a21\u5757\uff0ccap=cv2.VideoCapture\u7b49 self . new_video ( videos [ 0 ]) # new video else : self . cap = None assert self . nf > 0 , ( f \"No images or videos found in { p } . \" f \"Supported formats are: \\n images: { img_formats } \\n videos: { vid_formats } \" ) def __iter__ ( self ): \"\"\"\u8fed\u4ee3\u5668\"\"\" self . count = 0 return self def __next__ ( self ): \"\"\"\u4e0eiter\u4e00\u8d77\u7528\uff1f\"\"\" if self . count == self . nf : # \u6570\u636e\u8bfb\u5b8c\u4e86 raise StopIteration path = self . files [ self . count ] # \u8bfb\u53d6\u5f53\u524d\u6587\u4ef6\u8def\u5f84 if self . video_flag [ self . count ]: # \u5224\u65ad\u5f53\u524d\u6587\u4ef6\u662f\u5426\u662f\u89c6\u9891 # Read video self . mode = \"video\" # \u83b7\u53d6\u5f53\u524d\u5e27\u753b\u9762\uff0cret_val\u4e3a\u4e00\u4e2abool\u53d8\u91cf\uff0c\u76f4\u5230\u89c6\u9891\u8bfb\u53d6\u5b8c\u6bd5\u4e4b\u524d\u90fd\u4e3aTrue ret_val , img0 = self . cap . read () # \u5982\u679c\u5f53\u524d\u89c6\u9891\u8bfb\u53d6\u7ed3\u675f\uff0c\u5219\u8bfb\u53d6\u4e0b\u4e00\u4e2a\u89c6\u9891 if not ret_val : self . count += 1 self . cap . release () # self.count == self.nf\u8868\u793a\u89c6\u9891\u5df2\u7ecf\u8bfb\u53d6\u5b8c\u4e86 if self . count == self . nf : # last video raise StopIteration else : path = self . files [ self . count ] self . new_video ( path ) ret_val , img0 = self . cap . read () self . frame += 1 # \u5f53\u524d\u8bfb\u53d6\u89c6\u9891\u7684\u5e27\u6570 print ( f \"video { self . count + 1 } / { self . nf } ( { self . frame } / { self . frames } ) { path } : \" , end = \"\" , ) else : # Read image self . count += 1 img0 = cv2 . imread ( path ) # BGR assert img0 is not None , \"Image Not Found \" + path print ( f \"image { self . count } / { self . nf } { path } : \" , end = \"\" ) # Padded resize img = letterbox ( img0 , self . img_size , stride = self . stride )[ 0 ] # Convert img = img [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB and HWC to CHW img = np . ascontiguousarray ( img ) # \u8fd4\u56de\u8def\u5f84, resize+pad\u7684\u56fe\u7247, \u539f\u59cb\u56fe\u7247, \u89c6\u9891\u5bf9\u8c61 return path , img , img0 , self . cap def new_video ( self , path ): # \u8bb0\u5f55\u5e27\u6570 self . frame = 0 # \u521d\u59cb\u5316\u89c6\u9891\u5bf9\u8c61 self . cap = cv2 . VideoCapture ( path ) # \u5f97\u5230\u89c6\u9891\u6587\u4ef6\u4e2d\u7684\u603b\u5e27\u6570 self . frames = int ( self . cap . get ( cv2 . CAP_PROP_FRAME_COUNT )) def __len__ ( self ): return self . nf # number of files class LoadStreams : \"\"\" load \u6587\u4ef6\u5939\u4e2d\u89c6\u9891\u6d41 multiple IP or RTSP cameras \u5b9a\u4e49\u8fed\u4ee3\u5668 \u7528\u4e8edetect.py \"\"\" def __init__ ( self , sources = \"streams.txt\" , img_size = 640 , stride = 32 ): self . mode = \"stream\" # \u521d\u59cb\u5316mode\u4e3aimages self . img_size = img_size self . stride = stride # \u6700\u5927\u4e0b\u91c7\u6837\u6b65\u957f # \u5982\u679csources\u4e3a\u4e00\u4e2a\u4fdd\u5b58\u4e86\u591a\u4e2a\u89c6\u9891\u6d41\u7684\u6587\u4ef6 \u83b7\u53d6\u6bcf\u4e00\u4e2a\u89c6\u9891\u6d41\uff0c\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u5217\u8868 if os . path . isfile ( sources ): with open ( sources , \"r\" ) as f : sources = [ x . strip () for x in f . read () . strip () . splitlines () if len ( x . strip ()) ] else : # \u53cd\u4e4b\uff0c\u53ea\u6709\u4e00\u4e2a\u89c6\u9891\u6d41\u6587\u4ef6\u5c31\u76f4\u63a5\u4fdd\u5b58 sources = [ sources ] n = len ( sources ) # \u89c6\u9891\u6d41\u4e2a\u6570 # \u521d\u59cb\u5316\u56fe\u7247 fps \u603b\u5e27\u6570 \u7ebf\u7a0b\u6570 self . imgs , self . fps , self . frames , self . threads = ( [ None ] * n , [ 0 ] * n , [ 0 ] * n , [ None ] * n , ) self . sources = [ clean_str ( x ) for x in sources ] # clean source names for later # \u904d\u5386\u6bcf\u4e00\u4e2a\u89c6\u9891\u6d41 for i , s in enumerate ( sources ): # index, source # Start thread to read frames from video stream # \u6253\u5370\u5f53\u524d\u89c6\u9891index/\u603b\u89c6\u9891\u6570/\u89c6\u9891\u6d41\u5730\u5740 print ( f \" { i + 1 } / { n } : { s } ... \" , end = \"\" ) if \"youtube.com/\" in s or \"youtu.be/\" in s : # if source is YouTube video check_requirements (( \"pafy\" , \"youtube_dl\" )) import pafy s = pafy . new ( s ) . getbest ( preftype = \"mp4\" ) . url # YouTube URL s = eval ( s ) if s . isnumeric () else s # i.e. s = '0' local webcam \u672c\u5730\u6444\u50cf\u5934 # s='0'\u6253\u5f00\u672c\u5730\u6444\u50cf\u5934\uff0c\u5426\u5219\u6253\u5f00\u89c6\u9891\u6d41\u5730\u5740 cap = cv2 . VideoCapture ( s ) assert cap . isOpened (), f \"Failed to open { s } \" # \u83b7\u53d6\u89c6\u9891\u7684\u5bbd\u548c\u957f w = int ( cap . get ( cv2 . CAP_PROP_FRAME_WIDTH )) h = int ( cap . get ( cv2 . CAP_PROP_FRAME_HEIGHT )) # \u83b7\u53d6\u89c6\u9891\u7684\u5e27\u7387 self . fps [ i ] = ( max ( cap . get ( cv2 . CAP_PROP_FPS ) % 100 , 0 ) or 30.0 ) # 30 FPS fallback # \u5e27\u6570 self . frames [ i ] = max ( int ( cap . get ( cv2 . CAP_PROP_FRAME_COUNT )), 0 ) or float ( \"inf\" ) # infinite stream fallback # \u8bfb\u53d6\u5f53\u524d\u753b\u9762 _ , self . imgs [ i ] = cap . read () # guarantee first frame # \u521b\u5efa\u591a\u7ebf\u7a0b\u8bfb\u53d6\u89c6\u9891\u6d41\uff0cdaemon\u8868\u793a\u4e3b\u7ebf\u7a0b\u7ed3\u675f\u65f6\u5b50\u7ebf\u7a0b\u4e5f\u7ed3\u675f self . threads [ i ] = Thread ( target = self . update , args = ([ i , cap ]), daemon = True ) print ( f \" success ( { self . frames [ i ] } frames { w } x { h } at { self . fps [ i ] : .2f } FPS)\" ) self . threads [ i ] . start () print ( \"\" ) # newline # check for common shapes # \u83b7\u53d6\u8fdb\u884cresize+pad\u4e4b\u540e\u7684shape\uff0cletterbox\u51fd\u6570\u9ed8\u8ba4(\u53c2\u6570auto=True)\u662f\u6309\u7167\u77e9\u5f62\u63a8\u7406\u8fdb\u884c\u586b\u5145 s = np . stack ( [ letterbox ( x , self . img_size , stride = self . stride )[ 0 ] . shape for x in self . imgs ], 0 , ) # shapes self . rect = ( np . unique ( s , axis = 0 ) . shape [ 0 ] == 1 ) # rect inference if all shapes equal if not self . rect : print ( \"WARNING: Different stream shapes detected. For optimal performance supply similarly-shaped streams.\" ) def update ( self , i , cap ): # Read stream `i` frames in daemon thread n , f = 0 , self . frames [ i ] while cap . isOpened () and n < f : n += 1 # _, self.imgs[index] = cap.read() cap . grab () # \u6bcf4\u5e27\u8bfb\u53d6\u4e00\u6b21 if n % 4 : # read every 4th frame success , im = cap . retrieve () self . imgs [ i ] = im if success else self . imgs [ i ] * 0 time . sleep ( 1 / self . fps [ i ]) # wait time def __iter__ ( self ): self . count = - 1 return self def __next__ ( self ): self . count += 1 if not all ( x . is_alive () for x in self . threads ) or cv2 . waitKey ( 1 ) == ord ( \"q\" ): # q to quit cv2 . destroyAllWindows () raise StopIteration # Letterbox img0 = self . imgs . copy () img = [ letterbox ( x , self . img_size , auto = self . rect , stride = self . stride )[ 0 ] for x in img0 ] # Stack \u5c06\u8bfb\u53d6\u7684\u56fe\u7247\u62fc\u63a5\u5230\u4e00\u8d77 img = np . stack ( img , 0 ) # Convert img = img [:, :, :, :: - 1 ] . transpose ( 0 , 3 , 1 , 2 ) # BGR to RGB and BHWC to BCHW img = np . ascontiguousarray ( img ) return self . sources , img , img0 , None def __len__ ( self ): return 0 # 1E12 frames = 32 streams at 30 FPS for 30 years class LoadWebcam : # for inference \"\"\"\u7528\u5230\u5f88\u5c11 load web\u7f51\u9875\u4e2d\u7684\u6570\u636e\"\"\" def __init__ ( self , pipe = \"0\" , img_size = 640 , stride = 32 ): self . img_size = img_size self . stride = stride if pipe . isnumeric (): pipe = eval ( pipe ) # local camera # pipe = 'rtsp://192.168.1.64/1' # IP camera # pipe = 'rtsp://username:password@192.168.1.64/1' # IP camera with login # pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg' # IP golf camera self . pipe = pipe self . cap = cv2 . VideoCapture ( pipe ) # video capture object self . cap . set ( cv2 . CAP_PROP_BUFFERSIZE , 3 ) # set buffer size def __iter__ ( self ): self . count = - 1 return self def __next__ ( self ): self . count += 1 if cv2 . waitKey ( 1 ) == ord ( \"q\" ): # q to quit self . cap . release () cv2 . destroyAllWindows () raise StopIteration # Read frame if self . pipe == 0 : # local camera ret_val , img0 = self . cap . read () img0 = cv2 . flip ( img0 , 1 ) # flip left-right else : # IP camera n = 0 while True : n += 1 self . cap . grab () if n % 30 == 0 : # skip frames ret_val , img0 = self . cap . retrieve () if ret_val : break # Print assert ret_val , f \"Camera Error { self . pipe } \" img_path = \"webcam.jpg\" print ( f \"webcam { self . count } : \" , end = \"\" ) # Padded resize img = letterbox ( img0 , self . img_size , stride = self . stride )[ 0 ] # Convert img = img [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB and HWC to CHW img = np . ascontiguousarray ( img ) return img_path , img , img0 , None def __len__ ( self ): return 0 11. flatten_recursive \u8fd9\u4e2a\u6a21\u5757\u662f\u5c06\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u590d\u5236\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d \u5373\u5c06image\u6587\u4ef6\u548clabel\u6587\u4ef6\u653e\u5230\u4e00\u4e2a\u65b0\u6587\u4ef6\u5939\u4e2d\u3002 flatten_recursive\u6a21\u5757\u4ee3\u7801\uff1a def flatten_recursive ( path = DATASETS_DIR / \"coco128\" ): # \u5c06\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u590d\u5236\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d \u5373\u5c06image\u6587\u4ef6\u548clabel\u6587\u4ef6\u653e\u5230\u4e00\u4e2a\u65b0\u6587\u4ef6\u5939\u4e2d # Flatten a recursive directory by bringing all files to top level new_path = Path ( f \" { str ( path ) } _flat\" ) if os . path . exists ( new_path ): shutil . rmtree ( new_path ) # delete output folder os . makedirs ( new_path ) # make new output folder for file in tqdm ( glob . glob ( f \" { str ( Path ( path )) } /**/*.*\" , recursive = True )): # shutil.copyfile: \u590d\u5236\u6587\u4ef6\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d shutil . copyfile ( file , new_path / Path ( file ) . name ) 12.extract_boxes \u2003\u8fd9\u4e2a\u6a21\u5757\u662f\u5c06\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u5206\u7c7b\u6570\u636e\u96c6 \uff0c\u96c6\u4f53\u505a\u6cd5: \u628a\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2agt\u62c6\u89e3\u5f00 \u5206\u7c7b\u522b\u5b58\u50a8\u5230\u5bf9\u5e94\u7684\u6587\u4ef6\u5f53\u4e2d\u3002 def extract_boxes ( path = DATASETS_DIR / \"coco128\" , ): # from utils.dataloaders import *; extract_boxes() # Convert detection dataset into classification dataset, with one directory per class \"\"\"\u81ea\u884c\u4f7f\u7528 \u751f\u6210\u5206\u7c7b\u6570\u636e\u96c6 \u5c06\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u5206\u7c7b\u6570\u636e\u96c6 \u96c6\u4f53\u505a\u6cd5: \u628a\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2agt\u62c6\u89e3\u5f00 \u5206\u7c7b\u522b\u5b58\u50a8\u5230\u5bf9\u5e94\u7684\u6587\u4ef6\u5f53\u4e2d Convert detection dataset into classification dataset, with one directory per class \u4f7f\u7528: from utils.datasets import *; extract_boxes() :params path: \u6570\u636e\u96c6\u5730\u5740 \"\"\" path = Path ( path ) # images dir \u6570\u636e\u96c6\u6587\u4ef6\u76ee\u5f55 \u9ed8\u8ba4'..\\datasets\\coco128' shutil . rmtree ( path / \"classifier\" ) if ( path / \"classifier\" ) . is_dir () else None # remove existing files = list ( path . rglob ( \"*.*\" )) n = len ( files ) # number of files for im_file in tqdm ( files , total = n ): if im_file . suffix [ 1 :] in IMG_FORMATS : # \u5fc5\u987b\u5f97\u662f\u56fe\u7247\u6587\u4ef6 # image im = cv2 . imread ( str ( im_file ))[ ... , :: - 1 ] # BGR to RGB h , w = im . shape [: 2 ] # \u5f97\u5230\u8fd9\u5f20\u56fe\u7247h w # labels \u6839\u636e\u8fd9\u5f20\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u8fd9\u5f20\u56fe\u7247\u7684label\u8def\u5f84 lb_file = Path ( img2label_paths ([ str ( im_file )])[ 0 ]) if Path ( lb_file ) . exists (): with open ( lb_file ) as f : lb = np . array ([ x . split () for x in f . read () . strip () . splitlines ()], dtype = np . float32 ) # labels \u8bfb\u53d6label\u7684\u5404\u884c: \u5bf9\u5e94\u5404\u4e2agt\u5750\u6807 for j , x in enumerate ( lb ): # \u904d\u5386\u6bcf\u4e00\u4e2agt c = int ( x [ 0 ]) # class # \u751f\u6210\u65b0'file_name path\\classifier\\class_index\\image_name' # \u5982: 'F:\\yolo_v5\\datasets\\coco128\\images\\train2017\\classifier\\45\\train2017_000000000009_0.jpg' f = ( path / \"classifier\" ) / f \" { c } \" / f \" { path . stem } _ { im_file . stem } _ { j } .jpg\" # new filename if not f . parent . is_dir (): # \u6bcf\u4e00\u4e2a\u7c7b\u522b\u7684\u7b2c\u4e00\u5f20\u7167\u7247\u5b58\u8fdb\u53bb\u4e4b\u524d \u5148\u521b\u5efa\u5bf9\u5e94\u7c7b\u7684\u6587\u4ef6\u5939 f . parent . mkdir ( parents = True ) b = x [ 1 :] * [ w , h , w , h ] # box normalized to \u6b63\u5e38\u5927\u5c0f # b[2:] = b[2:].max() # rectangle to square b [ 2 :] = b [ 2 :] * 1.2 + 3 # pad b = xywh2xyxy ( b . reshape ( - 1 , 4 )) . ravel () . astype ( np . int ) b [[ 0 , 2 ]] = np . clip ( b [[ 0 , 2 ]], 0 , w ) # clip boxes outside of image \u9632\u6b62\u51fa\u754c b [[ 1 , 3 ]] = np . clip ( b [[ 1 , 3 ]], 0 , h ) assert cv2 . imwrite ( str ( f ), im [ b [ 1 ] : b [ 3 ], b [ 0 ] : b [ 2 ]]), f \"box failure in { f } \" 13. autosplit \u2003\u8fd9\u4e2a\u6a21\u5757\u662f\u8fdb\u884c\u81ea\u52a8\u5212\u5206\u6570\u636e\u96c6\u3002\u5f53\u4f7f\u7528\u81ea\u5df1\u6570\u636e\u96c6\u65f6\uff0c\u53ef\u4ee5\u7528\u8fd9\u4e2a\u6a21\u5757\u8fdb\u884c\u81ea\u884c\u5212\u5206\u6570\u636e\u96c6\u3002 autosplit\u6a21\u5757\u4ee3\u7801\uff1a def autosplit ( path = DATASETS_DIR / \"coco128/images\" , weights = ( 0.9 , 0.1 , 0.0 ), annotated_only = False ): \"\"\"Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files Usage: from utils.dataloaders import *; autosplit() Arguments path: Path to images directory weights: Train, val, test weights (list, tuple) annotated_only: Only use images with an annotated txt file \"\"\" path = Path ( path ) # images dir # \u83b7\u53d6images\u4e2d\u6240\u6709\u7684\u56fe\u7247 image files only files = sorted ( x for x in path . rglob ( \"*.*\" ) if x . suffix [ 1 :] . lower () in IMG_FORMATS ) # image files only n = len ( files ) # number of files # \u968f\u673a\u6570\u79cd\u5b50 random . seed ( 0 ) # for reproducibility # assign each image to a split \u6839\u636e(train, val, test)\u6743\u91cd\u5212\u5206\u539f\u59cb\u56fe\u7247\u6570\u636e\u96c6 # indices: [n] 0, 1, 2 \u5206\u522b\u8868\u793a\u6570\u636e\u96c6\u4e2d\u6bcf\u4e00\u5f20\u56fe\u7247\u5c5e\u4e8e\u54ea\u4e2a\u6570\u636e\u96c6 \u5206\u522b\u5bf9\u5e94\u7740(train, val, test) indices = random . choices ([ 0 , 1 , 2 ], weights = weights , k = n ) # assign each image to a split txt = [ \"autosplit_train.txt\" , \"autosplit_val.txt\" , \"autosplit_test.txt\" ] # 3 txt files [( path . parent / x ) . unlink ( missing_ok = True ) for x in txt ] # remove existing print ( f \"Autosplitting images from { path } \" + \", using *.txt labeled images only\" * annotated_only ) for i , img in tqdm ( zip ( indices , files ), total = n ): if not annotated_only or Path ( img2label_paths ([ str ( img )])[ 0 ]) . exists (): # check label with open ( path . parent / txt [ i ], \"a\" ) as f : f . write ( f \"./ { img . relative_to ( path . parent ) . as_posix () } \" + \" \\n \" ) # add image to txt file Reference \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011 atasets.py","title":"dataloaders.py"},{"location":"source_code_interpretation/utils/dataloaders_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/dataloaders.py","title":"\u524d\u8a00"},{"location":"source_code_interpretation/utils/dataloaders_py.html#1","text":"# YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license \"\"\" Dataloaders and dataset utils \"\"\" import contextlib import glob # python\u81ea\u5df1\u5e26\u7684\u4e00\u4e2a\u6587\u4ef6\u64cd\u4f5c\u76f8\u5173\u6a21\u5757 \u67e5\u627e\u7b26\u5408\u81ea\u5df1\u76ee\u7684\u7684\u6587\u4ef6(\u5982\u6a21\u7cca\u5339\u914d) import hashlib # \u54c8\u5e0c\u6a21\u5757 \u63d0\u4f9b\u4e86\u591a\u79cd\u5b89\u5168\u65b9\u4fbf\u7684hash\u65b9\u6cd5 import json # json\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 import math # \u6570\u5b66\u516c\u5f0f\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 \u5305\u542b\u6587\u4ef6\u8def\u5f84\u64cd\u4f5c\u548c\u89e3\u6790 import random # \u751f\u6210\u968f\u673a\u6570\u6a21\u5757 import shutil # \u6587\u4ef6\u5939\u3001\u538b\u7f29\u5305\u5904\u7406\u6a21\u5757 import time # \u65f6\u95f4\u6a21\u5757 \u66f4\u5e95\u5c42 from itertools import repeat # \u590d\u5236\u6a21\u5757 from multiprocessing.pool import Pool , ThreadPool # \u591a\u7ebf\u7a0b\u6a21\u5757 \u7ebf\u7a0b\u6c60 from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 from threading import Thread # \u591a\u7ebf\u7a0b\u64cd\u4f5c\u6a21\u5757 from urllib.parse import urlparse from zipfile import ZipFile import numpy as np # numpy\u77e9\u9635\u64cd\u4f5c\u6a21\u5757 import oneflow as flow # OneFlow\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757 import oneflow.nn.functional as F # OneFlow\u51fd\u6570\u63a5\u53e3 \u5c01\u88c5\u4e86\u5f88\u591a\u5377\u79ef\u3001\u6c60\u5316\u7b49\u51fd\u6570 import yaml # yaml\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 from oneflow.utils.data import DataLoader , Dataset , dataloader , distributed from PIL import ExifTags , Image , ImageOps # \u56fe\u7247\u3001\u76f8\u673a\u64cd\u4f5c\u6a21\u5757 from tqdm import tqdm # \u8fdb\u5ea6\u6761\u6a21\u5757 # augmentations.py\u6e90\u7801\u89e3\u8bfb: https://start.oneflow.org/oneflow-yolo-doc/source_code_interpretation/utils/augmentations_py.html from utils.augmentations import Albumentations , augment_hsv , copy_paste , letterbox , mixup , random_perspective from utils.general import ( DATASETS_DIR , LOGGER , NUM_THREADS , check_dataset , check_requirements , check_yaml , clean_str , cv2 , is_colab , is_kaggle , segments2boxes , xyn2xy , xywh2xyxy , xywhn2xyxy , xyxy2xywhn , ) # Parameters HELP_URL = \"https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\" IMG_FORMATS = ( \"bmp\" , \"dng\" , \"jpeg\" , \"jpg\" , \"mpo\" , \"png\" , \"tif\" , \"tiff\" , \"webp\" , ) # include image suffixes VID_FORMATS = ( \"asf\" , \"avi\" , \"gif\" , \"m4v\" , \"mkv\" , \"mov\" , \"mp4\" , \"mpeg\" , \"mpg\" , \"ts\" , \"wmv\" , ) # include video suffixes BAR_FORMAT = \" {l_bar}{bar:10}{r_bar}{bar:-10b} \" # tqdm bar format LOCAL_RANK = int ( os . getenv ( \"LOCAL_RANK\" , - 1 )) # https://oneflow.readthedocs.io/en/master/distributed.html?highlight=launch#launching-distributed-training RANK = int ( os . getenv ( \"RANK\" , - 1 ))","title":"1. \u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e"},{"location":"source_code_interpretation/utils/dataloaders_py.html#2","text":"\u8fd9\u90e8\u5206\u662f\u76f8\u673a\u76f8\u5173\u8bbe\u7f6e\uff0c\u5f53\u4f7f\u7528\u76f8\u673a\u91c7\u6837\u65f6\u624d\u4f1a\u4f7f\u7528\u3002 # \u76f8\u673a\u8bbe\u7f6e # Get orientation exif tag # \u4e13\u95e8\u4e3a\u6570\u7801\u76f8\u673a\u7684\u7167\u7247\u800c\u8bbe\u5b9a \u53ef\u4ee5\u8bb0\u5f55\u6570\u7801\u7167\u7247\u7684\u5c5e\u6027\u4fe1\u606f\u548c\u62cd\u6444\u6570\u636e for orientation in ExifTags . TAGS . keys (): if ExifTags . TAGS [ orientation ] == \"Orientation\" : break def get_hash ( paths ): # \u8fd4\u56de\u6587\u4ef6\u5217\u8868\u7684hash\u503c # Returns a single hash value of a list of paths (files or dirs) size = sum ( os . path . getsize ( p ) for p in paths if os . path . exists ( p )) # sizes h = hashlib . md5 ( str ( size ) . encode ()) # hash sizes h . update ( \"\" . join ( paths ) . encode ()) # hash paths return h . hexdigest () # return hash def exif_size ( img ): # \u83b7\u53d6\u6570\u7801\u76f8\u673a\u7684\u56fe\u7247\u5bbd\u9ad8\u4fe1\u606f \u5e76\u4e14\u5224\u65ad\u662f\u5426\u9700\u8981\u65cb\u8f6c\uff08\u6570\u7801\u76f8\u673a\u53ef\u4ee5\u591a\u89d2\u5ea6\u62cd\u6444\uff09 # Returns exif-corrected PIL size s = img . size # (width, height) with contextlib . suppress ( Exception ): rotation = dict ( img . _getexif () . items ())[ orientation ] if rotation in [ 6 , 8 ]: # rotation 270 or 90 s = ( s [ 1 ], s [ 0 ]) return s def exif_transpose ( image ): \"\"\" \u5982\u679c\u6709EXIF\u65b9\u5411\u6807\u8bb0\uff0c\u5219\u76f8\u5e94\u8c03\u6362PIL\u56fe\u50cf\u3002 Transpose a PIL image accordingly if it has an EXIF Orientation tag. Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose() :param image: The image to transpose. :return: An image. \"\"\" exif = image . getexif () orientation = exif . get ( 0x0112 , 1 ) # default 1 if orientation > 1 : method = { 2 : Image . FLIP_LEFT_RIGHT , 3 : Image . ROTATE_180 , 4 : Image . FLIP_TOP_BOTTOM , 5 : Image . TRANSPOSE , 6 : Image . ROTATE_270 , 7 : Image . TRANSVERSE , 8 : Image . ROTATE_90 , } . get ( orientation ) if method is not None : image = image . transpose ( method ) del exif [ 0x0112 ] image . info [ \"exif\" ] = exif . tobytes () return image def seed_worker ( worker_id ): # Set dataloader worker seed # https://oneflow.readthedocs.io/en/master/utils.data.html?highlight=randomness#platform-specific-behaviors worker_seed = flow . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) def create_dataloader ( path , # path: \u56fe\u7247\u6570\u636e\u52a0\u8f7d\u8def\u5f84 train/test \u5982: ../datasets/coco/images/train2017 imgsz , # train/test\u56fe\u7247\u5c3a\u5bf8\uff08\u6570\u636e\u589e\u5f3a\u540e\u5927\u5c0f\uff09 640 batch_size , # batch size \u5927\u5c0f 8/16/32 stride , # \u6a21\u578b\u6700\u5927stride=32 [32 16 8] single_cls = False , # \u6570\u636e\u96c6\u662f\u5426\u662f\u5355\u7c7b\u522b \u9ed8\u8ba4False hyp = None , # \u8d85\u53c2\u5217\u8868dict \u7f51\u7edc\u8bad\u7ec3\u65f6\u7684\u4e00\u4e9b\u8d85\u53c2\u6570\uff0c\u5305\u62ec\u5b66\u4e60\u7387\u7b49\uff0c\u8fd9\u91cc\u4e3b\u8981\u7528\u5230\u91cc\u9762\u4e00\u4e9b\u5173\u4e8e\u6570\u636e\u589e\u5f3a(\u65cb\u8f6c\u3001\u5e73\u79fb\u7b49)\u7684\u7cfb\u6570 augment = False , # \u662f\u5426\u8981\u8fdb\u884c\u6570\u636e\u589e\u5f3a True cache = False , # \u662f\u5426cache_images False pad = 0.0 , # \u8bbe\u7f6e\u77e9\u5f62\u8bad\u7ec3\u7684shape\u65f6\u8fdb\u884c\u7684\u586b\u5145 \u9ed8\u8ba40.0 rect = False , # \u662f\u5426\u5f00\u542f\u77e9\u5f62train/test \u9ed8\u8ba4\u8bad\u7ec3\u96c6\u5173\u95ed \u9a8c\u8bc1\u96c6\u5f00\u542f rank =- 1 , # \u591a\u5361\u8bad\u7ec3\u65f6\u7684\u8fdb\u7a0b\u7f16\u53f7 rank\u4e3a\u8fdb\u7a0b\u7f16\u53f7 -1\u4e14gpu=1\u65f6\u4e0d\u8fdb\u884c\u5206\u5e03\u5f0f -1\u4e14\u591a\u5757gpu\u4f7f\u7528DataParallel\u6a21\u5f0f \u9ed8\u8ba4-1 workers = 8 , # dataloader\u7684num_works \u52a0\u8f7d\u6570\u636e\u65f6\u7684cpu\u8fdb\u7a0b\u6570 image_weights = False , # \u8bad\u7ec3\u65f6\u662f\u5426\u6839\u636e\u56fe\u7247\u6837\u672c\u771f\u5b9e\u6846\u5206\u5e03\u6743\u91cd\u6765\u9009\u62e9\u56fe\u7247 \u9ed8\u8ba4False quad = False , # dataloader\u53d6\u6570\u636e\u65f6, \u662f\u5426\u4f7f\u7528collate_fn4\u4ee3\u66ffcollate_fn \u9ed8\u8ba4False prefix = \"\" , # \u663e\u793a\u4fe1\u606f \u4e00\u4e2a\u6807\u5fd7\uff0c\u591a\u4e3atrain/val\uff0c\u5904\u7406\u6807\u7b7e\u65f6\u4fdd\u5b58cache\u6587\u4ef6\u4f1a\u7528\u5230 shuffle = False , # \u5bf9\u8bad\u7ec3\u6570\u636e\u662f\u5426\u968f\u673a\u6253\u4e71\u3002 ): \"\"\"\u5728train.py\u4e2d\u88ab\u8c03\u7528\uff0c\u7528\u4e8e\u751f\u6210Trainloader, dataset\uff0ctestloader \u81ea\u5b9a\u4e49dataloader\u51fd\u6570: \u8c03\u7528LoadImagesAndLabels\u83b7\u53d6\u6570\u636e\u96c6(\u5305\u62ec\u6570\u636e\u589e\u5f3a) + \u8c03\u7528\u5206\u5e03\u5f0f\u91c7\u6837\u5668DistributedSampler + \u81ea\u5b9a\u4e49InfiniteDataLoader \u8fdb\u884c\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e \"\"\" if rect and shuffle : LOGGER . warning ( \"WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\" ) shuffle = False # \u8f7d\u5165\u6587\u4ef6\u6570\u636e(\u589e\u5f3a\u6570\u636e\u96c6) dataset = LoadImagesAndLabels ( path , imgsz , batch_size , augment = augment , # augmentation hyp = hyp , # hyperparameters rect = rect , # rectangular batches cache_images = cache , single_cls = single_cls , stride = int ( stride ), pad = pad , image_weights = image_weights , prefix = prefix , ) batch_size = min ( batch_size , len ( dataset )) nd = flow . cuda . device_count () # number of CUDA devices nw = min ([ os . cpu_count () // max ( nd , 1 ), batch_size if batch_size > 1 else 0 , workers ]) # number of workers # \u5206\u5e03\u5f0f\u91c7\u6837\u5668DistributedSampler sampler = None if rank == - 1 else distributed . DistributedSampler ( dataset , shuffle = shuffle ) # \u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u6765\u5bf9DataLoader\u8fdb\u884c\u5c01\u88c5, \u4ee3\u66ff\u539f\u5148\u7684DataLoader, \u80fd\u591f\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e loader = DataLoader if image_weights else InfiniteDataLoader # only DataLoader allows for attribute updates # \u968f\u673a\u6570\u751f\u6210\u5668 https://oneflow.readthedocs.io/en/master/generated/oneflow.randint.html?highlight=flow.Generator#oneflow.randint generator = flow . Generator () generator . manual_seed ( 6148914691236517205 + RANK ) return ( loader ( dataset , batch_size = batch_size , shuffle = shuffle and sampler is None , num_workers = nw , sampler = sampler , pin_memory = True , collate_fn = LoadImagesAndLabels . collate_fn4 if quad else LoadImagesAndLabels . collate_fn , worker_init_fn = seed_worker , generator = generator , ), dataset , )","title":"2. \u76f8\u673a\u8bbe\u7f6e"},{"location":"source_code_interpretation/utils/dataloaders_py.html#3dataloader","text":"\u5f53image_weights=False\u65f6\uff08\u4e0d\u6839\u636e\u56fe\u7247\u6837\u672c\u771f\u5b9e\u6846\u5206\u5e03\u6743\u91cd\u6765\u9009\u62e9\u56fe\u7247\uff09\u5c31\u4f1a\u8c03\u7528\u8fd9\u4e24\u4e2a\u51fd\u6570 \u8fdb\u884c\u81ea\u5b9a\u4e49DataLoader\uff0c\u8fdb\u884c\u6301\u7eed\u6027\u91c7\u6837\u3002\u5728\u4e0a\u9762\u7684create_dataloade\u51fd\u6570\u4e2d\u88ab\u8c03\u7528\u3002 class InfiniteDataLoader ( dataloader . DataLoader ): \"\"\"Dataloader that reuses workers \u5f53image_weights=False\u65f6\u5c31\u4f1a\u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u8fd9\u4e24\u4e2a\u7c7b\u5b9e\u73b0\u81ea\u5b9a\u4e49DataLoader \u4f7f\u7528InfiniteDataLoader\u548c_RepeatSampler\u6765\u5bf9DataLoader\u8fdb\u884c\u5c01\u88c5, \u4ee3\u66ff\u539f\u5148\u7684DataLoader, \u80fd\u591f\u6c38\u4e45\u6301\u7eed\u7684\u91c7\u6837\u6570\u636e Uses same syntax as vanilla DataLoader \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) # \u8c03\u7528_RepeatSampler\u8fdb\u884c\u6301\u7eed\u91c7\u6837 object . __setattr__ ( self , \"batch_sampler\" , _RepeatSampler ( self . batch_sampler )) self . iterator = super () . __iter__ () def __len__ ( self ): return len ( self . batch_sampler . sampler ) def __iter__ ( self ): for _ in range ( len ( self )): yield next ( self . iterator ) class _RepeatSampler : \"\"\"Sampler that repeats forever \u8fd9\u90e8\u5206\u662f\u8fdb\u884c\u6301\u7eed\u91c7\u6837 Args: sampler (Sampler) \"\"\" def __init__ ( self , sampler ): self . sampler = sampler def __iter__ ( self ): while True : yield from iter ( self . sampler )","title":"3.\u81ea\u5b9a\u4e49DataLoader"},{"location":"source_code_interpretation/utils/dataloaders_py.html#4-loadimagesandlabels","text":"\u8fd9\u4e2a\u90e8\u5206\u662f\u6570\u636e\u8f7d\u5165\uff08\u6570\u636e\u589e\u5f3a\uff09\u90e8\u5206\uff0c \u4e5f\u5c31\u662f\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u90e8\u5206\uff0c\u7ee7\u627f\u81eaDataset\uff0c\u9700\u8981\u91cd\u5199__init__,__getitem()__\u7b49\u62bd\u8c61\u65b9\u6cd5\uff0c \u53e6\u5916\u76ee\u6807\u68c0\u6d4b\u4e00\u822c\u8fd8\u9700\u8981\u91cd\u5199collate_fn\u51fd\u6570\u3002\u6240\u4ee5\uff0c\u7406\u89e3\u8fd9\u4e09\u4e2a\u51fd\u6570\u662f\u7406\u89e3\u6570\u636e\u589e\u5f3a\uff08\u6570\u636e\u8f7d\u5165\uff09\u7684\u91cd\u4e2d\u4e4b\u91cd\u3002","title":"4. LoadImagesAndLabels"},{"location":"source_code_interpretation/utils/dataloaders_py.html#41-init","text":"\u8fd9\u4e2a\u51fd\u6570\u7684\u5165\u53e3\u662f\u4e0a\u9762\u7684create_dataloader\u51fd\u6570\uff1a init \u4e3b\u8981\u5e72\u4e86\u4e00\u4e0b\u51e0\u4ef6\u4e8b\uff1a \u8d4b\u503c\u4e00\u4e9b\u57fa\u7840\u7684self\u53d8\u91cf \u7528\u4e8e\u540e\u9762\u5728__getitem__\u4e2d\u8c03\u7528 \u5f97\u5230path\u8def\u5f84\u4e0b\u7684\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84self.img_files \u6839\u636eimgs\u8def\u5f84\u627e\u5230labels\u7684\u8def\u5f84self.label_files cache label Read cache \u751f\u6210self.labels\u3001self.shapes\u3001self.img_files\u3001self.label_files\u3001self.batch\u3001self.n\u3001self.indices\u7b49\u53d8\u91cf \u4e3aRectangular Training\u4f5c\u51c6\u5907: \u751f\u6210self.batch_shapes \u662f\u5426\u9700\u8981cache image(\u4e00\u822c\u4e0d\u9700\u8981\uff0c\u592a\u5927\u4e86) __init__\u51fd\u6570\u4ee3\u7801\uff1a class LoadImagesAndLabels ( Dataset ): def __init__ ( self , path , img_size = 640 , batch_size = 16 , augment = False , hyp = None , rect = False , image_weights = False , cache_images = False , single_cls = False , stride = 32 , pad = 0.0 , prefix = \"\" , ): \"\"\" \u521d\u59cb\u5316\u8fc7\u7a0b\u5e76\u6ca1\u6709\u4ec0\u4e48\u5b9e\u8d28\u6027\u7684\u64cd\u4f5c,\u66f4\u591a\u662f\u4e00\u4e2a\u5b9a\u4e49\u53c2\u6570\u7684\u8fc7\u7a0b\uff08self\u53c2\u6570\uff09,\u4ee5\u4fbf\u5728__getitem()__\u4e2d\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u64cd\u4f5c,\u6240\u4ee5\u8fd9\u90e8\u5206\u4ee3\u7801\u53ea\u9700\u8981\u6293\u4f4fself\u4e2d\u7684\u5404\u4e2a\u53d8\u91cf\u7684\u542b\u4e49\u5c31\u7b97\u5dee\u4e0d\u591a\u4e86 self.img_files: {list: N} \u5b58\u653e\u7740\u6574\u4e2a\u6570\u636e\u96c6\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84 self.label_files: {list: N} \u5b58\u653e\u7740\u6574\u4e2a\u6570\u636e\u96c6\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84 cache label -> verify_image_label self.labels: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label labels\u5b58\u50a8\u7684label\u5c31\u90fd\u662f\u539f\u59cblabel(\u90fd\u662f\u6b63\u5e38\u7684\u77e9\u5f62label) \u5426\u5219\u5c06\u6240\u6709\u56fe\u7247\u6b63\u5e38gt\u7684label\u5b58\u5165labels \u4e0d\u6b63\u5e38gt(\u5b58\u5728\u4e00\u4e2a\u591a\u8fb9\u5f62)\u7ecf\u8fc7segments2boxes\u8f6c\u6362\u4e3a\u6b63\u5e38\u7684\u77e9\u5f62label self.shapes: \u6240\u6709\u56fe\u7247\u7684shape self.segments: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label self.segments=None \u5426\u5219\u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u6240\u6709\u5b58\u5728\u591a\u8fb9\u5f62gt\u7684\u56fe\u7247\u7684\u6240\u6709\u539f\u59cblabel(\u80af\u5b9a\u6709\u591a\u8fb9\u5f62label \u4e5f\u53ef\u80fd\u6709\u77e9\u5f62\u6b63\u5e38label \u672a\u77e5\u6570) self.batch: \u8bb0\u8f7d\u7740\u6bcf\u5f20\u56fe\u7247\u5c5e\u4e8e\u54ea\u4e2abatch self.n: \u6570\u636e\u96c6\u4e2d\u6240\u6709\u56fe\u7247\u7684\u6570\u91cf self.indices: \u8bb0\u8f7d\u7740\u6240\u6709\u56fe\u7247\u7684index self.rect=True\u65f6self.batch_shapes\u8bb0\u8f7d\u6bcf\u4e2abatch\u7684shape(\u540c\u4e00\u4e2abatch\u7684\u56fe\u7247shape\u76f8\u540c) \"\"\" # 1\u3001\u8d4b\u503c\u4e00\u4e9b\u57fa\u7840\u7684self\u53d8\u91cf \u7528\u4e8e\u540e\u9762\u5728__getitem__\u4e2d\u8c03\u7528 self . img_size = img_size # \u7ecf\u8fc7\u6570\u636e\u589e\u5f3a\u540e\u7684\u6570\u636e\u56fe\u7247\u7684\u5927\u5c0f self . augment = augment # \u662f\u5426\u542f\u52a8\u6570\u636e\u589e\u5f3a \u4e00\u822c\u8bad\u7ec3\u65f6\u6253\u5f00 \u9a8c\u8bc1\u65f6\u5173\u95ed self . hyp = hyp # \u8d85\u53c2\u5217\u8868 # \u56fe\u7247\u6309\u6743\u91cd\u91c7\u6837 True\u5c31\u53ef\u4ee5\u6839\u636e\u7c7b\u522b\u9891\u7387(\u9891\u7387\u9ad8\u7684\u6743\u91cd\u5c0f,\u53cd\u6b63\u5927)\u6765\u8fdb\u884c\u91c7\u6837 \u9ed8\u8ba4False: \u4e0d\u4f5c\u7c7b\u522b\u533a\u5206 self . image_weights = image_weights self . rect = False if image_weights else rect # \u662f\u5426\u542f\u52a8\u77e9\u5f62\u8bad\u7ec3 \u4e00\u822c\u8bad\u7ec3\u65f6\u5173\u95ed \u9a8c\u8bc1\u65f6\u6253\u5f00 \u53ef\u4ee5\u52a0\u901f self . mosaic = self . augment and not self . rect # load 4 images at a time into a mosaic (only during training) # mosaic\u589e\u5f3a\u7684\u8fb9\u754c\u503c [-320, -320] self . mosaic_border = [ - img_size // 2 , - img_size // 2 ] self . stride = stride # \u6700\u5927\u4e0b\u91c7\u6837\u7387 32 self . path = path # \u56fe\u7247\u8def\u5f84 self . albumentations = Albumentations () if augment else None # 2\u3001\u5f97\u5230path\u8def\u5f84\u4e0b\u7684\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84self.img_files \u8fd9\u91cc\u9700\u8981\u81ea\u5df1debug\u4e00\u4e0b \u4e0d\u4f1a\u592a\u96be try : f = [] # image files for p in path if isinstance ( path , list ) else [ path ]: # \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84path\uff0c\u5305\u542b\u56fe\u7247\u8def\u5f84\u7684txt\u6587\u4ef6\u6216\u8005\u5305\u542b\u56fe\u7247\u7684\u6587\u4ef6\u5939\u8def\u5f84 # \u4f7f\u7528pathlib.Path\u751f\u6210\u4e0e\u64cd\u4f5c\u7cfb\u7edf\u65e0\u5173\u7684\u8def\u5f84\uff0c\u56e0\u4e3a\u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf\u8def\u5f84\u7684\u2018/\u2019\u4f1a\u6709\u6240\u4e0d\u540c p = Path ( p ) # os-agnostic # \u5982\u679c\u8def\u5f84path\u4e3a\u5305\u542b\u56fe\u7247\u7684\u6587\u4ef6\u5939\u8def\u5f84 if p . is_dir (): # dir # glob.glab: \u8fd4\u56de\u6240\u6709\u5339\u914d\u7684\u6587\u4ef6\u8def\u5f84\u5217\u8868 \u9012\u5f52\u83b7\u53d6p\u8def\u5f84\u4e0b\u6240\u6709\u6587\u4ef6 f += glob . glob ( str ( p / '**' / '*.*' ), recursive = True ) # f = list(p.rglob('**/*.*')) # pathlib # \u5982\u679c\u8def\u5f84path\u4e3a\u5305\u542b\u56fe\u7247\u8def\u5f84\u7684txt\u6587\u4ef6 elif p . is_file (): # file with open ( p , 'r' ) as t : t = t . read () . strip () . splitlines () # \u83b7\u53d6\u56fe\u7247\u8def\u5f84\uff0c\u66f4\u6362\u76f8\u5bf9\u8def\u5f84 # \u83b7\u53d6\u6570\u636e\u96c6\u8def\u5f84\u7684\u4e0a\u7ea7\u7236\u76ee\u5f55 os.sep\u4e3a\u8def\u5f84\u91cc\u7684\u5206\u9694\u7b26\uff08\u4e0d\u540c\u8def\u5f84\u7684\u5206\u9694\u7b26\u4e0d\u540c\uff0cos.sep\u53ef\u4ee5\u6839\u636e\u7cfb\u7edf\u81ea\u9002\u5e94\uff09 parent = str ( p . parent ) + os . sep f += [ x . replace ( './' , parent ) if x . startswith ( './' ) else x for x in t ] # local to global path # f += [p.parent / x.lstrip(os.sep) for x in t] # local to global path (pathlib) else : raise Exception ( f ' { prefix }{ p } does not exist' ) # \u7834\u6298\u53f7\u66ff\u6362\u4e3aos.sep\uff0cos.path.splitext(x)\u5c06\u6587\u4ef6\u540d\u4e0e\u6269\u5c55\u540d\u5206\u5f00\u5e76\u8fd4\u56de\u4e00\u4e2a\u5217\u8868 # \u7b5b\u9009f\u4e2d\u6240\u6709\u7684\u56fe\u7247\u6587\u4ef6 self . im_files = sorted ( x . replace ( \"/\" , os . sep ) for x in f if x . split ( \".\" )[ - 1 ] . lower () in IMG_FORMATS ) # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS]) # pathlib assert self . im_files , f \" { prefix } No images found\" except Exception as e : raise Exception ( f \" { prefix } Error loading data from { path } : { e } \\n See { HELP_URL } \" ) # Check cache 3\u6839\u636eimgs\u8def\u5f84\u627e\u5230labels\u7684\u8def\u5f84self.label_files self . label_files = img2label_paths ( self . im_files ) # labels # 4\u3001cache label \u4e0b\u6b21\u8fd0\u884c\u8fd9\u4e2a\u811a\u672c\u7684\u65f6\u5019\u76f4\u63a5\u4ececache\u4e2d\u53d6label\u800c\u4e0d\u662f\u53bb\u6587\u4ef6\u4e2d\u53d6label \u901f\u5ea6\u66f4\u5feb cache_path = ( p if p . is_file () else Path ( self . label_files [ 0 ]) . parent ) . with_suffix ( \".cache\" ) try : # \u5982\u679c\u6709cache\u6587\u4ef6\uff0c\u76f4\u63a5\u52a0\u8f7d exists=True: \u662f\u5426\u5df2\u4ececache\u6587\u4ef6\u4e2d\u8bfb\u51fa\u4e86nf, nm, ne, nc, n\u7b49\u4fe1\u606f cache , exists = np . load ( cache_path , allow_pickle = True ) . item (), True # load dict assert cache [ \"version\" ] == self . cache_version # matches current version assert cache [ \"hash\" ] == get_hash ( self . label_files + self . im_files ) # identical hash except Exception : # \u5982\u679c\u56fe\u7247\u7248\u672c\u4fe1\u606f\u6216\u8005\u6587\u4ef6\u5217\u8868\u7684hash\u503c\u5bf9\u4e0d\u4e0a\u53f7 \u8bf4\u660e\u672c\u5730\u6570\u636e\u96c6\u56fe\u7247\u548clabel\u53ef\u80fd\u53d1\u751f\u4e86\u53d8\u5316 \u5c31\u91cd\u65b0cache label\u6587\u4ef6 cache , exists = self . cache_labels ( cache_path , prefix ), False # run cache ops # Display cache # \u6253\u5370cache\u7684\u7ed3\u679c nf nm ne nc n = \u627e\u5230\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u6f0f\u6389\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u7a7a\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u635f\u574f\u7684\u6807\u7b7e\u6570\u91cf\uff0c\u603b\u7684\u6807\u7b7e\u6570\u91cf nf , nm , ne , nc , n = cache . pop ( \"results\" ) # found, missing, empty, corrupt, total # \u5982\u679c\u5df2\u7ecf\u4ececache\u6587\u4ef6\u8bfb\u51fa\u4e86nf nm ne nc n\u7b49\u4fe1\u606f\uff0c\u76f4\u63a5\u663e\u793a\u6807\u7b7e\u4fe1\u606f msgs\u4fe1\u606f\u7b49 if exists and LOCAL_RANK in { - 1 , 0 }: d = f \"Scanning ' { cache_path } ' images and labels... { nf } found, { nm } missing, { ne } empty, { nc } corrupt\" tqdm ( None , desc = prefix + d , total = n , initial = n , bar_format = BAR_FORMAT ) # display cache results if cache [ \"msgs\" ]: LOGGER . info ( \" \\n \" . join ( cache [ \"msgs\" ])) # display warnings # \u6570\u636e\u96c6\u6ca1\u6709\u6807\u7b7e\u4fe1\u606f \u5c31\u53d1\u51fa\u8b66\u544a\u5e76\u663e\u793a\u6807\u7b7elabel\u4e0b\u8f7d\u5730\u5740help_url assert nf > 0 or not augment , f \" { prefix } No labels in { cache_path } . Can not train without labels. See { HELP_URL } \" # 5\u3001Read cache \u4ececache\u4e2d\u8bfb\u51fa\u6700\u65b0\u53d8\u91cf\u8d4b\u7ed9self \u65b9\u4fbf\u7ed9forward\u4e2d\u4f7f\u7528 # cache\u4e2d\u7684\u952e\u503c\u5bf9\u6700\u521d\u6709: cache[img_file]=[l, shape, segments] cache[hash] cache[results] cache[msg] cache[version] # \u5148\u4ececache\u4e2d\u53bb\u9664cache\u6587\u4ef6\u4e2d\u5176\u4ed6\u65e0\u5173\u952e\u503c\u5982:'hash', 'version', 'msgs'\u7b49\u90fd\u5220\u9664 [ cache . pop ( k ) for k in ( 'hash' , 'version' , 'msgs' )] # remove items # pop\u6389results\u3001hash\u3001version\u3001msgs\u540e\u53ea\u5269\u4e0bcache[img_file]=[l, shape, segments] # cache.values(): \u53d6cache\u4e2d\u6240\u6709\u503c \u5bf9\u5e94\u6240\u6709l, shape, segments # labels: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label labels\u5b58\u50a8\u7684label\u5c31\u90fd\u662f\u539f\u59cblabel(\u90fd\u662f\u6b63\u5e38\u7684\u77e9\u5f62label) # \u5426\u5219\u5c06\u6240\u6709\u56fe\u7247\u6b63\u5e38gt\u7684label\u5b58\u5165labels \u4e0d\u6b63\u5e38gt(\u5b58\u5728\u4e00\u4e2a\u591a\u8fb9\u5f62)\u7ecf\u8fc7segments2boxes\u8f6c\u6362\u4e3a\u6b63\u5e38\u7684\u77e9\u5f62label # shapes: \u6240\u6709\u56fe\u7247\u7684shape # self.segments: \u5982\u679c\u6570\u636e\u96c6\u6240\u6709\u56fe\u7247\u4e2d\u6ca1\u6709\u4e00\u4e2a\u591a\u8fb9\u5f62label self.segments=None # \u5426\u5219\u5b58\u50a8\u6570\u636e\u96c6\u4e2d\u6240\u6709\u5b58\u5728\u591a\u8fb9\u5f62gt\u7684\u56fe\u7247\u7684\u6240\u6709\u539f\u59cblabel(\u80af\u5b9a\u6709\u591a\u8fb9\u5f62label \u4e5f\u53ef\u80fd\u6709\u77e9\u5f62\u6b63\u5e38label \u672a\u77e5\u6570) # zip \u662f\u56e0\u4e3acache\u4e2d\u6240\u6709labels\u3001shapes\u3001segments\u4fe1\u606f\u90fd\u662f\u6309\u6bcf\u5f20img\u5206\u5f00\u5b58\u50a8\u7684, zip\u662f\u5c06\u6240\u6709\u56fe\u7247\u5bf9\u5e94\u7684\u4fe1\u606f\u53e0\u5728\u4e00\u8d77 labels , shapes , self . segments = zip ( * cache . values ()) # segments: \u90fd\u662f[] self . labels = list ( labels ) self . shapes = np . array ( shapes ) self . im_files = list ( cache . keys ()) # update self . label_files = img2label_paths ( cache . keys ()) # update \u66f4\u65b0\u6240\u6709\u56fe\u7247\u7684label_files\u4fe1\u606f(\u56e0\u4e3aimg_files\u4fe1\u606f\u53ef\u80fd\u53d1\u751f\u4e86\u53d8\u5316) n = len ( shapes ) # number of images bi = np . floor ( np . arange ( n ) / batch_size ) . astype ( np . int ) # batch index nb = bi [ - 1 ] + 1 # number of batches self . batch = bi # batch index of image \u6240\u6709\u56fe\u7247\u7684index self . n = n self . indices = range ( n ) # Update labels include_class = [] # filter labels to include only these classes (optional) include_class_array = np . array ( include_class ) . reshape ( 1 , - 1 ) for i , ( label , segment ) in enumerate ( zip ( self . labels , self . segments )): if include_class : j = ( label [:, 0 : 1 ] == include_class_array ) . any ( 1 ) self . labels [ i ] = label [ j ] if segment : self . segments [ i ] = segment [ j ] if single_cls : # single-class training, merge all classes into 0 self . labels [ i ][:, 0 ] = 0 if segment : self . segments [ i ][:, 0 ] = 0 # Rectangular Training # 6\u3001\u4e3aRectangular Training\u4f5c\u51c6\u5907 # \u8fd9\u91cc\u4e3b\u8981\u662f\u6ce8\u610fshapes\u7684\u751f\u6210 \u8fd9\u4e00\u6b65\u5f88\u91cd\u8981 \u56e0\u4e3a\u5982\u679c\u91c7\u6837\u77e9\u5f62\u8bad\u7ec3\u90a3\u4e48\u6574\u4e2abatch\u7684\u5f62\u72b6\u8981\u4e00\u6837 \u5c31\u8981\u8ba1\u7b97\u8fd9\u4e2a\u7b26\u5408\u6574\u4e2abatch\u7684shape # \u800c\u4e14\u8fd8\u8981\u5bf9\u6570\u636e\u96c6\u6309\u7167\u9ad8\u5bbd\u6bd4\u8fdb\u884c\u6392\u5e8f \u8fd9\u6837\u624d\u80fd\u4fdd\u8bc1\u540c\u4e00\u4e2abatch\u7684\u56fe\u7247\u7684\u5f62\u72b6\u5dee\u4e0d\u591a\u76f8\u540c \u518d\u9009\u5219\u4e00\u4e2a\u5171\u540c\u7684shape\u4ee3\u4ef7\u4e5f\u6bd4\u8f83\u5c0f if self . rect : # Sort by aspect ratio s = self . shapes # wh ar = s [:, 1 ] / s [:, 0 ] # aspect ratio irect = ar . argsort () # \u6839\u636e\u9ad8\u5bbd\u6bd4\u6392\u5e8f self . img_files = [ self . img_files [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684img_files self . label_files = [ self . label_files [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684label_files self . labels = [ self . labels [ i ] for i in irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684labels self . shapes = s [ irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684wh ar = ar [ irect ] # \u83b7\u53d6\u6392\u5e8f\u540e\u7684aspect ratio # \u8ba1\u7b97\u6bcf\u4e2abatch\u91c7\u7528\u7684\u7edf\u4e00\u5c3a\u5ea6 Set training image shapes shapes = [[ 1 , 1 ]] * nb # nb: number of batches for i in range ( nb ): ari = ar [ bi == i ] # bi: batch index mini , maxi = ari . min (), ari . max () # \u83b7\u53d6\u7b2ci\u4e2abatch\u4e2d\uff0c\u6700\u5c0f\u548c\u6700\u5927\u9ad8\u5bbd\u6bd4 # \u5982\u679c\u9ad8/\u5bbd\u5c0f\u4e8e1(w > h)\uff0c\u5c06w\u8bbe\u4e3aimg_size\uff08\u4fdd\u8bc1\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0d\u53d8\u8fdb\u884c\u7f29\u653e\uff09 if maxi < 1 : shapes [ i ] = [ maxi , 1 ] # maxi: h\u76f8\u5bf9\u6307\u5b9a\u5c3a\u5ea6\u7684\u6bd4\u4f8b 1: w\u76f8\u5bf9\u6307\u5b9a\u5c3a\u5ea6\u7684\u6bd4\u4f8b # \u5982\u679c\u9ad8/\u5bbd\u5927\u4e8e1(w < h)\uff0c\u5c06h\u8bbe\u7f6e\u4e3aimg_size\uff08\u4fdd\u8bc1\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0d\u53d8\u8fdb\u884c\u7f29\u653e\uff09 elif mini > 1 : shapes [ i ] = [ 1 , 1 / mini ] # \u8ba1\u7b97\u6bcf\u4e2abatch\u8f93\u5165\u7f51\u7edc\u7684shape\u503c(\u5411\u4e0a\u8bbe\u7f6e\u4e3a32\u7684\u6574\u6570\u500d) # \u8981\u6c42\u6bcf\u4e2abatch_shapes\u7684\u9ad8\u5bbd\u90fd\u662f32\u7684\u6574\u6570\u500d\uff0c\u6240\u4ee5\u8981\u5148\u9664\u4ee532\uff0c\u53d6\u6574\u518d\u4e58\u4ee532\uff08\u4e0d\u8fc7img_size\u5982\u679c\u662f32\u500d\u6570\u8fd9\u91cc\u5c31\u6ca1\u5fc5\u8981\u4e86\uff09 self . batch_shapes = np . ceil ( np . array ( shapes ) * img_size / stride + pad ) . astype ( np . int ) * stride # 7\u3001\u662f\u5426\u9700\u8981cache image \u4e00\u822c\u662fFalse \u56e0\u4e3aRAM\u4f1a\u4e0d\u8db3 cache label\u8fd8\u53ef\u4ee5 \u4f46\u662fcache image\u5c31\u592a\u5927\u4e86 \u6240\u4ee5\u4e00\u822c\u4e0d\u7528 # Cache images into RAM/disk for faster training (WARNING: large datasets may exceed system resources) self . ims = [ None ] * n self . npy_files = [ Path ( f ) . with_suffix ( \".npy\" ) for f in self . im_files ] if cache_images : gb = 0 # Gigabytes of cached images self . im_hw0 , self . im_hw = [ None ] * n , [ None ] * n fcn = self . cache_images_to_disk if cache_images == \"disk\" else self . load_image results = ThreadPool ( NUM_THREADS ) . imap ( fcn , range ( n )) pbar = tqdm ( enumerate ( results ), total = n , bar_format = BAR_FORMAT , disable = LOCAL_RANK > 0 ) for i , x in pbar : if cache_images == \"disk\" : gb += self . npy_files [ i ] . stat () . st_size else : # 'ram' ( self . ims [ i ], self . im_hw0 [ i ], self . im_hw [ i ], ) = x # im, hw_orig, hw_resized = load_image(self, i) gb += self . ims [ i ] . nbytes pbar . desc = f \" { prefix } Caching images ( { gb / 1E9 : .1f } GB { cache_images } )\" pbar . close ()","title":"4.1 init"},{"location":"source_code_interpretation/utils/dataloaders_py.html#42-cache_labels","text":"\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u52a0\u8f7d\u6587\u4ef6\u8def\u5f84\u4e2d\u7684label\u4fe1\u606f\u751f\u6210cache\u6587\u4ef6\u3002cache\u6587\u4ef6\u4e2d\u5305\u62ec\u7684\u4fe1\u606f\u6709\uff1aim_file, l, shape, segments, hash, results, msgs, version\u7b49\uff0c\u5177\u4f53\u770b\u4ee3\u7801\u6ce8\u91ca\u3002 def cache_labels ( self , path = Path ( './labels.cache' ), prefix = '' ): \"\"\"\u7528\u5728__init__\u51fd\u6570\u4e2d cache\u6570\u636e\u96c6label \u52a0\u8f7dlabel\u4fe1\u606f\u751f\u6210cache\u6587\u4ef6 Cache dataset labels, check images and read shapes :params path: cache\u6587\u4ef6\u4fdd\u5b58\u5730\u5740 :params prefix: \u65e5\u5fd7\u5934\u90e8\u4fe1\u606f(\u5f69\u6253\u9ad8\u4eae\u90e8\u5206) :return x: cache\u4e2d\u4fdd\u5b58\u7684\u5b57\u5178 \u5305\u62ec\u7684\u4fe1\u606f\u6709: x[im_file] = [l, shape, segments] \u4e00\u5f20\u56fe\u7247\u4e00\u4e2alabel\u76f8\u5bf9\u5e94\u7684\u4fdd\u5b58\u5230x, \u6700\u7ec8x\u4f1a\u4fdd\u5b58\u6240\u6709\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84\u3001gt\u6846\u7684\u4fe1\u606f\u3001\u5f62\u72b6shape\u3001\u6240\u6709\u7684\u591a\u8fb9\u5f62gt\u4fe1\u606f im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 l: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, cls+xywh(normalized)] shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape segments: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u6240\u6709gt\u7684label\u4fe1\u606f(\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] hash: \u5f53\u524d\u56fe\u7247\u548clabel\u6587\u4ef6\u7684hash\u503c 1 results: \u627e\u5230\u7684label\u4e2a\u6570nf, \u4e22\u5931label\u4e2a\u6570nm, \u7a7alabel\u4e2a\u6570ne, \u7834\u635flabel\u4e2a\u6570nc, \u603bimg/label\u4e2a\u6570len(self.img_files) msgs: \u6240\u6709\u6570\u636e\u96c6\u7684msgs\u4fe1\u606f version: \u5f53\u524dcache version \"\"\" x = {} # \u521d\u59cb\u5316\u6700\u7ec8cache\u4e2d\u4fdd\u5b58\u7684\u5b57\u5178dict # \u521d\u59cb\u5316number missing, found, empty, corrupt, messages # \u521d\u59cb\u5316\u6574\u4e2a\u6570\u636e\u96c6: \u6f0f\u6389\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u627e\u5230\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u7a7a\u7684\u6807\u7b7e(label)\u603b\u6570\u91cf, \u9519\u8bef\u6807\u7b7e(label)\u603b\u6570\u91cf, \u6240\u6709\u9519\u8bef\u4fe1\u606f nm , nf , ne , nc , msgs = 0 , 0 , 0 , 0 , [] desc = f \" { prefix } Scanning ' { path . parent / path . stem } ' images and labels...\" # \u65e5\u5fd7 # \u591a\u8fdb\u7a0b\u8c03\u7528verify_image_label\u51fd\u6570 with Pool ( num_threads ) as pool : # \u5b9a\u4e49pbar\u8fdb\u5ea6\u6761 # pool.imap_unordered: \u5bf9\u5927\u91cf\u6570\u636e\u904d\u5386\u591a\u8fdb\u7a0b\u8ba1\u7b97 \u8fd4\u56de\u4e00\u4e2a\u8fed\u4ee3\u5668 # \u628aself.img_files, self.label_files, repeat(prefix) list\u4e2d\u7684\u503c\u4f5c\u4e3a\u53c2\u6570\u4f9d\u6b21\u9001\u5165(\u4e00\u6b21\u9001\u4e00\u4e2a)verify_image_label\u51fd\u6570 pbar = tqdm ( pool . imap_unordered ( verify_image_label , zip ( self . img_files , self . label_files , repeat ( prefix ))), desc = desc , total = len ( self . img_files )) # im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 # l: [gt_num, cls+xywh(normalized)] # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u539flabel(\u5168\u90e8\u662f\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e) # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u7ecf\u8fc7segments2boxes\u5904\u7406\u597d\u7684\u6807\u7b7e(\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e\u4e0d\u5904\u7406 \u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u77e9\u5f62\u6807\u7b7e) # shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape # segments: \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5b58\u50a8None # \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5c31\u628a\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709label\u5b58\u50a8\u5230segments\u4e2d(\u82e5\u5e72\u4e2a\u6b63\u5e38gt \u82e5\u5e72\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] # nm_f(nm): number missing \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u4e22\u5931 \u4e22\u5931=1 \u5b58\u5728=0 # nf_f(nf): number found \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u5b58\u5728 \u5b58\u5728=1 \u4e22\u5931=0 # ne_f(ne): number empty \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u662f\u7a7a\u7684 \u7a7a\u7684=1 \u6ca1\u7a7a=0 # nc_f(nc): number corrupt \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u6587\u4ef6\u662f\u5426\u662f\u7834\u635f\u7684 \u7834\u635f\u7684=1 \u6ca1\u7834\u635f=0 # msg: \u8fd4\u56de\u7684msg\u4fe1\u606f label\u6587\u4ef6\u5b8c\u597d=\u2018\u2019 label\u6587\u4ef6\u7834\u635f=warning\u4fe1\u606f for im_file , l , shape , segments , nm_f , nf_f , ne_f , nc_f , msg in pbar : nm += nm_f # \u7d2f\u52a0\u603bnumber missing label nf += nf_f # \u7d2f\u52a0\u603bnumber found label ne += ne_f # \u7d2f\u52a0\u603bnumber empty label nc += nc_f # \u7d2f\u52a0\u603bnumber corrupt label if im_file : x [ im_file ] = [ l , shape , segments ] # \u4fe1\u606f\u5b58\u5165\u5b57\u5178 key=im_file value=[l, shape, segments] if msg : msgs . append ( msg ) # \u5c06msg\u52a0\u5165\u603bmsg pbar . desc = f \" { desc }{ nf } found, { nm } missing, { ne } empty, { nc } corrupted\" # \u65e5\u5fd7 pbar . close () # \u5173\u95ed\u8fdb\u5ea6\u6761 # \u65e5\u5fd7\u6253\u5370\u6240\u6709msg\u4fe1\u606f if msgs : logging . info ( ' \\n ' . join ( msgs )) # \u4e00\u5f20label\u90fd\u6ca1\u627e\u5230 \u65e5\u5fd7\u6253\u5370help_url\u4e0b\u8f7d\u5730\u5740 if nf == 0 : logging . info ( f ' { prefix } WARNING: No labels found in { path } . See { help_url } ' ) x [ 'hash' ] = get_hash ( self . label_files + self . img_files ) # \u5c06\u5f53\u524d\u56fe\u7247\u548clabel\u6587\u4ef6\u7684hash\u503c\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'results' ] = nf , nm , ne , nc , len ( self . img_files ) # \u5c06nf, nm, ne, nc, len(self.img_files)\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'msgs' ] = msgs # \u5c06\u6240\u6709\u6570\u636e\u96c6\u7684msgs\u4fe1\u606f\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist x [ 'version' ] = 0.3 # \u5c06\u5f53\u524dcache version\u5b58\u5165\u6700\u7ec8\u5b57\u5178dist try : torch . save ( x , path ) # save cache to path logging . info ( f ' { prefix } New cache created: { path } ' ) except Exception as e : logging . info ( f ' { prefix } WARNING: Cache directory { path . parent } is not writeable: { e } ' ) # path not writeable return x","title":"4.2 cache_labels"},{"location":"source_code_interpretation/utils/dataloaders_py.html#43-getitem","text":"\u8fd9\u90e8\u5206\u662f\u6570\u636e\u589e\u5f3a\u51fd\u6570\uff0c\u4e00\u822c\u4e00\u6b21\u6027\u6267\u884cbatch_size\u6b21\u3002 def __getitem__ ( self , index ): \"\"\" \u8fd9\u90e8\u5206\u662f\u6570\u636e\u589e\u5f3a\u51fd\u6570\uff0c\u4e00\u822c\u4e00\u6b21\u6027\u6267\u884cbatch_size\u6b21\u3002 \u8bad\u7ec3 \u6570\u636e\u589e\u5f3a: mosaic(random_perspective) + hsv + \u4e0a\u4e0b\u5de6\u53f3\u7ffb\u8f6c \u6d4b\u8bd5 \u6570\u636e\u589e\u5f3a: letterbox :return torch.from_numpy(img): \u8fd9\u4e2aindex\u7684\u56fe\u7247\u6570\u636e(\u589e\u5f3a\u540e) [3, 640, 640] :return labels_out: \u8fd9\u4e2aindex\u56fe\u7247\u7684gt label [6, 6] = [gt_num, 0+class+xywh(normalized)] :return self.img_files[index]: \u8fd9\u4e2aindex\u56fe\u7247\u7684\u8def\u5f84\u5730\u5740 :return shapes: \u8fd9\u4e2abatch\u7684\u56fe\u7247\u7684shapes \u6d4b\u8bd5\u65f6(\u77e9\u5f62\u8bad\u7ec3)\u624d\u6709 \u9a8c\u8bc1\u65f6\u4e3aNone for COCO mAP rescaling \"\"\" # \u8fd9\u91cc\u53ef\u4ee5\u901a\u8fc7\u4e09\u79cd\u5f62\u5f0f\u83b7\u53d6\u8981\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u56fe\u7247index linear, shuffled, or image_weights index = self . indices [ index ] # linear, shuffled, or image_weights hyp = self . hyp # \u8d85\u53c2 \u5305\u542b\u4f17\u591a\u6570\u636e\u589e\u5f3a\u8d85\u53c2 mosaic = self . mosaic and random . random () < hyp [ \"mosaic\" ] # mosaic\u589e\u5f3a \u5bf9\u56fe\u50cf\u8fdb\u884c4\u5f20\u56fe\u62fc\u63a5\u8bad\u7ec3 \u4e00\u822c\u8bad\u7ec3\u65f6\u8fd0\u884c # mosaic + MixUp if mosaic : # Load mosaic img , labels = self . load_mosaic ( index ) shapes = None # MixUp augmentation if random . random () < hyp [ \"mixup\" ]: img , labels = mixup ( img , labels , * self . load_mosaic ( random . randint ( 0 , self . n - 1 ))) else : # Load image # \u8f7d\u5165\u56fe\u7247 \u8f7d\u5165\u56fe\u7247\u540e\u8fd8\u4f1a\u8fdb\u884c\u4e00\u6b21resize \u5c06\u5f53\u524d\u56fe\u7247\u7684\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u7684\u5927\u5c0f(512), \u8f83\u5c0f\u8fb9\u540c\u6bd4\u4f8b\u7f29\u653e # load image img=(343, 512, 3)=(h, w, c) (h0, w0)=(335, 500) numpy index=4 # img: resize\u540e\u7684\u56fe\u7247 (h0, w0): \u539f\u59cb\u56fe\u7247\u7684hw (h, w): resize\u540e\u7684\u56fe\u7247\u7684hw # \u8fd9\u4e00\u6b65\u662f\u5c06(335, 500, 3) resize-> (343, 512, 3) img , ( h0 , w0 ), ( h , w ) = self . load_image ( index ) # Letterbox # letterbox\u4e4b\u524d\u786e\u5b9a\u8fd9\u5f20\u5f53\u524d\u56fe\u7247letterbox\u4e4b\u540e\u7684shape # \u5982\u679c\u4e0d\u7528self.rect\u77e9\u5f62\u8bad\u7ec3shape\u5c31\u662fself.img_size # \u5982\u679c\u4f7f\u7528self.rect\u77e9\u5f62\u8bad\u7ec3shape\u5c31\u662f\u5f53\u524dbatch\u7684shape # \u56e0\u4e3a\u77e9\u5f62\u8bad\u7ec3\u7684\u8bdd\u6211\u4eec\u6574\u4e2abatch\u7684shape\u5fc5\u987b\u7edf\u4e00(\u5728__init__\u51fd\u6570\u7b2c6\u8282\u5185\u5bb9) shape = self . batch_shapes [ self . batch [ index ]] if self . rect else self . img_size # final letterboxed shape img , ratio , pad = letterbox ( img , shape , auto = False , scaleup = self . augment ) shapes = ( h0 , w0 ), (( h / h0 , w / w0 ), pad ) # for COCO mAP rescaling labels = self . labels [ index ] . copy () if labels . size : # normalized xywh to pixel xyxy format labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], ratio [ 0 ] * w , ratio [ 1 ] * h , padw = pad [ 0 ], padh = pad [ 1 ]) if self . augment : # random_perspective\u589e\u5f3a: \u968f\u673a\u5bf9\u56fe\u7247\u8fdb\u884c\u65cb\u8f6c\uff0c\u5e73\u79fb\uff0c\u7f29\u653e\uff0c\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362 img , labels = random_perspective ( img , labels , degrees = hyp [ \"degrees\" ], translate = hyp [ \"translate\" ], scale = hyp [ \"scale\" ], shear = hyp [ \"shear\" ], perspective = hyp [ \"perspective\" ], ) nl = len ( labels ) # number of labels if nl : labels [:, 1 : 5 ] = xyxy2xywhn ( labels [:, 1 : 5 ], w = img . shape [ 1 ], h = img . shape [ 0 ], clip = True , eps = 1e-3 ) if self . augment : # Albumentations img , labels = self . albumentations ( img , labels ) nl = len ( labels ) # update after albumentations # HSV color-space \u8272\u57df\u7a7a\u95f4\u589e\u5f3aAugment colorspace augment_hsv ( img , hgain = hyp [ \"hsv_h\" ], sgain = hyp [ \"hsv_s\" ], vgain = hyp [ \"hsv_v\" ]) # Flip up-down if random . random () < hyp [ \"flipud\" ]: img = np . flipud ( img ) if nl : labels [:, 2 ] = 1 - labels [:, 2 ] # Flip left-right \u968f\u673a\u5de6\u53f3\u7ffb\u8f6c if random . random () < hyp [ \"fliplr\" ]: img = np . fliplr ( img ) if nl : labels [:, 1 ] = 1 - labels [:, 1 ] # Cutouts # labels = cutout(img, labels, p=0.5) # nl = len(labels) # update after cutout # 6\u4e2a\u503c\u7684tensor \u521d\u59cb\u5316\u6807\u7b7e\u6846\u5bf9\u5e94\u7684\u56fe\u7247\u5e8f\u53f7, \u914d\u5408\u4e0b\u9762\u7684collate_fn\u4f7f\u7528 labels_out = flow . zeros (( nl , 6 )) if nl : labels_out [:, 1 :] = flow . from_numpy ( labels ) # Convert img = img . transpose (( 2 , 0 , 1 ))[:: - 1 ] # HWC to CHW, BGR to RGB img = np . ascontiguousarray ( img ) # img\u53d8\u6210\u5185\u5b58\u8fde\u7eed\u7684\u6570\u636e \u52a0\u5feb\u8fd0\u7b97 return flow . from_numpy ( img ), labels_out , self . im_files [ index ], shapes","title":"4.3 getitem"},{"location":"source_code_interpretation/utils/dataloaders_py.html#44-collate_fn","text":"collate_fn \u4e00\u822c\u4e5f\u53ef\u4ee5\u53eb\u8c03\u6574\u51fd\u6570,\u5f88\u591a\u4eba\u4ee5\u4e3a\u5199\u5b8c init \u548c getitem \u51fd\u6570\u6570\u636e\u589e\u5f3a\u5c31\u505a\u5b8c\u4e86\uff0c\u6211\u4eec\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u786e\u5199\u5b8c\u8fd9\u4e24\u4e2a\u51fd\u6570\u5c31\u53ef\u4ee5\u4e86\uff0c\u56e0\u4e3a\u7cfb\u7edf\u4e2d\u662f\u7ed9\u6211\u4eec\u5199\u597d\u4e86\u4e00\u4e2acollate_fn\u51fd\u6570\u7684\uff0c\u4f46\u662f\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u6211\u4eec\u5374\u9700\u8981\u91cd\u5199collate_fn\u51fd\u6570\uff0c\u4e0b\u9762\u6211\u4f1a\u4ed4\u7ec6\u7684\u8bb2\u89e3\u8fd9\u6837\u505a\u7684\u539f\u56e0\uff08\u4ee3\u7801\u4e2d\u6ce8\u91ca\uff09\u3002 \u540c\u6837\u5728create_dataloader\u4e2d\u751f\u6210dataloader\u65f6\u8c03\u7528\uff1a @staticmethod def collate_fn4 ( batch ): \"\"\"\u540c\u6837\u5728create_dataloader\u4e2d\u751f\u6210dataloader\u65f6\u8c03\u7528\uff1a \u8fd9\u91cc\u662fyolo-v5\u4f5c\u8005\u5b9e\u9a8c\u6027\u7684\u4e00\u4e2a\u4ee3\u7801 quad-collate function \u5f53train.py\u7684opt\u53c2\u6570quad=True \u5219\u8c03\u7528collate_fn4\u4ee3\u66ffcollate_fn \u4f5c\u7528: \u5982\u4e4b\u524d\u7528collate_fn\u53ef\u4ee5\u8fd4\u56de\u56fe\u7247[16, 3, 640, 640] \u7ecf\u8fc7collate_fn4\u5219\u8fd4\u56de\u56fe\u7247[4, 3, 1280, 1280] \u5c064\u5f20mosaic\u56fe\u7247[1, 3, 640, 640]\u5408\u6210\u4e00\u5f20\u5927\u7684mosaic\u56fe\u7247[1, 3, 1280, 1280] \u5c06\u4e00\u4e2abatch\u7684\u56fe\u7247\u6bcf\u56db\u5f20\u5904\u7406, 0.5\u7684\u6982\u7387\u5c06\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5230\u4e00\u5f20\u5927\u56fe\u4e0a\u8bad\u7ec3, 0.5\u6982\u7387\u76f4\u63a5\u5c06\u67d0\u5f20\u56fe\u7247\u4e0a\u91c7\u6837\u4e24\u500d\u8bad\u7ec3 \"\"\" # img: \u6574\u4e2abatch\u7684\u56fe\u7247 [16, 3, 640, 640] # label: \u6574\u4e2abatch\u7684label\u6807\u7b7e [num_target, img_index+class_index+xywh(normalized)] # path: \u6574\u4e2abatch\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84 # shapes: (h0, w0), ((h / h0, w / w0), pad) for COCO mAP rescaling img , label , path , shapes = zip ( * batch ) # transposed n = len ( shapes ) // 4 # collate_fn4\u5904\u7406\u540e\u8fd9\u4e2abatch\u4e2d\u56fe\u7247\u7684\u4e2a\u6570 im4 , label4 , path4 , shapes4 = [], [], path [: n ], shapes [: n ] # \u521d\u59cb\u5316 ho = flow . tensor ([[ 0.0 , 0 , 0 , 1 , 0 , 0 ]]) wo = flow . tensor ([[ 0.0 , 0 , 1 , 0 , 0 , 0 ]]) s = flow . tensor ([[ 1 , 1 , 0.5 , 0.5 , 0.5 , 0.5 ]]) # scale for i in range ( n ): # zidane flow.zeros(16,3,720,1280) # BCHW i *= 4 # \u91c7\u6837 [0, 4, 8, 16] if random . random () < 0.5 : # \u968f\u673a\u6570\u5c0f\u4e8e0.5\u5c31\u76f4\u63a5\u5c06\u67d0\u5f20\u56fe\u7247\u4e0a\u91c7\u6837\u4e24\u500d\u8bad\u7ec3 im = F . interpolate ( img [ i ] . unsqueeze ( 0 ) . float (), scale_factor = 2.0 , mode = \"bilinear\" , align_corners = False ,)[ 0 ] . type ( img [ i ] . type ()) lb = label [ i ] else : # \u968f\u673a\u6570\u5927\u4e8e0.5\u5c31\u5c06\u56db\u5f20\u56fe\u7247(mosaic\u540e\u7684)\u62fc\u63a5\u5230\u4e00\u5f20\u5927\u56fe\u4e0a\u8bad\u7ec3 im = flow . cat ( ( flow . cat (( img [ i ], img [ i + 1 ]), 1 ), flow . cat (( img [ i + 2 ], img [ i + 3 ]), 1 ), ), 2 , ) lb = flow . cat (( label [ i ], label [ i + 1 ] + ho , label [ i + 2 ] + wo , label [ i + 3 ] + ho + wo ), 0 ) * s im4 . append ( im ) label4 . append ( lb ) # \u540e\u9762\u8fd4\u56de\u7684\u90e8\u5206\u548ccollate_fn\u5c31\u5dee\u4e0d\u591a\u4e86 \u539f\u56e0\u548c\u89e3\u91ca\u90fd\u5199\u5728\u4e0a\u4e00\u4e2a\u51fd\u6570\u4e86 \u81ea\u5df1debug\u770b\u4e00\u4e0b\u5427 for i , lb in enumerate ( label4 ): lb [:, 0 ] = i # add target image index for build_targets() return flow . stack ( im4 , 0 ), flow . cat ( label4 , 0 ), path4 , shapes4","title":"4.4 collate_fn"},{"location":"source_code_interpretation/utils/dataloaders_py.html#5-img2label_paths","text":"\u8fd9\u4e2a\u6587\u4ef6\u662f\u6839\u636e\u6570\u636e\u96c6\u4e2d\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709labels\u5bf9\u5e94\u7684\u8def\u5f84\u3002 \u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__init__\u51fd\u6570\u4e2d\u3002 def img2label_paths ( img_paths ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__init__\u51fd\u6570\u4e2d \u6839\u636eimgs\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u5bf9\u5e94labels\u7684\u8def\u5f84 Define label paths as a function of image paths :params img_paths: {list: 50} \u6574\u4e2a\u6570\u636e\u96c6\u7684\u56fe\u7247\u76f8\u5bf9\u8def\u5f84 \u4f8b\u5982: '..\\\\datasets\\\\VOC\\\\images\\\\train2007\\\\000012.jpg' => '..\\\\datasets\\\\VOC\\\\labels\\\\train2007\\\\000012.jpg' \"\"\" # \u56e0\u4e3apython\u662f\u8de8\u5e73\u53f0\u7684,\u5728Windows\u4e0a,\u6587\u4ef6\u7684\u8def\u5f84\u5206\u9694\u7b26\u662f'\\',\u5728Linux\u4e0a\u662f'/' # \u4e3a\u4e86\u8ba9\u4ee3\u7801\u5728\u4e0d\u540c\u7684\u5e73\u53f0\u4e0a\u90fd\u80fd\u8fd0\u884c\uff0c\u90a3\u4e48\u8def\u5f84\u5e94\u8be5\u5199'\\'\u8fd8\u662f'/'\u5462\uff1f os.sep\u6839\u636e\u4f60\u6240\u5904\u7684\u5e73\u53f0, \u81ea\u52a8\u91c7\u7528\u76f8\u5e94\u7684\u5206\u9694\u7b26\u53f7 # sa: '\\\\images\\\\' sb: '\\\\labels\\\\' sa , sb = os . sep + 'images' + os . sep , os . sep + 'labels' + os . sep # /images/, /labels/ substrings # \u628aimg_paths\u4e2d\u6240\u4ee5\u56fe\u7247\u8def\u5f84\u4e2d\u7684images\u66ff\u6362\u4e3alabels return [ sb . join ( x . rsplit ( sa , 1 )) . rsplit ( '.' , 1 )[ 0 ] + '.txt' for x in img_paths ]","title":"5. img2label_paths"},{"location":"source_code_interpretation/utils/dataloaders_py.html#6-verify_image_label","text":"\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u68c0\u67e5\u6bcf\u4e00\u5f20\u56fe\u7247\u548c\u6bcf\u4e00\u5f20label\u6587\u4ef6\u662f\u5426\u5b8c\u597d\u3002 \u2003 \u56fe\u7247\u6587\u4ef6: \u68c0\u67e5\u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027 \u2003 label\u6587\u4ef6: \u68c0\u67e5\u6bcf\u4e2agt\u5fc5\u987b\u662f\u77e9\u5f62(\u6bcf\u884c\u90fd\u5f97\u662f5\u4e2a\u6570 class+xywh) + \u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 + \u6807\u7b7e\u5750\u6807xywh\u662f\u5426\u5f52\u4e00\u5316 + \u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 verify_image_label\u51fd\u6570\u4ee3\u7801\uff1a def verify_image_label ( args ): \"\"\"\u7528\u5728cache_labels\u51fd\u6570\u4e2d \u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u6bcf\u5f20\u56fe\u7247\u548c\u6bcf\u5f20laebl\u662f\u5426\u5b8c\u597d \u56fe\u7247\u6587\u4ef6: \u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027 label\u6587\u4ef6: \u6bcf\u4e2agt\u5fc5\u987b\u662f\u77e9\u5f62(\u6bcf\u884c\u90fd\u5f97\u662f5\u4e2a\u6570 class+xywh) + \u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 + \u6807\u7b7e\u5750\u6807xywh\u662f\u5426\u5f52\u4e00\u5316 + \u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 :params im_file: \u6570\u636e\u96c6\u4e2d\u4e00\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 :params lb_file: \u6570\u636e\u96c6\u4e2d\u4e00\u5f20\u56fe\u7247\u7684label\u76f8\u5bf9\u8def\u5f84 :params prefix: \u65e5\u5fd7\u5934\u90e8\u4fe1\u606f(\u5f69\u6253\u9ad8\u4eae\u90e8\u5206) :return im_file: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684path\u76f8\u5bf9\u8def\u5f84 :return l: [gt_num, cls+xywh(normalized)] \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u539flabel(\u5168\u90e8\u662f\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e) \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e l\u5c31\u5b58\u50a8\u7ecf\u8fc7segments2boxes\u5904\u7406\u597d\u7684\u6807\u7b7e(\u6b63\u5e38\u77e9\u5f62\u6807\u7b7e\u4e0d\u5904\u7406 \u591a\u8fb9\u5f62\u6807\u7b7e\u8f6c\u5316\u4e3a\u77e9\u5f62\u6807\u7b7e) :return shape: \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684\u5f62\u72b6 shape :return segments: \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6ca1\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5b58\u50a8None \u5982\u679c\u8fd9\u5f20\u56fe\u7247\u6709\u4e00\u4e2asegment\u591a\u8fb9\u5f62\u6807\u7b7e \u5c31\u628a\u8fd9\u5f20\u56fe\u7247\u7684\u6240\u6709label\u5b58\u50a8\u5230segments\u4e2d(\u82e5\u5e72\u4e2a\u6b63\u5e38gt \u82e5\u5e72\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e) [gt_num, xy1...] :return nm: number missing \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u4e22\u5931 \u4e22\u5931=1 \u5b58\u5728=0 :return nf: number found \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u5b58\u5728 \u5b58\u5728=1 \u4e22\u5931=0 :return ne: number empty \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u662f\u5426\u662f\u7a7a\u7684 \u7a7a\u7684=1 \u6ca1\u7a7a=0 :return nc: number corrupt \u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u7684label\u6587\u4ef6\u662f\u5426\u662f\u7834\u635f\u7684 \u7834\u635f\u7684=1 \u6ca1\u7834\u635f=0 :return msg: \u8fd4\u56de\u7684msg\u4fe1\u606f label\u6587\u4ef6\u5b8c\u597d=\u2018\u2019 label\u6587\u4ef6\u7834\u635f=warning\u4fe1\u606f \"\"\" # Verify one image-label pair im_file , lb_file , prefix = args nm , nf , ne , nc , msg , segments = ( 0 , 0 , 0 , 0 , \"\" , [], ) # number (missing, found, empty, corrupt), message, segments try : # verify images \u68c0\u67e5\u8fd9\u5f20\u56fe\u7247(\u5185\u5bb9\u3001\u683c\u5f0f\u3001\u5927\u5c0f\u3001\u5b8c\u6574\u6027) verify images im = Image . open ( im_file ) # \u6253\u5f00\u56fe\u7247\u6587\u4ef6 im . verify () # PIL verify \u68c0\u67e5\u56fe\u7247\u5185\u5bb9\u548c\u683c\u5f0f\u662f\u5426\u6b63\u5e38 shape = exif_size ( im ) # image size \u5f53\u524d\u56fe\u7247\u7684\u5927\u5c0f image size # \u56fe\u7247\u5927\u5c0f\u5fc5\u987b\u5927\u4e8e9\u4e2apixels assert ( shape [ 0 ] > 9 ) & ( shape [ 1 ] > 9 ), f \"image size { shape } <10 pixels\" # \u56fe\u7247\u683c\u5f0f\u5fc5\u987b\u5728img_format\u4e2d assert im . format . lower () in IMG_FORMATS , f \"invalid image format { im . format } \" if im . format . lower () in ( \"jpg\" , \"jpeg\" ): # \u68c0\u67e5jpg\u683c\u5f0f\u6587\u4ef6 with open ( im_file , \"rb\" ) as f : # f.seek: -2 \u504f\u79fb\u91cf \u5411\u6587\u4ef6\u5934\u65b9\u5411\u4e2d\u79fb\u52a8\u7684\u5b57\u8282\u6570 2 \u76f8\u5bf9\u4f4d\u7f6e \u4ece\u6587\u4ef6\u5c3e\u5f00\u59cb\u504f\u79fb f . seek ( - 2 , 2 ) # f.read(): \u8bfb\u53d6\u56fe\u7247\u6587\u4ef6 \u6307\u4ee4: \\xff\\xd9 \u68c0\u6d4b\u6574\u5f20\u56fe\u7247\u662f\u5426\u5b8c\u6574 \u5982\u679c\u4e0d\u5b8c\u6574\u5c31\u8fd4\u56decorrupted JPEG if f . read () != b \" \\xff\\xd9 \" : # corrupt JPEG ImageOps . exif_transpose ( Image . open ( im_file )) . save ( im_file , \"JPEG\" , subsampling = 0 , quality = 100 ) msg = f \" { prefix } WARNING: { im_file } : corrupt JPEG restored and saved\" # verify labels if os . path . isfile ( lb_file ): nf = 1 # label found with open ( lb_file ) as f : # \u8bfb\u53d6\u5f53\u524dlabel\u6587\u4ef6\u7684\u6bcf\u4e00\u884c: \u6bcf\u4e00\u884c\u90fd\u662f\u5f53\u524d\u56fe\u7247\u7684\u4e00\u4e2agt lb = [ x . split () for x in f . read () . strip () . splitlines () if len ( x )] # any() \u51fd\u6570\u7528\u4e8e\u5224\u65ad\u7ed9\u5b9a\u7684\u53ef\u8fed\u4ee3\u53c2\u6570 \u662f\u5426\u5168\u90e8\u4e3aFalse,\u5219\u8fd4\u56de False; \u5982\u679c\u6709\u4e00\u4e2a\u4e3a True,\u5219\u8fd4\u56deTrue # \u5982\u679c\u5f53\u524d\u56fe\u7247\u7684label\u6587\u4ef6\u67d0\u4e00\u5217\u6570\u5927\u4e8e8, \u5219\u8ba4\u4e3alabel\u662f\u5b58\u5728segment\u7684polygon\u70b9(\u591a\u8fb9\u5f62) # \u5c31\u4e0d\u662f\u77e9\u9635 \u5219\u5c06label\u4fe1\u606f\u5b58\u5165segment\u4e2d if any ( len ( x ) > 6 for x in lb ): # is segment # \u5f53\u524d\u56fe\u7247\u4e2d\u6240\u6709gt\u6846\u7684\u7c7b\u522b classes = np . array ([ x [ 0 ] for x in lb ], dtype = np . float32 ) # \u83b7\u5f97\u8fd9\u5f20\u56fe\u4e2d\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) # \u56e0\u4e3asegment\u6807\u7b7e\u53ef\u4ee5\u662f\u4e0d\u540c\u957f\u5ea6\uff0c\u6240\u4ee5\u8fd9\u91ccsegments\u662f\u4e00\u4e2a\u5217\u8868 [gt_num, xy1...(normalized)] segments = [ np . array ( x [ 1 :], dtype = np . float32 ) . reshape ( - 1 , 2 ) for x in lb ] # (cls, xy1...) # \u83b7\u5f97\u8fd9\u5f20\u56fe\u4e2d\u6240\u6709gt\u6846\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegment\u591a\u8fb9\u5f62\u6807\u7b7e) # segments(\u591a\u8fb9\u5f62) -> bbox(\u6b63\u65b9\u5f62), \u5f97\u5230\u65b0\u6807\u7b7e [gt_num, cls+xywh(normalized)] lb = np . concatenate (( classes . reshape ( - 1 , 1 ), segments2boxes ( segments )), 1 ) # (cls, xywh) lb = np . array ( lb , dtype = np . float32 ) nl = len ( lb ) if nl : # \u5224\u65ad\u6807\u7b7e\u662f\u5426\u6709\u4e94\u5217 assert lb . shape [ 1 ] == 5 , f \"labels require 5 columns, { lb . shape [ 1 ] } columns detected\" # \u5224\u65ad\u6807\u7b7e\u662f\u5426\u5168\u90e8>=0 assert ( lb >= 0 ) . all (), f \"negative label values { lb [ lb < 0 ] } \" # \u5224\u65ad\u6807\u7b7e\u4e2d\u662f\u5426\u6709\u91cd\u590d\u7684\u5750\u6807 assert ( lb [:, 1 :] <= 1 ) . all (), f \"non-normalized or out of bounds coordinates { lb [:, 1 :][ lb [:, 1 :] > 1 ] } \" _ , i = np . unique ( lb , axis = 0 , return_index = True ) if len ( i ) < nl : # duplicate row check lb = lb [ i ] # remove duplicates if segments : segments = segments [ i ] msg = f \" { prefix } WARNING: { im_file } : { nl - len ( i ) } duplicate labels removed\" else : ne = 1 # label empty l.shape[0] == 0\u5219\u4e3a\u7a7a\u7684\u6807\u7b7e\uff0cne=1 lb = np . zeros (( 0 , 5 ), dtype = np . float32 ) else : nm = 1 # label missing lb = np . zeros (( 0 , 5 ), dtype = np . float32 ) return im_file , lb , shape , segments , nm , nf , ne , nc , msg except Exception as e : nc = 1 msg = f \" { prefix } WARNING: { im_file } : ignoring corrupt image/label: { e } \" return [ None , None , None , None , nm , nf , ne , nc , msg ]","title":"6. verify_image_label"},{"location":"source_code_interpretation/utils/dataloaders_py.html#7-load_image","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u6839\u636e\u56fe\u7247index\uff0c\u4eceself\u6216\u8005\u4ece\u5bf9\u5e94\u56fe\u7247\u8def\u5f84\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247 \u5e76\u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55\u3002 \u4f1a\u88ab\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u548cload_mosaic\u6a21\u5757\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247\uff1a load_image\u51fd\u6570\u4ee3\u7801\uff1a def load_image ( self , i ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u548cload_mosaic\u6a21\u5757\u4e2d \u4eceself\u6216\u8005\u4ece\u5bf9\u5e94\u56fe\u7247\u8def\u5f84\u4e2d\u8f7d\u5165\u5bf9\u5e94index\u7684\u56fe\u7247 \u5e76\u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55 loads 1 image from dataset, returns img, original hw, resized hw :params self: \u4e00\u822c\u662f\u5bfc\u5165LoadImagesAndLabels\u4e2d\u7684self :param index: \u5f53\u524d\u56fe\u7247\u7684index :return: img: resize\u540e\u7684\u56fe\u7247 (h0, w0): hw_original \u539f\u56fe\u7684hw img.shape[:2]: hw_resized resize\u540e\u7684\u56fe\u7247hw(hw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55) \"\"\" im , f , fn = ( self . ims [ i ], self . im_files [ i ], self . npy_files [ i ], ) if im is None : # not cached in RAM if fn . exists (): # load npy im = np . load ( fn ) else : # read image im = cv2 . imread ( f ) # BGR assert im is not None , f \"Image Not Found { f } \" h0 , w0 = im . shape [: 2 ] # orig hw r = self . img_size / max ( h0 , w0 ) # ratio if r != 1 : # if sizes are not equal # cv2.INTER_AREA: \u57fa\u4e8e\u533a\u57df\u50cf\u7d20\u5173\u7cfb\u7684\u4e00\u79cd\u91cd\u91c7\u6837\u6216\u8005\u63d2\u503c\u65b9\u5f0f.\u8be5\u65b9\u6cd5\u662f\u56fe\u50cf\u62bd\u53d6\u7684\u9996\u9009\u65b9\u6cd5, \u5b83\u53ef\u4ee5\u4ea7\u751f\u66f4\u5c11\u7684\u6ce2\u7eb9 # cv2.INTER_LINEAR: \u53cc\u7ebf\u6027\u63d2\u503c,\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4f7f\u7528\u8be5\u65b9\u5f0f\u8fdb\u884c\u63d2\u503c \u6839\u636eratio\u9009\u62e9\u4e0d\u540c\u7684\u63d2\u503c\u65b9\u5f0f # \u5c06\u539f\u56fe\u4e2dhw\u4e2d\u8f83\u5927\u8005\u6269\u5c55\u5230self.img_size, \u8f83\u5c0f\u8005\u540c\u6bd4\u4f8b\u6269\u5c55 interp = cv2 . INTER_LINEAR if ( self . augment or r > 1 ) else cv2 . INTER_AREA im = cv2 . resize ( im , ( int ( w0 * r ), int ( h0 * r )), interpolation = interp ) return im , ( h0 , w0 ), im . shape [: 2 ] # im, hw_original, hw_resized return self . ims [ i ], self . im_hw0 [ i ], self . im_hw [ i ] # im, hw_original, hw_resized","title":"7. load_image"},{"location":"source_code_interpretation/utils/dataloaders_py.html#8-augment_hsv","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5173\u4e8e\u56fe\u7247\u7684\u8272\u57df\u589e\u5f3a\u6a21\u5757\uff0c\u56fe\u7247\u5e76\u4e0d\u53d1\u751f\u79fb\u52a8\uff0c\u6240\u6709\u4e0d\u9700\u8981\u6539\u53d8label\uff0c\u53ea\u9700\u8981 img \u589e\u5f3a\u5373\u53ef\u3002 augment_hsv\u6a21\u5757\u4ee3\u7801\uff1a def augment_hsv ( img , hgain = 0.5 , sgain = 0.5 , vgain = 0.5 ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 hsv\u8272\u57df\u589e\u5f3a \u5904\u7406\u56fe\u50cfhsv\uff0c\u4e0d\u5bf9label\u8fdb\u884c\u4efb\u4f55\u5904\u7406 :param img: \u5f85\u5904\u7406\u56fe\u7247 BGR [736, 736] :param hgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684h\u901a\u9053 :param sgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684s\u901a\u9053 :param vgain: h\u901a\u9053\u8272\u57df\u53c2\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684v\u901a\u9053 :return: \u8fd4\u56dehsv\u589e\u5f3a\u540e\u7684\u56fe\u7247 img \"\"\" if hgain or sgain or vgain : # \u968f\u673a\u53d6-1\u52301\u4e09\u4e2a\u5b9e\u6570\uff0c\u4e58\u4ee5hyp\u4e2d\u7684hsv\u4e09\u901a\u9053\u7684\u7cfb\u6570 \u7528\u4e8e\u751f\u6210\u65b0\u7684hsv\u901a\u9053 r = np . random . uniform ( - 1 , 1 , 3 ) * [ hgain , sgain , vgain ] + 1 # random gains hue , sat , val = cv2 . split ( cv2 . cvtColor ( img , cv2 . COLOR_BGR2HSV )) # \u56fe\u50cf\u7684\u901a\u9053\u62c6\u5206 h s v dtype = img . dtype # uint8 x = np . arange ( 0 , 256 , dtype = r . dtype ) lut_hue = (( x * r [ 0 ]) % 180 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684h\u901a\u9053 lut_sat = np . clip ( x * r [ 1 ], 0 , 255 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684s\u901a\u9053 lut_val = np . clip ( x * r [ 2 ], 0 , 255 ) . astype ( dtype ) # \u751f\u6210\u65b0\u7684v\u901a\u9053 # \u56fe\u50cf\u7684\u901a\u9053\u5408\u5e76 img_hsv=h+s+v \u968f\u673a\u8c03\u6574hsv\u4e4b\u540e\u91cd\u65b0\u7ec4\u5408hsv\u901a\u9053 # cv2.LUT(hue, lut_hue) \u901a\u9053\u8272\u57df\u53d8\u6362 \u8f93\u5165\u53d8\u6362\u524d\u901a\u9053hue \u548c\u53d8\u6362\u540e\u901a\u9053lut_hue img_hsv = cv2 . merge (( cv2 . LUT ( hue , lut_hue ), cv2 . LUT ( sat , lut_sat ), cv2 . LUT ( val , lut_val ))) # no return needed dst:\u8f93\u51fa\u56fe\u50cf cv2 . cvtColor ( img_hsv , cv2 . COLOR_HSV2BGR , dst = img ) # no return needed hsv->bgr \u8fd8\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e2ahsv\u589e\u5f3a\u662f\u968f\u673a\u751f\u6210\u5404\u4e2a\u8272\u57df\u53c2\u6570\u7684\uff0c\u6240\u4ee5\u6bcf\u6b21\u589e\u5f3a\u7684\u6548\u679c\u90fd\u662f\u4e0d\u540c\u7684\uff1a \u8fd9\u4e2a\u51fd\u6570\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570\u4e2d\uff1a \u53e6\u5916\uff0c\u8fd9\u91cc\u6d89\u53ca\u5230\u7684\u4e09\u4e2a\u53d8\u91cf\u6765\u81eahyp.yaml\u8d85\u53c2\u6587\u4ef6\uff1a","title":"8. augment_hsv"},{"location":"source_code_interpretation/utils/dataloaders_py.html#9-load_mosaicload_mosaic9","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u90fd\u662fmosaic\u6570\u636e\u589e\u5f3a\uff0c\u53ea\u4e0d\u8fc7load_mosaic\u51fd\u6570\u662f\u62fc\u63a5\u56db\u5f20\u56fe\uff0c\u800cload_mosaic9\u51fd\u6570\u662f\u62fc\u63a5\u4e5d\u5f20\u56fe\u3002 \u66f4\u591a\u8bf7\u53c2\u9605 \u300amosaic \u89e3\u8bfb\u300b","title":"9. load_mosaic\u3001load_mosaic9"},{"location":"source_code_interpretation/utils/dataloaders_py.html#91-load_mosaic","text":"\u8fd9\u4e2a\u6a21\u5757\u5c31\u662f\u5f88\u6709\u540d\u7684mosaic\u589e\u5f3a\u6a21\u5757\uff0c\u51e0\u4e4e\u8bad\u7ec3\u7684\u65f6\u5019\u90fd\u4f1a\u7528\u5b83\uff0c\u53ef\u4ee5\u663e\u8457\u7684\u63d0\u9ad8\u5c0f\u6837\u672c\u7684mAP\u3002 \u4ee3\u7801\u662f\u6570\u636e\u589e\u5f3a\u91cc\u9762\u6700\u96be\u7684, \u4e5f\u662f\u6700\u6709\u4ef7\u503c\u7684\uff0cmosaic\u662f\u975e\u5e38\u975e\u5e38\u6709\u7528\u7684\u6570\u636e\u589e\u5f3atrick, \u4e00\u5b9a\u8981\u719f\u7ec3\u638c\u63e1\u3002 load_mosaic\u6a21\u5757\u4ee3\u7801\uff1a def load_mosaic ( self , index ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u8fdb\u884cmosaic\u6570\u636e\u589e\u5f3a \u5c06\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d loads images in a 4-mosaic :param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 :return: img4: mosaic\u548c\u968f\u673a\u900f\u89c6\u53d8\u6362\u540e\u7684\u4e00\u5f20\u56fe\u7247 numpy(640, 640, 3) labels4: img4\u5bf9\u5e94\u7684target [M, cls+x1y1x2y2] \"\"\" # labels4: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff084\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegments\u591a\u8fb9\u5f62) # segments4: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff084\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62) labels4 , segments4 = [], [] s = self . img_size # \u4e00\u822c\u7684\u56fe\u7247\u5927\u5c0f # \u968f\u673a\u521d\u59cb\u5316\u62fc\u63a5\u56fe\u50cf\u7684\u4e2d\u5fc3\u70b9\u5750\u6807 [0, s*2]\u4e4b\u95f4\u968f\u673a\u53d62\u4e2a\u6570\u4f5c\u4e3a\u62fc\u63a5\u56fe\u50cf\u7684\u4e2d\u5fc3\u5750\u6807 yc , xc = [ int ( random . uniform ( - x , 2 * s + x )) for x in self . mosaic_border ] # mosaic center x, y # \u4ecedataset\u4e2d\u968f\u673a\u5bfb\u627e\u989d\u5916\u7684\u4e09\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 [14, 26, 2, 16] \u518d\u968f\u673a\u9009\u4e09\u5f20\u56fe\u7247\u7684index indices = [ index ] + random . choices ( self . indices , k = 3 ) # 3 additional image indices # \u904d\u5386\u56db\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 4\u5f20\u4e0d\u540c\u5927\u5c0f\u7684\u56fe\u50cf => 1\u5f20[1472, 1472, 3]\u7684\u56fe\u50cf for i , index in enumerate ( indices ): # load image \u6bcf\u6b21\u62ff\u4e00\u5f20\u56fe\u7247 \u5e76\u5c06\u8fd9\u5f20\u56fe\u7247resize\u5230self.size(h,w) img , _ , ( h , w ) = load_image ( self , index ) # place img in img4 if i == 0 : # top left \u539f\u56fe[375, 500, 3] load_image->[552, 736, 3] hwc # \u521b\u5efa\u9a6c\u8d5b\u514b\u56fe\u50cf [1472, 1472, 3]=[h, w, c] img4 = np . full (( s * 2 , s * 2 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) w=736 h = 552 \u9a6c\u8d5b\u514b\u56fe\u50cf\uff1a(x1a,y1a)\u5de6\u4e0a\u89d2 (x2a,y2a)\u53f3\u4e0b\u89d2 x1a , y1a , x2a , y2a = max ( xc - w , 0 ), max ( yc - h , 0 ), xc , yc # xmin, ymin, xmax, ymax (large image) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e00\u5f20\u56fe\u50cf\u7684\u53f3\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) \u56fe\u50cf\uff1a(x1b,y1b)\u5de6\u4e0a\u89d2 (x2b,y2b)\u53f3\u4e0b\u89d2 x1b , y1b , x2b , y2b = w - ( x2a - x1a ), h - ( y2a - y1a ), w , h # xmin, ymin, xmax, ymax (small image) elif i == 1 : # top right # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = xc , max ( yc - h , 0 ), min ( xc + w , s * 2 ), yc # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e8c\u5f20\u56fe\u50cf\u7684\u5de6\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = 0 , h - ( y2a - y1a ), min ( w , x2a - x1a ), h elif i == 2 : # bottom left # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = max ( xc - w , 0 ), yc , xc , min ( s * 2 , yc + h ) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e09\u5f20\u56fe\u50cf\u7684\u53f3\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = w - ( x2a - x1a ), 0 , w , min ( y2a - y1a , h ) elif i == 3 : # bottom right # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d) x1a , y1a , x2a , y2a = xc , yc , min ( xc + w , s * 2 ), min ( s * 2 , yc + h ) # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u56db\u5f20\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df) x1b , y1b , x2b , y2b = 0 , 0 , min ( w , x2a - x1a ), min ( y2a - y1a , h ) # \u5c06\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u7684\u76f8\u5e94\u4f4d\u7f6e img4[h, w, c] # \u5c06\u56fe\u50cfimg\u7684\u3010(x1b,y1b)\u5de6\u4e0a\u89d2 (x2b,y2b)\u53f3\u4e0b\u89d2\u3011\u533a\u57df\u622a\u53d6\u51fa\u6765\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u7684\u3010(x1a,y1a)\u5de6\u4e0a\u89d2 (x2a,y2a)\u53f3\u4e0b\u89d2\u3011\u533a\u57df img4 [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] # \u8ba1\u7b97pad(\u5f53\u524d\u56fe\u50cf\u8fb9\u754c\u4e0e\u9a6c\u8d5b\u514b\u8fb9\u754c\u7684\u8ddd\u79bb\uff0c\u8d8a\u754c\u7684\u60c5\u51b5padw/padh\u4e3a\u8d1f\u503c) \u7528\u4e8e\u540e\u9762\u7684label\u6620\u5c04 padw = x1a - x1b # \u5f53\u524d\u56fe\u50cf\u4e0e\u9a6c\u8d5b\u514b\u56fe\u50cf\u5728w\u7ef4\u5ea6\u4e0a\u76f8\u5dee\u591a\u5c11 padh = y1a - y1b # \u5f53\u524d\u56fe\u50cf\u4e0e\u9a6c\u8d5b\u514b\u56fe\u50cf\u5728h\u7ef4\u5ea6\u4e0a\u76f8\u5dee\u591a\u5c11 # labels: \u83b7\u53d6\u5bf9\u5e94\u62fc\u63a5\u56fe\u50cf\u7684\u6240\u6709\u6b63\u5e38label\u4fe1\u606f(\u5982\u679c\u6709segments\u591a\u8fb9\u5f62\u4f1a\u88ab\u8f6c\u5316\u4e3a\u77e9\u5f62label) # segments: \u83b7\u53d6\u5bf9\u5e94\u62fc\u63a5\u56fe\u50cf\u7684\u6240\u6709\u4e0d\u6b63\u5e38label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62\u4e5f\u5305\u542b\u6b63\u5e38gt) labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : # normalized xywh normalized to pixel xyxy format labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padw , padh ) segments = [ xyn2xy ( x , w , h , padw , padh ) for x in segments ] labels4 . append ( labels ) # \u66f4\u65b0labels4 segments4 . extend ( segments ) # \u66f4\u65b0segments4 # Concat/clip labels4 \u628alabels4\uff08[(2, 5), (1, 5), (3, 5), (1, 5)] => (7, 5)\uff09\u538b\u7f29\u5230\u4e00\u8d77 labels4 = np . concatenate ( labels4 , 0 ) # \u9632\u6b62\u8d8a\u754c label[:, 1:]\u4e2d\u7684\u6240\u6709\u5143\u7d20\u7684\u503c\uff08\u4f4d\u7f6e\u4fe1\u606f\uff09\u5fc5\u987b\u5728[0, 2*s]\u4e4b\u95f4,\u5c0f\u4e8e0\u5c31\u4ee4\u5176\u7b49\u4e8e0,\u5927\u4e8e2*s\u5c31\u7b49\u4e8e2*s out: \u8fd4\u56de for x in ( labels4 [:, 1 :], * segments4 ): np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5\u524d\u9762\u7684mosaic\u6548\u679c # cv2.imshow(\"mosaic\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (1280, 1280, 3) # \u968f\u673a\u504f\u79fb\u6807\u7b7e\u4e2d\u5fc3\uff0c\u751f\u6210\u65b0\u7684\u6807\u7b7e\u4e0e\u539f\u6807\u7b7e\u7ed3\u5408 replicate # img4, labels4 = replicate(img4, labels4) # # # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5replicate\u6548\u679c # cv2.imshow(\"replicate\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (1280, 1280, 3) # Augment # random_perspective Augment \u968f\u673a\u900f\u89c6\u53d8\u6362 [1280, 1280, 3] => [640, 640, 3] # \u5bf9mosaic\u6574\u5408\u540e\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u88c1\u526a\uff0c\u900f\u89c6\u53d8\u6362\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove # \u6d4b\u8bd5\u4ee3\u7801 \u6d4b\u8bd5mosaic + random_perspective\u968f\u673a\u4eff\u5c04\u53d8\u6362\u6548\u679c # cv2.imshow(\"random_perspective\", img4) # cv2.waitKey(0) # cv2.destroyAllWindows() # print(img4.shape) # (640, 640, 3) return img4 , labels4","title":"9.1 load_mosaic"},{"location":"source_code_interpretation/utils/dataloaders_py.html#92-load_mosaic9","text":"\u8fd9\u4e2a\u6a21\u5757\u662f\u4f5c\u8005\u7684\u5b9e\u9a8c\u6a21\u5757\uff0c\u5c06\u4e5d\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u3002\u603b\u4f53\u4ee3\u7801\u6d41\u7a0b\u548cload_mosaic4\u51e0\u4e4e\u4e00\u6837\uff0c\u770b\u61c2\u4e86load_mosaic4\u518d\u770b\u8fd9\u4e2a\u5c31\u5f88\u7b80\u5355\u4e86\u3001 load_mosaic9\u6a21\u5757\u4ee3\u7801\uff1a def load_mosaic9 ( self , index ): \"\"\"\u7528\u5728LoadImagesAndLabels\u6a21\u5757\u7684__getitem__\u51fd\u6570 \u66ff\u6362mosaic\u6570\u636e\u589e\u5f3a \u5c06\u4e5d\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d loads images in a 9-mosaic :param self: :param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 :return: img9: mosaic\u548c\u4eff\u5c04\u589e\u5f3a\u540e\u7684\u4e00\u5f20\u56fe\u7247 labels9: img9\u5bf9\u5e94\u7684target \"\"\" # labels9: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff089\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u4e0d\u5305\u542bsegments\u591a\u8fb9\u5f62) # segments9: \u7528\u4e8e\u5b58\u653e\u62fc\u63a5\u56fe\u50cf\uff089\u5f20\u56fe\u62fc\u6210\u4e00\u5f20\uff09\u7684label\u4fe1\u606f(\u5305\u542bsegments\u591a\u8fb9\u5f62) labels9 , segments9 = [], [] s = self . img_size # \u4e00\u822c\u7684\u56fe\u7247\u5927\u5c0f(\u4e5f\u662f\u6700\u7ec8\u8f93\u51fa\u7684\u56fe\u7247\u5927\u5c0f) # \u4ecedataset\u4e2d\u968f\u673a\u5bfb\u627e\u989d\u5916\u7684\u4e09\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5 [14, 26, 2, 16] \u518d\u968f\u673a\u9009\u4e09\u5f20\u56fe\u7247\u7684index indices = [ index ] + random . choices ( self . indices , k = 8 ) # 8 additional image indices for i , index in enumerate ( indices ): # Load image \u6bcf\u6b21\u62ff\u4e00\u5f20\u56fe\u7247 \u5e76\u5c06\u8fd9\u5f20\u56fe\u7247resize\u5230self.size(h,w) img , _ , ( h , w ) = load_image ( self , index ) # \u8fd9\u91cc\u548c\u4e0a\u9762load_mosaic\u51fd\u6570\u7684\u64cd\u4f5c\u7c7b\u4f3c \u5c31\u662f\u5c06\u53d6\u51fa\u7684img\u56fe\u7247\u5d4c\u5230img9\u4e2d(\u4e0d\u662f\u771f\u7684\u5d4c\u5165 \u800c\u662f\u627e\u5230\u5bf9\u5e94\u7684\u4f4d\u7f6e) # place img in img9 if i == 0 : # center img9 = np . full (( s * 3 , s * 3 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles h0 , w0 = h , w c = s , s , s + w , s + h # xmin, ymin, xmax, ymax (base) coordinates elif i == 1 : # top c = s , s - h , s + w , s elif i == 2 : # top right c = s + wp , s - h , s + wp + w , s elif i == 3 : # right c = s + w0 , s , s + w0 + w , s + h elif i == 4 : # bottom right c = s + w0 , s + hp , s + w0 + w , s + hp + h elif i == 5 : # bottom c = s + w0 - w , s + h0 , s + w0 , s + h0 + h elif i == 6 : # bottom left c = s + w0 - wp - w , s + h0 , s + w0 - wp , s + h0 + h elif i == 7 : # left c = s - w , s + h0 - h , s , s + h0 elif i == 8 : # top left c = s - w , s + h0 - hp - h , s , s + h0 - hp padx , pady = c [: 2 ] x1 , y1 , x2 , y2 = [ max ( x , 0 ) for x in c ] # allocate coords # \u548c\u4e0a\u9762load_mosaic\u51fd\u6570\u7684\u64cd\u4f5c\u7c7b\u4f3c \u627e\u5230mosaic9\u589e\u5f3a\u540e\u7684labels9\u548csegments9 labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padx , pady ) # normalized xywh to pixel xyxy format segments = [ xyn2xy ( x , w , h , padx , pady ) for x in segments ] labels9 . append ( labels ) segments9 . extend ( segments ) # \u751f\u6210\u5bf9\u5e94\u7684img9\u56fe\u7247(\u5c06\u5bf9\u5e94\u4f4d\u7f6e\u7684\u56fe\u7247\u5d4c\u5165img9\u4e2d) img9 [ y1 : y2 , x1 : x2 ] = img [ y1 - pady :, x1 - padx :] # img9[ymin:ymax, xmin:xmax] hp , wp = h , w # height, width previous # Offset yc , xc = [ int ( random . uniform ( 0 , s )) for _ in self . mosaic_border ] # mosaic center x, y img9 = img9 [ yc : yc + 2 * s , xc : xc + 2 * s ] # Concat/clip labels labels9 = np . concatenate ( labels9 , 0 ) labels9 [:, [ 1 , 3 ]] -= xc labels9 [:, [ 2 , 4 ]] -= yc c = np . array ([ xc , yc ]) # centers segments9 = [ x - c for x in segments9 ] for x in ( labels9 [:, 1 :], * segments9 ): np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img9, labels9 = replicate(img9, labels9) # replicate # Augment \u540c\u6837\u8fdb\u884c \u968f\u673a\u900f\u89c6\u53d8\u6362 img9 , labels9 = random_perspective ( img9 , labels9 , segments9 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove return img9 , labels9 \u7528\u6cd5\u548cmosaic\u4e00\u6837\uff0c\u4f7f\u7528\u76f4\u63a5\u5c06class LoadImagesAndLabels(Dataset): \u4e2d getitem \u7684load_mosaic\u76f4\u63a5 \u76f4\u63a5\u66ff\u6362\u6210load_mosaic9\u5373\u53ef\uff1a","title":"9.2 load_mosaic9"},{"location":"source_code_interpretation/utils/dataloaders_py.html#10-loadimages-loadstreams-loadwebcam","text":"load \u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247/\u89c6\u9891 + \u7528\u5230\u5f88\u5c11 load web\u7f51\u9875\u4e2d\u7684\u6570\u636e\u3002 \u5168\u90e8\u4ee3\u7801\uff1a class LoadImages : # for inference \"\"\"\u5728detect.py\u4e2d\u4f7f\u7528 load \u6587\u4ef6\u5939\u4e2d\u7684\u56fe\u7247/\u89c6\u9891 \u5b9a\u4e49\u8fed\u4ee3\u5668 \u7528\u4e8edetect.py \"\"\" def __init__ ( self , path , img_size = 640 , stride = 32 ): p = str ( Path ( path ) . absolute ()) # os-agnostic absolute path # glob.glab: \u8fd4\u56de\u6240\u6709\u5339\u914d\u7684\u6587\u4ef6\u8def\u5f84\u5217\u8868 files: \u63d0\u53d6\u56fe\u7247\u6240\u6709\u8def\u5f84 if \"*\" in p : # \u5982\u679cp\u662f\u91c7\u6837\u6b63\u5219\u5316\u8868\u8fbe\u5f0f\u63d0\u53d6\u56fe\u7247/\u89c6\u9891, \u53ef\u4ee5\u4f7f\u7528glob\u83b7\u53d6\u6587\u4ef6\u8def\u5f84 files = sorted ( glob . glob ( p , recursive = True )) # glob elif os . path . isdir ( p ): # \u5982\u679cp\u662f\u4e00\u4e2a\u6587\u4ef6\u5939\uff0c\u4f7f\u7528glob\u83b7\u53d6\u5168\u90e8\u6587\u4ef6\u8def\u5f84 files = sorted ( glob . glob ( os . path . join ( p , \"*.*\" ))) # dir elif os . path . isfile ( p ): # \u5982\u679cp\u662f\u6587\u4ef6\u5219\u76f4\u63a5\u83b7\u53d6 files = [ p ] # files else : raise Exception ( f \"ERROR: { p } does not exist\" ) # images: \u76ee\u5f55\u4e0b\u6240\u6709\u56fe\u7247\u7684\u56fe\u7247\u540d videos: \u76ee\u5f55\u4e0b\u6240\u6709\u89c6\u9891\u7684\u89c6\u9891\u540d images = [ x for x in files if x . split ( \".\" )[ - 1 ] . lower () in img_formats ] videos = [ x for x in files if x . split ( \".\" )[ - 1 ] . lower () in vid_formats ] # \u56fe\u7247\u4e0e\u89c6\u9891\u6570\u91cf ni , nv = len ( images ), len ( videos ) self . img_size = img_size self . stride = stride # \u6700\u5927\u7684\u4e0b\u91c7\u6837\u7387 self . files = images + videos # \u6574\u5408\u56fe\u7247\u548c\u89c6\u9891\u8def\u5f84\u5230\u4e00\u4e2a\u5217\u8868 self . nf = ni + nv # number of files self . video_flag = [ False ] * ni + [ True ] * nv # \u662f\u4e0d\u662fvideo self . mode = \"image\" # \u9ed8\u8ba4\u662f\u8bfbimage\u6a21\u5f0f if any ( videos ): # \u5224\u65ad\u6709\u6ca1\u6709video\u6587\u4ef6 \u5982\u679c\u5305\u542bvideo\u6587\u4ef6\uff0c\u5219\u521d\u59cb\u5316opencv\u4e2d\u7684\u89c6\u9891\u6a21\u5757\uff0ccap=cv2.VideoCapture\u7b49 self . new_video ( videos [ 0 ]) # new video else : self . cap = None assert self . nf > 0 , ( f \"No images or videos found in { p } . \" f \"Supported formats are: \\n images: { img_formats } \\n videos: { vid_formats } \" ) def __iter__ ( self ): \"\"\"\u8fed\u4ee3\u5668\"\"\" self . count = 0 return self def __next__ ( self ): \"\"\"\u4e0eiter\u4e00\u8d77\u7528\uff1f\"\"\" if self . count == self . nf : # \u6570\u636e\u8bfb\u5b8c\u4e86 raise StopIteration path = self . files [ self . count ] # \u8bfb\u53d6\u5f53\u524d\u6587\u4ef6\u8def\u5f84 if self . video_flag [ self . count ]: # \u5224\u65ad\u5f53\u524d\u6587\u4ef6\u662f\u5426\u662f\u89c6\u9891 # Read video self . mode = \"video\" # \u83b7\u53d6\u5f53\u524d\u5e27\u753b\u9762\uff0cret_val\u4e3a\u4e00\u4e2abool\u53d8\u91cf\uff0c\u76f4\u5230\u89c6\u9891\u8bfb\u53d6\u5b8c\u6bd5\u4e4b\u524d\u90fd\u4e3aTrue ret_val , img0 = self . cap . read () # \u5982\u679c\u5f53\u524d\u89c6\u9891\u8bfb\u53d6\u7ed3\u675f\uff0c\u5219\u8bfb\u53d6\u4e0b\u4e00\u4e2a\u89c6\u9891 if not ret_val : self . count += 1 self . cap . release () # self.count == self.nf\u8868\u793a\u89c6\u9891\u5df2\u7ecf\u8bfb\u53d6\u5b8c\u4e86 if self . count == self . nf : # last video raise StopIteration else : path = self . files [ self . count ] self . new_video ( path ) ret_val , img0 = self . cap . read () self . frame += 1 # \u5f53\u524d\u8bfb\u53d6\u89c6\u9891\u7684\u5e27\u6570 print ( f \"video { self . count + 1 } / { self . nf } ( { self . frame } / { self . frames } ) { path } : \" , end = \"\" , ) else : # Read image self . count += 1 img0 = cv2 . imread ( path ) # BGR assert img0 is not None , \"Image Not Found \" + path print ( f \"image { self . count } / { self . nf } { path } : \" , end = \"\" ) # Padded resize img = letterbox ( img0 , self . img_size , stride = self . stride )[ 0 ] # Convert img = img [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB and HWC to CHW img = np . ascontiguousarray ( img ) # \u8fd4\u56de\u8def\u5f84, resize+pad\u7684\u56fe\u7247, \u539f\u59cb\u56fe\u7247, \u89c6\u9891\u5bf9\u8c61 return path , img , img0 , self . cap def new_video ( self , path ): # \u8bb0\u5f55\u5e27\u6570 self . frame = 0 # \u521d\u59cb\u5316\u89c6\u9891\u5bf9\u8c61 self . cap = cv2 . VideoCapture ( path ) # \u5f97\u5230\u89c6\u9891\u6587\u4ef6\u4e2d\u7684\u603b\u5e27\u6570 self . frames = int ( self . cap . get ( cv2 . CAP_PROP_FRAME_COUNT )) def __len__ ( self ): return self . nf # number of files class LoadStreams : \"\"\" load \u6587\u4ef6\u5939\u4e2d\u89c6\u9891\u6d41 multiple IP or RTSP cameras \u5b9a\u4e49\u8fed\u4ee3\u5668 \u7528\u4e8edetect.py \"\"\" def __init__ ( self , sources = \"streams.txt\" , img_size = 640 , stride = 32 ): self . mode = \"stream\" # \u521d\u59cb\u5316mode\u4e3aimages self . img_size = img_size self . stride = stride # \u6700\u5927\u4e0b\u91c7\u6837\u6b65\u957f # \u5982\u679csources\u4e3a\u4e00\u4e2a\u4fdd\u5b58\u4e86\u591a\u4e2a\u89c6\u9891\u6d41\u7684\u6587\u4ef6 \u83b7\u53d6\u6bcf\u4e00\u4e2a\u89c6\u9891\u6d41\uff0c\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u5217\u8868 if os . path . isfile ( sources ): with open ( sources , \"r\" ) as f : sources = [ x . strip () for x in f . read () . strip () . splitlines () if len ( x . strip ()) ] else : # \u53cd\u4e4b\uff0c\u53ea\u6709\u4e00\u4e2a\u89c6\u9891\u6d41\u6587\u4ef6\u5c31\u76f4\u63a5\u4fdd\u5b58 sources = [ sources ] n = len ( sources ) # \u89c6\u9891\u6d41\u4e2a\u6570 # \u521d\u59cb\u5316\u56fe\u7247 fps \u603b\u5e27\u6570 \u7ebf\u7a0b\u6570 self . imgs , self . fps , self . frames , self . threads = ( [ None ] * n , [ 0 ] * n , [ 0 ] * n , [ None ] * n , ) self . sources = [ clean_str ( x ) for x in sources ] # clean source names for later # \u904d\u5386\u6bcf\u4e00\u4e2a\u89c6\u9891\u6d41 for i , s in enumerate ( sources ): # index, source # Start thread to read frames from video stream # \u6253\u5370\u5f53\u524d\u89c6\u9891index/\u603b\u89c6\u9891\u6570/\u89c6\u9891\u6d41\u5730\u5740 print ( f \" { i + 1 } / { n } : { s } ... \" , end = \"\" ) if \"youtube.com/\" in s or \"youtu.be/\" in s : # if source is YouTube video check_requirements (( \"pafy\" , \"youtube_dl\" )) import pafy s = pafy . new ( s ) . getbest ( preftype = \"mp4\" ) . url # YouTube URL s = eval ( s ) if s . isnumeric () else s # i.e. s = '0' local webcam \u672c\u5730\u6444\u50cf\u5934 # s='0'\u6253\u5f00\u672c\u5730\u6444\u50cf\u5934\uff0c\u5426\u5219\u6253\u5f00\u89c6\u9891\u6d41\u5730\u5740 cap = cv2 . VideoCapture ( s ) assert cap . isOpened (), f \"Failed to open { s } \" # \u83b7\u53d6\u89c6\u9891\u7684\u5bbd\u548c\u957f w = int ( cap . get ( cv2 . CAP_PROP_FRAME_WIDTH )) h = int ( cap . get ( cv2 . CAP_PROP_FRAME_HEIGHT )) # \u83b7\u53d6\u89c6\u9891\u7684\u5e27\u7387 self . fps [ i ] = ( max ( cap . get ( cv2 . CAP_PROP_FPS ) % 100 , 0 ) or 30.0 ) # 30 FPS fallback # \u5e27\u6570 self . frames [ i ] = max ( int ( cap . get ( cv2 . CAP_PROP_FRAME_COUNT )), 0 ) or float ( \"inf\" ) # infinite stream fallback # \u8bfb\u53d6\u5f53\u524d\u753b\u9762 _ , self . imgs [ i ] = cap . read () # guarantee first frame # \u521b\u5efa\u591a\u7ebf\u7a0b\u8bfb\u53d6\u89c6\u9891\u6d41\uff0cdaemon\u8868\u793a\u4e3b\u7ebf\u7a0b\u7ed3\u675f\u65f6\u5b50\u7ebf\u7a0b\u4e5f\u7ed3\u675f self . threads [ i ] = Thread ( target = self . update , args = ([ i , cap ]), daemon = True ) print ( f \" success ( { self . frames [ i ] } frames { w } x { h } at { self . fps [ i ] : .2f } FPS)\" ) self . threads [ i ] . start () print ( \"\" ) # newline # check for common shapes # \u83b7\u53d6\u8fdb\u884cresize+pad\u4e4b\u540e\u7684shape\uff0cletterbox\u51fd\u6570\u9ed8\u8ba4(\u53c2\u6570auto=True)\u662f\u6309\u7167\u77e9\u5f62\u63a8\u7406\u8fdb\u884c\u586b\u5145 s = np . stack ( [ letterbox ( x , self . img_size , stride = self . stride )[ 0 ] . shape for x in self . imgs ], 0 , ) # shapes self . rect = ( np . unique ( s , axis = 0 ) . shape [ 0 ] == 1 ) # rect inference if all shapes equal if not self . rect : print ( \"WARNING: Different stream shapes detected. For optimal performance supply similarly-shaped streams.\" ) def update ( self , i , cap ): # Read stream `i` frames in daemon thread n , f = 0 , self . frames [ i ] while cap . isOpened () and n < f : n += 1 # _, self.imgs[index] = cap.read() cap . grab () # \u6bcf4\u5e27\u8bfb\u53d6\u4e00\u6b21 if n % 4 : # read every 4th frame success , im = cap . retrieve () self . imgs [ i ] = im if success else self . imgs [ i ] * 0 time . sleep ( 1 / self . fps [ i ]) # wait time def __iter__ ( self ): self . count = - 1 return self def __next__ ( self ): self . count += 1 if not all ( x . is_alive () for x in self . threads ) or cv2 . waitKey ( 1 ) == ord ( \"q\" ): # q to quit cv2 . destroyAllWindows () raise StopIteration # Letterbox img0 = self . imgs . copy () img = [ letterbox ( x , self . img_size , auto = self . rect , stride = self . stride )[ 0 ] for x in img0 ] # Stack \u5c06\u8bfb\u53d6\u7684\u56fe\u7247\u62fc\u63a5\u5230\u4e00\u8d77 img = np . stack ( img , 0 ) # Convert img = img [:, :, :, :: - 1 ] . transpose ( 0 , 3 , 1 , 2 ) # BGR to RGB and BHWC to BCHW img = np . ascontiguousarray ( img ) return self . sources , img , img0 , None def __len__ ( self ): return 0 # 1E12 frames = 32 streams at 30 FPS for 30 years class LoadWebcam : # for inference \"\"\"\u7528\u5230\u5f88\u5c11 load web\u7f51\u9875\u4e2d\u7684\u6570\u636e\"\"\" def __init__ ( self , pipe = \"0\" , img_size = 640 , stride = 32 ): self . img_size = img_size self . stride = stride if pipe . isnumeric (): pipe = eval ( pipe ) # local camera # pipe = 'rtsp://192.168.1.64/1' # IP camera # pipe = 'rtsp://username:password@192.168.1.64/1' # IP camera with login # pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg' # IP golf camera self . pipe = pipe self . cap = cv2 . VideoCapture ( pipe ) # video capture object self . cap . set ( cv2 . CAP_PROP_BUFFERSIZE , 3 ) # set buffer size def __iter__ ( self ): self . count = - 1 return self def __next__ ( self ): self . count += 1 if cv2 . waitKey ( 1 ) == ord ( \"q\" ): # q to quit self . cap . release () cv2 . destroyAllWindows () raise StopIteration # Read frame if self . pipe == 0 : # local camera ret_val , img0 = self . cap . read () img0 = cv2 . flip ( img0 , 1 ) # flip left-right else : # IP camera n = 0 while True : n += 1 self . cap . grab () if n % 30 == 0 : # skip frames ret_val , img0 = self . cap . retrieve () if ret_val : break # Print assert ret_val , f \"Camera Error { self . pipe } \" img_path = \"webcam.jpg\" print ( f \"webcam { self . count } : \" , end = \"\" ) # Padded resize img = letterbox ( img0 , self . img_size , stride = self . stride )[ 0 ] # Convert img = img [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB and HWC to CHW img = np . ascontiguousarray ( img ) return img_path , img , img0 , None def __len__ ( self ): return 0","title":"10. LoadImages &amp; LoadStreams &amp; LoadWebcam"},{"location":"source_code_interpretation/utils/dataloaders_py.html#11-flatten_recursive","text":"\u8fd9\u4e2a\u6a21\u5757\u662f\u5c06\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u590d\u5236\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d \u5373\u5c06image\u6587\u4ef6\u548clabel\u6587\u4ef6\u653e\u5230\u4e00\u4e2a\u65b0\u6587\u4ef6\u5939\u4e2d\u3002 flatten_recursive\u6a21\u5757\u4ee3\u7801\uff1a def flatten_recursive ( path = DATASETS_DIR / \"coco128\" ): # \u5c06\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u590d\u5236\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d \u5373\u5c06image\u6587\u4ef6\u548clabel\u6587\u4ef6\u653e\u5230\u4e00\u4e2a\u65b0\u6587\u4ef6\u5939\u4e2d # Flatten a recursive directory by bringing all files to top level new_path = Path ( f \" { str ( path ) } _flat\" ) if os . path . exists ( new_path ): shutil . rmtree ( new_path ) # delete output folder os . makedirs ( new_path ) # make new output folder for file in tqdm ( glob . glob ( f \" { str ( Path ( path )) } /**/*.*\" , recursive = True )): # shutil.copyfile: \u590d\u5236\u6587\u4ef6\u5230\u53e6\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d shutil . copyfile ( file , new_path / Path ( file ) . name )","title":"11. flatten_recursive"},{"location":"source_code_interpretation/utils/dataloaders_py.html#12extract_boxes","text":"\u8fd9\u4e2a\u6a21\u5757\u662f\u5c06\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u5206\u7c7b\u6570\u636e\u96c6 \uff0c\u96c6\u4f53\u505a\u6cd5: \u628a\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2agt\u62c6\u89e3\u5f00 \u5206\u7c7b\u522b\u5b58\u50a8\u5230\u5bf9\u5e94\u7684\u6587\u4ef6\u5f53\u4e2d\u3002 def extract_boxes ( path = DATASETS_DIR / \"coco128\" , ): # from utils.dataloaders import *; extract_boxes() # Convert detection dataset into classification dataset, with one directory per class \"\"\"\u81ea\u884c\u4f7f\u7528 \u751f\u6210\u5206\u7c7b\u6570\u636e\u96c6 \u5c06\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u5206\u7c7b\u6570\u636e\u96c6 \u96c6\u4f53\u505a\u6cd5: \u628a\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u4e2agt\u62c6\u89e3\u5f00 \u5206\u7c7b\u522b\u5b58\u50a8\u5230\u5bf9\u5e94\u7684\u6587\u4ef6\u5f53\u4e2d Convert detection dataset into classification dataset, with one directory per class \u4f7f\u7528: from utils.datasets import *; extract_boxes() :params path: \u6570\u636e\u96c6\u5730\u5740 \"\"\" path = Path ( path ) # images dir \u6570\u636e\u96c6\u6587\u4ef6\u76ee\u5f55 \u9ed8\u8ba4'..\\datasets\\coco128' shutil . rmtree ( path / \"classifier\" ) if ( path / \"classifier\" ) . is_dir () else None # remove existing files = list ( path . rglob ( \"*.*\" )) n = len ( files ) # number of files for im_file in tqdm ( files , total = n ): if im_file . suffix [ 1 :] in IMG_FORMATS : # \u5fc5\u987b\u5f97\u662f\u56fe\u7247\u6587\u4ef6 # image im = cv2 . imread ( str ( im_file ))[ ... , :: - 1 ] # BGR to RGB h , w = im . shape [: 2 ] # \u5f97\u5230\u8fd9\u5f20\u56fe\u7247h w # labels \u6839\u636e\u8fd9\u5f20\u56fe\u7247\u7684\u8def\u5f84\u627e\u5230\u8fd9\u5f20\u56fe\u7247\u7684label\u8def\u5f84 lb_file = Path ( img2label_paths ([ str ( im_file )])[ 0 ]) if Path ( lb_file ) . exists (): with open ( lb_file ) as f : lb = np . array ([ x . split () for x in f . read () . strip () . splitlines ()], dtype = np . float32 ) # labels \u8bfb\u53d6label\u7684\u5404\u884c: \u5bf9\u5e94\u5404\u4e2agt\u5750\u6807 for j , x in enumerate ( lb ): # \u904d\u5386\u6bcf\u4e00\u4e2agt c = int ( x [ 0 ]) # class # \u751f\u6210\u65b0'file_name path\\classifier\\class_index\\image_name' # \u5982: 'F:\\yolo_v5\\datasets\\coco128\\images\\train2017\\classifier\\45\\train2017_000000000009_0.jpg' f = ( path / \"classifier\" ) / f \" { c } \" / f \" { path . stem } _ { im_file . stem } _ { j } .jpg\" # new filename if not f . parent . is_dir (): # \u6bcf\u4e00\u4e2a\u7c7b\u522b\u7684\u7b2c\u4e00\u5f20\u7167\u7247\u5b58\u8fdb\u53bb\u4e4b\u524d \u5148\u521b\u5efa\u5bf9\u5e94\u7c7b\u7684\u6587\u4ef6\u5939 f . parent . mkdir ( parents = True ) b = x [ 1 :] * [ w , h , w , h ] # box normalized to \u6b63\u5e38\u5927\u5c0f # b[2:] = b[2:].max() # rectangle to square b [ 2 :] = b [ 2 :] * 1.2 + 3 # pad b = xywh2xyxy ( b . reshape ( - 1 , 4 )) . ravel () . astype ( np . int ) b [[ 0 , 2 ]] = np . clip ( b [[ 0 , 2 ]], 0 , w ) # clip boxes outside of image \u9632\u6b62\u51fa\u754c b [[ 1 , 3 ]] = np . clip ( b [[ 1 , 3 ]], 0 , h ) assert cv2 . imwrite ( str ( f ), im [ b [ 1 ] : b [ 3 ], b [ 0 ] : b [ 2 ]]), f \"box failure in { f } \"","title":"12.extract_boxes"},{"location":"source_code_interpretation/utils/dataloaders_py.html#13-autosplit","text":"\u8fd9\u4e2a\u6a21\u5757\u662f\u8fdb\u884c\u81ea\u52a8\u5212\u5206\u6570\u636e\u96c6\u3002\u5f53\u4f7f\u7528\u81ea\u5df1\u6570\u636e\u96c6\u65f6\uff0c\u53ef\u4ee5\u7528\u8fd9\u4e2a\u6a21\u5757\u8fdb\u884c\u81ea\u884c\u5212\u5206\u6570\u636e\u96c6\u3002 autosplit\u6a21\u5757\u4ee3\u7801\uff1a def autosplit ( path = DATASETS_DIR / \"coco128/images\" , weights = ( 0.9 , 0.1 , 0.0 ), annotated_only = False ): \"\"\"Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files Usage: from utils.dataloaders import *; autosplit() Arguments path: Path to images directory weights: Train, val, test weights (list, tuple) annotated_only: Only use images with an annotated txt file \"\"\" path = Path ( path ) # images dir # \u83b7\u53d6images\u4e2d\u6240\u6709\u7684\u56fe\u7247 image files only files = sorted ( x for x in path . rglob ( \"*.*\" ) if x . suffix [ 1 :] . lower () in IMG_FORMATS ) # image files only n = len ( files ) # number of files # \u968f\u673a\u6570\u79cd\u5b50 random . seed ( 0 ) # for reproducibility # assign each image to a split \u6839\u636e(train, val, test)\u6743\u91cd\u5212\u5206\u539f\u59cb\u56fe\u7247\u6570\u636e\u96c6 # indices: [n] 0, 1, 2 \u5206\u522b\u8868\u793a\u6570\u636e\u96c6\u4e2d\u6bcf\u4e00\u5f20\u56fe\u7247\u5c5e\u4e8e\u54ea\u4e2a\u6570\u636e\u96c6 \u5206\u522b\u5bf9\u5e94\u7740(train, val, test) indices = random . choices ([ 0 , 1 , 2 ], weights = weights , k = n ) # assign each image to a split txt = [ \"autosplit_train.txt\" , \"autosplit_val.txt\" , \"autosplit_test.txt\" ] # 3 txt files [( path . parent / x ) . unlink ( missing_ok = True ) for x in txt ] # remove existing print ( f \"Autosplitting images from { path } \" + \", using *.txt labeled images only\" * annotated_only ) for i , img in tqdm ( zip ( indices , files ), total = n ): if not annotated_only or Path ( img2label_paths ([ str ( img )])[ 0 ]) . exists (): # check label with open ( path . parent / txt [ i ], \"a\" ) as f : f . write ( f \"./ { img . relative_to ( path . parent ) . as_posix () } \" + \" \\n \" ) # add image to txt file","title":"13. autosplit"},{"location":"source_code_interpretation/utils/dataloaders_py.html#reference","text":"\u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011 atasets.py","title":"Reference"},{"location":"source_code_interpretation/utils/downloads_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/augmentations.py \u8fd9\u4e2a\u6587\u4ef6\u4e3b\u8981\u662f\u8d1f\u8d23\u4ecegithub/googleleaps/google drive \u7b49\u7f51\u7ad9\u6216\u8005 \u4e91\u670d\u52a1\u5668 \u4e0a\u4e0b\u8f7d\u6240\u9700\u7684\u4e00\u4e9b\u6587\u4ef6\u3002 \u662f\u4e00\u4e2a\u5de5\u5177\u7c7b\uff0c\u4ee3\u7801\u6bd4\u8f83\u7b80\u5355\uff0c\u51fd\u6570\u4e5f\u6bd4\u8f83\u5c11\uff0c\u4e3b\u8981\u96be\u70b9\u8fd8\u662f\u5728\u4e8e\u4e00\u4e9b\u5305\u53ef\u80fd\u5927\u5bb6\u4e0d\u662f\u5f88\u719f\u6089\uff0c\u4e0b\u9762\u4e00\u8d77\u6765\u5b66\u4e60\u4e0b\u3002 \u8fd9\u4e2a\u6587\u4ef6\u6bd4\u8f83\u91cd\u8981\u7684\u662f\u4e24\u4e2a\u51fd\u6570\uff1asafe_download\u548cattempt_download\u3002\u5728train.py\u6216\u8005yolo.py\u7b49\u6587\u4ef6\u4e2d\u90fd\u4f1a\u7528\u5230\u3002 1. \u5bfc\u5165\u9700\u8981\u7684\u5305 \"\"\" Download utils \"\"\" import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 import platform # \u63d0\u4f9b\u83b7\u53d6\u64cd\u4f5c\u7cfb\u7edf\u76f8\u5173\u4fe1\u606f\u7684\u6a21\u5757 import shutil # Python\u7684\u9ad8\u9636\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 import subprocess # \u5b50\u8fdb\u7a0b\u5b9a\u4e49\u53ca\u64cd\u4f5c\u7684\u6a21\u5757 import time # \u65f6\u95f4\u6a21\u5757 import urllib # \u7528\u4e8e\u64cd\u4f5c\u7f51\u9875 url \u5e76\u5bf9\u7f51\u9875\u7684\u5185\u5bb9\u8fdb\u884c\u6293\u53d6\u5904\u7406 \u5982urllib.parse: \u89e3\u6790url from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 from zipfile import ZipFile # \u5bfc\u5165\u6587\u4ef6\u89e3\u538b\u6a21\u5757 import oneflow as flow # \u5bfc\u5165\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6oneflow\u5305 import requests # \u901a\u8fc7urllib3\u5b9e\u73b0\u81ea\u52a8\u53d1\u9001HTTP/1.1\u8bf7\u6c42\u7684\u7b2c\u4e09\u65b9\u6a21\u5757 2. gsutil_getsize \u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5 url \u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f\u3002 def gsutil_getsize ( url = \"\" ): \"\"\"\u7528\u5728downloads.py\u7684print_mutation\u51fd\u6570\u5f53\u4e2d \u8ba1\u7b97\u67d0\u4e2aurl\u5bf9\u5e94\u7684\u6587\u4ef6\u5927\u5c0f \u7528\u4e8e\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5url\u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f\uff0c\u6ce8\u610f\u5355\u4f4d\u662fbytes gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du \"\"\" # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u5728\u547d\u4ee4\u884c\u6267\u884c gsutil du url \u547d\u4ee4(\u8bbf\u95ee Cloud Storage) \u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u6587\u4ef6) # gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du s = subprocess . check_output ( f \"gsutil du { url } \" , shell = True ) . decode ( \"utf-8\" ) return eval ( s . split ( \" \" )[ 0 ]) if len ( s ) else 0 # bytes 3. safe_download\u3001attempt_download \u8fd9\u4e24\u4e2a\u51fd\u6570\u4e3b\u8981\u662f\u7528\u6765\u4ece github \u6216\u8005 googleleaps \u4e91\u670d\u52a1\u5668\u4e2d\u4e0b\u8f7d\u6587\u4ef6\u7684\uff0c\u4e3b\u8981\u662f\u4e0b\u8f7d\u6743\u91cd\u6587\u4ef6\u3002 one-yolov5 \u4ed3\u5e93\u4e2d attempt_download \u51fd\u6570\u8c03\u7528 safe_download \u51fd\u6570\u3002 3.1 safe_download \u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u4e0b\u8f7d url\uff08github\uff09 \u6216\u8005 url2\uff08\u8c37\u6b4c\u4e91\u670d\u52a1\u5668\uff09 \u7f51\u9875\u8def\u5f84\u5bf9\u5e94\u7684\u6587\u4ef6\uff0c \u901a\u5e38\u662f\u4e0b\u8f7d\u6743\u91cd\u6587\u4ef6\uff0c\u7ecf\u5e38\u7528\u5728 attempt_download \u51fd\u6570\u4e2d\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a def safe_download ( file , url , url2 = None , min_bytes = 1e0 , error_msg = \"\" ): \"\"\"\u7ecf\u5e38\u7528\u5728 attempt_download \u51fd\u6570\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u5355\u72ec\u4f7f\u7528 \u4e0b\u8f7d url/url2 \u7f51\u9875\u8def\u5f84\u5bf9\u5e94\u7684\u6587\u4ef6 Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes @params file: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d @params url: \u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740 \u4e00\u822c\u662fgithub @params url2: \u7b2c\u4e8c\u4e2a\u4e0b\u8f7d\u5730\u5740(\u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740\u4e0b\u8f7d\u5931\u8d25\u540e\u4f7f\u7528) \u4e00\u822c\u662fgoogleleaps\u7b49\u4e91\u670d\u52a1\u5668 @params min_bytes: \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765 \u53ea\u6709\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes\u624d\u80fd\u5224\u65ad\u6587\u4ef6\u5df2\u7ecf\u4e0b\u8f7d\u4e0b\u6765\u4e86 @params error_msg: \u6587\u4ef6\u4e0b\u8f7d\u5931\u8d25\u7684\u663e\u793a\u4fe1\u606f \u521d\u59cb\u5316\u9ed8\u8ba4\u4e3a\u7a7a \"\"\" # Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes file = Path ( file ) assert_msg = f \"Downloaded file ' { file } ' does not exist or size is < min_bytes= { min_bytes } \" try : # url1 y: \u5c1d\u8bd5\u4ece url \u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662f github \u94fe\u63a5 print ( f \"Downloading { url } to { file } ...\" ) // \u4f7f\u7528 oneflow . hub . download_url_to_file \u4e0b\u8f7d url \u94fe\u63a5\u5bf9\u5e94\u7684\u6587\u4ef6 \uff0c // \u5173\u4e8eoneflow . hub \u6a21\u5757\u8bb2\u89e3\u53ef\u4ee5\u770b \uff1a https : // www . bilibili . com / video / BV1YG4y1B72u / ? spm_id_from = 333.999.0.0 flow . hub . download_url_to_file ( url , str ( file )) # \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765\u4e86 (\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8e min_bytes ) assert file . exists () and file . stat () . st_size > min_bytes , assert_msg # check except Exception as e : # url2 url1 \u4e0d\u884c\u5c31\u5c1d\u8bd5\u4ece url2 \u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgoogleleaps(\u4e91\u670d\u52a1\u5668) # \u79fb\u9664\u4e4b\u524d\u4e0b\u8f7d\u5931\u8d25\u7684\u4e0d\u5b8c\u6574\u6587\u4ef6 file . unlink ( missing_ok = True ) # remove partial downloads print ( f \"ERROR: { e } \\n Re-attempting { url2 or url } to { file } ...\" ) os . system ( f \"curl -L ' { url2 or url } ' -o ' { file } ' --retry 3 -C -\" ) # curl download, retry and resume on fail finally : # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765\u4e86 \u6216 \u6587\u4ef6\u5927\u5c0f\u662f\u5426\u5c0f\u4e8emin_bytes if not file . exists () or file . stat () . st_size < min_bytes : # check # \u4e0b\u8f7d\u5931\u8d25 \u79fb\u9664\u4e0b\u8f7d\u5931\u8d25\u7684\u4e0d\u5b8c\u6574\u6587\u4ef6 remove partial downloads file . unlink ( missing_ok = True ) # remove partial downloads # \u6253\u5370\u9519\u8bef\u4fe1\u606f print ( f \"ERROR: { assert_msg } \\n { error_msg } \" ) print ( \"\" ) url = \"https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/model_comparison.png\" safe_download ( \"op.png\" , url ) Downloading https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/model_comparison.png to op.png... 0%| | 0.00/118k [00:00<?, ?B/s] from PIL import Image display ( Image . open ( \"op.png\" )) # \u663e\u793a\u4e0b\u8f7d\u7684\u56fe\u7247 3.2 attempt_download \u8fd9\u4e2a\u51fd\u6570\u662f\u5b9e\u73b0\u4ece\u51e0\u4e2a\u4e91\u5e73\u53f0 (github/googleleaps\u4e91\u670d\u52a1\u5668/xxx) \u4e0b\u8f7d\u6587\u4ef6(\u5728one-yolov5\u4e2d\u4e00\u822c\u662f\u9884\u8bad\u7ec3\u6a21\u578b)\uff0c \u4f1a\u8c03\u7528\u4e0a\u9762\u7684 safe_download \u51fd\u6570\u3002\u4f1a\u7528\u5728 experimental.py \u4e2d\u7684 attempt_load \u51fd\u6570\u548c train.py \u4e2d\uff0c\u90fd\u662f\u7528\u6765\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002\u4ee3\u7801\u8be6\u89e3\u5982\u4e0b\uff1a def attempt_download ( file , repo = \"Oneflow-Inc/one-yolov5\" ): # from utils.downloads import *; attempt_download() \"\"\"\u7528\u5728attempt_download\u51fd\u6570\u4e2d \u4e0b\u8f7d url/url2 \u7f51\u9875\u8def\u5f84\u5bf9\u5e94\u7684\u6587\u4ef6 Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes :params file: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d :params url: \u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740 \u4e00\u822c\u662f github :params url2: \u7b2c\u4e8c\u4e2a\u4e0b\u8f7d\u5730\u5740(\u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740\u4e0b\u8f7d\u5931\u8d25\u540e\u4f7f\u7528) \u4e00\u822c\u662fgoogleleaps \u7b49\u4e91\u670d\u52a1\u5668 :params min_bytes: \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765 \u53ea\u6709\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes \u624d\u80fd\u5224\u65ad\u6587\u4ef6\u5df2\u7ecf\u4e0b\u8f7d\u4e0b\u6765\u4e86 :params error_msg: \u6587\u4ef6\u4e0b\u8f7d\u5931\u8d25\u7684\u663e\u793a\u4fe1\u606f \u521d\u59cb\u5316\u9ed8\u8ba4\u2019\u2018 \"\"\" # Attempt file download if does not exist file = Path ( str ( file ) . strip () . replace ( \"'\" , \"\" )) if not file . exists (): # \u5c1d\u8bd5\u4eceurl\u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgithub # URL specified # urllib.parse: \u89e3\u6790url # .unquote: \u5bf9url\u8fdb\u884c\u89e3\u7801 decode '%2F' to '/' etc. name = Path ( urllib . parse . unquote ( str ( file ))) . name # decode '%2F' to '/' etc. # \u5982\u679c\u89e3\u6790\u7684\u6587\u4ef6\u540d\u662fhttp:/ \u6216 https:/ \u5f00\u5934\u5c31\u76f4\u63a5\u4e0b\u8f7d if str ( file ) . startswith (( \"http:/\" , \"https:/\" )): # download # url: \u4e0b\u8f7d\u8def\u5f84 url \u5bf9\u5e94\u7684\u6587\u4ef6 url = str ( file ) . replace ( \":/\" , \"://\" ) # Pathlib turns :// -> :/ # name: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d file = name . split ( \"?\" )[ 0 ] # parse authentication https://url.com/file.txt?auth... # \u5982\u679c\u6587\u4ef6\u5df2\u7ecf\u5728\u672c\u5730\u5b58\u5728\u4e86\u5c31\u4e0d\u7528\u4e0b\u8f7d\u4e86 if Path ( file ) . is_file (): print ( f \"Found { url } locally at { file } \" ) # file already exists else : safe_download ( file = file , url = url , min_bytes = 1e5 ) # \u4e0b\u8f7d\u6587\u4ef6 return file # GitHub assets file . parent . mkdir ( parents = True , exist_ok = True ) # make parent dir (if required) try : # \u5229\u7528 github api \u83b7\u53d6\u6700\u65b0\u7684\u7248\u672c\u76f8\u5173\u4fe1\u606f \u8fd9\u91cc\u7684 response \u662f\u4e00\u4e2a\u5b57\u5178 response = requests . get ( f \"https://api.github.com/repos/ { repo } /releases/latest\" ) . json () # github api assets = [ x [ \"name\" ] for x in response [ \"assets\" ]] # release assets, i.e. ['yolov5s', 'yolov5m', ...] tag = response [ \"tag_name\" ] # i.e. 'v1.0' except : # fallback plan \u83b7\u53d6\u5931\u8d25 \u5c31\u9000\u800c\u6c42\u5176\u6b21 \u76f4\u63a5\u5229\u7528 git \u547d\u4ee4\u5f3a\u884c\u8865\u9f50\u7248\u672c\u4fe1\u606f assets = [ \"yolov5n.zip\" , \"yolov5s.zip\" , \"yolov5m.zip\" , \"yolov5l.zip\" , \"yolov5x.zip\" , \"yolov5n6.zip\" , \"yolov5s6.zip\" , \"yolov5m6.zip\" , \"yolov5l6.zip\" , \"yolov5x6.zip\" , ] try : # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u5728\u547d\u4ee4\u884c\u6267\u884c git tag \u547d\u4ee4(\u8fd4\u56de\u7248\u672c\u53f7 \u7248\u672c\u53f7\u4fe1\u606f\u4e00\u822c\u5728\u5b57\u5178\u6700\u540e\u4e00\u4e2a -1) \u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u7248\u672c\u53f7 tag) tag = subprocess . check_output ( \"git tag\" , shell = True , stderr = subprocess . STDOUT ) . decode () . split ()[ - 1 ] except : # \u5982\u679c\u8fd8\u662f\u5931\u8d25 \u5c31\u5f3a\u884c\u81ea\u5df1\u8865\u4e00\u4e2a\u7248\u672c\u53f7 tag='v1.1' \uff0c\u6bd4\u5982\u8fd9\u91cc\u5728 one-yolov5 \u4e2d\u76f4\u63a5\u8865\u5f53\u524d\u7684\u6700\u65b0\u7248\u672c v1.1. tag = \"v1.1\" # current release if \".zip\" not in name : name = name + \".zip\" file = Path ( name ) if name in assets : safe_download ( file , url = f \"https://github.com/ { repo } /releases/download/ { tag } / { name } \" , # url2=f'https://storage.googleapis.com/{repo}/ckpt/{name}', # backup url (optional) min_bytes = 1e5 , error_msg = f \" { file } missing, try downloading from https://github.com/ { repo } /releases/\" , ) if \".zip\" in name : new_dir = Path ( name [: - 4 ]) else : new_dir = Path ( name ) if not os . path . exists ( new_dir ): # \u5224\u65ad\u6587\u4ef6\u5939\u662f\u5426\u5b58\u5728 os . mkdir ( new_dir ) # \u65b0\u5efa\u6587\u4ef6\u5939 if \".zip\" in name : print ( \"unzipping... \" , end = \"\" ) # ZipFile(new_file).extractall(path=file.parent) # unzip f = ZipFile ( file ) f . extractall ( new_dir ) os . remove ( file ) # remove zip tmp_dir = \"/tmp/oneyolov5\" if os . path . isdir ( tmp_dir ): shutil . rmtree ( tmp_dir ) if \".zip\" in name : path1 = os . path . join ( name [: - 4 ], name [: - 4 ]) else : path1 = os . path . join ( name , name ) shutil . copytree ( path1 , tmp_dir ) shutil . rmtree ( new_dir ) shutil . copytree ( tmp_dir , new_dir ) shutil . rmtree ( tmp_dir ) return str ( file ) attempt_download ( \"yolov5n\" ) Downloading https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/yolov5n.zip to yolov5n.zip... 0%| | 0.00/3.53M [00:00<?, ?B/s] unzipping... 'yolov5n.zip' 4. get_token & gdrive_download\uff08\u6ca1\u4f7f\u7528\uff09 \u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u5b9e\u73b0\u4ece google drive \u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6\u3002\u4f46\u662f\u8fd9\u597d\u50cf\u5e76\u6ca1\u6709\u5728\u4ee3\u7801\u4e2d\u4f7f\u7528\uff0c\u6240\u4ee5\u8fd9\u4e24\u4e2a\u51fd\u6570\u53ef\u4ee5\u968f\u4fbf\u4e86\u89e3\u4e0b\u5c31\u597d\uff0c\u4e3b\u8981\u8fd8\u662f\u8981\u638c\u63e1\u4e0a\u9762\u7684\u4e24\u4e2a\u4e0b\u8f7d\u51fd\u6570\u7528\u7684\u6bd4\u8f83\u591a\u3002 4.1 get_token \u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4ece cookie\u4e2d \u83b7\u53d6\u4ee4\u724c token \u3002\u4f1a\u5728 gdrive_download \u4e2d\u88ab\u8c03\u7528\u3002 get_token\u51fd\u6570\u4ee3\u7801\uff1a def get_token ( cookie = \"./cookie\" ): \"\"\"\u5728gdrive_download\u4e2d\u4f7f\u7528 \u5b9e\u73b0\u4ececookie\u4e2d\u83b7\u53d6\u4ee4\u724ctoken \"\"\" with open ( cookie ) as f : for line in f : if \"download\" in line : return line . split ()[ - 1 ] return \"\" 4.2 gdrive_download \u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4ece google drive \u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6\u3002\u8fd9\u4e2a\u51fd\u6570\u8c8c\u4f3c\u6ca1\u7528\u5230\uff0c\u968f\u4fbf\u770b\u4e0b\u5c31\u597d\u3002 gdrive_download\u51fd\u6570\u4ee3\u7801\uff1a def gdrive_download ( id = '16TiPfZj7htmTyhntwcZyEEAejOUxuT6m' , file = 'tmp.zip' ): \"\"\" \u5b9e\u73b0\u4ece google drive \u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6 :params id: url\u7684?\u540e\u9762\u7684 id \u53c2\u6570\u7684\u53c2\u6570\u503c :params file: \u9700\u8981\u4e0b\u8f7d\u7684\u538b\u7f29\u6587\u4ef6\u540d \"\"\" t = time . time () # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 file = Path ( file ) # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 cookie = Path ( 'cookie' ) # gdrive cookie print ( f 'Downloading https://drive.google.com/uc?export=download&id= { id } as { file } ... ' , end = '' ) file . unlink ( missing_ok = True ) # \u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684\u6587\u4ef6(\u53ef\u80fd\u662f\u4e0b\u8f7d\u5931\u8d25/\u4e0b\u8f7d\u4e0d\u5b8c\u6574\u7684\u6587\u4ef6) cookie . unlink ( missing_ok = True ) # \u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684cookie # \u5c1d\u8bd5\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6 out = \"NUL\" if platform . system () == \"Windows\" else \"/dev/null\" # \u4f7f\u7528 cmd \u547d\u4ee4\u4ece google drive \u4e0a\u4e0b\u8f7d\u6587\u4ef6 os . system ( f 'curl -c ./cookie -s -L \"drive.google.com/uc?export=download&id= { id } \" > { out } ' ) if os . path . exists ( 'cookie' ): # \u5982\u679c\u6587\u4ef6\u8f83\u5927 \u5c31\u9700\u8981\u6709\u4ee4\u724c get_token (\u5b58\u5728 cookie \u624d\u6709\u4ee4\u724c)\u7684\u6307\u4ee4 s \u624d\u80fd\u4e0b\u8f7d # get_token() \u51fd\u6570\u5728\u4e0a\u9762\u5b9a\u4e49\u4e86\uff0c\u7528\u4e8e\u83b7\u53d6\u5f53\u524d cookie \u7684\u4ee4\u724c token s = f 'curl -Lb ./cookie \"drive.google.com/uc?export=download&confirm= { get_token () } &id= { id } \" -o { file } ' else : # \u5c0f\u6587\u4ef6\u5c31\u4e0d\u9700\u8981\u5e26\u4ee4\u724c\u7684\u6307\u4ee4 s \u76f4\u63a5\u4e0b\u8f7d\u5c31\u884c s = f 'curl -s -L -o { file } \"drive.google.com/uc?export=download&id= { id } \"' # \u6267\u884c\u4e0b\u8f7d\u6307\u4ee4 s \u5e76\u83b7\u5f97\u8fd4\u56de\u503c \u5982\u679c cmd \u547d\u4ee4\u6267\u884c\u6210\u529f \u5219 os.system()\u547d\u4ee4\u4f1a\u8fd4\u56de 0 r = os . system ( s ) cookie . unlink ( missing_ok = True ) # \u518d\u6b21\u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684cookie # \u4e0b\u8f7d\u9519\u8bef\u68c0\u6d4b \u5982\u679c r != 0 \u5219\u4e0b\u8f7d\u9519\u8bef if r != 0 : file . unlink ( missing_ok = True ) # \u4e0b\u8f7d\u9519\u8bef \u79fb\u9664\u4e0b\u8f7d\u7684\u6587\u4ef6(\u53ef\u80fd\u4e0d\u5b8c\u6574\u6216\u8005\u4e0b\u8f7d\u5931\u8d25) print ( 'Download error ' ) # raise Exception('Download error') return r # \u5982\u679c\u662f\u538b\u7f29\u6587\u4ef6 \u5c31\u89e3\u538b file.suffix \u65b9\u6cd5\u53ef\u4ee5\u83b7\u53d6 file \u6587\u4ef6\u7684\u540e\u7f00 if file . suffix == '.zip' : print ( 'unzipping... ' , end = '' ) os . system ( f 'unzip -q { file } ' ) # cmd\u547d\u4ee4\u6267\u884c\u89e3\u538b\u547d\u4ee4 file . unlink () # \u79fb\u9664 .zip \u538b\u7f29\u6587\u4ef6 print ( f 'Done ( { time . time () - t : .1f } s)' ) # \u6253\u5370\u4e0b\u8f7d + \u89e3\u538b\u8fc7\u7a0b\u6240\u9700\u8981\u7684\u65f6\u95f4 return r \u603b\u7ed3 \u8fd9\u4e2a\u6587\u4ef6\u7684\u4ee3\u7801\u6bd4\u8f83\u5c11\uff0c\u771f\u6b63\u6709\u7528\u7684\u51fd\u6570\u4e5f\u6bd4\u8f83\u5c11\u3002 \u4e5f\u5c31\u662fsafe_download\u548cattempt_download\u4e24\u4e2a\u51fd\u6570\u6bd4\u8f83\u91cd\u8981\uff0c\u5927\u5bb6\u91cd\u70b9\u638c\u63e1\u8fd9\u4e24\u4e2a\u51fd\u6570\u5373\u53ef\u3002 Reference \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011google_utils.py","title":"downloads.py"},{"location":"source_code_interpretation/utils/downloads_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/augmentations.py \u8fd9\u4e2a\u6587\u4ef6\u4e3b\u8981\u662f\u8d1f\u8d23\u4ecegithub/googleleaps/google drive \u7b49\u7f51\u7ad9\u6216\u8005 \u4e91\u670d\u52a1\u5668 \u4e0a\u4e0b\u8f7d\u6240\u9700\u7684\u4e00\u4e9b\u6587\u4ef6\u3002 \u662f\u4e00\u4e2a\u5de5\u5177\u7c7b\uff0c\u4ee3\u7801\u6bd4\u8f83\u7b80\u5355\uff0c\u51fd\u6570\u4e5f\u6bd4\u8f83\u5c11\uff0c\u4e3b\u8981\u96be\u70b9\u8fd8\u662f\u5728\u4e8e\u4e00\u4e9b\u5305\u53ef\u80fd\u5927\u5bb6\u4e0d\u662f\u5f88\u719f\u6089\uff0c\u4e0b\u9762\u4e00\u8d77\u6765\u5b66\u4e60\u4e0b\u3002 \u8fd9\u4e2a\u6587\u4ef6\u6bd4\u8f83\u91cd\u8981\u7684\u662f\u4e24\u4e2a\u51fd\u6570\uff1asafe_download\u548cattempt_download\u3002\u5728train.py\u6216\u8005yolo.py\u7b49\u6587\u4ef6\u4e2d\u90fd\u4f1a\u7528\u5230\u3002","title":"\u524d\u8a00"},{"location":"source_code_interpretation/utils/downloads_py.html#1","text":"\"\"\" Download utils \"\"\" import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 import platform # \u63d0\u4f9b\u83b7\u53d6\u64cd\u4f5c\u7cfb\u7edf\u76f8\u5173\u4fe1\u606f\u7684\u6a21\u5757 import shutil # Python\u7684\u9ad8\u9636\u6587\u4ef6\u64cd\u4f5c\u6a21\u5757 import subprocess # \u5b50\u8fdb\u7a0b\u5b9a\u4e49\u53ca\u64cd\u4f5c\u7684\u6a21\u5757 import time # \u65f6\u95f4\u6a21\u5757 import urllib # \u7528\u4e8e\u64cd\u4f5c\u7f51\u9875 url \u5e76\u5bf9\u7f51\u9875\u7684\u5185\u5bb9\u8fdb\u884c\u6293\u53d6\u5904\u7406 \u5982urllib.parse: \u89e3\u6790url from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 from zipfile import ZipFile # \u5bfc\u5165\u6587\u4ef6\u89e3\u538b\u6a21\u5757 import oneflow as flow # \u5bfc\u5165\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6oneflow\u5305 import requests # \u901a\u8fc7urllib3\u5b9e\u73b0\u81ea\u52a8\u53d1\u9001HTTP/1.1\u8bf7\u6c42\u7684\u7b2c\u4e09\u65b9\u6a21\u5757","title":"1. \u5bfc\u5165\u9700\u8981\u7684\u5305"},{"location":"source_code_interpretation/utils/downloads_py.html#2-gsutil_getsize","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5 url \u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f\u3002 def gsutil_getsize ( url = \"\" ): \"\"\"\u7528\u5728downloads.py\u7684print_mutation\u51fd\u6570\u5f53\u4e2d \u8ba1\u7b97\u67d0\u4e2aurl\u5bf9\u5e94\u7684\u6587\u4ef6\u5927\u5c0f \u7528\u4e8e\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5url\u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f\uff0c\u6ce8\u610f\u5355\u4f4d\u662fbytes gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du \"\"\" # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u5728\u547d\u4ee4\u884c\u6267\u884c gsutil du url \u547d\u4ee4(\u8bbf\u95ee Cloud Storage) \u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u6587\u4ef6) # gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du s = subprocess . check_output ( f \"gsutil du { url } \" , shell = True ) . decode ( \"utf-8\" ) return eval ( s . split ( \" \" )[ 0 ]) if len ( s ) else 0 # bytes","title":"2. gsutil_getsize"},{"location":"source_code_interpretation/utils/downloads_py.html#3-safe_downloadattempt_download","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u4e3b\u8981\u662f\u7528\u6765\u4ece github \u6216\u8005 googleleaps \u4e91\u670d\u52a1\u5668\u4e2d\u4e0b\u8f7d\u6587\u4ef6\u7684\uff0c\u4e3b\u8981\u662f\u4e0b\u8f7d\u6743\u91cd\u6587\u4ef6\u3002 one-yolov5 \u4ed3\u5e93\u4e2d attempt_download \u51fd\u6570\u8c03\u7528 safe_download \u51fd\u6570\u3002","title":"3. safe_download\u3001attempt_download"},{"location":"source_code_interpretation/utils/downloads_py.html#31-safe_download","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u4e0b\u8f7d url\uff08github\uff09 \u6216\u8005 url2\uff08\u8c37\u6b4c\u4e91\u670d\u52a1\u5668\uff09 \u7f51\u9875\u8def\u5f84\u5bf9\u5e94\u7684\u6587\u4ef6\uff0c \u901a\u5e38\u662f\u4e0b\u8f7d\u6743\u91cd\u6587\u4ef6\uff0c\u7ecf\u5e38\u7528\u5728 attempt_download \u51fd\u6570\u4e2d\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a def safe_download ( file , url , url2 = None , min_bytes = 1e0 , error_msg = \"\" ): \"\"\"\u7ecf\u5e38\u7528\u5728 attempt_download \u51fd\u6570\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u5355\u72ec\u4f7f\u7528 \u4e0b\u8f7d url/url2 \u7f51\u9875\u8def\u5f84\u5bf9\u5e94\u7684\u6587\u4ef6 Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes @params file: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d @params url: \u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740 \u4e00\u822c\u662fgithub @params url2: \u7b2c\u4e8c\u4e2a\u4e0b\u8f7d\u5730\u5740(\u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740\u4e0b\u8f7d\u5931\u8d25\u540e\u4f7f\u7528) \u4e00\u822c\u662fgoogleleaps\u7b49\u4e91\u670d\u52a1\u5668 @params min_bytes: \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765 \u53ea\u6709\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes\u624d\u80fd\u5224\u65ad\u6587\u4ef6\u5df2\u7ecf\u4e0b\u8f7d\u4e0b\u6765\u4e86 @params error_msg: \u6587\u4ef6\u4e0b\u8f7d\u5931\u8d25\u7684\u663e\u793a\u4fe1\u606f \u521d\u59cb\u5316\u9ed8\u8ba4\u4e3a\u7a7a \"\"\" # Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes file = Path ( file ) assert_msg = f \"Downloaded file ' { file } ' does not exist or size is < min_bytes= { min_bytes } \" try : # url1 y: \u5c1d\u8bd5\u4ece url \u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662f github \u94fe\u63a5 print ( f \"Downloading { url } to { file } ...\" ) // \u4f7f\u7528 oneflow . hub . download_url_to_file \u4e0b\u8f7d url \u94fe\u63a5\u5bf9\u5e94\u7684\u6587\u4ef6 \uff0c // \u5173\u4e8eoneflow . hub \u6a21\u5757\u8bb2\u89e3\u53ef\u4ee5\u770b \uff1a https : // www . bilibili . com / video / BV1YG4y1B72u / ? spm_id_from = 333.999.0.0 flow . hub . download_url_to_file ( url , str ( file )) # \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765\u4e86 (\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8e min_bytes ) assert file . exists () and file . stat () . st_size > min_bytes , assert_msg # check except Exception as e : # url2 url1 \u4e0d\u884c\u5c31\u5c1d\u8bd5\u4ece url2 \u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgoogleleaps(\u4e91\u670d\u52a1\u5668) # \u79fb\u9664\u4e4b\u524d\u4e0b\u8f7d\u5931\u8d25\u7684\u4e0d\u5b8c\u6574\u6587\u4ef6 file . unlink ( missing_ok = True ) # remove partial downloads print ( f \"ERROR: { e } \\n Re-attempting { url2 or url } to { file } ...\" ) os . system ( f \"curl -L ' { url2 or url } ' -o ' { file } ' --retry 3 -C -\" ) # curl download, retry and resume on fail finally : # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765\u4e86 \u6216 \u6587\u4ef6\u5927\u5c0f\u662f\u5426\u5c0f\u4e8emin_bytes if not file . exists () or file . stat () . st_size < min_bytes : # check # \u4e0b\u8f7d\u5931\u8d25 \u79fb\u9664\u4e0b\u8f7d\u5931\u8d25\u7684\u4e0d\u5b8c\u6574\u6587\u4ef6 remove partial downloads file . unlink ( missing_ok = True ) # remove partial downloads # \u6253\u5370\u9519\u8bef\u4fe1\u606f print ( f \"ERROR: { assert_msg } \\n { error_msg } \" ) print ( \"\" ) url = \"https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/model_comparison.png\" safe_download ( \"op.png\" , url ) Downloading https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/model_comparison.png to op.png... 0%| | 0.00/118k [00:00<?, ?B/s] from PIL import Image display ( Image . open ( \"op.png\" )) # \u663e\u793a\u4e0b\u8f7d\u7684\u56fe\u7247","title":"3.1 safe_download"},{"location":"source_code_interpretation/utils/downloads_py.html#32-attempt_download","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5b9e\u73b0\u4ece\u51e0\u4e2a\u4e91\u5e73\u53f0 (github/googleleaps\u4e91\u670d\u52a1\u5668/xxx) \u4e0b\u8f7d\u6587\u4ef6(\u5728one-yolov5\u4e2d\u4e00\u822c\u662f\u9884\u8bad\u7ec3\u6a21\u578b)\uff0c \u4f1a\u8c03\u7528\u4e0a\u9762\u7684 safe_download \u51fd\u6570\u3002\u4f1a\u7528\u5728 experimental.py \u4e2d\u7684 attempt_load \u51fd\u6570\u548c train.py \u4e2d\uff0c\u90fd\u662f\u7528\u6765\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002\u4ee3\u7801\u8be6\u89e3\u5982\u4e0b\uff1a def attempt_download ( file , repo = \"Oneflow-Inc/one-yolov5\" ): # from utils.downloads import *; attempt_download() \"\"\"\u7528\u5728attempt_download\u51fd\u6570\u4e2d \u4e0b\u8f7d url/url2 \u7f51\u9875\u8def\u5f84\u5bf9\u5e94\u7684\u6587\u4ef6 Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes :params file: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d :params url: \u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740 \u4e00\u822c\u662f github :params url2: \u7b2c\u4e8c\u4e2a\u4e0b\u8f7d\u5730\u5740(\u7b2c\u4e00\u4e2a\u4e0b\u8f7d\u5730\u5740\u4e0b\u8f7d\u5931\u8d25\u540e\u4f7f\u7528) \u4e00\u822c\u662fgoogleleaps \u7b49\u4e91\u670d\u52a1\u5668 :params min_bytes: \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e0b\u8f7d\u4e0b\u6765 \u53ea\u6709\u6587\u4ef6\u5b58\u5728\u4e14\u6587\u4ef6\u5927\u5c0f\u8981\u5927\u4e8emin_bytes \u624d\u80fd\u5224\u65ad\u6587\u4ef6\u5df2\u7ecf\u4e0b\u8f7d\u4e0b\u6765\u4e86 :params error_msg: \u6587\u4ef6\u4e0b\u8f7d\u5931\u8d25\u7684\u663e\u793a\u4fe1\u606f \u521d\u59cb\u5316\u9ed8\u8ba4\u2019\u2018 \"\"\" # Attempt file download if does not exist file = Path ( str ( file ) . strip () . replace ( \"'\" , \"\" )) if not file . exists (): # \u5c1d\u8bd5\u4eceurl\u4e2d\u4e0b\u8f7d\u6587\u4ef6 \u4e00\u822c\u662fgithub # URL specified # urllib.parse: \u89e3\u6790url # .unquote: \u5bf9url\u8fdb\u884c\u89e3\u7801 decode '%2F' to '/' etc. name = Path ( urllib . parse . unquote ( str ( file ))) . name # decode '%2F' to '/' etc. # \u5982\u679c\u89e3\u6790\u7684\u6587\u4ef6\u540d\u662fhttp:/ \u6216 https:/ \u5f00\u5934\u5c31\u76f4\u63a5\u4e0b\u8f7d if str ( file ) . startswith (( \"http:/\" , \"https:/\" )): # download # url: \u4e0b\u8f7d\u8def\u5f84 url \u5bf9\u5e94\u7684\u6587\u4ef6 url = str ( file ) . replace ( \":/\" , \"://\" ) # Pathlib turns :// -> :/ # name: \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d file = name . split ( \"?\" )[ 0 ] # parse authentication https://url.com/file.txt?auth... # \u5982\u679c\u6587\u4ef6\u5df2\u7ecf\u5728\u672c\u5730\u5b58\u5728\u4e86\u5c31\u4e0d\u7528\u4e0b\u8f7d\u4e86 if Path ( file ) . is_file (): print ( f \"Found { url } locally at { file } \" ) # file already exists else : safe_download ( file = file , url = url , min_bytes = 1e5 ) # \u4e0b\u8f7d\u6587\u4ef6 return file # GitHub assets file . parent . mkdir ( parents = True , exist_ok = True ) # make parent dir (if required) try : # \u5229\u7528 github api \u83b7\u53d6\u6700\u65b0\u7684\u7248\u672c\u76f8\u5173\u4fe1\u606f \u8fd9\u91cc\u7684 response \u662f\u4e00\u4e2a\u5b57\u5178 response = requests . get ( f \"https://api.github.com/repos/ { repo } /releases/latest\" ) . json () # github api assets = [ x [ \"name\" ] for x in response [ \"assets\" ]] # release assets, i.e. ['yolov5s', 'yolov5m', ...] tag = response [ \"tag_name\" ] # i.e. 'v1.0' except : # fallback plan \u83b7\u53d6\u5931\u8d25 \u5c31\u9000\u800c\u6c42\u5176\u6b21 \u76f4\u63a5\u5229\u7528 git \u547d\u4ee4\u5f3a\u884c\u8865\u9f50\u7248\u672c\u4fe1\u606f assets = [ \"yolov5n.zip\" , \"yolov5s.zip\" , \"yolov5m.zip\" , \"yolov5l.zip\" , \"yolov5x.zip\" , \"yolov5n6.zip\" , \"yolov5s6.zip\" , \"yolov5m6.zip\" , \"yolov5l6.zip\" , \"yolov5x6.zip\" , ] try : # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u5728\u547d\u4ee4\u884c\u6267\u884c git tag \u547d\u4ee4(\u8fd4\u56de\u7248\u672c\u53f7 \u7248\u672c\u53f7\u4fe1\u606f\u4e00\u822c\u5728\u5b57\u5178\u6700\u540e\u4e00\u4e2a -1) \u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u7248\u672c\u53f7 tag) tag = subprocess . check_output ( \"git tag\" , shell = True , stderr = subprocess . STDOUT ) . decode () . split ()[ - 1 ] except : # \u5982\u679c\u8fd8\u662f\u5931\u8d25 \u5c31\u5f3a\u884c\u81ea\u5df1\u8865\u4e00\u4e2a\u7248\u672c\u53f7 tag='v1.1' \uff0c\u6bd4\u5982\u8fd9\u91cc\u5728 one-yolov5 \u4e2d\u76f4\u63a5\u8865\u5f53\u524d\u7684\u6700\u65b0\u7248\u672c v1.1. tag = \"v1.1\" # current release if \".zip\" not in name : name = name + \".zip\" file = Path ( name ) if name in assets : safe_download ( file , url = f \"https://github.com/ { repo } /releases/download/ { tag } / { name } \" , # url2=f'https://storage.googleapis.com/{repo}/ckpt/{name}', # backup url (optional) min_bytes = 1e5 , error_msg = f \" { file } missing, try downloading from https://github.com/ { repo } /releases/\" , ) if \".zip\" in name : new_dir = Path ( name [: - 4 ]) else : new_dir = Path ( name ) if not os . path . exists ( new_dir ): # \u5224\u65ad\u6587\u4ef6\u5939\u662f\u5426\u5b58\u5728 os . mkdir ( new_dir ) # \u65b0\u5efa\u6587\u4ef6\u5939 if \".zip\" in name : print ( \"unzipping... \" , end = \"\" ) # ZipFile(new_file).extractall(path=file.parent) # unzip f = ZipFile ( file ) f . extractall ( new_dir ) os . remove ( file ) # remove zip tmp_dir = \"/tmp/oneyolov5\" if os . path . isdir ( tmp_dir ): shutil . rmtree ( tmp_dir ) if \".zip\" in name : path1 = os . path . join ( name [: - 4 ], name [: - 4 ]) else : path1 = os . path . join ( name , name ) shutil . copytree ( path1 , tmp_dir ) shutil . rmtree ( new_dir ) shutil . copytree ( tmp_dir , new_dir ) shutil . rmtree ( tmp_dir ) return str ( file ) attempt_download ( \"yolov5n\" ) Downloading https://github.com/Oneflow-Inc/one-yolov5/releases/download/v1.0.0/yolov5n.zip to yolov5n.zip... 0%| | 0.00/3.53M [00:00<?, ?B/s] unzipping... 'yolov5n.zip'","title":"3.2 attempt_download"},{"location":"source_code_interpretation/utils/downloads_py.html#4-get_token-gdrive_download","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u5b9e\u73b0\u4ece google drive \u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6\u3002\u4f46\u662f\u8fd9\u597d\u50cf\u5e76\u6ca1\u6709\u5728\u4ee3\u7801\u4e2d\u4f7f\u7528\uff0c\u6240\u4ee5\u8fd9\u4e24\u4e2a\u51fd\u6570\u53ef\u4ee5\u968f\u4fbf\u4e86\u89e3\u4e0b\u5c31\u597d\uff0c\u4e3b\u8981\u8fd8\u662f\u8981\u638c\u63e1\u4e0a\u9762\u7684\u4e24\u4e2a\u4e0b\u8f7d\u51fd\u6570\u7528\u7684\u6bd4\u8f83\u591a\u3002","title":"4. get_token &amp; gdrive_download\uff08\u6ca1\u4f7f\u7528\uff09"},{"location":"source_code_interpretation/utils/downloads_py.html#41-get_token","text":"\u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4ece cookie\u4e2d \u83b7\u53d6\u4ee4\u724c token \u3002\u4f1a\u5728 gdrive_download \u4e2d\u88ab\u8c03\u7528\u3002 get_token\u51fd\u6570\u4ee3\u7801\uff1a def get_token ( cookie = \"./cookie\" ): \"\"\"\u5728gdrive_download\u4e2d\u4f7f\u7528 \u5b9e\u73b0\u4ececookie\u4e2d\u83b7\u53d6\u4ee4\u724ctoken \"\"\" with open ( cookie ) as f : for line in f : if \"download\" in line : return line . split ()[ - 1 ] return \"\"","title":"4.1 get_token"},{"location":"source_code_interpretation/utils/downloads_py.html#42-gdrive_download","text":"\u8fd9\u4e2a\u51fd\u6570\u5b9e\u73b0\u4ece google drive \u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6\u3002\u8fd9\u4e2a\u51fd\u6570\u8c8c\u4f3c\u6ca1\u7528\u5230\uff0c\u968f\u4fbf\u770b\u4e0b\u5c31\u597d\u3002 gdrive_download\u51fd\u6570\u4ee3\u7801\uff1a def gdrive_download ( id = '16TiPfZj7htmTyhntwcZyEEAejOUxuT6m' , file = 'tmp.zip' ): \"\"\" \u5b9e\u73b0\u4ece google drive \u4e0a\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6\u5e76\u5c06\u5176\u89e3\u538b, \u518d\u5220\u9664\u6389\u538b\u7f29\u6587\u4ef6 :params id: url\u7684?\u540e\u9762\u7684 id \u53c2\u6570\u7684\u53c2\u6570\u503c :params file: \u9700\u8981\u4e0b\u8f7d\u7684\u538b\u7f29\u6587\u4ef6\u540d \"\"\" t = time . time () # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4 file = Path ( file ) # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 cookie = Path ( 'cookie' ) # gdrive cookie print ( f 'Downloading https://drive.google.com/uc?export=download&id= { id } as { file } ... ' , end = '' ) file . unlink ( missing_ok = True ) # \u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684\u6587\u4ef6(\u53ef\u80fd\u662f\u4e0b\u8f7d\u5931\u8d25/\u4e0b\u8f7d\u4e0d\u5b8c\u6574\u7684\u6587\u4ef6) cookie . unlink ( missing_ok = True ) # \u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684cookie # \u5c1d\u8bd5\u4e0b\u8f7d\u538b\u7f29\u6587\u4ef6 out = \"NUL\" if platform . system () == \"Windows\" else \"/dev/null\" # \u4f7f\u7528 cmd \u547d\u4ee4\u4ece google drive \u4e0a\u4e0b\u8f7d\u6587\u4ef6 os . system ( f 'curl -c ./cookie -s -L \"drive.google.com/uc?export=download&id= { id } \" > { out } ' ) if os . path . exists ( 'cookie' ): # \u5982\u679c\u6587\u4ef6\u8f83\u5927 \u5c31\u9700\u8981\u6709\u4ee4\u724c get_token (\u5b58\u5728 cookie \u624d\u6709\u4ee4\u724c)\u7684\u6307\u4ee4 s \u624d\u80fd\u4e0b\u8f7d # get_token() \u51fd\u6570\u5728\u4e0a\u9762\u5b9a\u4e49\u4e86\uff0c\u7528\u4e8e\u83b7\u53d6\u5f53\u524d cookie \u7684\u4ee4\u724c token s = f 'curl -Lb ./cookie \"drive.google.com/uc?export=download&confirm= { get_token () } &id= { id } \" -o { file } ' else : # \u5c0f\u6587\u4ef6\u5c31\u4e0d\u9700\u8981\u5e26\u4ee4\u724c\u7684\u6307\u4ee4 s \u76f4\u63a5\u4e0b\u8f7d\u5c31\u884c s = f 'curl -s -L -o { file } \"drive.google.com/uc?export=download&id= { id } \"' # \u6267\u884c\u4e0b\u8f7d\u6307\u4ee4 s \u5e76\u83b7\u5f97\u8fd4\u56de\u503c \u5982\u679c cmd \u547d\u4ee4\u6267\u884c\u6210\u529f \u5219 os.system()\u547d\u4ee4\u4f1a\u8fd4\u56de 0 r = os . system ( s ) cookie . unlink ( missing_ok = True ) # \u518d\u6b21\u79fb\u9664\u5df2\u7ecf\u5b58\u5728\u7684cookie # \u4e0b\u8f7d\u9519\u8bef\u68c0\u6d4b \u5982\u679c r != 0 \u5219\u4e0b\u8f7d\u9519\u8bef if r != 0 : file . unlink ( missing_ok = True ) # \u4e0b\u8f7d\u9519\u8bef \u79fb\u9664\u4e0b\u8f7d\u7684\u6587\u4ef6(\u53ef\u80fd\u4e0d\u5b8c\u6574\u6216\u8005\u4e0b\u8f7d\u5931\u8d25) print ( 'Download error ' ) # raise Exception('Download error') return r # \u5982\u679c\u662f\u538b\u7f29\u6587\u4ef6 \u5c31\u89e3\u538b file.suffix \u65b9\u6cd5\u53ef\u4ee5\u83b7\u53d6 file \u6587\u4ef6\u7684\u540e\u7f00 if file . suffix == '.zip' : print ( 'unzipping... ' , end = '' ) os . system ( f 'unzip -q { file } ' ) # cmd\u547d\u4ee4\u6267\u884c\u89e3\u538b\u547d\u4ee4 file . unlink () # \u79fb\u9664 .zip \u538b\u7f29\u6587\u4ef6 print ( f 'Done ( { time . time () - t : .1f } s)' ) # \u6253\u5370\u4e0b\u8f7d + \u89e3\u538b\u8fc7\u7a0b\u6240\u9700\u8981\u7684\u65f6\u95f4 return r","title":"4.2 gdrive_download"},{"location":"source_code_interpretation/utils/downloads_py.html#_2","text":"\u8fd9\u4e2a\u6587\u4ef6\u7684\u4ee3\u7801\u6bd4\u8f83\u5c11\uff0c\u771f\u6b63\u6709\u7528\u7684\u51fd\u6570\u4e5f\u6bd4\u8f83\u5c11\u3002 \u4e5f\u5c31\u662fsafe_download\u548cattempt_download\u4e24\u4e2a\u51fd\u6570\u6bd4\u8f83\u91cd\u8981\uff0c\u5927\u5bb6\u91cd\u70b9\u638c\u63e1\u8fd9\u4e24\u4e2a\u51fd\u6570\u5373\u53ef\u3002","title":"\u603b\u7ed3"},{"location":"source_code_interpretation/utils/downloads_py.html#reference","text":"\u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011google_utils.py","title":"Reference"},{"location":"source_code_interpretation/utils/general_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/general.py \u8fd9\u4e2a\u6587\u4ef6\u662fyolov5\u7684\u901a\u7528\u5de5\u5177\u7c7b\uff0c\u5199\u4e86\u4e00\u4e9b\u901a\u7528\u7684\u5de5\u5177\u51fd\u6570\uff0c\u7528\u7684\u5f88\u5e7f\uff0c\u6574\u4e2a\u9879\u76ee\u54ea\u91cc\u90fd\u53ef\u80fd\u7528\u5230\u3002 \u8fd9\u4e2a\u6587\u4ef6\u7684\u51fd\u6570\u975e\u5e38\u591a\uff0c\u4ee3\u7801\u91cf\u4e5f\u5f88\u5927\uff08\u4e0a\u5343\u884c\u4e86\uff09\uff0c\u4e5f\u90fd\u6bd4\u8f83\u91cd\u8981\uff0c\u5e0c\u671b\u5927\u5bb6\u770b\u7684\u65f6\u5019\u591a\u70b9\u8010\u5fc3\uff0c\u90fd\u80fd\u638c\u63e1\uff01 1. \u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e # import contextlib # python\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668 \u6267\u884cwith\u2026as\u2026\u7684\u65f6\u5019\u8c03\u7528contextlib import glob # \u4ec5\u652f\u6301\u90e8\u5206\u901a\u914d\u7b26\u7684\u6587\u4ef6\u641c\u7d22\u6a21\u5757 import logging # \u65e5\u5fd7\u6a21\u5757 import math # \u6570\u5b66\u516c\u5f0f\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 import platform # \u63d0\u4f9b\u83b7\u53d6\u64cd\u4f5c\u7cfb\u7edf\u76f8\u5173\u4fe1\u606f\u7684\u6a21\u5757 import random # \u751f\u6210\u968f\u673a\u6570\u7684\u6a21\u5757 import re # \u7528\u6765\u5339\u914d\u5b57\u7b26\u4e32\uff08\u52a8\u6001\u3001\u6a21\u7cca\uff09\u7684\u6a21\u5757 import signal # \u4fe1\u53f7\u5904\u7406\u6a21\u5757 import time # \u65f6\u95f4\u6a21\u5757 \u66f4\u5e95\u5c42 import urllib # \u7528\u4e8e\u64cd\u4f5c\u7f51\u9875URL, \u5e76\u5bf9\u7f51\u9875\u7684\u5185\u5bb9\u8fdb\u884c\u6293\u53d6\u5904\u7406 \u5982urllib.parse: \u89e3\u6790url from itertools import repeat # \u5faa\u73af\u5668\u6a21\u5757 \u521b\u5efa\u4e00\u4e2a\u8fed\u4ee3\u5668\uff0c\u91cd\u590d\u751f\u6210object from multiprocessing.pool import ThreadPool # \u591a\u7ebf\u7a0b\u6a21\u5757 \u7ebf\u7a0b\u6c60 from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 from subprocess import check_output # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u518d\u547d\u4ee4\u884c\u6267\u884c..., \u6700\u540e\u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u6587\u4ef6) from typing import Optional from zipfile import ZipFile import cv2 # opencv\u5e93 import numpy as np # numpy\u77e9\u9635\u5904\u7406\u51fd\u6570\u5e93 import oneflow as flow # OneFlow\u6846\u67b6 import oneflow.backends.cudnn as cudnn import pandas as pd # pandas\u77e9\u9635\u64cd\u4f5c\u6a21\u5757 import pkg_resources as pkg # \u7528\u4e8e\u67e5\u627e, \u81ea\u7701, \u6fc0\u6d3b\u548c\u4f7f\u7528\u5df2\u5b89\u88c5\u7684Python\u53d1\u884c\u7248 import yaml # yaml\u914d\u7f6e\u6587\u4ef6\u8bfb\u5199\u6a21\u5757 from utils.downloads import gsutil_getsize from utils.metrics import box_iou , fitness FILE = Path ( __file__ ) . resolve () ROOT = FILE . parents [ 1 ] # YOLOv5 root directory RANK = int ( os . getenv ( \"RANK\" , - 1 )) # Settings DATASETS_DIR = ROOT . parent / \"datasets\" # YOLOv5 datasets directory # \u786e\u5b9a\u6700\u5927\u7684\u7ebf\u7a0b\u6570 \u8fd9\u91cc\u88ab\u9650\u5236\u5728\u4e868 NUM_THREADS = min ( 8 , max ( 1 , os . cpu_count () - 1 )) # number of YOLOv5 multiprocessing threads AUTOINSTALL = str ( os . getenv ( \"YOLOv5_AUTOINSTALL\" , True )) . lower () == \"true\" # global auto-install mode VERBOSE = str ( os . getenv ( \"YOLOv5_VERBOSE\" , True )) . lower () == \"true\" # global verbose mode FONT = \"Arial.ttf\" # https://ultralytics.com/assets/Arial.ttf # \u8bbe\u7f6e\u8fd0\u884c\u76f8\u5173\u7684\u4e00\u4e9b\u57fa\u672c\u7684\u914d\u7f6e Settings # \u63a7\u5236 print \u6253\u5370 oneflow.tensor \u683c\u5f0f\u8bbe\u7f6e tensor \u7cbe\u5ea6\u4e3a5(\u5c0f\u6570\u70b9\u540e5\u4f4d) \u6bcf\u884c\u5b57\u7b26\u6570\u4e3a320\u4e2a \u663e\u793a\u65b9\u6cd5\u4e3along flow . set_printoptions ( linewidth = 320 , precision = 5 , profile = \"long\" ) # \u63a7\u5236print\u6253\u5370np.array\u683c\u5f0f\u8bbe\u7f6e \u7cbe\u5ea6\u4e3a5 \u6bcf\u884c\u5b57\u7b26\u6570\u4e3a320\u4e2a format short g, %precision=5 np . set_printoptions ( linewidth = 320 , formatter = { \"float_kind\" : \" {:11.5g} \" . format }) # format short g, %precision=5 # pandas\u7684\u6700\u5927\u663e\u793a\u884c\u6570\u662f10 pd . options . display . max_columns = 10 # \u963b\u6b62opencv\u53c2\u4e0e\u591a\u7ebf\u7a0b(\u4e0e Pytorch\u7684 Dataloader\u4e0d\u517c\u5bb9) cv2 . setNumThreads ( 0 ) # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader) os . environ [ \"NUMEXPR_MAX_THREADS\" ] = str ( NUM_THREADS ) # NumExpr max threads os . environ [ \"OMP_NUM_THREADS\" ] = \"1\" if platform . system () == \"darwin\" else str ( NUM_THREADS ) # OpenMP (Pyflow and SciPy) 2. timeout\uff08\u6ca1\u7528\u5230\uff09 \u8fd9\u4e2a\u51fd\u6570\u662f\u81ea\u5b9a\u4e49\u7684timeout\u8d85\u65f6\u51fd\u6570\uff0c\u5982\u679c\u67d0\u4e2a\u7a0b\u5e8f\u6267\u884c\u8d85\u65f6\uff0c \u5c31\u4f1a\u89e6\u53d1\u8d85\u65f6\u5904\u7406\u51fd\u6570_timeout_handler \u8fd4\u56de\u8d85\u65f6\u5f02\u5e38\u4fe1\u606f\u3002 \u4f46\u662f\u8fd9\u4e2a\u51fd\u6570\u6ca1\u7528\u5230\uff0c\u4ee3\u7801\u4e2d\u90fd\u662f\u4f7f\u7528\u5e93\u51fd\u6570\u81ea\u5df1\u5b9a\u4e49\u7684timeout\uff0c\u6ca1\u7528\u7528\u8fd9\u4e2a\u81ea\u5b9a\u4e49\u7684timeout\u51fd\u6570\u3002 \u6240\u4ee5\u8fd9\u4e2a\u51fd\u6570\u53ef\u4ee5\u4e86\u89e3\u4e0b\u5c31\u884c\uff0c\u4e0d\u8fc7\u8fd9\u79cd\u8d85\u65f6\u63d0\u793a\u7684\u4ee3\u7801\u8fd8\u662f\u6709\u5fc5\u8981\u5b66\u4e60\u7684\u3002 timeout\u51fd\u6570\u4ee3\u7801\uff1a class timeout ( contextlib . ContextDecorator ): \"\"\"\u6ca1\u7528\u5230 \u4ee3\u7801\u4e2d\u90fd\u662f\u4f7f\u7528\u5e93\u51fd\u6570\u81ea\u5df1\u5b9a\u4e49\u7684timeout \u6ca1\u7528\u7528\u8fd9\u4e2a\u81ea\u5b9a\u4e49\u7684timeout\u51fd\u6570 \u8bbe\u7f6e\u4e00\u4e2a\u8d85\u65f6\u51fd\u6570 \u5982\u679c\u67d0\u4e2a\u7a0b\u5e8f\u6267\u884c\u8d85\u65f6 \u5c31\u4f1a\u89e6\u53d1\u8d85\u65f6\u5904\u7406\u51fd\u6570_timeout_handler \u8fd4\u56de\u8d85\u65f6\u5f02\u5e38\u4fe1\u606f \u5e76\u6ca1\u6709\u7528\u5230 \u8fd9\u91cc\u9762\u7684timeout\u90fd\u662f\u7528python\u5e93\u51fd\u6570\u5b9e\u73b0\u7684 \u5e76\u4e0d\u9700\u8981\u81ea\u5df1\u53e6\u5916\u5199\u4e00\u4e2a \u4f7f\u7528: with timeout(seconds): sleep(10) \u6216\u8005 @timeout(seconds) decorator dealing with wandb login-options timeout issues as well as check_github() timeout issues \"\"\" def __init__ ( self , seconds , * , timeout_msg = '' , suppress_timeout_errors = True ): self . seconds = int ( seconds ) # \u9650\u5236\u65f6\u95f4 self . timeout_message = timeout_msg # \u62a5\u9519\u4fe1\u606f self . suppress = bool ( suppress_timeout_errors ) def _timeout_handler ( self , signum , frame ): # \u8d85\u65f6\u5904\u7406\u51fd\u6570 \u4e00\u65e6\u8d85\u65f6 \u5c31\u5728seconds\u540e\u53d1\u9001\u8d85\u65f6\u4fe1\u606f raise TimeoutError ( self . timeout_message ) def __enter__ ( self ): # signal.signal: \u8bbe\u7f6e\u4fe1\u53f7\u5904\u7406\u7684\u51fd\u6570_timeout_handler # \u6267\u884c\u6d41\u8fdb\u5165with\u4e2d\u4f1a\u6267\u884c__enter__\u65b9\u6cd5 \u5982\u679c\u53d1\u751f\u8d85\u65f6, \u5c31\u4f1a\u89e6\u53d1\u8d85\u65f6\u5904\u7406\u51fd\u6570_timeout_handler \u8fd4\u56de\u8d85\u65f6\u5f02\u5e38\u4fe1\u606f signal . signal ( signal . SIGALRM , self . _timeout_handler ) # Set handler for SIGALRM # signal.alarm: \u8bbe\u7f6e\u53d1\u9001SIGALRM\u4fe1\u53f7\u7684\u5b9a\u65f6\u5668 signal . alarm ( self . seconds ) # start countdown for SIGALRM to be raised def __exit__ ( self , exc_type , exc_val , exc_tb ): # \u6267\u884c\u6d41\u79bb\u5f00 with \u5757\u65f6(\u6ca1\u6709\u53d1\u751f\u8d85\u65f6), \u5219\u8c03\u7528\u8fd9\u4e2a\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u7684__exit__\u65b9\u6cd5\u6765\u6e05\u7406\u6240\u4f7f\u7528\u7684\u8d44\u6e90 signal . alarm ( 0 ) # Cancel SIGALRM if it's scheduled if self . suppress and exc_type is TimeoutError : # Suppress TimeoutError return True 3.set_logging\u3001init_seeds \u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u4e00\u4e9b\u521d\u59cb\u5316\u64cd\u4f5c\u3002 set_logging\u662f\u5bf9\u65e5\u5fd7\u7684\u8bbe\u7f6e(format\u3001level)\u7b49\u8fdb\u884c\u521d\u59cb\u5316\uff0cinit_seeds\u662f\u8bbe\u7f6e\u4e00\u7cfb\u5217\u7684\u968f\u673a\u6570\u79cd\u5b50 3.1 set_logging \u8fd9\u4e2a\u51fd\u6570\u662f\u5bf9\u65e5\u5fd7\u7684\u683c\u5f0f\u3001\u7b49\u7ea7\u7b49\u8fdb\u884c\u4e00\u4e2a\u521d\u59cb\u5316\u3002 def set_logging ( name = None , verbose = VERBOSE ): \"\"\"\u5e7f\u6cdb\u4f7f\u7528\u5728train.py\u3001test.py\u3001detect.py\u7b49\u6587\u4ef6\u7684main\u51fd\u6570\u7684\u7b2c\u4e00\u6b65 \u5bf9\u65e5\u5fd7\u7684\u8bbe\u7f6e(format\u3001level)\u7b49\u8fdb\u884c\u521d\u59cb\u5316 \"\"\" # Sets level and returns logger if is_kaggle (): for h in logging . root . handlers : logging . root . removeHandler ( h ) # remove all handlers associated with the root logger object rank = int ( os . getenv ( \"RANK\" , - 1 )) # rank in world for Multi-GPU trainings' # \u8bbe\u7f6e\u65e5\u5fd7\u7ea7\u522b level = logging . INFO if verbose and rank in { - 1 , 0 } else logging . ERROR log = logging . getLogger ( name ) log . setLevel ( level ) handler = logging . StreamHandler () handler . setFormatter ( logging . Formatter ( \" %(message)s \" )) handler . setLevel ( level ) log . addHandler ( handler ) 3.2 init_seeds \u8fd9\u4e2a\u51fd\u6570\u662f\u4f7f\u7528random.random()\u3001np.random.rand()\u3001init_torch_seeds\uff08\u8c03\u7528torch_utils.py\u4e2d\u7684\u51fd\u6570\uff09 \u7b49\u751f\u6210\u4e00\u7cfb\u5217\u7684\u968f\u673a\u6570\u79cd\u5b50\uff0c\u4ee5\u4fdd\u8bc1\u7ed3\u679c\u7684\u53ef\u590d\u73b0\u6027\u3002 init_seeds\u51fd\u6570\u4ee3\u7801\uff1a def init_seeds ( seed = 0 , deterministic = False ): # Initialize random number generator (RNG) seeds https://pyflow.org/docs/stable/notes/randomness.html # cudnn seed 0 settings are slower and more reproducible, else faster and less reproducible # \u8bbe\u7f6e\u968f\u673a\u6570 \u9488\u5bf9\u4f7f\u7528random.random()\u751f\u6210\u968f\u673a\u6570\u7684\u65f6\u5019\u76f8\u540c random . seed ( seed ) # \u8bbe\u7f6e\u968f\u673a\u6570 \u9488\u5bf9\u4f7f\u7528np.random.rand()\u751f\u6210\u968f\u673a\u6570\u7684\u65f6\u5019\u76f8\u540c np . random . seed ( seed ) # \u4e3aCPU\u8bbe\u7f6e\u79cd\u5b50\u7528\u4e8e\u751f\u6210\u968f\u673a\u6570\u7684\u65f6\u5019\u76f8\u540c \u5e76\u786e\u5b9a\u8bad\u7ec3\u6a21\u5f0f flow . manual_seed ( seed ) cudnn . benchmark , cudnn . deterministic = ( False , True ) flow . cuda . manual_seed ( seed ) flow . cuda . manual_seed_all ( seed ) # for Multi-GPU, exception safe 4. get_latest_run \u8fd9\u4e2a\u51fd\u6570\u7684\u4f5c\u7528\u662f\u67e5\u627e\u6700\u8fd1\u4fdd\u5b58\u7684\u6743\u91cd\u6587\u4ef6 last*.pt\uff0c\u7528\u4ee5\u8fdb\u884c\u65ad\u70b9\u7eed\u8bad\u3002 get_latest_run\u51fd\u6570\u4ee3\u7801\uff1a def get_latest_run ( search_dir = \".\" ): # Return path to most recent 'last.pt' in /runs (i.e. to --resume from) \"\"\"\u7528\u5728train.py\u67e5\u627e\u6700\u8fd1\u7684pt\u6587\u4ef6\u8fdb\u884c\u65ad\u70b9\u7eed\u8bad \u7528\u4e8e\u8fd4\u56de\u8be5\u9879\u76ee\u4e2d\u6700\u8fd1\u7684\u6a21\u578b 'last.pt'\u5bf9\u5e94\u7684\u8def\u5f84 :params search_dir: \u8981\u641c\u7d22\u7684\u6587\u4ef6\u7684\u6839\u76ee\u5f55 \u9ed8\u8ba4\u662f '.' \u8868\u793a\u641c\u7d22\u8be5\u9879\u76ee\u4e2d\u7684\u6587\u4ef6 \"\"\" # \u4ecePython\u7248\u672c3.5\u5f00\u59cb, glob\u6a21\u5757\u652f\u6301\u8be5\"**\"\u6307\u4ee4\uff08\u4ec5\u5f53\u4f20\u9012recursive\u6807\u5fd7\u65f6\u624d\u4f1a\u89e3\u6790\u8be5\u6307\u4ee4) # glob.glob\u51fd\u6570\u5339\u914d\u6240\u6709\u7684\u7b26\u5408\u6761\u4ef6\u7684\u6587\u4ef6, \u5e76\u5c06\u5176\u4ee5list\u7684\u5f62\u5f0f\u8fd4\u56de last_list = glob . glob ( f \" { search_dir } /**/last\" , recursive = True ) # os.path.getctime \u8fd4\u56de\u8def\u5f84\u5bf9\u5e94\u6587\u4ef6\u7684\u521b\u5efa\u65f6\u95f4 # \u6240\u4ee5\u8fd9\u91cc\u662f\u8fd4\u56de\u8def\u5f84\u5217\u8868\u4e2d\u521b\u5efa\u65f6\u95f4\u6700\u665a(\u6700\u8fd1\u7684last\u6587\u4ef6)\u7684\u8def\u5f84 return max ( last_list , key = os . path . getctime ) if last_list else \"\" \u51fd\u6570\u5728train.py\u4e2d\u88ab\u8c03\u7528\uff1a 5. is_docker\u3001is_colab\u3001is_pip \u4e0b\u9762\u662f\u4e09\u4e2a\u68c0\u6d4b\u51fd\u6570\uff0cis_docker\u68c0\u6d4b\u5f53\u524d\u73af\u5883\u662f\u5426\u662fdocker\u73af\u5883\uff0c is_colab\u68c0\u67e5\u5f53\u524d\u73af\u5883\u662f\u5426\u662fGoogle Colab\u73af\u5883\uff0cis_pip\u68c0\u6d4b 5.1 is_docker \u8fd9\u4e2a\u51fd\u6570\u662f\u67e5\u8be2\u5f53\u524d\u73af\u5883\u662f\u5426\u662fdocker\u73af\u5883\uff0c\u4f1a\u7528\u5230\u540e\u9762\u7684check_git_status\u548ccheck_imshow\u7b49\u51fd\u6570\u4e2d\u3002 is_docker\u51fd\u6570\u4ee3\u7801\uff1a def is_docker () -> bool : \"\"\" \u5728\u540e\u9762\u7684check_git_status\u548ccheck_imshow\u7b49\u51fd\u6570\u4e2d\u88ab\u8c03\u7528 \u67e5\u8be2\u5f53\u524d\u73af\u5883\u662f\u5426\u662fdocker\u73af\u5883 Is environment a Docker container? Check if the process runs inside a docker container. \"\"\" if Path ( \"/.dockerenv\" ) . exists (): return True try : # check if docker is in control groups with open ( \"/proc/self/cgroup\" ) as file : return any ( \"docker\" in line for line in file ) except OSError : return False 5.2 is_colab \u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u5f53\u524d\u73af\u5883\u662f\u5426\u662fGoogle Colab\u73af\u5883\uff0c\u4f1a\u7528\u5230\u540e\u9762\u7684check_imshow\u51fd\u6570\u4e2d\u3002 is_colab\u51fd\u6570\u4ee3\u7801\uff1a def is_colab (): \"\"\"\u7528\u5230\u540e\u9762\u7684check_imshow\u51fd\u6570\u4e2d \u68c0\u67e5\u5f53\u524d\u73af\u5883\u662f\u5426\u662fGoogle Colab\u73af\u5883 Is environment a Google Colab instance? \"\"\" try : import google.colab return True except Exception as e : return False 5.3 is_pip\uff08\u6ca1\u7528\u5230\uff09 \u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u6d4b\u5f53\u524d\u6587\u4ef6\u662f\u5426\u5728pip package(site-packages)\u6587\u4ef6\u91cc\uff0c\u4e0d\u8fc7\u8fd9\u4e2a\u51fd\u6570\u6ca1\u7528\u5230\u3002 is_pip\u51fd\u6570\u4ee3\u7801\uff1a def is_pip (): \"\"\"\u6ca1\u7528\u5230 \u5f53\u524d\u6587\u4ef6\u662f\u5426\u5728pip package(site-packages)\u6587\u4ef6\u91cc Is file in a pip package? \"\"\" return 'site-packages' in Path ( __file__ ) . absolute () . parts 6. file_size\uff08\u6ca1\u7528\u5230\uff09 \u8fd9\u4e2a\u51fd\u6570\u662f\u8fd4\u56de\u672c\u5730\u6587\u4ef6\u7684\u5927\u5c0f\uff0c \u529f\u80fd\u548c\u4e4b\u524dgoogle_utils.py\u4e2d\u7684gsutil_getsize\u51fd\u6570\uff08\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5\u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f\uff09\u5f88\u50cf\u3002 \u4e0d\u8fc7\u8fd9\u4e2a\u51fd\u6570\u5e76\u6ca1\u6709\u7528\u5230\u54e6\uff0c\u968f\u4fbf\u770b\u770b\u5c31\u597d\u3002 def file_size ( path ): # Return file/dir size (MB) \u8fd4\u56de\u672c\u5730\u6587\u4ef6\u7684\u5927\u5c0f(MB) #:params path: \u8981\u67e5\u8be2\u7684\u6587\u4ef6\u5730\u5740 mb = 1 << 20 # bytes to MiB (1024 ** 2) path = Path ( path ) if path . is_file (): return path . stat () . st_size / mb elif path . is_dir (): # .stat(): \u8fd4\u56de\u6587\u4ef6\u76f8\u5173\u72b6\u6001 st_size: \u8fd4\u56de\u6587\u4ef6\u7684\u5927\u5c0f return sum ( f . stat () . st_size for f in path . glob ( \"**/*\" ) if f . is_file ()) / mb else : return 0.0 7. colorstr \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u8f93\u51fa\u7684\u5f00\u5934\u548c\u7ed3\u5c3e\u52a0\u4e0a\u989c\u8272\uff0c\u4f7f\u547d\u4ee4\u884c\u8f93\u51fa\u663e\u793a\u4f1a\u66f4\u52a0\u597d\u770b\u3002 colorstr\u51fd\u6570\u4ee3\u7801\uff1a def colorstr ( * input ): \"\"\"\u7528\u5230\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570 train.py\u3001test.py\u3001detect.py\u7b49\u6587\u4ef6\u4e2d \u628a\u8f93\u51fa\u7684\u5f00\u5934\u548c\u7ed3\u5c3e\u52a0\u4e0a\u989c\u8272 \u547d\u4ee4\u884c\u8f93\u51fa\u663e\u793a\u4f1a\u66f4\u52a0\u597d\u770b \u5982: colorstr('blue', 'hello world') Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code \"\"\" # \u5982\u679c\u8f93\u5165\u957f\u5ea6\u4e3a1, \u5c31\u662f\u6ca1\u6709\u9009\u62e9\u989c\u8272 \u5219\u9009\u62e9\u9ed8\u8ba4\u989c\u8272\u8bbe\u7f6e blue + bold # args: \u8f93\u5165\u7684\u989c\u8272\u5e8f\u5217 string: \u8f93\u5165\u7684\u5b57\u7b26\u4e32 # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e. colorstr('blue', 'hello world') * args , string = input if len ( input ) > 1 else ( \"blue\" , \"bold\" , input [ 0 ]) # color arguments, string # \u5b9a\u4e49\u4e00\u4e9b\u57fa\u7840\u7684\u989c\u8272 \u548c \u5b57\u4f53\u8bbe\u7f6e colors = { \"black\" : \" \\033 [30m\" , # basic colors \"red\" : \" \\033 [31m\" , \"green\" : \" \\033 [32m\" , \"yellow\" : \" \\033 [33m\" , \"blue\" : \" \\033 [34m\" , \"magenta\" : \" \\033 [35m\" , \"cyan\" : \" \\033 [36m\" , \"white\" : \" \\033 [37m\" , \"bright_black\" : \" \\033 [90m\" , # bright colors \"bright_red\" : \" \\033 [91m\" , \"bright_green\" : \" \\033 [92m\" , \"bright_yellow\" : \" \\033 [93m\" , \"bright_blue\" : \" \\033 [94m\" , \"bright_magenta\" : \" \\033 [95m\" , \"bright_cyan\" : \" \\033 [96m\" , \"bright_white\" : \" \\033 [97m\" , \"end\" : \" \\033 [0m\" , # misc \"bold\" : \" \\033 [1m\" , \"underline\" : \" \\033 [4m\" , } # \u628a\u8f93\u51fa\u7684\u5f00\u5934\u548c\u7ed3\u5c3e\u52a0\u4e0a\u989c\u8272 \u547d\u4ee4\u884c\u8f93\u51fa\u663e\u793a\u4f1a\u66f4\u52a0\u597d\u770b return \"\" . join ( colors [ x ] for x in args ) + f \" { string } \" + colors [ \"end\" ] \u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u5230\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\uff0c \u800c\u4e14\u8fd8\u4f1a\u5e7f\u6cdb\u7528\u5728train.py\u3001val.py\u3001detect.py\u7b49\u5176\u4ed6\u6587\u4ef6\u4e2d\u5982\uff1a \u51fd\u6570\u6548\u679c\u5982\u4e0b\uff08\u53ef\u4ee5\u770b\u5230\u8f93\u51fa\u5f00\u5934\u3001\u7ed3\u5c3e\u53d8\u91cf\u4f7f\u7528\u5176\u4ed6\u989c\u8272\uff09\uff1a 8. check_online \u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u5f53\u524d\u4e3b\u673a\u662f\u5426\u8054\u7f51\u4e86\u3002\u4f1a\u5728\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\u4f7f\u7528\u3002 check_online\u51fd\u6570\u4ee3\u7801: def check_online (): \"\"\"\u5728\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\u4f7f\u7528 \u68c0\u67e5\u5f53\u524d\u4e3b\u673a\u7f51\u7edc\u8fde\u63a5\u662f\u5426\u53ef\u7528 \"\"\" import socket # \u5bfc\u5165socket\u6a21\u5757 \u53ef\u89e3\u51b3\u57fa\u4e8etcp\u548cucp\u534f\u8bae\u7684\u7f51\u7edc\u4f20\u8f93 try : # \u8fde\u63a5\u5230\u4e00\u4e2aip \u5730\u5740addr(\"1.1.1.1\")\u7684TCP\u670d\u52a1\u4e0a, \u7aef\u53e3\u53f7port=443 timeout=5 \u65f6\u96505\u79d2 \u5e76\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u5957\u63a5\u5b57\u5bf9\u8c61 socket . create_connection (( \"1.1.1.1\" , 443 ), 5 ) # check host accessibility # \u6ca1\u53d1\u73b0\u4ec0\u4e48\u5f02\u5e38, \u8fde\u63a5\u6210\u529f, \u6709\u7f51, \u5c31\u8fd4\u56deTrue return True except OSError : # \u8fde\u63a5\u5f02\u5e38, \u6ca1\u7f51, \u8fd4\u56deFalse return False 9.emojis \u8fd9\u4e2a\u51fd\u6570\u662f\u5ffd\u7565\u6389\u5b57\u7b26\u4e32\u4e2d\u65e0\u6cd5\u7528ascii\u7f16\u7801\u7684\u5185\u5bb9(\u6bd4\u5982\u8868\u60c5\u3001\u56fe\u50cf)\uff0c\u8fd4\u56deWindows\u7cfb\u7edf\u53ef\u4ee5\u5b89\u5168\u3001\u5b8c\u6574\u663e\u793a\u7684\u5b57\u7b26\u4e32\u3002\u4f1a\u5728\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\u4f7f\u7528\u3002 emojis\u51fd\u6570\u4ee3\u7801\uff1a def emojis ( str = '' ): \"\"\"\u5728\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\u4f7f\u7528 \u8fd4\u56deWindows\u7cfb\u7edf\u53ef\u4ee5\u5b89\u5168\u3001\u5b8c\u6574\u663e\u793a\u7684\u5b57\u7b26\u4e32 Return platform-dependent emoji-safe version of string \"\"\" # \u901a\u8fc7.encode().decode()\u7684\u7ec4\u5408\u5ffd\u7565\u6389\u65e0\u6cd5\u7528ascii\u7f16\u7801\u7684\u5185\u5bb9(\u6bd4\u5982\u8868\u60c5\u3001\u56fe\u50cf) return str . encode () . decode ( 'ascii' , 'ignore' ) if platform . system () == 'Windows' else str 10. check_git_status \u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u5f53\u524d\u7684\u4ee3\u7801\u7248\u672c\u662f\u5426\u662f\u6700\u65b0\u7684\u3002\u5982\u679c\u4e0d\u662f\u6700\u65b0\u7684\uff0c\u4f1a\u63d0\u793a\u4f7f\u7528git pull\u547d\u4ee4\u8fdb\u884c\u5347\u7ea7\u3002 \u51fd\u6570\u4ee3\u7801\uff1a @try_except @WorkingDirectory ( ROOT ) def check_git_status ( repo = \"Oneflow-Inc/one-yolo\" ): \"\"\"\u7528\u5728train.py\u7684main\u51fd\u6570\u7684\u4e00\u5f00\u59cb\u90e8\u5206 \u68c0\u67e5\u5f53\u524d\u4ee3\u7801\u7248\u672c\u662f\u5426\u662f\u6700\u65b0\u7684 \u5982\u679c\u4e0d\u662f\u6700\u65b0\u7684 \u4f1a\u63d0\u793a\u4f7f\u7528git pull\u547d\u4ee4\u8fdb\u884c\u5347\u7ea7 \"\"\" # YOLOv5 status check, recommend 'git pull' if code is out of date url = f \"https://github.com/ { repo } \" msg = f \", for updates see { url } \" s = colorstr ( \"github: \" ) # string # \u68c0\u67e5\u7535\u8111\u6709\u6ca1\u6709\u5b89\u88c5git\u4ed3\u5e93 \u6ca1\u6709\u5b89\u88c5\u76f4\u63a5\u62a5\u5f02\u5e38\u5e76\u8f93\u51fa\u5f02\u5e38\u4fe1\u606f assert Path ( \".git\" ) . exists (), s + \"skipping check (not a git repository)\" + msg # \u68c0\u67e5\u4e3b\u673a\u662f\u5426\u8054\u7f51 assert check_online (), s + \"skipping check (offline)\" + msg splits = re . split ( pattern = r \"\\s\" , string = check_output ( \"git remote -v\" , shell = True ) . decode ()) matches = [ repo in s for s in splits ] if any ( matches ): remote = splits [ matches . index ( True ) - 1 ] else : remote = \"Oneflow-Inc\" check_output ( f \"git remote add { remote } { url } \" , shell = True ) check_output ( f \"git fetch { remote } \" , shell = True , timeout = 5 ) # git fetch branch = check_output ( \"git rev-parse --abbrev-ref HEAD\" , shell = True ) . decode () . strip () # checked out n = int ( check_output ( f \"git rev-list { branch } .. { remote } /master --count\" , shell = True )) # commits behind if n > 0 : # \u5982\u679c\u4e0d\u662f\u6700\u65b0 \u63d0\u5347\u5b57\u7b26s: WARNING... pull = \"git pull\" if remote == \"origin\" else f \"git pull { remote } master\" s += f \"\u26a0\ufe0f YOLOv5 is out of date by { n } commit { 's' * ( n > 1 ) } . Use ` { pull } ` or `git clone { url } ` to update.\" else : s += f \"up to date with { url } \u2705\" LOGGER . info ( s ) \u8fd9\u4e2a\u51fd\u6570\u53ea\u7528\u5728train.py\u7684main\u51fd\u6570\u7684\u4e00\u5f00\u59cb\u90e8\u5206\uff1a 11. check_python\u3001check_requirements check_python\u662f\u68c0\u67e5\u5f53\u524d\u7684\u7248\u672c\u53f7\u662f\u5426\u6ee1\u8db3\u6700\u5c0f\u7248\u672c\u53f7minimum\uff0c check_requirements\u662f\u68c0\u67e5\u5df2\u7ecf\u5b89\u88c5\u7684\u5305\u662f\u5426\u6ee1\u8db3requirements\u5bf9\u5e94txt\u6587\u4ef6\u7684\u8981\u6c42\u3002 check_requirements\u4f1a\u8c03\u7528check_python\u3002 11.1 check_python \u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u5f53\u524d\u7684\u7248\u672c\u53f7\u662f\u5426\u6ee1\u8db3\u6700\u5c0f\u7248\u672c\u53f7minimum\u3002 \u4f1a\u5728\u4e0b\u9762\u7684check_requirements\u51fd\u6570\u88ab\u8c03\u7528\u3002 check_python\u51fd\u6570\u4ee3\u7801\uff1a def check_python ( minimum = '3.7.0' ): # Check current python version vs. required python version check_version ( platform . python_version (), minimum , name = 'Python ' , hard = True ) 11.2 check_requirements \u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u68c0\u67e5\u5df2\u7ecf\u5b89\u88c5\u7684\u5305\u662f\u5426\u6ee1\u8db3requirements\u5bf9\u5e94txt\u6587\u4ef6\u7684\u8981\u6c42\u3002\u4f1a\u8c03\u7528colorstr\u3001check_python\u3001check_online\u7b49\u51fd\u6570\u3002 check_requirements\u51fd\u6570\u4ee3\u7801\uff1a @TryExcept () def check_requirements ( requirements = ROOT / 'requirements.txt' , exclude = (), install = True , cmds = '' ): \"\"\"\u7528\u5728train.py\u3001test.py\u3001detect.py\u7b49\u6587\u4ef6 \u7528\u4e8e\u68c0\u67e5\u5df2\u7ecf\u5b89\u88c5\u7684\u5305\u662f\u5426\u6ee1\u8db3requirements\u5bf9\u5e94txt\u6587\u4ef6\u7684\u8981\u6c42 Check installed dependencies meet requirements (pass *.txt file or list of packages) \"\"\" # Check installed dependencies meet YOLOv5 requirements (pass *.txt file or list of packages or single package str) # \u7ea2\u8272\u663e\u793arequirements\u5355\u8bcd requirements: prefix = colorstr ( 'red' , 'bold' , 'requirements:' ) # \u68c0\u67e5\u5f53\u524d\u7684python\u7248\u672c\u7b26\u4e0d\u7b26\u5408\u6700\u4f4e\u7248\u672c\u8981\u6c42 check python version check_python () # check python version # \u89e3\u6790requirements.txt\u4e2d\u7684\u6240\u6709\u5305 \u89e3\u6790\u6210list \u91cc\u9762\u5b58\u653e\u7740\u4e00\u4e2a\u4e2a\u7684pkg_resources.Requirement\u7c7b # \u5982: ['matplotlib>=3.2.2', 'numpy>=1.18.5', \u2026\u2026] if isinstance ( requirements , Path ): # requirements.txt file file = requirements . resolve () assert file . exists (), f \" { prefix } { file } not found, check failed.\" with file . open () as f : requirements = [ f ' { x . name }{ x . specifier } ' for x in pkg . parse_requirements ( f ) if x . name not in exclude ] elif isinstance ( requirements , str ): requirements = [ requirements ] s = '' n = 0 # \u7edf\u8ba1\u4e0b\u9762\u7a0b\u5e8f\u66f4\u65b0\u5305\u7684\u4e2a\u6570 number of packages updates # \u4f9d\u6b21\u68c0\u67e5\u73af\u5883\u4e2d\u5b89\u88c5\u7684\u5305(\u53ca\u6bcf\u4e2a\u5305\u5bf9\u5e94\u7684\u4f9d\u8d56\u5305)\u662f\u5426\u6ee1\u8db3requirements\u4e2d\u7684\u6bcf\u4e00\u4e2a\u6700\u4f4e\u8981\u6c42\u5b89\u88c5\u5305 for r in requirements : try : # pkg_resources.require(file) \u8fd4\u56de\u5bf9\u5e94\u5305\u6240\u9700\u7684\u6240\u6709\u4f9d\u8d56\u5305 \u5f53\u8fd9\u4e9b\u5305\u6709\u54ea\u4e2a\u672a\u5b89\u88c5\u6216\u8005\u7248\u672c\u4e0d\u5bf9\u7684\u65f6\u5019\u5c31\u4f1a\u62a5\u9519 pkg . require ( r ) except ( pkg . VersionConflict , pkg . DistributionNotFound ): # exception if requirements not met s += f '\" { r } \" ' n += 1 if s and install and AUTOINSTALL : # check environment variable LOGGER . info ( f \" { prefix } YOLOv5 requirement { 's' * ( n > 1 ) } { s } not found, attempting AutoUpdate...\" ) try : # \u518d\u68c0\u67e5\u5f53\u524d\u4e3b\u673a\u662f\u5426\u8054\u7f51 assert check_online (), \"AutoUpdate skipped (offline)\" # \u6700\u540e\u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u518d\u6267\u884cpip\u6307\u4ee4\u5e76\u8fd4\u56de\u6267\u884c\u7ed3\u679c LOGGER . info ( check_output ( f 'pip install { s } { cmds } ' , shell = True ) . decode ()) source = file if 'file' in locals () else requirements s = f \" { prefix } { n } package { 's' * ( n > 1 ) } updated per { source } \\n \" \\ f \" { prefix } \u26a0\ufe0f { colorstr ( 'bold' , 'Restart runtime or rerun command for updates to take effect' ) } \\n \" LOGGER . info ( s ) except Exception as e : LOGGER . warning ( f ' { prefix } \u274c { e } ' ) \u7528\u5728train.py\u4e2d\uff1a val.py \u4e2d\uff1a 12. make_divisible\u3001check_img_size \u8fd9\u4e24\u4e2a\u51fd\u6570\u4e3b\u8981\u662f\u7528\u6765\u7ea6\u675f\u56fe\u50cf\u7684\u957f\u6b3e\u6216\u8005feature map\u7684\u957f\u6b3e\uff0c \u5fc5\u987b\u662fdivisor\uff08\u7b49\u4e8e\u7b97\u6cd5\u7684\u6700\u5927\u4e0b\u91c7\u6837\u7387\u4e00\u822c\u662f32\uff09\u7684\u6700\u5c0f\u500d\u6570\u3002 12.1 make_divisible def make_divisible ( x , divisor ): \"\"\"\u7528\u5728\u4e0b\u9762\u7684make_divisible\u51fd\u6570\u4e2d yolo.py\u7684parse_model\u51fd\u6570\u548ccommom.py\u7684AutoShape\u51fd\u6570\u4e2d \u53d6\u5927\u4e8e\u7b49\u4e8ex\u4e14\u662fdivisor\u7684\u6700\u5c0f\u500d\u6570 Returns x evenly divisible by divisor \"\"\" if isinstance ( divisor , flow . Tensor ): divisor = int ( divisor . max ()) # to int # math.ceil \u5411\u4e0a\u53d6\u6574 return math . ceil ( x / divisor ) * \u8fd9\u4e2a\u51fd\u6570\u7528\u5728\u4e0b\u9762\u7684make_divisible\u51fd\u6570\u4e2d\u53ca yolo.py\u7684parse_model\u51fd\u6570\u548ccommom.py\u7684AutoShape\u51fd\u6570\u4e2d\uff1a 12.2 check_img_size \u8fd9\u4e2a\u51fd\u6570\u662f\u4e3a\u4e86\u4fdd\u8bc1img_size\u662f\u80fd\u88abs\uff0832\uff09\u6574\u9664\uff0c\u5982\u679c\u4e0d\u80fd\u5c31\u8fd4\u56de\u5927\u4e8e\u7b49\u4e8eimg_size\u4e14\u662fs\u7684\u6700\u5c0f\u500d\u6570\u3002 \u8fd9\u4e2a\u51fd\u6570\u672c\u8d28\u662f\u901a\u8fc7\u8c03\u7528make_divisible\u51fd\u6570\u5b9e\u73b0\u7684\u3002 check_img_size\u51fd\u6570\u4ee3\u7801\uff1a def check_img_size ( imgsz , s = 32 , floor = 0 ): \"\"\"\u8fd9\u4e2a\u51fd\u6570\u4e3b\u8981\u7528\u4e8etrain.py\u4e2d\u548cdetect.py\u4e2d \u7528\u6765\u68c0\u67e5\u56fe\u7247\u7684\u957f\u5bbd\u662f\u5426\u7b26\u5408\u89c4\u5b9a \u68c0\u67e5img_size\u662f\u5426\u80fd\u88abs\u6574\u9664\uff0c\u8fd9\u91cc\u9ed8\u8ba4s\u4e3a32 \u8fd4\u56de\u5927\u4e8e\u7b49\u4e8eimg_size\u4e14\u662fs\u7684\u6700\u5c0f\u500d\u6570 Verify img_size is a multiple of stride s \"\"\" # Verify image size is a multiple of stride s in each dimension if isinstance ( imgsz , int ): # integer i.e. img_size=640 # \u53d6\u5927\u4e8e\u7b49\u4e8ex\u7684\u6700\u5c0f\u503c\u4e14\u8be5\u503c\u80fd\u88abdivisor\u6574\u9664 new_size = max ( make_divisible ( imgsz , int ( s )), floor ) else : # list i.e. img_size=[640, 480] imgsz = list ( imgsz ) # convert to list if tuple new_size = [ max ( make_divisible ( x , int ( s )), floor ) for x in imgsz ] if new_size != imgsz : LOGGER . warning ( f \"WARNING: --img-size { imgsz } must be multiple of max stride { s } , updating to { new_size } \" ) return new_size \u7528\u6765\u4fdd\u8bc1img\u7684\u957f\u5bbd\u7b26\u5408\u89c4\u5b9a\uff0c\u7528\u5728val.py , detect.py ,train.py\u4e2d\uff1a 13. check_imshow \u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u4e00\u4e0b\u524d\u73af\u5883\u662f\u5426\u53ef\u4ee5\u4f7f\u7528opencv.imshow\u663e\u793a\u56fe\u7247\u3002 def check_imshow (): \"\"\"\u7528\u5728detect.py\u4e2d \u4f7f\u7528webcam\u7684\u65f6\u5019\u8c03\u7528 \u68c0\u67e5\u5f53\u524d\u73af\u5883\u662f\u5426\u53ef\u4ee5\u4f7f\u7528opencv.imshow\u663e\u793a\u56fe\u7247 \u4e3b\u8981\u6709\u4e24\u70b9\u9650\u5236: Docker\u73af\u5883 + Google Colab\u73af\u5883 \"\"\" # Check if environment supports image displays try : assert not is_docker (), \"cv2.imshow() is disabled in Docker environments\" assert not is_colab (), \"cv2.imshow() is disabled in Google Colab environments\" # \u521d\u59cb\u5316\u4e00\u5f20\u56fe\u7247\u68c0\u67e5\u4e0bopencv\u662f\u5426\u53ef\u7528 cv2 . imshow ( \"test\" , np . zeros (( 1 , 1 , 3 ))) cv2 . waitKey ( 1 ) cv2 . destroyAllWindows () cv2 . waitKey ( 1 ) return True except Exception as e : LOGGER . warning ( f \"WARNING: Environment does not support cv2.imshow() or PIL Image.show() image displays \\n { e } \" ) return False \u4f1a\u5728detect.py\u4e2d\u4f7f\u7528webcam\u7684\u65f6\u5019\u8c03\u7528\uff1a 14. check_file \u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u672c\u90fd\u76f8\u5173\u6587\u4ef6\u8def\u5f84\u80fd\u5426\u627e\u5230\u8fd9\u4e2a\u6587\u4ef6\uff0c\u6ca1\u627e\u5230\u5c31\u8bf4\u660e\u6587\u4ef6\u4e22\u5931\u4e86\uff0c \u8fd4\u56de\u7a7a\uff1b \u5982\u679c\u4f20\u5165\u7684\u662f\u4e00\u4e2a\u7f51\u7edc\u5730\u5740\u5c31\u76f4\u63a5\u4e0b\u8f7d\u8fd9\u4e2a\u6587\u4ef6\uff1b \u5426\u5219\u627e\u5230\u5c31\u8fd4\u56de\u672c\u5730\u5339\u914d\u5230\u7684\u7b2c\u4e00\u4e2a\u6587\u4ef6\u540d\u3002\u8fd9\u4e2a\u51fd\u6570\u5f88\u6709\u7528\uff0c\u7528\u7684\u5f88\u5e7f\u3002 def check_file ( file , suffix = \"\" ): \"\"\"\u7528\u5728train.py\u548ctest.py\u6587\u4ef6\u4e2d \u68c0\u67e5\u672c\u5730\u6709\u6ca1\u6709\u8fd9\u4e2a\u6587\u4ef6 \u68c0\u67e5\u76f8\u5173\u6587\u4ef6\u8def\u5f84\u80fd\u5426\u627e\u5230\u6587\u4ef6 \u5e76\u8fd4\u56de\u6587\u4ef6\u540d Search/download file (if necessary) and return path \"\"\" # Search/download file (if necessary) and return path check_suffix ( file , suffix ) # optional file = str ( file ) # convert to str() # \u5982\u679c\u4f20\u8fdb\u6765\u7684\u662f\u6587\u4ef6\u6216\u8005\u662f\u2019\u2018, \u76f4\u63a5\u8fd4\u56de\u6587\u4ef6\u540dstr if Path ( file ) . is_file () or not file : # exists return file # \u5982\u679c\u4f20\u8fdb\u6765\u7684\u4ee5 'http:/' \u6216\u8005 'https:/' \u5f00\u5934\u7684url\u5730\u5740, \u5c31\u4e0b\u8f7d elif file . startswith (( \"http:/\" , \"https:/\" )): # download url = file # warning: Pathlib turns :// -> :/ file = Path ( urllib . parse . unquote ( file ) . split ( \"?\" )[ 0 ]) . name # '%2F' to '/', split https://url.com/file.txt?auth if Path ( file ) . is_file (): LOGGER . info ( f \"Found { url } locally at { file } \" ) # file already exists else : LOGGER . info ( f \"Downloading { url } to { file } ...\" ) # \u4f7f\u7528flow.hub.download_url_to_file\u4eceurl\u5730\u5740\u4e0a\u4e2d\u4e0b\u8f7d\u6587\u4ef6\u540d\u4e3afile\u7684\u6587\u4ef6 flow . hub . download_url_to_file ( url , file ) # \u68c0\u67e5\u662f\u5426\u4e0b\u8f7d\u6210\u529f assert Path ( file ) . exists () and Path ( file ) . stat () . st_size > 0 , f \"File download failed: { url } \" # check # \u8fd4\u56de\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d return file elif file . startswith ( \"clearml://\" ): # ClearML Dataset ID assert \"clearml\" in sys . modules , \"ClearML is not installed, so cannot use ClearML dataset. Try running 'pip install clearml'.\" return file else : # search files = [] for d in \"data\" , \"models\" , \"utils\" : # search directories files . extend ( glob . glob ( str ( ROOT / d / \"**\" / file ), recursive = True )) # find file assert len ( files ), f \"File not found: { file } \" # assert file was found assert len ( files ) == 1 , f \"Multiple files match ' { file } ', specify exact path: { files } \" # assert unique # \u8fd4\u56de\u7b2c\u4e00\u4e2a\u5339\u914d\u5230\u7684\u6587\u4ef6\u540d return files [ 0 ] # return file \u5728train.py\u4e2d\u4f7f\u7528\uff08\u68c0\u67e5\u672c\u5730data\u3001cfg\u3001hyp\u7b49\u6587\u4ef6\u662f\u5426\u5b58\u5728\uff09 \u5728test.py\u4e2d\u4f7f\u7528\uff08\u68c0\u67e5\u672c\u5730data\u6587\u4ef6\u662f\u5426\u5b58\u5728\uff09 15. check_dataset \u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u672c\u5730\u662f\u5426\u6709\u6307\u5b9a\u7684\u6570\u636e\u96c6\uff0c\u6ca1\u7528\u5c31\u4ecetorch\u5e93\u4e2d\u4e0b\u8f7d\u5e76\u89e3\u538b\u6570\u636e\u96c6\u3002 check_dataset\u51fd\u6570\u4ee3\u7801: def check_dataset ( data , autodownload = True ): # Download, check and/or unzip dataset if not found locally \"\"\"\u7528\u5728train.py\u548cdetect.py\u4e2d \u68c0\u67e5\u672c\u5730\u6709\u6ca1\u6709\u6570\u636e\u96c6 \u68c0\u67e5\u6570\u636e\u96c6 \u5982\u679c\u672c\u5730\u6ca1\u6709\u5219\u4eceone-yolov5\u5e93\u4e2d\u4e0b\u8f7d\u5e76\u89e3\u538b\u6570\u636e\u96c6 :params data: \u662f\u4e00\u4e2a\u89e3\u6790\u8fc7\u7684data_dict len=7 \u4f8b\u5982: ['path'='../datasets/coco128', 'train','val', 'test', 'nc', 'names', 'download'] :params autodownload: \u5982\u679c\u672c\u5730\u6ca1\u6709\u6570\u636e\u96c6\u662f\u5426\u9700\u8981\u76f4\u63a5\u4eceone-yolov5\u5e93\u4e2d\u4e0b\u8f7d\u6570\u636e\u96c6 \u9ed8\u8ba4True \"\"\" # Download (optional) extract_dir = \"\" if isinstance ( data , ( str , Path )) and str ( data ) . endswith ( \".zip\" ): # i.e. gs://bucket/dir/coco128.zip download ( data , dir = DATASETS_DIR , unzip = True , delete = False , curl = False , threads = 1 ) data = next (( DATASETS_DIR / Path ( data ) . stem ) . rglob ( \"*.yaml\" )) extract_dir , autodownload = data . parent , False # Read yaml (optional) if isinstance ( data , ( str , Path )): with open ( data , errors = \"ignore\" ) as f : data = yaml . safe_load ( f ) # dictionary # Checks for k in \"train\" , \"val\" , \"nc\" : assert k in data , f \"data.yaml ' { k } :' field missing \u274c\" if \"names\" not in data : LOGGER . warning ( \"data.yaml 'names:' field missing \u26a0\ufe0f, assigning default names 'class0', 'class1', etc.\" ) data [ \"names\" ] = [ f \"class { i } \" for i in range ( data [ \"nc\" ])] # default names # Resolve paths path = Path ( extract_dir or data . get ( \"path\" ) or \"\" ) # optional 'path' default to '.' if not path . is_absolute (): path = ( ROOT / path ) . resolve () for k in \"train\" , \"val\" , \"test\" : if data . get ( k ): # prepend path data [ k ] = str ( path / data [ k ]) if isinstance ( data [ k ], str ) else [ str ( path / x ) for x in data [ k ]] # Parse yaml train , val , test , s = ( data . get ( x ) for x in ( \"train\" , \"val\" , \"test\" , \"download\" )) if val : # path.resolve() \u8be5\u65b9\u6cd5\u5c06\u4e00\u4e9b\u7684 \u8def\u5f84/\u8def\u5f84\u6bb5 \u89e3\u6790\u4e3a\u7edd\u5bf9\u8def\u5f84 # val: [WindowsPath('E:/yolo_v5/datasets/coco128/images/train2017')] val = [ Path ( x ) . resolve () for x in ( val if isinstance ( val , list ) else [ val ])] # val path # \u5982\u679cval\u4e0d\u5b58\u5728 \u8bf4\u660e\u672c\u5730\u4e0d\u5b58\u5728\u6570\u636e\u96c6 if not all ( x . exists () for x in val ): LOGGER . info ( \" \\n Dataset not found \u26a0\ufe0f, missing paths %s \" % [ str ( x ) for x in val if not x . exists ()]) if not s or not autodownload : raise Exception ( \"Dataset not found \u274c\" ) t = time . time () root = path . parent if \"path\" in data else \"..\" # unzip directory i.e. '../' if s . startswith ( \"http\" ) and s . endswith ( \".zip\" ): # URL f = Path ( s ) . name # filename LOGGER . info ( f \"Downloading { s } to { f } ...\" ) flow . hub . download_url_to_file ( s , f ) Path ( root ) . mkdir ( parents = True , exist_ok = True ) # create root ZipFile ( f ) . extractall ( path = root ) # unzip Path ( f ) . unlink () # remove zip r = None # success # \u5982\u679c\u4e0b\u8f7d\u5730\u5740s\u662fbash\u5f00\u5934\u5c31\u4f7f\u7528bash\u6307\u4ee4\u4e0b\u8f7d\u6570\u636e\u96c6 elif s . startswith ( \"bash \" ): # bash script LOGGER . info ( f \"Running { s } ...\" ) # \u4f7f\u7528bash\u547d\u4ee4\u4e0b\u8f7d r = os . system ( s ) # \u5426\u5219\u4e0b\u8f7d\u5730\u5740\u5c31\u662f\u4e00\u4e2apython\u811a\u672c \u6267\u884cpython\u811a\u672c\u4e0b\u8f7d\u6570\u636e\u96c6 else : # python script r = exec ( s , { \"yaml\" : data }) # return None dt = f \"( { round ( time . time () - t , 1 ) } s)\" s = f \"success \u2705 { dt } , saved to { colorstr ( 'bold' , root ) } \" if r in ( 0 , None ) else f \"failure { dt } \u274c\" LOGGER . info ( f \"Dataset download { s } \" ) check_font ( \"Arial.ttf\" if is_ascii ( data [ \"names\" ]) else \"Arial.Unicode.ttf\" , progress = True ) # download fonts return data # dictionary 16. download \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06url\u4e2d\u7684\u6587\u4ef6\u4e0b\u8f7d\u4e0b\u6765\uff0c\u518d\u89e3\u538b\u3002\u4f46\u662f\u8fd9\u4e2a\u6587\u4ef6\u5e76\u6ca1\u6709\u5728\u7a0b\u5e8f\u4e2d\u88ab\u8c03\u7528\uff0c flow.hub.download_url_to_file\u7cfb\u7edf\u51fd\u6570\u548cgoogle_utils.py \u4e2d\u7684attempt_download\u51fd\u6570\u8fdb\u884c\u4e0b\u8f7d\u6587\u4ef6\u3002\u6240\u4ee5\uff0c\u8fd9\u4e2a\u51fd\u6570\u968f\u4fbf\u770b\u770b\u5c31\u597d\u3002 def download ( url , dir = \".\" , unzip = True , delete = True , curl = False , threads = 1 , retry = 3 ): # Multi-threaded file download and unzip function, used in data.yaml for autodownload \"\"\"\u5728coco.yaml\u4e2d\u4e0b\u8f7d\u6570\u636e\u96c6 Multi-threaded file download and unzip function :params url: \u4e0b\u8f7d\u6587\u4ef6\u7684url\u5730\u5740 :params dir: \u4e0b\u8f7d\u4e0b\u6765\u6587\u4ef6\u4fdd\u5b58\u7684\u76ee\u5f55 :params unzip: \u4e0b\u8f7d\u540e\u6587\u4ef6\u662f\u5426\u9700\u8981\u89e3\u538b :params delete: \u89e3\u538b\u540e\u539f\u6587\u4ef6(\u672a\u89e3\u538b)\u662f\u5426\u9700\u8981\u5220\u9664 :params curl: \u662f\u5426\u4f7f\u7528cmd curl\u8bed\u53e5\u4e0b\u8f7d\u6587\u4ef6 False\u5c31\u4f7f\u7528torch.hub\u4e0b\u8f7d :params threads: \u4e0b\u8f7d\u4e00\u4e2a\u6587\u4ef6\u9700\u8981\u7684\u7ebf\u7a0b\u6570 \"\"\" def download_one ( url , dir ): \"\"\" Download 1 file :params url: \u6587\u4ef6\u4e0b\u8f7d\u5730\u5740 Path(url).name=\u6587\u4ef6\u540d :params dir: \u6587\u4ef6\u4fdd\u5b58\u7684\u76ee\u5f55 \"\"\" # Download 1 file success = True f = dir / Path ( url ) . name # filename if Path ( url ) . is_file (): # exists in current path Path ( url ) . rename ( f ) # move to dir # \u8fd9\u4e2a\u76ee\u5f55\u4e0b\u4e0d\u5b58\u5728\u8fd9\u4e2a\u6587\u4ef6 \u5c31\u76f4\u63a5\u4e0b\u8f7d elif not f . exists (): LOGGER . info ( f \"Downloading { url } to { f } ...\" ) for i in range ( retry + 1 ): if curl : s = \"sS\" if threads > 1 else \"\" # silent r = os . system ( f 'curl - { s } L \" { url } \" -o \" { f } \" --retry 9 -C -' ) # curl download with retry, continue success = r == 0 else : flow . hub . download_url_to_file ( url , f , progress = threads == 1 ) # torch download success = f . is_file () if success : break elif i < retry : LOGGER . warning ( f \"Download failure, retrying { i + 1 } / { retry } { url } ...\" ) else : LOGGER . warning ( f \"Failed to download { url } ...\" ) # \u5982\u679c\u9700\u8981\u89e3\u538b \u4e14\u4e0b\u8f7d\u7684\u6587\u4ef6\u540e\u7f00\u662f '.zip' \u6216 '.gz' if unzip and success and f . suffix in ( \".zip\" , \".gz\" ): LOGGER . info ( f \"Unzipping { f } ...\" ) if f . suffix == \".zip\" : ZipFile ( f ) . extractall ( path = dir ) # unzip elif f . suffix == \".gz\" : os . system ( f \"tar xfz { f } --directory { f . parent } \" ) # unzip # \u89e3\u538b\u540e\u662f\u5426\u9700\u8981\u5220\u9664\u672a\u89e3\u538b\u7684\u6587\u4ef6 if delete : f . unlink () # remove zip dir = Path ( dir ) dir . mkdir ( parents = True , exist_ok = True ) # make directory if threads > 1 : # \u4f7f\u7528\u7ebf\u7a0b\u6c60 # \u5b9a\u4e49\u4e86\u4e00\u4e2a\u7ebf\u7a0b\u6c60, \u6700\u591a\u521b\u5efathreads\u4e2a\u7ebf\u7a0b pool = ThreadPool ( threads ) # \u8fdb\u7a0b\u6c60\u4e2d\u7684\u8be5\u65b9\u6cd5\u4f1a\u5c06 iterable \u53c2\u6570\u4f20\u5165\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\u5206\u6210 chunksize \u4efd\u4f20\u9012\u7ed9\u4e0d\u540c\u7684\u8fdb\u7a0b\u6765\u5904\u7406\u3002 pool . imap ( lambda x : download_one ( * x ), zip ( url , repeat ( dir ))) # multi-threaded pool . close () pool . join () else : for u in [ url ] if isinstance ( url , ( str , Path )) else url : download_one ( u , dir ) 17. clean_str \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u5b57\u7b26\u4e32\u4e2d\u4e00\u4e9b\u5947\u602a\u7684\u7b26\u53f7 \u201c|@#!\u00a1\u00b7$\u20ac%&()=?\u00bf^*;:,\u00a8\u00b4><+\u201d \u6362\u6210\u4e0b\u5212\u7ebf \u2018_\u2019\u3002 def clean_str ( s ): \"\"\"\u5728datasets.py\u4e2d\u7684LoadStreams\u7c7b\u4e2d\u88ab\u8c03\u7528 \u5b57\u7b26\u4e32s\u91cc\u5728pattern\u4e2d\u5b57\u7b26\u66ff\u6362\u4e3a\u4e0b\u5212\u7ebf_ \u6ce8\u610fpattern\u4e2d[]\u4e0d\u80fd\u7701 Cleans a string by replacing special characters with underscore _ \"\"\" # re: \u7528\u6765\u5339\u914d\u5b57\u7b26\u4e32\uff08\u52a8\u6001\u3001\u6a21\u7cca\uff09\u7684\u6a21\u5757 \u6b63\u5219\u8868\u8fbe\u5f0f\u6a21\u5757 # pattern: \u8868\u793a\u6b63\u5219\u4e2d\u7684\u6a21\u5f0f\u5b57\u7b26\u4e32 repl: \u5c31\u662freplacement\u7684\u5b57\u7b26\u4e32 string: \u8981\u88ab\u5904\u7406, \u8981\u88ab\u66ff\u6362\u7684\u90a3\u4e2astring\u5b57\u7b26\u4e32 # \u6240\u4ee5\u8fd9\u53e5\u8bdd\u6267\u884c\u7684\u662f\u5c06\u5b57\u7b26\u4e32s\u91cc\u5728pattern\u4e2d\u7684\u5b57\u7b26\u4e32\u66ff\u6362\u4e3a \"_\" # Cleans a string by replacing special characters with underscore _ return re . sub ( pattern = \"[|@#!\u00a1\u00b7$\u20ac%&()=?\u00bf^*;:,\u00a8\u00b4><+]\" , repl = \"_\" , string = s ) \u53ea\u7528\u5728datasets.py\u4e2d\u7684LoadStreams\u7c7b\u4e2d\uff1a 18. one_cycle \u8fd9\u4e2a\u51fd\u6570\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u5b66\u4e60\u7387\u8870\u51cf\u7b56\u7565\u3002\u6765\u81ea\u8fd9\u7bc7\u8bba\u6587\uff1a one_cycle . \u611f\u5174\u8da3\u7684 \u670b\u53cb\u53ef\u4ee5\u8bfb\u4e00\u8bfb\u3002 def one_cycle ( y1 = 0.0 , y2 = 1.0 , steps = 100 ): \"\"\"\u7528\u5728train.py\u7684\u5b66\u4e60\u7387\u8870\u51cf\u7b56\u7565\u6a21\u5757 one_cycle lr lr\u5148\u589e\u52a0, \u518d\u51cf\u5c11, \u518d\u4ee5\u66f4\u5c0f\u7684\u659c\u7387\u51cf\u5c11 \u8bba\u6587: https://arxiv.org/pdf/1803.09820.pdf \"\"\" # lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf return lambda x : (( 1 - math . cos ( x * math . pi / steps )) / 2 ) * ( y2 - y1 ) + y1 \u4e00\u822c\u4f7f\u7528one_cycle\u7684\u6548\u679c\u4f1a\u6bd4\u8f83\u597d\u3002 19. labels_to_class_weights & labels_to_image_weights \u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u8054\u5408\u4f7f\u7528\u7684\u3002 \u6700\u7ec8\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u5728\u6570\u636e\u96c6\u4e2d\u91c7\u6837\u7684\u65f6\u5019\uff0c\u4e0d\u4f7f\u7528\u968f\u673a\u91c7\u6837\uff0c\u800c\u662f\u4f7f\u7528\u66f4\u52a0\u79d1\u5b66\u7684\u6309\u56fe\u7247\u6743\u91cd\u8fdb\u884c\u91c7\u6837\u3002 \u7b2c\u4e00\u4e2a\u51fd\u6570labels_to_class_weights\u662f\u4e3a\u4e86\u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709\u7c7b\u522b\u7684\u6743\u91cd\uff08\u9891\u7387\u5927\u7684\u6743\u91cd\u5c0f\uff09\u3002 \u7b2c\u4e8c\u4e2a\u51fd\u6570labels_to_image_weights\u662f\u5229\u7528labels_to_class_weights\u51fd\u6570\u5f97\u5230\u7684\u7c7b\u522b\u6743\u91cd\u5f97\u5230\u6bcf\u5f20\u56fe\u7247\u5bf9\u5e94\u7684\u4e00\u4e2a\u6743\u91cd\u3002 \u7136\u540e\u5229\u7528\u6bcf\u5f20\u56fe\u7247\u7684\u6743\u91cd\u5728\u5f53\u524dbatch\u8fdb\u884c\u91c7\u6837\uff0c\u8fd9\u6837\u7684\u91c7\u6837\u65b9\u5f0f\u4f1a\u66f4\u52a0\u79d1\u5b66\u70b9\u3002 \u4e24\u4e2a\u51fd\u6570\u90fd\u53ea\u5728train.py\u4e2d\u4f7f\u7528\uff0c\u4e14\u662f\u540c\u65f6\u4f7f\u7528\u7684\u5982\u56fe\uff1a 19.1 labels_to_class_weights \u8fd9\u4e2a\u51fd\u6570\u662f\u4ece\u8bad\u7ec3(gt)\u6807\u7b7e\u83b7\u5f97\u6bcf\u4e2a\u7c7b\u7684\u6743\u91cd \uff0c\u6807\u7b7e\u9891\u7387\u9ad8\u7684\u7c7b\u6743\u91cd\u4f4e\u3002 labels_to_class_weights\u51fd\u6570\u4ee3\u7801\uff1a def labels_to_class_weights ( labels , nc = 80 ): \"\"\"\u7528\u5728train.py\u4e2d \u5f97\u5230\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd \u6807\u7b7e\u9891\u7387\u9ad8\u7684\u7c7b\u6743\u91cd\u4f4e \u4ece\u8bad\u7ec3(gt)\u6807\u7b7e\u83b7\u5f97\u6bcf\u4e2a\u7c7b\u7684\u6743\u91cd \u6807\u7b7e\u9891\u7387\u9ad8\u7684\u7c7b\u6743\u91cd\u4f4e Get class weights (inverse frequency) from training labels :params labels: gt\u6846\u7684\u6240\u6709\u771f\u5b9e\u6807\u7b7elabels :params nc: \u6570\u636e\u96c6\u7684\u7c7b\u522b\u6570 :return torch.from_numpy(weights): \u6bcf\u4e00\u4e2a\u7c7b\u522b\u6839\u636elabels\u5f97\u5230\u7684\u5360\u6bd4(\u6b21\u6570\u8d8a\u591a\u6743\u91cd\u8d8a\u5c0f) tensor \"\"\" if labels [ 0 ] is None : # no labels loaded return flow . Tensor () labels = np . concatenate ( labels , 0 ) # labels.shape = (866643, 5) for COCO # classes: \u6240\u6709\u6807\u7b7e\u5bf9\u5e94\u7684\u7c7b\u522blabels labels[:, 0]: \u7c7b\u522b .astype(np.int): \u53d6\u6574 classes = labels [:, 0 ] . astype ( np . int ) # labels = [labels_num, class+xywh] # weight: \u8fd4\u56de\u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570 [1, nc] weights = np . bincount ( classes , minlength = nc ) # occurrences per class # Prepend gridpoint count (for uCE training) # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum() # gridpoints per image # weights = np.hstack([gpi * len(labels) - weights.sum() * 9, weights * 9]) ** 0.5 # prepend gridpoints to start # \u5c06\u51fa\u73b0\u6b21\u6570\u4e3a0\u7684\u7c7b\u522b\u6743\u91cd\u5168\u90e8\u53d61 replace empty bins with 1 weights [ weights == 0 ] = 1 # \u5176\u4ed6\u6240\u6709\u7684\u7c7b\u522b\u7684\u6743\u91cd\u5168\u90e8\u53d6\u6b21\u6570\u7684\u5012\u6570 number of targets per class weights = 1 / weights # normalize \u6c42\u51fa\u6bcf\u4e00\u7c7b\u522b\u7684\u5360\u6bd4 weights /= weights . sum () return flow . from_numpy ( weights ) # numpy -> tensor 19.2 labels_to_image_weights \u8fd9\u4e2a\u51fd\u6570\u662f\u5229\u7528\u6bcf\u5f20\u56fe\u7247\u771f\u5b9egt\u6846\u7684\u771f\u5b9e\u6807\u7b7elabels\u548c\u4e0a\u4e00\u6b65labels_to_class_weights\u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd\u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6bcf\u5f20\u56fe\u7247\u5bf9\u5e94\u7684\u6743\u91cd\u3002 labels_to_image_weights\u51fd\u6570\u4ee3\u7801\uff1a def labels_to_image_weights ( labels , nc = 80 , class_weights = np . ones ( 80 )): \"\"\"\u7528\u5728train.py\u4e2d \u5229\u7528\u4e0a\u9762\u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd\u5f97\u5230\u6bcf\u4e00\u5f20\u56fe\u7247\u7684\u6743\u91cd \u518d\u5bf9\u56fe\u7247\u8fdb\u884c\u6309\u6743\u91cd\u8fdb\u884c\u91c7\u6837 \u901a\u8fc7\u6bcf\u5f20\u56fe\u7247\u771f\u5b9egt\u6846\u7684\u771f\u5b9e\u6807\u7b7elabels\u548c\u4e0a\u4e00\u6b65labels_to_class_weights\u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd\u8fdb\u884c\u91c7\u6837 Produces image weights based on class_weights and image contents :params labels: \u6bcf\u5f20\u56fe\u7247\u771f\u5b9egt\u6846\u7684\u771f\u5b9e\u6807\u7b7e :params nc: \u6570\u636e\u96c6\u7684\u7c7b\u522b\u6570 \u9ed8\u8ba480 :params class_weights: [80] \u4e0a\u4e00\u6b65labels_to_class_weights\u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd \"\"\" # class_counts: \u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570 [num_labels, nc] \u6bcf\u4e00\u884c\u662f\u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570 num_labels=\u56fe\u7247\u6570\u91cf=label\u6570\u91cf class_counts = np . array ([ np . bincount ( x [:, 0 ] . astype ( np . int ), minlength = nc ) for x in labels ]) # [80] -> [1, 80] # \u6574\u4e2a\u6570\u636e\u96c6\u7684\u6bcf\u4e2a\u7c7b\u522b\u6743\u91cd[1, 80] * \u6bcf\u5f20\u56fe\u7247\u7684\u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570[num_labels, 80] = \u5f97\u5230\u6bcf\u4e00\u5f20\u56fe\u7247\u6bcf\u4e2a\u7c7b\u5bf9\u5e94\u7684\u6743\u91cd[num_labels, 80] # \u53e6\u5916\u6ce8\u610f: \u8fd9\u91cc\u4e0d\u662f\u77e9\u9635\u76f8\u4e58, \u662f\u5143\u7d20\u76f8\u4e58 [1, 80] \u548c\u6bcf\u4e00\u884c\u56fe\u7247\u7684\u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570 [1, 80] \u5206\u522b\u6309\u5143\u7d20\u76f8\u4e58 # \u518dsum(1): \u6309\u884c\u76f8\u52a0 \u5f97\u5230\u6700\u7ec8image_weights: \u5f97\u5230\u6bcf\u4e00\u5f20\u56fe\u7247\u5bf9\u5e94\u7684\u91c7\u6837\u6743\u91cd[num_labels] return ( class_weights . reshape ( 1 , nc ) * class_counts ) . sum ( 1 ) 20. coco80_to_coco91_class \u8fd9\u4e2a\u51fd\u6570\u662f\u5c0680\u4e2a\u7c7b\u7684coco\u7d22\u5f15\u6362\u621091\u7c7b\u7684coco\u7d22\u5f15\u3002 coco80_to_coco91_class\u51fd\u6570\u4ee3\u7801: def coco80_to_coco91_class (): \"\"\"\u7528\u5728test.py\u4e2d \u4ece80\u7c7b\u6620\u5c04\u523091\u7c7b\u7684coco\u7d22\u5f15 \u53d6\u5f97\u5bf9\u5e94\u7684class id \u5c0680\u4e2a\u7c7b\u7684coco\u7d22\u5f15\u6362\u621091\u7c7b\u7684coco\u7d22\u5f15 :return x: \u4e3a80\u7c7b\u7684\u6bcf\u4e00\u7c7b\u572891\u7c7b\u4e2d\u7684\u4f4d\u7f6e \"\"\" # converts 80-index (val2014) to 91-index (paper) # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/ # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n') # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n') # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)] # darknet to coco # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)] # coco to darknet x = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 27 , 28 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 63 , 64 , 65 , 67 , 70 , 72 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 84 , 85 , 86 , 87 , 88 , 89 , 90 ] return x \u5728 val.py \u4e2d\u4f7f\u7528\uff1a 21. clip_coords \u8fd9\u4e2a\u51fd\u6570\u7684\u4f5c\u7528\u662f\uff1a \u5c06boxes\u7684\u5750\u6807(x1y1x2y2 \u5de6\u4e0a\u89d2\u53f3\u4e0b\u89d2)\u9650\u5b9a\u5728\u56fe\u50cf\u7684\u5c3a\u5bf8(img_shape hw)\u5185\uff0c\u9632\u6b62\u51fa\u754c\u3002 \u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u5728\u4e0b\u9762\u7684xyxy2xywhn\u3001save_one_boxd\u7b49\u51fd\u6570\u4e2d\uff0c\u5f88\u91cd\u8981\uff0c\u5fc5\u987b\u638c\u63e1\u3002 clip_coords\u51fd\u6570\u4ee3\u7801\uff1a def clip_coords ( boxes , shape ): \"\"\"\u7528\u5728\u4e0b\u9762\u7684xyxy2xywhn\u3001save_one_boxd\u7b49\u51fd\u6570\u4e2d \u5c06boxes\u7684\u5750\u6807(x1y1x2y2 \u5de6\u4e0a\u89d2\u53f3\u4e0b\u89d2)\u9650\u5b9a\u5728\u56fe\u50cf\u7684\u5c3a\u5bf8\u5185 Clip bounding x1y1x2y2 bounding boxes to image shape (height, width) \"\"\" # Clip bounding xyxy bounding boxes to image shape (height, width) if isinstance ( boxes , flow . Tensor ): # faster individually boxes [:, 0 ] . clamp_ ( 0 , shape [ 1 ]) # x1 boxes [:, 1 ] . clamp_ ( 0 , shape [ 0 ]) # y1 boxes [:, 2 ] . clamp_ ( 0 , shape [ 1 ]) # x2 boxes [:, 3 ] . clamp_ ( 0 , shape [ 0 ]) # y2 else : # np.array (faster grouped) boxes [:, [ 0 , 2 ]] = boxes [:, [ 0 , 2 ]] . clip ( 0 , shape [ 1 ]) # x1, x2 boxes [:, [ 1 , 3 ]] = boxes [:, [ 1 , 3 ]] . clip ( 0 , shape [ 0 ]) # y1, y2 22. scale_coords \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u5750\u6807coords(x1y1x2y2)\u4eceimg1_shape\u5c3a\u5bf8\u7f29\u653e\u5230img0_shape\u5c3a\u5bf8\u3002 x\u7684\u6b63\u5750\u6807\u662f\u5411\u53f3\uff0cy\u7684\u6b63\u5750\u6807\u662f\u5411\u4e0b\u3002\u8fd9\u4e2a\u51fd\u6570\u4e5f\u662f\u5f88\u91cd\u8981\u7684\u3002 scale_coords\u51fd\u6570\u4ee3\u7801\uff1a def scale_coords ( img1_shape , coords , img0_shape , ratio_pad = None ): \"\"\"\u7528\u5728detect.py\u548cval.py\u4e2d \u5c06\u9884\u6d4b\u5750\u6807\u4ecefeature map\u6620\u5c04\u56deimg0 \u5c06\u5750\u6807coords(x1y1x2y2)\u4eceimg1_shape\u7f29\u653e\u5230img0_shape\u5c3a\u5bf8 Rescale coords (xyxy) from img1_shape to img0_shape :params img1_shape: coords\u76f8\u5bf9\u4e8e\u7684shape\u5927\u5c0f :params coords: \u8981\u8fdb\u884c\u7f29\u653e\u7684box\u5750\u6807\u4fe1\u606f x1y1x2y2 \u5de6\u4e0a\u89d2 + \u53f3\u4e0b\u89d2 :params img0_shape: \u8981\u5c06coords\u7f29\u653e\u5230\u76f8\u5bf9\u7684\u76ee\u6807shape\u5927\u5c0f :params ratio_pad: \u7f29\u653e\u6bd4\u4f8bgain\u548cpad\u503c None\u5c31\u5148\u8ba1\u7b97gain\u548cpad\u503c\u518dpad+scale \u4e0d\u4e3a\u7a7a\u5c31\u76f4\u63a5pad+scale \"\"\" # ratio_pad\u4e3a\u7a7a\u5c31\u5148\u7b97\u653e\u7f29\u6bd4\u4f8bgain\u548cpad\u503c calculate from img0_shape if ratio_pad is None : # gain = old / new \u53d6\u9ad8\u5bbd\u7f29\u653e\u6bd4\u4f8b\u4e2d\u8f83\u5c0f\u7684,\u4e4b\u540e\u8fd8\u53ef\u4ee5\u518dpad \u5982\u679c\u76f4\u63a5\u53d6\u5927\u7684, \u88c1\u526a\u5c31\u53ef\u80fd\u51cf\u53bb\u76ee\u6807 gain = min ( img1_shape [ 0 ] / img0_shape [ 0 ], img1_shape [ 1 ] / img0_shape [ 1 ]) # wh padding wh\u4e2d\u6709\u4e00\u4e2a\u4e3a0 \u4e3b\u8981\u662fpad\u53e6\u4e00\u4e2a pad = ( img1_shape [ 1 ] - img0_shape [ 1 ] * gain ) / 2 , ( img1_shape [ 0 ] - img0_shape [ 0 ] * gain ) / 2 else : gain = ratio_pad [ 0 ][ 0 ] # \u6307\u5b9a\u6bd4\u4f8b pad = ratio_pad [ 1 ] # \u6307\u5b9apad\u503c # \u56e0\u4e3apad = img1_shape - img0_shape \u6240\u4ee5\u8981\u628a\u5c3a\u5bf8\u4eceimg1 -> img0 \u5c31\u540c\u6837\u4e5f\u9700\u8981\u51cf\u53bbpad # \u5982\u679cimg1_shape>img0_shape pad>0 coords\u4ece\u5927\u5c3a\u5bf8\u7f29\u653e\u5230\u5c0f\u5c3a\u5bf8 \u51cf\u53bbpad \u7b26\u5408 # \u5982\u679cimg1_shape<img0_shape pad<0 coords\u4ece\u5c0f\u5c3a\u5bf8\u7f29\u653e\u5230\u5927\u5c3a\u5bf8 \u51cf\u53bbpad \u7b26\u5408 coords [:, [ 0 , 2 ]] -= pad [ 0 ] # x padding coords [:, [ 1 , 3 ]] -= pad [ 1 ] # y padding # \u7f29\u653escale coords [:, : 4 ] /= gain # \u9632\u6b62\u653e\u7f29\u540e\u7684\u5750\u6807\u8fc7\u754c \u8fb9\u754c\u5904\u76f4\u63a5\u526a\u5207 clip_coords ( coords , img0_shape ) return coords 23. xyxy2xywh & xywh2xyxy \u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u4e24\u4e2a\u76f8\u53cd\u7684\u8fc7\u7a0b\u3002 xyxy2xywh\u662f\u5c06\u9884\u6d4b\u4fe1\u606fxyxy\u683c\u5f0f\u8f6c\u5316\u4e3axywh\u7684\u683c\u5f0f\uff0c\u800cxywh2xyxy\u662f\u5c06\u9884\u6d4b\u4fe1\u606fxywh\u683c\u5f0f\u8f6c\u5316\u4e3axyxy\u7684\u683c\u5f0f\u3002 \u8fd9\u4e24\u4e2a\u51fd\u6570\u7684\u4ee3\u7801\u5f88\u91cd\u8981\uff0c\u4e00\u5b9a\u8981\u638c\u63e1\u3002 \u4ee3\u7801\u8fd8\u662f\u90a3\u53e5\u8bdd\uff1ax\u7684\u6b63\u5750\u6807\u662f\u5411\u53f3\uff0cy\u7684\u6b63\u5750\u6807\u662f\u5411\u4e0b\u3002 23.1 xyxy2xywh \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u9884\u6d4b\u4fe1\u606fxyxy\u683c\u5f0f\u8f6c\u5316\u4e3axywh\u7684\u683c\u5f0f\u3002 xyxy2xywh\u51fd\u6570\u4ee3\u7801\uff1a def xyxy2xywh ( x ): \"\"\"\"\u7528\u5728detect.py\u548ctest.py\u4e2d \u64cd\u4f5c\u6700\u540e, \u5c06\u9884\u6d4b\u4fe1\u606f\u4ecexyxy\u683c\u5f0f\u8f6c\u4e3axywh\u683c\u5f0f \u518d\u4fdd\u5b58 Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] where x1y1=top-left, x2y2=bottom-right :params x: [n, x1y1x2y2] (x1, y1): \u5de6\u4e0a\u89d2 (x2, y2): \u53f3\u4e0b\u89d2 :return y: [n, xywh] (x, y): \u4e2d\u5fc3\u70b9 wh: \u5bbd\u9ad8 \"\"\" y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = ( x [:, 0 ] + x [:, 2 ]) / 2 # x center y [:, 1 ] = ( x [:, 1 ] + x [:, 3 ]) / 2 # y center y [:, 2 ] = x [:, 2 ] - x [:, 0 ] # width y [:, 3 ] = x [:, 3 ] - x [:, 1 ] # height return y \u5728detect.py\u4e2d\u4f7f\u7528\uff1a # Write results for *xyxy, conf, cls in reversed(det): if save_txt: # Write to file xywh = (xyxy2xywh(flow.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist() # normalized xywh 23.2 xywh2xyxy \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u9884\u6d4b\u4fe1\u606fxywh\u683c\u5f0f\u8f6c\u5316\u4e3axyxy\u7684\u683c\u5f0f\u3002 xywh2xyxy\u51fd\u6570\u4ee3\u7801\uff1a def xywh2xyxy ( x ): \"\"\"\u7528\u5728val.py\u4e2d \u64cd\u4f5c\u4e4b\u524d \u8f6c\u4e3axyxy\u624d\u53ef\u4ee5\u8fdb\u884c\u64cd\u4f5c \u6ce8\u610f: x\u7684\u6b63\u65b9\u5411\u4e3a\u53f3\u9762 y\u7684\u6b63\u65b9\u5411\u4e3a\u4e0b\u9762 Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where x1y1=top-left, x2y2=bottom-right :params x: [n, xywh] (x, y): :return y: [n, x1y1x2y2] (x1, y1): \u5de6\u4e0a\u89d2 (x2, y2): \u53f3\u4e0b\u89d2 \"\"\" y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = x [:, 0 ] - x [:, 2 ] / 2 # top left x y [:, 1 ] = x [:, 1 ] - x [:, 3 ] / 2 # top left y y [:, 2 ] = x [:, 0 ] + x [:, 2 ] / 2 # bottom right x y [:, 3 ] = x [:, 1 ] + x [:, 3 ] / 2 # bottom right y return y 24. xywhn2xyxy & xyxy2xywhn & xyn2xy \u8fd9\u4e09\u4e2a\u51fd\u6570\u4e3b\u8981\u7528\u4e8edataloaders.py\u6587\u4ef6\u4e2d\u3002\u4e3b\u8981\u662f\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e00\u4e9b\u53d8\u6362\u64cd\u4f5c\u3002 xywhn2xyxy\u662f\u5c06xywh(normalized) -> x1y1x2y2\u3002xyxy2xywhn\u662f\u5c06x1y1x2y2 -> xywh(normalized)\u3002 xyn2xy\u662f\u5c06xy(normalized) -> xy\u3002\u8fd9\u4e09\u4e2a\u51fd\u6570\u4e5f\u662f\u6bd4\u8f83\u91cd\u8981\u7684\uff0c\u5927\u5bb6\u5fc5\u987b\u638c\u63e1\u3002 24.1 xywhn2xyxy \u8fd9\u4e2a\u51fd\u6570\u662fxywh(normalized) -> x1y1x2y2\u3002 xywhn2xyxy\u51fd\u6570\u4ee3\u7801: def xywhn2xyxy ( x , w = 640 , h = 640 , padw = 0 , padh = 0 ): \"\"\"\u7528\u5728dataloaders.py\u7684 LoadImagesAndLabels\u7c7b\u7684__getitem__\u51fd\u6570\u3001load_mosaic\u3001load_mosaic9\u7b49\u51fd\u6570\u4e2d \u5c06xywh(normalized) -> x1y1x2y2 (x, y): \u4e2d\u95f4\u70b9 wh: \u5bbd\u9ad8 (x1, y1): \u5de6\u4e0a\u70b9 (x2, y2): \u53f3\u4e0b\u70b9 Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right \"\"\" y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = w * ( x [:, 0 ] - x [:, 2 ] / 2 ) + padw # top left x y [:, 1 ] = h * ( x [:, 1 ] - x [:, 3 ] / 2 ) + padh # top left y y [:, 2 ] = w * ( x [:, 0 ] + x [:, 2 ] / 2 ) + padw # bottom right x y [:, 3 ] = h * ( x [:, 1 ] + x [:, 3 ] / 2 ) + padh # bottom right y return y 24.2 xyxy2xywhn \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06x1y1x2y2 -> xywh(normalized)\u3002 xyxy2xywhn\u51fd\u6570\u4ee3\u7801\uff1a def xyxy2xywhn ( x , w = 640 , h = 640 , clip = False , eps = 0.0 ): \"\"\"\u7528\u5728dataloaders.py\u7684 LoadImagesAndLabels\u7c7b\u7684__getitem__\u51fd\u6570\u4e2d \u5c06 x1y1x2y2 -> xywh(normalized) (x1, y1): \u5de6\u4e0a\u70b9 (x2, y2): \u53f3\u4e0b\u70b9 (x, y): \u4e2d\u95f4\u70b9 wh: \u5bbd\u9ad8 Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right \"\"\" # Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right if clip : clip_coords ( x , ( h - eps , w - eps )) # warning: inplace clip y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = (( x [:, 0 ] + x [:, 2 ]) / 2 ) / w # x center y [:, 1 ] = (( x [:, 1 ] + x [:, 3 ]) / 2 ) / h # y center y [:, 2 ] = ( x [:, 2 ] - x [:, 0 ]) / w # width y [:, 3 ] = ( x [:, 3 ] - x [:, 1 ]) / h # height return y 24.3 xyn2xy \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06xy(normalized) -> xy\u3002 xyn2xy\u51fd\u6570\u4ee3\u7801\uff1a def xyn2xy ( x , w = 640 , h = 640 , padw = 0 , padh = 0 ): \"\"\"\u7528\u5728dataloaders.py\u7684load_mosaic\u548cload_mosaic9\u51fd\u6570\u4e2d xy(normalized) -> xy Convert normalized segments into pixel segments, shape (n,2) \"\"\" # Convert normalized segments into pixel segments, shape (n,2) y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = w * x [:, 0 ] + padw # top left x y [:, 1 ] = h * x [:, 1 ] + padh # top left y return 25. non_max_suppression NMS(\u975e\u6781\u5927\u503c\u6291\u5236)\uff0c\u8fd9\u4e2a\u51fd\u6570\u76f8\u4fe1\u5927\u5bb6\u90fd\u5df2\u7ecf\u5f88\u719f\u6089\u4e86\uff0c\u8fd9\u662f\u76ee\u6807\u68c0\u6d4b\u6700\u57fa\u672c\u7684\u64cd\u4f5c\u4e4b\u4e00\u4e86\u3002 \u53ef\u4ee5\u8bf4\u8fd9\u4e2a\u51fd\u6570\u662f\u8fd9\u7bc7\u535a\u5ba2\u5f53\u4e2d\u6700\u91cd\u8981\u7684\u4ee3\u7801\u4e5f\u4e0d\u4e3a\u8fc7\uff0c\u6240\u4ee5\u5927\u5bb6\u4e00\u5b9a\u8981\u638c\u63e1\u8fd9\u4e2a\u51fd\u6570\uff08\u6d41\u7a0b\u539f\u7406+\u4ee3\u7801\uff09\u3002 \u66f4\u591a\u5173\u4e8enms\u8bf7\u53c2\u9605\uff1a \u300anms\u300b non_max_suppression\u51fd\u6570\u4ee3\u7801\uff1a def non_max_suppression ( prediction , # [batch, num_anchors(3\u4e2ayolo\u9884\u6d4b\u5c42), (x+y+w+h+1+num_classes)] = [1, 18900, 25] # 3\u4e2aanchor\u7684\u9884\u6d4b\u7ed3\u679c\u603b\u548c conf_thres = 0.25 , # \u5148\u8fdb\u884c\u4e00\u8f6e\u7b5b\u9009\uff0c\u5c06\u5206\u6570\u8fc7\u4f4e\u7684\u9884\u6d4b\u6846\uff08<conf_thres\uff09\u5220\u9664\uff08\u5206\u6570\u7f6e0\uff09 iou_thres = 0.45 , # iou\u9608\u503c, \u5982\u679c\u5176\u4f59\u9884\u6d4b\u6846\u4e0etarget\u7684iou>iou_thres, \u5c31\u5c06\u90a3\u4e2a\u9884\u6d4b\u6846\u7f6e0 classes = None , # \u662f\u5426nms\u540e\u53ea\u4fdd\u7559\u7279\u5b9a\u7684\u7c7b\u522b \u9ed8\u8ba4\u4e3aNone agnostic = False , # \u8fdb\u884cnms\u662f\u5426\u4e5f\u53bb\u9664\u4e0d\u540c\u7c7b\u522b\u4e4b\u95f4\u7684\u6846 \u9ed8\u8ba4False multi_label = False , # \u662f\u5426\u662f\u591a\u6807\u7b7e nc>1 \u4e00\u822c\u662fTrue labels = (), # \u6807\u7b7e max_det = 300 , # \u6bcf\u5f20\u56fe\u7247\u7684\u6700\u5927\u76ee\u6807\u4e2a\u6570 \u9ed8\u8ba41000 ): \"\"\"Non-Maximum Suppression (NMS) on inference results to reject overlapping bounding boxes Returns: list of detections, on (n,6) tensor per image [xyxy, conf, cls] \"\"\" if isinstance ( prediction , ( list , tuple )): # YOLOv5 model in validation model, output = (inference_out, loss_out) prediction = prediction [ 0 ] # select only inference output # Settings \u8bbe\u7f6e\u4e00\u4e9b\u53d8\u91cf bs = prediction . shape [ 0 ] # batch size nc = prediction . shape [ 2 ] - 5 # number of classes xc = prediction [ ... , 4 ] > conf_thres # candidates # Checks assert 0 <= conf_thres <= 1 , f \"Invalid Confidence threshold { conf_thres } , valid values are between 0.0 and 1.0\" assert 0 <= iou_thres <= 1 , f \"Invalid IoU { iou_thres } , valid values are between 0.0 and 1.0\" # Settings # min_wh = 2 # (pixels) minimum box width and height # (pixels) \u9884\u6d4b\u7269\u4f53\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5927\u5c0f\u8303\u56f4 [min_wh, max_wh] max_wh = 7680 # (pixels) maximum box width and height # \u6bcf\u4e2a\u56fe\u50cf\u6700\u591a\u68c0\u6d4b\u7269\u4f53\u7684\u4e2a\u6570 maximum number of boxes into torchvision.ops.nms() max_nms = 30000 # maximum number of boxes into flow.nms() # nms\u6267\u884c\u65f6\u95f4\u9608\u503c \u8d85\u8fc7\u8fd9\u4e2a\u65f6\u95f4\u5c31\u9000\u51fa\u4e86 seconds to quit after time_limit = 0.3 + 0.03 * bs # seconds to quit after # \u662f\u5426\u9700\u8981\u5197\u4f59\u7684detections require redundant detections redundant = True # require redundant detections multi_label &= nc > 1 # multiple labels per box (adds 0.5ms/img) merge = False # use merge-NMS t = time . time () # \u8bb0\u5f55\u5f53\u524d\u65f6\u523b\u65f6\u95f4 output = [ flow . zeros (( 0 , 6 ), device = prediction . device )] * bs for xi , x in enumerate ( prediction ): # image index, image inference # Apply constraints # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0 # width-height x = x [ xc [ xi ]] # confidence # {list: bs} \u7b2c\u4e00\u5f20\u56fe\u7247\u7684target[17, 5] \u7b2c\u4e8c\u5f20[1, 5] \u7b2c\u4e09\u5f20[7, 5] \u7b2c\u56db\u5f20[6, 5] # Cat apriori labels if autolabelling \u81ea\u52a8\u6807\u6ce8label\u65f6\u8c03\u7528 \u4e00\u822c\u4e0d\u7528 # \u81ea\u52a8\u6807\u8bb0\u5728\u975e\u5e38\u9ad8\u7684\u7f6e\u4fe1\u9608\u503c\uff08\u5373 0.90 \u7f6e\u4fe1\u5ea6\uff09\u4e0b\u6548\u679c\u6700\u4f73,\u800c mAP \u8ba1\u7b97\u4f9d\u8d56\u4e8e\u975e\u5e38\u4f4e\u7684\u7f6e\u4fe1\u9608\u503c\uff08\u5373 0.001\uff09\u6765\u6b63\u786e\u8bc4\u4f30 PR \u66f2\u7ebf\u4e0b\u7684\u533a\u57df\u3002 # \u8fd9\u4e2a\u81ea\u52a8\u6807\u6ce8\u6211\u89c9\u5f97\u5e94\u8be5\u662f\u4e00\u4e2a\u7c7b\u4f3cRNN\u91cc\u9762\u7684Teacher Forcing\u7684\u8bad\u7ec3\u673a\u5236 \u5c31\u662f\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u8ddf\u7740\u8001\u5e08(ground truth)\u8d70 # \u4f46\u662f\u8fd9\u6837\u53c8\u4f1a\u9020\u6210\u4e00\u4e2a\u95ee\u9898: \u4e00\u76f4\u9760\u8001\u5e08\u5e26\u7684\u5b69\u5b50\u662f\u8d70\u4e0d\u8fdc\u7684 \u8fd9\u6837\u7684\u6a21\u578b\u56e0\u4e3a\u4f9d\u8d56\u6807\u7b7e\u6570\u636e,\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d,\u6a21\u578b\u4f1a\u6709\u8f83\u597d\u7684\u6548\u679c # \u4f46\u662f\u5728\u6d4b\u8bd5\u7684\u65f6\u5019\u56e0\u4e3a\u4e0d\u80fd\u5f97\u5230ground truth\u7684\u652f\u6301, \u6240\u4ee5\u5982\u679c\u76ee\u524d\u751f\u6210\u7684\u5e8f\u5217\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6709\u5f88\u5927\u4e0d\u540c, \u6a21\u578b\u5c31\u4f1a\u53d8\u5f97\u8106\u5f31\u3002 # \u6240\u4ee5\u4e2a\u4eba\u8ba4\u4e3a(\u4e2a\u4eba\u89c2\u70b9): \u5e94\u8be5\u5728\u4e0b\u9762\u4f7f\u7528\u7684\u65f6\u5019\u6709\u9009\u62e9\u7684\u5f00\u542f\u8fd9\u4e2atrick \u6bd4\u5982\u8bbe\u7f6e\u4e00\u4e2a\u6982\u7387p\u968f\u673a\u5f00\u542f \u6216\u8005\u5728\u8bad\u7ec3\u7684\u524dn\u4e2aepoch\u4f7f\u7528 \u540e\u9762\u518d\u5173\u95ed # Cat apriori labels if autolabelling if labels and len ( labels [ xi ]): lb = labels [ xi ] v = flow . zeros (( len ( lb ), nc + 5 ), device = x . device ) v [:, : 4 ] = lb [:, 1 : 5 ] # box v [:, 4 ] = 1.0 # conf v [ range ( len ( lb )), lb [:, 0 ] . long () + 5 ] = 1.0 # cls x = flow . cat (( x , v ), 0 ) # If none remain process next image # \u7ecf\u8fc7\u524d\u4e24\u5c42\u8fc7\u6ee4\u540e\u5982\u679c\u8be5feature map\u6ca1\u6709\u76ee\u6807\u6846\u4e86\uff0c\u5c31\u7ed3\u675f\u8fd9\u8f6e\u76f4\u63a5\u8fdb\u884c\u4e0b\u4e00\u5f20\u56fe if not x . shape [ 0 ]: continue # Compute conf \u8ba1\u7b97conf_score x [:, 5 :] *= x [:, 4 : 5 ] # conf = obj_conf * cls_conf # Box (center x, center y, width, height) to (x1, y1, x2, y2) \u5de6\u4e0a\u89d2 \u53f3\u4e0b\u89d2 [59, 4] box = xywh2xyxy ( x [:, : 4 ]) # Detections matrix nx6 (xyxy, conf, cls) if multi_label : # \u7b2c\u4e09\u8f6e\u8fc7\u6ee4:\u9488\u5bf9\u6bcf\u4e2a\u7c7b\u522bscore(obj_conf * cls_conf) > conf_thres [59, 6] -> [51, 6] # \u8fd9\u91cc\u4e00\u4e2a\u6846\u662f\u6709\u53ef\u80fd\u6709\u591a\u4e2a\u7269\u4f53\u7684\uff0c\u6240\u4ee5\u8981\u7b5b\u9009 # nonzero: \u83b7\u5f97\u77e9\u9635\u4e2d\u7684\u975e0(True)\u6570\u636e\u7684\u4e0b\u6807 a.t(): \u5c06a\u77e9\u9635\u62c6\u5f00 # i: \u4e0b\u6807 [43] j: \u7c7b\u522bindex [43] \u8fc7\u6ee4\u4e86\u4e24\u4e2ascore\u592a\u4f4e\u7684 i , j = ( x [:, 5 :] > conf_thres ) . nonzero ( as_tuple = False ) . T x = flow . cat (( box [ i ], x [ i , j + 5 , None ], j [:, None ] . float ()), 1 ) else : # best class only conf , j = x [:, 5 :] . max ( 1 , keepdim = True ) # \u4e00\u4e2a\u7c7b\u522b\u76f4\u63a5\u53d6\u5206\u6570\u6700\u5927\u7c7b\u7684\u5373\u53ef x = flow . cat (( box , conf , j . float ()), 1 )[ conf . view ( - 1 ) > conf_thres ] # Filter by class \u662f\u5426\u53ea\u4fdd\u7559\u7279\u5b9a\u7684\u7c7b\u522b \u9ed8\u8ba4None \u4e0d\u6267\u884c\u8fd9\u91cc if classes is not None : x = x [( x [:, 5 : 6 ] == flow . tensor ( classes , device = x . device )) . any ( 1 )] # Apply finite constraint # if not flow.isfinite(x).all(): # x = x[flow.isfinite(x).all(1)] # Check shape n = x . shape [ 0 ] # number of boxes if not n : # no boxes \u5982\u679c\u7ecf\u8fc7\u7b2c\u4e09\u8f6e\u8fc7\u6ee4\u8be5feature map\u6ca1\u6709\u76ee\u6807\u6846\u4e86\uff0c\u5c31\u7ed3\u675f\u8fd9\u8f6e\u76f4\u63a5\u8fdb\u884c\u4e0b\u4e00\u5f20\u56fe continue elif n > max_nms : # excess boxes \u5982\u679c\u7ecf\u8fc7\u7b2c\u4e09\u8f6e\u8fc7\u6ee4\u8be5feature map\u8fd8\u8981\u5f88\u591a\u6846(>max_nms) \u5c31\u9700\u8981\u6392\u5e8f x = x [ x [:, 4 ] . argsort ( descending = True )[: max_nms ]] # sort by confidence # Batched NMS # \u7b2c4\u8f6e\u8fc7\u6ee4 Batched NMS [51, 6] -> [5, 6] c = x [:, 5 : 6 ] * ( 0 if agnostic else max_wh ) # classes # \u505a\u4e2a\u5207\u7247 \u5f97\u5230boxes\u548cscores \u4e0d\u540c\u7c7b\u522b\u7684box\u4f4d\u7f6e\u4fe1\u606f\u52a0\u4e0a\u4e00\u4e2a\u5f88\u5927\u7684\u6570\u4f46\u53c8\u4e0d\u540c\u7684\u6570c # \u8fd9\u6837\u4f5c\u975e\u6781\u5927\u6291\u5236\u7684\u65f6\u5019\u4e0d\u540c\u7c7b\u522b\u7684\u6846\u5c31\u4e0d\u4f1a\u63ba\u548c\u5230\u4e00\u5757\u4e86 \u8fd9\u662f\u4e00\u4e2a\u4f5cnms\u633a\u5de7\u5999\u7684\u6280\u5de7 boxes , scores = x [:, : 4 ] + c , x [:, 4 ] # boxes (offset by class), scores # \u8fd4\u56denms\u8fc7\u6ee4\u540e\u7684bounding box(boxes)\u7684\u7d22\u5f15\uff08\u964d\u5e8f\u6392\u5217\uff09 # i = torchvision.ops.nms(boxes, scores, iou_thres) # NMS i = flow . nms ( boxes , scores , iou_thres ) # NMS if i . shape [ 0 ] > max_det : # limit detections i = i [: max_det ] if merge and ( 1 < n < 3e3 ): # Merge NMS (boxes merged using weighted mean) # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4) iou = box_iou ( boxes [ i ], boxes ) > iou_thres # iou matrix weights = iou * scores [ None ] # box weights # bounding box\u5408\u5e76 \u5176\u5b9e\u5c31\u662f\u628a\u6743\u91cd\u548c\u6846\u76f8\u4e58\u518d\u9664\u4ee5\u6743\u91cd\u4e4b\u548c x [ i , : 4 ] = flow . mm ( weights , x [:, : 4 ]) . float () / weights . sum ( 1 , keepdim = True ) # merged boxes if redundant : i = i [ iou . sum ( 1 ) > 1 ] # require redundancy output [ xi ] = x [ i ] # \u6700\u7ec8\u8f93\u51fa [5, 6] # \u770b\u4e0b\u65f6\u95f4\u8d85\u6ca1\u8d85\u65f6 \u8d85\u65f6\u6ca1\u505a\u5b8c\u7684\u5c31\u4e0d\u505a\u4e86 if ( time . time () - t ) > time_limit : LOGGER . warning ( f \"WARNING: NMS time limit { time_limit : .3f } s exceeded\" ) break # time limit exceeded return output \u8fd9\u4e2a\u51fd\u6570\u4e00\u822c\u4f1a\u7528\u5728detect.py\u6216\u8005val.py\u7684\u6a21\u578b\u524d\u5411\u63a8\u7406\u7ed3\u675f\u4e4b\u540e\u3002 \u66f4\u591a\u5173\u4e8eNMS\u51fd\u6570\u6d41\u7a0b\u548c\u4ee3\u7801\uff1a \u3010YOLO-V3-SPP \u6e90\u7801\u89e3\u8bfb\u3011\u4e09\u3001\u9884\u6d4b\u6a21\u5757. 26. strip_optimizer \u8fd9\u4e2a\u51fd\u6570\u662f\u5728\u6a21\u578b\u8bad\u7ec3\u5b8c\u540e, strip_optimizer\u51fd\u6570\u5c06optimizer\u3001training_results\u3001updates\u2026 \u4ece\u4fdd\u5b58\u7684\u6a21\u578b\u6587\u4ef6ckpt\u4e2d\u5220\u9664\u3002 strip_optimizer\u51fd\u6570\u4ee3\u7801\uff1a def strip_optimizer ( f = \"best\" , s = \"\" ): # from utils.general import *; strip_optimizer() \"\"\"\u7528\u5728train.py\u6a21\u578b\u8bad\u7ec3\u5b8c\u540e \u5c06optimizer\u3001training_results\u3001updates...\u4ece\u4fdd\u5b58\u7684\u6a21\u578b\u6587\u4ef6f\u4e2d\u5220\u9664 Strip optimizer from 'f' to finalize training, optionally save as 's' :params f: \u4f20\u5165\u7684\u539f\u59cb\u4fdd\u5b58\u7684\u6a21\u578b\u6587\u4ef6 :params s: \u5220\u9664optimizer\u7b49\u53d8\u91cf\u540e\u7684\u6a21\u578b\u4fdd\u5b58\u7684\u5730\u5740 dir \"\"\" # Strip optimizer from 'f' to finalize training, optionally save as 's' x = flow . load ( f , map_location = flow . device ( \"cpu\" )) # x: \u4e3a\u52a0\u8f7d\u8bad\u7ec3\u7684\u6a21\u578b if x . get ( \"ema\" ): # \u5982\u679c\u6a21\u578b\u662fema replace model with ema x [ \"model\" ] = x [ \"ema\" ] # replace model with ema # \u4ee5\u4e0b\u6a21\u578b\u8bad\u7ec3\u6d89\u53ca\u5230\u7684\u82e5\u5e72\u4e2a\u6307\u5b9a\u53d8\u91cf\u7f6e\u7a7a for k in \"optimizer\" , \"best_fitness\" , \"wandb_id\" , \"ema\" , \"updates\" : # keys x [ k ] = None x [ \"epoch\" ] = - 1 # \u6a21\u578bepoch\u6062\u590d\u521d\u59cb\u503c -1 x [ \"model\" ] . half () # to FP16 for p in x [ \"model\" ] . parameters (): p . requires_grad = False # \u4fdd\u5b58\u6a21\u578b x -> s/f flow . save ( x , s or f ) mb = os . path . getsize ( s or f ) / 1e6 # filesize LOGGER . info ( f \"Optimizer stripped from { f } , { f ' saved as { s } ,' if s else '' } { mb : .1f } MB\" ) 27. print_mutation \u8fd9\u4e2a\u51fd\u6570\u7528\u6765\u6253\u5370\u8fdb\u5316\u540e\u7684\u8d85\u53c2\u7ed3\u679c\u548cresults\u5230evolve.txt\u548chyp_evolved.yaml\u4e2d\u3002 print_mutation\u51fd\u6570\u4ee3\u7801\uff1a def print_mutation ( results , hyp , save_dir , bucket , prefix = colorstr ( \"evolve: \" )): \"\"\"\u7528\u5728train.py\u7684\u8fdb\u5316\u8d85\u53c2\u7ed3\u675f\u540e \u6253\u5370\u8fdb\u5316\u540e\u7684\u8d85\u53c2\u7ed3\u679c\u548cresults\u5230evolve.txt\u548chyp_evolved.yaml\u4e2d Print mutation results to evolve.txt (for use with train.py --evolve) :params hyp: \u8fdb\u5316\u540e\u7684\u8d85\u53c2 dict {28\u5bf9 key:value} :params results: tuple(7) (mp, mr, map50, map50:95, box_loss, obj_loss, cls_loss) :params yaml_file: \u8981\u4fdd\u5b58\u7684\u8fdb\u5316\u540e\u7684\u8d85\u53c2\u6587\u4ef6\u540d runs\\train\\evolve\\hyp_evolved.yaml :params bucket: '' \"\"\" evolve_csv = save_dir / \"evolve.csv\" evolve_yaml = save_dir / \"hyp_evolve.yaml\" keys = ( \"metrics/precision\" , \"metrics/recall\" , \"metrics/mAP_0.5\" , \"metrics/mAP_0.5:0.95\" , \"val/box_loss\" , \"val/obj_loss\" , \"val/cls_loss\" ,) + tuple ( hyp . keys () ) # [results + hyps] keys = tuple ( x . strip () for x in keys ) vals = results + tuple ( hyp . values ()) n = len ( keys ) # Download (optional) if bucket : url = f \"gs:// { bucket } /evolve.csv\" if gsutil_getsize ( url ) > ( evolve_csv . stat () . st_size if evolve_csv . exists () else 0 ): os . system ( f \"gsutil cp { url } { save_dir } \" ) # download evolve.csv if larger than local # Log to evolve.csv s = \"\" if evolve_csv . exists () else (( \" %20s ,\" * n % keys ) . rstrip ( \",\" ) + \" \\n \" ) # add header with open ( evolve_csv , \"a\" ) as f : f . write ( s + ( \" %20.5g ,\" * n % vals ) . rstrip ( \",\" ) + \" \\n \" ) # Save yaml with open ( evolve_yaml , \"w\" ) as f : data = pd . read_csv ( evolve_csv ) data = data . rename ( columns = lambda x : x . strip ()) # strip keys i = np . argmax ( fitness ( data . values [:, : 4 ])) # generations = len ( data ) f . write ( \"# YOLOv5 Hyperparameter Evolution Results \\n \" + f \"# Best generation: { i } \\n \" + f \"# Last generation: { generations - 1 } \\n \" + \"# \" + \", \" . join ( f \" { x . strip () : >20s } \" for x in keys [: 7 ]) + \" \\n \" + \"# \" + \", \" . join ( f \" { x : >20.5g } \" for x in data . values [ i , : 7 ]) + \" \\n\\n \" ) yaml . safe_dump ( data . loc [ i ][ 7 :] . to_dict (), f , sort_keys = False ) # Print to screen LOGGER . info ( prefix + f \" { generations } generations finished, current result: \\n \" + prefix + \", \" . join ( f \" { x . strip () : >20s } \" for x in keys ) + \" \\n \" + prefix + \", \" . join ( f \" { x : 20.5g } \" for x in vals ) + \" \\n\\n \" ) if bucket : os . system ( f \"gsutil cp { evolve_csv } { evolve_yaml } gs:// { bucket } \" ) # upload 28. apply_classifier \u8fd9\u4e2a\u51fd\u6570\u5b9a\u4e49\u4e86\u4e00\u4e2a\u4e8c\u7ea7\u5206\u7c7b\u5668\u6765\u5904\u7406yolo\u7684\u8f93\u51fa\uff0c\u53ef\u4ee5\u5c06\u5b83\u7528\u5728detect.py\u4e2d\u3002 \u8fd9\u91cc\u5199\u7684\u8fd9\u4e2a\u51fd\u6570\u53ea\u662f\u4e00\u4e2a\u666e\u901a\u7684\u5b9e\u73b0\uff0c\u4f60\u4e5f\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u4efb\u52a1\u6539\u5199\u8fd9\u4e2a\u51fd\u6570\u3002 \u4e0d\u8fc7\u8fd9\u4e2a\u51fd\u6570\u6211\u4eec\u51e0\u4e4e\u4e0d\u4f1a\u7528\u5b83\uff0c\u56e0\u4e3a\u5b83\u5f88\u5bb9\u6613\u51fa\u9519\u3002\u6211\u4eec\u8fd9\u91cc\u5c31\u4e0d\u4ed4\u7ec6\u4ecb\u7ecd\u4e86\uff0c\u771f\u7684\u5f88\u96be\u7528\u5230\u8fd9\u4e2a\u51fd\u6570\uff0c\u968f\u4fbf\u770b\u4e0b\u5c31\u597d\u3002 \u51fd\u6570\u4ee3\u7801\uff1a def apply_classifier ( x , model , img , im0 ): \"\"\"\u7528\u5728detect.py\u6587\u4ef6\u7684nms\u540e\u7ee7\u7eed\u5bf9feature map\u9001\u5165model2 \u8fdb\u884c\u4e8c\u6b21\u5206\u7c7b \u5b9a\u4e49\u4e86\u4e00\u4e2a\u4e8c\u7ea7\u5206\u7c7b\u5668\u6765\u5904\u7406yolo\u7684\u8f93\u51fa \u5f53\u524d\u5b9e\u73b0\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u53c2\u8003\u8d77\u70b9\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u5b83\u81ea\u884c\u5b9e\u73b0\u6b64\u9879 \u6bd4\u5982\u4f60\u6709\u7167\u7247\u4e0e\u6c7d\u8f66\u4e0e\u8f66\u724c, \u4f60\u7b2c\u4e00\u6b21\u526a\u5207\u8f66\u724c, \u5e76\u5c06\u5176\u53d1\u9001\u5230\u7b2c\u4e8c\u9636\u6bb5\u5206\u7c7b\u5668, \u4ee5\u68c0\u6d4b\u5176\u4e2d\u7684\u5b57\u7b26 Apply a second stage classifier to yolo outputs https://github.com/ultralytics/yolov5/issues/2700 \u8fd9\u4e2a\u51fd\u6570\u4f7f\u7528\u8d77\u6765\u5f88\u5bb9\u6613\u51fa\u9519 \u4e0d\u662f\u5f88\u63a8\u8350\u4f7f\u7528 https://github.com/ultralytics/yolov5/issues/1472 :params x: yolo\u5c42\u7684\u8f93\u51fa :params model: \u5206\u7c7b\u6a21\u578b :params img: \u8fdb\u884cresize + pad\u4e4b\u540e\u7684\u56fe\u7247 :params im0: \u539f\u5c3a\u5bf8\u7684\u56fe\u7247 \"\"\" im0 = [ im0 ] if isinstance ( im0 , np . ndarray ) else im0 for i , d in enumerate ( x ): # per image if d is not None and len ( d ): d = d . clone () # Reshape and pad cutouts b = xyxy2xywh ( d [:, : 4 ]) # boxes xyxy -> xywh b [:, 2 :] = b [:, 2 :] . max ( 1 )[ 0 ] . unsqueeze ( 1 ) # rectangle to square b [:, 2 :] = b [:, 2 :] * 1.3 + 30 # pad d [:, : 4 ] = xywh2xyxy ( b ) . long () # xywh -> xyxy # Rescale boxes from img_size to im0 size scale_coords ( img . shape [ 2 :], d [:, : 4 ], im0 [ i ] . shape ) # Classes pred_cls1 = d [:, 5 ] . long () # \u5728\u4e4b\u524d\u7684yolo\u6a21\u578b\u9884\u6d4b\u7684\u7c7b\u522b ims = [] for j , a in enumerate ( d ): # per item cutout = im0 [ i ][ int ( a [ 1 ]): int ( a [ 3 ]), int ( a [ 0 ]): int ( a [ 2 ])] im = cv2 . resize ( cutout , ( 224 , 224 )) # BGR # cv2.imwrite('test%i.jpg' % j, cutout) im = im [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB, to 3x416x416 im = np . ascontiguousarray ( im , dtype = np . float32 ) # uint8 to float32 im /= 255.0 # 0 - 255 to 0.0 - 1.0 ims . append ( im ) # \u7528model\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b pred_cls2 = model ( flow . Tensor ( ims ) . to ( d . device )) . argmax ( 1 ) # classifier prediction # \u4fdd\u7559\u9884\u6d4b\u4e00\u81f4\u7684\u7ed3\u679c x [ i ] = x [ i ][ pred_cls1 == pred_cls2 ] # retain matching class detections return x 29. increment_path \u7528\u4e8e\u9012\u589e\u8def\u5f84\u3002 \u6bd4\u5982\u6211\u8f93\u5165\u8def\u5f84\u662frun/train/exp\uff0c\u4f46\u662f\u53d1\u73b0\u6587\u4ef6\u5939\u91cc\u9762\u5df2\u7ecf\u6709\u8fd9\u4e2a\u6587\u4ef6\u4e86\uff0c \u90a3\u4e48\u5c31\u5c06\u6587\u4ef6\u8def\u5f84\u6269\u5c55\u56f4\u4e3a\uff1aruns/train/exp{sep}0, runs/exp{sep}1 etc\u3002 increment_path\u51fd\u6570\u4ee3\u7801\uff1a def increment_path ( path , exist_ok = False , sep = \"\" , mkdir = False ): \"\"\"\u8fd9\u662f\u4e2a\u7528\u5904\u7279\u522b\u5e7f\u6cdb\u7684\u51fd\u6570 train.py\u3001detect.py\u3001test.py\u7b49\u90fd\u4f1a\u7528\u5230 \u9012\u589e\u8def\u5f84 \u5982 run/train/exp --> runs/train/exp{sep}0, runs/exp{sep}1 etc. :params path: window path run/train/exp :params exist_ok: False :params sep: exp\u6587\u4ef6\u540d\u7684\u540e\u7f00 \u9ed8\u8ba4'' :params mkdir: \u662f\u5426\u5728\u8fd9\u91cc\u521b\u5efadir False \"\"\" # Increment file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc. path = Path ( path ) # os-agnostic # \u5982\u679c\u8be5\u6587\u4ef6\u5939\u5df2\u7ecf\u5b58\u5728 \u5219\u5c06\u8def\u5f84run/train/exp\u4fee\u6539\u4e3a runs/train/exp1 if path . exists () and not exist_ok : # path.suffix \u5f97\u5230\u8def\u5f84path\u7684\u540e\u7f00 '' path , suffix = ( path . with_suffix ( \"\" ), path . suffix ) if path . is_file () else ( path , \"\" ) # Method 1 for n in range ( 2 , 9999 ): p = f \" { path }{ sep }{ n }{ suffix } \" # increment path if not os . path . exists ( p ): # break path = Path ( p ) # Method 2 (deprecated) # dirs = glob.glob(f\"{path}{sep}*\") # similar paths # matches = [re.search(rf\"{path.stem}{sep}(\\d+)\", d) for d in dirs] # i = [int(m.groups()[0]) for m in matches if m] # indices # n = max(i) + 1 if i else 2 # increment number # path = Path(f\"{path}{sep}{n}{suffix}\") # increment path if mkdir : path . mkdir ( parents = True , exist_ok = True ) # make directory return path 30. resample_segments \u8fd9\u4e2a\u51fd\u6570\u662f \u5bf9segment\u91cd\u65b0\u91c7\u6837\uff0c\u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000)\u3002 resample_segments\u51fd\u6570\u4ee3\u7801\uff1a def resample_segments ( segments , n = 1000 ): \"\"\"\u7528\u5728augmentations.py\u6587\u4ef6\u4e2d\u7684random_perspective\u51fd\u6570\u4e2d \u5bf9segment\u91cd\u65b0\u91c7\u6837\uff0c\u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000) :params segments: [N, x1x2...] :params n: \u91c7\u6837\u4e2a\u6570 :return segments: [N, n/2, 2] \"\"\" # Up-sample an (n,2) segment for i , s in enumerate ( segments ): s = np . concatenate (( s , s [ 0 : 1 , :]), axis = 0 ) x = np . linspace ( 0 , len ( s ) - 1 , n ) xp = np . arange ( len ( s )) # \u5bf9\u6240\u6709\u7684segments\u90fd\u8fdb\u884c\u91cd\u65b0\u91c7\u6837 \u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000) segments [ i ] = np . concatenate ([ np . interp ( x , xp , s [:, i ]) for i in range ( 2 )]) . reshape ( 2 , - 1 ) . T # segment xy0 return segments 31. segment2box \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e(\u4e0d\u662f\u77e9\u5f62\u6807\u7b7e \u5230\u5e95\u662f\u51e0\u8fb9\u5f62\u672a\u77e5)\u8f6c\u5316\u4e3a\u4e00\u4e2a\u77e9\u5f62\u6807\u7b7e\u3002 segment2box\u51fd\u6570\u4ee3\u7801\uff1a def segment2box ( segment , width = 640 , height = 640 ): \"\"\"\u7528\u5728augmentations.py\u6587\u4ef6\u4e2d\u7684random_perspective\u51fd\u6570\u4e2d \u5c06\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e(\u4e0d\u662f\u77e9\u5f62\u6807\u7b7e \u5230\u5e95\u662f\u51e0\u8fb9\u5f62\u672a\u77e5)\u8f6c\u5316\u4e3a\u4e00\u4e2a\u77e9\u5f62\u6807\u7b7e \u65b9\u6cd5: \u5bf9\u591a\u8fb9\u5f62\u6240\u6709\u7684\u70b9x1y1 x2y2... \u83b7\u53d6\u5176\u4e2d\u7684(x_min,y_min)\u548c(x_max,y_max) \u4f5c\u4e3a\u77e9\u5f62label\u7684\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2 Convert 1 segment label to 1 box label, applying inside-image constraint :params segment: \u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e [n, 2] \u4f20\u5165\u8fd9\u4e2a\u591a\u8fb9\u5f62n\u4e2a\u9876\u70b9\u7684\u5750\u6807 :params width: \u8fd9\u4e2a\u591a\u8fb9\u5f62\u6240\u5728\u56fe\u7247\u7684\u5bbd\u5ea6 :params height: \u8fd9\u4e2a\u591a\u8fb9\u5f62\u6240\u5728\u56fe\u7247\u7684\u9ad8\u5ea6 :return \u77e9\u5f62\u6807\u7b7e [1, x_min+y_min+x_max+y_max] \"\"\" # \u5206\u522b\u83b7\u53d6\u5f53\u524d\u591a\u8fb9\u5f62\u4e2d\u6240\u6709\u591a\u8fb9\u5f62\u70b9\u7684x\u548cy\u5750\u6807 x , y = segment . T # segment xy # inside: \u7b5b\u9009\u6761\u4ef6 xy\u5750\u6807\u5fc5\u987b\u5927\u4e8e\u7b49\u4e8e0 x\u5750\u6807\u5fc5\u987b\u5c0f\u4e8e\u7b49\u4e8e\u5bbd\u5ea6 y\u5750\u6807\u5fc5\u987b\u5c0f\u4e8e\u7b49\u4e8e\u9ad8\u5ea6 inside = ( x >= 0 ) & ( y >= 0 ) & ( x <= width ) & ( y <= height ) # \u83b7\u53d6\u7b5b\u9009\u540e\u7684\u6240\u6709\u591a\u8fb9\u5f62\u70b9\u7684x\u548cy\u5750\u6807 x , y , = x [ inside ], y [ inside ] # \u53d6\u5f53\u524d\u591a\u8fb9\u5f62\u4e2dxy\u5750\u6807\u7684\u6700\u5927\u6700\u5c0f\u503c\uff0c\u5f97\u5230\u8fb9\u6846\u7684\u5750\u6807xyxy return np . array ([ x . min (), y . min (), x . max (), y . max ()]) if any ( x ) else np . zeros (( 1 , 4 )) 32. segments2boxes \u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u591a\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e(\u4e0d\u662f\u77e9\u5f62\u6807\u7b7e \u5230\u5e95\u662f\u51e0\u8fb9\u5f62\u672a\u77e5)\u8f6c\u5316\u4e3a\u591a\u4e2a\u77e9\u5f62\u6807\u7b7e\u3002 segments2boxes\u6a21\u5757\u4ee3\u7801: def segments2boxes ( segments ): \"\"\"\u7528\u5728dataloaders.py\u6587\u4ef6\u4e2d\u7684verify_image_label\u51fd\u6570\u4e2d \u5c06\u591a\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e(\u4e0d\u662f\u77e9\u5f62\u6807\u7b7e \u5230\u5e95\u662f\u51e0\u8fb9\u5f62\u672a\u77e5)\u8f6c\u5316\u4e3a\u591a\u4e2a\u77e9\u5f62\u6807\u7b7e Convert segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh) :params segments: [N, cls+x1y1+x2y2 ...] :return [N, cls+xywh] \"\"\" boxes = [] for s in segments : # \u5206\u522b\u83b7\u53d6\u5f53\u524d\u591a\u8fb9\u5f62\u4e2d\u6240\u6709\u591a\u8fb9\u5f62\u70b9\u7684x\u548cy\u5750\u6807 x , y = s . T # \u53d6\u5f53\u524d\u591a\u8fb9\u5f62\u4e2dx\u548cy\u5750\u6807\u7684\u6700\u5927\u6700\u5c0f\u503c\uff0c\u5f97\u5230\u8fb9\u6846\u7684\u5750\u6807xyxy boxes . append ([ x . min (), y . min (), x . max (), y . max ()]) # [N, cls+xywh] return xyxy2xywh ( np . array ( boxes )) \u603b\u7ed3 \u8fd9\u4e2a\u6587\u4ef6\u7684\u4ee3\u7801\u4e3b\u8981\u662f\u4e00\u4e9b\u901a\u7528\u7684\u5de5\u5177\u51fd\u6570\uff0c\u4f1a\u5e7f\u6cdb\u7684\u5728\u6574\u4e2a\u9879\u76ee\u7684\u6587\u4ef6\u4e2d\u4f7f\u7528\uff0c\u6240\u4ee5\u6bd4\u8f83\u91cd\u8981\uff0c\u5e0c\u671b\u5927\u5bb6\u90fd\u53ef\u4ee5\u638c\u63e1\u3002 \u6bd4\u8f83\u91cd\u8981\u7684\u51fd\u6570\u6709\uff1aset_logging\u3001init_seeds\u3001get_latest_run\u3001colorstr\u3001check_git_status\u3001check_requirements\u3001make_divisible\u3001check_file\u3001check_dataset\u3001one_cycle\u3001labels_to_class_weights\u3001labels_to_image_weights\u3001strip_optimizer\u3001print_mutation\u3001save_one_box\u3001increment_path\u3002 \u975e\u5e38\u91cd\u8981\u7684\u6709\uff1aclip_coords\u3001scale_coords\u3001xyxy2xywh\u3001xywh2xyxy\u3001xywhn2xyxy\u3001xyxy2xywhn\u3001xyn2xy\u3001non_max_suppression\u3002 Reference \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011general.py","title":"geneal.py"},{"location":"source_code_interpretation/utils/general_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a utils/general.py \u8fd9\u4e2a\u6587\u4ef6\u662fyolov5\u7684\u901a\u7528\u5de5\u5177\u7c7b\uff0c\u5199\u4e86\u4e00\u4e9b\u901a\u7528\u7684\u5de5\u5177\u51fd\u6570\uff0c\u7528\u7684\u5f88\u5e7f\uff0c\u6574\u4e2a\u9879\u76ee\u54ea\u91cc\u90fd\u53ef\u80fd\u7528\u5230\u3002 \u8fd9\u4e2a\u6587\u4ef6\u7684\u51fd\u6570\u975e\u5e38\u591a\uff0c\u4ee3\u7801\u91cf\u4e5f\u5f88\u5927\uff08\u4e0a\u5343\u884c\u4e86\uff09\uff0c\u4e5f\u90fd\u6bd4\u8f83\u91cd\u8981\uff0c\u5e0c\u671b\u5927\u5bb6\u770b\u7684\u65f6\u5019\u591a\u70b9\u8010\u5fc3\uff0c\u90fd\u80fd\u638c\u63e1\uff01","title":"\u524d\u8a00"},{"location":"source_code_interpretation/utils/general_py.html#1","text":"# import contextlib # python\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668 \u6267\u884cwith\u2026as\u2026\u7684\u65f6\u5019\u8c03\u7528contextlib import glob # \u4ec5\u652f\u6301\u90e8\u5206\u901a\u914d\u7b26\u7684\u6587\u4ef6\u641c\u7d22\u6a21\u5757 import logging # \u65e5\u5fd7\u6a21\u5757 import math # \u6570\u5b66\u516c\u5f0f\u6a21\u5757 import os # \u4e0e\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u7684\u6a21\u5757 import platform # \u63d0\u4f9b\u83b7\u53d6\u64cd\u4f5c\u7cfb\u7edf\u76f8\u5173\u4fe1\u606f\u7684\u6a21\u5757 import random # \u751f\u6210\u968f\u673a\u6570\u7684\u6a21\u5757 import re # \u7528\u6765\u5339\u914d\u5b57\u7b26\u4e32\uff08\u52a8\u6001\u3001\u6a21\u7cca\uff09\u7684\u6a21\u5757 import signal # \u4fe1\u53f7\u5904\u7406\u6a21\u5757 import time # \u65f6\u95f4\u6a21\u5757 \u66f4\u5e95\u5c42 import urllib # \u7528\u4e8e\u64cd\u4f5c\u7f51\u9875URL, \u5e76\u5bf9\u7f51\u9875\u7684\u5185\u5bb9\u8fdb\u884c\u6293\u53d6\u5904\u7406 \u5982urllib.parse: \u89e3\u6790url from itertools import repeat # \u5faa\u73af\u5668\u6a21\u5757 \u521b\u5efa\u4e00\u4e2a\u8fed\u4ee3\u5668\uff0c\u91cd\u590d\u751f\u6210object from multiprocessing.pool import ThreadPool # \u591a\u7ebf\u7a0b\u6a21\u5757 \u7ebf\u7a0b\u6c60 from pathlib import Path # Path\u5c06str\u8f6c\u6362\u4e3aPath\u5bf9\u8c61 \u4f7f\u5b57\u7b26\u4e32\u8def\u5f84\u6613\u4e8e\u64cd\u4f5c\u7684\u6a21\u5757 from subprocess import check_output # \u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u518d\u547d\u4ee4\u884c\u6267\u884c..., \u6700\u540e\u8fd4\u56de\u6267\u884c\u7ed3\u679c(\u6587\u4ef6) from typing import Optional from zipfile import ZipFile import cv2 # opencv\u5e93 import numpy as np # numpy\u77e9\u9635\u5904\u7406\u51fd\u6570\u5e93 import oneflow as flow # OneFlow\u6846\u67b6 import oneflow.backends.cudnn as cudnn import pandas as pd # pandas\u77e9\u9635\u64cd\u4f5c\u6a21\u5757 import pkg_resources as pkg # \u7528\u4e8e\u67e5\u627e, \u81ea\u7701, \u6fc0\u6d3b\u548c\u4f7f\u7528\u5df2\u5b89\u88c5\u7684Python\u53d1\u884c\u7248 import yaml # yaml\u914d\u7f6e\u6587\u4ef6\u8bfb\u5199\u6a21\u5757 from utils.downloads import gsutil_getsize from utils.metrics import box_iou , fitness FILE = Path ( __file__ ) . resolve () ROOT = FILE . parents [ 1 ] # YOLOv5 root directory RANK = int ( os . getenv ( \"RANK\" , - 1 )) # Settings DATASETS_DIR = ROOT . parent / \"datasets\" # YOLOv5 datasets directory # \u786e\u5b9a\u6700\u5927\u7684\u7ebf\u7a0b\u6570 \u8fd9\u91cc\u88ab\u9650\u5236\u5728\u4e868 NUM_THREADS = min ( 8 , max ( 1 , os . cpu_count () - 1 )) # number of YOLOv5 multiprocessing threads AUTOINSTALL = str ( os . getenv ( \"YOLOv5_AUTOINSTALL\" , True )) . lower () == \"true\" # global auto-install mode VERBOSE = str ( os . getenv ( \"YOLOv5_VERBOSE\" , True )) . lower () == \"true\" # global verbose mode FONT = \"Arial.ttf\" # https://ultralytics.com/assets/Arial.ttf # \u8bbe\u7f6e\u8fd0\u884c\u76f8\u5173\u7684\u4e00\u4e9b\u57fa\u672c\u7684\u914d\u7f6e Settings # \u63a7\u5236 print \u6253\u5370 oneflow.tensor \u683c\u5f0f\u8bbe\u7f6e tensor \u7cbe\u5ea6\u4e3a5(\u5c0f\u6570\u70b9\u540e5\u4f4d) \u6bcf\u884c\u5b57\u7b26\u6570\u4e3a320\u4e2a \u663e\u793a\u65b9\u6cd5\u4e3along flow . set_printoptions ( linewidth = 320 , precision = 5 , profile = \"long\" ) # \u63a7\u5236print\u6253\u5370np.array\u683c\u5f0f\u8bbe\u7f6e \u7cbe\u5ea6\u4e3a5 \u6bcf\u884c\u5b57\u7b26\u6570\u4e3a320\u4e2a format short g, %precision=5 np . set_printoptions ( linewidth = 320 , formatter = { \"float_kind\" : \" {:11.5g} \" . format }) # format short g, %precision=5 # pandas\u7684\u6700\u5927\u663e\u793a\u884c\u6570\u662f10 pd . options . display . max_columns = 10 # \u963b\u6b62opencv\u53c2\u4e0e\u591a\u7ebf\u7a0b(\u4e0e Pytorch\u7684 Dataloader\u4e0d\u517c\u5bb9) cv2 . setNumThreads ( 0 ) # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader) os . environ [ \"NUMEXPR_MAX_THREADS\" ] = str ( NUM_THREADS ) # NumExpr max threads os . environ [ \"OMP_NUM_THREADS\" ] = \"1\" if platform . system () == \"darwin\" else str ( NUM_THREADS ) # OpenMP (Pyflow and SciPy)","title":"1. \u5bfc\u5165\u9700\u8981\u7684\u5305\u548c\u57fa\u672c\u914d\u7f6e"},{"location":"source_code_interpretation/utils/general_py.html#2-timeout","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u81ea\u5b9a\u4e49\u7684timeout\u8d85\u65f6\u51fd\u6570\uff0c\u5982\u679c\u67d0\u4e2a\u7a0b\u5e8f\u6267\u884c\u8d85\u65f6\uff0c \u5c31\u4f1a\u89e6\u53d1\u8d85\u65f6\u5904\u7406\u51fd\u6570_timeout_handler \u8fd4\u56de\u8d85\u65f6\u5f02\u5e38\u4fe1\u606f\u3002 \u4f46\u662f\u8fd9\u4e2a\u51fd\u6570\u6ca1\u7528\u5230\uff0c\u4ee3\u7801\u4e2d\u90fd\u662f\u4f7f\u7528\u5e93\u51fd\u6570\u81ea\u5df1\u5b9a\u4e49\u7684timeout\uff0c\u6ca1\u7528\u7528\u8fd9\u4e2a\u81ea\u5b9a\u4e49\u7684timeout\u51fd\u6570\u3002 \u6240\u4ee5\u8fd9\u4e2a\u51fd\u6570\u53ef\u4ee5\u4e86\u89e3\u4e0b\u5c31\u884c\uff0c\u4e0d\u8fc7\u8fd9\u79cd\u8d85\u65f6\u63d0\u793a\u7684\u4ee3\u7801\u8fd8\u662f\u6709\u5fc5\u8981\u5b66\u4e60\u7684\u3002 timeout\u51fd\u6570\u4ee3\u7801\uff1a class timeout ( contextlib . ContextDecorator ): \"\"\"\u6ca1\u7528\u5230 \u4ee3\u7801\u4e2d\u90fd\u662f\u4f7f\u7528\u5e93\u51fd\u6570\u81ea\u5df1\u5b9a\u4e49\u7684timeout \u6ca1\u7528\u7528\u8fd9\u4e2a\u81ea\u5b9a\u4e49\u7684timeout\u51fd\u6570 \u8bbe\u7f6e\u4e00\u4e2a\u8d85\u65f6\u51fd\u6570 \u5982\u679c\u67d0\u4e2a\u7a0b\u5e8f\u6267\u884c\u8d85\u65f6 \u5c31\u4f1a\u89e6\u53d1\u8d85\u65f6\u5904\u7406\u51fd\u6570_timeout_handler \u8fd4\u56de\u8d85\u65f6\u5f02\u5e38\u4fe1\u606f \u5e76\u6ca1\u6709\u7528\u5230 \u8fd9\u91cc\u9762\u7684timeout\u90fd\u662f\u7528python\u5e93\u51fd\u6570\u5b9e\u73b0\u7684 \u5e76\u4e0d\u9700\u8981\u81ea\u5df1\u53e6\u5916\u5199\u4e00\u4e2a \u4f7f\u7528: with timeout(seconds): sleep(10) \u6216\u8005 @timeout(seconds) decorator dealing with wandb login-options timeout issues as well as check_github() timeout issues \"\"\" def __init__ ( self , seconds , * , timeout_msg = '' , suppress_timeout_errors = True ): self . seconds = int ( seconds ) # \u9650\u5236\u65f6\u95f4 self . timeout_message = timeout_msg # \u62a5\u9519\u4fe1\u606f self . suppress = bool ( suppress_timeout_errors ) def _timeout_handler ( self , signum , frame ): # \u8d85\u65f6\u5904\u7406\u51fd\u6570 \u4e00\u65e6\u8d85\u65f6 \u5c31\u5728seconds\u540e\u53d1\u9001\u8d85\u65f6\u4fe1\u606f raise TimeoutError ( self . timeout_message ) def __enter__ ( self ): # signal.signal: \u8bbe\u7f6e\u4fe1\u53f7\u5904\u7406\u7684\u51fd\u6570_timeout_handler # \u6267\u884c\u6d41\u8fdb\u5165with\u4e2d\u4f1a\u6267\u884c__enter__\u65b9\u6cd5 \u5982\u679c\u53d1\u751f\u8d85\u65f6, \u5c31\u4f1a\u89e6\u53d1\u8d85\u65f6\u5904\u7406\u51fd\u6570_timeout_handler \u8fd4\u56de\u8d85\u65f6\u5f02\u5e38\u4fe1\u606f signal . signal ( signal . SIGALRM , self . _timeout_handler ) # Set handler for SIGALRM # signal.alarm: \u8bbe\u7f6e\u53d1\u9001SIGALRM\u4fe1\u53f7\u7684\u5b9a\u65f6\u5668 signal . alarm ( self . seconds ) # start countdown for SIGALRM to be raised def __exit__ ( self , exc_type , exc_val , exc_tb ): # \u6267\u884c\u6d41\u79bb\u5f00 with \u5757\u65f6(\u6ca1\u6709\u53d1\u751f\u8d85\u65f6), \u5219\u8c03\u7528\u8fd9\u4e2a\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u7684__exit__\u65b9\u6cd5\u6765\u6e05\u7406\u6240\u4f7f\u7528\u7684\u8d44\u6e90 signal . alarm ( 0 ) # Cancel SIGALRM if it's scheduled if self . suppress and exc_type is TimeoutError : # Suppress TimeoutError return True","title":"2. timeout\uff08\u6ca1\u7528\u5230\uff09"},{"location":"source_code_interpretation/utils/general_py.html#3set_logginginit_seeds","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u4e00\u4e9b\u521d\u59cb\u5316\u64cd\u4f5c\u3002 set_logging\u662f\u5bf9\u65e5\u5fd7\u7684\u8bbe\u7f6e(format\u3001level)\u7b49\u8fdb\u884c\u521d\u59cb\u5316\uff0cinit_seeds\u662f\u8bbe\u7f6e\u4e00\u7cfb\u5217\u7684\u968f\u673a\u6570\u79cd\u5b50","title":"3.set_logging\u3001init_seeds"},{"location":"source_code_interpretation/utils/general_py.html#31-set_logging","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5bf9\u65e5\u5fd7\u7684\u683c\u5f0f\u3001\u7b49\u7ea7\u7b49\u8fdb\u884c\u4e00\u4e2a\u521d\u59cb\u5316\u3002 def set_logging ( name = None , verbose = VERBOSE ): \"\"\"\u5e7f\u6cdb\u4f7f\u7528\u5728train.py\u3001test.py\u3001detect.py\u7b49\u6587\u4ef6\u7684main\u51fd\u6570\u7684\u7b2c\u4e00\u6b65 \u5bf9\u65e5\u5fd7\u7684\u8bbe\u7f6e(format\u3001level)\u7b49\u8fdb\u884c\u521d\u59cb\u5316 \"\"\" # Sets level and returns logger if is_kaggle (): for h in logging . root . handlers : logging . root . removeHandler ( h ) # remove all handlers associated with the root logger object rank = int ( os . getenv ( \"RANK\" , - 1 )) # rank in world for Multi-GPU trainings' # \u8bbe\u7f6e\u65e5\u5fd7\u7ea7\u522b level = logging . INFO if verbose and rank in { - 1 , 0 } else logging . ERROR log = logging . getLogger ( name ) log . setLevel ( level ) handler = logging . StreamHandler () handler . setFormatter ( logging . Formatter ( \" %(message)s \" )) handler . setLevel ( level ) log . addHandler ( handler )","title":"3.1 set_logging"},{"location":"source_code_interpretation/utils/general_py.html#32-init_seeds","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u4f7f\u7528random.random()\u3001np.random.rand()\u3001init_torch_seeds\uff08\u8c03\u7528torch_utils.py\u4e2d\u7684\u51fd\u6570\uff09 \u7b49\u751f\u6210\u4e00\u7cfb\u5217\u7684\u968f\u673a\u6570\u79cd\u5b50\uff0c\u4ee5\u4fdd\u8bc1\u7ed3\u679c\u7684\u53ef\u590d\u73b0\u6027\u3002 init_seeds\u51fd\u6570\u4ee3\u7801\uff1a def init_seeds ( seed = 0 , deterministic = False ): # Initialize random number generator (RNG) seeds https://pyflow.org/docs/stable/notes/randomness.html # cudnn seed 0 settings are slower and more reproducible, else faster and less reproducible # \u8bbe\u7f6e\u968f\u673a\u6570 \u9488\u5bf9\u4f7f\u7528random.random()\u751f\u6210\u968f\u673a\u6570\u7684\u65f6\u5019\u76f8\u540c random . seed ( seed ) # \u8bbe\u7f6e\u968f\u673a\u6570 \u9488\u5bf9\u4f7f\u7528np.random.rand()\u751f\u6210\u968f\u673a\u6570\u7684\u65f6\u5019\u76f8\u540c np . random . seed ( seed ) # \u4e3aCPU\u8bbe\u7f6e\u79cd\u5b50\u7528\u4e8e\u751f\u6210\u968f\u673a\u6570\u7684\u65f6\u5019\u76f8\u540c \u5e76\u786e\u5b9a\u8bad\u7ec3\u6a21\u5f0f flow . manual_seed ( seed ) cudnn . benchmark , cudnn . deterministic = ( False , True ) flow . cuda . manual_seed ( seed ) flow . cuda . manual_seed_all ( seed ) # for Multi-GPU, exception safe","title":"3.2 init_seeds"},{"location":"source_code_interpretation/utils/general_py.html#4-get_latest_run","text":"\u8fd9\u4e2a\u51fd\u6570\u7684\u4f5c\u7528\u662f\u67e5\u627e\u6700\u8fd1\u4fdd\u5b58\u7684\u6743\u91cd\u6587\u4ef6 last*.pt\uff0c\u7528\u4ee5\u8fdb\u884c\u65ad\u70b9\u7eed\u8bad\u3002 get_latest_run\u51fd\u6570\u4ee3\u7801\uff1a def get_latest_run ( search_dir = \".\" ): # Return path to most recent 'last.pt' in /runs (i.e. to --resume from) \"\"\"\u7528\u5728train.py\u67e5\u627e\u6700\u8fd1\u7684pt\u6587\u4ef6\u8fdb\u884c\u65ad\u70b9\u7eed\u8bad \u7528\u4e8e\u8fd4\u56de\u8be5\u9879\u76ee\u4e2d\u6700\u8fd1\u7684\u6a21\u578b 'last.pt'\u5bf9\u5e94\u7684\u8def\u5f84 :params search_dir: \u8981\u641c\u7d22\u7684\u6587\u4ef6\u7684\u6839\u76ee\u5f55 \u9ed8\u8ba4\u662f '.' \u8868\u793a\u641c\u7d22\u8be5\u9879\u76ee\u4e2d\u7684\u6587\u4ef6 \"\"\" # \u4ecePython\u7248\u672c3.5\u5f00\u59cb, glob\u6a21\u5757\u652f\u6301\u8be5\"**\"\u6307\u4ee4\uff08\u4ec5\u5f53\u4f20\u9012recursive\u6807\u5fd7\u65f6\u624d\u4f1a\u89e3\u6790\u8be5\u6307\u4ee4) # glob.glob\u51fd\u6570\u5339\u914d\u6240\u6709\u7684\u7b26\u5408\u6761\u4ef6\u7684\u6587\u4ef6, \u5e76\u5c06\u5176\u4ee5list\u7684\u5f62\u5f0f\u8fd4\u56de last_list = glob . glob ( f \" { search_dir } /**/last\" , recursive = True ) # os.path.getctime \u8fd4\u56de\u8def\u5f84\u5bf9\u5e94\u6587\u4ef6\u7684\u521b\u5efa\u65f6\u95f4 # \u6240\u4ee5\u8fd9\u91cc\u662f\u8fd4\u56de\u8def\u5f84\u5217\u8868\u4e2d\u521b\u5efa\u65f6\u95f4\u6700\u665a(\u6700\u8fd1\u7684last\u6587\u4ef6)\u7684\u8def\u5f84 return max ( last_list , key = os . path . getctime ) if last_list else \"\" \u51fd\u6570\u5728train.py\u4e2d\u88ab\u8c03\u7528\uff1a","title":"4. get_latest_run"},{"location":"source_code_interpretation/utils/general_py.html#5-is_dockeris_colabis_pip","text":"\u4e0b\u9762\u662f\u4e09\u4e2a\u68c0\u6d4b\u51fd\u6570\uff0cis_docker\u68c0\u6d4b\u5f53\u524d\u73af\u5883\u662f\u5426\u662fdocker\u73af\u5883\uff0c is_colab\u68c0\u67e5\u5f53\u524d\u73af\u5883\u662f\u5426\u662fGoogle Colab\u73af\u5883\uff0cis_pip\u68c0\u6d4b","title":"5. is_docker\u3001is_colab\u3001is_pip"},{"location":"source_code_interpretation/utils/general_py.html#51-is_docker","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u67e5\u8be2\u5f53\u524d\u73af\u5883\u662f\u5426\u662fdocker\u73af\u5883\uff0c\u4f1a\u7528\u5230\u540e\u9762\u7684check_git_status\u548ccheck_imshow\u7b49\u51fd\u6570\u4e2d\u3002 is_docker\u51fd\u6570\u4ee3\u7801\uff1a def is_docker () -> bool : \"\"\" \u5728\u540e\u9762\u7684check_git_status\u548ccheck_imshow\u7b49\u51fd\u6570\u4e2d\u88ab\u8c03\u7528 \u67e5\u8be2\u5f53\u524d\u73af\u5883\u662f\u5426\u662fdocker\u73af\u5883 Is environment a Docker container? Check if the process runs inside a docker container. \"\"\" if Path ( \"/.dockerenv\" ) . exists (): return True try : # check if docker is in control groups with open ( \"/proc/self/cgroup\" ) as file : return any ( \"docker\" in line for line in file ) except OSError : return False","title":"5.1 is_docker"},{"location":"source_code_interpretation/utils/general_py.html#52-is_colab","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u5f53\u524d\u73af\u5883\u662f\u5426\u662fGoogle Colab\u73af\u5883\uff0c\u4f1a\u7528\u5230\u540e\u9762\u7684check_imshow\u51fd\u6570\u4e2d\u3002 is_colab\u51fd\u6570\u4ee3\u7801\uff1a def is_colab (): \"\"\"\u7528\u5230\u540e\u9762\u7684check_imshow\u51fd\u6570\u4e2d \u68c0\u67e5\u5f53\u524d\u73af\u5883\u662f\u5426\u662fGoogle Colab\u73af\u5883 Is environment a Google Colab instance? \"\"\" try : import google.colab return True except Exception as e : return False","title":"5.2 is_colab"},{"location":"source_code_interpretation/utils/general_py.html#53-is_pip","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u6d4b\u5f53\u524d\u6587\u4ef6\u662f\u5426\u5728pip package(site-packages)\u6587\u4ef6\u91cc\uff0c\u4e0d\u8fc7\u8fd9\u4e2a\u51fd\u6570\u6ca1\u7528\u5230\u3002 is_pip\u51fd\u6570\u4ee3\u7801\uff1a def is_pip (): \"\"\"\u6ca1\u7528\u5230 \u5f53\u524d\u6587\u4ef6\u662f\u5426\u5728pip package(site-packages)\u6587\u4ef6\u91cc Is file in a pip package? \"\"\" return 'site-packages' in Path ( __file__ ) . absolute () . parts","title":"5.3 is_pip\uff08\u6ca1\u7528\u5230\uff09"},{"location":"source_code_interpretation/utils/general_py.html#6-file_size","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u8fd4\u56de\u672c\u5730\u6587\u4ef6\u7684\u5927\u5c0f\uff0c \u529f\u80fd\u548c\u4e4b\u524dgoogle_utils.py\u4e2d\u7684gsutil_getsize\u51fd\u6570\uff08\u8fd4\u56de\u7f51\u7ad9\u94fe\u63a5\u5bf9\u5e94\u6587\u4ef6\u7684\u5927\u5c0f\uff09\u5f88\u50cf\u3002 \u4e0d\u8fc7\u8fd9\u4e2a\u51fd\u6570\u5e76\u6ca1\u6709\u7528\u5230\u54e6\uff0c\u968f\u4fbf\u770b\u770b\u5c31\u597d\u3002 def file_size ( path ): # Return file/dir size (MB) \u8fd4\u56de\u672c\u5730\u6587\u4ef6\u7684\u5927\u5c0f(MB) #:params path: \u8981\u67e5\u8be2\u7684\u6587\u4ef6\u5730\u5740 mb = 1 << 20 # bytes to MiB (1024 ** 2) path = Path ( path ) if path . is_file (): return path . stat () . st_size / mb elif path . is_dir (): # .stat(): \u8fd4\u56de\u6587\u4ef6\u76f8\u5173\u72b6\u6001 st_size: \u8fd4\u56de\u6587\u4ef6\u7684\u5927\u5c0f return sum ( f . stat () . st_size for f in path . glob ( \"**/*\" ) if f . is_file ()) / mb else : return 0.0","title":"6. file_size\uff08\u6ca1\u7528\u5230\uff09"},{"location":"source_code_interpretation/utils/general_py.html#7-colorstr","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u8f93\u51fa\u7684\u5f00\u5934\u548c\u7ed3\u5c3e\u52a0\u4e0a\u989c\u8272\uff0c\u4f7f\u547d\u4ee4\u884c\u8f93\u51fa\u663e\u793a\u4f1a\u66f4\u52a0\u597d\u770b\u3002 colorstr\u51fd\u6570\u4ee3\u7801\uff1a def colorstr ( * input ): \"\"\"\u7528\u5230\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570 train.py\u3001test.py\u3001detect.py\u7b49\u6587\u4ef6\u4e2d \u628a\u8f93\u51fa\u7684\u5f00\u5934\u548c\u7ed3\u5c3e\u52a0\u4e0a\u989c\u8272 \u547d\u4ee4\u884c\u8f93\u51fa\u663e\u793a\u4f1a\u66f4\u52a0\u597d\u770b \u5982: colorstr('blue', 'hello world') Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code \"\"\" # \u5982\u679c\u8f93\u5165\u957f\u5ea6\u4e3a1, \u5c31\u662f\u6ca1\u6709\u9009\u62e9\u989c\u8272 \u5219\u9009\u62e9\u9ed8\u8ba4\u989c\u8272\u8bbe\u7f6e blue + bold # args: \u8f93\u5165\u7684\u989c\u8272\u5e8f\u5217 string: \u8f93\u5165\u7684\u5b57\u7b26\u4e32 # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e. colorstr('blue', 'hello world') * args , string = input if len ( input ) > 1 else ( \"blue\" , \"bold\" , input [ 0 ]) # color arguments, string # \u5b9a\u4e49\u4e00\u4e9b\u57fa\u7840\u7684\u989c\u8272 \u548c \u5b57\u4f53\u8bbe\u7f6e colors = { \"black\" : \" \\033 [30m\" , # basic colors \"red\" : \" \\033 [31m\" , \"green\" : \" \\033 [32m\" , \"yellow\" : \" \\033 [33m\" , \"blue\" : \" \\033 [34m\" , \"magenta\" : \" \\033 [35m\" , \"cyan\" : \" \\033 [36m\" , \"white\" : \" \\033 [37m\" , \"bright_black\" : \" \\033 [90m\" , # bright colors \"bright_red\" : \" \\033 [91m\" , \"bright_green\" : \" \\033 [92m\" , \"bright_yellow\" : \" \\033 [93m\" , \"bright_blue\" : \" \\033 [94m\" , \"bright_magenta\" : \" \\033 [95m\" , \"bright_cyan\" : \" \\033 [96m\" , \"bright_white\" : \" \\033 [97m\" , \"end\" : \" \\033 [0m\" , # misc \"bold\" : \" \\033 [1m\" , \"underline\" : \" \\033 [4m\" , } # \u628a\u8f93\u51fa\u7684\u5f00\u5934\u548c\u7ed3\u5c3e\u52a0\u4e0a\u989c\u8272 \u547d\u4ee4\u884c\u8f93\u51fa\u663e\u793a\u4f1a\u66f4\u52a0\u597d\u770b return \"\" . join ( colors [ x ] for x in args ) + f \" { string } \" + colors [ \"end\" ] \u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u5230\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\uff0c \u800c\u4e14\u8fd8\u4f1a\u5e7f\u6cdb\u7528\u5728train.py\u3001val.py\u3001detect.py\u7b49\u5176\u4ed6\u6587\u4ef6\u4e2d\u5982\uff1a \u51fd\u6570\u6548\u679c\u5982\u4e0b\uff08\u53ef\u4ee5\u770b\u5230\u8f93\u51fa\u5f00\u5934\u3001\u7ed3\u5c3e\u53d8\u91cf\u4f7f\u7528\u5176\u4ed6\u989c\u8272\uff09\uff1a","title":"7. colorstr"},{"location":"source_code_interpretation/utils/general_py.html#8-check_online","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u5f53\u524d\u4e3b\u673a\u662f\u5426\u8054\u7f51\u4e86\u3002\u4f1a\u5728\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\u4f7f\u7528\u3002 check_online\u51fd\u6570\u4ee3\u7801: def check_online (): \"\"\"\u5728\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\u4f7f\u7528 \u68c0\u67e5\u5f53\u524d\u4e3b\u673a\u7f51\u7edc\u8fde\u63a5\u662f\u5426\u53ef\u7528 \"\"\" import socket # \u5bfc\u5165socket\u6a21\u5757 \u53ef\u89e3\u51b3\u57fa\u4e8etcp\u548cucp\u534f\u8bae\u7684\u7f51\u7edc\u4f20\u8f93 try : # \u8fde\u63a5\u5230\u4e00\u4e2aip \u5730\u5740addr(\"1.1.1.1\")\u7684TCP\u670d\u52a1\u4e0a, \u7aef\u53e3\u53f7port=443 timeout=5 \u65f6\u96505\u79d2 \u5e76\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u5957\u63a5\u5b57\u5bf9\u8c61 socket . create_connection (( \"1.1.1.1\" , 443 ), 5 ) # check host accessibility # \u6ca1\u53d1\u73b0\u4ec0\u4e48\u5f02\u5e38, \u8fde\u63a5\u6210\u529f, \u6709\u7f51, \u5c31\u8fd4\u56deTrue return True except OSError : # \u8fde\u63a5\u5f02\u5e38, \u6ca1\u7f51, \u8fd4\u56deFalse return False","title":"8. check_online"},{"location":"source_code_interpretation/utils/general_py.html#9emojis","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5ffd\u7565\u6389\u5b57\u7b26\u4e32\u4e2d\u65e0\u6cd5\u7528ascii\u7f16\u7801\u7684\u5185\u5bb9(\u6bd4\u5982\u8868\u60c5\u3001\u56fe\u50cf)\uff0c\u8fd4\u56deWindows\u7cfb\u7edf\u53ef\u4ee5\u5b89\u5168\u3001\u5b8c\u6574\u663e\u793a\u7684\u5b57\u7b26\u4e32\u3002\u4f1a\u5728\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\u4f7f\u7528\u3002 emojis\u51fd\u6570\u4ee3\u7801\uff1a def emojis ( str = '' ): \"\"\"\u5728\u4e0b\u9762\u7684check_git_status\u3001check_requirements\u7b49\u51fd\u6570\u4e2d\u4f7f\u7528 \u8fd4\u56deWindows\u7cfb\u7edf\u53ef\u4ee5\u5b89\u5168\u3001\u5b8c\u6574\u663e\u793a\u7684\u5b57\u7b26\u4e32 Return platform-dependent emoji-safe version of string \"\"\" # \u901a\u8fc7.encode().decode()\u7684\u7ec4\u5408\u5ffd\u7565\u6389\u65e0\u6cd5\u7528ascii\u7f16\u7801\u7684\u5185\u5bb9(\u6bd4\u5982\u8868\u60c5\u3001\u56fe\u50cf) return str . encode () . decode ( 'ascii' , 'ignore' ) if platform . system () == 'Windows' else str","title":"9.emojis"},{"location":"source_code_interpretation/utils/general_py.html#10-check_git_status","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u5f53\u524d\u7684\u4ee3\u7801\u7248\u672c\u662f\u5426\u662f\u6700\u65b0\u7684\u3002\u5982\u679c\u4e0d\u662f\u6700\u65b0\u7684\uff0c\u4f1a\u63d0\u793a\u4f7f\u7528git pull\u547d\u4ee4\u8fdb\u884c\u5347\u7ea7\u3002 \u51fd\u6570\u4ee3\u7801\uff1a @try_except @WorkingDirectory ( ROOT ) def check_git_status ( repo = \"Oneflow-Inc/one-yolo\" ): \"\"\"\u7528\u5728train.py\u7684main\u51fd\u6570\u7684\u4e00\u5f00\u59cb\u90e8\u5206 \u68c0\u67e5\u5f53\u524d\u4ee3\u7801\u7248\u672c\u662f\u5426\u662f\u6700\u65b0\u7684 \u5982\u679c\u4e0d\u662f\u6700\u65b0\u7684 \u4f1a\u63d0\u793a\u4f7f\u7528git pull\u547d\u4ee4\u8fdb\u884c\u5347\u7ea7 \"\"\" # YOLOv5 status check, recommend 'git pull' if code is out of date url = f \"https://github.com/ { repo } \" msg = f \", for updates see { url } \" s = colorstr ( \"github: \" ) # string # \u68c0\u67e5\u7535\u8111\u6709\u6ca1\u6709\u5b89\u88c5git\u4ed3\u5e93 \u6ca1\u6709\u5b89\u88c5\u76f4\u63a5\u62a5\u5f02\u5e38\u5e76\u8f93\u51fa\u5f02\u5e38\u4fe1\u606f assert Path ( \".git\" ) . exists (), s + \"skipping check (not a git repository)\" + msg # \u68c0\u67e5\u4e3b\u673a\u662f\u5426\u8054\u7f51 assert check_online (), s + \"skipping check (offline)\" + msg splits = re . split ( pattern = r \"\\s\" , string = check_output ( \"git remote -v\" , shell = True ) . decode ()) matches = [ repo in s for s in splits ] if any ( matches ): remote = splits [ matches . index ( True ) - 1 ] else : remote = \"Oneflow-Inc\" check_output ( f \"git remote add { remote } { url } \" , shell = True ) check_output ( f \"git fetch { remote } \" , shell = True , timeout = 5 ) # git fetch branch = check_output ( \"git rev-parse --abbrev-ref HEAD\" , shell = True ) . decode () . strip () # checked out n = int ( check_output ( f \"git rev-list { branch } .. { remote } /master --count\" , shell = True )) # commits behind if n > 0 : # \u5982\u679c\u4e0d\u662f\u6700\u65b0 \u63d0\u5347\u5b57\u7b26s: WARNING... pull = \"git pull\" if remote == \"origin\" else f \"git pull { remote } master\" s += f \"\u26a0\ufe0f YOLOv5 is out of date by { n } commit { 's' * ( n > 1 ) } . Use ` { pull } ` or `git clone { url } ` to update.\" else : s += f \"up to date with { url } \u2705\" LOGGER . info ( s ) \u8fd9\u4e2a\u51fd\u6570\u53ea\u7528\u5728train.py\u7684main\u51fd\u6570\u7684\u4e00\u5f00\u59cb\u90e8\u5206\uff1a","title":"10. check_git_status"},{"location":"source_code_interpretation/utils/general_py.html#11-check_pythoncheck_requirements","text":"check_python\u662f\u68c0\u67e5\u5f53\u524d\u7684\u7248\u672c\u53f7\u662f\u5426\u6ee1\u8db3\u6700\u5c0f\u7248\u672c\u53f7minimum\uff0c check_requirements\u662f\u68c0\u67e5\u5df2\u7ecf\u5b89\u88c5\u7684\u5305\u662f\u5426\u6ee1\u8db3requirements\u5bf9\u5e94txt\u6587\u4ef6\u7684\u8981\u6c42\u3002 check_requirements\u4f1a\u8c03\u7528check_python\u3002","title":"11. check_python\u3001check_requirements"},{"location":"source_code_interpretation/utils/general_py.html#111-check_python","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u5f53\u524d\u7684\u7248\u672c\u53f7\u662f\u5426\u6ee1\u8db3\u6700\u5c0f\u7248\u672c\u53f7minimum\u3002 \u4f1a\u5728\u4e0b\u9762\u7684check_requirements\u51fd\u6570\u88ab\u8c03\u7528\u3002 check_python\u51fd\u6570\u4ee3\u7801\uff1a def check_python ( minimum = '3.7.0' ): # Check current python version vs. required python version check_version ( platform . python_version (), minimum , name = 'Python ' , hard = True )","title":"11.1 check_python"},{"location":"source_code_interpretation/utils/general_py.html#112-check_requirements","text":"\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u68c0\u67e5\u5df2\u7ecf\u5b89\u88c5\u7684\u5305\u662f\u5426\u6ee1\u8db3requirements\u5bf9\u5e94txt\u6587\u4ef6\u7684\u8981\u6c42\u3002\u4f1a\u8c03\u7528colorstr\u3001check_python\u3001check_online\u7b49\u51fd\u6570\u3002 check_requirements\u51fd\u6570\u4ee3\u7801\uff1a @TryExcept () def check_requirements ( requirements = ROOT / 'requirements.txt' , exclude = (), install = True , cmds = '' ): \"\"\"\u7528\u5728train.py\u3001test.py\u3001detect.py\u7b49\u6587\u4ef6 \u7528\u4e8e\u68c0\u67e5\u5df2\u7ecf\u5b89\u88c5\u7684\u5305\u662f\u5426\u6ee1\u8db3requirements\u5bf9\u5e94txt\u6587\u4ef6\u7684\u8981\u6c42 Check installed dependencies meet requirements (pass *.txt file or list of packages) \"\"\" # Check installed dependencies meet YOLOv5 requirements (pass *.txt file or list of packages or single package str) # \u7ea2\u8272\u663e\u793arequirements\u5355\u8bcd requirements: prefix = colorstr ( 'red' , 'bold' , 'requirements:' ) # \u68c0\u67e5\u5f53\u524d\u7684python\u7248\u672c\u7b26\u4e0d\u7b26\u5408\u6700\u4f4e\u7248\u672c\u8981\u6c42 check python version check_python () # check python version # \u89e3\u6790requirements.txt\u4e2d\u7684\u6240\u6709\u5305 \u89e3\u6790\u6210list \u91cc\u9762\u5b58\u653e\u7740\u4e00\u4e2a\u4e2a\u7684pkg_resources.Requirement\u7c7b # \u5982: ['matplotlib>=3.2.2', 'numpy>=1.18.5', \u2026\u2026] if isinstance ( requirements , Path ): # requirements.txt file file = requirements . resolve () assert file . exists (), f \" { prefix } { file } not found, check failed.\" with file . open () as f : requirements = [ f ' { x . name }{ x . specifier } ' for x in pkg . parse_requirements ( f ) if x . name not in exclude ] elif isinstance ( requirements , str ): requirements = [ requirements ] s = '' n = 0 # \u7edf\u8ba1\u4e0b\u9762\u7a0b\u5e8f\u66f4\u65b0\u5305\u7684\u4e2a\u6570 number of packages updates # \u4f9d\u6b21\u68c0\u67e5\u73af\u5883\u4e2d\u5b89\u88c5\u7684\u5305(\u53ca\u6bcf\u4e2a\u5305\u5bf9\u5e94\u7684\u4f9d\u8d56\u5305)\u662f\u5426\u6ee1\u8db3requirements\u4e2d\u7684\u6bcf\u4e00\u4e2a\u6700\u4f4e\u8981\u6c42\u5b89\u88c5\u5305 for r in requirements : try : # pkg_resources.require(file) \u8fd4\u56de\u5bf9\u5e94\u5305\u6240\u9700\u7684\u6240\u6709\u4f9d\u8d56\u5305 \u5f53\u8fd9\u4e9b\u5305\u6709\u54ea\u4e2a\u672a\u5b89\u88c5\u6216\u8005\u7248\u672c\u4e0d\u5bf9\u7684\u65f6\u5019\u5c31\u4f1a\u62a5\u9519 pkg . require ( r ) except ( pkg . VersionConflict , pkg . DistributionNotFound ): # exception if requirements not met s += f '\" { r } \" ' n += 1 if s and install and AUTOINSTALL : # check environment variable LOGGER . info ( f \" { prefix } YOLOv5 requirement { 's' * ( n > 1 ) } { s } not found, attempting AutoUpdate...\" ) try : # \u518d\u68c0\u67e5\u5f53\u524d\u4e3b\u673a\u662f\u5426\u8054\u7f51 assert check_online (), \"AutoUpdate skipped (offline)\" # \u6700\u540e\u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b\u518d\u6267\u884cpip\u6307\u4ee4\u5e76\u8fd4\u56de\u6267\u884c\u7ed3\u679c LOGGER . info ( check_output ( f 'pip install { s } { cmds } ' , shell = True ) . decode ()) source = file if 'file' in locals () else requirements s = f \" { prefix } { n } package { 's' * ( n > 1 ) } updated per { source } \\n \" \\ f \" { prefix } \u26a0\ufe0f { colorstr ( 'bold' , 'Restart runtime or rerun command for updates to take effect' ) } \\n \" LOGGER . info ( s ) except Exception as e : LOGGER . warning ( f ' { prefix } \u274c { e } ' ) \u7528\u5728train.py\u4e2d\uff1a val.py \u4e2d\uff1a","title":"11.2 check_requirements"},{"location":"source_code_interpretation/utils/general_py.html#12-make_divisiblecheck_img_size","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u4e3b\u8981\u662f\u7528\u6765\u7ea6\u675f\u56fe\u50cf\u7684\u957f\u6b3e\u6216\u8005feature map\u7684\u957f\u6b3e\uff0c \u5fc5\u987b\u662fdivisor\uff08\u7b49\u4e8e\u7b97\u6cd5\u7684\u6700\u5927\u4e0b\u91c7\u6837\u7387\u4e00\u822c\u662f32\uff09\u7684\u6700\u5c0f\u500d\u6570\u3002","title":"12. make_divisible\u3001check_img_size"},{"location":"source_code_interpretation/utils/general_py.html#121-make_divisible","text":"def make_divisible ( x , divisor ): \"\"\"\u7528\u5728\u4e0b\u9762\u7684make_divisible\u51fd\u6570\u4e2d yolo.py\u7684parse_model\u51fd\u6570\u548ccommom.py\u7684AutoShape\u51fd\u6570\u4e2d \u53d6\u5927\u4e8e\u7b49\u4e8ex\u4e14\u662fdivisor\u7684\u6700\u5c0f\u500d\u6570 Returns x evenly divisible by divisor \"\"\" if isinstance ( divisor , flow . Tensor ): divisor = int ( divisor . max ()) # to int # math.ceil \u5411\u4e0a\u53d6\u6574 return math . ceil ( x / divisor ) * \u8fd9\u4e2a\u51fd\u6570\u7528\u5728\u4e0b\u9762\u7684make_divisible\u51fd\u6570\u4e2d\u53ca yolo.py\u7684parse_model\u51fd\u6570\u548ccommom.py\u7684AutoShape\u51fd\u6570\u4e2d\uff1a","title":"12.1 make_divisible"},{"location":"source_code_interpretation/utils/general_py.html#122-check_img_size","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u4e3a\u4e86\u4fdd\u8bc1img_size\u662f\u80fd\u88abs\uff0832\uff09\u6574\u9664\uff0c\u5982\u679c\u4e0d\u80fd\u5c31\u8fd4\u56de\u5927\u4e8e\u7b49\u4e8eimg_size\u4e14\u662fs\u7684\u6700\u5c0f\u500d\u6570\u3002 \u8fd9\u4e2a\u51fd\u6570\u672c\u8d28\u662f\u901a\u8fc7\u8c03\u7528make_divisible\u51fd\u6570\u5b9e\u73b0\u7684\u3002 check_img_size\u51fd\u6570\u4ee3\u7801\uff1a def check_img_size ( imgsz , s = 32 , floor = 0 ): \"\"\"\u8fd9\u4e2a\u51fd\u6570\u4e3b\u8981\u7528\u4e8etrain.py\u4e2d\u548cdetect.py\u4e2d \u7528\u6765\u68c0\u67e5\u56fe\u7247\u7684\u957f\u5bbd\u662f\u5426\u7b26\u5408\u89c4\u5b9a \u68c0\u67e5img_size\u662f\u5426\u80fd\u88abs\u6574\u9664\uff0c\u8fd9\u91cc\u9ed8\u8ba4s\u4e3a32 \u8fd4\u56de\u5927\u4e8e\u7b49\u4e8eimg_size\u4e14\u662fs\u7684\u6700\u5c0f\u500d\u6570 Verify img_size is a multiple of stride s \"\"\" # Verify image size is a multiple of stride s in each dimension if isinstance ( imgsz , int ): # integer i.e. img_size=640 # \u53d6\u5927\u4e8e\u7b49\u4e8ex\u7684\u6700\u5c0f\u503c\u4e14\u8be5\u503c\u80fd\u88abdivisor\u6574\u9664 new_size = max ( make_divisible ( imgsz , int ( s )), floor ) else : # list i.e. img_size=[640, 480] imgsz = list ( imgsz ) # convert to list if tuple new_size = [ max ( make_divisible ( x , int ( s )), floor ) for x in imgsz ] if new_size != imgsz : LOGGER . warning ( f \"WARNING: --img-size { imgsz } must be multiple of max stride { s } , updating to { new_size } \" ) return new_size \u7528\u6765\u4fdd\u8bc1img\u7684\u957f\u5bbd\u7b26\u5408\u89c4\u5b9a\uff0c\u7528\u5728val.py , detect.py ,train.py\u4e2d\uff1a","title":"12.2 check_img_size"},{"location":"source_code_interpretation/utils/general_py.html#13-check_imshow","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u4e00\u4e0b\u524d\u73af\u5883\u662f\u5426\u53ef\u4ee5\u4f7f\u7528opencv.imshow\u663e\u793a\u56fe\u7247\u3002 def check_imshow (): \"\"\"\u7528\u5728detect.py\u4e2d \u4f7f\u7528webcam\u7684\u65f6\u5019\u8c03\u7528 \u68c0\u67e5\u5f53\u524d\u73af\u5883\u662f\u5426\u53ef\u4ee5\u4f7f\u7528opencv.imshow\u663e\u793a\u56fe\u7247 \u4e3b\u8981\u6709\u4e24\u70b9\u9650\u5236: Docker\u73af\u5883 + Google Colab\u73af\u5883 \"\"\" # Check if environment supports image displays try : assert not is_docker (), \"cv2.imshow() is disabled in Docker environments\" assert not is_colab (), \"cv2.imshow() is disabled in Google Colab environments\" # \u521d\u59cb\u5316\u4e00\u5f20\u56fe\u7247\u68c0\u67e5\u4e0bopencv\u662f\u5426\u53ef\u7528 cv2 . imshow ( \"test\" , np . zeros (( 1 , 1 , 3 ))) cv2 . waitKey ( 1 ) cv2 . destroyAllWindows () cv2 . waitKey ( 1 ) return True except Exception as e : LOGGER . warning ( f \"WARNING: Environment does not support cv2.imshow() or PIL Image.show() image displays \\n { e } \" ) return False \u4f1a\u5728detect.py\u4e2d\u4f7f\u7528webcam\u7684\u65f6\u5019\u8c03\u7528\uff1a","title":"13. check_imshow"},{"location":"source_code_interpretation/utils/general_py.html#14-check_file","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u672c\u90fd\u76f8\u5173\u6587\u4ef6\u8def\u5f84\u80fd\u5426\u627e\u5230\u8fd9\u4e2a\u6587\u4ef6\uff0c\u6ca1\u627e\u5230\u5c31\u8bf4\u660e\u6587\u4ef6\u4e22\u5931\u4e86\uff0c \u8fd4\u56de\u7a7a\uff1b \u5982\u679c\u4f20\u5165\u7684\u662f\u4e00\u4e2a\u7f51\u7edc\u5730\u5740\u5c31\u76f4\u63a5\u4e0b\u8f7d\u8fd9\u4e2a\u6587\u4ef6\uff1b \u5426\u5219\u627e\u5230\u5c31\u8fd4\u56de\u672c\u5730\u5339\u914d\u5230\u7684\u7b2c\u4e00\u4e2a\u6587\u4ef6\u540d\u3002\u8fd9\u4e2a\u51fd\u6570\u5f88\u6709\u7528\uff0c\u7528\u7684\u5f88\u5e7f\u3002 def check_file ( file , suffix = \"\" ): \"\"\"\u7528\u5728train.py\u548ctest.py\u6587\u4ef6\u4e2d \u68c0\u67e5\u672c\u5730\u6709\u6ca1\u6709\u8fd9\u4e2a\u6587\u4ef6 \u68c0\u67e5\u76f8\u5173\u6587\u4ef6\u8def\u5f84\u80fd\u5426\u627e\u5230\u6587\u4ef6 \u5e76\u8fd4\u56de\u6587\u4ef6\u540d Search/download file (if necessary) and return path \"\"\" # Search/download file (if necessary) and return path check_suffix ( file , suffix ) # optional file = str ( file ) # convert to str() # \u5982\u679c\u4f20\u8fdb\u6765\u7684\u662f\u6587\u4ef6\u6216\u8005\u662f\u2019\u2018, \u76f4\u63a5\u8fd4\u56de\u6587\u4ef6\u540dstr if Path ( file ) . is_file () or not file : # exists return file # \u5982\u679c\u4f20\u8fdb\u6765\u7684\u4ee5 'http:/' \u6216\u8005 'https:/' \u5f00\u5934\u7684url\u5730\u5740, \u5c31\u4e0b\u8f7d elif file . startswith (( \"http:/\" , \"https:/\" )): # download url = file # warning: Pathlib turns :// -> :/ file = Path ( urllib . parse . unquote ( file ) . split ( \"?\" )[ 0 ]) . name # '%2F' to '/', split https://url.com/file.txt?auth if Path ( file ) . is_file (): LOGGER . info ( f \"Found { url } locally at { file } \" ) # file already exists else : LOGGER . info ( f \"Downloading { url } to { file } ...\" ) # \u4f7f\u7528flow.hub.download_url_to_file\u4eceurl\u5730\u5740\u4e0a\u4e2d\u4e0b\u8f7d\u6587\u4ef6\u540d\u4e3afile\u7684\u6587\u4ef6 flow . hub . download_url_to_file ( url , file ) # \u68c0\u67e5\u662f\u5426\u4e0b\u8f7d\u6210\u529f assert Path ( file ) . exists () and Path ( file ) . stat () . st_size > 0 , f \"File download failed: { url } \" # check # \u8fd4\u56de\u4e0b\u8f7d\u7684\u6587\u4ef6\u540d return file elif file . startswith ( \"clearml://\" ): # ClearML Dataset ID assert \"clearml\" in sys . modules , \"ClearML is not installed, so cannot use ClearML dataset. Try running 'pip install clearml'.\" return file else : # search files = [] for d in \"data\" , \"models\" , \"utils\" : # search directories files . extend ( glob . glob ( str ( ROOT / d / \"**\" / file ), recursive = True )) # find file assert len ( files ), f \"File not found: { file } \" # assert file was found assert len ( files ) == 1 , f \"Multiple files match ' { file } ', specify exact path: { files } \" # assert unique # \u8fd4\u56de\u7b2c\u4e00\u4e2a\u5339\u914d\u5230\u7684\u6587\u4ef6\u540d return files [ 0 ] # return file \u5728train.py\u4e2d\u4f7f\u7528\uff08\u68c0\u67e5\u672c\u5730data\u3001cfg\u3001hyp\u7b49\u6587\u4ef6\u662f\u5426\u5b58\u5728\uff09 \u5728test.py\u4e2d\u4f7f\u7528\uff08\u68c0\u67e5\u672c\u5730data\u6587\u4ef6\u662f\u5426\u5b58\u5728\uff09","title":"14. check_file"},{"location":"source_code_interpretation/utils/general_py.html#15-check_dataset","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u68c0\u67e5\u672c\u5730\u662f\u5426\u6709\u6307\u5b9a\u7684\u6570\u636e\u96c6\uff0c\u6ca1\u7528\u5c31\u4ecetorch\u5e93\u4e2d\u4e0b\u8f7d\u5e76\u89e3\u538b\u6570\u636e\u96c6\u3002 check_dataset\u51fd\u6570\u4ee3\u7801: def check_dataset ( data , autodownload = True ): # Download, check and/or unzip dataset if not found locally \"\"\"\u7528\u5728train.py\u548cdetect.py\u4e2d \u68c0\u67e5\u672c\u5730\u6709\u6ca1\u6709\u6570\u636e\u96c6 \u68c0\u67e5\u6570\u636e\u96c6 \u5982\u679c\u672c\u5730\u6ca1\u6709\u5219\u4eceone-yolov5\u5e93\u4e2d\u4e0b\u8f7d\u5e76\u89e3\u538b\u6570\u636e\u96c6 :params data: \u662f\u4e00\u4e2a\u89e3\u6790\u8fc7\u7684data_dict len=7 \u4f8b\u5982: ['path'='../datasets/coco128', 'train','val', 'test', 'nc', 'names', 'download'] :params autodownload: \u5982\u679c\u672c\u5730\u6ca1\u6709\u6570\u636e\u96c6\u662f\u5426\u9700\u8981\u76f4\u63a5\u4eceone-yolov5\u5e93\u4e2d\u4e0b\u8f7d\u6570\u636e\u96c6 \u9ed8\u8ba4True \"\"\" # Download (optional) extract_dir = \"\" if isinstance ( data , ( str , Path )) and str ( data ) . endswith ( \".zip\" ): # i.e. gs://bucket/dir/coco128.zip download ( data , dir = DATASETS_DIR , unzip = True , delete = False , curl = False , threads = 1 ) data = next (( DATASETS_DIR / Path ( data ) . stem ) . rglob ( \"*.yaml\" )) extract_dir , autodownload = data . parent , False # Read yaml (optional) if isinstance ( data , ( str , Path )): with open ( data , errors = \"ignore\" ) as f : data = yaml . safe_load ( f ) # dictionary # Checks for k in \"train\" , \"val\" , \"nc\" : assert k in data , f \"data.yaml ' { k } :' field missing \u274c\" if \"names\" not in data : LOGGER . warning ( \"data.yaml 'names:' field missing \u26a0\ufe0f, assigning default names 'class0', 'class1', etc.\" ) data [ \"names\" ] = [ f \"class { i } \" for i in range ( data [ \"nc\" ])] # default names # Resolve paths path = Path ( extract_dir or data . get ( \"path\" ) or \"\" ) # optional 'path' default to '.' if not path . is_absolute (): path = ( ROOT / path ) . resolve () for k in \"train\" , \"val\" , \"test\" : if data . get ( k ): # prepend path data [ k ] = str ( path / data [ k ]) if isinstance ( data [ k ], str ) else [ str ( path / x ) for x in data [ k ]] # Parse yaml train , val , test , s = ( data . get ( x ) for x in ( \"train\" , \"val\" , \"test\" , \"download\" )) if val : # path.resolve() \u8be5\u65b9\u6cd5\u5c06\u4e00\u4e9b\u7684 \u8def\u5f84/\u8def\u5f84\u6bb5 \u89e3\u6790\u4e3a\u7edd\u5bf9\u8def\u5f84 # val: [WindowsPath('E:/yolo_v5/datasets/coco128/images/train2017')] val = [ Path ( x ) . resolve () for x in ( val if isinstance ( val , list ) else [ val ])] # val path # \u5982\u679cval\u4e0d\u5b58\u5728 \u8bf4\u660e\u672c\u5730\u4e0d\u5b58\u5728\u6570\u636e\u96c6 if not all ( x . exists () for x in val ): LOGGER . info ( \" \\n Dataset not found \u26a0\ufe0f, missing paths %s \" % [ str ( x ) for x in val if not x . exists ()]) if not s or not autodownload : raise Exception ( \"Dataset not found \u274c\" ) t = time . time () root = path . parent if \"path\" in data else \"..\" # unzip directory i.e. '../' if s . startswith ( \"http\" ) and s . endswith ( \".zip\" ): # URL f = Path ( s ) . name # filename LOGGER . info ( f \"Downloading { s } to { f } ...\" ) flow . hub . download_url_to_file ( s , f ) Path ( root ) . mkdir ( parents = True , exist_ok = True ) # create root ZipFile ( f ) . extractall ( path = root ) # unzip Path ( f ) . unlink () # remove zip r = None # success # \u5982\u679c\u4e0b\u8f7d\u5730\u5740s\u662fbash\u5f00\u5934\u5c31\u4f7f\u7528bash\u6307\u4ee4\u4e0b\u8f7d\u6570\u636e\u96c6 elif s . startswith ( \"bash \" ): # bash script LOGGER . info ( f \"Running { s } ...\" ) # \u4f7f\u7528bash\u547d\u4ee4\u4e0b\u8f7d r = os . system ( s ) # \u5426\u5219\u4e0b\u8f7d\u5730\u5740\u5c31\u662f\u4e00\u4e2apython\u811a\u672c \u6267\u884cpython\u811a\u672c\u4e0b\u8f7d\u6570\u636e\u96c6 else : # python script r = exec ( s , { \"yaml\" : data }) # return None dt = f \"( { round ( time . time () - t , 1 ) } s)\" s = f \"success \u2705 { dt } , saved to { colorstr ( 'bold' , root ) } \" if r in ( 0 , None ) else f \"failure { dt } \u274c\" LOGGER . info ( f \"Dataset download { s } \" ) check_font ( \"Arial.ttf\" if is_ascii ( data [ \"names\" ]) else \"Arial.Unicode.ttf\" , progress = True ) # download fonts return data # dictionary","title":"15. check_dataset"},{"location":"source_code_interpretation/utils/general_py.html#16-download","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06url\u4e2d\u7684\u6587\u4ef6\u4e0b\u8f7d\u4e0b\u6765\uff0c\u518d\u89e3\u538b\u3002\u4f46\u662f\u8fd9\u4e2a\u6587\u4ef6\u5e76\u6ca1\u6709\u5728\u7a0b\u5e8f\u4e2d\u88ab\u8c03\u7528\uff0c flow.hub.download_url_to_file\u7cfb\u7edf\u51fd\u6570\u548cgoogle_utils.py \u4e2d\u7684attempt_download\u51fd\u6570\u8fdb\u884c\u4e0b\u8f7d\u6587\u4ef6\u3002\u6240\u4ee5\uff0c\u8fd9\u4e2a\u51fd\u6570\u968f\u4fbf\u770b\u770b\u5c31\u597d\u3002 def download ( url , dir = \".\" , unzip = True , delete = True , curl = False , threads = 1 , retry = 3 ): # Multi-threaded file download and unzip function, used in data.yaml for autodownload \"\"\"\u5728coco.yaml\u4e2d\u4e0b\u8f7d\u6570\u636e\u96c6 Multi-threaded file download and unzip function :params url: \u4e0b\u8f7d\u6587\u4ef6\u7684url\u5730\u5740 :params dir: \u4e0b\u8f7d\u4e0b\u6765\u6587\u4ef6\u4fdd\u5b58\u7684\u76ee\u5f55 :params unzip: \u4e0b\u8f7d\u540e\u6587\u4ef6\u662f\u5426\u9700\u8981\u89e3\u538b :params delete: \u89e3\u538b\u540e\u539f\u6587\u4ef6(\u672a\u89e3\u538b)\u662f\u5426\u9700\u8981\u5220\u9664 :params curl: \u662f\u5426\u4f7f\u7528cmd curl\u8bed\u53e5\u4e0b\u8f7d\u6587\u4ef6 False\u5c31\u4f7f\u7528torch.hub\u4e0b\u8f7d :params threads: \u4e0b\u8f7d\u4e00\u4e2a\u6587\u4ef6\u9700\u8981\u7684\u7ebf\u7a0b\u6570 \"\"\" def download_one ( url , dir ): \"\"\" Download 1 file :params url: \u6587\u4ef6\u4e0b\u8f7d\u5730\u5740 Path(url).name=\u6587\u4ef6\u540d :params dir: \u6587\u4ef6\u4fdd\u5b58\u7684\u76ee\u5f55 \"\"\" # Download 1 file success = True f = dir / Path ( url ) . name # filename if Path ( url ) . is_file (): # exists in current path Path ( url ) . rename ( f ) # move to dir # \u8fd9\u4e2a\u76ee\u5f55\u4e0b\u4e0d\u5b58\u5728\u8fd9\u4e2a\u6587\u4ef6 \u5c31\u76f4\u63a5\u4e0b\u8f7d elif not f . exists (): LOGGER . info ( f \"Downloading { url } to { f } ...\" ) for i in range ( retry + 1 ): if curl : s = \"sS\" if threads > 1 else \"\" # silent r = os . system ( f 'curl - { s } L \" { url } \" -o \" { f } \" --retry 9 -C -' ) # curl download with retry, continue success = r == 0 else : flow . hub . download_url_to_file ( url , f , progress = threads == 1 ) # torch download success = f . is_file () if success : break elif i < retry : LOGGER . warning ( f \"Download failure, retrying { i + 1 } / { retry } { url } ...\" ) else : LOGGER . warning ( f \"Failed to download { url } ...\" ) # \u5982\u679c\u9700\u8981\u89e3\u538b \u4e14\u4e0b\u8f7d\u7684\u6587\u4ef6\u540e\u7f00\u662f '.zip' \u6216 '.gz' if unzip and success and f . suffix in ( \".zip\" , \".gz\" ): LOGGER . info ( f \"Unzipping { f } ...\" ) if f . suffix == \".zip\" : ZipFile ( f ) . extractall ( path = dir ) # unzip elif f . suffix == \".gz\" : os . system ( f \"tar xfz { f } --directory { f . parent } \" ) # unzip # \u89e3\u538b\u540e\u662f\u5426\u9700\u8981\u5220\u9664\u672a\u89e3\u538b\u7684\u6587\u4ef6 if delete : f . unlink () # remove zip dir = Path ( dir ) dir . mkdir ( parents = True , exist_ok = True ) # make directory if threads > 1 : # \u4f7f\u7528\u7ebf\u7a0b\u6c60 # \u5b9a\u4e49\u4e86\u4e00\u4e2a\u7ebf\u7a0b\u6c60, \u6700\u591a\u521b\u5efathreads\u4e2a\u7ebf\u7a0b pool = ThreadPool ( threads ) # \u8fdb\u7a0b\u6c60\u4e2d\u7684\u8be5\u65b9\u6cd5\u4f1a\u5c06 iterable \u53c2\u6570\u4f20\u5165\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\u5206\u6210 chunksize \u4efd\u4f20\u9012\u7ed9\u4e0d\u540c\u7684\u8fdb\u7a0b\u6765\u5904\u7406\u3002 pool . imap ( lambda x : download_one ( * x ), zip ( url , repeat ( dir ))) # multi-threaded pool . close () pool . join () else : for u in [ url ] if isinstance ( url , ( str , Path )) else url : download_one ( u , dir )","title":"16. download"},{"location":"source_code_interpretation/utils/general_py.html#17-clean_str","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u5b57\u7b26\u4e32\u4e2d\u4e00\u4e9b\u5947\u602a\u7684\u7b26\u53f7 \u201c|@#!\u00a1\u00b7$\u20ac%&()=?\u00bf^*;:,\u00a8\u00b4><+\u201d \u6362\u6210\u4e0b\u5212\u7ebf \u2018_\u2019\u3002 def clean_str ( s ): \"\"\"\u5728datasets.py\u4e2d\u7684LoadStreams\u7c7b\u4e2d\u88ab\u8c03\u7528 \u5b57\u7b26\u4e32s\u91cc\u5728pattern\u4e2d\u5b57\u7b26\u66ff\u6362\u4e3a\u4e0b\u5212\u7ebf_ \u6ce8\u610fpattern\u4e2d[]\u4e0d\u80fd\u7701 Cleans a string by replacing special characters with underscore _ \"\"\" # re: \u7528\u6765\u5339\u914d\u5b57\u7b26\u4e32\uff08\u52a8\u6001\u3001\u6a21\u7cca\uff09\u7684\u6a21\u5757 \u6b63\u5219\u8868\u8fbe\u5f0f\u6a21\u5757 # pattern: \u8868\u793a\u6b63\u5219\u4e2d\u7684\u6a21\u5f0f\u5b57\u7b26\u4e32 repl: \u5c31\u662freplacement\u7684\u5b57\u7b26\u4e32 string: \u8981\u88ab\u5904\u7406, \u8981\u88ab\u66ff\u6362\u7684\u90a3\u4e2astring\u5b57\u7b26\u4e32 # \u6240\u4ee5\u8fd9\u53e5\u8bdd\u6267\u884c\u7684\u662f\u5c06\u5b57\u7b26\u4e32s\u91cc\u5728pattern\u4e2d\u7684\u5b57\u7b26\u4e32\u66ff\u6362\u4e3a \"_\" # Cleans a string by replacing special characters with underscore _ return re . sub ( pattern = \"[|@#!\u00a1\u00b7$\u20ac%&()=?\u00bf^*;:,\u00a8\u00b4><+]\" , repl = \"_\" , string = s ) \u53ea\u7528\u5728datasets.py\u4e2d\u7684LoadStreams\u7c7b\u4e2d\uff1a","title":"17. clean_str"},{"location":"source_code_interpretation/utils/general_py.html#18-one_cycle","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u5b66\u4e60\u7387\u8870\u51cf\u7b56\u7565\u3002\u6765\u81ea\u8fd9\u7bc7\u8bba\u6587\uff1a one_cycle . \u611f\u5174\u8da3\u7684 \u670b\u53cb\u53ef\u4ee5\u8bfb\u4e00\u8bfb\u3002 def one_cycle ( y1 = 0.0 , y2 = 1.0 , steps = 100 ): \"\"\"\u7528\u5728train.py\u7684\u5b66\u4e60\u7387\u8870\u51cf\u7b56\u7565\u6a21\u5757 one_cycle lr lr\u5148\u589e\u52a0, \u518d\u51cf\u5c11, \u518d\u4ee5\u66f4\u5c0f\u7684\u659c\u7387\u51cf\u5c11 \u8bba\u6587: https://arxiv.org/pdf/1803.09820.pdf \"\"\" # lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf return lambda x : (( 1 - math . cos ( x * math . pi / steps )) / 2 ) * ( y2 - y1 ) + y1 \u4e00\u822c\u4f7f\u7528one_cycle\u7684\u6548\u679c\u4f1a\u6bd4\u8f83\u597d\u3002","title":"18. one_cycle"},{"location":"source_code_interpretation/utils/general_py.html#19-labels_to_class_weights-labels_to_image_weights","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u8054\u5408\u4f7f\u7528\u7684\u3002 \u6700\u7ec8\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u5728\u6570\u636e\u96c6\u4e2d\u91c7\u6837\u7684\u65f6\u5019\uff0c\u4e0d\u4f7f\u7528\u968f\u673a\u91c7\u6837\uff0c\u800c\u662f\u4f7f\u7528\u66f4\u52a0\u79d1\u5b66\u7684\u6309\u56fe\u7247\u6743\u91cd\u8fdb\u884c\u91c7\u6837\u3002 \u7b2c\u4e00\u4e2a\u51fd\u6570labels_to_class_weights\u662f\u4e3a\u4e86\u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6240\u6709\u7c7b\u522b\u7684\u6743\u91cd\uff08\u9891\u7387\u5927\u7684\u6743\u91cd\u5c0f\uff09\u3002 \u7b2c\u4e8c\u4e2a\u51fd\u6570labels_to_image_weights\u662f\u5229\u7528labels_to_class_weights\u51fd\u6570\u5f97\u5230\u7684\u7c7b\u522b\u6743\u91cd\u5f97\u5230\u6bcf\u5f20\u56fe\u7247\u5bf9\u5e94\u7684\u4e00\u4e2a\u6743\u91cd\u3002 \u7136\u540e\u5229\u7528\u6bcf\u5f20\u56fe\u7247\u7684\u6743\u91cd\u5728\u5f53\u524dbatch\u8fdb\u884c\u91c7\u6837\uff0c\u8fd9\u6837\u7684\u91c7\u6837\u65b9\u5f0f\u4f1a\u66f4\u52a0\u79d1\u5b66\u70b9\u3002 \u4e24\u4e2a\u51fd\u6570\u90fd\u53ea\u5728train.py\u4e2d\u4f7f\u7528\uff0c\u4e14\u662f\u540c\u65f6\u4f7f\u7528\u7684\u5982\u56fe\uff1a","title":"19. labels_to_class_weights &amp; labels_to_image_weights"},{"location":"source_code_interpretation/utils/general_py.html#191-labels_to_class_weights","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u4ece\u8bad\u7ec3(gt)\u6807\u7b7e\u83b7\u5f97\u6bcf\u4e2a\u7c7b\u7684\u6743\u91cd \uff0c\u6807\u7b7e\u9891\u7387\u9ad8\u7684\u7c7b\u6743\u91cd\u4f4e\u3002 labels_to_class_weights\u51fd\u6570\u4ee3\u7801\uff1a def labels_to_class_weights ( labels , nc = 80 ): \"\"\"\u7528\u5728train.py\u4e2d \u5f97\u5230\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd \u6807\u7b7e\u9891\u7387\u9ad8\u7684\u7c7b\u6743\u91cd\u4f4e \u4ece\u8bad\u7ec3(gt)\u6807\u7b7e\u83b7\u5f97\u6bcf\u4e2a\u7c7b\u7684\u6743\u91cd \u6807\u7b7e\u9891\u7387\u9ad8\u7684\u7c7b\u6743\u91cd\u4f4e Get class weights (inverse frequency) from training labels :params labels: gt\u6846\u7684\u6240\u6709\u771f\u5b9e\u6807\u7b7elabels :params nc: \u6570\u636e\u96c6\u7684\u7c7b\u522b\u6570 :return torch.from_numpy(weights): \u6bcf\u4e00\u4e2a\u7c7b\u522b\u6839\u636elabels\u5f97\u5230\u7684\u5360\u6bd4(\u6b21\u6570\u8d8a\u591a\u6743\u91cd\u8d8a\u5c0f) tensor \"\"\" if labels [ 0 ] is None : # no labels loaded return flow . Tensor () labels = np . concatenate ( labels , 0 ) # labels.shape = (866643, 5) for COCO # classes: \u6240\u6709\u6807\u7b7e\u5bf9\u5e94\u7684\u7c7b\u522blabels labels[:, 0]: \u7c7b\u522b .astype(np.int): \u53d6\u6574 classes = labels [:, 0 ] . astype ( np . int ) # labels = [labels_num, class+xywh] # weight: \u8fd4\u56de\u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570 [1, nc] weights = np . bincount ( classes , minlength = nc ) # occurrences per class # Prepend gridpoint count (for uCE training) # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum() # gridpoints per image # weights = np.hstack([gpi * len(labels) - weights.sum() * 9, weights * 9]) ** 0.5 # prepend gridpoints to start # \u5c06\u51fa\u73b0\u6b21\u6570\u4e3a0\u7684\u7c7b\u522b\u6743\u91cd\u5168\u90e8\u53d61 replace empty bins with 1 weights [ weights == 0 ] = 1 # \u5176\u4ed6\u6240\u6709\u7684\u7c7b\u522b\u7684\u6743\u91cd\u5168\u90e8\u53d6\u6b21\u6570\u7684\u5012\u6570 number of targets per class weights = 1 / weights # normalize \u6c42\u51fa\u6bcf\u4e00\u7c7b\u522b\u7684\u5360\u6bd4 weights /= weights . sum () return flow . from_numpy ( weights ) # numpy -> tensor","title":"19.1  labels_to_class_weights"},{"location":"source_code_interpretation/utils/general_py.html#192-labels_to_image_weights","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5229\u7528\u6bcf\u5f20\u56fe\u7247\u771f\u5b9egt\u6846\u7684\u771f\u5b9e\u6807\u7b7elabels\u548c\u4e0a\u4e00\u6b65labels_to_class_weights\u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd\u5f97\u5230\u6570\u636e\u96c6\u4e2d\u6bcf\u5f20\u56fe\u7247\u5bf9\u5e94\u7684\u6743\u91cd\u3002 labels_to_image_weights\u51fd\u6570\u4ee3\u7801\uff1a def labels_to_image_weights ( labels , nc = 80 , class_weights = np . ones ( 80 )): \"\"\"\u7528\u5728train.py\u4e2d \u5229\u7528\u4e0a\u9762\u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd\u5f97\u5230\u6bcf\u4e00\u5f20\u56fe\u7247\u7684\u6743\u91cd \u518d\u5bf9\u56fe\u7247\u8fdb\u884c\u6309\u6743\u91cd\u8fdb\u884c\u91c7\u6837 \u901a\u8fc7\u6bcf\u5f20\u56fe\u7247\u771f\u5b9egt\u6846\u7684\u771f\u5b9e\u6807\u7b7elabels\u548c\u4e0a\u4e00\u6b65labels_to_class_weights\u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd\u8fdb\u884c\u91c7\u6837 Produces image weights based on class_weights and image contents :params labels: \u6bcf\u5f20\u56fe\u7247\u771f\u5b9egt\u6846\u7684\u771f\u5b9e\u6807\u7b7e :params nc: \u6570\u636e\u96c6\u7684\u7c7b\u522b\u6570 \u9ed8\u8ba480 :params class_weights: [80] \u4e0a\u4e00\u6b65labels_to_class_weights\u5f97\u5230\u7684\u6bcf\u4e2a\u7c7b\u522b\u7684\u6743\u91cd \"\"\" # class_counts: \u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570 [num_labels, nc] \u6bcf\u4e00\u884c\u662f\u5f53\u524d\u8fd9\u5f20\u56fe\u7247\u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570 num_labels=\u56fe\u7247\u6570\u91cf=label\u6570\u91cf class_counts = np . array ([ np . bincount ( x [:, 0 ] . astype ( np . int ), minlength = nc ) for x in labels ]) # [80] -> [1, 80] # \u6574\u4e2a\u6570\u636e\u96c6\u7684\u6bcf\u4e2a\u7c7b\u522b\u6743\u91cd[1, 80] * \u6bcf\u5f20\u56fe\u7247\u7684\u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570[num_labels, 80] = \u5f97\u5230\u6bcf\u4e00\u5f20\u56fe\u7247\u6bcf\u4e2a\u7c7b\u5bf9\u5e94\u7684\u6743\u91cd[num_labels, 80] # \u53e6\u5916\u6ce8\u610f: \u8fd9\u91cc\u4e0d\u662f\u77e9\u9635\u76f8\u4e58, \u662f\u5143\u7d20\u76f8\u4e58 [1, 80] \u548c\u6bcf\u4e00\u884c\u56fe\u7247\u7684\u6bcf\u4e2a\u7c7b\u522b\u51fa\u73b0\u7684\u6b21\u6570 [1, 80] \u5206\u522b\u6309\u5143\u7d20\u76f8\u4e58 # \u518dsum(1): \u6309\u884c\u76f8\u52a0 \u5f97\u5230\u6700\u7ec8image_weights: \u5f97\u5230\u6bcf\u4e00\u5f20\u56fe\u7247\u5bf9\u5e94\u7684\u91c7\u6837\u6743\u91cd[num_labels] return ( class_weights . reshape ( 1 , nc ) * class_counts ) . sum ( 1 )","title":"19.2 labels_to_image_weights"},{"location":"source_code_interpretation/utils/general_py.html#20-coco80_to_coco91_class","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c0680\u4e2a\u7c7b\u7684coco\u7d22\u5f15\u6362\u621091\u7c7b\u7684coco\u7d22\u5f15\u3002 coco80_to_coco91_class\u51fd\u6570\u4ee3\u7801: def coco80_to_coco91_class (): \"\"\"\u7528\u5728test.py\u4e2d \u4ece80\u7c7b\u6620\u5c04\u523091\u7c7b\u7684coco\u7d22\u5f15 \u53d6\u5f97\u5bf9\u5e94\u7684class id \u5c0680\u4e2a\u7c7b\u7684coco\u7d22\u5f15\u6362\u621091\u7c7b\u7684coco\u7d22\u5f15 :return x: \u4e3a80\u7c7b\u7684\u6bcf\u4e00\u7c7b\u572891\u7c7b\u4e2d\u7684\u4f4d\u7f6e \"\"\" # converts 80-index (val2014) to 91-index (paper) # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/ # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n') # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n') # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)] # darknet to coco # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)] # coco to darknet x = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 27 , 28 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 63 , 64 , 65 , 67 , 70 , 72 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 84 , 85 , 86 , 87 , 88 , 89 , 90 ] return x \u5728 val.py \u4e2d\u4f7f\u7528\uff1a","title":"20. coco80_to_coco91_class"},{"location":"source_code_interpretation/utils/general_py.html#21-clip_coords","text":"\u8fd9\u4e2a\u51fd\u6570\u7684\u4f5c\u7528\u662f\uff1a \u5c06boxes\u7684\u5750\u6807(x1y1x2y2 \u5de6\u4e0a\u89d2\u53f3\u4e0b\u89d2)\u9650\u5b9a\u5728\u56fe\u50cf\u7684\u5c3a\u5bf8(img_shape hw)\u5185\uff0c\u9632\u6b62\u51fa\u754c\u3002 \u8fd9\u4e2a\u51fd\u6570\u4f1a\u7528\u5728\u4e0b\u9762\u7684xyxy2xywhn\u3001save_one_boxd\u7b49\u51fd\u6570\u4e2d\uff0c\u5f88\u91cd\u8981\uff0c\u5fc5\u987b\u638c\u63e1\u3002 clip_coords\u51fd\u6570\u4ee3\u7801\uff1a def clip_coords ( boxes , shape ): \"\"\"\u7528\u5728\u4e0b\u9762\u7684xyxy2xywhn\u3001save_one_boxd\u7b49\u51fd\u6570\u4e2d \u5c06boxes\u7684\u5750\u6807(x1y1x2y2 \u5de6\u4e0a\u89d2\u53f3\u4e0b\u89d2)\u9650\u5b9a\u5728\u56fe\u50cf\u7684\u5c3a\u5bf8\u5185 Clip bounding x1y1x2y2 bounding boxes to image shape (height, width) \"\"\" # Clip bounding xyxy bounding boxes to image shape (height, width) if isinstance ( boxes , flow . Tensor ): # faster individually boxes [:, 0 ] . clamp_ ( 0 , shape [ 1 ]) # x1 boxes [:, 1 ] . clamp_ ( 0 , shape [ 0 ]) # y1 boxes [:, 2 ] . clamp_ ( 0 , shape [ 1 ]) # x2 boxes [:, 3 ] . clamp_ ( 0 , shape [ 0 ]) # y2 else : # np.array (faster grouped) boxes [:, [ 0 , 2 ]] = boxes [:, [ 0 , 2 ]] . clip ( 0 , shape [ 1 ]) # x1, x2 boxes [:, [ 1 , 3 ]] = boxes [:, [ 1 , 3 ]] . clip ( 0 , shape [ 0 ]) # y1, y2","title":"21. clip_coords"},{"location":"source_code_interpretation/utils/general_py.html#22-scale_coords","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u5750\u6807coords(x1y1x2y2)\u4eceimg1_shape\u5c3a\u5bf8\u7f29\u653e\u5230img0_shape\u5c3a\u5bf8\u3002 x\u7684\u6b63\u5750\u6807\u662f\u5411\u53f3\uff0cy\u7684\u6b63\u5750\u6807\u662f\u5411\u4e0b\u3002\u8fd9\u4e2a\u51fd\u6570\u4e5f\u662f\u5f88\u91cd\u8981\u7684\u3002 scale_coords\u51fd\u6570\u4ee3\u7801\uff1a def scale_coords ( img1_shape , coords , img0_shape , ratio_pad = None ): \"\"\"\u7528\u5728detect.py\u548cval.py\u4e2d \u5c06\u9884\u6d4b\u5750\u6807\u4ecefeature map\u6620\u5c04\u56deimg0 \u5c06\u5750\u6807coords(x1y1x2y2)\u4eceimg1_shape\u7f29\u653e\u5230img0_shape\u5c3a\u5bf8 Rescale coords (xyxy) from img1_shape to img0_shape :params img1_shape: coords\u76f8\u5bf9\u4e8e\u7684shape\u5927\u5c0f :params coords: \u8981\u8fdb\u884c\u7f29\u653e\u7684box\u5750\u6807\u4fe1\u606f x1y1x2y2 \u5de6\u4e0a\u89d2 + \u53f3\u4e0b\u89d2 :params img0_shape: \u8981\u5c06coords\u7f29\u653e\u5230\u76f8\u5bf9\u7684\u76ee\u6807shape\u5927\u5c0f :params ratio_pad: \u7f29\u653e\u6bd4\u4f8bgain\u548cpad\u503c None\u5c31\u5148\u8ba1\u7b97gain\u548cpad\u503c\u518dpad+scale \u4e0d\u4e3a\u7a7a\u5c31\u76f4\u63a5pad+scale \"\"\" # ratio_pad\u4e3a\u7a7a\u5c31\u5148\u7b97\u653e\u7f29\u6bd4\u4f8bgain\u548cpad\u503c calculate from img0_shape if ratio_pad is None : # gain = old / new \u53d6\u9ad8\u5bbd\u7f29\u653e\u6bd4\u4f8b\u4e2d\u8f83\u5c0f\u7684,\u4e4b\u540e\u8fd8\u53ef\u4ee5\u518dpad \u5982\u679c\u76f4\u63a5\u53d6\u5927\u7684, \u88c1\u526a\u5c31\u53ef\u80fd\u51cf\u53bb\u76ee\u6807 gain = min ( img1_shape [ 0 ] / img0_shape [ 0 ], img1_shape [ 1 ] / img0_shape [ 1 ]) # wh padding wh\u4e2d\u6709\u4e00\u4e2a\u4e3a0 \u4e3b\u8981\u662fpad\u53e6\u4e00\u4e2a pad = ( img1_shape [ 1 ] - img0_shape [ 1 ] * gain ) / 2 , ( img1_shape [ 0 ] - img0_shape [ 0 ] * gain ) / 2 else : gain = ratio_pad [ 0 ][ 0 ] # \u6307\u5b9a\u6bd4\u4f8b pad = ratio_pad [ 1 ] # \u6307\u5b9apad\u503c # \u56e0\u4e3apad = img1_shape - img0_shape \u6240\u4ee5\u8981\u628a\u5c3a\u5bf8\u4eceimg1 -> img0 \u5c31\u540c\u6837\u4e5f\u9700\u8981\u51cf\u53bbpad # \u5982\u679cimg1_shape>img0_shape pad>0 coords\u4ece\u5927\u5c3a\u5bf8\u7f29\u653e\u5230\u5c0f\u5c3a\u5bf8 \u51cf\u53bbpad \u7b26\u5408 # \u5982\u679cimg1_shape<img0_shape pad<0 coords\u4ece\u5c0f\u5c3a\u5bf8\u7f29\u653e\u5230\u5927\u5c3a\u5bf8 \u51cf\u53bbpad \u7b26\u5408 coords [:, [ 0 , 2 ]] -= pad [ 0 ] # x padding coords [:, [ 1 , 3 ]] -= pad [ 1 ] # y padding # \u7f29\u653escale coords [:, : 4 ] /= gain # \u9632\u6b62\u653e\u7f29\u540e\u7684\u5750\u6807\u8fc7\u754c \u8fb9\u754c\u5904\u76f4\u63a5\u526a\u5207 clip_coords ( coords , img0_shape ) return coords","title":"22. scale_coords"},{"location":"source_code_interpretation/utils/general_py.html#23-xyxy2xywh-xywh2xyxy","text":"\u8fd9\u4e24\u4e2a\u51fd\u6570\u662f\u4e24\u4e2a\u76f8\u53cd\u7684\u8fc7\u7a0b\u3002 xyxy2xywh\u662f\u5c06\u9884\u6d4b\u4fe1\u606fxyxy\u683c\u5f0f\u8f6c\u5316\u4e3axywh\u7684\u683c\u5f0f\uff0c\u800cxywh2xyxy\u662f\u5c06\u9884\u6d4b\u4fe1\u606fxywh\u683c\u5f0f\u8f6c\u5316\u4e3axyxy\u7684\u683c\u5f0f\u3002 \u8fd9\u4e24\u4e2a\u51fd\u6570\u7684\u4ee3\u7801\u5f88\u91cd\u8981\uff0c\u4e00\u5b9a\u8981\u638c\u63e1\u3002 \u4ee3\u7801\u8fd8\u662f\u90a3\u53e5\u8bdd\uff1ax\u7684\u6b63\u5750\u6807\u662f\u5411\u53f3\uff0cy\u7684\u6b63\u5750\u6807\u662f\u5411\u4e0b\u3002","title":"23. xyxy2xywh &amp; xywh2xyxy"},{"location":"source_code_interpretation/utils/general_py.html#231-xyxy2xywh","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u9884\u6d4b\u4fe1\u606fxyxy\u683c\u5f0f\u8f6c\u5316\u4e3axywh\u7684\u683c\u5f0f\u3002 xyxy2xywh\u51fd\u6570\u4ee3\u7801\uff1a def xyxy2xywh ( x ): \"\"\"\"\u7528\u5728detect.py\u548ctest.py\u4e2d \u64cd\u4f5c\u6700\u540e, \u5c06\u9884\u6d4b\u4fe1\u606f\u4ecexyxy\u683c\u5f0f\u8f6c\u4e3axywh\u683c\u5f0f \u518d\u4fdd\u5b58 Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] where x1y1=top-left, x2y2=bottom-right :params x: [n, x1y1x2y2] (x1, y1): \u5de6\u4e0a\u89d2 (x2, y2): \u53f3\u4e0b\u89d2 :return y: [n, xywh] (x, y): \u4e2d\u5fc3\u70b9 wh: \u5bbd\u9ad8 \"\"\" y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = ( x [:, 0 ] + x [:, 2 ]) / 2 # x center y [:, 1 ] = ( x [:, 1 ] + x [:, 3 ]) / 2 # y center y [:, 2 ] = x [:, 2 ] - x [:, 0 ] # width y [:, 3 ] = x [:, 3 ] - x [:, 1 ] # height return y \u5728detect.py\u4e2d\u4f7f\u7528\uff1a # Write results for *xyxy, conf, cls in reversed(det): if save_txt: # Write to file xywh = (xyxy2xywh(flow.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist() # normalized xywh","title":"23.1 xyxy2xywh"},{"location":"source_code_interpretation/utils/general_py.html#232-xywh2xyxy","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u9884\u6d4b\u4fe1\u606fxywh\u683c\u5f0f\u8f6c\u5316\u4e3axyxy\u7684\u683c\u5f0f\u3002 xywh2xyxy\u51fd\u6570\u4ee3\u7801\uff1a def xywh2xyxy ( x ): \"\"\"\u7528\u5728val.py\u4e2d \u64cd\u4f5c\u4e4b\u524d \u8f6c\u4e3axyxy\u624d\u53ef\u4ee5\u8fdb\u884c\u64cd\u4f5c \u6ce8\u610f: x\u7684\u6b63\u65b9\u5411\u4e3a\u53f3\u9762 y\u7684\u6b63\u65b9\u5411\u4e3a\u4e0b\u9762 Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where x1y1=top-left, x2y2=bottom-right :params x: [n, xywh] (x, y): :return y: [n, x1y1x2y2] (x1, y1): \u5de6\u4e0a\u89d2 (x2, y2): \u53f3\u4e0b\u89d2 \"\"\" y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = x [:, 0 ] - x [:, 2 ] / 2 # top left x y [:, 1 ] = x [:, 1 ] - x [:, 3 ] / 2 # top left y y [:, 2 ] = x [:, 0 ] + x [:, 2 ] / 2 # bottom right x y [:, 3 ] = x [:, 1 ] + x [:, 3 ] / 2 # bottom right y return y","title":"23.2 xywh2xyxy"},{"location":"source_code_interpretation/utils/general_py.html#24-xywhn2xyxy-xyxy2xywhn-xyn2xy","text":"\u8fd9\u4e09\u4e2a\u51fd\u6570\u4e3b\u8981\u7528\u4e8edataloaders.py\u6587\u4ef6\u4e2d\u3002\u4e3b\u8981\u662f\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e00\u4e9b\u53d8\u6362\u64cd\u4f5c\u3002 xywhn2xyxy\u662f\u5c06xywh(normalized) -> x1y1x2y2\u3002xyxy2xywhn\u662f\u5c06x1y1x2y2 -> xywh(normalized)\u3002 xyn2xy\u662f\u5c06xy(normalized) -> xy\u3002\u8fd9\u4e09\u4e2a\u51fd\u6570\u4e5f\u662f\u6bd4\u8f83\u91cd\u8981\u7684\uff0c\u5927\u5bb6\u5fc5\u987b\u638c\u63e1\u3002","title":"24. xywhn2xyxy &amp; xyxy2xywhn &amp; xyn2xy"},{"location":"source_code_interpretation/utils/general_py.html#241-xywhn2xyxy","text":"\u8fd9\u4e2a\u51fd\u6570\u662fxywh(normalized) -> x1y1x2y2\u3002 xywhn2xyxy\u51fd\u6570\u4ee3\u7801: def xywhn2xyxy ( x , w = 640 , h = 640 , padw = 0 , padh = 0 ): \"\"\"\u7528\u5728dataloaders.py\u7684 LoadImagesAndLabels\u7c7b\u7684__getitem__\u51fd\u6570\u3001load_mosaic\u3001load_mosaic9\u7b49\u51fd\u6570\u4e2d \u5c06xywh(normalized) -> x1y1x2y2 (x, y): \u4e2d\u95f4\u70b9 wh: \u5bbd\u9ad8 (x1, y1): \u5de6\u4e0a\u70b9 (x2, y2): \u53f3\u4e0b\u70b9 Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right \"\"\" y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = w * ( x [:, 0 ] - x [:, 2 ] / 2 ) + padw # top left x y [:, 1 ] = h * ( x [:, 1 ] - x [:, 3 ] / 2 ) + padh # top left y y [:, 2 ] = w * ( x [:, 0 ] + x [:, 2 ] / 2 ) + padw # bottom right x y [:, 3 ] = h * ( x [:, 1 ] + x [:, 3 ] / 2 ) + padh # bottom right y return y","title":"24.1 xywhn2xyxy"},{"location":"source_code_interpretation/utils/general_py.html#242-xyxy2xywhn","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06x1y1x2y2 -> xywh(normalized)\u3002 xyxy2xywhn\u51fd\u6570\u4ee3\u7801\uff1a def xyxy2xywhn ( x , w = 640 , h = 640 , clip = False , eps = 0.0 ): \"\"\"\u7528\u5728dataloaders.py\u7684 LoadImagesAndLabels\u7c7b\u7684__getitem__\u51fd\u6570\u4e2d \u5c06 x1y1x2y2 -> xywh(normalized) (x1, y1): \u5de6\u4e0a\u70b9 (x2, y2): \u53f3\u4e0b\u70b9 (x, y): \u4e2d\u95f4\u70b9 wh: \u5bbd\u9ad8 Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right \"\"\" # Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right if clip : clip_coords ( x , ( h - eps , w - eps )) # warning: inplace clip y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = (( x [:, 0 ] + x [:, 2 ]) / 2 ) / w # x center y [:, 1 ] = (( x [:, 1 ] + x [:, 3 ]) / 2 ) / h # y center y [:, 2 ] = ( x [:, 2 ] - x [:, 0 ]) / w # width y [:, 3 ] = ( x [:, 3 ] - x [:, 1 ]) / h # height return y","title":"24.2 xyxy2xywhn"},{"location":"source_code_interpretation/utils/general_py.html#243-xyn2xy","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06xy(normalized) -> xy\u3002 xyn2xy\u51fd\u6570\u4ee3\u7801\uff1a def xyn2xy ( x , w = 640 , h = 640 , padw = 0 , padh = 0 ): \"\"\"\u7528\u5728dataloaders.py\u7684load_mosaic\u548cload_mosaic9\u51fd\u6570\u4e2d xy(normalized) -> xy Convert normalized segments into pixel segments, shape (n,2) \"\"\" # Convert normalized segments into pixel segments, shape (n,2) y = x . clone () if isinstance ( x , flow . Tensor ) else np . copy ( x ) y [:, 0 ] = w * x [:, 0 ] + padw # top left x y [:, 1 ] = h * x [:, 1 ] + padh # top left y return","title":"24.3 xyn2xy"},{"location":"source_code_interpretation/utils/general_py.html#25-non_max_suppression","text":"NMS(\u975e\u6781\u5927\u503c\u6291\u5236)\uff0c\u8fd9\u4e2a\u51fd\u6570\u76f8\u4fe1\u5927\u5bb6\u90fd\u5df2\u7ecf\u5f88\u719f\u6089\u4e86\uff0c\u8fd9\u662f\u76ee\u6807\u68c0\u6d4b\u6700\u57fa\u672c\u7684\u64cd\u4f5c\u4e4b\u4e00\u4e86\u3002 \u53ef\u4ee5\u8bf4\u8fd9\u4e2a\u51fd\u6570\u662f\u8fd9\u7bc7\u535a\u5ba2\u5f53\u4e2d\u6700\u91cd\u8981\u7684\u4ee3\u7801\u4e5f\u4e0d\u4e3a\u8fc7\uff0c\u6240\u4ee5\u5927\u5bb6\u4e00\u5b9a\u8981\u638c\u63e1\u8fd9\u4e2a\u51fd\u6570\uff08\u6d41\u7a0b\u539f\u7406+\u4ee3\u7801\uff09\u3002 \u66f4\u591a\u5173\u4e8enms\u8bf7\u53c2\u9605\uff1a \u300anms\u300b non_max_suppression\u51fd\u6570\u4ee3\u7801\uff1a def non_max_suppression ( prediction , # [batch, num_anchors(3\u4e2ayolo\u9884\u6d4b\u5c42), (x+y+w+h+1+num_classes)] = [1, 18900, 25] # 3\u4e2aanchor\u7684\u9884\u6d4b\u7ed3\u679c\u603b\u548c conf_thres = 0.25 , # \u5148\u8fdb\u884c\u4e00\u8f6e\u7b5b\u9009\uff0c\u5c06\u5206\u6570\u8fc7\u4f4e\u7684\u9884\u6d4b\u6846\uff08<conf_thres\uff09\u5220\u9664\uff08\u5206\u6570\u7f6e0\uff09 iou_thres = 0.45 , # iou\u9608\u503c, \u5982\u679c\u5176\u4f59\u9884\u6d4b\u6846\u4e0etarget\u7684iou>iou_thres, \u5c31\u5c06\u90a3\u4e2a\u9884\u6d4b\u6846\u7f6e0 classes = None , # \u662f\u5426nms\u540e\u53ea\u4fdd\u7559\u7279\u5b9a\u7684\u7c7b\u522b \u9ed8\u8ba4\u4e3aNone agnostic = False , # \u8fdb\u884cnms\u662f\u5426\u4e5f\u53bb\u9664\u4e0d\u540c\u7c7b\u522b\u4e4b\u95f4\u7684\u6846 \u9ed8\u8ba4False multi_label = False , # \u662f\u5426\u662f\u591a\u6807\u7b7e nc>1 \u4e00\u822c\u662fTrue labels = (), # \u6807\u7b7e max_det = 300 , # \u6bcf\u5f20\u56fe\u7247\u7684\u6700\u5927\u76ee\u6807\u4e2a\u6570 \u9ed8\u8ba41000 ): \"\"\"Non-Maximum Suppression (NMS) on inference results to reject overlapping bounding boxes Returns: list of detections, on (n,6) tensor per image [xyxy, conf, cls] \"\"\" if isinstance ( prediction , ( list , tuple )): # YOLOv5 model in validation model, output = (inference_out, loss_out) prediction = prediction [ 0 ] # select only inference output # Settings \u8bbe\u7f6e\u4e00\u4e9b\u53d8\u91cf bs = prediction . shape [ 0 ] # batch size nc = prediction . shape [ 2 ] - 5 # number of classes xc = prediction [ ... , 4 ] > conf_thres # candidates # Checks assert 0 <= conf_thres <= 1 , f \"Invalid Confidence threshold { conf_thres } , valid values are between 0.0 and 1.0\" assert 0 <= iou_thres <= 1 , f \"Invalid IoU { iou_thres } , valid values are between 0.0 and 1.0\" # Settings # min_wh = 2 # (pixels) minimum box width and height # (pixels) \u9884\u6d4b\u7269\u4f53\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5927\u5c0f\u8303\u56f4 [min_wh, max_wh] max_wh = 7680 # (pixels) maximum box width and height # \u6bcf\u4e2a\u56fe\u50cf\u6700\u591a\u68c0\u6d4b\u7269\u4f53\u7684\u4e2a\u6570 maximum number of boxes into torchvision.ops.nms() max_nms = 30000 # maximum number of boxes into flow.nms() # nms\u6267\u884c\u65f6\u95f4\u9608\u503c \u8d85\u8fc7\u8fd9\u4e2a\u65f6\u95f4\u5c31\u9000\u51fa\u4e86 seconds to quit after time_limit = 0.3 + 0.03 * bs # seconds to quit after # \u662f\u5426\u9700\u8981\u5197\u4f59\u7684detections require redundant detections redundant = True # require redundant detections multi_label &= nc > 1 # multiple labels per box (adds 0.5ms/img) merge = False # use merge-NMS t = time . time () # \u8bb0\u5f55\u5f53\u524d\u65f6\u523b\u65f6\u95f4 output = [ flow . zeros (( 0 , 6 ), device = prediction . device )] * bs for xi , x in enumerate ( prediction ): # image index, image inference # Apply constraints # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0 # width-height x = x [ xc [ xi ]] # confidence # {list: bs} \u7b2c\u4e00\u5f20\u56fe\u7247\u7684target[17, 5] \u7b2c\u4e8c\u5f20[1, 5] \u7b2c\u4e09\u5f20[7, 5] \u7b2c\u56db\u5f20[6, 5] # Cat apriori labels if autolabelling \u81ea\u52a8\u6807\u6ce8label\u65f6\u8c03\u7528 \u4e00\u822c\u4e0d\u7528 # \u81ea\u52a8\u6807\u8bb0\u5728\u975e\u5e38\u9ad8\u7684\u7f6e\u4fe1\u9608\u503c\uff08\u5373 0.90 \u7f6e\u4fe1\u5ea6\uff09\u4e0b\u6548\u679c\u6700\u4f73,\u800c mAP \u8ba1\u7b97\u4f9d\u8d56\u4e8e\u975e\u5e38\u4f4e\u7684\u7f6e\u4fe1\u9608\u503c\uff08\u5373 0.001\uff09\u6765\u6b63\u786e\u8bc4\u4f30 PR \u66f2\u7ebf\u4e0b\u7684\u533a\u57df\u3002 # \u8fd9\u4e2a\u81ea\u52a8\u6807\u6ce8\u6211\u89c9\u5f97\u5e94\u8be5\u662f\u4e00\u4e2a\u7c7b\u4f3cRNN\u91cc\u9762\u7684Teacher Forcing\u7684\u8bad\u7ec3\u673a\u5236 \u5c31\u662f\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u8ddf\u7740\u8001\u5e08(ground truth)\u8d70 # \u4f46\u662f\u8fd9\u6837\u53c8\u4f1a\u9020\u6210\u4e00\u4e2a\u95ee\u9898: \u4e00\u76f4\u9760\u8001\u5e08\u5e26\u7684\u5b69\u5b50\u662f\u8d70\u4e0d\u8fdc\u7684 \u8fd9\u6837\u7684\u6a21\u578b\u56e0\u4e3a\u4f9d\u8d56\u6807\u7b7e\u6570\u636e,\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d,\u6a21\u578b\u4f1a\u6709\u8f83\u597d\u7684\u6548\u679c # \u4f46\u662f\u5728\u6d4b\u8bd5\u7684\u65f6\u5019\u56e0\u4e3a\u4e0d\u80fd\u5f97\u5230ground truth\u7684\u652f\u6301, \u6240\u4ee5\u5982\u679c\u76ee\u524d\u751f\u6210\u7684\u5e8f\u5217\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6709\u5f88\u5927\u4e0d\u540c, \u6a21\u578b\u5c31\u4f1a\u53d8\u5f97\u8106\u5f31\u3002 # \u6240\u4ee5\u4e2a\u4eba\u8ba4\u4e3a(\u4e2a\u4eba\u89c2\u70b9): \u5e94\u8be5\u5728\u4e0b\u9762\u4f7f\u7528\u7684\u65f6\u5019\u6709\u9009\u62e9\u7684\u5f00\u542f\u8fd9\u4e2atrick \u6bd4\u5982\u8bbe\u7f6e\u4e00\u4e2a\u6982\u7387p\u968f\u673a\u5f00\u542f \u6216\u8005\u5728\u8bad\u7ec3\u7684\u524dn\u4e2aepoch\u4f7f\u7528 \u540e\u9762\u518d\u5173\u95ed # Cat apriori labels if autolabelling if labels and len ( labels [ xi ]): lb = labels [ xi ] v = flow . zeros (( len ( lb ), nc + 5 ), device = x . device ) v [:, : 4 ] = lb [:, 1 : 5 ] # box v [:, 4 ] = 1.0 # conf v [ range ( len ( lb )), lb [:, 0 ] . long () + 5 ] = 1.0 # cls x = flow . cat (( x , v ), 0 ) # If none remain process next image # \u7ecf\u8fc7\u524d\u4e24\u5c42\u8fc7\u6ee4\u540e\u5982\u679c\u8be5feature map\u6ca1\u6709\u76ee\u6807\u6846\u4e86\uff0c\u5c31\u7ed3\u675f\u8fd9\u8f6e\u76f4\u63a5\u8fdb\u884c\u4e0b\u4e00\u5f20\u56fe if not x . shape [ 0 ]: continue # Compute conf \u8ba1\u7b97conf_score x [:, 5 :] *= x [:, 4 : 5 ] # conf = obj_conf * cls_conf # Box (center x, center y, width, height) to (x1, y1, x2, y2) \u5de6\u4e0a\u89d2 \u53f3\u4e0b\u89d2 [59, 4] box = xywh2xyxy ( x [:, : 4 ]) # Detections matrix nx6 (xyxy, conf, cls) if multi_label : # \u7b2c\u4e09\u8f6e\u8fc7\u6ee4:\u9488\u5bf9\u6bcf\u4e2a\u7c7b\u522bscore(obj_conf * cls_conf) > conf_thres [59, 6] -> [51, 6] # \u8fd9\u91cc\u4e00\u4e2a\u6846\u662f\u6709\u53ef\u80fd\u6709\u591a\u4e2a\u7269\u4f53\u7684\uff0c\u6240\u4ee5\u8981\u7b5b\u9009 # nonzero: \u83b7\u5f97\u77e9\u9635\u4e2d\u7684\u975e0(True)\u6570\u636e\u7684\u4e0b\u6807 a.t(): \u5c06a\u77e9\u9635\u62c6\u5f00 # i: \u4e0b\u6807 [43] j: \u7c7b\u522bindex [43] \u8fc7\u6ee4\u4e86\u4e24\u4e2ascore\u592a\u4f4e\u7684 i , j = ( x [:, 5 :] > conf_thres ) . nonzero ( as_tuple = False ) . T x = flow . cat (( box [ i ], x [ i , j + 5 , None ], j [:, None ] . float ()), 1 ) else : # best class only conf , j = x [:, 5 :] . max ( 1 , keepdim = True ) # \u4e00\u4e2a\u7c7b\u522b\u76f4\u63a5\u53d6\u5206\u6570\u6700\u5927\u7c7b\u7684\u5373\u53ef x = flow . cat (( box , conf , j . float ()), 1 )[ conf . view ( - 1 ) > conf_thres ] # Filter by class \u662f\u5426\u53ea\u4fdd\u7559\u7279\u5b9a\u7684\u7c7b\u522b \u9ed8\u8ba4None \u4e0d\u6267\u884c\u8fd9\u91cc if classes is not None : x = x [( x [:, 5 : 6 ] == flow . tensor ( classes , device = x . device )) . any ( 1 )] # Apply finite constraint # if not flow.isfinite(x).all(): # x = x[flow.isfinite(x).all(1)] # Check shape n = x . shape [ 0 ] # number of boxes if not n : # no boxes \u5982\u679c\u7ecf\u8fc7\u7b2c\u4e09\u8f6e\u8fc7\u6ee4\u8be5feature map\u6ca1\u6709\u76ee\u6807\u6846\u4e86\uff0c\u5c31\u7ed3\u675f\u8fd9\u8f6e\u76f4\u63a5\u8fdb\u884c\u4e0b\u4e00\u5f20\u56fe continue elif n > max_nms : # excess boxes \u5982\u679c\u7ecf\u8fc7\u7b2c\u4e09\u8f6e\u8fc7\u6ee4\u8be5feature map\u8fd8\u8981\u5f88\u591a\u6846(>max_nms) \u5c31\u9700\u8981\u6392\u5e8f x = x [ x [:, 4 ] . argsort ( descending = True )[: max_nms ]] # sort by confidence # Batched NMS # \u7b2c4\u8f6e\u8fc7\u6ee4 Batched NMS [51, 6] -> [5, 6] c = x [:, 5 : 6 ] * ( 0 if agnostic else max_wh ) # classes # \u505a\u4e2a\u5207\u7247 \u5f97\u5230boxes\u548cscores \u4e0d\u540c\u7c7b\u522b\u7684box\u4f4d\u7f6e\u4fe1\u606f\u52a0\u4e0a\u4e00\u4e2a\u5f88\u5927\u7684\u6570\u4f46\u53c8\u4e0d\u540c\u7684\u6570c # \u8fd9\u6837\u4f5c\u975e\u6781\u5927\u6291\u5236\u7684\u65f6\u5019\u4e0d\u540c\u7c7b\u522b\u7684\u6846\u5c31\u4e0d\u4f1a\u63ba\u548c\u5230\u4e00\u5757\u4e86 \u8fd9\u662f\u4e00\u4e2a\u4f5cnms\u633a\u5de7\u5999\u7684\u6280\u5de7 boxes , scores = x [:, : 4 ] + c , x [:, 4 ] # boxes (offset by class), scores # \u8fd4\u56denms\u8fc7\u6ee4\u540e\u7684bounding box(boxes)\u7684\u7d22\u5f15\uff08\u964d\u5e8f\u6392\u5217\uff09 # i = torchvision.ops.nms(boxes, scores, iou_thres) # NMS i = flow . nms ( boxes , scores , iou_thres ) # NMS if i . shape [ 0 ] > max_det : # limit detections i = i [: max_det ] if merge and ( 1 < n < 3e3 ): # Merge NMS (boxes merged using weighted mean) # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4) iou = box_iou ( boxes [ i ], boxes ) > iou_thres # iou matrix weights = iou * scores [ None ] # box weights # bounding box\u5408\u5e76 \u5176\u5b9e\u5c31\u662f\u628a\u6743\u91cd\u548c\u6846\u76f8\u4e58\u518d\u9664\u4ee5\u6743\u91cd\u4e4b\u548c x [ i , : 4 ] = flow . mm ( weights , x [:, : 4 ]) . float () / weights . sum ( 1 , keepdim = True ) # merged boxes if redundant : i = i [ iou . sum ( 1 ) > 1 ] # require redundancy output [ xi ] = x [ i ] # \u6700\u7ec8\u8f93\u51fa [5, 6] # \u770b\u4e0b\u65f6\u95f4\u8d85\u6ca1\u8d85\u65f6 \u8d85\u65f6\u6ca1\u505a\u5b8c\u7684\u5c31\u4e0d\u505a\u4e86 if ( time . time () - t ) > time_limit : LOGGER . warning ( f \"WARNING: NMS time limit { time_limit : .3f } s exceeded\" ) break # time limit exceeded return output \u8fd9\u4e2a\u51fd\u6570\u4e00\u822c\u4f1a\u7528\u5728detect.py\u6216\u8005val.py\u7684\u6a21\u578b\u524d\u5411\u63a8\u7406\u7ed3\u675f\u4e4b\u540e\u3002 \u66f4\u591a\u5173\u4e8eNMS\u51fd\u6570\u6d41\u7a0b\u548c\u4ee3\u7801\uff1a \u3010YOLO-V3-SPP \u6e90\u7801\u89e3\u8bfb\u3011\u4e09\u3001\u9884\u6d4b\u6a21\u5757.","title":"25. non_max_suppression"},{"location":"source_code_interpretation/utils/general_py.html#26-strip_optimizer","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5728\u6a21\u578b\u8bad\u7ec3\u5b8c\u540e, strip_optimizer\u51fd\u6570\u5c06optimizer\u3001training_results\u3001updates\u2026 \u4ece\u4fdd\u5b58\u7684\u6a21\u578b\u6587\u4ef6ckpt\u4e2d\u5220\u9664\u3002 strip_optimizer\u51fd\u6570\u4ee3\u7801\uff1a def strip_optimizer ( f = \"best\" , s = \"\" ): # from utils.general import *; strip_optimizer() \"\"\"\u7528\u5728train.py\u6a21\u578b\u8bad\u7ec3\u5b8c\u540e \u5c06optimizer\u3001training_results\u3001updates...\u4ece\u4fdd\u5b58\u7684\u6a21\u578b\u6587\u4ef6f\u4e2d\u5220\u9664 Strip optimizer from 'f' to finalize training, optionally save as 's' :params f: \u4f20\u5165\u7684\u539f\u59cb\u4fdd\u5b58\u7684\u6a21\u578b\u6587\u4ef6 :params s: \u5220\u9664optimizer\u7b49\u53d8\u91cf\u540e\u7684\u6a21\u578b\u4fdd\u5b58\u7684\u5730\u5740 dir \"\"\" # Strip optimizer from 'f' to finalize training, optionally save as 's' x = flow . load ( f , map_location = flow . device ( \"cpu\" )) # x: \u4e3a\u52a0\u8f7d\u8bad\u7ec3\u7684\u6a21\u578b if x . get ( \"ema\" ): # \u5982\u679c\u6a21\u578b\u662fema replace model with ema x [ \"model\" ] = x [ \"ema\" ] # replace model with ema # \u4ee5\u4e0b\u6a21\u578b\u8bad\u7ec3\u6d89\u53ca\u5230\u7684\u82e5\u5e72\u4e2a\u6307\u5b9a\u53d8\u91cf\u7f6e\u7a7a for k in \"optimizer\" , \"best_fitness\" , \"wandb_id\" , \"ema\" , \"updates\" : # keys x [ k ] = None x [ \"epoch\" ] = - 1 # \u6a21\u578bepoch\u6062\u590d\u521d\u59cb\u503c -1 x [ \"model\" ] . half () # to FP16 for p in x [ \"model\" ] . parameters (): p . requires_grad = False # \u4fdd\u5b58\u6a21\u578b x -> s/f flow . save ( x , s or f ) mb = os . path . getsize ( s or f ) / 1e6 # filesize LOGGER . info ( f \"Optimizer stripped from { f } , { f ' saved as { s } ,' if s else '' } { mb : .1f } MB\" )","title":"26. strip_optimizer"},{"location":"source_code_interpretation/utils/general_py.html#27-print_mutation","text":"\u8fd9\u4e2a\u51fd\u6570\u7528\u6765\u6253\u5370\u8fdb\u5316\u540e\u7684\u8d85\u53c2\u7ed3\u679c\u548cresults\u5230evolve.txt\u548chyp_evolved.yaml\u4e2d\u3002 print_mutation\u51fd\u6570\u4ee3\u7801\uff1a def print_mutation ( results , hyp , save_dir , bucket , prefix = colorstr ( \"evolve: \" )): \"\"\"\u7528\u5728train.py\u7684\u8fdb\u5316\u8d85\u53c2\u7ed3\u675f\u540e \u6253\u5370\u8fdb\u5316\u540e\u7684\u8d85\u53c2\u7ed3\u679c\u548cresults\u5230evolve.txt\u548chyp_evolved.yaml\u4e2d Print mutation results to evolve.txt (for use with train.py --evolve) :params hyp: \u8fdb\u5316\u540e\u7684\u8d85\u53c2 dict {28\u5bf9 key:value} :params results: tuple(7) (mp, mr, map50, map50:95, box_loss, obj_loss, cls_loss) :params yaml_file: \u8981\u4fdd\u5b58\u7684\u8fdb\u5316\u540e\u7684\u8d85\u53c2\u6587\u4ef6\u540d runs\\train\\evolve\\hyp_evolved.yaml :params bucket: '' \"\"\" evolve_csv = save_dir / \"evolve.csv\" evolve_yaml = save_dir / \"hyp_evolve.yaml\" keys = ( \"metrics/precision\" , \"metrics/recall\" , \"metrics/mAP_0.5\" , \"metrics/mAP_0.5:0.95\" , \"val/box_loss\" , \"val/obj_loss\" , \"val/cls_loss\" ,) + tuple ( hyp . keys () ) # [results + hyps] keys = tuple ( x . strip () for x in keys ) vals = results + tuple ( hyp . values ()) n = len ( keys ) # Download (optional) if bucket : url = f \"gs:// { bucket } /evolve.csv\" if gsutil_getsize ( url ) > ( evolve_csv . stat () . st_size if evolve_csv . exists () else 0 ): os . system ( f \"gsutil cp { url } { save_dir } \" ) # download evolve.csv if larger than local # Log to evolve.csv s = \"\" if evolve_csv . exists () else (( \" %20s ,\" * n % keys ) . rstrip ( \",\" ) + \" \\n \" ) # add header with open ( evolve_csv , \"a\" ) as f : f . write ( s + ( \" %20.5g ,\" * n % vals ) . rstrip ( \",\" ) + \" \\n \" ) # Save yaml with open ( evolve_yaml , \"w\" ) as f : data = pd . read_csv ( evolve_csv ) data = data . rename ( columns = lambda x : x . strip ()) # strip keys i = np . argmax ( fitness ( data . values [:, : 4 ])) # generations = len ( data ) f . write ( \"# YOLOv5 Hyperparameter Evolution Results \\n \" + f \"# Best generation: { i } \\n \" + f \"# Last generation: { generations - 1 } \\n \" + \"# \" + \", \" . join ( f \" { x . strip () : >20s } \" for x in keys [: 7 ]) + \" \\n \" + \"# \" + \", \" . join ( f \" { x : >20.5g } \" for x in data . values [ i , : 7 ]) + \" \\n\\n \" ) yaml . safe_dump ( data . loc [ i ][ 7 :] . to_dict (), f , sort_keys = False ) # Print to screen LOGGER . info ( prefix + f \" { generations } generations finished, current result: \\n \" + prefix + \", \" . join ( f \" { x . strip () : >20s } \" for x in keys ) + \" \\n \" + prefix + \", \" . join ( f \" { x : 20.5g } \" for x in vals ) + \" \\n\\n \" ) if bucket : os . system ( f \"gsutil cp { evolve_csv } { evolve_yaml } gs:// { bucket } \" ) # upload","title":"27. print_mutation"},{"location":"source_code_interpretation/utils/general_py.html#28-apply_classifier","text":"\u8fd9\u4e2a\u51fd\u6570\u5b9a\u4e49\u4e86\u4e00\u4e2a\u4e8c\u7ea7\u5206\u7c7b\u5668\u6765\u5904\u7406yolo\u7684\u8f93\u51fa\uff0c\u53ef\u4ee5\u5c06\u5b83\u7528\u5728detect.py\u4e2d\u3002 \u8fd9\u91cc\u5199\u7684\u8fd9\u4e2a\u51fd\u6570\u53ea\u662f\u4e00\u4e2a\u666e\u901a\u7684\u5b9e\u73b0\uff0c\u4f60\u4e5f\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u4efb\u52a1\u6539\u5199\u8fd9\u4e2a\u51fd\u6570\u3002 \u4e0d\u8fc7\u8fd9\u4e2a\u51fd\u6570\u6211\u4eec\u51e0\u4e4e\u4e0d\u4f1a\u7528\u5b83\uff0c\u56e0\u4e3a\u5b83\u5f88\u5bb9\u6613\u51fa\u9519\u3002\u6211\u4eec\u8fd9\u91cc\u5c31\u4e0d\u4ed4\u7ec6\u4ecb\u7ecd\u4e86\uff0c\u771f\u7684\u5f88\u96be\u7528\u5230\u8fd9\u4e2a\u51fd\u6570\uff0c\u968f\u4fbf\u770b\u4e0b\u5c31\u597d\u3002 \u51fd\u6570\u4ee3\u7801\uff1a def apply_classifier ( x , model , img , im0 ): \"\"\"\u7528\u5728detect.py\u6587\u4ef6\u7684nms\u540e\u7ee7\u7eed\u5bf9feature map\u9001\u5165model2 \u8fdb\u884c\u4e8c\u6b21\u5206\u7c7b \u5b9a\u4e49\u4e86\u4e00\u4e2a\u4e8c\u7ea7\u5206\u7c7b\u5668\u6765\u5904\u7406yolo\u7684\u8f93\u51fa \u5f53\u524d\u5b9e\u73b0\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u53c2\u8003\u8d77\u70b9\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u5b83\u81ea\u884c\u5b9e\u73b0\u6b64\u9879 \u6bd4\u5982\u4f60\u6709\u7167\u7247\u4e0e\u6c7d\u8f66\u4e0e\u8f66\u724c, \u4f60\u7b2c\u4e00\u6b21\u526a\u5207\u8f66\u724c, \u5e76\u5c06\u5176\u53d1\u9001\u5230\u7b2c\u4e8c\u9636\u6bb5\u5206\u7c7b\u5668, \u4ee5\u68c0\u6d4b\u5176\u4e2d\u7684\u5b57\u7b26 Apply a second stage classifier to yolo outputs https://github.com/ultralytics/yolov5/issues/2700 \u8fd9\u4e2a\u51fd\u6570\u4f7f\u7528\u8d77\u6765\u5f88\u5bb9\u6613\u51fa\u9519 \u4e0d\u662f\u5f88\u63a8\u8350\u4f7f\u7528 https://github.com/ultralytics/yolov5/issues/1472 :params x: yolo\u5c42\u7684\u8f93\u51fa :params model: \u5206\u7c7b\u6a21\u578b :params img: \u8fdb\u884cresize + pad\u4e4b\u540e\u7684\u56fe\u7247 :params im0: \u539f\u5c3a\u5bf8\u7684\u56fe\u7247 \"\"\" im0 = [ im0 ] if isinstance ( im0 , np . ndarray ) else im0 for i , d in enumerate ( x ): # per image if d is not None and len ( d ): d = d . clone () # Reshape and pad cutouts b = xyxy2xywh ( d [:, : 4 ]) # boxes xyxy -> xywh b [:, 2 :] = b [:, 2 :] . max ( 1 )[ 0 ] . unsqueeze ( 1 ) # rectangle to square b [:, 2 :] = b [:, 2 :] * 1.3 + 30 # pad d [:, : 4 ] = xywh2xyxy ( b ) . long () # xywh -> xyxy # Rescale boxes from img_size to im0 size scale_coords ( img . shape [ 2 :], d [:, : 4 ], im0 [ i ] . shape ) # Classes pred_cls1 = d [:, 5 ] . long () # \u5728\u4e4b\u524d\u7684yolo\u6a21\u578b\u9884\u6d4b\u7684\u7c7b\u522b ims = [] for j , a in enumerate ( d ): # per item cutout = im0 [ i ][ int ( a [ 1 ]): int ( a [ 3 ]), int ( a [ 0 ]): int ( a [ 2 ])] im = cv2 . resize ( cutout , ( 224 , 224 )) # BGR # cv2.imwrite('test%i.jpg' % j, cutout) im = im [:, :, :: - 1 ] . transpose ( 2 , 0 , 1 ) # BGR to RGB, to 3x416x416 im = np . ascontiguousarray ( im , dtype = np . float32 ) # uint8 to float32 im /= 255.0 # 0 - 255 to 0.0 - 1.0 ims . append ( im ) # \u7528model\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b pred_cls2 = model ( flow . Tensor ( ims ) . to ( d . device )) . argmax ( 1 ) # classifier prediction # \u4fdd\u7559\u9884\u6d4b\u4e00\u81f4\u7684\u7ed3\u679c x [ i ] = x [ i ][ pred_cls1 == pred_cls2 ] # retain matching class detections return x","title":"28. apply_classifier"},{"location":"source_code_interpretation/utils/general_py.html#29-increment_path","text":"\u7528\u4e8e\u9012\u589e\u8def\u5f84\u3002 \u6bd4\u5982\u6211\u8f93\u5165\u8def\u5f84\u662frun/train/exp\uff0c\u4f46\u662f\u53d1\u73b0\u6587\u4ef6\u5939\u91cc\u9762\u5df2\u7ecf\u6709\u8fd9\u4e2a\u6587\u4ef6\u4e86\uff0c \u90a3\u4e48\u5c31\u5c06\u6587\u4ef6\u8def\u5f84\u6269\u5c55\u56f4\u4e3a\uff1aruns/train/exp{sep}0, runs/exp{sep}1 etc\u3002 increment_path\u51fd\u6570\u4ee3\u7801\uff1a def increment_path ( path , exist_ok = False , sep = \"\" , mkdir = False ): \"\"\"\u8fd9\u662f\u4e2a\u7528\u5904\u7279\u522b\u5e7f\u6cdb\u7684\u51fd\u6570 train.py\u3001detect.py\u3001test.py\u7b49\u90fd\u4f1a\u7528\u5230 \u9012\u589e\u8def\u5f84 \u5982 run/train/exp --> runs/train/exp{sep}0, runs/exp{sep}1 etc. :params path: window path run/train/exp :params exist_ok: False :params sep: exp\u6587\u4ef6\u540d\u7684\u540e\u7f00 \u9ed8\u8ba4'' :params mkdir: \u662f\u5426\u5728\u8fd9\u91cc\u521b\u5efadir False \"\"\" # Increment file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc. path = Path ( path ) # os-agnostic # \u5982\u679c\u8be5\u6587\u4ef6\u5939\u5df2\u7ecf\u5b58\u5728 \u5219\u5c06\u8def\u5f84run/train/exp\u4fee\u6539\u4e3a runs/train/exp1 if path . exists () and not exist_ok : # path.suffix \u5f97\u5230\u8def\u5f84path\u7684\u540e\u7f00 '' path , suffix = ( path . with_suffix ( \"\" ), path . suffix ) if path . is_file () else ( path , \"\" ) # Method 1 for n in range ( 2 , 9999 ): p = f \" { path }{ sep }{ n }{ suffix } \" # increment path if not os . path . exists ( p ): # break path = Path ( p ) # Method 2 (deprecated) # dirs = glob.glob(f\"{path}{sep}*\") # similar paths # matches = [re.search(rf\"{path.stem}{sep}(\\d+)\", d) for d in dirs] # i = [int(m.groups()[0]) for m in matches if m] # indices # n = max(i) + 1 if i else 2 # increment number # path = Path(f\"{path}{sep}{n}{suffix}\") # increment path if mkdir : path . mkdir ( parents = True , exist_ok = True ) # make directory return path","title":"29. increment_path"},{"location":"source_code_interpretation/utils/general_py.html#30-resample_segments","text":"\u8fd9\u4e2a\u51fd\u6570\u662f \u5bf9segment\u91cd\u65b0\u91c7\u6837\uff0c\u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000)\u3002 resample_segments\u51fd\u6570\u4ee3\u7801\uff1a def resample_segments ( segments , n = 1000 ): \"\"\"\u7528\u5728augmentations.py\u6587\u4ef6\u4e2d\u7684random_perspective\u51fd\u6570\u4e2d \u5bf9segment\u91cd\u65b0\u91c7\u6837\uff0c\u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000) :params segments: [N, x1x2...] :params n: \u91c7\u6837\u4e2a\u6570 :return segments: [N, n/2, 2] \"\"\" # Up-sample an (n,2) segment for i , s in enumerate ( segments ): s = np . concatenate (( s , s [ 0 : 1 , :]), axis = 0 ) x = np . linspace ( 0 , len ( s ) - 1 , n ) xp = np . arange ( len ( s )) # \u5bf9\u6240\u6709\u7684segments\u90fd\u8fdb\u884c\u91cd\u65b0\u91c7\u6837 \u6bd4\u5982\u8bf4segment\u5750\u6807\u53ea\u6709100\u4e2a\uff0c\u901a\u8fc7interp\u51fd\u6570\u5c06\u5176\u91c7\u6837\u4e3an\u4e2a(\u9ed8\u8ba41000) segments [ i ] = np . concatenate ([ np . interp ( x , xp , s [:, i ]) for i in range ( 2 )]) . reshape ( 2 , - 1 ) . T # segment xy0 return segments","title":"30. resample_segments"},{"location":"source_code_interpretation/utils/general_py.html#31-segment2box","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e(\u4e0d\u662f\u77e9\u5f62\u6807\u7b7e \u5230\u5e95\u662f\u51e0\u8fb9\u5f62\u672a\u77e5)\u8f6c\u5316\u4e3a\u4e00\u4e2a\u77e9\u5f62\u6807\u7b7e\u3002 segment2box\u51fd\u6570\u4ee3\u7801\uff1a def segment2box ( segment , width = 640 , height = 640 ): \"\"\"\u7528\u5728augmentations.py\u6587\u4ef6\u4e2d\u7684random_perspective\u51fd\u6570\u4e2d \u5c06\u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e(\u4e0d\u662f\u77e9\u5f62\u6807\u7b7e \u5230\u5e95\u662f\u51e0\u8fb9\u5f62\u672a\u77e5)\u8f6c\u5316\u4e3a\u4e00\u4e2a\u77e9\u5f62\u6807\u7b7e \u65b9\u6cd5: \u5bf9\u591a\u8fb9\u5f62\u6240\u6709\u7684\u70b9x1y1 x2y2... \u83b7\u53d6\u5176\u4e2d\u7684(x_min,y_min)\u548c(x_max,y_max) \u4f5c\u4e3a\u77e9\u5f62label\u7684\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2 Convert 1 segment label to 1 box label, applying inside-image constraint :params segment: \u4e00\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e [n, 2] \u4f20\u5165\u8fd9\u4e2a\u591a\u8fb9\u5f62n\u4e2a\u9876\u70b9\u7684\u5750\u6807 :params width: \u8fd9\u4e2a\u591a\u8fb9\u5f62\u6240\u5728\u56fe\u7247\u7684\u5bbd\u5ea6 :params height: \u8fd9\u4e2a\u591a\u8fb9\u5f62\u6240\u5728\u56fe\u7247\u7684\u9ad8\u5ea6 :return \u77e9\u5f62\u6807\u7b7e [1, x_min+y_min+x_max+y_max] \"\"\" # \u5206\u522b\u83b7\u53d6\u5f53\u524d\u591a\u8fb9\u5f62\u4e2d\u6240\u6709\u591a\u8fb9\u5f62\u70b9\u7684x\u548cy\u5750\u6807 x , y = segment . T # segment xy # inside: \u7b5b\u9009\u6761\u4ef6 xy\u5750\u6807\u5fc5\u987b\u5927\u4e8e\u7b49\u4e8e0 x\u5750\u6807\u5fc5\u987b\u5c0f\u4e8e\u7b49\u4e8e\u5bbd\u5ea6 y\u5750\u6807\u5fc5\u987b\u5c0f\u4e8e\u7b49\u4e8e\u9ad8\u5ea6 inside = ( x >= 0 ) & ( y >= 0 ) & ( x <= width ) & ( y <= height ) # \u83b7\u53d6\u7b5b\u9009\u540e\u7684\u6240\u6709\u591a\u8fb9\u5f62\u70b9\u7684x\u548cy\u5750\u6807 x , y , = x [ inside ], y [ inside ] # \u53d6\u5f53\u524d\u591a\u8fb9\u5f62\u4e2dxy\u5750\u6807\u7684\u6700\u5927\u6700\u5c0f\u503c\uff0c\u5f97\u5230\u8fb9\u6846\u7684\u5750\u6807xyxy return np . array ([ x . min (), y . min (), x . max (), y . max ()]) if any ( x ) else np . zeros (( 1 , 4 ))","title":"31. segment2box"},{"location":"source_code_interpretation/utils/general_py.html#32-segments2boxes","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u5c06\u591a\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e(\u4e0d\u662f\u77e9\u5f62\u6807\u7b7e \u5230\u5e95\u662f\u51e0\u8fb9\u5f62\u672a\u77e5)\u8f6c\u5316\u4e3a\u591a\u4e2a\u77e9\u5f62\u6807\u7b7e\u3002 segments2boxes\u6a21\u5757\u4ee3\u7801: def segments2boxes ( segments ): \"\"\"\u7528\u5728dataloaders.py\u6587\u4ef6\u4e2d\u7684verify_image_label\u51fd\u6570\u4e2d \u5c06\u591a\u4e2a\u591a\u8fb9\u5f62\u6807\u7b7e(\u4e0d\u662f\u77e9\u5f62\u6807\u7b7e \u5230\u5e95\u662f\u51e0\u8fb9\u5f62\u672a\u77e5)\u8f6c\u5316\u4e3a\u591a\u4e2a\u77e9\u5f62\u6807\u7b7e Convert segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh) :params segments: [N, cls+x1y1+x2y2 ...] :return [N, cls+xywh] \"\"\" boxes = [] for s in segments : # \u5206\u522b\u83b7\u53d6\u5f53\u524d\u591a\u8fb9\u5f62\u4e2d\u6240\u6709\u591a\u8fb9\u5f62\u70b9\u7684x\u548cy\u5750\u6807 x , y = s . T # \u53d6\u5f53\u524d\u591a\u8fb9\u5f62\u4e2dx\u548cy\u5750\u6807\u7684\u6700\u5927\u6700\u5c0f\u503c\uff0c\u5f97\u5230\u8fb9\u6846\u7684\u5750\u6807xyxy boxes . append ([ x . min (), y . min (), x . max (), y . max ()]) # [N, cls+xywh] return xyxy2xywh ( np . array ( boxes ))","title":"32. segments2boxes"},{"location":"source_code_interpretation/utils/general_py.html#_2","text":"\u8fd9\u4e2a\u6587\u4ef6\u7684\u4ee3\u7801\u4e3b\u8981\u662f\u4e00\u4e9b\u901a\u7528\u7684\u5de5\u5177\u51fd\u6570\uff0c\u4f1a\u5e7f\u6cdb\u7684\u5728\u6574\u4e2a\u9879\u76ee\u7684\u6587\u4ef6\u4e2d\u4f7f\u7528\uff0c\u6240\u4ee5\u6bd4\u8f83\u91cd\u8981\uff0c\u5e0c\u671b\u5927\u5bb6\u90fd\u53ef\u4ee5\u638c\u63e1\u3002 \u6bd4\u8f83\u91cd\u8981\u7684\u51fd\u6570\u6709\uff1aset_logging\u3001init_seeds\u3001get_latest_run\u3001colorstr\u3001check_git_status\u3001check_requirements\u3001make_divisible\u3001check_file\u3001check_dataset\u3001one_cycle\u3001labels_to_class_weights\u3001labels_to_image_weights\u3001strip_optimizer\u3001print_mutation\u3001save_one_box\u3001increment_path\u3002 \u975e\u5e38\u91cd\u8981\u7684\u6709\uff1aclip_coords\u3001scale_coords\u3001xyxy2xywh\u3001xywh2xyxy\u3001xywhn2xyxy\u3001xyxy2xywhn\u3001xyn2xy\u3001non_max_suppression\u3002","title":"\u603b\u7ed3"},{"location":"source_code_interpretation/utils/general_py.html#reference","text":"\u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011general.py","title":"Reference"},{"location":"source_code_interpretation/utils/loss_py.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a loss.py \u5176\u4e2d\u4e00\u4e9b\u5e38\u89c1\u7684\u635f\u5931\u51fd\u6570\u5305\u62ec\uff1a \u5206\u7c7b\u635f\u5931(cls_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u5224\u65ad\u6a21\u578b\u662f\u5426\u80fd\u591f\u51c6\u786e\u5730\u8bc6\u522b\u51fa\u56fe\u50cf\u4e2d\u7684\u5bf9\u8c61\uff0c\u5e76\u5c06\u5176\u5206\u7c7b\u5230\u6b63\u786e\u7684\u7c7b\u522b\u4e2d\u3002 \u7f6e\u4fe1\u5ea6\u635f\u5931(obj_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u7684\u6846\uff08\u5373\u5305\u542b\u5bf9\u8c61\u7684\u77e9\u5f62\uff09\u4e0e\u771f\u5b9e\u6846\u4e4b\u95f4\u7684\u5dee\u5f02\u3002 \u8fb9\u754c\u6846\u635f\u5931(box_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4e0e\u771f\u5b9e\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u8fd9\u6709\u52a9\u4e8e\u786e\u4fdd\u6a21\u578b\u80fd\u591f\u51c6\u786e\u5730\u5b9a\u4f4d\u5bf9\u8c61\u3002 \u8fd9\u4e9b\u635f\u5931\u51fd\u6570\u5728\u8bad\u7ec3\u6a21\u578b\u65f6\u88ab\u7ec4\u5408\u4f7f\u7528\uff0c\u4ee5\u4f18\u5316\u6a21\u578b\u7684\u6027\u80fd\u3002\u901a\u8fc7\u4f7f\u7528\u8fd9\u4e9b\u635f\u5931\u51fd\u6570\uff0cYOLOv5\u53ef\u4ee5\u51c6\u786e\u5730\u8bc6\u522b\u56fe\u50cf\u4e2d\u7684\u5bf9\u8c61\uff0c\u5e76\u5c06\u5176\u5b9a\u4f4d\u5230\u56fe\u50cf\u4e2d\u7684\u5177\u4f53\u4f4d\u7f6e\u3002 1. \u5bfc\u5165\u9700\u8981\u7684\u5305 import oneflow as flow import oneflow.nn as nn from utils.metrics import bbox_iou from utils.oneflow_utils import de_parallel 2. smooth_BCE \u8fd9\u4e2a\u51fd\u6570\u662f\u4e00\u4e2a\u6807\u7b7e\u5e73\u6ed1\u7684\u7b56\u7565(trick)\uff0c\u662f\u4e00\u79cd\u5728 \u5206\u7c7b/\u68c0\u6d4b \u95ee\u9898\u4e2d\uff0c\u9632\u6b62\u8fc7\u62df\u5408\u7684\u65b9\u6cd5\u3002 \u5982\u679c\u8981\u8be6\u7ec6\u7406\u89e3\u8fd9\u4e2a\u7b56\u7565\u7684\u539f\u7406\uff0c\u8bf7\u53c2\u9605\u535a\u6587: \u300atrick 1\u300bLabel Smoothing\uff08\u6807\u7b7e\u5e73\u6ed1\uff09\u2014\u2014 \u5206\u7c7b\u95ee\u9898\u4e2d\u9519\u8bef\u6807\u6ce8\u7684\u4e00\u79cd\u89e3\u51b3\u65b9\u6cd5. smooth_BCE\u51fd\u6570\u4ee3\u7801: # \u6807\u7b7e\u5e73\u6ed1 def smooth_BCE ( eps = 0.1 ): # https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441 \"\"\"\u7528\u5728ComputeLoss\u7c7b\u4e2d \u6807\u7b7e\u5e73\u6ed1\u64cd\u4f5c [1, 0] => [0.95, 0.05] :params eps: \u5e73\u6ed1\u53c2\u6570 :return positive, negative label smoothing BCE targets \u4e24\u4e2a\u503c\u5206\u522b\u4ee3\u8868\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\u7684\u6807\u7b7e\u53d6\u503c \u539f\u5148\u7684\u6b63\u6837\u672c=1 \u8d1f\u6837\u672c=0 \u6539\u4e3a \u6b63\u6837\u672c=1.0 - 0.5 * eps \u8d1f\u6837\u672c=0.5 * eps \"\"\" # return positive, negative label smoothing BCE targets return 1.0 - 0.5 * eps , 0.5 * eps \u901a\u5e38\u4f1a\u7528\u5728\u5206\u7c7b\u635f\u5931\u5f53\u4e2d\uff0c\u5982\u4e0bComputeLoss\u7c7b\u7684__init__\u51fd\u6570\u5b9a\u4e49\uff1a self.cp, self.cn = smooth_BCE(eps=h.get(\"label_smoothing\", 0.0)) # positive, negative BCE targets ComputeLoss\u7c7b\u7684__call__\u51fd\u6570\u8c03\u7528\uff1a # Classification if self.nc > 1: # cls loss (only if multiple classes) t = flow.full_like(pcls, self.cn, device=self.device) # targets # t[range(n), tcls[i]] = self.cp t[flow.arange(n, device=self.device), tcls[i]] = self.cp lcls = lcls + self.BCEcls(pcls, t) # BCE 3. BCEBlurWithLogitsLoss \u8fd9\u4e2a\u51fd\u6570\u662fBCE\u51fd\u6570\u7684\u4e00\u4e2a\u66ff\u4ee3\uff0c\u662fyolov5\u4f5c\u8005\u7684\u4e00\u4e2a\u5b9e\u9a8c\u6027\u7684\u51fd\u6570\uff0c\u53ef\u4ee5\u81ea\u5df1\u8bd5\u8bd5\u6548\u679c\u3002 \u4f7f\u7528\u8d77\u6765\u76f4\u63a5\u5728ComputeLoss\u7c7b\u7684__init__\u51fd\u6570\u4e2d\u66ff\u4ee3\u4f20\u7edf\u7684BCE\u51fd\u6570\u5373\u53ef\uff1a class BCEBlurWithLogitsLoss ( nn . Module ): \"\"\"\u7528\u5728ComputeLoss\u7c7b\u7684__init__\u51fd\u6570\u4e2d BCEwithLogitLoss() with reduced missing label effects. https://github.com/ultralytics/yolov5/issues/1030 The idea was to reduce the effects of false positive (missing labels) \u5c31\u662f\u68c0\u6d4b\u6210\u6b63\u6837\u672c\u4e86 \u4f46\u662f\u68c0\u6d4b\u9519\u4e86 \"\"\" def __init__ ( self , alpha = 0.05 ): super ( BCEBlurWithLogitsLoss , self ) . __init__ () self . loss_fcn = nn . BCEWithLogitsLoss ( reduction = 'none' ) # must be nn.BCEWithLogitsLoss() self . alpha = alpha def forward ( self , pred , true ): loss = self . loss_fcn ( pred , true ) pred = flow . sigmoid ( pred ) # prob from logits # dx = [-1, 1] \u5f53pred=1 true=0\u65f6(\u7f51\u7edc\u9884\u6d4b\u8bf4\u8fd9\u91cc\u6709\u4e2aobj\u4f46\u662fgt\u8bf4\u8fd9\u91cc\u6ca1\u6709), dx=1 => alpha_factor=0 => loss=0 # \u8fd9\u79cd\u5c31\u662f\u68c0\u6d4b\u6210\u6b63\u6837\u672c\u4e86\u4f46\u662f\u68c0\u6d4b\u9519\u4e86\uff08false positive\uff09\u6216\u8005missing label\u7684\u60c5\u51b5 \u8fd9\u79cd\u60c5\u51b5\u4e0d\u5e94\u8be5\u8fc7\u591a\u7684\u60e9\u7f5a->loss=0 dx = pred - true # reduce only missing label effects # \u5982\u679c\u91c7\u6837\u7edd\u5bf9\u503c\u7684\u8bdd \u4f1a\u51cf\u8f7bpred\u548cgt\u5dee\u5f02\u8fc7\u5927\u800c\u9020\u6210\u7684\u5f71\u54cd # dx = (pred - true).abs() # reduce missing label and false label effects alpha_factor = 1 - flow . exp (( dx - 1 ) / ( self . alpha + 1e-4 )) loss *= alpha_factor return loss . mean () 4. FocalLoss FocalLoss\u635f\u5931\u51fd\u6570\u6765\u81ea Kaiming He\u57282017\u5e74\u53d1\u8868\u7684\u4e00\u7bc7\u8bba\u6587\uff1aFocal Loss for Dense Object Detection. \u8fd9\u7bc7\u8bba\u6587\u8bbe\u8ba1\u7684\u4e3b\u8981\u601d\u8def: \u5e0c\u671b\u90a3\u4e9bhard examples\u5bf9\u635f\u5931\u7684\u8d21\u732e\u53d8\u5927\uff0c\u4f7f\u7f51\u7edc\u66f4\u503e\u5411\u4e8e\u4ece\u8fd9\u4e9b\u6837\u672c\u4e0a\u5b66\u4e60\u3002\u9632\u6b62\u7531\u4e8eeasy examples\u8fc7\u591a\uff0c\u4e3b\u5bfc\u6574\u4e2a\u635f\u5931\u51fd\u6570\u3002 \u4f18\u70b9\uff1a \u89e3\u51b3\u4e86one-stage object detection\u4e2d\u56fe\u7247\u4e2d\u6b63\u8d1f\u6837\u672c\uff08\u524d\u666f\u548c\u80cc\u666f\uff09\u4e0d\u5747\u8861\u7684\u95ee\u9898\uff1b \u964d\u4f4e\u7b80\u5355\u6837\u672c\u7684\u6743\u91cd\uff0c\u4f7f\u635f\u5931\u51fd\u6570\u66f4\u5173\u6ce8\u56f0\u96be\u6837\u672c\uff1b \u51fd\u6570\u516c\u5f0f\uff1a \\(F L\\left(p_{t}\\right)=-\\alpha_{t}\\left(1-p_{t}\\right)^{\\gamma} \\log \\left(p_{t}\\right)\\) \\(\\begin{array}{c} p_{t} = \\left\\{\\begin{array}{ll} p & y = 1 \\\\ 1-p & \\text { \u5176\u4ed6 } \\end{array}\\right. \\end{array}\\) \\(\\alpha_{t}=\\left\\{\\begin{array}{ll} \\alpha & y=1(\\text { \u6b63\u6837\u672c }) \\\\ 1-\\alpha & \\text { \u5176\u4ed6 }(\\text { \u8d1f\u6837\u672c }) \\end{array} ; \\text { \u5176\u4e2d } \\alpha \\in[0,1]\\right.\\) \\(\\begin{array}{c} \\text { \u5176\u4e2d } \\alpha_{t} \\text { \u6765\u534f\u8c03\u6b63\u8d1f\u6837\u672c\u4e4b\u95f4\u7684\u5e73\u8861\uff0c } \\gamma \\text { \u6765\u964d\u4f4e\u7b80\u5355\u6837\u672c\u7684\u6743\u91cd\uff0c\u4f7f\u635f\u5931\u51fd\u6570\u66f4\u5173\u6ce8\u56f0\u96be\u6837\u672c\u3002 } \\end{array}\\) FocalLoss\u51fd\u6570\u4ee3\u7801\uff1a class FocalLoss ( nn . Module ): \"\"\"\u7528\u5728\u4ee3\u66ff\u539f\u672c\u7684BCEcls\uff08\u5206\u7c7b\u635f\u5931\uff09\u548cBCEobj\uff08\u7f6e\u4fe1\u5ea6\u635f\u5931\uff09 Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5) \u8bba\u6587: https://arxiv.org/abs/1708.02002 https://blog.csdn.net/qq_38253797/article/details/116292496 TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py \"\"\" # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5) def __init__ ( self , loss_fcn , gamma = 1.5 , alpha = 0.25 ): super () . __init__ () self . loss_fcn = loss_fcn # must be nn.BCEWithLogitsLoss() \u5b9a\u4e49\u4e3a\u591a\u5206\u7c7b\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 self . gamma = gamma # \u53c2\u6570gamma \u7528\u4e8e\u524a\u5f31\u7b80\u5355\u6837\u672c\u5bf9loss\u7684\u8d21\u732e\u7a0b\u5ea6 self . alpha = alpha # \u53c2\u6570alpha \u7528\u4e8e\u5e73\u8861\u6b63\u8d1f\u6837\u672c\u4e2a\u6570\u4e0d\u5747\u8861\u7684\u95ee\u9898 self . reduction = loss_fcn . reduction # self.reduction: \u63a7\u5236FocalLoss\u635f\u5931\u8f93\u51fa\u6a21\u5f0f sum/mean/none \u9ed8\u8ba4\u662fMean # focalloss\u4e2d\u7684BCE\u51fd\u6570\u7684reduction='None' BCE\u4e0d\u4f7f\u7528Sum\u6216\u8005Mean # \u9700\u8981\u5c06Focal loss\u5e94\u7528\u4e8e\u6bcf\u4e00\u4e2a\u6837\u672c\u4e4b\u4e2d self . loss_fcn . reduction = \"none\" # required to apply FL to each element def forward ( self , pred , true ): # \u6b63\u5e38BCE\u7684loss: loss = -log(p_t) loss = self . loss_fcn ( pred , true ) # p_t = flow.exp(-loss) # loss *= self.alpha * (1.000001 - p_t) ** self.gamma # non-zero power for gradient stability # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py pred_prob = flow . sigmoid ( pred ) # prob from logits p_t = true * pred_prob + ( 1 - true ) * ( 1 - pred_prob ) alpha_factor = true * self . alpha + ( 1 - true ) * ( 1 - self . alpha ) modulating_factor = ( 1.0 - p_t ) ** self . gamma # \u8fd9\u91cc\u4ee3\u8868Focal loss\u4e2d\u7684\u6307\u6570\u9879 # \u8fd4\u56de\u6700\u7ec8\u7684loss=BCE * \u4e24\u4e2a\u53c2\u6570 (\u770b\u770b\u516c\u5f0f\u5c31\u884c\u4e86 \u548c\u516c\u5f0f\u4e00\u6a21\u4e00\u6837) loss = loss * alpha_factor * modulating_factor # \u6700\u540e\u9009\u62e9focalloss\u8fd4\u56de\u7684\u7c7b\u578b \u9ed8\u8ba4\u662fmean if self . reduction == \"mean\" : return loss . mean () elif self . reduction == \"sum\" : return loss . sum () else : # 'none' return loss \u8fd9\u4e2a\u51fd\u6570\u7528\u5728\u4ee3\u66ff\u539f\u672c\u7684BCEcls\u548cBCEobj: # Focal loss g = h [ \"fl_gamma\" ] # focal loss gamma g=0 \u4ee3\u8868\u4e0d\u7528focal loss if g > 0 : BCEcls , BCEobj = FocalLoss ( BCEcls , g ), FocalLoss ( BCEobj , g ) 5. QFocalLoss QFocalLoss\u635f\u5931\u51fd\u6570\u6765\u81ea20\u5e74\u7684\u4e00\u7bc7\u6587\u7ae0\uff1a Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection. \u5982\u679c\u5bf9\u8fd9\u7bc7\u8bba\u6587\u611f\u5174\u8da3\u53ef\u4ee5\u770b\u770b\u5927\u795e\u535a\u5ba2\uff1a \u5927\u767d\u8bdd Generalized Focal Loss. \u516c\u5f0f: \\(\\mathbf{Q F L}(\\sigma)=-|y-\\sigma|^{\\beta}((1-y) \\log (1-\\sigma)+y \\log (\\sigma))\\) QFocalLoss\u51fd\u6570\u4ee3\u7801\uff1a class QFocalLoss ( nn . Module ): \"\"\"\u7528\u6765\u4ee3\u66ffFocalLoss QFocalLoss \u6765\u81eaGeneral Focal Loss\u8bba\u6587: https://arxiv.org/abs/2006.04388 Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5) \"\"\" # Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5) def __init__ ( self , loss_fcn , gamma = 1.5 , alpha = 0.25 ): super () . __init__ () self . loss_fcn = loss_fcn # must be nn.BCEWithLogitsLoss() self . gamma = gamma self . alpha = alpha self . reduction = loss_fcn . reduction self . loss_fcn . reduction = \"none\" # required to apply FL to each element def forward ( self , pred , true ): loss = self . loss_fcn ( pred , true ) pred_prob = flow . sigmoid ( pred ) # prob from logits alpha_factor = true * self . alpha + ( 1 - true ) * ( 1 - self . alpha ) modulating_factor = flow . abs ( true - pred_prob ) ** self . gamma loss = loss * ( alpha_factor * modulating_factor ) if self . reduction == \"mean\" : return loss . mean () elif self . reduction == \"sum\" : return loss . sum () else : # 'none' return loss \u4f7f\u7528 QFolcalLoss \u76f4\u63a5\u5728 ComputeLoss \u7c7b\u4e2d\u4f7f\u7528 QFolcalLoss \u66ff\u6362\u6389 FocalLoss \u5373\u53ef\uff1a (\u4e5f\u5c31\u662f\u8bf4\u7528 QFolcalLoss \u66ff\u6362\u5982\u4e0b\u56fe\u4ee3\u7801\u5904\u7684 FocalLoss ) 6. ComputeLoss\u7c7b 6.1 __init__\u51fd\u6570 sort_obj_iou = False # \u540e\u9762\u7b5b\u9009\u7f6e\u4fe1\u5ea6\u635f\u5931\u6b63\u6837\u672c\u7684\u65f6\u5019\u662f\u5426\u5148\u5bf9iou\u6392\u5e8f # Compute losses def __init__ ( self , model , autobalance = False ): # \u83b7\u53d6\u6a21\u578b\u6240\u5728\u7684\u8bbe\u5907 device = next ( model . parameters ()) . device # \u83b7\u53d6\u6a21\u578b\u7684\u8d85\u53c2\u6570 h = model . hyp # \u5b9a\u4e49\u5206\u7c7b\u635f\u5931\u548c\u7f6e\u4fe1\u5ea6\u635f\u5931 BCEcls = nn . BCEWithLogitsLoss ( pos_weight = flow . tensor ([ h [ \"cls_pw\" ]], device = device )) BCEobj = nn . BCEWithLogitsLoss ( pos_weight = flow . tensor ([ h [ \"obj_pw\" ]], device = device )) # \u6807\u7b7e\u5e73\u6ed1 eps=0\u4ee3\u8868\u4e0d\u505a\u6807\u7b7e\u5e73\u6ed1-> cp=1 cn=0 / eps!=0\u4ee3\u8868\u505a\u6807\u7b7e\u5e73\u6ed1 # cp\u4ee3\u8868\u6b63\u6837\u672c\u7684\u6807\u7b7e\u503c cn\u4ee3\u8868\u8d1f\u6837\u672c\u7684\u6807\u7b7e\u503c # \u8bf7\u53c2\u8003\uff1aClass label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3 self . cp , self . cn = smooth_BCE ( eps = h . get ( \"label_smoothing\" , 0.0 )) # positive, negative BCE targets # Focal loss g = h [ \"fl_gamma\" ] # Focal Loss \u7684\u8d85\u53c2\u6570 gamma if g > 0 : # \u5982\u679c g>0 \u5c06\u5206\u7c7b\u635f\u5931\u548c\u7f6e\u4fe1\u5ea6\u635f\u5931(BCE)\u90fd\u6362\u6210 FocalLoss \u635f\u5931\u51fd\u6570 BCEcls , BCEobj = FocalLoss ( BCEcls , g ), FocalLoss ( BCEobj , g ) # m: \u8fd4\u56de\u7684\u662f\u6a21\u578b\u76843\u4e2a\u68c0\u6d4b\u5934\u5206\u522b\u5bf9\u5e94\u4ea7\u751f\u76843\u4e2a\u8f93\u51fa\u7279\u5f81\u56fe m = de_parallel ( model ) . model [ - 1 ] # Detect() module \"\"\"self.balance \u7528\u6765\u5b9e\u73b0obj,box,cls loss\u4e4b\u95f4\u6743\u91cd\u7684\u5e73\u8861 {3: [4.0, 1.0, 0.4]} \u8868\u793a\u6709\u4e09\u4e2alayer\u7684\u8f93\u51fa\uff0c\u7b2c\u4e00\u4e2alayer\u7684weight\u662f4.0\uff0c\u7b2c\u4e8c\u4e2a1.0\uff0c\u7b2c\u4e09\u4e2a\u4ee5\u6b64\u7c7b\u63a8\u3002 \u5982\u679c\u67095\u4e2alayer\u7684\u8f93\u51fa\uff0c\u90a3\u4e48\u6743\u91cd\u5206\u522b\u662f[4.0, 1.0, 0.25, 0.06, 0.02] \"\"\" self . balance = { 3 : [ 4.0 , 1.0 , 0.4 ]} . get ( m . nl , [ 4.0 , 1.0 , 0.25 , 0.06 , 0.02 ]) # P3-P7 # \u4e09\u4e2a\u68c0\u6d4b\u5934\u7684\u4e0b\u91c7\u6837\u7387 m.stride: [8, 16, 32] .index(16): \u6c42\u51fa\u4e0b\u91c7\u6837\u7387 stride=16 \u7684\u7d22\u5f15 # \u8fd9\u4e2a\u53c2\u6570\u4f1a\u7528\u6765\u81ea\u52a8\u8ba1\u7b97\u66f4\u65b0 3 \u4e2a feature map \u7684\u7f6e\u4fe1\u5ea6\u635f\u5931\u7cfb\u6570 self.balance self . ssi = list ( m . stride ) . index ( 16 ) if autobalance else 0 # stride 16 index self . BCEcls , self . BCEobj , self . gr , self . hyp , self . autobalance = ( BCEcls , BCEobj , 1.0 , h , autobalance , ) self . na = m . na # number of anchors \u6bcf\u4e2agrid_cell\u7684anchor\u6570\u91cf = 3 self . nc = m . nc # number of classes \u6570\u636e\u96c6\u7684\u603b\u7c7b\u522b = 80 self . nl = m . nl # number of layers \u68c0\u6d4b\u5934\u7684\u4e2a\u6570 = 3 # anchors: \u5f62\u72b6 [3, 3, 2] \u4ee3\u8868 3 \u4e2a feature map \u6bcf\u4e2a feature map \u4e0a\u6709 3 \u4e2a anchor(w,h) # \u8fd9\u91cc\u7684 anchors \u5c3a\u5bf8\u662f\u76f8\u5bf9 feature map \u7684 self . anchors = m . anchors self . device = device 6.2 build_targets \u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u4e3a\u6240\u6709GT\u7b5b\u9009\u76f8\u5e94\u7684anchor\u6b63\u6837\u672c\u3002 \u7b5b\u9009\u6761\u4ef6\u662f\u6bd4\u8f83GT\u548canchor\u7684\u5bbd\u6bd4\u548c\u9ad8\u6bd4\uff0c\u5927\u4e8e\u4e00\u5b9a\u7684\u9608\u503c\u5c31\u662f\u8d1f\u6837\u672c\uff0c\u53cd\u4e4b\u6b63\u6837\u672c\u3002 \u7b5b\u9009\u5230\u7684\u6b63\u6837\u672c\u4fe1\u606f\uff08image_index, anchor_index, gridy, gridx\uff09\uff0c\u4f20\u5165 __call__ \u51fd\u6570\uff0c \u901a\u8fc7\u8fd9\u4e2a\u4fe1\u606f\u53bb\u7b5b\u9009 pred \u91cc\u6bcf\u4e2a grid \u9884\u6d4b\u5f97\u5230\u7684\u4fe1\u606f\uff0c\u4fdd\u7559\u5bf9\u5e94 grid_cell \u4e0a\u7684\u6b63\u6837\u672c\u3002 \u901a\u8fc7 build_targets \u7b5b\u9009\u7684 GT \u4e2d\u7684\u6b63\u6837\u672c\u548c pred \u7b5b\u9009\u51fa\u7684\u5bf9\u5e94\u4f4d\u7f6e\u7684\u9884\u6d4b\u6837\u672c \u8fdb\u884c\u8ba1\u7b97\u635f\u5931\u3002 \u8865\u5145\u7406\u89e3\uff1a \u8fd9\u4e2a\u51fd\u6570\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u6bcf\u4e2a GT \u5339\u914d\u5bf9\u5e94\u7684\u9ad8\u8d28\u91cf Anchor \u6b63\u6837\u672c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c j = flow.max(r, 1. / r).max(2)[0] < self.hyp[\"anchor_t\"] \u8fd9\u6b65\u7684\u6bd4\u8f83\u662f\u4e3a\u4e86\u5c06 GT \u5206\u914d\u5230\u4e0d\u540c\u5c42\u4e0a\u53bb\u68c0\u6d4b\uff0c(\u8be6\u7ec6\u89e3\u91ca\u8bf7\u770b\u4e0b\u9762\u7684\u9010\u884c\u4ee3\u7801\u6ce8\u91ca) \u540e\u9762\u7684\u6b65\u9aa4\u662f\u4e3a\u4e86\u786e\u5b9a\u5728\u8fd9\u5c42\u68c0\u6d4b\u7684 GT \u4e2d\u5fc3\u5750\u6807\uff0c \u8fdb\u800c\u786e\u5b9a\u8fd9\u4e2a GT \u5728\u8fd9\u5c42\u54ea\u4e2a grid cell \u8fdb\u884c\u68c0\u6d4b\u3002 \u505a\u5230\u8fd9\u4e00\u6b65\u4e5f\u5c31\u505a\u5230\u4e86\u4e3a\u6bcf\u4e2a GT \u5339\u914d Anchor \u6b63\u6837\u672c\u7684\u76ee\u7684\u3002 # --------------------------------------------------------- # build_targets \u51fd\u6570\u7528\u4e8e\u83b7\u5f97\u5728\u8bad\u7ec3\u65f6\u8ba1\u7b97 loss \u6240\u9700\u8981\u7684\u76ee\u6807\u6846\uff0c\u4e5f\u5373\u6b63\u6837\u672c\u3002\u4e0eyolov3/v4\u7684\u4e0d\u540c\uff0cyolov5\u652f\u6301\u8de8\u7f51\u683c\u9884\u6d4b\u3002 # \u5bf9\u4e8e\u4efb\u4f55\u4e00\u4e2a GT bbox\uff0c\u4e09\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u90fd\u53ef\u80fd\u6709\u5148\u9a8c\u6846\u5339\u914d\uff0c\u6240\u4ee5\u8be5\u51fd\u6570\u8f93\u51fa\u7684\u6b63\u6837\u672c\u6846\u6bd4\u4f20\u5165\u7684 targets \uff08GT\u6846\uff09\u6570\u76ee\u591a # \u5177\u4f53\u5904\u7406\u8fc7\u7a0b: # (1)\u9996\u5148\u901a\u8fc7 bbox \u4e0e\u5f53\u524d\u5c42 anchor \u505a\u4e00\u904d\u8fc7\u6ee4\u3002\u5bf9\u4e8e\u4efb\u4f55\u4e00\u5c42\u8ba1\u7b97\u5f53\u524d bbox \u4e0e\u5f53\u524d\u5c42 anchor \u7684\u5339\u914d\u7a0b\u5ea6\uff0c\u4e0d\u91c7\u7528IoU\uff0c\u800c\u91c7\u7528shape\u6bd4\u4f8b\u3002\u5982\u679canchor\u4e0ebbox\u7684\u5bbd\u9ad8\u6bd4\u5dee\u8ddd\u5927\u4e8e4\uff0c\u5219\u8ba4\u4e3a\u4e0d\u5339\u914d\uff0c\u6b64\u65f6\u5ffd\u7565\u76f8\u5e94\u7684bbox\uff0c\u5373\u5f53\u505a\u80cc\u666f; # (2)\u6839\u636e\u7559\u4e0b\u7684bbox\uff0c\u5728\u4e0a\u4e0b\u5de6\u53f3\u56db\u4e2a\u7f51\u683c\u56db\u4e2a\u65b9\u5411\u6269\u589e\u91c7\u6837\uff08\u5373\u5bf9 bbox \u8ba1\u7b97\u843d\u5728\u7684\u7f51\u683c\u6240\u6709 anchors \u90fd\u8ba1\u7b97 loss(\u5e76\u4e0d\u662f\u76f4\u63a5\u548c GT \u6846\u6bd4\u8f83\u8ba1\u7b97 loss) ) # \u6ce8\u610f\u6b64\u65f6\u843d\u5728\u7f51\u683c\u4e0d\u518d\u662f\u4e00\u4e2a\uff0c\u800c\u662f\u9644\u8fd1\u7684\u591a\u4e2a\uff0c\u8fd9\u6837\u5c31\u589e\u52a0\u4e86\u6b63\u6837\u672c\u6570\u3002 # yolov5 \u6ca1\u6709 conf \u5206\u652f\u5ffd\u7565\u9608\u503c(ignore_thresh)\u7684\u64cd\u4f5c\uff0c\u800cyoloy3/v4\u6709\u3002 # -------------------------------------------------------- def build_targets ( self , p , targets ): \"\"\"\u6240\u6709GT\u7b5b\u9009\u76f8\u5e94\u7684anchor\u6b63\u6837\u672c \u8fd9\u91cc\u901a\u8fc7 p : list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) targets : targets.shape[314, 6] \u89e3\u6790 build_targets(self, p, targets):\u51fd\u6570 Build targets for compute_loss() :params p: p[i]\u7684\u4f5c\u7528\u53ea\u662f\u5f97\u5230\u6bcf\u4e2afeature map\u7684shape \u9884\u6d4b\u6846 \u7531\u6a21\u578b\u6784\u5efa\u4e2d\u7684\u4e09\u4e2a\u68c0\u6d4b\u5934Detector\u8fd4\u56de\u7684\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa tensor\u683c\u5f0f list\u5217\u8868 \u5b58\u653e\u4e09\u4e2atensor \u5bf9\u5e94\u7684\u662f\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa \u5982: list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) [bs, anchor_num, grid_h, grid_w, xywh+class+classes] \u53ef\u4ee5\u770b\u51fa\u6765\u8fd9\u91cc\u7684\u9884\u6d4b\u503cp\u662f\u4e09\u4e2ayolo\u5c42\u6bcf\u4e2agrid_cell(\u6bcf\u4e2agrid_cell\u6709\u4e09\u4e2a\u9884\u6d4b\u503c)\u7684\u9884\u6d4b\u503c,\u540e\u9762\u80af\u5b9a\u8981\u8fdb\u884c\u6b63\u6837\u672c\u7b5b\u9009 :params targets: \u6570\u636e\u589e\u5f3a\u540e\u7684\u771f\u5b9e\u6846 [63, 6] [num_target, image_index+class+xywh] xywh\u4e3a\u5f52\u4e00\u5316\u540e\u7684\u6846 :return tcls: \u8868\u793a\u8fd9\u4e2atarget\u6240\u5c5e\u7684class index tbox: xywh \u5176\u4e2dxy\u4e3a\u8fd9\u4e2atarget\u5bf9\u5f53\u524dgrid_cell\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\u91cf indices: b: \u8868\u793a\u8fd9\u4e2atarget\u5c5e\u4e8e\u7684image index a: \u8868\u793a\u8fd9\u4e2atarget\u4f7f\u7528\u7684anchor index gj: \u7ecf\u8fc7\u7b5b\u9009\u540e\u786e\u5b9a\u67d0\u4e2atarget\u5728\u67d0\u4e2a\u7f51\u683c\u4e2d\u8fdb\u884c\u9884\u6d4b(\u8ba1\u7b97\u635f\u5931) gj\u8868\u793a\u8fd9\u4e2a\u7f51\u683c\u7684\u5de6\u4e0a\u89d2y\u5750\u6807 gi: \u8868\u793a\u8fd9\u4e2a\u7f51\u683c\u7684\u5de6\u4e0a\u89d2x\u5750\u6807 anch: \u8868\u793a\u8fd9\u4e2atarget\u6240\u4f7f\u7528anchor\u7684\u5c3a\u5ea6\uff08\u76f8\u5bf9\u4e8e\u8fd9\u4e2afeature map\uff09 \u6ce8\u610f\u53ef\u80fd\u4e00\u4e2atarget\u4f1a\u4f7f\u7528\u5927\u5c0f\u4e0d\u540canchor\u8fdb\u884c\u8ba1\u7b97 \"\"\" # Build targets for compute_loss(), input targets(image,class,x,y,w,h) # na = 3 ; nt = 314 na , nt = self . na , targets . shape [ 0 ] # number of anchors, targets tcls , tbox , indices , anch = [], [], [], [] # gain.shape=[7] gain = flow . ones ( 7 , device = self . device ) # normalized to gridspace gain # ai.shape = (na,nt) \u751f\u6210anchor\u7d22\u5f15 # anchor\u7d22\u5f15\uff0c\u540e\u9762\u6709\u7528\uff0c\u7528\u4e8e\u8868\u793a\u5f53\u524dbbox\u548c\u5f53\u524d\u5c42\u7684\u54ea\u4e2aanchor\u5339\u914d # \u9700\u8981\u57283\u4e2aanchor\u4e0a\u90fd\u8fdb\u884c\u8bad\u7ec3 \u6240\u4ee5\u5c06\u6807\u7b7e\u8d4b\u503cna=3\u4e2a # ai\u4ee3\u88683\u4e2aanchor\u4e0a\u5728\u6240\u6709\u7684target\u5bf9\u5e94\u7684anchor\u7d22\u5f15 \u5c31\u662f\u7528\u6765\u6807\u8bb0\u4e0b\u5f53\u524d\u8fd9\u4e2atarget\u5c5e\u4e8e\u54ea\u4e2aanchor # [1, 3] -> [3, 1] -> [3, 314]=[na, nt] \u4e09\u884c \u7b2c\u4e00\u884c63\u4e2a0 \u7b2c\u4e8c\u884c63\u4e2a1 \u7b2c\u4e09\u884c63\u4e2a2 # ai.shape =[3, 314] ai = flow . arange ( na , device = self . device ) . float () . view ( na , 1 ) . repeat ( 1 , nt ) # same as .repeat_interleave(nt) # [314, 6] [3, 314] -> [3, 314, 6] [3, 314, 1] -> [3, 314, 7] 7: [image_index+class+xywh+anchor_index] # \u5bf9\u6bcf\u4e00\u4e2afeature map: \u8fd9\u4e00\u6b65\u662f\u5c06target\u590d\u5236\u4e09\u4efd \u5bf9\u5e94\u4e00\u4e2afeature map\u7684\u4e09\u4e2aanchor # \u5148\u5047\u8bbe\u6240\u6709\u7684target\u90fd\u7531\u8fd9\u5c42\u7684\u4e09\u4e2aanchor\u8fdb\u884c\u68c0\u6d4b(\u590d\u5236\u4e09\u4efd) \u518d\u8fdb\u884c\u7b5b\u9009 \u5e76\u5c06ai\u52a0\u8fdb\u53bb\u6807\u8bb0\u5f53\u524d\u662f\u54ea\u4e2aanchor\u7684target # targets.shape = [3, 314, 7] targets = flow . cat (( targets . repeat ( na , 1 , 1 ), ai [ ... , None ]), 2 ) # append anchor indices # \u8fd9\u4e24\u4e2a\u53d8\u91cf\u662f\u7528\u6765\u6269\u5c55\u6b63\u6837\u672c\u7684 \u56e0\u4e3a\u9884\u6d4b\u6846\u9884\u6d4b\u5230target\u6709\u53ef\u80fd\u4e0d\u6b62\u5f53\u524d\u7684\u683c\u5b50\u9884\u6d4b\u5230\u4e86 # \u53ef\u80fd\u5468\u56f4\u7684\u683c\u5b50\u4e5f\u9884\u6d4b\u5230\u4e86\u9ad8\u8d28\u91cf\u7684\u6837\u672c \u6211\u4eec\u4e5f\u8981\u628a\u8fd9\u90e8\u5206\u7684\u9884\u6d4b\u4fe1\u606f\u52a0\u5165\u6b63\u6837\u672c\u4e2d # \u8bbe\u7f6e\u7f51\u683c\u4e2d\u5fc3\u504f\u79fb\u91cf g = 0.5 # bias # \u9644\u8fd1\u76844\u4e2a\u6846 # \u4ee5\u81ea\u8eab + \u5468\u56f4\u5de6\u4e0a\u53f3\u4e0b4\u4e2a\u7f51\u683c = 5\u4e2a\u7f51\u683c \u7528\u6765\u8ba1\u7b97offsets off = ( flow . tensor ( [ [ 0 , 0 ], [ 1 , 0 ], [ 0 , 1 ], [ - 1 , 0 ], [ 0 , - 1 ], # j,k,l,m # [1, 1], [1, -1], [-1, 1], [-1, -1], # jk,jm,lk,lm ], device = self . device , ) . float () * g ) # offsets # \u5bf9\u6bcf\u4e2a\u68c0\u6d4b\u5c42\u8fdb\u884c\u5904\u7406 # \u904d\u5386\u4e09\u4e2afeature \u7b5b\u9009gt\u7684anchor\u6b63\u6837\u672c for i in range ( self . nl ): # self.nl: number of detection layers Detect\u7684\u4e2a\u6570 = 3 # anchors: \u5f53\u524dfeature map\u5bf9\u5e94\u7684\u4e09\u4e2aanchor\u5c3a\u5bf8(\u76f8\u5bf9feature map) [3, 2] anchors , shape = self . anchors [ i ], p [ i ] . shape # gain: \u4fdd\u5b58\u6bcf\u4e2a\u8f93\u51fafeature map\u7684\u5bbd\u9ad8 -> gain[2:6] = flow.tensor(shape)[[3, 2, 3, 2]] # [1, 1, 1, 1, 1, 1, 1] -> [1, 1, 112, 112, 112,112, 1]=image_index+class+xywh+anchor_index gain [ 2 : 6 ] = flow . tensor ( p [ i ] . shape , device = self . device )[[ 3 , 2 , 3 , 2 ]] . float () # xyxy gain # Match targets to anchors # t.shape = [3, 314, 7] \u5c06target\u4e2d\u7684xywh\u7684\u5f52\u4e00\u5316\u5c3a\u5ea6\u653e\u7f29\u5230\u76f8\u5bf9\u5f53\u524dfeature map\u7684\u5750\u6807\u5c3a\u5ea6 # [3, 314, image_index+class+xywh+anchor_index] t = targets * gain # shape(3,n,7) if nt : # \u5982\u679c\u6709\u76ee\u6807\u5c31\u5f00\u59cb\u5339\u914d # Matches # \u6240\u6709\u7684gt\u4e0e\u5f53\u524d\u5c42\u7684\u4e09\u4e2aanchor\u7684\u5bbd\u9ad8\u6bd4(w/w h/h) # r.shape = [3, 314, 2] r = t [ ... , 4 : 6 ] / anchors [:, None ] # wh ratio # \u7b5b\u9009\u6761\u4ef6 GT\u4e0eanchor\u7684\u5bbd\u6bd4\u6216\u9ad8\u6bd4\u8d85\u8fc7\u4e00\u5b9a\u7684\u9608\u503c \u5c31\u5f53\u4f5c\u8d1f\u6837\u672c # flow.max(r, 1. / r)=[3, 314, 2] \u7b5b\u9009\u51fa\u5bbd\u6bd4w1/w2 w2/w1 \u9ad8\u6bd4h1/h2 h2/h1\u4e2d\u6700\u5927\u7684\u90a3\u4e2a # .max(2)\u8fd4\u56de\u5bbd\u6bd4 \u9ad8\u6bd4\u4e24\u8005\u4e2d\u8f83\u5927\u7684\u4e00\u4e2a\u503c\u548c\u5b83\u7684\u7d22\u5f15 [0]\u8fd4\u56de\u8f83\u5927\u7684\u4e00\u4e2a\u503c # j.shape = [3, 314] False: \u5f53\u524danchor\u662f\u5f53\u524dgt\u7684\u8d1f\u6837\u672c True: \u5f53\u524danchor\u662f\u5f53\u524dgt\u7684\u6b63\u6837\u672c j = flow . max ( r , 1 / r ) . max ( 2 )[ 0 ] < self . hyp [ \"anchor_t\" ] # compare # yolov3 v4\u7684\u7b5b\u9009\u65b9\u6cd5: wh_iou GT\u4e0eanchor\u7684wh_iou\u8d85\u8fc7\u4e00\u5b9a\u7684\u9608\u503c\u5c31\u662f\u6b63\u6837\u672c # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t'] # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2)) # \u6839\u636e\u7b5b\u9009\u6761\u4ef6j, \u8fc7\u6ee4\u8d1f\u6837\u672c, \u5f97\u5230\u6240\u6709gt\u7684anchor\u6b63\u6837\u672c(batch_size\u5f20\u56fe\u7247) # \u77e5\u9053\u5f53\u524dgt\u7684\u5750\u6807 \u5c5e\u4e8e\u54ea\u5f20\u56fe\u7247 \u6b63\u6837\u672c\u5bf9\u5e94\u7684idx \u4e5f\u5c31\u5f97\u5230\u4e86\u5f53\u524dgt\u7684\u6b63\u6837\u672canchor # t: [3, 314, 7] -> [555, 7] [num_Positive_sample, image_index+class+xywh+anchor_index] t = t [ j ] # filter # Offsets \u7b5b\u9009\u5f53\u524d\u683c\u5b50\u5468\u56f4\u683c\u5b50 \u627e\u5230 2 \u4e2a\u79bbtarget\u4e2d\u5fc3\u6700\u8fd1\u7684\u4e24\u4e2a\u683c\u5b50 # \u53ef\u80fd\u5468\u56f4\u7684\u683c\u5b50\u4e5f\u9884\u6d4b\u5230\u4e86\u9ad8\u8d28\u91cf\u7684\u6837\u672c \u6211\u4eec\u4e5f\u8981\u628a\u8fd9\u90e8\u5206\u7684\u9884\u6d4b\u4fe1\u606f\u52a0\u5165\u6b63\u6837\u672c\u4e2d # \u9664\u4e86target\u6240\u5728\u7684\u5f53\u524d\u683c\u5b50\u5916, \u8fd8\u67092\u4e2a\u683c\u5b50\u5bf9\u76ee\u6807\u8fdb\u884c\u68c0\u6d4b(\u8ba1\u7b97\u635f\u5931) # \u4e5f\u5c31\u662f\u8bf4\u4e00\u4e2a\u76ee\u6807\u9700\u89813\u4e2a\u683c\u5b50\u53bb\u9884\u6d4b(\u8ba1\u7b97\u635f\u5931) # \u9996\u5148\u5f53\u524d\u683c\u5b50\u662f\u5176\u4e2d1\u4e2a \u518d\u4ece\u5f53\u524d\u683c\u5b50\u7684\u4e0a\u4e0b\u5de6\u53f3\u56db\u4e2a\u683c\u5b50\u4e2d\u9009\u62e92\u4e2a # \u7528\u8fd9\u4e09\u4e2a\u683c\u5b50\u53bb\u9884\u6d4b\u8fd9\u4e2a\u76ee\u6807(\u8ba1\u7b97\u635f\u5931) # feature map\u4e0a\u7684\u539f\u70b9\u5728\u5de6\u4e0a\u89d2 \u5411\u53f3\u4e3ax\u8f74\u6b63\u5750\u6807 \u5411\u4e0b\u4e3ay\u8f74\u6b63\u5750\u6807 # grid xy \u53d6target\u4e2d\u5fc3\u7684\u5750\u6807xy(\u76f8\u5bf9feature map\u5de6\u4e0a\u89d2\u7684\u5750\u6807) # gxy.shape = [555, 2] gxy = t [:, 2 : 4 ] # grid xy # inverse \u5f97\u5230target\u4e2d\u5fc3\u70b9\u76f8\u5bf9\u4e8e\u53f3\u4e0b\u89d2\u7684\u5750\u6807 gain[[2, 3]]\u4e3a\u5f53\u524dfeature map\u7684wh # gxi.shape = [555, 2] gxi = gain [[ 2 , 3 ]] - gxy # inverse # \u7b5b\u9009\u4e2d\u5fc3\u5750\u6807\u8ddd\u79bb\u5f53\u524dgrid_cell\u7684\u5de6\u3001\u4e0a\u65b9\u504f\u79fb\u5c0f\u4e8eg=0.5 # \u4e14 \u4e2d\u5fc3\u5750\u6807\u5fc5\u987b\u5927\u4e8e1(\u5750\u6807\u4e0d\u80fd\u5728\u8fb9\u4e0a \u6b64\u65f6\u5c31\u6ca1\u67094\u4e2a\u683c\u5b50\u4e86) # j: [555] bool \u5982\u679c\u662fTrue\u8868\u793a\u5f53\u524dtarget\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u683c\u5b50\u7684\u5de6\u8fb9\u683c\u5b50\u4e5f\u5bf9\u8be5target\u8fdb\u884c\u56de\u5f52(\u540e\u7eed\u8fdb\u884c\u8ba1\u7b97\u635f\u5931) # k: [555] bool \u5982\u679c\u662fTrue\u8868\u793a\u5f53\u524dtarget\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u683c\u5b50\u7684\u4e0a\u8fb9\u683c\u5b50\u4e5f\u5bf9\u8be5target\u8fdb\u884c\u56de\u5f52(\u540e\u7eed\u8fdb\u884c\u8ba1\u7b97\u635f\u5931) j , k = (( gxy % 1 < g ) & ( gxy > 1 )) . T # \u7b5b\u9009\u4e2d\u5fc3\u5750\u6807\u8ddd\u79bb\u5f53\u524dgrid_cell\u7684\u53f3\u3001\u4e0b\u65b9\u504f\u79fb\u5c0f\u4e8eg=0.5 \u4e14 \u4e2d\u5fc3\u5750\u6807\u5fc5\u987b\u5927\u4e8e1(\u5750\u6807\u4e0d\u80fd\u5728\u8fb9\u4e0a \u6b64\u65f6\u5c31\u6ca1\u67094\u4e2a\u683c\u5b50\u4e86) # l: [555] bool \u5982\u679c\u662fTrue\u8868\u793a\u5f53\u524dtarget\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u683c\u5b50\u7684\u53f3\u8fb9\u683c\u5b50\u4e5f\u5bf9\u8be5target\u8fdb\u884c\u56de\u5f52(\u540e\u7eed\u8fdb\u884c\u8ba1\u7b97\u635f\u5931) # m: [555] bool \u5982\u679c\u662fTrue\u8868\u793a\u5f53\u524dtarget\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u683c\u5b50\u7684\u4e0b\u8fb9\u683c\u5b50\u4e5f\u5bf9\u8be5target\u8fdb\u884c\u56de\u5f52(\u540e\u7eed\u8fdb\u884c\u8ba1\u7b97\u635f\u5931) l , m = (( gxi % 1 < g ) & ( gxi > 1 )) . T # j.shape=[5, 555] j = flow . stack (( flow . ones_like ( j ), j , k , l , m )) # \u5f97\u5230\u7b5b\u9009\u540e\u6240\u6709\u683c\u5b50\u7684\u6b63\u6837\u672c \u683c\u5b50\u6570<=3*555 \u90fd\u4e0d\u5728\u8fb9\u4e0a\u7b49\u53f7\u6210\u7acb # t: [555, 7] -> \u590d\u5236 5 \u4efdtarget[5, 555, 7] \u5206\u522b\u5bf9\u5e94\u5f53\u524d\u683c\u5b50\u548c\u5de6\u4e0a\u53f3\u4e0b\u683c\u5b505\u4e2a\u683c\u5b50 # \u4f7f\u7528 j \u7b5b\u9009\u540e t \u7684\u5f62\u72b6: [1659, 7] t = t . repeat (( 5 , 1 , 1 ))[ j ] # flow.zeros_like(gxy)[None]: [1, 555, 2] off[:, None]: [5, 1, 2] => [5, 555, 2] # \u5f97\u5230\u6240\u6709\u7b5b\u9009\u540e\u7684\u7f51\u683c\u7684\u4e2d\u5fc3\u76f8\u5bf9\u4e8e\u8fd9\u4e2a\u8981\u9884\u6d4b\u7684\u771f\u5b9e\u6846\u6240\u5728\u7f51\u683c\u8fb9\u754c # \uff08\u5de6\u53f3\u4e0a\u4e0b\u8fb9\u6846\uff09\u7684\u504f\u79fb\u91cf\uff0c\u7136\u540e\u901a\u8fc7 j \u7b5b\u9009\u6700\u7ec8 offsets \u7684\u5f62\u72b6\u662f [1659, 2] offsets = ( flow . zeros_like ( gxy )[ None ] + off [:, None ])[ j ] else : t = targets [ 0 ] offsets = 0 # Define # bc.shape = [1659, 2] # gxy.shape = [1659, 2] # gwh.shape = [1659, 2] # a.shape = [1659, 1] bc , gxy , gwh , a = t . chunk ( 4 , 1 ) # (image, class), grid xy, grid wh, anchors # a, (b, c) = a.long().view(-1), bc.long().T # anchors, image, class # a.shape = [1659] # (b, c).shape = [1659, 2] a , ( b , c ) = ( a . contiguous () . long () . view ( - 1 ), bc . contiguous () . long () . T , ) # anchors, image, class # gij = (gxy - offsets).long() # \u9884\u6d4b\u771f\u5b9e\u6846\u7684\u7f51\u683c\u6240\u5728\u7684\u5de6\u4e0a\u89d2\u5750\u6807(\u6709\u5de6\u4e0a\u53f3\u4e0b\u7684\u7f51\u683c) # gij.shape = [1659, 2] gij = ( gxy - offsets ) . contiguous () . long () # \u8fd9\u91cc\u7684\u62c6\u5206\u6211\u4eec\u53ef\u4ee5\u7528\u4e0b\u9762\u7684\u793a\u4f8b\u4ee3\u7801\u6765\u8fdb\u884c\u89e3\u91ca\uff1a # import oneflow as flow # x = flow.randn(3, 2) # y, z = x.T # print(y.shape) # print(z.shape) # => oneflow.Size([3]) # => oneflow.Size([3]) # \u56e0\u6b64\uff1a # gi.shape = [1659] # gj.shape = [1659] gi , gj = gij . T # grid indices # Append # indices.append((b, a, gj.clamp_(0, shape[2] - 1), gi.clamp_(0, shape[3] - 1))) # image, anchor, grid # gi.shape = [1659] # gj.shape = [1659] gi = gi . clamp ( 0 , shape [ 3 ] - 1 ) gj = gj . clamp ( 0 , shape [ 2 ] - 1 ) # b: image index a: anchor index gj: \u7f51\u683c\u7684\u5de6\u4e0a\u89d2y\u5750\u6807 gi: \u7f51\u683c\u7684\u5de6\u4e0a\u89d2x\u5750\u6807 indices . append (( b , a , gj , gi )) # image, anchor, grid # tbix: xywh \u5176\u4e2dxy\u4e3a\u8fd9\u4e2atarget\u5bf9\u5f53\u524dgrid_cell\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\u91cf tbox . append ( flow . cat (( gxy - gij , gwh ), 1 )) # box anch . append ( anchors [ a ]) # anchors \u5bf9\u5e94\u7684\u6240\u6709anchors tcls . append ( c ) # class return tcls , tbox , indices , anch 6.3 __call__\u51fd\u6570 \u8fd9\u4e2a\u51fd\u6570\u76f8\u5f53\u4e8e forward \u51fd\u6570\uff0c\u5728\u8fd9\u4e2a\u51fd\u6570\u4e2d\u8fdb\u884c\u635f\u5931\u51fd\u6570\u7684\u524d\u5411\u4f20\u64ad\u3002 def __call__ ( self , p , targets ): # predictions, targets \"\"\" \u8fd9\u91cc\u901a\u8fc7\u8f93\u5165 p : list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) targets : targets.shape[314, 6] \u4e3a\u4f8b\u89e3\u6790 __call__ \u51fd\u6570 :params p: \u9884\u6d4b\u6846 \u7531\u6a21\u578b\u6784\u5efa\u4e2d\u7684 Detect \u5c42\u8fd4\u56de\u7684\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa\uff08\u6ce8\u610f\u662f\u8bad\u7ec3\u6a21\u5f0f\u624d\u8fd4\u56de\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa\uff09 tensor\u683c\u5f0f list\u5217\u8868 \u5b58\u653e\u4e09\u4e2atensor \u5bf9\u5e94\u7684\u662f\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa \u5982: ([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) [bs, anchor_num, grid_h, grid_w, xywh+class+classes] \u53ef\u4ee5\u770b\u51fa\u6765\u8fd9\u91cc\u7684\u9884\u6d4b\u503c p \u662f\u4e09\u4e2ayolo\u5c42\u6bcf\u4e2a grid_cell \u7684\u9884\u6d4b\u503c(\u6bcf\u4e2a grid_cell \u6709\u4e09\u4e2a\u9884\u6d4b\u503c), \u540e\u9762\u8981\u8fdb\u884c\u6b63\u6837\u672c\u7b5b\u9009 :params targets: \u6570\u636e\u589e\u5f3a\u540e\u7684\u771f\u5b9e\u6846 [314, 6] [num_object, batch_index+class+xywh] :params loss * bs: \u6574\u4e2abatch\u7684\u603b\u635f\u5931\uff08\u4e00\u4e2a\u5217\u8868\uff09 \u8fdb\u884c\u53cd\u5411\u4f20\u64ad :params flow.cat((lbox, lobj, lcls, loss)).detach(): \u56de\u5f52\u635f\u5931\u3001\u7f6e\u4fe1\u5ea6\u635f\u5931\u3001\u5206\u7c7b\u635f\u5931\u548c\u603b\u635f\u5931 \u8fd9\u4e2a\u53c2\u6570\u53ea\u7528\u6765\u53ef\u89c6\u5316\u53c2\u6570\u6216\u4fdd\u5b58\u4fe1\u606f \"\"\" # \u521d\u59cb\u5316\u5404\u4e2a\u90e8\u5206\u635f\u5931 \u59cb\u5316lcls, lbox, lobj\u4e09\u79cd\u635f\u5931\u503c tensor([0.]) # lcls.shape = [1] lcls = flow . zeros ( 1 , device = self . device ) # class loss # lbox.shape = [1] lbox = flow . zeros ( 1 , device = self . device ) # box loss # lobj.shape = [1] lobj = flow . zeros ( 1 , device = self . device ) # object loss # \u83b7\u5f97\u6807\u7b7e\u5206\u7c7b, \u8fb9\u6846, \u7d22\u5f15\uff0c anchors # \u6bcf\u4e00\u4e2a\u90fd\u662f\u5217\u8868\uff0c \u6709 feature map \u4e2a # \u90fd\u662f\u5f53\u524d\u8fd9\u4e2afeature map\u4e2d3\u4e2aanchor\u7b5b\u9009\u51fa\u7684\u6240\u6709\u7684target(3\u4e2agrid_cell\u8fdb\u884c\u9884\u6d4b) # tcls: \u8868\u793a\u8fd9\u4e2atarget\u6240\u5c5e\u7684class index # tbox: xywh \u5176\u4e2dxy\u4e3a\u8fd9\u4e2atarget\u5bf9\u5f53\u524dgrid_cell\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\u91cf # indices: b: \u8868\u793a\u8fd9\u4e2atarget\u5c5e\u4e8e\u7684image index # a: \u8868\u793a\u8fd9\u4e2atarget\u4f7f\u7528\u7684anchor index # gj: \u7ecf\u8fc7\u7b5b\u9009\u540e\u786e\u5b9a\u67d0\u4e2atarget\u5728\u67d0\u4e2a\u7f51\u683c\u4e2d\u8fdb\u884c\u9884\u6d4b(\u8ba1\u7b97\u635f\u5931) # gj\u8868\u793a\u8fd9\u4e2a\u7f51\u683c\u7684\u5de6\u4e0a\u89d2y\u5750\u6807 # gi: \u8868\u793a\u8fd9\u4e2a\u7f51\u683c\u7684\u5de6\u4e0a\u89d2x\u5750\u6807 # anch: \u8868\u793a\u8fd9\u4e2atarget\u6240\u4f7f\u7528anchor\u7684\u5c3a\u5ea6\uff08\u76f8\u5bf9\u4e8e\u8fd9\u4e2afeature map\uff09 # \u53ef\u80fd\u4e00\u4e2atarget\u4f1a\u4f7f\u7528\u5927\u5c0f\u4e0d\u540canchor\u8fdb\u884c\u8ba1\u7b97 \"\"\"shape p : list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) targets : [314, 6] tcls : list([1659], [1625], [921]) tbox : list([1659, 4], [1625, 4], [921, 4]) indices : list( list([1659],[1659],[1659],[1659]), list([1625],[1625],[1625],[1625]) , list([921],[921],[921],[921]) ) anchors : list([1659, 2], [1625, 2], [921, 2]) \"\"\" tcls , tbox , indices , anchors = self . build_targets ( p , targets ) # targets # Losses \u4f9d\u6b21\u904d\u5386\u4e09\u4e2afeature map\u7684\u9884\u6d4b\u8f93\u51fapi for i , pi in enumerate ( p ): # layer index, layer predictions # \u8fd9\u91cc\u901a\u8fc7 pi \u5f62\u72b6\u4e3a[16, 3, 80, 80, 85] \u8fdb\u884c\u89e3\u6790 \"\"\"shape b : [1659] a : [1659] gj : [1659] gi : [1659] \"\"\" b , a , gj , gi = indices [ i ] # image, anchor, gridy, gridx # tobj = flow.zeros( pi.shape[:4] , dtype=pi.dtype, device=self.device) # target obj # \u521d\u59cb\u5316target\u7f6e\u4fe1\u5ea6(\u5148\u5168\u662f\u8d1f\u6837\u672c \u540e\u9762\u518d\u7b5b\u9009\u6b63\u6837\u672c\u8d4b\u503c) # tobj.shape = [16, 3, 80, 80] tobj = flow . zeros (( pi . shape [: 4 ]), dtype = pi . dtype , device = self . device ) # target obj # n = 1659 n = b . shape [ 0 ] # number of targets if n : # \u7cbe\u786e\u5f97\u5230\u7b2c b \u5f20\u56fe\u7247\u7684\u7b2c a \u4e2a feature map \u7684 grid_cell(gi, gj) \u5bf9\u5e94\u7684\u9884\u6d4b\u503c # \u7528\u8fd9\u4e2a\u9884\u6d4b\u503c\u4e0e\u6211\u4eec\u7b5b\u9009\u7684\u8fd9\u4e2a grid_cell \u7684\u771f\u5b9e\u6846\u8fdb\u884c\u9884\u6d4b(\u8ba1\u7b97\u635f\u5931) # pxy, pwh, _, pcls = pi[b, a, gj, gi].tensor_split((2, 4, 5), dim=1) \"\"\"shape pxy : [1659, 2] pwh : [1659, 2] _ : [1659, 1] pcls : [1659, 80] \"\"\" pxy , pwh , _ , pcls = pi [ b , a , gj , gi ] . split (( 2 , 2 , 1 , self . nc ), 1 ) # target-subset of predictions # Regression loss \u53ea\u8ba1\u7b97\u6240\u6709\u6b63\u6837\u672c\u7684\u56de\u5f52\u635f\u5931 # \u65b0\u7684\u516c\u5f0f: pxy = [-0.5 + cx, 1.5 + cx] pwh = [0, 4pw] \u8fd9\u4e2a\u533a\u57df\u5185\u90fd\u662f\u6b63\u6837\u672c # Get more positive samples, accelerate convergence and be more stable # pxy.shape = [1659, 2] pxy = pxy . sigmoid () * 2 - 0.5 # https://github.com/ultralytics/yolov3/issues/168 # pwh.shape = [1659, 2] pwh = ( pwh . sigmoid () * 2 ) ** 2 * anchors [ i ] # \u548c\u8bba\u6587\u91cc\u4e0d\u540c \u8fd9\u91cc\u662f\u4f5c\u8005\u81ea\u5df1\u63d0\u51fa\u7684\u516c\u5f0f # pbox.shape = [1659, 4] pbox = flow . cat (( pxy , pwh ), 1 ) # predicted box # \u8fd9\u91cc\u7684tbox[i]\u4e2d\u7684xy\u662f\u8fd9\u4e2atarget\u5bf9\u5f53\u524dgrid_cell\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\u91cf[0,1] \u800cpbox.T\u662f\u4e00\u4e2a\u5f52\u4e00\u5316\u7684\u503c # \u5c31\u662f\u8981\u7528\u8fd9\u79cd\u65b9\u5f0f\u8bad\u7ec3 \u4f20\u56deloss \u4fee\u6539\u68af\u5ea6 \u8ba9pbox\u8d8a\u6765\u8d8a\u63a5\u8fd1tbox(\u504f\u79fb\u91cf) # iou.shape = [1659] iou = bbox_iou ( pbox , tbox [ i ], CIoU = True ) . squeeze () # iou(prediction, target) # lbox.shape = [1] lbox = lbox + ( 1.0 - iou ) . mean () # iou loss # Objectness # iou.detach() \u4e0d\u4f1a\u66f4\u65b0iou\u68af\u5ea6 iou\u5e76\u4e0d\u662f\u53cd\u5411\u4f20\u64ad\u7684\u53c2\u6570 \u6240\u4ee5\u4e0d\u9700\u8981\u53cd\u5411\u4f20\u64ad\u68af\u5ea6\u4fe1\u606f # iou.shape = [1659] iou = iou . detach () . clamp ( 0 ) . type ( tobj . dtype ) # \u8fd9\u91cc\u5bf9 iou \u8fdb\u884c\u6392\u5e8f\u518d\u505a\u4e00\u4e2a\u4f18\u5316\uff1a\u5f53\u4e00\u4e2a\u6b63\u6837\u672c\u51fa\u73b0\u591a\u4e2a GT \u7684\u60c5\u51b5\u4e5f\u5c31\u662f\u540c\u4e00\u4e2a grid \u4e2d\u6709\u4e24\u4e2a gt (\u5bc6\u96c6\u578b\u4e14\u5f62\u72b6\u5dee\u4e0d\u591a\u7269\u4f53) # There maybe several GTs match the same anchor when calculate ComputeLoss in the scene with dense targets if self . sort_obj_iou : # https://github.com/ultralytics/yolov5/issues/3605 # There maybe several GTs match the same anchor when calculate ComputeLoss in the scene with dense targets j = iou . argsort () # \u5982\u679c\u540c\u4e00\u4e2a grid \u51fa\u73b0\u4e24\u4e2a GT \u90a3\u4e48\u7ecf\u8fc7\u6392\u5e8f\u4e4b\u540e\u6bcf\u4e2a grid \u4e2d\u7684 score_iou \u90fd\u80fd\u4fdd\u8bc1\u662f\u6700\u5927\u7684 # (\u5c0f\u7684\u4f1a\u88ab\u8986\u76d6 \u56e0\u4e3a\u540c\u4e00\u4e2agrid\u5750\u6807\u80af\u5b9a\u76f8\u540c)\u90a3\u4e48\u4ece\u65f6\u95f4\u987a\u5e8f\u7684\u8bdd, \u6700\u540e\u4e00\u4e2a\u603b\u662f\u548c\u6700\u5927\u7684 iou \u53bb\u8ba1\u7b97 loss b , a , gj , gi , iou = b [ j ], a [ j ], gj [ j ], gi [ j ], iou [ j ] # \u9884\u6d4b\u4fe1\u606f\u6709\u7f6e\u4fe1\u5ea6 \u4f46\u662f\u771f\u5b9e\u6846\u4fe1\u606f\u662f\u6ca1\u6709\u7f6e\u4fe1\u5ea6\u7684 \u6240\u4ee5\u9700\u8981\u6211\u4eec\u4eba\u4e3a\u7684\u7ed9\u4e00\u4e2a\u6807\u51c6\u7f6e\u4fe1\u5ea6 # self.gr\u662fiou ratio [0, 1] self.gr\u8d8a\u5927\u7f6e\u4fe1\u5ea6\u8d8a\u63a5\u8fd1iou self.gr\u8d8a\u5c0f\u7f6e\u4fe1\u5ea6\u8d8a\u63a5\u8fd11(\u4eba\u4e3a\u52a0\u5927\u8bad\u7ec3\u96be\u5ea6) if self . gr < 1 : iou = ( 1.0 - self . gr ) + self . gr * iou tobj [ b , a , gj , gi ] = iou # iou ratio # Classification \u53ea\u8ba1\u7b97\u6240\u6709\u6b63\u6837\u672c\u7684\u5206\u7c7b\u635f\u5931 # self.nc = 80 if self . nc > 1 : # cls loss (only if multiple classes) # targets \u539f\u672c\u8d1f\u6837\u672c\u662f0 \u8fd9\u91cc\u4f7f\u7528smooth label \u5c31\u662fcn # t.shape = [1659,80] t = flow . full_like ( pcls , self . cn , device = self . device ) # targets # t[range(n), tcls[i]] = self.cp \u7b5b\u9009\u5230\u7684\u6b63\u6837\u672c\u5bf9\u5e94\u4f4d\u7f6e\u503c\u662fcp t [ flow . arange ( n , device = self . device ), tcls [ i ]] = self . cp # lcls.shape = [1] lcls = lcls + self . BCEcls ( pcls , t ) # BCE # Append targets to text file # with open('targets.txt', 'a') as file: # [file.write('%11.5g ' * 4 % tuple(x) + '\\n') for x in flow.cat((txy[i], twh[i]), 1)] # \u7f6e\u4fe1\u5ea6\u635f\u5931\u662f\u7528\u6240\u6709\u6837\u672c(\u6b63\u6837\u672c + \u8d1f\u6837\u672c)\u4e00\u8d77\u8ba1\u7b97\u635f\u5931\u7684 obji = self . BCEobj ( pi [ ... , 4 ], tobj ) # \u6bcf\u4e2a feature map \u7684\u7f6e\u4fe1\u5ea6\u635f\u5931\u6743\u91cd\u4e0d\u540c \u8981\u4e58\u4ee5\u76f8\u5e94\u7684\u6743\u91cd\u7cfb\u6570 self.balance[i] # \u4e00\u822c\u6765\u8bf4\uff0c\u68c0\u6d4b\u5c0f\u7269\u4f53\u7684\u96be\u5ea6\u5927\u4e00\u70b9\uff0c\u6240\u4ee5\u4f1a\u589e\u52a0\u5927\u7279\u5f81\u56fe\u7684\u635f\u5931\u7cfb\u6570\uff0c\u8ba9\u6a21\u578b\u66f4\u52a0\u4fa7\u91cd\u5c0f\u7269\u4f53\u7684\u68c0\u6d4b lobj = lobj + ( obji * self . balance [ i ]) # obj loss if self . autobalance : # \u81ea\u52a8\u66f4\u65b0\u5404\u4e2a feature map \u7684\u7f6e\u4fe1\u5ea6\u635f\u5931\u7cfb\u6570 self . balance [ i ] = self . balance [ i ] * 0.9999 + 0.0001 / obji . detach () . item () if self . autobalance : self . balance = [ x / self . balance [ self . ssi ] for x in self . balance ] # \u6839\u636e\u8d85\u53c2\u4e2d\u7684\u635f\u5931\u6743\u91cd\u53c2\u6570 \u5bf9\u5404\u4e2a\u635f\u5931\u8fdb\u884c\u5e73\u8861 \u9632\u6b62\u603b\u635f\u5931\u88ab\u67d0\u4e2a\u635f\u5931\u4e3b\u5bfc \"\"\"shape lbox : [1] lobj : [1] lcls : [1] \"\"\" lbox *= self . hyp [ \"box\" ] lobj *= self . hyp [ \"obj\" ] lcls *= self . hyp [ \"cls\" ] bs = tobj . shape [ 0 ] # batch size # loss = lbox + lobj + lcls \u5e73\u5747\u6bcf\u5f20\u56fe\u7247\u7684\u603b\u635f\u5931 # loss * bs: \u6574\u4e2abatch\u7684\u603b\u635f\u5931 # .detach() \u5229\u7528\u635f\u5931\u503c\u8fdb\u884c\u53cd\u5411\u4f20\u64ad return ( lbox + lobj + lcls ) * bs , flow . cat (( lbox , lobj , lcls )) . detach () \u4f7f\u7528\uff1a train.py\u521d\u59cb\u5316\u635f\u5931\u51fd\u6570\u7c7b\uff1a compute_loss = ComputeLoss(model) # init loss class \u8c03\u7528\u6267\u884c\u635f\u5931\u51fd\u6570\uff0c\u8ba1\u7b97\u635f\u5931\uff1a loss, loss_items = compute_loss(pred, targets.to(device)) # loss scaled by batch_size \u603b\u7ed3 \u6211\u4eec\u8ba4\u4e3a yolov5/one-yolov5 \u5de5\u7a0b\u5b9e\u73b0\u6700\u91cd\u8981\u7684\u5c31\u662f ComputeLoss \u7c7b\u4e86\u3002\u4f46\u4ee3\u7801\u5176\u5b9e\u8fd8\u662f\u975e\u5e38\u96be\u7684\uff0c\u5c24\u5176 build_target \u91cc\u9762\u82b1\u91cc\u80e1\u54e8\u7684\u77e9\u9635\u64cd\u4f5c\u548cslice\u64cd\u4f5c\u975e\u5e38\u591a\uff0c pytorch\u6216\u8005oneflow\u4e0d\u719f\u7684\u4eba\u4f1a\u770b\u7684\u6bd4\u8f83\u75db\u82e6\uff0c\u4f46\u662f\u5982\u679c\u4f60\u575a\u6301\u770b\u4e0b\u6765\u6211\u4eec\u7684\u6ce8\u91ca\u518d\u52a0\u4e0a\u81ea\u5df1\u7684\u51a5\u60f3\uff0c\u5e94\u8be5\u662f\u80fd\u60f3\u660e\u767d\u7684\u3002 Reference \u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011loss.py \u76ee\u6807\u68c0\u6d4b YOLOv5 - Sample Assignment yolov5--loss.py --v5.0\u7248\u672c-\u6700\u65b0\u4ee3\u7801\u8be6\u7ec6\u89e3\u91ca-2021-7-1\u66f4\u65b0 YOLO-V3-SPP \u8bad\u7ec3\u65f6\u6b63\u6837\u672c\u7b5b\u9009\u6e90\u7801\u89e3\u6790\u4e4bbuild_targets YOLOv5-4.0-loss.py \u6e90\u4ee3\u7801\u5bfc\u8bfb(\u635f\u5931\u51fd\u6570\uff09 yolov5 \u4ee3\u7801\u89e3\u8bfb \u635f\u5931\u51fd\u6570 loss.py","title":"loss.py"},{"location":"source_code_interpretation/utils/loss_py.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6e90\u7801\u89e3\u8bfb\uff1a loss.py \u5176\u4e2d\u4e00\u4e9b\u5e38\u89c1\u7684\u635f\u5931\u51fd\u6570\u5305\u62ec\uff1a \u5206\u7c7b\u635f\u5931(cls_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u5224\u65ad\u6a21\u578b\u662f\u5426\u80fd\u591f\u51c6\u786e\u5730\u8bc6\u522b\u51fa\u56fe\u50cf\u4e2d\u7684\u5bf9\u8c61\uff0c\u5e76\u5c06\u5176\u5206\u7c7b\u5230\u6b63\u786e\u7684\u7c7b\u522b\u4e2d\u3002 \u7f6e\u4fe1\u5ea6\u635f\u5931(obj_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u7684\u6846\uff08\u5373\u5305\u542b\u5bf9\u8c61\u7684\u77e9\u5f62\uff09\u4e0e\u771f\u5b9e\u6846\u4e4b\u95f4\u7684\u5dee\u5f02\u3002 \u8fb9\u754c\u6846\u635f\u5931(box_loss)\uff1a\u8be5\u635f\u5931\u7528\u4e8e\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4e0e\u771f\u5b9e\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u8fd9\u6709\u52a9\u4e8e\u786e\u4fdd\u6a21\u578b\u80fd\u591f\u51c6\u786e\u5730\u5b9a\u4f4d\u5bf9\u8c61\u3002 \u8fd9\u4e9b\u635f\u5931\u51fd\u6570\u5728\u8bad\u7ec3\u6a21\u578b\u65f6\u88ab\u7ec4\u5408\u4f7f\u7528\uff0c\u4ee5\u4f18\u5316\u6a21\u578b\u7684\u6027\u80fd\u3002\u901a\u8fc7\u4f7f\u7528\u8fd9\u4e9b\u635f\u5931\u51fd\u6570\uff0cYOLOv5\u53ef\u4ee5\u51c6\u786e\u5730\u8bc6\u522b\u56fe\u50cf\u4e2d\u7684\u5bf9\u8c61\uff0c\u5e76\u5c06\u5176\u5b9a\u4f4d\u5230\u56fe\u50cf\u4e2d\u7684\u5177\u4f53\u4f4d\u7f6e\u3002","title":"\u524d\u8a00"},{"location":"source_code_interpretation/utils/loss_py.html#1","text":"import oneflow as flow import oneflow.nn as nn from utils.metrics import bbox_iou from utils.oneflow_utils import de_parallel","title":"1. \u5bfc\u5165\u9700\u8981\u7684\u5305"},{"location":"source_code_interpretation/utils/loss_py.html#2-smooth_bce","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u4e00\u4e2a\u6807\u7b7e\u5e73\u6ed1\u7684\u7b56\u7565(trick)\uff0c\u662f\u4e00\u79cd\u5728 \u5206\u7c7b/\u68c0\u6d4b \u95ee\u9898\u4e2d\uff0c\u9632\u6b62\u8fc7\u62df\u5408\u7684\u65b9\u6cd5\u3002 \u5982\u679c\u8981\u8be6\u7ec6\u7406\u89e3\u8fd9\u4e2a\u7b56\u7565\u7684\u539f\u7406\uff0c\u8bf7\u53c2\u9605\u535a\u6587: \u300atrick 1\u300bLabel Smoothing\uff08\u6807\u7b7e\u5e73\u6ed1\uff09\u2014\u2014 \u5206\u7c7b\u95ee\u9898\u4e2d\u9519\u8bef\u6807\u6ce8\u7684\u4e00\u79cd\u89e3\u51b3\u65b9\u6cd5. smooth_BCE\u51fd\u6570\u4ee3\u7801: # \u6807\u7b7e\u5e73\u6ed1 def smooth_BCE ( eps = 0.1 ): # https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441 \"\"\"\u7528\u5728ComputeLoss\u7c7b\u4e2d \u6807\u7b7e\u5e73\u6ed1\u64cd\u4f5c [1, 0] => [0.95, 0.05] :params eps: \u5e73\u6ed1\u53c2\u6570 :return positive, negative label smoothing BCE targets \u4e24\u4e2a\u503c\u5206\u522b\u4ee3\u8868\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\u7684\u6807\u7b7e\u53d6\u503c \u539f\u5148\u7684\u6b63\u6837\u672c=1 \u8d1f\u6837\u672c=0 \u6539\u4e3a \u6b63\u6837\u672c=1.0 - 0.5 * eps \u8d1f\u6837\u672c=0.5 * eps \"\"\" # return positive, negative label smoothing BCE targets return 1.0 - 0.5 * eps , 0.5 * eps \u901a\u5e38\u4f1a\u7528\u5728\u5206\u7c7b\u635f\u5931\u5f53\u4e2d\uff0c\u5982\u4e0bComputeLoss\u7c7b\u7684__init__\u51fd\u6570\u5b9a\u4e49\uff1a self.cp, self.cn = smooth_BCE(eps=h.get(\"label_smoothing\", 0.0)) # positive, negative BCE targets ComputeLoss\u7c7b\u7684__call__\u51fd\u6570\u8c03\u7528\uff1a # Classification if self.nc > 1: # cls loss (only if multiple classes) t = flow.full_like(pcls, self.cn, device=self.device) # targets # t[range(n), tcls[i]] = self.cp t[flow.arange(n, device=self.device), tcls[i]] = self.cp lcls = lcls + self.BCEcls(pcls, t) # BCE","title":"2. smooth_BCE"},{"location":"source_code_interpretation/utils/loss_py.html#3-bceblurwithlogitsloss","text":"\u8fd9\u4e2a\u51fd\u6570\u662fBCE\u51fd\u6570\u7684\u4e00\u4e2a\u66ff\u4ee3\uff0c\u662fyolov5\u4f5c\u8005\u7684\u4e00\u4e2a\u5b9e\u9a8c\u6027\u7684\u51fd\u6570\uff0c\u53ef\u4ee5\u81ea\u5df1\u8bd5\u8bd5\u6548\u679c\u3002 \u4f7f\u7528\u8d77\u6765\u76f4\u63a5\u5728ComputeLoss\u7c7b\u7684__init__\u51fd\u6570\u4e2d\u66ff\u4ee3\u4f20\u7edf\u7684BCE\u51fd\u6570\u5373\u53ef\uff1a class BCEBlurWithLogitsLoss ( nn . Module ): \"\"\"\u7528\u5728ComputeLoss\u7c7b\u7684__init__\u51fd\u6570\u4e2d BCEwithLogitLoss() with reduced missing label effects. https://github.com/ultralytics/yolov5/issues/1030 The idea was to reduce the effects of false positive (missing labels) \u5c31\u662f\u68c0\u6d4b\u6210\u6b63\u6837\u672c\u4e86 \u4f46\u662f\u68c0\u6d4b\u9519\u4e86 \"\"\" def __init__ ( self , alpha = 0.05 ): super ( BCEBlurWithLogitsLoss , self ) . __init__ () self . loss_fcn = nn . BCEWithLogitsLoss ( reduction = 'none' ) # must be nn.BCEWithLogitsLoss() self . alpha = alpha def forward ( self , pred , true ): loss = self . loss_fcn ( pred , true ) pred = flow . sigmoid ( pred ) # prob from logits # dx = [-1, 1] \u5f53pred=1 true=0\u65f6(\u7f51\u7edc\u9884\u6d4b\u8bf4\u8fd9\u91cc\u6709\u4e2aobj\u4f46\u662fgt\u8bf4\u8fd9\u91cc\u6ca1\u6709), dx=1 => alpha_factor=0 => loss=0 # \u8fd9\u79cd\u5c31\u662f\u68c0\u6d4b\u6210\u6b63\u6837\u672c\u4e86\u4f46\u662f\u68c0\u6d4b\u9519\u4e86\uff08false positive\uff09\u6216\u8005missing label\u7684\u60c5\u51b5 \u8fd9\u79cd\u60c5\u51b5\u4e0d\u5e94\u8be5\u8fc7\u591a\u7684\u60e9\u7f5a->loss=0 dx = pred - true # reduce only missing label effects # \u5982\u679c\u91c7\u6837\u7edd\u5bf9\u503c\u7684\u8bdd \u4f1a\u51cf\u8f7bpred\u548cgt\u5dee\u5f02\u8fc7\u5927\u800c\u9020\u6210\u7684\u5f71\u54cd # dx = (pred - true).abs() # reduce missing label and false label effects alpha_factor = 1 - flow . exp (( dx - 1 ) / ( self . alpha + 1e-4 )) loss *= alpha_factor return loss . mean ()","title":"3. BCEBlurWithLogitsLoss"},{"location":"source_code_interpretation/utils/loss_py.html#4-focalloss","text":"FocalLoss\u635f\u5931\u51fd\u6570\u6765\u81ea Kaiming He\u57282017\u5e74\u53d1\u8868\u7684\u4e00\u7bc7\u8bba\u6587\uff1aFocal Loss for Dense Object Detection. \u8fd9\u7bc7\u8bba\u6587\u8bbe\u8ba1\u7684\u4e3b\u8981\u601d\u8def: \u5e0c\u671b\u90a3\u4e9bhard examples\u5bf9\u635f\u5931\u7684\u8d21\u732e\u53d8\u5927\uff0c\u4f7f\u7f51\u7edc\u66f4\u503e\u5411\u4e8e\u4ece\u8fd9\u4e9b\u6837\u672c\u4e0a\u5b66\u4e60\u3002\u9632\u6b62\u7531\u4e8eeasy examples\u8fc7\u591a\uff0c\u4e3b\u5bfc\u6574\u4e2a\u635f\u5931\u51fd\u6570\u3002 \u4f18\u70b9\uff1a \u89e3\u51b3\u4e86one-stage object detection\u4e2d\u56fe\u7247\u4e2d\u6b63\u8d1f\u6837\u672c\uff08\u524d\u666f\u548c\u80cc\u666f\uff09\u4e0d\u5747\u8861\u7684\u95ee\u9898\uff1b \u964d\u4f4e\u7b80\u5355\u6837\u672c\u7684\u6743\u91cd\uff0c\u4f7f\u635f\u5931\u51fd\u6570\u66f4\u5173\u6ce8\u56f0\u96be\u6837\u672c\uff1b \u51fd\u6570\u516c\u5f0f\uff1a \\(F L\\left(p_{t}\\right)=-\\alpha_{t}\\left(1-p_{t}\\right)^{\\gamma} \\log \\left(p_{t}\\right)\\) \\(\\begin{array}{c} p_{t} = \\left\\{\\begin{array}{ll} p & y = 1 \\\\ 1-p & \\text { \u5176\u4ed6 } \\end{array}\\right. \\end{array}\\) \\(\\alpha_{t}=\\left\\{\\begin{array}{ll} \\alpha & y=1(\\text { \u6b63\u6837\u672c }) \\\\ 1-\\alpha & \\text { \u5176\u4ed6 }(\\text { \u8d1f\u6837\u672c }) \\end{array} ; \\text { \u5176\u4e2d } \\alpha \\in[0,1]\\right.\\) \\(\\begin{array}{c} \\text { \u5176\u4e2d } \\alpha_{t} \\text { \u6765\u534f\u8c03\u6b63\u8d1f\u6837\u672c\u4e4b\u95f4\u7684\u5e73\u8861\uff0c } \\gamma \\text { \u6765\u964d\u4f4e\u7b80\u5355\u6837\u672c\u7684\u6743\u91cd\uff0c\u4f7f\u635f\u5931\u51fd\u6570\u66f4\u5173\u6ce8\u56f0\u96be\u6837\u672c\u3002 } \\end{array}\\) FocalLoss\u51fd\u6570\u4ee3\u7801\uff1a class FocalLoss ( nn . Module ): \"\"\"\u7528\u5728\u4ee3\u66ff\u539f\u672c\u7684BCEcls\uff08\u5206\u7c7b\u635f\u5931\uff09\u548cBCEobj\uff08\u7f6e\u4fe1\u5ea6\u635f\u5931\uff09 Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5) \u8bba\u6587: https://arxiv.org/abs/1708.02002 https://blog.csdn.net/qq_38253797/article/details/116292496 TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py \"\"\" # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5) def __init__ ( self , loss_fcn , gamma = 1.5 , alpha = 0.25 ): super () . __init__ () self . loss_fcn = loss_fcn # must be nn.BCEWithLogitsLoss() \u5b9a\u4e49\u4e3a\u591a\u5206\u7c7b\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 self . gamma = gamma # \u53c2\u6570gamma \u7528\u4e8e\u524a\u5f31\u7b80\u5355\u6837\u672c\u5bf9loss\u7684\u8d21\u732e\u7a0b\u5ea6 self . alpha = alpha # \u53c2\u6570alpha \u7528\u4e8e\u5e73\u8861\u6b63\u8d1f\u6837\u672c\u4e2a\u6570\u4e0d\u5747\u8861\u7684\u95ee\u9898 self . reduction = loss_fcn . reduction # self.reduction: \u63a7\u5236FocalLoss\u635f\u5931\u8f93\u51fa\u6a21\u5f0f sum/mean/none \u9ed8\u8ba4\u662fMean # focalloss\u4e2d\u7684BCE\u51fd\u6570\u7684reduction='None' BCE\u4e0d\u4f7f\u7528Sum\u6216\u8005Mean # \u9700\u8981\u5c06Focal loss\u5e94\u7528\u4e8e\u6bcf\u4e00\u4e2a\u6837\u672c\u4e4b\u4e2d self . loss_fcn . reduction = \"none\" # required to apply FL to each element def forward ( self , pred , true ): # \u6b63\u5e38BCE\u7684loss: loss = -log(p_t) loss = self . loss_fcn ( pred , true ) # p_t = flow.exp(-loss) # loss *= self.alpha * (1.000001 - p_t) ** self.gamma # non-zero power for gradient stability # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py pred_prob = flow . sigmoid ( pred ) # prob from logits p_t = true * pred_prob + ( 1 - true ) * ( 1 - pred_prob ) alpha_factor = true * self . alpha + ( 1 - true ) * ( 1 - self . alpha ) modulating_factor = ( 1.0 - p_t ) ** self . gamma # \u8fd9\u91cc\u4ee3\u8868Focal loss\u4e2d\u7684\u6307\u6570\u9879 # \u8fd4\u56de\u6700\u7ec8\u7684loss=BCE * \u4e24\u4e2a\u53c2\u6570 (\u770b\u770b\u516c\u5f0f\u5c31\u884c\u4e86 \u548c\u516c\u5f0f\u4e00\u6a21\u4e00\u6837) loss = loss * alpha_factor * modulating_factor # \u6700\u540e\u9009\u62e9focalloss\u8fd4\u56de\u7684\u7c7b\u578b \u9ed8\u8ba4\u662fmean if self . reduction == \"mean\" : return loss . mean () elif self . reduction == \"sum\" : return loss . sum () else : # 'none' return loss \u8fd9\u4e2a\u51fd\u6570\u7528\u5728\u4ee3\u66ff\u539f\u672c\u7684BCEcls\u548cBCEobj: # Focal loss g = h [ \"fl_gamma\" ] # focal loss gamma g=0 \u4ee3\u8868\u4e0d\u7528focal loss if g > 0 : BCEcls , BCEobj = FocalLoss ( BCEcls , g ), FocalLoss ( BCEobj , g )","title":"4. FocalLoss"},{"location":"source_code_interpretation/utils/loss_py.html#5-qfocalloss","text":"QFocalLoss\u635f\u5931\u51fd\u6570\u6765\u81ea20\u5e74\u7684\u4e00\u7bc7\u6587\u7ae0\uff1a Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection. \u5982\u679c\u5bf9\u8fd9\u7bc7\u8bba\u6587\u611f\u5174\u8da3\u53ef\u4ee5\u770b\u770b\u5927\u795e\u535a\u5ba2\uff1a \u5927\u767d\u8bdd Generalized Focal Loss. \u516c\u5f0f: \\(\\mathbf{Q F L}(\\sigma)=-|y-\\sigma|^{\\beta}((1-y) \\log (1-\\sigma)+y \\log (\\sigma))\\) QFocalLoss\u51fd\u6570\u4ee3\u7801\uff1a class QFocalLoss ( nn . Module ): \"\"\"\u7528\u6765\u4ee3\u66ffFocalLoss QFocalLoss \u6765\u81eaGeneral Focal Loss\u8bba\u6587: https://arxiv.org/abs/2006.04388 Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5) \"\"\" # Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5) def __init__ ( self , loss_fcn , gamma = 1.5 , alpha = 0.25 ): super () . __init__ () self . loss_fcn = loss_fcn # must be nn.BCEWithLogitsLoss() self . gamma = gamma self . alpha = alpha self . reduction = loss_fcn . reduction self . loss_fcn . reduction = \"none\" # required to apply FL to each element def forward ( self , pred , true ): loss = self . loss_fcn ( pred , true ) pred_prob = flow . sigmoid ( pred ) # prob from logits alpha_factor = true * self . alpha + ( 1 - true ) * ( 1 - self . alpha ) modulating_factor = flow . abs ( true - pred_prob ) ** self . gamma loss = loss * ( alpha_factor * modulating_factor ) if self . reduction == \"mean\" : return loss . mean () elif self . reduction == \"sum\" : return loss . sum () else : # 'none' return loss \u4f7f\u7528 QFolcalLoss \u76f4\u63a5\u5728 ComputeLoss \u7c7b\u4e2d\u4f7f\u7528 QFolcalLoss \u66ff\u6362\u6389 FocalLoss \u5373\u53ef\uff1a (\u4e5f\u5c31\u662f\u8bf4\u7528 QFolcalLoss \u66ff\u6362\u5982\u4e0b\u56fe\u4ee3\u7801\u5904\u7684 FocalLoss )","title":"5. QFocalLoss"},{"location":"source_code_interpretation/utils/loss_py.html#6-computeloss","text":"","title":"6. ComputeLoss\u7c7b"},{"location":"source_code_interpretation/utils/loss_py.html#61-__init__","text":"sort_obj_iou = False # \u540e\u9762\u7b5b\u9009\u7f6e\u4fe1\u5ea6\u635f\u5931\u6b63\u6837\u672c\u7684\u65f6\u5019\u662f\u5426\u5148\u5bf9iou\u6392\u5e8f # Compute losses def __init__ ( self , model , autobalance = False ): # \u83b7\u53d6\u6a21\u578b\u6240\u5728\u7684\u8bbe\u5907 device = next ( model . parameters ()) . device # \u83b7\u53d6\u6a21\u578b\u7684\u8d85\u53c2\u6570 h = model . hyp # \u5b9a\u4e49\u5206\u7c7b\u635f\u5931\u548c\u7f6e\u4fe1\u5ea6\u635f\u5931 BCEcls = nn . BCEWithLogitsLoss ( pos_weight = flow . tensor ([ h [ \"cls_pw\" ]], device = device )) BCEobj = nn . BCEWithLogitsLoss ( pos_weight = flow . tensor ([ h [ \"obj_pw\" ]], device = device )) # \u6807\u7b7e\u5e73\u6ed1 eps=0\u4ee3\u8868\u4e0d\u505a\u6807\u7b7e\u5e73\u6ed1-> cp=1 cn=0 / eps!=0\u4ee3\u8868\u505a\u6807\u7b7e\u5e73\u6ed1 # cp\u4ee3\u8868\u6b63\u6837\u672c\u7684\u6807\u7b7e\u503c cn\u4ee3\u8868\u8d1f\u6837\u672c\u7684\u6807\u7b7e\u503c # \u8bf7\u53c2\u8003\uff1aClass label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3 self . cp , self . cn = smooth_BCE ( eps = h . get ( \"label_smoothing\" , 0.0 )) # positive, negative BCE targets # Focal loss g = h [ \"fl_gamma\" ] # Focal Loss \u7684\u8d85\u53c2\u6570 gamma if g > 0 : # \u5982\u679c g>0 \u5c06\u5206\u7c7b\u635f\u5931\u548c\u7f6e\u4fe1\u5ea6\u635f\u5931(BCE)\u90fd\u6362\u6210 FocalLoss \u635f\u5931\u51fd\u6570 BCEcls , BCEobj = FocalLoss ( BCEcls , g ), FocalLoss ( BCEobj , g ) # m: \u8fd4\u56de\u7684\u662f\u6a21\u578b\u76843\u4e2a\u68c0\u6d4b\u5934\u5206\u522b\u5bf9\u5e94\u4ea7\u751f\u76843\u4e2a\u8f93\u51fa\u7279\u5f81\u56fe m = de_parallel ( model ) . model [ - 1 ] # Detect() module \"\"\"self.balance \u7528\u6765\u5b9e\u73b0obj,box,cls loss\u4e4b\u95f4\u6743\u91cd\u7684\u5e73\u8861 {3: [4.0, 1.0, 0.4]} \u8868\u793a\u6709\u4e09\u4e2alayer\u7684\u8f93\u51fa\uff0c\u7b2c\u4e00\u4e2alayer\u7684weight\u662f4.0\uff0c\u7b2c\u4e8c\u4e2a1.0\uff0c\u7b2c\u4e09\u4e2a\u4ee5\u6b64\u7c7b\u63a8\u3002 \u5982\u679c\u67095\u4e2alayer\u7684\u8f93\u51fa\uff0c\u90a3\u4e48\u6743\u91cd\u5206\u522b\u662f[4.0, 1.0, 0.25, 0.06, 0.02] \"\"\" self . balance = { 3 : [ 4.0 , 1.0 , 0.4 ]} . get ( m . nl , [ 4.0 , 1.0 , 0.25 , 0.06 , 0.02 ]) # P3-P7 # \u4e09\u4e2a\u68c0\u6d4b\u5934\u7684\u4e0b\u91c7\u6837\u7387 m.stride: [8, 16, 32] .index(16): \u6c42\u51fa\u4e0b\u91c7\u6837\u7387 stride=16 \u7684\u7d22\u5f15 # \u8fd9\u4e2a\u53c2\u6570\u4f1a\u7528\u6765\u81ea\u52a8\u8ba1\u7b97\u66f4\u65b0 3 \u4e2a feature map \u7684\u7f6e\u4fe1\u5ea6\u635f\u5931\u7cfb\u6570 self.balance self . ssi = list ( m . stride ) . index ( 16 ) if autobalance else 0 # stride 16 index self . BCEcls , self . BCEobj , self . gr , self . hyp , self . autobalance = ( BCEcls , BCEobj , 1.0 , h , autobalance , ) self . na = m . na # number of anchors \u6bcf\u4e2agrid_cell\u7684anchor\u6570\u91cf = 3 self . nc = m . nc # number of classes \u6570\u636e\u96c6\u7684\u603b\u7c7b\u522b = 80 self . nl = m . nl # number of layers \u68c0\u6d4b\u5934\u7684\u4e2a\u6570 = 3 # anchors: \u5f62\u72b6 [3, 3, 2] \u4ee3\u8868 3 \u4e2a feature map \u6bcf\u4e2a feature map \u4e0a\u6709 3 \u4e2a anchor(w,h) # \u8fd9\u91cc\u7684 anchors \u5c3a\u5bf8\u662f\u76f8\u5bf9 feature map \u7684 self . anchors = m . anchors self . device = device","title":"6.1 __init__\u51fd\u6570"},{"location":"source_code_interpretation/utils/loss_py.html#62-build_targets","text":"\u8fd9\u4e2a\u51fd\u6570\u662f\u7528\u6765\u4e3a\u6240\u6709GT\u7b5b\u9009\u76f8\u5e94\u7684anchor\u6b63\u6837\u672c\u3002 \u7b5b\u9009\u6761\u4ef6\u662f\u6bd4\u8f83GT\u548canchor\u7684\u5bbd\u6bd4\u548c\u9ad8\u6bd4\uff0c\u5927\u4e8e\u4e00\u5b9a\u7684\u9608\u503c\u5c31\u662f\u8d1f\u6837\u672c\uff0c\u53cd\u4e4b\u6b63\u6837\u672c\u3002 \u7b5b\u9009\u5230\u7684\u6b63\u6837\u672c\u4fe1\u606f\uff08image_index, anchor_index, gridy, gridx\uff09\uff0c\u4f20\u5165 __call__ \u51fd\u6570\uff0c \u901a\u8fc7\u8fd9\u4e2a\u4fe1\u606f\u53bb\u7b5b\u9009 pred \u91cc\u6bcf\u4e2a grid \u9884\u6d4b\u5f97\u5230\u7684\u4fe1\u606f\uff0c\u4fdd\u7559\u5bf9\u5e94 grid_cell \u4e0a\u7684\u6b63\u6837\u672c\u3002 \u901a\u8fc7 build_targets \u7b5b\u9009\u7684 GT \u4e2d\u7684\u6b63\u6837\u672c\u548c pred \u7b5b\u9009\u51fa\u7684\u5bf9\u5e94\u4f4d\u7f6e\u7684\u9884\u6d4b\u6837\u672c \u8fdb\u884c\u8ba1\u7b97\u635f\u5931\u3002 \u8865\u5145\u7406\u89e3\uff1a \u8fd9\u4e2a\u51fd\u6570\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u6bcf\u4e2a GT \u5339\u914d\u5bf9\u5e94\u7684\u9ad8\u8d28\u91cf Anchor \u6b63\u6837\u672c\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c j = flow.max(r, 1. / r).max(2)[0] < self.hyp[\"anchor_t\"] \u8fd9\u6b65\u7684\u6bd4\u8f83\u662f\u4e3a\u4e86\u5c06 GT \u5206\u914d\u5230\u4e0d\u540c\u5c42\u4e0a\u53bb\u68c0\u6d4b\uff0c(\u8be6\u7ec6\u89e3\u91ca\u8bf7\u770b\u4e0b\u9762\u7684\u9010\u884c\u4ee3\u7801\u6ce8\u91ca) \u540e\u9762\u7684\u6b65\u9aa4\u662f\u4e3a\u4e86\u786e\u5b9a\u5728\u8fd9\u5c42\u68c0\u6d4b\u7684 GT \u4e2d\u5fc3\u5750\u6807\uff0c \u8fdb\u800c\u786e\u5b9a\u8fd9\u4e2a GT \u5728\u8fd9\u5c42\u54ea\u4e2a grid cell \u8fdb\u884c\u68c0\u6d4b\u3002 \u505a\u5230\u8fd9\u4e00\u6b65\u4e5f\u5c31\u505a\u5230\u4e86\u4e3a\u6bcf\u4e2a GT \u5339\u914d Anchor \u6b63\u6837\u672c\u7684\u76ee\u7684\u3002 # --------------------------------------------------------- # build_targets \u51fd\u6570\u7528\u4e8e\u83b7\u5f97\u5728\u8bad\u7ec3\u65f6\u8ba1\u7b97 loss \u6240\u9700\u8981\u7684\u76ee\u6807\u6846\uff0c\u4e5f\u5373\u6b63\u6837\u672c\u3002\u4e0eyolov3/v4\u7684\u4e0d\u540c\uff0cyolov5\u652f\u6301\u8de8\u7f51\u683c\u9884\u6d4b\u3002 # \u5bf9\u4e8e\u4efb\u4f55\u4e00\u4e2a GT bbox\uff0c\u4e09\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u90fd\u53ef\u80fd\u6709\u5148\u9a8c\u6846\u5339\u914d\uff0c\u6240\u4ee5\u8be5\u51fd\u6570\u8f93\u51fa\u7684\u6b63\u6837\u672c\u6846\u6bd4\u4f20\u5165\u7684 targets \uff08GT\u6846\uff09\u6570\u76ee\u591a # \u5177\u4f53\u5904\u7406\u8fc7\u7a0b: # (1)\u9996\u5148\u901a\u8fc7 bbox \u4e0e\u5f53\u524d\u5c42 anchor \u505a\u4e00\u904d\u8fc7\u6ee4\u3002\u5bf9\u4e8e\u4efb\u4f55\u4e00\u5c42\u8ba1\u7b97\u5f53\u524d bbox \u4e0e\u5f53\u524d\u5c42 anchor \u7684\u5339\u914d\u7a0b\u5ea6\uff0c\u4e0d\u91c7\u7528IoU\uff0c\u800c\u91c7\u7528shape\u6bd4\u4f8b\u3002\u5982\u679canchor\u4e0ebbox\u7684\u5bbd\u9ad8\u6bd4\u5dee\u8ddd\u5927\u4e8e4\uff0c\u5219\u8ba4\u4e3a\u4e0d\u5339\u914d\uff0c\u6b64\u65f6\u5ffd\u7565\u76f8\u5e94\u7684bbox\uff0c\u5373\u5f53\u505a\u80cc\u666f; # (2)\u6839\u636e\u7559\u4e0b\u7684bbox\uff0c\u5728\u4e0a\u4e0b\u5de6\u53f3\u56db\u4e2a\u7f51\u683c\u56db\u4e2a\u65b9\u5411\u6269\u589e\u91c7\u6837\uff08\u5373\u5bf9 bbox \u8ba1\u7b97\u843d\u5728\u7684\u7f51\u683c\u6240\u6709 anchors \u90fd\u8ba1\u7b97 loss(\u5e76\u4e0d\u662f\u76f4\u63a5\u548c GT \u6846\u6bd4\u8f83\u8ba1\u7b97 loss) ) # \u6ce8\u610f\u6b64\u65f6\u843d\u5728\u7f51\u683c\u4e0d\u518d\u662f\u4e00\u4e2a\uff0c\u800c\u662f\u9644\u8fd1\u7684\u591a\u4e2a\uff0c\u8fd9\u6837\u5c31\u589e\u52a0\u4e86\u6b63\u6837\u672c\u6570\u3002 # yolov5 \u6ca1\u6709 conf \u5206\u652f\u5ffd\u7565\u9608\u503c(ignore_thresh)\u7684\u64cd\u4f5c\uff0c\u800cyoloy3/v4\u6709\u3002 # -------------------------------------------------------- def build_targets ( self , p , targets ): \"\"\"\u6240\u6709GT\u7b5b\u9009\u76f8\u5e94\u7684anchor\u6b63\u6837\u672c \u8fd9\u91cc\u901a\u8fc7 p : list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) targets : targets.shape[314, 6] \u89e3\u6790 build_targets(self, p, targets):\u51fd\u6570 Build targets for compute_loss() :params p: p[i]\u7684\u4f5c\u7528\u53ea\u662f\u5f97\u5230\u6bcf\u4e2afeature map\u7684shape \u9884\u6d4b\u6846 \u7531\u6a21\u578b\u6784\u5efa\u4e2d\u7684\u4e09\u4e2a\u68c0\u6d4b\u5934Detector\u8fd4\u56de\u7684\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa tensor\u683c\u5f0f list\u5217\u8868 \u5b58\u653e\u4e09\u4e2atensor \u5bf9\u5e94\u7684\u662f\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa \u5982: list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) [bs, anchor_num, grid_h, grid_w, xywh+class+classes] \u53ef\u4ee5\u770b\u51fa\u6765\u8fd9\u91cc\u7684\u9884\u6d4b\u503cp\u662f\u4e09\u4e2ayolo\u5c42\u6bcf\u4e2agrid_cell(\u6bcf\u4e2agrid_cell\u6709\u4e09\u4e2a\u9884\u6d4b\u503c)\u7684\u9884\u6d4b\u503c,\u540e\u9762\u80af\u5b9a\u8981\u8fdb\u884c\u6b63\u6837\u672c\u7b5b\u9009 :params targets: \u6570\u636e\u589e\u5f3a\u540e\u7684\u771f\u5b9e\u6846 [63, 6] [num_target, image_index+class+xywh] xywh\u4e3a\u5f52\u4e00\u5316\u540e\u7684\u6846 :return tcls: \u8868\u793a\u8fd9\u4e2atarget\u6240\u5c5e\u7684class index tbox: xywh \u5176\u4e2dxy\u4e3a\u8fd9\u4e2atarget\u5bf9\u5f53\u524dgrid_cell\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\u91cf indices: b: \u8868\u793a\u8fd9\u4e2atarget\u5c5e\u4e8e\u7684image index a: \u8868\u793a\u8fd9\u4e2atarget\u4f7f\u7528\u7684anchor index gj: \u7ecf\u8fc7\u7b5b\u9009\u540e\u786e\u5b9a\u67d0\u4e2atarget\u5728\u67d0\u4e2a\u7f51\u683c\u4e2d\u8fdb\u884c\u9884\u6d4b(\u8ba1\u7b97\u635f\u5931) gj\u8868\u793a\u8fd9\u4e2a\u7f51\u683c\u7684\u5de6\u4e0a\u89d2y\u5750\u6807 gi: \u8868\u793a\u8fd9\u4e2a\u7f51\u683c\u7684\u5de6\u4e0a\u89d2x\u5750\u6807 anch: \u8868\u793a\u8fd9\u4e2atarget\u6240\u4f7f\u7528anchor\u7684\u5c3a\u5ea6\uff08\u76f8\u5bf9\u4e8e\u8fd9\u4e2afeature map\uff09 \u6ce8\u610f\u53ef\u80fd\u4e00\u4e2atarget\u4f1a\u4f7f\u7528\u5927\u5c0f\u4e0d\u540canchor\u8fdb\u884c\u8ba1\u7b97 \"\"\" # Build targets for compute_loss(), input targets(image,class,x,y,w,h) # na = 3 ; nt = 314 na , nt = self . na , targets . shape [ 0 ] # number of anchors, targets tcls , tbox , indices , anch = [], [], [], [] # gain.shape=[7] gain = flow . ones ( 7 , device = self . device ) # normalized to gridspace gain # ai.shape = (na,nt) \u751f\u6210anchor\u7d22\u5f15 # anchor\u7d22\u5f15\uff0c\u540e\u9762\u6709\u7528\uff0c\u7528\u4e8e\u8868\u793a\u5f53\u524dbbox\u548c\u5f53\u524d\u5c42\u7684\u54ea\u4e2aanchor\u5339\u914d # \u9700\u8981\u57283\u4e2aanchor\u4e0a\u90fd\u8fdb\u884c\u8bad\u7ec3 \u6240\u4ee5\u5c06\u6807\u7b7e\u8d4b\u503cna=3\u4e2a # ai\u4ee3\u88683\u4e2aanchor\u4e0a\u5728\u6240\u6709\u7684target\u5bf9\u5e94\u7684anchor\u7d22\u5f15 \u5c31\u662f\u7528\u6765\u6807\u8bb0\u4e0b\u5f53\u524d\u8fd9\u4e2atarget\u5c5e\u4e8e\u54ea\u4e2aanchor # [1, 3] -> [3, 1] -> [3, 314]=[na, nt] \u4e09\u884c \u7b2c\u4e00\u884c63\u4e2a0 \u7b2c\u4e8c\u884c63\u4e2a1 \u7b2c\u4e09\u884c63\u4e2a2 # ai.shape =[3, 314] ai = flow . arange ( na , device = self . device ) . float () . view ( na , 1 ) . repeat ( 1 , nt ) # same as .repeat_interleave(nt) # [314, 6] [3, 314] -> [3, 314, 6] [3, 314, 1] -> [3, 314, 7] 7: [image_index+class+xywh+anchor_index] # \u5bf9\u6bcf\u4e00\u4e2afeature map: \u8fd9\u4e00\u6b65\u662f\u5c06target\u590d\u5236\u4e09\u4efd \u5bf9\u5e94\u4e00\u4e2afeature map\u7684\u4e09\u4e2aanchor # \u5148\u5047\u8bbe\u6240\u6709\u7684target\u90fd\u7531\u8fd9\u5c42\u7684\u4e09\u4e2aanchor\u8fdb\u884c\u68c0\u6d4b(\u590d\u5236\u4e09\u4efd) \u518d\u8fdb\u884c\u7b5b\u9009 \u5e76\u5c06ai\u52a0\u8fdb\u53bb\u6807\u8bb0\u5f53\u524d\u662f\u54ea\u4e2aanchor\u7684target # targets.shape = [3, 314, 7] targets = flow . cat (( targets . repeat ( na , 1 , 1 ), ai [ ... , None ]), 2 ) # append anchor indices # \u8fd9\u4e24\u4e2a\u53d8\u91cf\u662f\u7528\u6765\u6269\u5c55\u6b63\u6837\u672c\u7684 \u56e0\u4e3a\u9884\u6d4b\u6846\u9884\u6d4b\u5230target\u6709\u53ef\u80fd\u4e0d\u6b62\u5f53\u524d\u7684\u683c\u5b50\u9884\u6d4b\u5230\u4e86 # \u53ef\u80fd\u5468\u56f4\u7684\u683c\u5b50\u4e5f\u9884\u6d4b\u5230\u4e86\u9ad8\u8d28\u91cf\u7684\u6837\u672c \u6211\u4eec\u4e5f\u8981\u628a\u8fd9\u90e8\u5206\u7684\u9884\u6d4b\u4fe1\u606f\u52a0\u5165\u6b63\u6837\u672c\u4e2d # \u8bbe\u7f6e\u7f51\u683c\u4e2d\u5fc3\u504f\u79fb\u91cf g = 0.5 # bias # \u9644\u8fd1\u76844\u4e2a\u6846 # \u4ee5\u81ea\u8eab + \u5468\u56f4\u5de6\u4e0a\u53f3\u4e0b4\u4e2a\u7f51\u683c = 5\u4e2a\u7f51\u683c \u7528\u6765\u8ba1\u7b97offsets off = ( flow . tensor ( [ [ 0 , 0 ], [ 1 , 0 ], [ 0 , 1 ], [ - 1 , 0 ], [ 0 , - 1 ], # j,k,l,m # [1, 1], [1, -1], [-1, 1], [-1, -1], # jk,jm,lk,lm ], device = self . device , ) . float () * g ) # offsets # \u5bf9\u6bcf\u4e2a\u68c0\u6d4b\u5c42\u8fdb\u884c\u5904\u7406 # \u904d\u5386\u4e09\u4e2afeature \u7b5b\u9009gt\u7684anchor\u6b63\u6837\u672c for i in range ( self . nl ): # self.nl: number of detection layers Detect\u7684\u4e2a\u6570 = 3 # anchors: \u5f53\u524dfeature map\u5bf9\u5e94\u7684\u4e09\u4e2aanchor\u5c3a\u5bf8(\u76f8\u5bf9feature map) [3, 2] anchors , shape = self . anchors [ i ], p [ i ] . shape # gain: \u4fdd\u5b58\u6bcf\u4e2a\u8f93\u51fafeature map\u7684\u5bbd\u9ad8 -> gain[2:6] = flow.tensor(shape)[[3, 2, 3, 2]] # [1, 1, 1, 1, 1, 1, 1] -> [1, 1, 112, 112, 112,112, 1]=image_index+class+xywh+anchor_index gain [ 2 : 6 ] = flow . tensor ( p [ i ] . shape , device = self . device )[[ 3 , 2 , 3 , 2 ]] . float () # xyxy gain # Match targets to anchors # t.shape = [3, 314, 7] \u5c06target\u4e2d\u7684xywh\u7684\u5f52\u4e00\u5316\u5c3a\u5ea6\u653e\u7f29\u5230\u76f8\u5bf9\u5f53\u524dfeature map\u7684\u5750\u6807\u5c3a\u5ea6 # [3, 314, image_index+class+xywh+anchor_index] t = targets * gain # shape(3,n,7) if nt : # \u5982\u679c\u6709\u76ee\u6807\u5c31\u5f00\u59cb\u5339\u914d # Matches # \u6240\u6709\u7684gt\u4e0e\u5f53\u524d\u5c42\u7684\u4e09\u4e2aanchor\u7684\u5bbd\u9ad8\u6bd4(w/w h/h) # r.shape = [3, 314, 2] r = t [ ... , 4 : 6 ] / anchors [:, None ] # wh ratio # \u7b5b\u9009\u6761\u4ef6 GT\u4e0eanchor\u7684\u5bbd\u6bd4\u6216\u9ad8\u6bd4\u8d85\u8fc7\u4e00\u5b9a\u7684\u9608\u503c \u5c31\u5f53\u4f5c\u8d1f\u6837\u672c # flow.max(r, 1. / r)=[3, 314, 2] \u7b5b\u9009\u51fa\u5bbd\u6bd4w1/w2 w2/w1 \u9ad8\u6bd4h1/h2 h2/h1\u4e2d\u6700\u5927\u7684\u90a3\u4e2a # .max(2)\u8fd4\u56de\u5bbd\u6bd4 \u9ad8\u6bd4\u4e24\u8005\u4e2d\u8f83\u5927\u7684\u4e00\u4e2a\u503c\u548c\u5b83\u7684\u7d22\u5f15 [0]\u8fd4\u56de\u8f83\u5927\u7684\u4e00\u4e2a\u503c # j.shape = [3, 314] False: \u5f53\u524danchor\u662f\u5f53\u524dgt\u7684\u8d1f\u6837\u672c True: \u5f53\u524danchor\u662f\u5f53\u524dgt\u7684\u6b63\u6837\u672c j = flow . max ( r , 1 / r ) . max ( 2 )[ 0 ] < self . hyp [ \"anchor_t\" ] # compare # yolov3 v4\u7684\u7b5b\u9009\u65b9\u6cd5: wh_iou GT\u4e0eanchor\u7684wh_iou\u8d85\u8fc7\u4e00\u5b9a\u7684\u9608\u503c\u5c31\u662f\u6b63\u6837\u672c # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t'] # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2)) # \u6839\u636e\u7b5b\u9009\u6761\u4ef6j, \u8fc7\u6ee4\u8d1f\u6837\u672c, \u5f97\u5230\u6240\u6709gt\u7684anchor\u6b63\u6837\u672c(batch_size\u5f20\u56fe\u7247) # \u77e5\u9053\u5f53\u524dgt\u7684\u5750\u6807 \u5c5e\u4e8e\u54ea\u5f20\u56fe\u7247 \u6b63\u6837\u672c\u5bf9\u5e94\u7684idx \u4e5f\u5c31\u5f97\u5230\u4e86\u5f53\u524dgt\u7684\u6b63\u6837\u672canchor # t: [3, 314, 7] -> [555, 7] [num_Positive_sample, image_index+class+xywh+anchor_index] t = t [ j ] # filter # Offsets \u7b5b\u9009\u5f53\u524d\u683c\u5b50\u5468\u56f4\u683c\u5b50 \u627e\u5230 2 \u4e2a\u79bbtarget\u4e2d\u5fc3\u6700\u8fd1\u7684\u4e24\u4e2a\u683c\u5b50 # \u53ef\u80fd\u5468\u56f4\u7684\u683c\u5b50\u4e5f\u9884\u6d4b\u5230\u4e86\u9ad8\u8d28\u91cf\u7684\u6837\u672c \u6211\u4eec\u4e5f\u8981\u628a\u8fd9\u90e8\u5206\u7684\u9884\u6d4b\u4fe1\u606f\u52a0\u5165\u6b63\u6837\u672c\u4e2d # \u9664\u4e86target\u6240\u5728\u7684\u5f53\u524d\u683c\u5b50\u5916, \u8fd8\u67092\u4e2a\u683c\u5b50\u5bf9\u76ee\u6807\u8fdb\u884c\u68c0\u6d4b(\u8ba1\u7b97\u635f\u5931) # \u4e5f\u5c31\u662f\u8bf4\u4e00\u4e2a\u76ee\u6807\u9700\u89813\u4e2a\u683c\u5b50\u53bb\u9884\u6d4b(\u8ba1\u7b97\u635f\u5931) # \u9996\u5148\u5f53\u524d\u683c\u5b50\u662f\u5176\u4e2d1\u4e2a \u518d\u4ece\u5f53\u524d\u683c\u5b50\u7684\u4e0a\u4e0b\u5de6\u53f3\u56db\u4e2a\u683c\u5b50\u4e2d\u9009\u62e92\u4e2a # \u7528\u8fd9\u4e09\u4e2a\u683c\u5b50\u53bb\u9884\u6d4b\u8fd9\u4e2a\u76ee\u6807(\u8ba1\u7b97\u635f\u5931) # feature map\u4e0a\u7684\u539f\u70b9\u5728\u5de6\u4e0a\u89d2 \u5411\u53f3\u4e3ax\u8f74\u6b63\u5750\u6807 \u5411\u4e0b\u4e3ay\u8f74\u6b63\u5750\u6807 # grid xy \u53d6target\u4e2d\u5fc3\u7684\u5750\u6807xy(\u76f8\u5bf9feature map\u5de6\u4e0a\u89d2\u7684\u5750\u6807) # gxy.shape = [555, 2] gxy = t [:, 2 : 4 ] # grid xy # inverse \u5f97\u5230target\u4e2d\u5fc3\u70b9\u76f8\u5bf9\u4e8e\u53f3\u4e0b\u89d2\u7684\u5750\u6807 gain[[2, 3]]\u4e3a\u5f53\u524dfeature map\u7684wh # gxi.shape = [555, 2] gxi = gain [[ 2 , 3 ]] - gxy # inverse # \u7b5b\u9009\u4e2d\u5fc3\u5750\u6807\u8ddd\u79bb\u5f53\u524dgrid_cell\u7684\u5de6\u3001\u4e0a\u65b9\u504f\u79fb\u5c0f\u4e8eg=0.5 # \u4e14 \u4e2d\u5fc3\u5750\u6807\u5fc5\u987b\u5927\u4e8e1(\u5750\u6807\u4e0d\u80fd\u5728\u8fb9\u4e0a \u6b64\u65f6\u5c31\u6ca1\u67094\u4e2a\u683c\u5b50\u4e86) # j: [555] bool \u5982\u679c\u662fTrue\u8868\u793a\u5f53\u524dtarget\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u683c\u5b50\u7684\u5de6\u8fb9\u683c\u5b50\u4e5f\u5bf9\u8be5target\u8fdb\u884c\u56de\u5f52(\u540e\u7eed\u8fdb\u884c\u8ba1\u7b97\u635f\u5931) # k: [555] bool \u5982\u679c\u662fTrue\u8868\u793a\u5f53\u524dtarget\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u683c\u5b50\u7684\u4e0a\u8fb9\u683c\u5b50\u4e5f\u5bf9\u8be5target\u8fdb\u884c\u56de\u5f52(\u540e\u7eed\u8fdb\u884c\u8ba1\u7b97\u635f\u5931) j , k = (( gxy % 1 < g ) & ( gxy > 1 )) . T # \u7b5b\u9009\u4e2d\u5fc3\u5750\u6807\u8ddd\u79bb\u5f53\u524dgrid_cell\u7684\u53f3\u3001\u4e0b\u65b9\u504f\u79fb\u5c0f\u4e8eg=0.5 \u4e14 \u4e2d\u5fc3\u5750\u6807\u5fc5\u987b\u5927\u4e8e1(\u5750\u6807\u4e0d\u80fd\u5728\u8fb9\u4e0a \u6b64\u65f6\u5c31\u6ca1\u67094\u4e2a\u683c\u5b50\u4e86) # l: [555] bool \u5982\u679c\u662fTrue\u8868\u793a\u5f53\u524dtarget\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u683c\u5b50\u7684\u53f3\u8fb9\u683c\u5b50\u4e5f\u5bf9\u8be5target\u8fdb\u884c\u56de\u5f52(\u540e\u7eed\u8fdb\u884c\u8ba1\u7b97\u635f\u5931) # m: [555] bool \u5982\u679c\u662fTrue\u8868\u793a\u5f53\u524dtarget\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u683c\u5b50\u7684\u4e0b\u8fb9\u683c\u5b50\u4e5f\u5bf9\u8be5target\u8fdb\u884c\u56de\u5f52(\u540e\u7eed\u8fdb\u884c\u8ba1\u7b97\u635f\u5931) l , m = (( gxi % 1 < g ) & ( gxi > 1 )) . T # j.shape=[5, 555] j = flow . stack (( flow . ones_like ( j ), j , k , l , m )) # \u5f97\u5230\u7b5b\u9009\u540e\u6240\u6709\u683c\u5b50\u7684\u6b63\u6837\u672c \u683c\u5b50\u6570<=3*555 \u90fd\u4e0d\u5728\u8fb9\u4e0a\u7b49\u53f7\u6210\u7acb # t: [555, 7] -> \u590d\u5236 5 \u4efdtarget[5, 555, 7] \u5206\u522b\u5bf9\u5e94\u5f53\u524d\u683c\u5b50\u548c\u5de6\u4e0a\u53f3\u4e0b\u683c\u5b505\u4e2a\u683c\u5b50 # \u4f7f\u7528 j \u7b5b\u9009\u540e t \u7684\u5f62\u72b6: [1659, 7] t = t . repeat (( 5 , 1 , 1 ))[ j ] # flow.zeros_like(gxy)[None]: [1, 555, 2] off[:, None]: [5, 1, 2] => [5, 555, 2] # \u5f97\u5230\u6240\u6709\u7b5b\u9009\u540e\u7684\u7f51\u683c\u7684\u4e2d\u5fc3\u76f8\u5bf9\u4e8e\u8fd9\u4e2a\u8981\u9884\u6d4b\u7684\u771f\u5b9e\u6846\u6240\u5728\u7f51\u683c\u8fb9\u754c # \uff08\u5de6\u53f3\u4e0a\u4e0b\u8fb9\u6846\uff09\u7684\u504f\u79fb\u91cf\uff0c\u7136\u540e\u901a\u8fc7 j \u7b5b\u9009\u6700\u7ec8 offsets \u7684\u5f62\u72b6\u662f [1659, 2] offsets = ( flow . zeros_like ( gxy )[ None ] + off [:, None ])[ j ] else : t = targets [ 0 ] offsets = 0 # Define # bc.shape = [1659, 2] # gxy.shape = [1659, 2] # gwh.shape = [1659, 2] # a.shape = [1659, 1] bc , gxy , gwh , a = t . chunk ( 4 , 1 ) # (image, class), grid xy, grid wh, anchors # a, (b, c) = a.long().view(-1), bc.long().T # anchors, image, class # a.shape = [1659] # (b, c).shape = [1659, 2] a , ( b , c ) = ( a . contiguous () . long () . view ( - 1 ), bc . contiguous () . long () . T , ) # anchors, image, class # gij = (gxy - offsets).long() # \u9884\u6d4b\u771f\u5b9e\u6846\u7684\u7f51\u683c\u6240\u5728\u7684\u5de6\u4e0a\u89d2\u5750\u6807(\u6709\u5de6\u4e0a\u53f3\u4e0b\u7684\u7f51\u683c) # gij.shape = [1659, 2] gij = ( gxy - offsets ) . contiguous () . long () # \u8fd9\u91cc\u7684\u62c6\u5206\u6211\u4eec\u53ef\u4ee5\u7528\u4e0b\u9762\u7684\u793a\u4f8b\u4ee3\u7801\u6765\u8fdb\u884c\u89e3\u91ca\uff1a # import oneflow as flow # x = flow.randn(3, 2) # y, z = x.T # print(y.shape) # print(z.shape) # => oneflow.Size([3]) # => oneflow.Size([3]) # \u56e0\u6b64\uff1a # gi.shape = [1659] # gj.shape = [1659] gi , gj = gij . T # grid indices # Append # indices.append((b, a, gj.clamp_(0, shape[2] - 1), gi.clamp_(0, shape[3] - 1))) # image, anchor, grid # gi.shape = [1659] # gj.shape = [1659] gi = gi . clamp ( 0 , shape [ 3 ] - 1 ) gj = gj . clamp ( 0 , shape [ 2 ] - 1 ) # b: image index a: anchor index gj: \u7f51\u683c\u7684\u5de6\u4e0a\u89d2y\u5750\u6807 gi: \u7f51\u683c\u7684\u5de6\u4e0a\u89d2x\u5750\u6807 indices . append (( b , a , gj , gi )) # image, anchor, grid # tbix: xywh \u5176\u4e2dxy\u4e3a\u8fd9\u4e2atarget\u5bf9\u5f53\u524dgrid_cell\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\u91cf tbox . append ( flow . cat (( gxy - gij , gwh ), 1 )) # box anch . append ( anchors [ a ]) # anchors \u5bf9\u5e94\u7684\u6240\u6709anchors tcls . append ( c ) # class return tcls , tbox , indices , anch","title":"6.2 build_targets"},{"location":"source_code_interpretation/utils/loss_py.html#63-__call__","text":"\u8fd9\u4e2a\u51fd\u6570\u76f8\u5f53\u4e8e forward \u51fd\u6570\uff0c\u5728\u8fd9\u4e2a\u51fd\u6570\u4e2d\u8fdb\u884c\u635f\u5931\u51fd\u6570\u7684\u524d\u5411\u4f20\u64ad\u3002 def __call__ ( self , p , targets ): # predictions, targets \"\"\" \u8fd9\u91cc\u901a\u8fc7\u8f93\u5165 p : list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) targets : targets.shape[314, 6] \u4e3a\u4f8b\u89e3\u6790 __call__ \u51fd\u6570 :params p: \u9884\u6d4b\u6846 \u7531\u6a21\u578b\u6784\u5efa\u4e2d\u7684 Detect \u5c42\u8fd4\u56de\u7684\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa\uff08\u6ce8\u610f\u662f\u8bad\u7ec3\u6a21\u5f0f\u624d\u8fd4\u56de\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa\uff09 tensor\u683c\u5f0f list\u5217\u8868 \u5b58\u653e\u4e09\u4e2atensor \u5bf9\u5e94\u7684\u662f\u4e09\u4e2ayolo\u5c42\u7684\u8f93\u51fa \u5982: ([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) [bs, anchor_num, grid_h, grid_w, xywh+class+classes] \u53ef\u4ee5\u770b\u51fa\u6765\u8fd9\u91cc\u7684\u9884\u6d4b\u503c p \u662f\u4e09\u4e2ayolo\u5c42\u6bcf\u4e2a grid_cell \u7684\u9884\u6d4b\u503c(\u6bcf\u4e2a grid_cell \u6709\u4e09\u4e2a\u9884\u6d4b\u503c), \u540e\u9762\u8981\u8fdb\u884c\u6b63\u6837\u672c\u7b5b\u9009 :params targets: \u6570\u636e\u589e\u5f3a\u540e\u7684\u771f\u5b9e\u6846 [314, 6] [num_object, batch_index+class+xywh] :params loss * bs: \u6574\u4e2abatch\u7684\u603b\u635f\u5931\uff08\u4e00\u4e2a\u5217\u8868\uff09 \u8fdb\u884c\u53cd\u5411\u4f20\u64ad :params flow.cat((lbox, lobj, lcls, loss)).detach(): \u56de\u5f52\u635f\u5931\u3001\u7f6e\u4fe1\u5ea6\u635f\u5931\u3001\u5206\u7c7b\u635f\u5931\u548c\u603b\u635f\u5931 \u8fd9\u4e2a\u53c2\u6570\u53ea\u7528\u6765\u53ef\u89c6\u5316\u53c2\u6570\u6216\u4fdd\u5b58\u4fe1\u606f \"\"\" # \u521d\u59cb\u5316\u5404\u4e2a\u90e8\u5206\u635f\u5931 \u59cb\u5316lcls, lbox, lobj\u4e09\u79cd\u635f\u5931\u503c tensor([0.]) # lcls.shape = [1] lcls = flow . zeros ( 1 , device = self . device ) # class loss # lbox.shape = [1] lbox = flow . zeros ( 1 , device = self . device ) # box loss # lobj.shape = [1] lobj = flow . zeros ( 1 , device = self . device ) # object loss # \u83b7\u5f97\u6807\u7b7e\u5206\u7c7b, \u8fb9\u6846, \u7d22\u5f15\uff0c anchors # \u6bcf\u4e00\u4e2a\u90fd\u662f\u5217\u8868\uff0c \u6709 feature map \u4e2a # \u90fd\u662f\u5f53\u524d\u8fd9\u4e2afeature map\u4e2d3\u4e2aanchor\u7b5b\u9009\u51fa\u7684\u6240\u6709\u7684target(3\u4e2agrid_cell\u8fdb\u884c\u9884\u6d4b) # tcls: \u8868\u793a\u8fd9\u4e2atarget\u6240\u5c5e\u7684class index # tbox: xywh \u5176\u4e2dxy\u4e3a\u8fd9\u4e2atarget\u5bf9\u5f53\u524dgrid_cell\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\u91cf # indices: b: \u8868\u793a\u8fd9\u4e2atarget\u5c5e\u4e8e\u7684image index # a: \u8868\u793a\u8fd9\u4e2atarget\u4f7f\u7528\u7684anchor index # gj: \u7ecf\u8fc7\u7b5b\u9009\u540e\u786e\u5b9a\u67d0\u4e2atarget\u5728\u67d0\u4e2a\u7f51\u683c\u4e2d\u8fdb\u884c\u9884\u6d4b(\u8ba1\u7b97\u635f\u5931) # gj\u8868\u793a\u8fd9\u4e2a\u7f51\u683c\u7684\u5de6\u4e0a\u89d2y\u5750\u6807 # gi: \u8868\u793a\u8fd9\u4e2a\u7f51\u683c\u7684\u5de6\u4e0a\u89d2x\u5750\u6807 # anch: \u8868\u793a\u8fd9\u4e2atarget\u6240\u4f7f\u7528anchor\u7684\u5c3a\u5ea6\uff08\u76f8\u5bf9\u4e8e\u8fd9\u4e2afeature map\uff09 # \u53ef\u80fd\u4e00\u4e2atarget\u4f1a\u4f7f\u7528\u5927\u5c0f\u4e0d\u540canchor\u8fdb\u884c\u8ba1\u7b97 \"\"\"shape p : list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85]) targets : [314, 6] tcls : list([1659], [1625], [921]) tbox : list([1659, 4], [1625, 4], [921, 4]) indices : list( list([1659],[1659],[1659],[1659]), list([1625],[1625],[1625],[1625]) , list([921],[921],[921],[921]) ) anchors : list([1659, 2], [1625, 2], [921, 2]) \"\"\" tcls , tbox , indices , anchors = self . build_targets ( p , targets ) # targets # Losses \u4f9d\u6b21\u904d\u5386\u4e09\u4e2afeature map\u7684\u9884\u6d4b\u8f93\u51fapi for i , pi in enumerate ( p ): # layer index, layer predictions # \u8fd9\u91cc\u901a\u8fc7 pi \u5f62\u72b6\u4e3a[16, 3, 80, 80, 85] \u8fdb\u884c\u89e3\u6790 \"\"\"shape b : [1659] a : [1659] gj : [1659] gi : [1659] \"\"\" b , a , gj , gi = indices [ i ] # image, anchor, gridy, gridx # tobj = flow.zeros( pi.shape[:4] , dtype=pi.dtype, device=self.device) # target obj # \u521d\u59cb\u5316target\u7f6e\u4fe1\u5ea6(\u5148\u5168\u662f\u8d1f\u6837\u672c \u540e\u9762\u518d\u7b5b\u9009\u6b63\u6837\u672c\u8d4b\u503c) # tobj.shape = [16, 3, 80, 80] tobj = flow . zeros (( pi . shape [: 4 ]), dtype = pi . dtype , device = self . device ) # target obj # n = 1659 n = b . shape [ 0 ] # number of targets if n : # \u7cbe\u786e\u5f97\u5230\u7b2c b \u5f20\u56fe\u7247\u7684\u7b2c a \u4e2a feature map \u7684 grid_cell(gi, gj) \u5bf9\u5e94\u7684\u9884\u6d4b\u503c # \u7528\u8fd9\u4e2a\u9884\u6d4b\u503c\u4e0e\u6211\u4eec\u7b5b\u9009\u7684\u8fd9\u4e2a grid_cell \u7684\u771f\u5b9e\u6846\u8fdb\u884c\u9884\u6d4b(\u8ba1\u7b97\u635f\u5931) # pxy, pwh, _, pcls = pi[b, a, gj, gi].tensor_split((2, 4, 5), dim=1) \"\"\"shape pxy : [1659, 2] pwh : [1659, 2] _ : [1659, 1] pcls : [1659, 80] \"\"\" pxy , pwh , _ , pcls = pi [ b , a , gj , gi ] . split (( 2 , 2 , 1 , self . nc ), 1 ) # target-subset of predictions # Regression loss \u53ea\u8ba1\u7b97\u6240\u6709\u6b63\u6837\u672c\u7684\u56de\u5f52\u635f\u5931 # \u65b0\u7684\u516c\u5f0f: pxy = [-0.5 + cx, 1.5 + cx] pwh = [0, 4pw] \u8fd9\u4e2a\u533a\u57df\u5185\u90fd\u662f\u6b63\u6837\u672c # Get more positive samples, accelerate convergence and be more stable # pxy.shape = [1659, 2] pxy = pxy . sigmoid () * 2 - 0.5 # https://github.com/ultralytics/yolov3/issues/168 # pwh.shape = [1659, 2] pwh = ( pwh . sigmoid () * 2 ) ** 2 * anchors [ i ] # \u548c\u8bba\u6587\u91cc\u4e0d\u540c \u8fd9\u91cc\u662f\u4f5c\u8005\u81ea\u5df1\u63d0\u51fa\u7684\u516c\u5f0f # pbox.shape = [1659, 4] pbox = flow . cat (( pxy , pwh ), 1 ) # predicted box # \u8fd9\u91cc\u7684tbox[i]\u4e2d\u7684xy\u662f\u8fd9\u4e2atarget\u5bf9\u5f53\u524dgrid_cell\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\u91cf[0,1] \u800cpbox.T\u662f\u4e00\u4e2a\u5f52\u4e00\u5316\u7684\u503c # \u5c31\u662f\u8981\u7528\u8fd9\u79cd\u65b9\u5f0f\u8bad\u7ec3 \u4f20\u56deloss \u4fee\u6539\u68af\u5ea6 \u8ba9pbox\u8d8a\u6765\u8d8a\u63a5\u8fd1tbox(\u504f\u79fb\u91cf) # iou.shape = [1659] iou = bbox_iou ( pbox , tbox [ i ], CIoU = True ) . squeeze () # iou(prediction, target) # lbox.shape = [1] lbox = lbox + ( 1.0 - iou ) . mean () # iou loss # Objectness # iou.detach() \u4e0d\u4f1a\u66f4\u65b0iou\u68af\u5ea6 iou\u5e76\u4e0d\u662f\u53cd\u5411\u4f20\u64ad\u7684\u53c2\u6570 \u6240\u4ee5\u4e0d\u9700\u8981\u53cd\u5411\u4f20\u64ad\u68af\u5ea6\u4fe1\u606f # iou.shape = [1659] iou = iou . detach () . clamp ( 0 ) . type ( tobj . dtype ) # \u8fd9\u91cc\u5bf9 iou \u8fdb\u884c\u6392\u5e8f\u518d\u505a\u4e00\u4e2a\u4f18\u5316\uff1a\u5f53\u4e00\u4e2a\u6b63\u6837\u672c\u51fa\u73b0\u591a\u4e2a GT \u7684\u60c5\u51b5\u4e5f\u5c31\u662f\u540c\u4e00\u4e2a grid \u4e2d\u6709\u4e24\u4e2a gt (\u5bc6\u96c6\u578b\u4e14\u5f62\u72b6\u5dee\u4e0d\u591a\u7269\u4f53) # There maybe several GTs match the same anchor when calculate ComputeLoss in the scene with dense targets if self . sort_obj_iou : # https://github.com/ultralytics/yolov5/issues/3605 # There maybe several GTs match the same anchor when calculate ComputeLoss in the scene with dense targets j = iou . argsort () # \u5982\u679c\u540c\u4e00\u4e2a grid \u51fa\u73b0\u4e24\u4e2a GT \u90a3\u4e48\u7ecf\u8fc7\u6392\u5e8f\u4e4b\u540e\u6bcf\u4e2a grid \u4e2d\u7684 score_iou \u90fd\u80fd\u4fdd\u8bc1\u662f\u6700\u5927\u7684 # (\u5c0f\u7684\u4f1a\u88ab\u8986\u76d6 \u56e0\u4e3a\u540c\u4e00\u4e2agrid\u5750\u6807\u80af\u5b9a\u76f8\u540c)\u90a3\u4e48\u4ece\u65f6\u95f4\u987a\u5e8f\u7684\u8bdd, \u6700\u540e\u4e00\u4e2a\u603b\u662f\u548c\u6700\u5927\u7684 iou \u53bb\u8ba1\u7b97 loss b , a , gj , gi , iou = b [ j ], a [ j ], gj [ j ], gi [ j ], iou [ j ] # \u9884\u6d4b\u4fe1\u606f\u6709\u7f6e\u4fe1\u5ea6 \u4f46\u662f\u771f\u5b9e\u6846\u4fe1\u606f\u662f\u6ca1\u6709\u7f6e\u4fe1\u5ea6\u7684 \u6240\u4ee5\u9700\u8981\u6211\u4eec\u4eba\u4e3a\u7684\u7ed9\u4e00\u4e2a\u6807\u51c6\u7f6e\u4fe1\u5ea6 # self.gr\u662fiou ratio [0, 1] self.gr\u8d8a\u5927\u7f6e\u4fe1\u5ea6\u8d8a\u63a5\u8fd1iou self.gr\u8d8a\u5c0f\u7f6e\u4fe1\u5ea6\u8d8a\u63a5\u8fd11(\u4eba\u4e3a\u52a0\u5927\u8bad\u7ec3\u96be\u5ea6) if self . gr < 1 : iou = ( 1.0 - self . gr ) + self . gr * iou tobj [ b , a , gj , gi ] = iou # iou ratio # Classification \u53ea\u8ba1\u7b97\u6240\u6709\u6b63\u6837\u672c\u7684\u5206\u7c7b\u635f\u5931 # self.nc = 80 if self . nc > 1 : # cls loss (only if multiple classes) # targets \u539f\u672c\u8d1f\u6837\u672c\u662f0 \u8fd9\u91cc\u4f7f\u7528smooth label \u5c31\u662fcn # t.shape = [1659,80] t = flow . full_like ( pcls , self . cn , device = self . device ) # targets # t[range(n), tcls[i]] = self.cp \u7b5b\u9009\u5230\u7684\u6b63\u6837\u672c\u5bf9\u5e94\u4f4d\u7f6e\u503c\u662fcp t [ flow . arange ( n , device = self . device ), tcls [ i ]] = self . cp # lcls.shape = [1] lcls = lcls + self . BCEcls ( pcls , t ) # BCE # Append targets to text file # with open('targets.txt', 'a') as file: # [file.write('%11.5g ' * 4 % tuple(x) + '\\n') for x in flow.cat((txy[i], twh[i]), 1)] # \u7f6e\u4fe1\u5ea6\u635f\u5931\u662f\u7528\u6240\u6709\u6837\u672c(\u6b63\u6837\u672c + \u8d1f\u6837\u672c)\u4e00\u8d77\u8ba1\u7b97\u635f\u5931\u7684 obji = self . BCEobj ( pi [ ... , 4 ], tobj ) # \u6bcf\u4e2a feature map \u7684\u7f6e\u4fe1\u5ea6\u635f\u5931\u6743\u91cd\u4e0d\u540c \u8981\u4e58\u4ee5\u76f8\u5e94\u7684\u6743\u91cd\u7cfb\u6570 self.balance[i] # \u4e00\u822c\u6765\u8bf4\uff0c\u68c0\u6d4b\u5c0f\u7269\u4f53\u7684\u96be\u5ea6\u5927\u4e00\u70b9\uff0c\u6240\u4ee5\u4f1a\u589e\u52a0\u5927\u7279\u5f81\u56fe\u7684\u635f\u5931\u7cfb\u6570\uff0c\u8ba9\u6a21\u578b\u66f4\u52a0\u4fa7\u91cd\u5c0f\u7269\u4f53\u7684\u68c0\u6d4b lobj = lobj + ( obji * self . balance [ i ]) # obj loss if self . autobalance : # \u81ea\u52a8\u66f4\u65b0\u5404\u4e2a feature map \u7684\u7f6e\u4fe1\u5ea6\u635f\u5931\u7cfb\u6570 self . balance [ i ] = self . balance [ i ] * 0.9999 + 0.0001 / obji . detach () . item () if self . autobalance : self . balance = [ x / self . balance [ self . ssi ] for x in self . balance ] # \u6839\u636e\u8d85\u53c2\u4e2d\u7684\u635f\u5931\u6743\u91cd\u53c2\u6570 \u5bf9\u5404\u4e2a\u635f\u5931\u8fdb\u884c\u5e73\u8861 \u9632\u6b62\u603b\u635f\u5931\u88ab\u67d0\u4e2a\u635f\u5931\u4e3b\u5bfc \"\"\"shape lbox : [1] lobj : [1] lcls : [1] \"\"\" lbox *= self . hyp [ \"box\" ] lobj *= self . hyp [ \"obj\" ] lcls *= self . hyp [ \"cls\" ] bs = tobj . shape [ 0 ] # batch size # loss = lbox + lobj + lcls \u5e73\u5747\u6bcf\u5f20\u56fe\u7247\u7684\u603b\u635f\u5931 # loss * bs: \u6574\u4e2abatch\u7684\u603b\u635f\u5931 # .detach() \u5229\u7528\u635f\u5931\u503c\u8fdb\u884c\u53cd\u5411\u4f20\u64ad return ( lbox + lobj + lcls ) * bs , flow . cat (( lbox , lobj , lcls )) . detach () \u4f7f\u7528\uff1a train.py\u521d\u59cb\u5316\u635f\u5931\u51fd\u6570\u7c7b\uff1a compute_loss = ComputeLoss(model) # init loss class \u8c03\u7528\u6267\u884c\u635f\u5931\u51fd\u6570\uff0c\u8ba1\u7b97\u635f\u5931\uff1a loss, loss_items = compute_loss(pred, targets.to(device)) # loss scaled by batch_size","title":"6.3 __call__\u51fd\u6570"},{"location":"source_code_interpretation/utils/loss_py.html#_2","text":"\u6211\u4eec\u8ba4\u4e3a yolov5/one-yolov5 \u5de5\u7a0b\u5b9e\u73b0\u6700\u91cd\u8981\u7684\u5c31\u662f ComputeLoss \u7c7b\u4e86\u3002\u4f46\u4ee3\u7801\u5176\u5b9e\u8fd8\u662f\u975e\u5e38\u96be\u7684\uff0c\u5c24\u5176 build_target \u91cc\u9762\u82b1\u91cc\u80e1\u54e8\u7684\u77e9\u9635\u64cd\u4f5c\u548cslice\u64cd\u4f5c\u975e\u5e38\u591a\uff0c pytorch\u6216\u8005oneflow\u4e0d\u719f\u7684\u4eba\u4f1a\u770b\u7684\u6bd4\u8f83\u75db\u82e6\uff0c\u4f46\u662f\u5982\u679c\u4f60\u575a\u6301\u770b\u4e0b\u6765\u6211\u4eec\u7684\u6ce8\u91ca\u518d\u52a0\u4e0a\u81ea\u5df1\u7684\u51a5\u60f3\uff0c\u5e94\u8be5\u662f\u80fd\u60f3\u660e\u767d\u7684\u3002","title":"\u603b\u7ed3"},{"location":"source_code_interpretation/utils/loss_py.html#reference","text":"\u3010YOLOV5-5.x \u6e90\u7801\u89e3\u8bfb\u3011loss.py \u76ee\u6807\u68c0\u6d4b YOLOv5 - Sample Assignment yolov5--loss.py --v5.0\u7248\u672c-\u6700\u65b0\u4ee3\u7801\u8be6\u7ec6\u89e3\u91ca-2021-7-1\u66f4\u65b0 YOLO-V3-SPP \u8bad\u7ec3\u65f6\u6b63\u6837\u672c\u7b5b\u9009\u6e90\u7801\u89e3\u6790\u4e4bbuild_targets YOLOv5-4.0-loss.py \u6e90\u4ee3\u7801\u5bfc\u8bfb(\u635f\u5931\u51fd\u6570\uff09 yolov5 \u4ee3\u7801\u89e3\u8bfb \u635f\u5931\u51fd\u6570 loss.py","title":"Reference"},{"location":"thesis_interpretation/00_yolo_history.html","text":"\ud83c\udfc6\u4e00\u77a5\u4fbf\u662f\u60ca\u9e3f\uff0c\u82b3\u534e\u4e71\u4e86\u6d6e\u751f~ \u7531\u4e8e\u5176\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c \\(YOLO\\) \u6210\u4e3a\u4e16\u754c\u8457\u540d\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e4b\u4e00\u3002 YOLOv1\ud83c\udf89 \\(YOLO\\) \u662f \"You only look once\" \u7684\u7f29\u5199 , \u662f\u5c06\u56fe\u50cf\u5212\u5206\u4e3a\u7f51\u683c\u7cfb\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u3002( \ud83e\udd14\ufe0f\u7f51\u683c\u4e2d\u7684\u6bcf\u4e2a\u5355\u5143\u8d1f\u8d23\u68c0\u6d4b\u81ea\u8eab\u5185\u7684\u76ee\u6807 )\u3002 \u5b98\u65b9\u8bba\u6587: You Only Look Once: Unified, Real-Time Object Detection Author: Joseph Redmon YOLOv2\ud83c\udf1f \\(YOLOv2\\) \u662f \\(YOLO\\) \u7684\u539f\u4f5c\u8005Joseph Redmon \u548c Ali Farhadi \u7684\u5171\u540c\u4f5c\u54c1\u3002 \u4ed6\u4eec\u4e00\u8d77\u53d1\u8868\u4e86\uff1a YOLO9000:Better, Faster, Stronger Author: Joseph Redmon and Ali Farhadi Released: 25 Dec 2016 YOLOv3\ud83c\udf1f \\(YOLOv3\\) \u662f \\(YOLOv2\\) \u6539\u826f\u7248 \uff0c\u51fa\u81ea \\(YOLOv2\\) \u7684\u539f\u4f5c\u8005 (Joseph Redmon \u548c Ali Farhadi) , \u4e00\u8d77\u505a\u51fa\u6765\u8d21\u732e\u3002 \u4ed6\u4eec\u5171\u540c\u53d1\u8868\u4e86 YOLOv3: An Incremental Improvement \u6700\u521d\u7684\u7ea6\u6d1b\u8bba\u6587\u662f\u7531\u8c01\u63d0\u4f9b\u7684 here Author: Joseph Redmon and Ali Farhadi Released: 8 Apr 2018 YOLOv4\ud83c\udf70 \u968f\u7740\u539f\u4f5c\u8005 \\(YOLO\\) \u7684\u5de5\u4f5c\u9677\u5165\u50f5\u5c40, \\(YOLOv4\\) \u53d1\u8868\u7531 Alexey Bochoknovskiy, Chien-Yao Wang, \u548c Hong-Yuan Mark Liao. \u8bba\u6587\u540d\u4e3a YOLOv4: Optimal Speed and Accuracy of Object Detection YOLOV5 \ud83d\ude80 \\(YOLOv4\\) \u53d1\u5e03\u540e\u4e0d\u4e45\uff0cGlenn Jocher\u4f7f\u7528Pytorch\u6846\u67b6\u5f15\u5165\u4e86 \\(YOLOv5\\) \u6ca1\u6709\u53d1\u5e03\u8bba\u6587\u3002 \u4ee3\u7801\u94fe\u63a5: https://github.com/ultralytics/yolov5 YOLOv6\u26a1 \\(YOLOv6\\) \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u9762\u5411\u5404\u79cd\u5de5\u4e1a\u5e94\u7528\u573a\u666f\u7684\u6a21\u578b\uff0c\u5305\u62ec\u5fae\u5c0f\u7ea7(nano)\uff0c\u6781\u5c0f\u6781(tiny)\u3001\u5c0f(small)\uff0c\u4e2d(medium)\uff0c\u5927\u6a21\u578b(large)\u3002 \u5b98\u65b9\u8bba\u6587: YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications \u4ee3\u7801\u94fe\u63a5\uff1a https://github.com/meituan/YOLOv6 YOLOv7\ud83d\udc4d \u5b98\u65b9\u8bba\u6587: YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors \u4ee3\u7801\u94fe\u63a5\uff1a https://github.com/WongKinYiu/yolov7 \u5feb\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"history"},{"location":"thesis_interpretation/00_yolo_history.html#yolov1","text":"\\(YOLO\\) \u662f \"You only look once\" \u7684\u7f29\u5199 , \u662f\u5c06\u56fe\u50cf\u5212\u5206\u4e3a\u7f51\u683c\u7cfb\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u3002( \ud83e\udd14\ufe0f\u7f51\u683c\u4e2d\u7684\u6bcf\u4e2a\u5355\u5143\u8d1f\u8d23\u68c0\u6d4b\u81ea\u8eab\u5185\u7684\u76ee\u6807 )\u3002 \u5b98\u65b9\u8bba\u6587: You Only Look Once: Unified, Real-Time Object Detection Author: Joseph Redmon","title":"YOLOv1\ud83c\udf89"},{"location":"thesis_interpretation/00_yolo_history.html#yolov2","text":"\\(YOLOv2\\) \u662f \\(YOLO\\) \u7684\u539f\u4f5c\u8005Joseph Redmon \u548c Ali Farhadi \u7684\u5171\u540c\u4f5c\u54c1\u3002 \u4ed6\u4eec\u4e00\u8d77\u53d1\u8868\u4e86\uff1a YOLO9000:Better, Faster, Stronger Author: Joseph Redmon and Ali Farhadi Released: 25 Dec 2016","title":"YOLOv2\ud83c\udf1f"},{"location":"thesis_interpretation/00_yolo_history.html#yolov3","text":"\\(YOLOv3\\) \u662f \\(YOLOv2\\) \u6539\u826f\u7248 \uff0c\u51fa\u81ea \\(YOLOv2\\) \u7684\u539f\u4f5c\u8005 (Joseph Redmon \u548c Ali Farhadi) , \u4e00\u8d77\u505a\u51fa\u6765\u8d21\u732e\u3002 \u4ed6\u4eec\u5171\u540c\u53d1\u8868\u4e86 YOLOv3: An Incremental Improvement \u6700\u521d\u7684\u7ea6\u6d1b\u8bba\u6587\u662f\u7531\u8c01\u63d0\u4f9b\u7684 here Author: Joseph Redmon and Ali Farhadi Released: 8 Apr 2018","title":"YOLOv3\ud83c\udf1f"},{"location":"thesis_interpretation/00_yolo_history.html#yolov4","text":"\u968f\u7740\u539f\u4f5c\u8005 \\(YOLO\\) \u7684\u5de5\u4f5c\u9677\u5165\u50f5\u5c40, \\(YOLOv4\\) \u53d1\u8868\u7531 Alexey Bochoknovskiy, Chien-Yao Wang, \u548c Hong-Yuan Mark Liao. \u8bba\u6587\u540d\u4e3a YOLOv4: Optimal Speed and Accuracy of Object Detection","title":"YOLOv4\ud83c\udf70"},{"location":"thesis_interpretation/00_yolo_history.html#yolov5","text":"\\(YOLOv4\\) \u53d1\u5e03\u540e\u4e0d\u4e45\uff0cGlenn Jocher\u4f7f\u7528Pytorch\u6846\u67b6\u5f15\u5165\u4e86 \\(YOLOv5\\) \u6ca1\u6709\u53d1\u5e03\u8bba\u6587\u3002 \u4ee3\u7801\u94fe\u63a5: https://github.com/ultralytics/yolov5","title":"YOLOV5 \ud83d\ude80"},{"location":"thesis_interpretation/00_yolo_history.html#yolov6","text":"\\(YOLOv6\\) \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u9762\u5411\u5404\u79cd\u5de5\u4e1a\u5e94\u7528\u573a\u666f\u7684\u6a21\u578b\uff0c\u5305\u62ec\u5fae\u5c0f\u7ea7(nano)\uff0c\u6781\u5c0f\u6781(tiny)\u3001\u5c0f(small)\uff0c\u4e2d(medium)\uff0c\u5927\u6a21\u578b(large)\u3002 \u5b98\u65b9\u8bba\u6587: YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications \u4ee3\u7801\u94fe\u63a5\uff1a https://github.com/meituan/YOLOv6","title":"YOLOv6\u26a1"},{"location":"thesis_interpretation/00_yolo_history.html#yolov7","text":"\u5b98\u65b9\u8bba\u6587: YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors \u4ee3\u7801\u94fe\u63a5\uff1a https://github.com/WongKinYiu/yolov7 \u5feb\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"YOLOv7\ud83d\udc4d"},{"location":"thesis_interpretation/01_yolo.html","text":"\u539f\u6587\u5730\u5740: https://arxiv.org/pdf/1506.02640.pdf \u6458\u8981 \u2003\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5 \\(YOLO\\) \u3002\u4ee5\u524d\u7684\u76ee\u6807\u68c0\u6d4b\u5de5\u4f5c\u91cd\u65b0\u5229\u7528\u5206\u7c7b\u5668\u6765\u6267\u884c\u68c0\u6d4b\u3002\u76f8\u53cd\uff0c\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u6846\u67b6\u770b\u4f5c\u4ece\u7a7a\u95f4\u5206\u79bb\u7684\u8fb9\u754c\u6846\u548c\u76f8\u5173\u7c7b\u522b\u6982\u7387\u7684\u56de\u5f52\u95ee\u9898\u3002\u5728\u4e00\u6b21\u8bc4\u4f30\u4e2d\uff0c\u4e00\u4e2a\u5355\u4e00\u7684\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u4ece\u5b8c\u6574\u7684\u56fe\u50cf\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u3002\u7531\u4e8e\u6574\u4e2a\u68c0\u6d4b\u7ba1\u9053\u662f\u4e00\u4e2a\u5355\u4e00\u7684\u7f51\u7edc\uff0c\u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u5bf9\u68c0\u6d4b\u6027\u80fd\u8fdb\u884c\u7aef\u5230\u7aef( \u8bd1\u8005\u6ce8\uff1a\u7aef\u5bf9\u7aef\u6307\u7684\u662f\u8f93\u5165\u539f\u59cb\u6570\u636e\uff0c\u8f93\u51fa\u7684\u662f\u6700\u540e\u7ed3\u679c\uff0c\u5e94\u7528\u5728\u7279\u5f81\u5b66\u4e60\u878d\u5165\u7b97\u6cd5\uff0c\u65e0\u9700\u5355\u72ec\u5904\u7406 )\u4f18\u5316\u3002 \u2003 \u6211\u4eec\u7684\u7edf\u4e00\u67b6\u6784\u975e\u5e38\u5feb\u3002\u6211\u4eec\u7684\u57fa\u672c \\(YOLO\\) \u6a21\u578b\u4ee5\u6bcf\u79d245\u5e27\u7684\u901f\u5ea6\u5b9e\u65f6\u5904\u7406\u56fe\u50cf\u3002\u8be5\u7f51\u7edc\u7684\u4e00\u4e2a\u5c0f\u7248\u672c\uff1a \\(Fast \\ YOLO\\) \u662f \\(YOLO\\) \u7684\u4e00\u4e2a\u8f83\u5c0f\u7248\u672c\uff0c\u6bcf\u79d2\u80fd\u8fbe\u5230\u5904\u7406\u60ca\u4eba\u7684155\u5e27\u56fe\u50cf\uff0c\u540c\u65f6\u4ecd\u7136\u8fbe\u5230\u5176\u4ed6\u5b9e\u65f6\u63a2\u6d4b\u5668\u7684\u4e24\u500d \\(mAP\\) \u3002\u4e0e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\uff0c \\(YOLO\\) YOLO\u867d\u7136\u5b58\u5728\u8f83\u591a\u7684\u5b9a\u4f4d\u9519\u8bef\uff0c\u4f46\u5f88\u5c11\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u5047\u9633\u6027( \u8bd1\u8005\u6ce8\uff1a\u5176\u5b83\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u76ee\u6807\u7684\u6982\u7387\u8f83\u5927 )\u3002\u6700\u540e\uff0c \\(YOLO\\) \u80fd\u5b66\u4e60\u5230\u76ee\u6807\u7684\u975e\u5e38\u901a\u7528\u3002\u65e0\u8bba\u4ece\u81ea\u7136\u56fe\u50cf\u5230\u827a\u672f\u54c1\u7b49\u5176\u4ed6\u9886\u57df\u6cdb\u5316\u65f6\uff0c\u5b83\u90fd\u4f18\u4e8e\u5176\u4ed6\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6bd4\u5982 \\(DPM\\) \u548c \\(R-CNN\\) \u3002 1.\u4ecb\u7ecd \u2003\u4eba\u7c7b\u77a5\u4e00\u773c\u56fe\u50cf\uff0c\u5c31\u4f1a\u7acb\u5373\u77e5\u9053\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\u662f\u4ec0\u4e48\uff0c\u5b83\u4eec\u5728\u54ea\u91cc\uff0c\u4ee5\u53ca\u5b83\u4eec\u662f\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u7684\u3002\u4eba\u7c7b\u7684\u89c6\u89c9\u7cfb\u7edf\u5feb\u901f\u548c\u51c6\u786e\u7684\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u5728\u51e0\u4e4e\u6ca1\u6709\u610f\u8bc6\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u590d\u6742\u7684\u4efb\u52a1\uff0c\u5982\u9a7e\u9a76\u3002\u5feb\u901f\u3001\u51c6\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5c06\u5141\u8bb8\u8ba1\u7b97\u673a\u5728\u6ca1\u6709\u4e13\u7528\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u9a7e\u9a76\u6c7d\u8f66\uff0c\u4f7f\u8f85\u52a9\u8bbe\u5907\u80fd\u591f\u5411\u4eba\u7c7b\u7528\u6237\u4f20\u9001\u5b9e\u65f6\u573a\u666f\u4fe1\u606f\u5e76\u91ca\u653e\u901a\u7528\u3001\u54cd\u5e94\u7075\u654f\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6f5c\u529b\u3002\u5feb\u901f\u3001\u51c6\u786e\u7684\u7269\u4f53\u68c0\u6d4b\u7b97\u6cd5\u5c06\u5e2e\u52a9\u8ba1\u7b97\u673a\u5728\u6ca1\u6709\u4e13\u95e8\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u9a7e\u9a76\u6c7d\u8f66\uff0c\u8f85\u52a9\u8bbe\u5907\u80fd\u591f\u5c06\u5b9e\u65f6\u573a\u666f\u4fe1\u606f\u4f20\u8fbe\u7ed9\u7528\u6237\uff0c\u5e76\u663e\u793a\u901a\u7528\u3001\u54cd\u5e94\u5f0f\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6f5c\u529b\u3002 \u2003 \u76ee\u524d\u7684\u68c0\u6d4b\u7cfb\u7edf\u91cd\u590d\u5229\u7528\u5206\u7c7b\u5668\u6765\u6267\u884c\u68c0\u6d4b\u3002\u4e3a\u4e86\u68c0\u6d4b\u76ee\u6807\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u4e3a\u8be5\u76ee\u6807\u63d0\u4f9b\u4e00\u4e2a\u5206\u7c7b\u5668\uff0c\u5e76\u5728\u6d4b\u8bd5\u56fe\u50cf\u7684\u4e0d\u540c\u4f4d\u7f6e\u548c\u5c3a\u5ea6\u4e0a\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002\u4f8b\u5982\u50cf\u53ef\u53d8\u5f62\u90e8\u4ef6\u6a21\u578b \\((DPM)\\) \u8fd9\u6837\u7684\u7cfb\u7edf\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\uff0c\u5176\u4e2d\u5206\u7c7b\u5668\u5728\u6574\u4e2a\u56fe\u50cf\u4e0a\u5747\u5300\u95f4\u9694\u7684\u4f4d\u7f6e\u8fd0\u884c[10]\u3002 \u56fe1: YOLO\u68c0\u6d4b\u7cfb\u7edf\u3002 \u7528YOLO\u5904\u7406\u56fe\u50cf\u7b80\u5355\u800c\u76f4\u63a5\u3002\u5728\u6211\u4eec\u7684\u7cfb\u7edf\u4e2d: \u5c06\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u8c03\u6574\u4e3a448 \u00d7 448\u3002 \u5728\u56fe\u50cf\u4e0a\u8fd0\u884c\u4e00\u4e2a\u5377\u79ef\u7f51\u7edc\u3002 \u6839\u636e\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u5bf9\u7ed3\u679c\u68c0\u6d4b\u8fdb\u884c\u9608\u503c\u3002 \u2003\u6700\u8fd1\u7684\u65b9\u6cd5\uff0c\u5982R-CNN\u63d0\u51fa\u4f7f\u7528\u90e8\u5206\u533a\u57df\uff0c\u9996\u5148\u5728\u56fe\u50cf\u4e2d\u751f\u6210\u6f5c\u5728\u7684\u8fb9\u754c\u6846\uff0c\u7136\u540e\u5728\u8fd9\u4e9b\u6846\u4e0a\u8fd0\u884c\u5206\u7c7b\u5668\u3002\u5b8c\u6210\u5206\u7c7b\u540e\uff0c\u901a\u8fc7\u540e\u5904\u7406\u5728\u7ec6\u5316\u8fb9\u754c\u6846\uff0c\u6d88\u9664\u91cd\u590d\u68c0\u6d4b\uff0c\u5e76\u57fa\u4e8e\u573a\u666f\u4e2d\u7684\u5176\u4ed6\u76ee\u6807\u91cd\u65b0\u5b9a\u4f4d\u8fb9\u754c\u6846[13]\u3002\u8fd9\u4e9b\u590d\u6742\u7684\u6d41\u7a0b\u5f88\u6162\uff0c\u5f88\u96be\u4f18\u5316\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u5355\u72ec\u7684\u7ec4\u4ef6\u90fd\u5fc5\u987b\u5355\u72ec\u8bad\u7ec3\u3002 \u2003\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5355\u4e00\u7684\u56de\u5f52\u95ee\u9898\uff0c\u76f4\u63a5\u4ece\u56fe\u50cf\u50cf\u7d20\u5230\u8fb9\u754c\u6846\u5750\u6807\u548c\u7c7b\u522b\u6982\u7387\u3002\u4f7f\u7528\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u60a8\u53ea\u9700\u8981\u5728\u56fe\u50cf\u4e0a\u770b\u4e00\u6b21\uff08you only look once, \\(YOLO\\) \uff09\uff0c\u5c31\u4ee5\u9884\u6d4b\u4ec0\u4e48\u76ee\u6807\u51fa\u73b0\u548c\u5b83\u4eec\u5728\u54ea\u91cc\u3002 \u2003 \\(YOLO\\) \u65b0\u5947\u53c8\u5f88\u7b80\u5355\uff1a\u5982\u56fe1\u6240\u793a\u3002\u5355\u4e2a\u5377\u79ef\u7f51\u7edc\u540c\u65f6\u9884\u6d4b\u8fd9\u4e9b\u6846\u7684\u591a\u4e2a\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u503c\u3002YOLO\u5728\u5b8c\u6574\u56fe\u50cf\u4e0a\u8bad\u7ec3\uff0c\u5e76\u76f4\u63a5\u4f18\u5316\u68c0\u6d4b\u6027\u80fd\u3002\u4e0e\u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8fd9\u79cd\u7edf\u4e00\u7684\u6a21\u578b\u6709\u51e0\u4e2a\u4f18\u70b9\u3002 \u2003 \u9996\u5148\uff0c \\(YOLO\\) \u901f\u5ea6\u975e\u5e38\u5feb\u3002\u7531\u4e8e\u6211\u4eec\u5c06\u68c0\u6d4b\u89c6\u4e3a\u56de\u5f52\u95ee\u9898\uff0c\u6240\u4ee5\u6211\u4eec\u4e0d\u9700\u8981\u590d\u6742\u7684\u6d41\u7a0b\u3002\u6d4b\u8bd5\u65f6\u6211\u4eec\u5728\u4e00\u5f20\u65b0\u56fe\u50cf\u4e0a\u7b80\u5355\u7684\u8fd0\u884c\u6211\u4eec\u7684\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u68c0\u6d4b\u7684\u7ed3\u679c\u3002\u5728Titan X GPU\u4e0a\u6ca1\u6709\u6279\u5904\u7406\u4e2d\uff0c\u6211\u4eec\u7684\u57fa\u7840\u7f51\u7edc\u4ee5\u6bcf\u79d245\u5e27\u7684\u901f\u5ea6\u8fd0\u884c\u3002\u5feb\u901f\u7248\u672c\u8fd0\u884c\u901f\u5ea6\u8d85\u8fc7150fps\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u53ef\u4ee5\u5728\u4e0d\u523025\u6beb\u79d2\u7684\u5ef6\u8fdf\u5185\u5b9e\u65f6\u5904\u7406\u6d41\u5a92\u4f53\u89c6\u9891\u3002\u6b64\u5916\uff0c \\(YOLO\\) \u5b9e\u73b0\u4e86\u5176\u5b83\u5b9e\u65f6\u7cfb\u7edf\u4e24\u500d\u4ee5\u4e0a\u7684mAP\u3002\u5173\u4e8e\u6211\u4eec\u7684\u7cfb\u7edf\u5728\u7f51\u7edc\u6444\u50cf\u5934\u4e0a\u5b9e\u65f6\u8fd0\u884c\u7684\u6f14\u793a\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684\u9879\u76ee\u7f51\u9875\uff1ahttp://pjreddie.com/yolo/\u3002 \u2003 \u5176\u6b21\uff0c \\(YOLO\\) \u5728\u8fdb\u884c\u9884\u6d4b\u65f6\uff0c\u4f1a\u5bf9\u56fe\u50cf\u8fdb\u884c\u5168\u5c40\u5730\u63a8\u7406\u3002\u4e0e\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3( sliding window )\u548c\u57fa\u4e8e\u533a\u57df\u63d0\u8bae( region proposal )\u7684\u6280\u672f\u4e0d\u540c\uff0c \\(YOLO\\) \u5728\u8bad\u7ec3\u671f\u95f4\u548c\u6d4b\u8bd5\u65f6\u4f1a\u770b\u5230\u6574\u4e2a\u56fe\u50cf\uff0c\u56e0\u6b64\u5b83\u9690\u5f0f\u5730\u7f16\u7801\u5173\u4e8e\u7c7b\u53ca\u5176\u5916\u89c2\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002 \\(Fast \\ R-CNN\\) \u662f\u4e00\u79cd\u9876\u90e8\u7684\u68c0\u6d4b\u65b9\u6cd5[14]\uff0c\u4f46\u56e0\u4e3a\u5b83\u770b\u4e0d\u5230\u66f4\u5927\u7684\u4e0a\u4e0b\u6587\uff0c\u6240\u4ee5\u5728\u56fe\u50cf\u4e2d\u4f1a\u5c06\u80cc\u666f\u5757\u8bef\u68c0\u4e3a\u76ee\u6807\u3002\u4e0e \\(Fast R-CNN\\) \u76f8\u6bd4\uff0cYOLO\u7684\u80cc\u666f\u8bef\u68c0\u6570\u91cf\u5c11\u4e86\u4e00\u534a\u3002 \u2003 \u7b2c\u4e09\uff0c \\(YOLO\\) \u5b66\u4e60\u76ee\u6807\u53ef\u6cdb\u5316\u8868\u793a\u3002\u5f53\u5728\u81ea\u7136\u7684\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u5bf9\u827a\u672f\u4f5c\u54c1\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c \\(YOLO\\) \u5927\u5e45\u4f18\u4e8e \\(DPM\\) \u548c \\(R-CNN\\) \u7b49\u9876\u7ea7\u68c0\u6d4b\u65b9\u6cd5\u3002\u7531\u4e8e \\(YOLO\\) \u5177\u6709\u9ad8\u5ea6\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u5728\u5e94\u7528\u4e8e\u65b0\u9886\u57df\u6216\u78b0\u5230\u975e\u6b63\u5e38\u8f93\u5165\u65f6\u5f88\u5c11\u51fa\u6545\u969c\u3002 \u2003 \\(YOLO\\) \u5728\u51c6\u786e\u5ea6\u4e0a\u4ecd\u7136\u843d\u540e\u4e8e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002\u867d\u7136\u5b83\u53ef\u4ee5\u5feb\u901f\u8bc6\u522b\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff0c\u4f46\u5b83\u5f88\u96be\u7cbe\u786e\u5b9a\u4f4d\u4e00\u4e9b\u76ee\u6807\uff0c\u5c24\u5176\u662f\u4e00\u4e9b\u5c0f\u76ee\u6807\u3002\u6211\u4eec\u5728\u5b9e\u9a8c\u4e2d\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u8fd9\u4e9b\u6743\u8861\u3002 \u2003 \\(YOLO\\) \u6211\u4eec\u6240\u6709\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u90fd\u662f\u5f00\u6e90\u7684\u3002\u5404\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\u4e5f\u90fd\u53ef\u4ee5\u4e0b\u8f7d\u3002 2.\u7edf\u4e00\u7684\u68c0\u6d4b \u2003 \u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u7684\u5355\u72ec\u7ec4\u4ef6\u96c6\u6210\u5230\u5355\u4e2a\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002\u6211\u4eec\u7684\u7f51\u7edc\u5229\u7528\u6574\u4e2a\u56fe\u50cf\u7684\u7279\u5f81\u6765\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u3002\u5b83\u8fd8\u53ef\u4ee5\u540c\u65f6\u9884\u6d4b\u4e00\u5f20\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u7c7b\u522b\u7684\u6240\u6709\u8fb9\u754c\u6846\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u7f51\u7edc\u5bf9\u6574\u4e2a\u56fe\u50cf\u548c\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u5bf9\u8c61\u8fdb\u884c\u5168\u5c40\u63a8\u7406\u3002 \\(YOLO\\) \u8bbe\u8ba1\u53ef\u5b9e\u73b0\u7aef\u5230\u7aef\u8bad\u7ec3\u548c\u5b9e\u65f6\u7684\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u5e73\u5747\u7cbe\u5ea6( \u5373mAP\u503c )\u3002 \u2003 \u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u8f93\u5165\u56fe\u50cf\u5206\u6210 \\(S\u00d7S\\) \u7684\u7f51\u683c\u3002\u5982\u679c\u4e00\u4e2a\u76ee\u6807\u7684\u4e2d\u5fc3\u843d\u5165\u4e00\u4e2a\u7f51\u683c\u5355\u5143\u4e2d\uff0c\u8be5\u7f51\u683c\u5355\u5143\u8d1f\u8d23\u68c0\u6d4b\u8be5\u76ee\u6807\u3002 \u2003 \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u9884\u6d4b \\(B\\) \u4e2a\u8fb9\u754c\u6846\u548c\u7f6e\u4fe1\u5ea6\u5206\u6570\u5bf9\u4e8e\u90a3\u4e9b\u6846\u3002\u8fd9\u4e9b\u7f6e\u4fe1\u5ea6\u5206\u6570\u53cd\u6620\u4e86\u8be5\u6a21\u578b\u5bf9\u6846\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u7f6e\u4fe1\u5ea6\uff0c\u4ee5\u53ca\u5b83\u9884\u6d4b\u6846\u7684\u51c6\u786e\u5ea6\u3002\u5728\u5f62\u5f0f\u4e0a\uff0c\u6211\u4eec\u5c06\u7f6e\u4fe1\u5ea6\u5b9a\u4e49\u4e3a \\(Pr(Object)\u2217IOU^{truth}_{pred}\\) \u3002\u5982\u679c\u8be5\u5355\u5143\u683c\u4e2d\u4e0d\u5b58\u5728\u76ee\u6807\uff0c\u5219\u7f6e\u4fe1\u5ea6\u5206\u6570\u5e94\u4e3a \\(0\\) \u3002\u5426\u5219\uff0c\u6211\u4eec\u5e0c\u671b\u7f6e\u4fe1\u5ea6\u5206\u6570\u7b49\u4e8e\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u8054\u5408\u90e8\u5206\u7684\u4ea4\u96c6( \\(IOU\\) )\u3002 \u2003\u6bcf\u4e2a\u8fb9\u754c\u6846\u5305\u542b5\u4e2a\u9884\u503c\uff1a \\(x,y,w,h,confidence\\) \u3002 \\((x,y)\\) \u5750\u6807\u8868\u793a\u8fb9\u754c\u6846\u76f8\u5bf9\u4e8e\u7f51\u683c\u5355\u5143\u8fb9\u754c\u7684\u65b9\u6846\u4e2d\u5fc3\u3002\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u662f\u76f8\u5bf9\u4e8e\u6574\u5f20\u56fe\u50cf\u9884\u6d4b\u7684\u3002\u6700\u540e\uff0c\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u8868\u793a\u4e3a\u9884\u6d4b\u6846\u4e0e\u5b9e\u9645\u8fb9\u754c\u6846\u4e4b\u95f4\u7684 \\(IOU\\) \u3002 \u2003 \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u8fd8\u9884\u6d4b \\(C\\) \u4e2a\u6761\u4ef6\u7c7b\u522b\u6982\u7387 \\(Pr(Class_i|Object)\\) \u3002\u8fd9\u4e9b\u6982\u7387\u4ee5\u5305\u542b\u76ee\u6807\u7684\u7f51\u683c\u5355\u5143\u4e3a\u6761\u4ef6\u3002\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u6211\u4eec\u53ea\u9884\u6d4b\u7684\u4e00\u7ec4\u7c7b\u522b\u6982\u7387\uff0c\u800c\u4e0d\u7ba1\u8fb9\u754c\u6846\u7684\u7684\u6570\u91cf \\(B\\) \u662f\u591a\u5c11\u3002 \u2003\u5728\u6d4b\u8bd5\u65f6\uff0c\u6211\u4eec\u5c06\u6761\u4ef6\u7c7b\u6982\u7387\u548c\u5355\u4e2a\u6846\u7684\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u503c\u76f8\u4e58\uff1a \\(\\small{Pr(Class_i|Object) \u2217 Pr(Object) \u2217 IOU^{truth}_{pred} = Pr(Class_i) \u2217 IOU^{truth}_{pred}}\\) (1) \u5b83\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u6bcf\u4e2a\u6846\u7279\u5b9a\u7c7b\u522b\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\u3002\u8fd9\u4e9b\u5206\u6570\u7f16\u7801\u4e86\u8be5\u7c7b\u51fa\u73b0\u5728\u6846\u4e2d\u7684\u6982\u7387\u4ee5\u53ca\u9884\u6d4b\u6846\u62df\u5408\u76ee\u6807\u7684\u7a0b\u5ea6\u3002 \u56fe2\uff1a\u6a21\u578b\u3002 \u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u68c0\u6d4b\u5efa\u6a21\u4e3a\u4e00\u4e2a\u56de\u5f52\u95ee\u9898\u3002\u5b83\u5c06\u56fe\u50cf\u5212\u5206\u4e3a\u4e00\u4e2a \\(S \u00d7 S\\) \u7f51\u683c\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u9884\u6d4b \\(B\\) \u4e2a\u8fb9\u754c\u6846\u3001\u8fd9\u4e9b\u6846\u7684\u7f6e\u4fe1\u5ea6 \u548c \\(C\\) \u7c7b\u522b\u6982\u7387\u3002\u8fd9\u4e9b\u9884\u6d4b\u88ab\u7f16\u7801\u4e3a \\(S \u00d7 S \u00d7 (B * 5 + C)\\) \u7684\u5f20\u91cf \\(S\\times{S}\\) grid on input( \\(S\\times{S}\\) \u7684\u7f51\u683c\u5728\u8f93\u5165\u4e0a) Bounding boxes (\u8fb9\u754c\u6846) confidence (\u7f6e\u4fe1\u5ea6) Class probability map(\u7c7b\u522b\u6982\u7387\u5730\u56fe) Final detections (\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c) \u4e3a\u4e86\u5728 \\(Pascal \\ VOC\\) \u4e0a\u8bc4\u4f30 \\(YOLO\\) \uff0c\u6211\u4eec\u4f7f\u7528 \\(S=7\uff0cB=2\u3002Pascal VOC\\) \u6709 \\(20\\) \u4e2a\u6807\u6ce8\u7c7b\uff0c\u6240\u4ee5 \\(C=20\\) \u3002\u6211\u4eec\u6700\u7ec8\u7684\u9884\u6d4b\u662f \\(7\u00d77\u00d730\\) \u7684\u5f20\u91cf\u3002 \u6ce8\u610f\uff1a \u2003 \u2003 1.\u7531\u4e8e\u8f93\u51fa\u5c42\u4e3a\u5168\u8fde\u63a5\u5c42\uff0c\u56e0\u6b64\u5728\u68c0\u6d4b\u65f6\uff0cYOLO\u8bad\u7ec3\u6a21\u578b\u53ea\u652f\u6301\u4e0e\u8bad\u7ec3\u56fe\u50cf\u76f8\u540c\u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002 \u2003 \u2003 2.\u867d\u7136\u6bcf\u4e2a\u683c\u5b50\u53ef\u4ee5\u9884\u6d4bB\u4e2abounding box\uff0c\u4f46\u662f\u6700\u7ec8\u53ea\u9009\u62e9\u53ea\u9009\u62e9IOU\u6700\u9ad8\u7684bounding box\u4f5c\u4e3a\u7269\u4f53\u68c0\u6d4b\u8f93\u51fa\uff0c\u5373\u6bcf\u4e2a\u683c\u5b50\u6700\u591a\u53ea\u9884\u6d4b\u51fa\u4e00\u4e2a\u7269\u4f53\u3002\u5f53\u7269\u4f53\u5360\u753b\u9762\u6bd4\u4f8b\u8f83\u5c0f\uff0c\u5982\u56fe\u50cf\u4e2d\u5305\u542b\u755c\u7fa4\u6216\u9e1f\u7fa4\u65f6\uff0c\u6bcf\u4e2a\u683c\u5b50\u5305\u542b\u591a\u4e2a\u7269\u4f53\uff0c\u4f46\u5374\u53ea\u80fd\u68c0\u6d4b\u51fa\u5176\u4e2d\u4e00\u4e2a\u3002\u8fd9\u662fYOLO\u65b9\u6cd5\u7684\u4e00\u4e2a\u7f3a\u9677\u3002 2.1 \u7f51\u7edc\u8bbe\u8ba1 \u2003\u6211\u4eec\u5c06\u8be5\u6a21\u578b\u5b9e\u73b0\u4e3a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u5728 \\(PASCAL \\ VOC\\) \u68c0\u6d4b\u6570\u636e\u96c6[9]\u4e0a\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002\u7f51\u7edc\u7684\u521d\u59cb\u5377\u79ef\u5c42\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u800c\u5168\u8fde\u901a\u5c42\u9884\u6d4b\u8f93\u51fa\u6982\u7387\u548c\u5750\u6807\u3002 \u2003\u6211\u4eec\u7684\u7f51\u7edc\u67b6\u6784\u7684\u7075\u611f\u6765\u81ea\u4e8e\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b[34]\u7684 \\(GoogLeNet\\) \u6a21\u578b\u3002\u6211\u4eec\u7684\u7f51\u7edc\u6709 \\(24\\) \u4e2a\u5377\u79ef\u5c42\u548c \\(2\\) \u4e2a\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u7b80\u5355\u5730\u4f7f\u7528 \\(1 \u00d7 1\\) \u8fd8\u539f\u5c42\u548c \\(3 \u00d7 3\\) \u5377\u79ef\u5c42\uff0c\u7c7b\u4f3c \\(Lin\\) \u7b49[22]\u3002\u5b8c\u6574\u7684\u7f51\u7edc \\(\u5982\u56fe3\\) \u6240\u793a\u3002 \u56fe3 :\u4f53\u7cfb\u7ed3\u6784\u3002 \u6211\u4eec\u7684\u68c0\u6d4b\u7f51\u7edc\u6709 \\(24\\) \u4e2a\u5377\u79ef\u5c42\u548c \\(2\\) \u4e2a\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u4ea4\u66ff\u7684 \\(1 \u00d7 1\\) \u5377\u79ef\u5c42\u51cf\u5c11\u4e86\u524d\u4e00\u5c42\u7684\u7279\u5f81\u7a7a\u95f4\u3002\u6211\u4eec\u5728 \\(ImageNet\\) \u5206\u7c7b\u4efb\u52a1\u4e0a\u4ee5\u4e00\u534a\u5206\u8fa8\u7387( \\(224 \u00d7 224\\) \u8f93\u5165\u56fe\u50cf)\u5bf9\u5377\u79ef\u5c42\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5c06\u5206\u8fa8\u7387\u63d0\u9ad8\u4e00\u500d\u7528\u4e8e\u68c0\u6d4b\u3002 \u2003\u6211\u4eec\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5feb\u901f\u7248\u672c\u7684 \\(YOLO\\) \uff0c\u65e8\u5728\u63a8\u52a8\u5feb\u901f\u76ee\u6807\u68c0\u6d4b\u7684\u8fb9\u754c\u3002 \\(Fast \\ YOLO\\) \u4f7f\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u66f4\u5c11\u7684\u5377\u79ef\u5c42(9\u5c42\u800c\u4e0d\u662f24\u5c42)\uff0c\u8fd9\u4e9b\u5c42\u4e2d\u7684\u8fc7\u6ee4\u5668\u4e5f\u66f4\u5c11\u3002\u9664\u4e86\u7f51\u7edc\u7684\u89c4\u6a21\uff0c \\(YOLO\\) \u548c \\(Fast \\ YOLO\\) \u4e4b\u95f4\u7684\u6240\u6709\u8bad\u7ec3\u548c\u6d4b\u8bd5\u53c2\u6570\u90fd\u662f\u76f8\u540c\u7684\u3002 \u2003\u6211\u4eec\u7684\u7f51\u7edc\u7684\u6700\u7ec8\u8f93\u51fa\u662f \\(7 \u00d7 7 \u00d7 30\\) \u5f20\u91cf\u7684\u9884\u6d4b\u3002 2.2 \u8bad\u7ec3 \u2003 \u9884\u8bad\u7ec3\u5206\u7c7b\u7f51\u7edc\uff1a\u6211\u4eec\u5728ImageNet 1000\u7c7b\u7ade\u8d5b\u6570\u636e\u96c6[30]\u4e0a\u9884\u8bad\u7ec3\u5377\u79ef\u5c42\u3002\u5bf9\u4e8e\u9884\u8bad\u7ec3\uff0c\u6211\u4eec\u4f7f\u7528\u56fe3\u4e2d\u7684\u524d20\u4e2a\u5377\u79ef\u5c42\uff0c\u7136\u540e\u662f\u5e73\u5747\u6c60\u5316\u5c42\u548c\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u6211\u4eec\u5bf9\u8be5\u7f51\u7edc\u8fdb\u884c\u4e86\u5927\u7ea6\u4e00\u5468\u7684\u8bad\u7ec3\uff0c\u5e76\u5728ImageNet 2012\u9a8c\u8bc1\u96c6\u4e0a\u5b9e\u73b0\u4e8688%\u7684\u5355\u4e00\u4f5c\u7269\u524d5\u540d\u7684\u51c6\u786e\u6027\uff0c\u4e0eCaffe\u7684Model Zoo[24]\u4e2d\u7684GoogLeNet\u6a21\u578b\u76f8\u5f53\u3002\u6211\u4eec\u4f7f\u7528Darknet\u6846\u67b6\u8fdb\u884c\u6240\u6709\u7684\u8bad\u7ec3\u548c\u63a8\u7406[26]\u3002 \u2003 \u7136\u540e\u6211\u4eec\u5c06\u6a21\u578b\u8f6c\u6362\u4e3a\u6267\u884c\u68c0\u6d4b\u3002Ren\u7b49\u4eba\u8868\u660e\uff0c\u5728\u9884\u8bad\u7ec3\u7684\u7f51\u7edc\u4e2d\u540c\u65f6\u6dfb\u52a0\u5377\u79ef\u5c42\u548c\u8fde\u63a5\u5c42\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd[29]\u3002 \u6309\u7167\u4ed6\u4eec\u7684\u4f8b\u5b50\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u56db\u4e2a\u5377\u79ef\u5c42\u548c\u4e24\u4e2a\u5177\u6709\u968f\u673a\u521d\u59cb\u5316\u6743\u503c\u7684\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u68c0\u6d4b\u901a\u5e38\u9700\u8981\u7ec6\u7c92\u5ea6\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u56e0\u6b64\u6211\u4eec\u5c06\u7f51\u7edc\u7684\u8f93\u5165\u5206\u8fa8\u7387\u4ece \\(224 \u00d7 224\\) \u63d0\u9ad8\u5230 \\(448 \u00d7 448\\) \u3002 \u2003 \u6211\u4eec\u7684\u6700\u540e\u4e00\u5c42\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u548c\u8fb9\u754c\u6846\u5750\u6807\u3002\u6211\u4eec\u901a\u8fc7\u56fe\u50cf\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u6765\u5f52\u4e00\u5316\u8fb9\u754c\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u4f7f\u5b83\u4eec\u843d\u57280\u548c1\u4e4b\u95f4\u3002\u6211\u4eec\u5c06\u8fb9\u754c\u6846x\u548cy\u5750\u6807\u53c2\u6570\u5316\u4e3a\u7279\u5b9a\u7f51\u683c\u5355\u5143\u4f4d\u7f6e\u7684\u504f\u79fb\u91cf\uff0c\u56e0\u6b64\u5b83\u4eec\u8fb9\u754c\u4e5f\u57280\u548c1\u4e4b\u95f4\u3002 \u2003 \u6211\u4eec\u5bf9\u6700\u540e\u4e00\u5c42\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u6240\u6709\u5176\u5b83\u5c42\u4f7f\u7528\u4e0b\u9762\u7684leaky ReLU\u6fc0\u6d3b\u51fd\u6570: \\(\\phi(x)=\\left\\{\\begin{array}{ll} x, & \\text { if } x>0 \\\\ 0.1 x, & \\text { otherwise } \\end{array}\\right.\\) (2) \u6211\u4eec\u4f18\u5316\u4e86\u6a21\u578b\u8f93\u51fa\u7684\u5e73\u65b9\u548c\u8bef\u5dee\u3002\u6211\u4eec\u4f7f\u7528\u5e73\u65b9\u548c\u8bef\u5dee\u662f\u56e0\u4e3a\u5b83\u5f88\u5bb9\u6613\u8fdb\u884c\u4f18\u5316\uff0c\u4f46\u662f\u5b83\u5e76\u4e0d\u5b8c\u5168\u7b26\u5408\u6211\u4eec\u6700\u5927\u5316\u5e73\u5747\u7cbe\u5ea6\u7684\u76ee\u6807\u3002\u5206\u7c7b\u8bef\u5dee\u4e0e\u5b9a\u4f4d\u8bef\u5dee\u7684\u6743\u91cd\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u53ef\u80fd\u5e76\u4e0d\u7406\u60f3\u3002\u53e6\u5916\uff0c\u5728\u6bcf\u5f20\u56fe\u50cf\u4e2d\uff0c\u8bb8\u591a\u7f51\u683c\u5355\u5143\u4e0d\u5305\u542b\u4efb\u4f55\u5bf9\u8c61\u3002\u8fd9\u5c06\u5bfc\u81f4\u8fd9\u4e9b\u5355\u5143\u683c\u7684 \\(\"\u7f6e\u4fe1\u5ea6\"\\) \u5206\u6570\u4e3a\u96f6\uff0c\u901a\u5e38\u538b\u5012\u4e86\u5305\u542b\u76ee\u6807\u7684\u5355\u5143\u683c\u7684\u68af\u5ea6\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u4ece\u800c\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u65e9\u53d1\u6563\u3002 \u2003\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u589e\u52a0\u4e86\u8fb9\u754c\u6846\u5750\u6807\u9884\u6d4b\u7684\u635f\u5931\uff0c\u51cf\u5c11\u4e86\u4e0d\u5305\u542b\u76ee\u6807\u7684\u6846\u7684\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u7684\u635f\u5931\u3002\u6211\u4eec\u4f7f\u7528\u4e24\u4e2a\u53c2\u6570\uff0c \\(\\lambda_{coord}\\) \u548c \\(\\lambda{noobj}\\) \u6765\u5b8c\u6210\u8fd9\u4e2a\u4efb\u52a1\u3002\u6211\u4eec\u8bbe\u7f6e \\(\\lambda_{coord} = 5\\) , \\(\\lambda_{noobj} = 0.5\\) \u3002 \u2003 \u5e73\u65b9\u548c\u8bef\u5dee\u5728\u5927\u65b9\u6846\u548c\u5c0f\u65b9\u6846\u4e2d\u7684\u6743\u91cd\u76f8\u540c\u3002\u6211\u4eec\u7684\u8bef\u5dee\u5ea6\u91cf\u5e94\u8be5\u53cd\u6620\u5927\u65b9\u6846\u91cc\u7684\u5c0f\u504f\u5dee\u6bd4\u5c0f\u65b9\u6846\u91cc\u7684\u5f71\u54cd\u5c0f\u3002\u4e3a\u4e86\u90e8\u5206\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u9884\u6d4b\u8fb9\u754c\u6846\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5e73\u65b9\u6839\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u3002\u4e3a\u4e86\u7f13\u548c\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u9884\u6d4b\u8fb9\u754c\u6846\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5e73\u65b9\u6839\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u3002 \u2003 \\(YOLO\\) \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u6709\u9884\u6d4b\u591a\u4e2a\u8fb9\u754c\u6846\u3002\u5728\u8bad\u7ec3\u65f6\uff0c\u6bcf\u4e2a\u76ee\u6807\u6211\u4eec\u53ea\u9700\u8981\u4e00\u4e2a\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u6765\u8d1f\u8d23\u3002\u6211\u4eec\u6839\u636e\u54ea\u4e2a\u9884\u6d4b\u5668\u7684\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u5177\u6709\u5f53\u524d\u6700\u9ad8\u7684 \\(IOU\\) \u6765\u6307\u5b9a\u54ea\u4e2a\u9884\u6d4b\u5668 \u8d1f\u8d23 \u9884\u6d4b\u8be5\u76ee\u6807\u3002\u8fd9\u5bfc\u81f4\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u4e4b\u95f4\u7684\u4e13\u4e00\u5316\u3002\u6bcf\u4e2a\u9884\u6d4b\u5668\u53ef\u4ee5\u66f4\u597d\u5730\u9884\u6d4b\u7279\u5b9a\u5927\u5c0f\u3001\u957f\u5bbd\u6bd4\u6216\u76ee\u6807\u7684\u7c7b\u522b\uff0c\u4ece\u800c\u6539\u5584\u6574\u4f53\u53ec\u56de\u7387\u3002 \u2003\u5728\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u4f18\u5316\u4ee5\u4e0b\u7531\u591a\u90e8\u5206\u7ec4\u6210\u7684\u635f\u5931\u51fd\u6570\uff1a \\(\\begin{array}{c} \\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(x_{i}-\\hat{x}_{i}\\right)^{2}+\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\\right] \\\\ +\\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(\\sqrt{w_{i}}-\\sqrt{\\hat{w}_{i}}\\right)^{2}+\\left(\\sqrt{h_{i}}-\\sqrt{\\hat{h}_{i}}\\right)^{2}\\right] \\\\ +\\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ +\\lambda_{\\text {noobj }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {noobj }}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ +\\sum_{i=0}^{S^{2}} \\mathbb{1}_{i}^{\\text {obj }} \\sum_{c \\in \\text { classes }}\\left(p_{i}(c)-\\hat{p}_{i}(c)\\right)^{2} \\end{array}\\) (3) \u5176\u4e2d \\(\\mathbb{1}_{i}^{\\mathrm{obj}}\\) \u8868\u793a\u5982\u679c\u76ee\u6807\u51fa\u73b0\u5728\u5355\u5143\u683c \\(i\\) \u5e76\u4e14 \\(\\mathbb{1}_{i j}^{\\mathrm{obj}}\\) \u8868\u793a\u7b2c \\(j\\) \u4e2a\u8fb9\u754c\u6846\u8d1f\u8d23\u5728\u5355\u5143\u683c \\(i\\) \u9884\u6d4b \u3002 \u2003 \u6ce8\u610f\uff0c\u5982\u679c\u76ee\u6807\u5b58\u5728\u4e8e\u8be5\u7f51\u683c\u5355\u5143\u4e2d\uff08\u524d\u9762\u8ba8\u8bba\u7684\u6761\u4ef6\u7c7b\u522b\u6982\u7387\uff09\uff0c\u5219\u635f\u5931\u51fd\u6570\u60e9\u7f5a\u5206\u7c7b\u8bef\u5dee\u3002\u5982\u679c\u9884\u6d4b\u5668 \\(\"\u8d1f\u8d23\"\\) \u771f\u5b9e\u8fb9\u754c\u6846\uff08\u5373\u8be5\u7f51\u683c\u5355\u5143\u4e2d\u5177\u6709\u6700\u9ad8 \\(IOU\\) \u7684\u9884\u6d4b\u5668\uff09\uff0c\u5219\u5b83\u4e5f\u4ec5\u60e9\u7f5a\u8fb9\u754c\u6846\u5750\u6807\u8bef\u5dee\u3002 \u2003 \u6211\u4eec\u5728 \\(Pascal \\ VOC \\ 2007\\) \u548c \\(2012\\) \u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5927\u7ea6 \\(135\\) \u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u7f51\u7edc\u8bad\u7ec3\u3002 \u5728 \\(Pascal \\ VOC \\ 2012\\) \u4e0a\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c\u6211\u4eec\u7684\u8bad\u7ec3\u8fd8\u5305\u542b\u4e86 \\(P0ascal \\ VOC \\ 2007\\) \u7684\u6d4b\u8bd5\u6570\u636e\u3002\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e86batch-size = 64 ( \u6279\u5927\u5c0f )\uff0cmomentum = 0.9 ( \u52a8\u91cf )\u548c decay = 0.0005 ( \u8870\u51cf\u7387 )\u3002 \u2003 \u6211\u4eec\u7684\u5b66\u4e60\u7387\u65b9\u6848\u5982\u4e0b\uff1a\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u8fed\u4ee3\u5468\u671f\uff0c\u6211\u4eec\u6162\u6162\u5730\u5c06\u5b66\u4e60\u7387\u4ece \\(10^{-3}\\) \u63d0\u9ad8\u5230 \\(10^{-2}\\) \u3002\u5982\u679c\u6211\u4eec\u4ece\u9ad8\u5b66\u4e60\u7387\u5f00\u59cb\uff0c\u6211\u4eec\u7684\u6a21\u578b\u5f80\u5f80\u4f1a\u7531\u4e8e\u68af\u5ea6\u4e0d\u7a33\u5b9a\u800c\u53d1\u6563\u3002\u6211\u4eec\u7ee7\u7eed\u4ee5 \\(10^{-2}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 \\(75\\) \u4e2a epochs( \u5373\u8fed\u4ee3\u5468\u671f )\uff0c\u7136\u540e\u7528 \\(10^{-3}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 \\(30\\) \u4e2aepochs\uff0c\u6700\u540e\u7528 \\(10^{-4}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 30\u4e2aepochs\u3002 \u2003 \u4e3a\u4e86\u907f\u514d\u8fc7\u5ea6\u62df\u5408\uff0c\u6211\u4eec\u4f7f\u7528 \\(dropout\\) \u548c \u5e7f\u6cdb\u7684\u6570\u636e\u589e\u5f3a\u3002\u5728\u7b2c\u4e00\u4e2a\u8fde\u63a5\u5c42\u4e4b\u540e\u6211\u4eec\u4e22\u5f03\u5177\u6709\u901f\u7387=0.5\u7684\u5c42\uff0c\u9632\u6b62\u5c42\u4e4b\u95f4\u7684\uff08\u76f8\u4e92\u5f71\u54cd\uff09\u3002\u5bf9\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u6211\u4eec\u5f15\u5165\u968f\u673a\u7f29\u653e\u548c\u6700\u591a\u539f\u59cb\u56fe\u50cf\u5927\u5c0f\u768420%\u7684translations\u3002\u6211\u4eec\u8fd8\u968f\u673a\u8c03\u6574\u66dd\u5149\u548c\u9971\u548c\u5ea6\u7684\u56fe\u50cf\u591a\u8fbe1.5\u500d\u7684HSV\u989c\u8272\u7a7a\u95f4\u3002 \u2003\u5728\u7b2c\u4e00\u4e2a\u8fde\u63a5\u5c42\u4e4b\u540e\uff0c \\(dropout\\) \u5c42\u4f7f\u7528rate=0.5\u7684\u6bd4\u4f8b\uff0c\u9632\u6b62\u5c42\u4e4b\u95f4\u7684\u76f8\u4e92\u5f71\u54cd( co-adaptation )[18]\u3002\u5bf9\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u6211\u4eec\u5f15\u5165\u9ad8\u8fbe\u539f\u59cb\u56fe\u50cf20%\u5927\u5c0f\u7684\u968f\u673a\u7f29\u653e\u548c\u8f6c\u6362\u3002\u6211\u4eec\u8fd8\u5728HSV\u8272\u5f69\u7a7a\u95f4\u4e2d\u4f7f\u7528\u9ad8\u8fbe1.5\u7684\u56e0\u5b50\u6765\u968f\u673a\u8c03\u6574\u56fe\u50cf\u7684\u66dd\u5149\u548c\u9971\u548c\u5ea6\u3002 2.3 \u63a8\u7406 \u2003\u4e0e\u8bad\u7ec3\u65f6\u4e00\u6837\uff0c\u9884\u6d4b\u6d4b\u8bd5\u56fe\u50cf\u7684\u68c0\u6d4b\u53ea\u9700\u8981\u4e00\u6b21\u7f51\u7edc\u8bc4\u4f30\u3002\u5728 \\(Pascal \\ VOC\\) \u4e0a\uff0c\u6bcf\u5f20\u56fe\u50cf\u4e0a\u7f51\u7edc\u9884\u6d4b98\u4e2a\u8fb9\u754c\u6846\uff08 \u8bd1\u8005\u6ce8\uff1a\u6bcf\u5f20\u56fe\u50cf\u88ab\u5212\u5206\u62107 7\u7684\u683c\u5b50\uff0c\u6bcf\u4e2a\u683c\u5b50\u9884\u6d4b\u4e24\u4e2a\u8fb9\u754c\u6846\uff0c\u603b\u517198\u4e2a\u8fb9\u754c\u6846*\uff09\u548c\u6bcf\u4e2a\u6846\u7684\u7c7b\u522b\u6982\u7387\u3002\u4e0e\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c \\(YOLO\\) \u5728\u6d4b\u8bd5\u65f6\u975e\u5e38\u5feb\uff0c\u56e0\u4e3a\u5b83\u53ea\u9700\u8981\u8fd0\u884c\u4e00\u6b21\u7f51\u7edc\u8bc4\u4f30\u3002 \u2003\u7f51\u683c\u8bbe\u8ba1\u52a0\u5f3a\u4e86\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u7a7a\u95f4\u591a\u6837\u6027\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u76ee\u6807\u843d\u5728\u54ea\u4e2a\u7f51\u683c\u5355\u5143\u683c\u4e2d\u662f\u5f88\u6e05\u695a\u7684\uff0c\u7f51\u7edc\u9884\u6d4b\u7684\u6bcf\u4e2a\u76ee\u6807\u5bf9\u5e94\u4e00\u4e2a\u6846\u3002\u4e00\u4e9b\u5927\u7684\u76ee\u6807\u6216\u9760\u8fd1\u591a\u4e2a\u7f51\u683c\u5355\u5143\u8fb9\u754c\u7684\u76ee\u6807\u53ef\u4ee5\u88ab\u591a\u4e2a\u7f51\u683c\u5355\u5143\u5f88\u597d\u5730\u5b9a\u4f4d\u3002\u975e\u6781\u5927\u503c\u6291\u5236\uff08 \u5373NMS \uff09\u53ef\u4ee5\u7528\u6765\u4fee\u6b63\u8fd9\u4e9b\u591a\u91cd\u68c0\u6d4b\u3002\u867d\u7136\u4e0d\u50cf \\(R-CNN\\) \u6216 \\(DPM\\) \u90a3\u6837\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u975e\u6700\u5927\u6291\u5236\u589e\u52a0\u4e862~3%\u7684 \\(mAP\\) \u3002 2.4 YOLO\u7684\u5c40\u9650\u6027 \u2003YOLO\u5bf9\u8fb9\u754c\u6846\u9884\u6d4b\u65bd\u52a0\u4e86\u5f88\u5f3a\u7684\u7a7a\u95f4\u7ea6\u675f\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u683c\u53ea\u80fd\u9884\u6d4b\u4e24\u4e2a\u6846\uff0c\u5e76\u4e14\u53ea\u80fd\u6709\u4e00\u4e2a\u7c7b\u3002\u8fd9\u79cd\u7a7a\u95f4\u7ea6\u675f\u9650\u5236\u4e86\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u9884\u6d4b\u7684\u9644\u8fd1\u7269\u4f53\u7684\u6570\u91cf\u3002\u6211\u4eec\u7684\u6a21\u578b\u5f88\u96be\u5904\u7406\u6210\u7fa4\u51fa\u73b0\u7684\u5c0f\u7269\u4f53\uff0c\u6bd4\u5982\u9e1f\u7fa4\u3002 \u2003 \u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u5b66\u4e60\u4ece\u6570\u636e\u4e2d\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u56e0\u6b64\u5b83\u5f88\u96be\u6cdb\u5316\u5230\u65b0\u7684\u3001\u4e0d\u5e38\u89c1\u7684\u957f\u5bbd\u6bd4\u6216\u914d\u7f6e\u4e2d\u7684\u76ee\u6807\u3002\u6211\u4eec\u7684\u6a21\u578b\u4e5f\u4f7f\u7528\u76f8\u5bf9\u8f83\u7c97\u7cd9\u7684\u7279\u5f81\u6765\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u56e0\u4e3a\u6211\u4eec\u7684\u67b6\u6784\u5177\u6709\u6765\u81ea\u8f93\u5165\u56fe\u50cf\u7684\u591a\u4e2a\u4e0b\u91c7\u6837\u5c42\u3002 \u2003\u6700\u540e\uff0c\u5f53\u6211\u4eec\u8bad\u7ec3\u4e00\u4e2a\u8fd1\u4f3c\u68c0\u6d4b\u6027\u80fd\u7684\u635f\u5931\u51fd\u6570\u65f6\uff0c\u6211\u4eec\u7684\u635f\u5931\u51fd\u6570\u5bf9\u5f85\u5c0f\u8fb9\u754c\u6846\u4e0e\u5927\u8fb9\u754c\u6846\u7684\u4f1a\u6709\u540c\u6837\u7684\u8bef\u5dee\u3002\u5927\u8fb9\u754c\u6846\u7684\u5c0f\u8bef\u5dee\u901a\u5e38\u662f\u826f\u6027\u7684\uff0c\u4f46\u5c0f\u8fb9\u754c\u6846\u7684\u5c0f\u8bef\u5dee\u5bf9 \\(IOU\\) \u7684\u5f71\u54cd\u8981\u5927\u5f97\u591a\u3002\u6211\u4eec\u7684\u4e3b\u8981\u8bef\u5dee\u6765\u6e90\u662f\u5b9a\u4f4d\u8bef\u5dee\u3002 3. \u4e0e\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u7684\u6bd4\u8f83 \u2003\u76ee\u6807\u68c0\u6d4b\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u6838\u5fc3\u95ee\u9898\u3002\u68c0\u6d4b\u6d41\u7a0b\u901a\u5e38\u4ece\u8f93\u5165\u56fe\u50cf\u4e0a\u63d0\u53d6\u4e00\u7ec4\u5065\u58ee\u7684\u7279\u5f81\uff08 \\(Haar\\) [25]\uff0c \\(SIFT\\) [23]\uff0c \\(HOG\\) [4]\uff0c\u5377\u79ef\u7279\u5f81[6]\uff09\u5f00\u59cb\u3002\u7136\u540e\uff0c\u5206\u7c7b\u5668[36,21,13,10]\u6216\u5b9a\u4f4d\u5668[1,32]\u88ab\u7528\u6765\u8bc6\u522b\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u76ee\u6807\u3002 \u8fd9\u4e9b\u5206\u7c7b\u5668\u6216\u5b9a\u4f4d\u5668\u4ee5\u6ed1\u52a8\u7a97\u53e3\u7684\u65b9\u5f0f\u5728\u6574\u4e2a\u56fe\u50cf\u4e0a\u8fd0\u884c,\u6216\u8005\u5728\u56fe\u50cf\u4e2d\u7684\u4e00\u4e9b\u533a\u57df\u7684\u5b50\u96c6[35,15,39]\u4e0a\u3002 \u6211\u4eec\u5c06 \\(YOLO\\) \u68c0\u6d4b\u7cfb\u7edf\u4e0e\u51e0\u79cd\u9876\u7ea7\u68c0\u6d4b\u6846\u67b6\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u7a81\u51fa\u4e86\u4e3b\u8981\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\u3002 \u2003 \u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b \uff08 Deformable parts models \uff09\u3002\u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b\uff08 \\(DPM\\) \uff09\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b[10]\u3002DPM\u4f7f\u7528\u4e0d\u76f8\u4ea4\u7684\u6d41\u7a0b\u6765\u63d0\u53d6\u9759\u6001\u7279\u5f81\uff0c\u5bf9\u533a\u57df\u8fdb\u884c\u5206\u7c7b\uff0c\u9884\u6d4b\u9ad8\u8bc4\u5206\u533a\u57df\u7684\u8fb9\u754c\u6846\u7b49\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u7528\u5355\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u66ff\u6362\u6240\u6709\u8fd9\u4e9b\u4e0d\u540c\u7684\u90e8\u5206\u3002\u7f51\u7edc\u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3001\u8fb9\u754c\u6846\u9884\u6d4b\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u3002\u7f51\u7edc\u5185\u5d4c\u8bad\u7ec3\u7279\u5f81\u800c\u4e0d\u662f\u9759\u6001\u7279\u5f81\uff0c\u5e76\u4f18\u5316\u5b83\u4eec\u5b8c\u6210\u68c0\u6d4b\u4efb\u52a1\u3002\u6211\u4eec\u7684\u7edf\u4e00\u67b6\u6784\u83b7\u5f97\u4e86\u6bd4DPM\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u6a21\u578b\u3002 \u2003 \\(R-CNN\\) \u53ca\u5176\u53d8\u79cd\u4f7f\u7528 \\(region \\ proposals\\) \u800c\u4e0d\u662f\u6ed1\u52a8\u7a97\u53e3\u6765\u67e5\u627e\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u3002Selective Search[35]\u4ea7\u751f\u6f5c\u5728\u7684\u8fb9\u754c\u6846\u3001\u5377\u79ef\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\u3001 \\(SVM\\) \u5bf9\u8fb9\u754c\u6846\u8fdb\u884c\u8bc4\u5206\u3001\u7ebf\u6027\u6a21\u578b\u8c03\u6574\u8fb9\u754c\u6846\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u6d88\u9664\u91cd\u590d\u68c0\u6d4b\u3002\u8fd9\u4e2a\u590d\u6742\u6d41\u7a0b\u7684\u6bcf\u4e2a\u9636\u6bb5\u90fd\u5fc5\u987b\u72ec\u7acb\u5730\u8fdb\u884c\u7cbe\u786e\u8c03\u6574\uff0c\u6240\u5f97\u5230\u7684\u7cfb\u7edf\u975e\u5e38\u6162\uff0c\u6d4b\u8bd5\u65f6\u6bcf\u5f20\u56fe\u50cf\u9700\u8981\u8d85\u8fc740\u79d2[14]\u3002 \\(YOLO\\) \u4e0e $R-CNN $ \u6709\u4e00\u4e9b\u76f8\u4f3c\u4e4b\u5904\u3002\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u63d0\u51fa\u6f5c\u5728\u7684\u8fb9\u754c\u6846\u5e76\u4f7f\u7528\u5377\u79ef\u7279\u5f81\u5bf9\u8fd9\u4e9b\u6846\u8fdb\u884c\u8bc4\u5206\u3002\u4f46\u662f\u6211\u4eec\u7684\u7cfb\u7edf\u5bf9\u7f51\u683c\u5355\u5143\u63d0\u51fa\u8fdb\u884c\u4e86\u7a7a\u95f4\u9650\u5236\uff0c\u8fd9\u6709\u52a9\u4e8e\u7f13\u89e3\u5bf9\u540c\u4e00\u76ee\u6807\u7684\u591a\u6b21\u68c0\u6d4b\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u8fd8\u63d0\u51fa\u4e86\u66f4\u5c11\u7684\u8fb9\u754c\u6846\uff0c\u6bcf\u5f20\u56fe\u50cf\u53ea\u6709 \\(98\\) \u4e2a\uff0c\u800c \\(Selective Search\\) \u5219\u9700\u8981 \\(2000\\) \u4e2a\u5de6\u53f3\u3002\u6700\u540e\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u8fd9\u4e9b\u5355\u72ec\u7684\u7ec4\u4ef6\u7ec4\u5408\u6210\u4e00\u4e2a\u5355\u4e00\u7684\u3001\u5171\u540c\u4f18\u5316\u7684\u6a21\u578b\u3002 \u2003 \u5176\u5b83\u5feb\u901f\u68c0\u6d4b\u5668( Other Fast Detectors ) \u3002 \\(Fast\\) \u548c \\(Faster \\ R-CNN\\) \u901a\u8fc7\u5171\u4eab\u8ba1\u7b97\u548c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3 \\(Selective \\ Search\\) \u6765\u63d0\u51fa\u533a\u57df\u52a0\u901f \\(R-CNN\\) \u6846\u67b6[14][28]\u3002\u867d\u7136\u5b83\u4eec\u63d0\u4f9b\u4e86\u6bd4 \\(R-CNN\\) \u66f4\u5feb\u7684\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u5ea6\uff0c\u4f46\u4e24\u8005\u4ecd\u7136\u4e0d\u80fd\u8fbe\u5230\u5b9e\u65f6\u6027\u80fd\u3002 \u2003\u8bb8\u591a\u7814\u7a76\u5de5\u4f5c\u96c6\u4e2d\u5728\u52a0\u5feb \\(DPM\\) \u6d41\u7a0b\u4e0a[31][38][5]\u3002\u5b83\u4eec\u52a0\u901f \\(HOG\\) \u8ba1\u7b97\uff0c\u4f7f\u7528\u7ea7\u8054\uff0c\u5e76\u5c06\u8ba1\u7b97\u63a8\u52a8\u5230 \\(GPU\\) \u4e0a\u3002\u4f46\u662f\uff0c\u5b9e\u9645\u4e0a \\(DPM\\) [31]\u5b9e\u65f6\u8fd0\u884c\u53ea\u8fbe\u5230 \\(30Hz\\) \u3002 \u2003 \\(YOLO\\) \u4e0d\u662f\u8bd5\u56fe\u4f18\u5316\u5927\u578b\u68c0\u6d4b\u6d41\u7a0b\u7684\u5355\u4e2a\u7ec4\u4ef6\uff0c\u800c\u662f\u5b8c\u5168\u629b\u5f03\u6d41\u7a0b\uff0c\u4e3a\u63d0\u5347\u68c0\u6d4b\u901f\u5ea6\u800c\u91cd\u65b0\u8bbe\u8ba1\u3002 \u2003\u50cf\u4eba\u8138\u6216\u884c\u4eba\u7b49\u5355\u7c7b\u522b\u7684\u68c0\u6d4b\u5668\u53ef\u4ee5\u88ab\u9ad8\u5ea6\u4f18\u5316\uff0c\u56e0\u4e3a\u4ed6\u4eec\u53ea\u9700\u5904\u7406\u66f4\u5c11\u7684\u591a\u6837\u6027[37]\u3002 \\(YOLO\\) \u662f\u4e00\u79cd\u901a\u7528\u7684\u68c0\u6d4b\u5668\uff0c\u53ef\u4ee5\u5b66\u4e60\u540c\u65f6\u68c0\u6d4b\u5404\u79cd\u76ee\u6807\u3002 \u2003 Deep MultiBox :\u4e0eR-CNN\u4e0d\u540c\uff0cSzegedy\u7b49\u4eba\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u611f\u5174\u8da3\u533a\u57df\uff08 ROI \uff09[8]\uff0c\u800c\u4e0d\u662f\u4f7f\u7528 \\(Selective \\ Search\\) \u3002MultiBox\u8fd8\u53ef\u4ee5\u901a\u8fc7\u7528\u5355\u7c7b\u522b\u9884\u6d4b\u66ff\u6362\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u6765\u6267\u884c\u5355\u76ee\u6807\u68c0\u6d4b\u3002\u7136\u800c\uff0c \\(MultiBox\\) \u65e0\u6cd5\u6267\u884c\u901a\u7528\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u5e76\u4e14\u4ecd\u7136\u53ea\u662f\u4e00\u4e2a\u8f83\u5927\u7684\u68c0\u6d4b\u6d41\u7a0b\u4e2d\u7684\u4e00\u90e8\u5206\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u5bf9\u56fe\u50cf\u5757\u8fdb\u884c\u5206\u7c7b\u3002 \\(YOLO\\) \u548c \\(MultiBox\\) \u90fd\u4f7f\u7528\u5377\u79ef\u7f51\u7edc\u6765\u9884\u6d4b\u56fe\u50cf\u4e2d\u7684\u8fb9\u754c\u6846\uff0c\u4f46\u662f \\(YOLO\\) \u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002 \u2003 \\(OverFeat\\) :Sermanet\u7b49\u4eba\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u5b9a\u4f4d\u5de5\u4f5c\uff0c\u5e76\u4f7f\u8be5\u5b9a\u4f4d\u5668\u8fdb\u884c\u68c0\u6d4b[32]\u3002 \\(OverFeat\\) \u53ef\u4ee5\u9ad8\u6548\u5730\u6267\u884c\u6ed1\u52a8\u7a97\u53e3\u68c0\u6d4b\uff0c\u4f46\u5b83\u4ecd\u7136\u662f\u4e00\u4e2a\u4e0d\u8fde\u8d2f\u7684\u7cfb\u7edf\u3002 \\(OverFeat\\) \u4f18\u5316\u4e86\u5b9a\u4f4d\uff0c\u800c\u4e0d\u662f\u68c0\u6d4b\u6027\u80fd\u3002\u50cf \\(DPM\\) \u4e00\u6837\uff0c\u5b9a\u4f4d\u5668\u5728\u8fdb\u884c\u9884\u6d4b\u65f6\u53ea\u80fd\u770b\u5230\u5c40\u90e8\u4fe1\u606f\u3002 \\(OverFeat\\) \u4e0d\u80fd\u63a8\u7406\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u56e0\u6b64\u9700\u8981\u5927\u91cf\u7684\u540e\u5904\u7406\u6765\u4ea7\u751f\u4e00\u81f4\u7684\u68c0\u6d4b\u3002 \u2003 \\(MultiGrasp\\) : \u6211\u4eec\u7684\u5de5\u4f5c\u5728\u8bbe\u8ba1\u4e0a\u7c7b\u4f3c\u4e8e \\(Redmon\\) \u7b49[27]\u7684 \\(grasp\\) \u68c0\u6d4b\u3002\u6211\u4eec\u5bf9\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u7f51\u683c\u65b9\u6cd5\u662f\u57fa\u4e8e \\(MultiGrasp\\) \u7cfb\u7edf\u5bf9\u4e8e \\(grasp\u68c0\u6d4b\\) \u7684\u56de\u5f52\u5206\u6790\u3002\u7136\u800c\uff0c \\(grasp\\) \u68c0\u6d4b\u6bd4\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u8981\u7b80\u5355\u5f97\u591a\u3002 \\(MultiGrasp\\) \u53ea\u9700\u8981\u4e3a\u5305\u542b\u4e00\u4e2a\u76ee\u6807\u7684\u56fe\u50cf\u9884\u6d4b\u4e00\u4e2a\u53ef\u4ee5 \\(grasp\\) \u7684\u533a\u57df( \u5373\u9002\u5408\u6293\u53d6\u7684\u533a\u57df )\u3002\u4e0d\u5fc5\u4f30\u8ba1\u76ee\u6807\u7684\u5927\u5c0f\u3001\u4f4d\u7f6e\u6216\u76ee\u6807\u8fb9\u754c\u6216\u9884\u6d4b\u76ee\u6807\u7684\u7c7b\u522b\uff0c\u53ea\u9700\u8981\u627e\u5230\u9002\u5408\u6293\u53d6\u7684\u533a\u57df\u3002 \\(YOLO\\) \u53ef\u4ee5\u9884\u6d4b\u56fe\u50cf\u4e2d\u591a\u4e2a\u7c7b\u522b\u7684\u591a\u4e2a\u76ee\u6807\u7684\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u3002 4. \u6d4b\u8bd5\u5b9e\u9a8c \u9996\u5148\uff0c\u6211\u4eec\u5728 \\(PASCAL \\ VOC \\ 2007\\) \u4e0a\u6bd4\u8f83\u4e86 \\(YOLO\\) \u548c\u5176\u5b83\u7684\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf\u3002\u4e3a\u4e86\u7406\u89e3 \\(YOLO\\) \u548c \\(R-CNN\\) \u53d8\u79cd\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u63a2\u7d22\u4e86 \\(YOLO\\) \u548c \\(R-CNN\\) \u6027\u80fd\u6700\u9ad8\u7684\u7248\u672c\u4e4b\u4e00 \\(Fast\\ R-CNN\\) [14]\u5728 \\(VOC \\ 2007\\) \u4e0a\u9519\u8bef\u7387\u3002\u6839\u636e\u4e0d\u540c\u7684\u8bef\u5dee\u66f2\u7ebf\uff0c\u6211\u4eec\u7684\u7814\u7a76\u663e\u793a \\(YOLO\\) \u53ef\u4ee5\u7528\u6765\u91cd\u65b0\u8bc4\u4f30 \\(Fast \\ R-CNN\\) \u68c0\u6d4b\uff0c\u5e76\u51cf\u5c11\u80cc\u666f\u5047\u9633\u6027\u5e26\u6765\u7684\u8bef\u5dee\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u5728 \\(VOC \\ 2012\\) \u4e0a\u7684\u7ed3\u679c\uff0c\u5e76\u4e0e\u76ee\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u6bd4\u8f83\u4e86 \\(mAP\\) \u3002\u6700\u540e\uff0c\u5728\u4e24\u4e2a\u827a\u672f\u54c1\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86\u6211\u4eec \\(YOLO\\) \u6bd4\u5176\u4ed6\u68c0\u6d4b\u5668\u66f4\u80fd\u6cdb\u5316\u5230\u65b0\u7684\u9886\u57df\u3002 4.1 \u4e0e\u5176\u4ed6\u5b9e\u65f6\u7cfb\u7edf\u7684\u6bd4\u8f83 \u2003\u76ee\u6807\u68c0\u6d4b\u65b9\u9762\u7684\u8bb8\u591a\u7814\u7a76\u5de5\u4f5c\u90fd\u96c6\u4e2d\u5728\u5bf9\u6807\u51c6\u68c0\u6d4b\u6d41\u7a0b[5]\uff0c[38]\uff0c[31]\uff0c[14]\uff0c[17]\uff0c[28]\u63d0\u5347\u901f\u5ea6\u4e0a\u3002\u7136\u800c\uff0c\u53ea\u6709Sadeghi\u7b49\u771f\u6b63\u7814\u7a76\u51fa\u4e86\u4e00\u4e2a\u5b9e\u65f6\u8fd0\u884c\u7684\u68c0\u6d4b\u7cfb\u7edf\uff08\u6bcf\u79d230\u5e27\u6216\u66f4\u597d\uff09[31]\u3002\u6211\u4eec\u5c06YOLO\u4e0e\u4ed6\u4eecDPM\u7684GPU\u5b9e\u73b0\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5176\u572830Hz\u6216100Hz\u4e0b\u8fd0\u884c\u3002\u867d\u7136\u5176\u5b83\u7684\u7814\u7a76\u5de5\u4f5c\u6ca1\u6709\u8fbe\u5230\u5b9e\u65f6\u68c0\u6d4b\u7684\u6807\u51c6\uff0c\u6211\u4eec\u4e5f\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u76f8\u5bf9mAP\u548c\u901f\u5ea6\u6765\u68c0\u67e5\u76ee\u6807\u68c0\u6d4b\u7cfb\u7edf\u4e2d\u7cbe\u5ea6\u2014\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002 \u2003 \\(Fast \\ YOLO\\) \u662f \\(PASCAL\\) \u4e0a\u6700\u5feb\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5;\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u662f\u73b0\u5b58\u901f\u5ea6\u6700\u5feb\u7684\u7269\u4f53\u63a2\u6d4b\u5668\u3002 \\(mAP\\) \u7684\u51c6\u786e\u7387\u4e3a \\(52.7%\\) \uff0c\u662f\u4e4b\u524d\u5b9e\u65f6\u68c0\u6d4b\u5de5\u4f5c\u7684\u4e24\u500d\u591a\u3002 \\(YOLO\\) \u5c06 \\(mAP\\) \u63a8\u81f3 \\(63.4%\\) \uff0c\u540c\u65f6\u4ecd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002 \u2003\u6211\u4eec\u4e5f\u4f7f\u7528 \\(VGG-16\\) \u8bad\u7ec3\u4e86 \\(YOLO\\) \u3002\uff08 \u8bd1\u8005\u6ce8\uff1aYOLO\u4f7f\u7528\u4e86\u4f5c\u8005\u81ea\u5df1\u5f00\u53d1\u7684DarkNet\u6a21\u578b\u4e3abaseline \uff09\u8fd9\u4e2a\u6a21\u578b\u6bd4 \\(YOLO\\) \u66f4\u51c6\u786e\uff0c\u4f46\u901f\u5ea6\u6162\u5f97\u591a\u3002\u8fd9\u4e2a\u6a21\u578b\u53ef\u4ee5\u7528\u6765\u4e0e\u4f9d\u8d56\u4e8e \\(VGG-16\\) \u7684\u5176\u5b83\u68c0\u6d4b\u7cfb\u7edf\u4f5c\u6bd4\u8f83\uff0c\u4f46\u7531\u4e8e\u5b83\u6bd4\u5b9e\u65f6\u7684 \\(YOLO\\) \u66f4\u6162\uff0c\u672c\u6587\u7684\u5176\u4f59\u90e8\u5206\u4e3b\u8981\u5173\u6ce8\u6211\u4eec\u66f4\u5feb\u7684\u6a21\u578b\u3002 \u2003 \\(Fastest \\ DPM\\) \u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u592a\u591a \\(mAP\\) \u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5730\u52a0\u901f \\(DPM\\) \uff0c\u4f46\u5b83\u4ecd\u7136\u4f1a\u5c06\u5b9e\u65f6\u6027\u80fd\u964d\u4f4e2\u500d[38]\u3002\u4e0e\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u76f8\u6bd4\uff0c \\(DPM\\) \u76f8\u5bf9\u8f83\u4f4e\u7684\u68c0\u6d4b\u7cbe\u5ea6\u4e5f\u662f\u5176\u9650\u5236\u3002 \\(\\begin{array}{lrrr} \\text { Real-Time Detectors } & \\text { Train } & \\text { mAP } & \\text { FPS } \\\\ \\hline \\text { 100Hz DPM [31] } & 2007 & 16.0 & 100 \\\\ \\text { 30Hz DPM [31] } & 2007 & 26.1 & 30 \\\\ \\text { Fast YOLO } & 2007+2012 & 52.7 & \\mathbf{1 5 5} \\\\ \\text { YOLO } & 2007+2012 & \\mathbf{6 3 . 4} & 45 \\\\ \\hline \\hline \\text { Less Than Real-Time } & & & \\\\ \\hline \\text { Fastest DPM [38] } & 2007 & 30.4 & 15 \\\\ \\text { R-CNN Minus R [20] } & 2007 & 53.5 & 6 \\\\ \\text { Fast R-CNN [14] } & 2007+2012 & 70.0 & 0.5 \\\\ \\text { Faster R-CNN VGG-16[28] } & 2007+2012 & 73.2 & 7 \\\\ \\text { Faster R-CNN ZF [28] } & 2007+2012 & 62.1 & 18 \\\\ \\text { YOLO VGG-16 } & 2007+2012 & 66.4 & 21 \\end{array}\\) \u88681\uff1aPASCAL VOC 2007 \u7684\u5b9e\u65f6\u7cfb\u7edf \u6bd4\u8f83\u5feb\u901f\u63a2\u6d4b\u5668\u7684\u6027\u80fd\u548c\u901f\u5ea6\u3002 \\(Fast \\ YOLO\\) \u662f \\(PASCAL \\ VOC\\) \u68c0\u6d4b\u8bb0\u5f55\u4e2d\u6700\u5feb\u7684\u68c0\u6d4b\u5668\uff0c\u51c6\u786e\u6027\u4ecd\u7136\u662f\u4efb\u4f55\u5176\u4ed6\u5b9e\u65f6\u68c0\u6d4b\u5668\u7684\u4e24\u500d\u3002 \\(YOLO\\) \u6bd4\u5feb\u901f\u7248\u672c\u66f4\u7cbe\u786e \\(10mAP\\) \uff0c\u540c\u65f6\u5b9e\u65f6\u901f\u5ea6\u8fdc\u8fdc\u9ad8\u4e8e\u5176\u4ed6\u68c0\u6d4b\u5668\u3002 \u2003 \\(R-CNN \\ minnus \\ R\\) \u5c06\u9009\u62e9\u6027\u641c\u7d22\u66ff\u6362\u4e3a\u9759\u6001\u8fb9\u754c\u6846proposals [20]\u3002\u867d\u7136\u901f\u5ea6\u6bd4R-CNN\u66f4\u5feb\uff0c\u4f46\u4ecd\u7136\u8fbe\u4e0d\u5230\u5b9e\u65f6\uff0c\u5e76\u4e14\u7531\u4e8e\u6ca1\u6709\u597d\u7684\u8fb9\u754c\u6846proposals\uff0c\u51c6\u786e\u6027\u53d7\u5230\u4e86\u4e25\u91cd\u5f71\u54cd\u3002 \u2003 \\(Fast \\ R-CNN\\) \u52a0\u5feb\u4e86 \\(R-CNN\\) \u7684\u5206\u7c7b\u9636\u6bb5\uff0c\u4f46\u662f\u4ecd\u7136\u4f9d\u8d56selective search\uff0c\u6bcf\u5f20\u56fe\u50cf\u9700\u8981\u82b1\u8d39\u5927\u7ea62\u79d2\u6765\u751f\u6210\u8fb9\u754c\u6846proposals\u3002\u56e0\u6b64\uff0c\u5b83\u5177\u6709\u5f88\u9ad8\u7684mAP\uff0c\u4f46\u662f0.5 fps\u7684\u901f\u5ea6\u4ecd\u79bb\u5b9e\u65f6\u6027\u5f88\u8fdc\u3002 \u2003 \u6700\u8fd1 \\(Faster \\ R-CNN\\) \u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u4e86selective search\u6765\u63d0\u51fa\u8fb9\u754c\u6846\uff0c\u7c7b\u4f3c\u4e8eSzegedy\u7b49[8]\u3002\u5728\u6211\u4eec\u7684\u6d4b\u8bd5\u4e2d\uff0c\u4ed6\u4eec\u6700\u7cbe\u786e\u7684\u6a21\u578b\u8fbe\u5230\u4e867fps\uff0c\u800c\u8f83\u5c0f\u7684\u3001\u4e0d\u592a\u7cbe\u786e\u7684\u6a21\u578b\u8fd0\u884c\u901f\u5ea6\u8fbe\u523018fps\u3002 \\(VGG-16\\) \u7248\u672c\u7684 \\(Faster \\ R-CNN\\) \u8981\u9ad8\u51fa \\(10mAP\\) \uff0c\u4f46\u901f\u5ea6\u6bd4 \\(YOLO\\) \u6162 \\(6\\) \u500d\u3002ZeilerFergus\u7684 \\(Faster \\ R-CNN\\) \u53ea\u6bd4 \\(YOLO\\) \u6162\u4e862.5\u500d\uff0c\u4f46\u4e5f\u4e0d\u592a\u51c6\u786e\u3002 4.2 \u5728VOC 2007\u4e0a\u7684\u8bef\u5dee\u5206\u6790 \u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u68c0\u67e5 \\(YOLO\\) \u548c\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u8be6\u7ec6\u5206\u6790\u4e86 \\(VOC \\ 2007\\) \u7684\u7ed3\u679c\u3002\u6211\u4eec\u5c06 \\(YOLO\\) \u4e0e \\(Fast \\ R-CNN\\) \u8fdb\u884c\u6bd4\u8f83\uff0c\u56e0\u4e3a \\(Fast \\ R-CNN\\) \u662f \\(PASCAL\\) \u4e0a\u6027\u80fd\u6700\u9ad8\u7684\u68c0\u6d4b\u5668\u4e4b\u4e00\u5e76\u4e14\u5b83\u7684\u68c0\u6d4b\u4ee3\u7801\u662f\u53ef\u516c\u5f00\u5f97\u5230\u7684\u3002 \u2003\u6211\u4eec\u4f7f\u7528Hoiem\u7b49\u4eba[19]\u7684\u65b9\u6cd5\u548c\u5de5\u5177\u3002\u5bf9\u4e8e\u6d4b\u8bd5\u65f6\u7684\u6bcf\u4e2a\u7c7b\u522b\uff0c\u6211\u4eec\u53ea\u5173\u6ce8\u8fd9\u4e2a\u7c7b\u522b\u7684\u524dN\u4e2a\u9884\u6d4b\u3002\u6bcf\u4e2a\u9884\u6d4b\u8981\u4e48\u5f52\u4e3a\u6b63\u786e\uff0c\u8981\u4e48\u6839\u636e\u9519\u8bef\u7c7b\u578b\u8fdb\u884c\u5f52\u7c7b\uff1a Correct\uff1a\u5206\u7c7b\u6b63\u786e\u4e14 \\(IOU >0.5\\) \u3002 Localization\uff1a\u5206\u7c7b\u6b63\u786e\u4f46 \\(0.1<IOU<0.5\\) \u3002 Similar\uff1a\u5206\u7c7b\u7684\u7c7b\u522b\u76f8\u4f3c\u4e14 \\(IOU>0.1\\) \u3002 Other\uff1a\u7c7b\u522b\u9519\u8bef\uff0c \\(IOU>0.1\\) \u3002 Background\uff1a\u5206\u7c7b\u4e3a\u5176\u5b83\u4efb\u4f55\u76ee\u6807\uff0c \\(IOU<0.1\\) \u3002 \u56fe4\uff1a\u9519\u8bef\u5206\u6790: \\(Fast \\ R-CNN\\) vs. \\(YOLO\\) \u8fd9\u4e9b\u56fe\u8868\u663e\u793a\u4e86\u5404\u79cd\u7c7b\u522b\u7684\u524dN\u4e2a\u68c0\u6d4b\u4e2d\u5b9a\u4f4d\u548c\u80cc\u666f\u9519\u8bef\u7684\u767e\u5206\u6bd4(N = #\u8be5\u7c7b\u522b\u4e2d\u7684\u76ee\u6807\u6570) \u2003 \\(YOLO\\) \u5f88\u96be\u6b63\u786e\u6b63\u786e\u5b9a\u4f4d\u76ee\u6807\u3002\u5b9a\u4f4d\u8bef\u5dee\u6bd4\u5176\u5b83\u8bef\u5dee\u9519\u8bef\u6765\u6e90\u603b\u5408\u90fd\u591a\u3002 \\(Fast \\ R-CNN\\) \u5b9a\u4f4d\u8bef\u5dee\u5c11\u5f88\u591a\uff0c\u4f46\u80cc\u666f\u8bef\u5dee\u66f4\u591a\u3002\u5b83\u7684\u68c0\u6d4b\u7ed3\u679c\u4e2d \\(13.6%\\) \u662f\u4e0d\u5305\u542b\u4efb\u4f55\u76ee\u6807\u7684\u5047\u9633\u6027\u3002 \\(Fast \\ R-CNN\\) \u4e0e \\(YOLO\\) \u76f8\u6bd4\uff0c\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u76ee\u6807\u7684\u53ef\u80fd\u6027\u9ad8\u51fa\u8fd13\u500d\u3002\uff08 \u8bd1\u8005\u6ce8\uff1a\u6839\u636e\u56fe4\uff0c13.6/4.75=2.86 \uff09 4.3 \u7ed3\u5408 \\(Fast \\ R-CNN\\) \u548c \\(YOLO\\) \u2003 \\(YOLO\\) \u6bd4 \\(Fast \\ R-CNN\\) \u7684\u80cc\u666f\u8bef\u68c0\u8981\u5c11\u5f97\u591a\u3002\u901a\u8fc7\u4f7f\u7528 \\(YOLO\\) \u6d88\u9664 \\(Fast \\ R-CNN\\) \u7684\u80cc\u666f\u68c0\u6d4b\uff0c\u6211\u4eec\u83b7\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u5bf9\u4e8e \\(RCNN\\) \u9884\u6d4b\u7684\u6bcf\u4e2a\u8fb9\u754c\u6846\uff0c\u6211\u4eec\u68c0\u67e5 \\(YOLO\\) \u662f\u5426\u9884\u6d4b\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u7684\u6846\u3002\u5982\u679c\u662f\u8fd9\u6837\uff0c\u6211\u4eec\u6839\u636e \\(YOLO\\) \u9884\u6d4b\u7684\u6982\u7387\u548c\u4e24\u4e2a\u76d2\u5b50\u4e4b\u95f4\u7684\u91cd\u53e0\u6765\u5bf9\u8fd9\u4e2a\u9884\u6d4b\u8fdb\u884c\u6539\u8fdb\u3002 \u2003\u6700\u597d\u7684 \\(Fast \\ R-CNN\\) \u6a21\u578b\u5728 \\(VOC \\ 2007\\) \u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230\u4e86 71.8%\u7684 \\(mAP\\) \u3002\u5f53\u4e0e \\(YOLO\\) \u7ed3\u5408\u65f6\uff0c\u5176 \\(mAP\\) \u589e\u52a0\u4e86 3.2% \u8fbe\u5230\u4e86 75.0% \u3002\u6211\u4eec\u4e5f\u5c1d\u8bd5\u5c06\u6700\u597d\u7684 \\(Fast \\ R-CNN\\) \u6a21\u578b\u4e0e\u5176\u5b83\u51e0\u4e2a\u7248\u672c\u7684 \\(Fast \\ R-CNN\\) \u7ed3\u5408\u8d77\u6765\u3002\u8fd9\u4e9b\u6a21\u578b\u7ec4\u5408\u4ea7\u751f\u4e860.3-0.6%\u7684\u5c0f\u5e45\u589e\u52a0\uff0c\u8be6\u89c1\u88682\u3002 \\(\\begin{array}{lrrr} & \\text { mAP } & \\text { Combined } & \\text { Gain } \\\\ \\hline \\text { Fast R-CNN } & 71.8 & - & - \\\\ \\hline \\text { Fast R-CNN (2007 data) } & \\mathbf{6 6 . 9} & 72.4 & .6 \\\\ \\text { Fast R-CNN (VGG-M) } & 59.2 & 72.4 & .6 \\\\ \\text { Fast R-CNN (CaffeNet) } & 57.1 & 72.1 & .3 \\\\ \\text { YOLO } & 63.4 & \\mathbf{7 5 . 0} & \\mathbf{3 . 2} \\end{array}\\) \u88682:VOC 2007\u7684\u6a21\u578b\u7ec4\u5408\u8bd5\u9a8c\u3002\u6211\u4eec\u7528 \\(Fast \\ R-CNN\\) \u7684\u6700\u4f73\u7248\u672c\u6765\u68c0\u9a8c\u5404\u79cd\u6a21\u578b\u7684\u7ec4\u5408\u6548\u679c\u3002 \\(Fast \\ R-CNN\\) \u7684\u5176\u4ed6\u7248\u672c\u53ea\u6539\u5584\u4e86\u5f88\u5c0f\u7684\u6027\u80fd\uff0c\u800c \\(YOLO\\) \u63d0\u4f9b\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002 \u88683:PASCAL VOC 2012\u6392\u884c\u699c\u30022015\u5e7411\u67086\u65e5\uff0cYOLO\u4e0e\u5b8c\u6574comp4(\u5141\u8bb8\u5916\u90e8\u6570\u636e)\u516c\u5f00\u6392\u884c\u699c\u7684\u5bf9\u6bd4\u3002 \\(mAP\\) \u548c \u6bcf\u4e2a\u7c7bAP \u90fd\u663e\u793a\u5728\u5404\u79cd\u68c0\u6d4b\u65b9\u6cd5\u3002 \\(YOLO\\) \u662f\u552f\u4e00\u7684\u5b9e\u65f6\u68c0\u6d4b\u5668\u3002 \\(Fast \\ R-CNN + YOLO\\) \u662f\u7b2c\u56db\u9ad8\u7684\u5f97\u5206\u65b9\u6cd5\uff0c\u6bd4 \\(Fast \\ R-CNN\\) \u63d0\u9ad8\u4e862.3%\u7684 \\(mAP\\) \u3002 \u2003\u6765\u81eaYOLO\u7684\u63d0\u5347\u4e0d\u4ec5\u4ec5\u662f\u6a21\u578b\u96c6\u6210\u7684\u526f\u4ea7\u54c1\uff0c\u56e0\u4e3a\u7ec4\u5408\u4e0d\u540c\u7248\u672c\u7684Fast R-CNN\u51e0\u4e4e\u6ca1\u6709\u4ec0\u4e48\u6539\u8fdb\u3002\u76f8\u53cd\uff0c\u6b63\u662f\u56e0\u4e3a \\(YOLO\\) \u5728\u6d4b\u8bd5\u65f6\u51fa\u73b0\u4e86\u5404\u79cd\u5404\u6837\u7684\u8bef\u5dee\uff0c\u6240\u4ee5\u5728\u63d0\u9ad8 \\(Fast \\ R-CNN\\) \u7684\u6027\u80fd\u65b9\u9762\u975e\u5e38\u6709\u6548\u3002 \u2003\u9057\u61be\u7684\u662f\uff0c\u8fd9\u4e2a\u7ec4\u5408\u5e76\u6ca1\u6709\u4ece \\(YOLO\\) \u7684\u901f\u5ea6\u4e2d\u53d7\u76ca\uff0c\u56e0\u4e3a\u6211\u4eec\u5206\u522b\u8fd0\u884c\u6bcf\u4e2a\u6a21\u578b\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u7ec4\u5408\u8d77\u6765\u3002\u4f46\u662f\uff0c\u7531\u4e8e \\(YOLO\\) \u901f\u5ea6\u5982\u6b64\u4e4b\u5feb\uff0c\u4e0e \\(Fast \\ R-CNN\\) \u76f8\u6bd4\uff0c\u4e0d\u4f1a\u663e\u8457\u7684\u589e\u52a0\u4efb\u4f55\u8ba1\u7b97\u65f6\u95f4\u3002 4.4 VOC 2012\u6761\u7ed3\u679c \u2003\u5728 \\(VOC \\ 2012\\) \u6d4b\u8bd5\u96c6\u4e0a\uff0c \\(YOLO\\) \u83b7\u5f97\u4e8657.9% \u7684 \\(mAP\\) \u3002\u8fd9\u4f4e\u4e8e\u73b0\u6709\u7684\u6700\u597d\u6280\u672f\uff0c\u5982\u88683\u6240\u793a\u5176\u63a5\u8fd1\u4e8e\u4f7f\u7528VGG-16\u7684\u539f\u59cbR-CNN\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u4e0e\u5176\u6700\u63a5\u8fd1\u7684\u7ade\u4e89\u5bf9\u624b\u76f8\u6bd4\uff0c\u9700\u8981\u6539\u5584\u5728\u5c0f\u76ee\u6807\u4e0a\u7684\u68c0\u6d4b\u3002\u5728\u6c34\u74f6\u3001\u7ef5\u7f8a\u548c\u7535\u89c6/\u663e\u793a\u5668\u7b49\u7c7b\u522b\u4e0a\uff0cYOLO\u7684\u5f97\u5206\u6bd4R-CNN\u6216Feature Edit\u4f4e8\u221210%\u3002\u7136\u800c\uff0c\u5728\u732b\u548c\u706b\u8f66\u7b49\u5176\u5b83\u7c7b\u522b\u4e0aYOLO\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u3002 \u2003\u6211\u4eec\u8054\u5408\u7684 \\(Fast \\ R-CNN+YOLO\\) \u6a21\u578b\u662f\u6027\u80fd\u6700\u9ad8\u7684\u68c0\u6d4b\u65b9\u6cd5\u4e4b\u4e00\u3002 \\(Fast \\ R-CNN\\) \u548c \\(YOLO\\) \u7684\u7ec4\u5408\u4e2d\u83b7\u5f97\u4e862.3%\u7684\u63d0\u9ad8\uff0c\u5728\u516c\u5f00\u6392\u884c\u699c\u4e0a\u63d0\u5347\u4e865\u4e2a\u540d\u6b21\u3002 4.5 \u6cdb\u5316\u80fd\u529b\uff1a\u827a\u672f\u54c1\u4e2d\u7684\u4eba\u7269\u68c0\u6d4b \u2003\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u672f\u6570\u636e\u96c6\u4ee5\u76f8\u540c\u5206\u5e03\u83b7\u53d6\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u3002\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u4e2d\uff0c\u5f88\u96be\u9884\u6d4b\u6240\u6709\u53ef\u80fd\u7684\u6837\u672c\uff0c\u800c\u4e14\u6d4b\u8bd5\u6570\u636e\u53ef\u80fd\u4e0e\u7cfb\u7edf\u4e4b\u524d\u770b\u5230\u7684\u4e0d\u540c[3]\u3002( \u56e0\u4e3a\u6d4b\u8bd5\u6570\u636e\u4e0e\u6a21\u578b\u8bad\u7ec3\u7684\u6570\u636e\u53ef\u80fd\u5728\u98ce\u683c\u3001\u6a21\u5f0f\u3001\u76ee\u6807\u8868\u73b0\u5f62\u5f0f\u7b49\u65b9\u9762\u6709\u5f88\u5927\u7684\u533a\u522b\uff0c\u4f8b\u5982\u6a21\u578b\u8bad\u7ec3\u65f6\u7684\u6570\u636e\u662f\u7528\u76f8\u673a\u62cd\u6444\u7684\u56fe\u50cf\uff0c\u800c\u6d4b\u8bd5\u65f6\u7528\u6cb9\u753b\u4f5c\u54c1\u56fe\u50cf\uff0c\u6b64\u65f6\u7531\u4e8e\u6cb9\u753b\u4f5c\u54c1\u6bd4\u8f83\u62bd\u8c61\uff0c\u6a21\u578b\u5c31\u53ef\u80fd\u65e0\u6cd5\u5f88\u597d\u5730\u8bc6\u522b\u5176\u4e2d\u7684\u76ee\u6807 ) \u6211\u4eec\u5728 \\(Picasso\\) \u6570\u636e\u96c6\u4e0a[12]\u548c \\(People-Art\\) \u6570\u636e\u96c6[3]\u4e0a\u5c06 \\(YOLO\\) \u4e0e\u5176\u5b83\u7684\u68c0\u6d4b\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\uff0c\u4e24\u4e2a\u6570\u636e\u96c6\u7528\u4e8e\u827a\u672f\u54c1\u4e0a\u7684\u4eba\u7269\u68c0\u6d4b\u3002 \u2003\u56fe5\u6240\u793a\u4e3a \\(YOLO\\) \u548c\u5176\u5b83\u68c0\u6d4b\u65b9\u6cd5\u4e4b\u95f4\u6027\u80fd\u6bd4\u8f83\u7684\u7ed3\u679c\u3002\u4f5c\u4e3a\u53c2\u8003\uff0c\u6211\u4eec\u5728person\u4e0a\u63d0\u4f9b \\(VOC \\ 2007\\) \u7684\u68c0\u6d4b \\(AP\\) \uff0c\u5176\u4e2d\u6240\u6709\u6a21\u578b\u4ec5\u5728 \\(VOC \\ 2007\\) \u6570\u636e\u4e0a\u8bad\u7ec3\u3002\u5728Picasso\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u7684\u6a21\u578b\u4f7f\u7528 \\(VOC \\ 2012\\) \u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u800c \\(People-Art\\) \u6570\u636e\u96c6\u6d4b\u8bd5\u7684\u6a21\u578b\u4f7f\u7528 \\(VOC \\ 2010\\) \u8fdb\u884c\u4e86\u8bad\u7ec3\u3002 \u2003 \\(R-CNN\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u7684 \\(AP\\) \u5f88\u9ad8\u3002\u4f46\u662f\u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u7cbe\u5ea6\u4e0b\u964d\u4e86\u5f88\u591a\u3002 \\(R-CNN\\) \u4f7f\u7528Selective Search\u6765\u751f\u6210\u5019\u9009\u8fb9\u754c\u6846\uff0c\u73b0\u5728\u6362\u4e3a\u81ea\u7136\u56fe\u7247\u3002\u5728\u5206\u7c7b\u65f6\u53ea\u80fd\u770b\u5230\u56fe\u7247\u7684\u4e00\u4e2a\u5c0f\u533a\u57df\uff0c\u9700\u8981\u8d28\u91cf\u5f88\u9ad8\u7684\u5019\u9009\u624d\u53ef\u4ee5\u3002 \u2003 \\(DPM\\) \u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u540e \\(AP\\) \u8fd8\u4fdd\u6301\u7684\u4e0d\u9519\u3002\u4e4b\u524d\u7684\u5de5\u4f5c\u7406\u8bba \\(DPM\\) \u8868\u73b0\u4e0d\u9519\u7684\u539f\u56e0\u662f\u5b83\u5bf9\u4e8e\u7269\u4f53\u7684\u5f62\u72b6\u548c\u5e03\u5c40\u6709\u5f88\u5f3a\u7684\u7a7a\u95f4\u6a21\u578b\u3002\u867d\u7136 \\(DPM\\) \u6ca1\u6709\u50cf \\(R-CNN\\) \u90a3\u6837\u7cbe\u5ea6\u4e0b\u964d\u5f88\u591a\uff0c\u4f46\u662f\u5b83\u7684 \\(AP\\) \u672c\u6765\u5c31\u6bd4\u8f83\u4f4e\u3002 \u2003 \\(YOLO\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u7684\u8868\u73b0\u4e0d\u9519\uff0c\u5f53\u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u65f6\u6bd4\u5176\u4ed6\u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\u7684\u5c11\u3002\u4e0e \\(DPM\\) \u7c7b\u4f3c\uff0c \\(YOLO\\) \u5bf9\u7269\u4f53\u7684\u5927\u5c0f\u548c\u5f62\u72b6\u8fdb\u884c\u5efa\u6a21\uff0c\u8fd8\u6709\u7269\u4f53\u548c\u7269\u4f53\u901a\u5e38\u51fa\u73b0\u7684\u4f4d\u7f6e\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u827a\u672f\u54c1\u548c\u81ea\u7136\u56fe\u7247\u5728\u50cf\u7d20\u7ea7\u522b\u4e0a\u5dee\u5f02\u5f88\u5927\uff0c\u4f46\u662f\u7269\u4f53\u7684\u5927\u5c0f\u548c\u5f62\u72b6\u662f\u7c7b\u4f3c\u7684\uff0c\u56e0\u6b64 \\(YOLO\\) \u4ecd\u7136\u53ef\u4ee5\u5f88\u597d\u7684\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u68c0\u6d4b\u7269\u4f53\u3002 \u56fe5\uff1aPicasso \u548c People-Art \u6570\u636e\u96c6\u7efc\u5408\u7684\u7ed3\u679c\u3002 (a): \u5728Picasso\u6570\u636e\u96c6\u4e0a\u7684PR\u66f2\u7ebf\u3002 (b): \u5728 VOC 2007, Picasso, \u548c People-Art \u7684\u7ed3\u679c\u6570\u636e\u3002Picasso \u6570\u636e\u96c6\u8bc4\u4f30AP\u548c\u6700\u4f73 \\(F_1\\) \u5206\u6570\u3002 \u56fe6\uff1a\u68c0\u6d4b\u7684\u7ed3\u679c\u3002 \\(YOLO\\) \u8fd0\u884c\u7684\u6837\u672c\u827a\u672f\u4f5c\u54c1 \u548c \u6765\u81ea\u4e92\u8054\u7f51\u7684\u81ea\u7136\u56fe\u50cf\u3002\u867d\u7136\u5b83\u786e\u5b9e\u8ba4\u4e3a\u4e00\u4e2a\u4eba\u662f\u4e00\u67b6\u98de\u673a\uff0c\u4f46\u5b83\u57fa\u672c\u4e0a\u662f\u51c6\u786e\u7684\u3002 5.\u91ce\u5916\u5b9e\u65f6\u68c0\u6d4b \u2003 \\(YOLO\\) \u662f\u4e00\u79cd\u5feb\u901f\u3001\u7cbe\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u975e\u5e38\u9002\u5408\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u3002\u6211\u4eec\u5c06 \\(YOLO\\) \u8fde\u63a5\u5230\u7f51\u7edc\u6444\u50cf\u5934\uff0c\u5e76\u9a8c\u8bc1\u5b83\u662f\u5426\u80fd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\uff0c\u5305\u62ec\u4ece\u6444\u50cf\u5934\u83b7\u53d6\u56fe\u50cf\u5e76\u663e\u793a\u68c0\u6d4b\u7ed3\u679c\u7684\u65f6\u95f4\u3002 \u2003\u6700\u7ec8\u7684\u7cfb\u7edf\u662f\u4ea4\u4e92\u5f0f\u7684\u5e76\u4e14\u662f\u53c2\u4e0e\u5f0f\u7684\u3002\u867d\u7136 \\(YOLO\\) \u5355\u72ec\u5730\u5904\u7406\u56fe\u50cf\uff0c\u4f46\u5f53\u8fde\u63a5\u5230\u7f51\u7edc\u6444\u50cf\u5934\u65f6\uff0c\u5176\u529f\u80fd\u7c7b\u4f3c\u4e8e\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u53ef\u5728\u76ee\u6807\u79fb\u52a8\u548c\u5916\u89c2\u53d8\u5316\u65f6\u68c0\u6d4b\u76ee\u6807\u3002\u7cfb\u7edf\u6f14\u793a\u548c\u6e90\u4ee3\u7801\u53ef\u4ee5\u5728\u6211\u4eec\u7684\u9879\u76ee\u7f51\u7ad9\u4e0a\u627e\u5230\uff1ahttp://pjreddie.com/yolo/\u3002 6.\u603b\u7ed3 \u2003 \u6211\u4eec\u4ecb\u7ecd\u4e86 \\(YOLO\\) \uff0c\u4e00\u79cd\u7edf\u4e00\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u3002\u6211\u4eec\u7684\u6a21\u578b\u6784\u5efa\u7b80\u5355\uff0c\u53ef\u4ee5\u76f4\u63a5\u5728\u6574\u5f20\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u4e0e\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c \\(YOLO\\) \u76f4\u63a5\u5728\u5bf9\u5e94\u68c0\u6d4b\u6027\u80fd\u7684\u635f\u5931\u51fd\u6570\u4e0a\u8bad\u7ec3\uff0c\u5e76\u4e14\u6574\u4e2a\u6a21\u578b\u7edf\u4e00\u8bad\u7ec3\u3002 \\(Fast \\ YOLO\\) \u662f\u6587\u732e\u4e2d\u6700\u5feb\u7684\u901a\u7528\u76ee\u7684\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c \\(YOLO\\) \u63a8\u52a8\u4e86\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7684\u6700\u65b0\u6280\u672f\u3002 \\(YOLO\\) \u8fd8\u5f88\u597d\u5730\u6cdb\u5316\u5230\u65b0\u9886\u57df\uff0c\u4f7f\u5176\u6210\u4e3a\u8981\u6c42\u5feb\u901f\u3001\u5f3a\u5927\u76ee\u6807\u68c0\u6d4b\u5e94\u7528\u7684\u7406\u60f3\u9009\u62e9\u3002 Acknowledgements : This work is partially supported by ONR N00014-13-1-0720, NSF IIS-1338054, and The Allen Distinguished Investigator Award. References [1] M. B. Blaschko and C. H. Lampert. Learning to localize objects with structured output regression. In Computer Vision\u2013ECCV 2008, pages 2\u201315. Springer, 2008. 4 [2] L. Bourdev and J. Malik. Poselets: Body part detectors trained using 3d human pose annotations. In International Conference on Computer Vision (ICCV), 2009. 8 [3] H. Cai, Q. Wu, T. Corradi, and P. Hall. The cross-depiction problem: Computer vision algorithms for recognising objects in artwork and in photographs. arXiv preprint arXiv:1505.00110, 2015. 7 [4] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conferenceon, volume 1, pages 886\u2013893. IEEE, 2005. 4, 8 [5] T. Dean, M. Ruzon, M. Segal, J. Shlens, S. Vijayanarasimhan, J. Yagnik, et al. Fast, accurate detection of 100,000 object classes on a single machine. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pages 1814\u20131821. IEEE, 2013. 5 [6] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. arXiv preprint arXiv:1310.1531, 2013. 4 [7] J. Dong, Q. Chen, S. Yan, and A. Yuille. Towards unified object detection and semantic segmentation. In Computer Vision\u2013ECCV 2014, pages 299\u2013314. Springer, 2014. 7 [8] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov. Scalable object detection using deep neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2155\u20132162. IEEE, 2014. 5, 6 [9] M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The pascal visual object classes challenge: A retrospective. International Journal of Computer Vision, 111(1):98\u2013136, Jan. 2015. 2 [10] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9):1627\u20131645, 2010. 1, 4 [11] S. Gidaris and N. Komodakis. Object detection via a multiregion & semantic segmentation-aware CNN model. CoRR, abs/1505.01749, 2015. 7 [12] S. Ginosar, D. Haas, T. Brown, and J. Malik. Detecting people in cubist art. In Computer Vision-ECCV 2014 Workshops, pages 101\u2013116. Springer, 2014. 7 [13] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 580\u2013587. IEEE, 2014. 1, 4, 7 [14] R. B. Girshick. Fast R-CNN. CoRR, abs/1504.08083, 2015. 2, 5, 6, 7 [15] S. Gould, T. Gao, and D. Koller. Region-based segmentation and object detection. In Advances in neural information processing systems, pages 655\u2013663, 2009. 4 [16] B. Hariharan, P. Arbel\u00e1ez, R. Girshick, and J. Malik. Simultaneous detection and segmentation. In Computer Vision\u2013ECCV 2014, pages 297\u2013312. Springer, 2014. 7 [17] K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling in deep convolutional networks for visual recognition. arXiv preprint arXiv:1406.4729, 2014. 5 [18] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580, 2012. 4 [19] D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error in object detectors. In Computer Vision\u2013ECCV 2012, pages 340\u2013353. Springer, 2012. 6 [20] K. Lenc and A. Vedaldi. R-cnn minus r. arXiv preprint arXiv:1506.06981, 2015. 5, 6 [21] R. Lienhart and J. Maydt. An extended set of haar-like features for rapid object detection. In Image Processing. 2002. Proceedings. 2002 International Conference on, volume 1, pages I\u2013900. IEEE, 2002. 4 [22] M. Lin, Q. Chen, and S. Yan. Network in network. CoRR, abs/1312.4400, 2013. 2 [23] D. G. Lowe. Object recognition from local scale-invariant features. In Computer vision, 1999. The proceedings of the seventh IEEE international conference on, volume 2, pages 1150\u20131157. Ieee, 1999. 4 [24] D. Mishkin. Models accuracy on imagenet 2012 val. https://github.com/BVLC/caffe/wiki/Models-accuracy-on-ImageNet-2012-val. Ac-cessed: 2015-10-2. 3 [25] C. P. Papageorgiou, M. Oren, and T. Poggio. A general framework for object detection. In Computer vision, 1998. sixth international conference on, pages 555\u2013562. IEEE,1998. 4 [26] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 3 [27] J. Redmon and A. Angelova. Real-time grasp detection using convolutional neural networks. CoRR, abs/1412.3128, 2014.5 [28] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497, 2015. 5, 6, 7 [29] S. Ren, K. He, R. B. Girshick, X. Zhang, and J. Sun. Object detection networks on convolutional feature maps. CoRR, abs/1504.06066, 2015. 3, 7 [30] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. 3 [31] M. A. Sadeghi and D. Forsyth. 30hz object detection with dpm v5. In Computer Vision\u2013ECCV 2014, pages 65\u201379. Springer, 2014. 5, 6 [32] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. LeCun. Overfeat: Integrated recognition, localization and detection using convolutional networks. CoRR, abs/1312.6229, 2013. 4, 5- [33] Z. Shen and X. Xue. Do more dropouts in pool5 feature maps for better object detection. arXiv preprint arXiv:1409.6911, 2014. 7 [34] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. CoRR, abs/1409.4842, 2014. 2 [35] J. R. Uijlings, K. E. van de Sande, T. Gevers, and A. W. Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154\u2013171, 2013. 4, 5 [36] P. Viola and M. Jones. Robust real-time object detection. International Journal of Computer Vision, 4:34\u201347, 2001. 4 [37] P. Viola and M. J. Jones. Robust real-time face detection. International journal of computer vision, 57(2):137\u2013154, 2004. 5 [38] J. Yan, Z. Lei, L. Wen, and S. Z. Li. The fastest deformable part model for object detection. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2497\u20132504. IEEE, 2014. 5, 6 [39] C. L. Zitnick and P. Doll\u00e1r. Edge boxes: Locating object proposals from edges. In Computer Vision\u2013ECCV 2014, pages 391\u2013405. Springer, 2014. 4","title":"YOLOv1"},{"location":"thesis_interpretation/01_yolo.html#_1","text":"\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5 \\(YOLO\\) \u3002\u4ee5\u524d\u7684\u76ee\u6807\u68c0\u6d4b\u5de5\u4f5c\u91cd\u65b0\u5229\u7528\u5206\u7c7b\u5668\u6765\u6267\u884c\u68c0\u6d4b\u3002\u76f8\u53cd\uff0c\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u6846\u67b6\u770b\u4f5c\u4ece\u7a7a\u95f4\u5206\u79bb\u7684\u8fb9\u754c\u6846\u548c\u76f8\u5173\u7c7b\u522b\u6982\u7387\u7684\u56de\u5f52\u95ee\u9898\u3002\u5728\u4e00\u6b21\u8bc4\u4f30\u4e2d\uff0c\u4e00\u4e2a\u5355\u4e00\u7684\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u4ece\u5b8c\u6574\u7684\u56fe\u50cf\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u3002\u7531\u4e8e\u6574\u4e2a\u68c0\u6d4b\u7ba1\u9053\u662f\u4e00\u4e2a\u5355\u4e00\u7684\u7f51\u7edc\uff0c\u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u5bf9\u68c0\u6d4b\u6027\u80fd\u8fdb\u884c\u7aef\u5230\u7aef( \u8bd1\u8005\u6ce8\uff1a\u7aef\u5bf9\u7aef\u6307\u7684\u662f\u8f93\u5165\u539f\u59cb\u6570\u636e\uff0c\u8f93\u51fa\u7684\u662f\u6700\u540e\u7ed3\u679c\uff0c\u5e94\u7528\u5728\u7279\u5f81\u5b66\u4e60\u878d\u5165\u7b97\u6cd5\uff0c\u65e0\u9700\u5355\u72ec\u5904\u7406 )\u4f18\u5316\u3002 \u2003 \u6211\u4eec\u7684\u7edf\u4e00\u67b6\u6784\u975e\u5e38\u5feb\u3002\u6211\u4eec\u7684\u57fa\u672c \\(YOLO\\) \u6a21\u578b\u4ee5\u6bcf\u79d245\u5e27\u7684\u901f\u5ea6\u5b9e\u65f6\u5904\u7406\u56fe\u50cf\u3002\u8be5\u7f51\u7edc\u7684\u4e00\u4e2a\u5c0f\u7248\u672c\uff1a \\(Fast \\ YOLO\\) \u662f \\(YOLO\\) \u7684\u4e00\u4e2a\u8f83\u5c0f\u7248\u672c\uff0c\u6bcf\u79d2\u80fd\u8fbe\u5230\u5904\u7406\u60ca\u4eba\u7684155\u5e27\u56fe\u50cf\uff0c\u540c\u65f6\u4ecd\u7136\u8fbe\u5230\u5176\u4ed6\u5b9e\u65f6\u63a2\u6d4b\u5668\u7684\u4e24\u500d \\(mAP\\) \u3002\u4e0e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\uff0c \\(YOLO\\) YOLO\u867d\u7136\u5b58\u5728\u8f83\u591a\u7684\u5b9a\u4f4d\u9519\u8bef\uff0c\u4f46\u5f88\u5c11\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u5047\u9633\u6027( \u8bd1\u8005\u6ce8\uff1a\u5176\u5b83\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u76ee\u6807\u7684\u6982\u7387\u8f83\u5927 )\u3002\u6700\u540e\uff0c \\(YOLO\\) \u80fd\u5b66\u4e60\u5230\u76ee\u6807\u7684\u975e\u5e38\u901a\u7528\u3002\u65e0\u8bba\u4ece\u81ea\u7136\u56fe\u50cf\u5230\u827a\u672f\u54c1\u7b49\u5176\u4ed6\u9886\u57df\u6cdb\u5316\u65f6\uff0c\u5b83\u90fd\u4f18\u4e8e\u5176\u4ed6\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6bd4\u5982 \\(DPM\\) \u548c \\(R-CNN\\) \u3002","title":"\u6458\u8981"},{"location":"thesis_interpretation/01_yolo.html#1","text":"\u4eba\u7c7b\u77a5\u4e00\u773c\u56fe\u50cf\uff0c\u5c31\u4f1a\u7acb\u5373\u77e5\u9053\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\u662f\u4ec0\u4e48\uff0c\u5b83\u4eec\u5728\u54ea\u91cc\uff0c\u4ee5\u53ca\u5b83\u4eec\u662f\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u7684\u3002\u4eba\u7c7b\u7684\u89c6\u89c9\u7cfb\u7edf\u5feb\u901f\u548c\u51c6\u786e\u7684\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u5728\u51e0\u4e4e\u6ca1\u6709\u610f\u8bc6\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u590d\u6742\u7684\u4efb\u52a1\uff0c\u5982\u9a7e\u9a76\u3002\u5feb\u901f\u3001\u51c6\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5c06\u5141\u8bb8\u8ba1\u7b97\u673a\u5728\u6ca1\u6709\u4e13\u7528\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u9a7e\u9a76\u6c7d\u8f66\uff0c\u4f7f\u8f85\u52a9\u8bbe\u5907\u80fd\u591f\u5411\u4eba\u7c7b\u7528\u6237\u4f20\u9001\u5b9e\u65f6\u573a\u666f\u4fe1\u606f\u5e76\u91ca\u653e\u901a\u7528\u3001\u54cd\u5e94\u7075\u654f\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6f5c\u529b\u3002\u5feb\u901f\u3001\u51c6\u786e\u7684\u7269\u4f53\u68c0\u6d4b\u7b97\u6cd5\u5c06\u5e2e\u52a9\u8ba1\u7b97\u673a\u5728\u6ca1\u6709\u4e13\u95e8\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\u9a7e\u9a76\u6c7d\u8f66\uff0c\u8f85\u52a9\u8bbe\u5907\u80fd\u591f\u5c06\u5b9e\u65f6\u573a\u666f\u4fe1\u606f\u4f20\u8fbe\u7ed9\u7528\u6237\uff0c\u5e76\u663e\u793a\u901a\u7528\u3001\u54cd\u5e94\u5f0f\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6f5c\u529b\u3002 \u2003 \u76ee\u524d\u7684\u68c0\u6d4b\u7cfb\u7edf\u91cd\u590d\u5229\u7528\u5206\u7c7b\u5668\u6765\u6267\u884c\u68c0\u6d4b\u3002\u4e3a\u4e86\u68c0\u6d4b\u76ee\u6807\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u4e3a\u8be5\u76ee\u6807\u63d0\u4f9b\u4e00\u4e2a\u5206\u7c7b\u5668\uff0c\u5e76\u5728\u6d4b\u8bd5\u56fe\u50cf\u7684\u4e0d\u540c\u4f4d\u7f6e\u548c\u5c3a\u5ea6\u4e0a\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002\u4f8b\u5982\u50cf\u53ef\u53d8\u5f62\u90e8\u4ef6\u6a21\u578b \\((DPM)\\) \u8fd9\u6837\u7684\u7cfb\u7edf\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\uff0c\u5176\u4e2d\u5206\u7c7b\u5668\u5728\u6574\u4e2a\u56fe\u50cf\u4e0a\u5747\u5300\u95f4\u9694\u7684\u4f4d\u7f6e\u8fd0\u884c[10]\u3002 \u56fe1: YOLO\u68c0\u6d4b\u7cfb\u7edf\u3002 \u7528YOLO\u5904\u7406\u56fe\u50cf\u7b80\u5355\u800c\u76f4\u63a5\u3002\u5728\u6211\u4eec\u7684\u7cfb\u7edf\u4e2d: \u5c06\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u8c03\u6574\u4e3a448 \u00d7 448\u3002 \u5728\u56fe\u50cf\u4e0a\u8fd0\u884c\u4e00\u4e2a\u5377\u79ef\u7f51\u7edc\u3002 \u6839\u636e\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u5bf9\u7ed3\u679c\u68c0\u6d4b\u8fdb\u884c\u9608\u503c\u3002 \u2003\u6700\u8fd1\u7684\u65b9\u6cd5\uff0c\u5982R-CNN\u63d0\u51fa\u4f7f\u7528\u90e8\u5206\u533a\u57df\uff0c\u9996\u5148\u5728\u56fe\u50cf\u4e2d\u751f\u6210\u6f5c\u5728\u7684\u8fb9\u754c\u6846\uff0c\u7136\u540e\u5728\u8fd9\u4e9b\u6846\u4e0a\u8fd0\u884c\u5206\u7c7b\u5668\u3002\u5b8c\u6210\u5206\u7c7b\u540e\uff0c\u901a\u8fc7\u540e\u5904\u7406\u5728\u7ec6\u5316\u8fb9\u754c\u6846\uff0c\u6d88\u9664\u91cd\u590d\u68c0\u6d4b\uff0c\u5e76\u57fa\u4e8e\u573a\u666f\u4e2d\u7684\u5176\u4ed6\u76ee\u6807\u91cd\u65b0\u5b9a\u4f4d\u8fb9\u754c\u6846[13]\u3002\u8fd9\u4e9b\u590d\u6742\u7684\u6d41\u7a0b\u5f88\u6162\uff0c\u5f88\u96be\u4f18\u5316\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u5355\u72ec\u7684\u7ec4\u4ef6\u90fd\u5fc5\u987b\u5355\u72ec\u8bad\u7ec3\u3002 \u2003\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5355\u4e00\u7684\u56de\u5f52\u95ee\u9898\uff0c\u76f4\u63a5\u4ece\u56fe\u50cf\u50cf\u7d20\u5230\u8fb9\u754c\u6846\u5750\u6807\u548c\u7c7b\u522b\u6982\u7387\u3002\u4f7f\u7528\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u60a8\u53ea\u9700\u8981\u5728\u56fe\u50cf\u4e0a\u770b\u4e00\u6b21\uff08you only look once, \\(YOLO\\) \uff09\uff0c\u5c31\u4ee5\u9884\u6d4b\u4ec0\u4e48\u76ee\u6807\u51fa\u73b0\u548c\u5b83\u4eec\u5728\u54ea\u91cc\u3002 \u2003 \\(YOLO\\) \u65b0\u5947\u53c8\u5f88\u7b80\u5355\uff1a\u5982\u56fe1\u6240\u793a\u3002\u5355\u4e2a\u5377\u79ef\u7f51\u7edc\u540c\u65f6\u9884\u6d4b\u8fd9\u4e9b\u6846\u7684\u591a\u4e2a\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u503c\u3002YOLO\u5728\u5b8c\u6574\u56fe\u50cf\u4e0a\u8bad\u7ec3\uff0c\u5e76\u76f4\u63a5\u4f18\u5316\u68c0\u6d4b\u6027\u80fd\u3002\u4e0e\u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8fd9\u79cd\u7edf\u4e00\u7684\u6a21\u578b\u6709\u51e0\u4e2a\u4f18\u70b9\u3002 \u2003 \u9996\u5148\uff0c \\(YOLO\\) \u901f\u5ea6\u975e\u5e38\u5feb\u3002\u7531\u4e8e\u6211\u4eec\u5c06\u68c0\u6d4b\u89c6\u4e3a\u56de\u5f52\u95ee\u9898\uff0c\u6240\u4ee5\u6211\u4eec\u4e0d\u9700\u8981\u590d\u6742\u7684\u6d41\u7a0b\u3002\u6d4b\u8bd5\u65f6\u6211\u4eec\u5728\u4e00\u5f20\u65b0\u56fe\u50cf\u4e0a\u7b80\u5355\u7684\u8fd0\u884c\u6211\u4eec\u7684\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u68c0\u6d4b\u7684\u7ed3\u679c\u3002\u5728Titan X GPU\u4e0a\u6ca1\u6709\u6279\u5904\u7406\u4e2d\uff0c\u6211\u4eec\u7684\u57fa\u7840\u7f51\u7edc\u4ee5\u6bcf\u79d245\u5e27\u7684\u901f\u5ea6\u8fd0\u884c\u3002\u5feb\u901f\u7248\u672c\u8fd0\u884c\u901f\u5ea6\u8d85\u8fc7150fps\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u53ef\u4ee5\u5728\u4e0d\u523025\u6beb\u79d2\u7684\u5ef6\u8fdf\u5185\u5b9e\u65f6\u5904\u7406\u6d41\u5a92\u4f53\u89c6\u9891\u3002\u6b64\u5916\uff0c \\(YOLO\\) \u5b9e\u73b0\u4e86\u5176\u5b83\u5b9e\u65f6\u7cfb\u7edf\u4e24\u500d\u4ee5\u4e0a\u7684mAP\u3002\u5173\u4e8e\u6211\u4eec\u7684\u7cfb\u7edf\u5728\u7f51\u7edc\u6444\u50cf\u5934\u4e0a\u5b9e\u65f6\u8fd0\u884c\u7684\u6f14\u793a\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684\u9879\u76ee\u7f51\u9875\uff1ahttp://pjreddie.com/yolo/\u3002 \u2003 \u5176\u6b21\uff0c \\(YOLO\\) \u5728\u8fdb\u884c\u9884\u6d4b\u65f6\uff0c\u4f1a\u5bf9\u56fe\u50cf\u8fdb\u884c\u5168\u5c40\u5730\u63a8\u7406\u3002\u4e0e\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3( sliding window )\u548c\u57fa\u4e8e\u533a\u57df\u63d0\u8bae( region proposal )\u7684\u6280\u672f\u4e0d\u540c\uff0c \\(YOLO\\) \u5728\u8bad\u7ec3\u671f\u95f4\u548c\u6d4b\u8bd5\u65f6\u4f1a\u770b\u5230\u6574\u4e2a\u56fe\u50cf\uff0c\u56e0\u6b64\u5b83\u9690\u5f0f\u5730\u7f16\u7801\u5173\u4e8e\u7c7b\u53ca\u5176\u5916\u89c2\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002 \\(Fast \\ R-CNN\\) \u662f\u4e00\u79cd\u9876\u90e8\u7684\u68c0\u6d4b\u65b9\u6cd5[14]\uff0c\u4f46\u56e0\u4e3a\u5b83\u770b\u4e0d\u5230\u66f4\u5927\u7684\u4e0a\u4e0b\u6587\uff0c\u6240\u4ee5\u5728\u56fe\u50cf\u4e2d\u4f1a\u5c06\u80cc\u666f\u5757\u8bef\u68c0\u4e3a\u76ee\u6807\u3002\u4e0e \\(Fast R-CNN\\) \u76f8\u6bd4\uff0cYOLO\u7684\u80cc\u666f\u8bef\u68c0\u6570\u91cf\u5c11\u4e86\u4e00\u534a\u3002 \u2003 \u7b2c\u4e09\uff0c \\(YOLO\\) \u5b66\u4e60\u76ee\u6807\u53ef\u6cdb\u5316\u8868\u793a\u3002\u5f53\u5728\u81ea\u7136\u7684\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u5bf9\u827a\u672f\u4f5c\u54c1\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c \\(YOLO\\) \u5927\u5e45\u4f18\u4e8e \\(DPM\\) \u548c \\(R-CNN\\) \u7b49\u9876\u7ea7\u68c0\u6d4b\u65b9\u6cd5\u3002\u7531\u4e8e \\(YOLO\\) \u5177\u6709\u9ad8\u5ea6\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u5728\u5e94\u7528\u4e8e\u65b0\u9886\u57df\u6216\u78b0\u5230\u975e\u6b63\u5e38\u8f93\u5165\u65f6\u5f88\u5c11\u51fa\u6545\u969c\u3002 \u2003 \\(YOLO\\) \u5728\u51c6\u786e\u5ea6\u4e0a\u4ecd\u7136\u843d\u540e\u4e8e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002\u867d\u7136\u5b83\u53ef\u4ee5\u5feb\u901f\u8bc6\u522b\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff0c\u4f46\u5b83\u5f88\u96be\u7cbe\u786e\u5b9a\u4f4d\u4e00\u4e9b\u76ee\u6807\uff0c\u5c24\u5176\u662f\u4e00\u4e9b\u5c0f\u76ee\u6807\u3002\u6211\u4eec\u5728\u5b9e\u9a8c\u4e2d\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u8fd9\u4e9b\u6743\u8861\u3002 \u2003 \\(YOLO\\) \u6211\u4eec\u6240\u6709\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4ee3\u7801\u90fd\u662f\u5f00\u6e90\u7684\u3002\u5404\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\u4e5f\u90fd\u53ef\u4ee5\u4e0b\u8f7d\u3002","title":"1.\u4ecb\u7ecd"},{"location":"thesis_interpretation/01_yolo.html#2","text":"\u6211\u4eec\u5c06\u76ee\u6807\u68c0\u6d4b\u7684\u5355\u72ec\u7ec4\u4ef6\u96c6\u6210\u5230\u5355\u4e2a\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002\u6211\u4eec\u7684\u7f51\u7edc\u5229\u7528\u6574\u4e2a\u56fe\u50cf\u7684\u7279\u5f81\u6765\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u3002\u5b83\u8fd8\u53ef\u4ee5\u540c\u65f6\u9884\u6d4b\u4e00\u5f20\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u7c7b\u522b\u7684\u6240\u6709\u8fb9\u754c\u6846\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u7f51\u7edc\u5bf9\u6574\u4e2a\u56fe\u50cf\u548c\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u5bf9\u8c61\u8fdb\u884c\u5168\u5c40\u63a8\u7406\u3002 \\(YOLO\\) \u8bbe\u8ba1\u53ef\u5b9e\u73b0\u7aef\u5230\u7aef\u8bad\u7ec3\u548c\u5b9e\u65f6\u7684\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u5e73\u5747\u7cbe\u5ea6( \u5373mAP\u503c )\u3002 \u2003 \u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u8f93\u5165\u56fe\u50cf\u5206\u6210 \\(S\u00d7S\\) \u7684\u7f51\u683c\u3002\u5982\u679c\u4e00\u4e2a\u76ee\u6807\u7684\u4e2d\u5fc3\u843d\u5165\u4e00\u4e2a\u7f51\u683c\u5355\u5143\u4e2d\uff0c\u8be5\u7f51\u683c\u5355\u5143\u8d1f\u8d23\u68c0\u6d4b\u8be5\u76ee\u6807\u3002 \u2003 \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u9884\u6d4b \\(B\\) \u4e2a\u8fb9\u754c\u6846\u548c\u7f6e\u4fe1\u5ea6\u5206\u6570\u5bf9\u4e8e\u90a3\u4e9b\u6846\u3002\u8fd9\u4e9b\u7f6e\u4fe1\u5ea6\u5206\u6570\u53cd\u6620\u4e86\u8be5\u6a21\u578b\u5bf9\u6846\u662f\u5426\u5305\u542b\u76ee\u6807\u7684\u7f6e\u4fe1\u5ea6\uff0c\u4ee5\u53ca\u5b83\u9884\u6d4b\u6846\u7684\u51c6\u786e\u5ea6\u3002\u5728\u5f62\u5f0f\u4e0a\uff0c\u6211\u4eec\u5c06\u7f6e\u4fe1\u5ea6\u5b9a\u4e49\u4e3a \\(Pr(Object)\u2217IOU^{truth}_{pred}\\) \u3002\u5982\u679c\u8be5\u5355\u5143\u683c\u4e2d\u4e0d\u5b58\u5728\u76ee\u6807\uff0c\u5219\u7f6e\u4fe1\u5ea6\u5206\u6570\u5e94\u4e3a \\(0\\) \u3002\u5426\u5219\uff0c\u6211\u4eec\u5e0c\u671b\u7f6e\u4fe1\u5ea6\u5206\u6570\u7b49\u4e8e\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u8054\u5408\u90e8\u5206\u7684\u4ea4\u96c6( \\(IOU\\) )\u3002 \u2003\u6bcf\u4e2a\u8fb9\u754c\u6846\u5305\u542b5\u4e2a\u9884\u503c\uff1a \\(x,y,w,h,confidence\\) \u3002 \\((x,y)\\) \u5750\u6807\u8868\u793a\u8fb9\u754c\u6846\u76f8\u5bf9\u4e8e\u7f51\u683c\u5355\u5143\u8fb9\u754c\u7684\u65b9\u6846\u4e2d\u5fc3\u3002\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u662f\u76f8\u5bf9\u4e8e\u6574\u5f20\u56fe\u50cf\u9884\u6d4b\u7684\u3002\u6700\u540e\uff0c\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u8868\u793a\u4e3a\u9884\u6d4b\u6846\u4e0e\u5b9e\u9645\u8fb9\u754c\u6846\u4e4b\u95f4\u7684 \\(IOU\\) \u3002 \u2003 \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u8fd8\u9884\u6d4b \\(C\\) \u4e2a\u6761\u4ef6\u7c7b\u522b\u6982\u7387 \\(Pr(Class_i|Object)\\) \u3002\u8fd9\u4e9b\u6982\u7387\u4ee5\u5305\u542b\u76ee\u6807\u7684\u7f51\u683c\u5355\u5143\u4e3a\u6761\u4ef6\u3002\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u6211\u4eec\u53ea\u9884\u6d4b\u7684\u4e00\u7ec4\u7c7b\u522b\u6982\u7387\uff0c\u800c\u4e0d\u7ba1\u8fb9\u754c\u6846\u7684\u7684\u6570\u91cf \\(B\\) \u662f\u591a\u5c11\u3002 \u2003\u5728\u6d4b\u8bd5\u65f6\uff0c\u6211\u4eec\u5c06\u6761\u4ef6\u7c7b\u6982\u7387\u548c\u5355\u4e2a\u6846\u7684\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u503c\u76f8\u4e58\uff1a \\(\\small{Pr(Class_i|Object) \u2217 Pr(Object) \u2217 IOU^{truth}_{pred} = Pr(Class_i) \u2217 IOU^{truth}_{pred}}\\) (1) \u5b83\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u6bcf\u4e2a\u6846\u7279\u5b9a\u7c7b\u522b\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\u3002\u8fd9\u4e9b\u5206\u6570\u7f16\u7801\u4e86\u8be5\u7c7b\u51fa\u73b0\u5728\u6846\u4e2d\u7684\u6982\u7387\u4ee5\u53ca\u9884\u6d4b\u6846\u62df\u5408\u76ee\u6807\u7684\u7a0b\u5ea6\u3002 \u56fe2\uff1a\u6a21\u578b\u3002 \u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u68c0\u6d4b\u5efa\u6a21\u4e3a\u4e00\u4e2a\u56de\u5f52\u95ee\u9898\u3002\u5b83\u5c06\u56fe\u50cf\u5212\u5206\u4e3a\u4e00\u4e2a \\(S \u00d7 S\\) \u7f51\u683c\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u9884\u6d4b \\(B\\) \u4e2a\u8fb9\u754c\u6846\u3001\u8fd9\u4e9b\u6846\u7684\u7f6e\u4fe1\u5ea6 \u548c \\(C\\) \u7c7b\u522b\u6982\u7387\u3002\u8fd9\u4e9b\u9884\u6d4b\u88ab\u7f16\u7801\u4e3a \\(S \u00d7 S \u00d7 (B * 5 + C)\\) \u7684\u5f20\u91cf \\(S\\times{S}\\) grid on input( \\(S\\times{S}\\) \u7684\u7f51\u683c\u5728\u8f93\u5165\u4e0a) Bounding boxes (\u8fb9\u754c\u6846) confidence (\u7f6e\u4fe1\u5ea6) Class probability map(\u7c7b\u522b\u6982\u7387\u5730\u56fe) Final detections (\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c) \u4e3a\u4e86\u5728 \\(Pascal \\ VOC\\) \u4e0a\u8bc4\u4f30 \\(YOLO\\) \uff0c\u6211\u4eec\u4f7f\u7528 \\(S=7\uff0cB=2\u3002Pascal VOC\\) \u6709 \\(20\\) \u4e2a\u6807\u6ce8\u7c7b\uff0c\u6240\u4ee5 \\(C=20\\) \u3002\u6211\u4eec\u6700\u7ec8\u7684\u9884\u6d4b\u662f \\(7\u00d77\u00d730\\) \u7684\u5f20\u91cf\u3002 \u6ce8\u610f\uff1a \u2003 \u2003 1.\u7531\u4e8e\u8f93\u51fa\u5c42\u4e3a\u5168\u8fde\u63a5\u5c42\uff0c\u56e0\u6b64\u5728\u68c0\u6d4b\u65f6\uff0cYOLO\u8bad\u7ec3\u6a21\u578b\u53ea\u652f\u6301\u4e0e\u8bad\u7ec3\u56fe\u50cf\u76f8\u540c\u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002 \u2003 \u2003 2.\u867d\u7136\u6bcf\u4e2a\u683c\u5b50\u53ef\u4ee5\u9884\u6d4bB\u4e2abounding box\uff0c\u4f46\u662f\u6700\u7ec8\u53ea\u9009\u62e9\u53ea\u9009\u62e9IOU\u6700\u9ad8\u7684bounding box\u4f5c\u4e3a\u7269\u4f53\u68c0\u6d4b\u8f93\u51fa\uff0c\u5373\u6bcf\u4e2a\u683c\u5b50\u6700\u591a\u53ea\u9884\u6d4b\u51fa\u4e00\u4e2a\u7269\u4f53\u3002\u5f53\u7269\u4f53\u5360\u753b\u9762\u6bd4\u4f8b\u8f83\u5c0f\uff0c\u5982\u56fe\u50cf\u4e2d\u5305\u542b\u755c\u7fa4\u6216\u9e1f\u7fa4\u65f6\uff0c\u6bcf\u4e2a\u683c\u5b50\u5305\u542b\u591a\u4e2a\u7269\u4f53\uff0c\u4f46\u5374\u53ea\u80fd\u68c0\u6d4b\u51fa\u5176\u4e2d\u4e00\u4e2a\u3002\u8fd9\u662fYOLO\u65b9\u6cd5\u7684\u4e00\u4e2a\u7f3a\u9677\u3002","title":"2.\u7edf\u4e00\u7684\u68c0\u6d4b"},{"location":"thesis_interpretation/01_yolo.html#21","text":"\u6211\u4eec\u5c06\u8be5\u6a21\u578b\u5b9e\u73b0\u4e3a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u5728 \\(PASCAL \\ VOC\\) \u68c0\u6d4b\u6570\u636e\u96c6[9]\u4e0a\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002\u7f51\u7edc\u7684\u521d\u59cb\u5377\u79ef\u5c42\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u800c\u5168\u8fde\u901a\u5c42\u9884\u6d4b\u8f93\u51fa\u6982\u7387\u548c\u5750\u6807\u3002 \u2003\u6211\u4eec\u7684\u7f51\u7edc\u67b6\u6784\u7684\u7075\u611f\u6765\u81ea\u4e8e\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b[34]\u7684 \\(GoogLeNet\\) \u6a21\u578b\u3002\u6211\u4eec\u7684\u7f51\u7edc\u6709 \\(24\\) \u4e2a\u5377\u79ef\u5c42\u548c \\(2\\) \u4e2a\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u7b80\u5355\u5730\u4f7f\u7528 \\(1 \u00d7 1\\) \u8fd8\u539f\u5c42\u548c \\(3 \u00d7 3\\) \u5377\u79ef\u5c42\uff0c\u7c7b\u4f3c \\(Lin\\) \u7b49[22]\u3002\u5b8c\u6574\u7684\u7f51\u7edc \\(\u5982\u56fe3\\) \u6240\u793a\u3002 \u56fe3 :\u4f53\u7cfb\u7ed3\u6784\u3002 \u6211\u4eec\u7684\u68c0\u6d4b\u7f51\u7edc\u6709 \\(24\\) \u4e2a\u5377\u79ef\u5c42\u548c \\(2\\) \u4e2a\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u4ea4\u66ff\u7684 \\(1 \u00d7 1\\) \u5377\u79ef\u5c42\u51cf\u5c11\u4e86\u524d\u4e00\u5c42\u7684\u7279\u5f81\u7a7a\u95f4\u3002\u6211\u4eec\u5728 \\(ImageNet\\) \u5206\u7c7b\u4efb\u52a1\u4e0a\u4ee5\u4e00\u534a\u5206\u8fa8\u7387( \\(224 \u00d7 224\\) \u8f93\u5165\u56fe\u50cf)\u5bf9\u5377\u79ef\u5c42\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5c06\u5206\u8fa8\u7387\u63d0\u9ad8\u4e00\u500d\u7528\u4e8e\u68c0\u6d4b\u3002 \u2003\u6211\u4eec\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5feb\u901f\u7248\u672c\u7684 \\(YOLO\\) \uff0c\u65e8\u5728\u63a8\u52a8\u5feb\u901f\u76ee\u6807\u68c0\u6d4b\u7684\u8fb9\u754c\u3002 \\(Fast \\ YOLO\\) \u4f7f\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u66f4\u5c11\u7684\u5377\u79ef\u5c42(9\u5c42\u800c\u4e0d\u662f24\u5c42)\uff0c\u8fd9\u4e9b\u5c42\u4e2d\u7684\u8fc7\u6ee4\u5668\u4e5f\u66f4\u5c11\u3002\u9664\u4e86\u7f51\u7edc\u7684\u89c4\u6a21\uff0c \\(YOLO\\) \u548c \\(Fast \\ YOLO\\) \u4e4b\u95f4\u7684\u6240\u6709\u8bad\u7ec3\u548c\u6d4b\u8bd5\u53c2\u6570\u90fd\u662f\u76f8\u540c\u7684\u3002 \u2003\u6211\u4eec\u7684\u7f51\u7edc\u7684\u6700\u7ec8\u8f93\u51fa\u662f \\(7 \u00d7 7 \u00d7 30\\) \u5f20\u91cf\u7684\u9884\u6d4b\u3002","title":"2.1 \u7f51\u7edc\u8bbe\u8ba1"},{"location":"thesis_interpretation/01_yolo.html#22","text":"\u9884\u8bad\u7ec3\u5206\u7c7b\u7f51\u7edc\uff1a\u6211\u4eec\u5728ImageNet 1000\u7c7b\u7ade\u8d5b\u6570\u636e\u96c6[30]\u4e0a\u9884\u8bad\u7ec3\u5377\u79ef\u5c42\u3002\u5bf9\u4e8e\u9884\u8bad\u7ec3\uff0c\u6211\u4eec\u4f7f\u7528\u56fe3\u4e2d\u7684\u524d20\u4e2a\u5377\u79ef\u5c42\uff0c\u7136\u540e\u662f\u5e73\u5747\u6c60\u5316\u5c42\u548c\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u6211\u4eec\u5bf9\u8be5\u7f51\u7edc\u8fdb\u884c\u4e86\u5927\u7ea6\u4e00\u5468\u7684\u8bad\u7ec3\uff0c\u5e76\u5728ImageNet 2012\u9a8c\u8bc1\u96c6\u4e0a\u5b9e\u73b0\u4e8688%\u7684\u5355\u4e00\u4f5c\u7269\u524d5\u540d\u7684\u51c6\u786e\u6027\uff0c\u4e0eCaffe\u7684Model Zoo[24]\u4e2d\u7684GoogLeNet\u6a21\u578b\u76f8\u5f53\u3002\u6211\u4eec\u4f7f\u7528Darknet\u6846\u67b6\u8fdb\u884c\u6240\u6709\u7684\u8bad\u7ec3\u548c\u63a8\u7406[26]\u3002 \u2003 \u7136\u540e\u6211\u4eec\u5c06\u6a21\u578b\u8f6c\u6362\u4e3a\u6267\u884c\u68c0\u6d4b\u3002Ren\u7b49\u4eba\u8868\u660e\uff0c\u5728\u9884\u8bad\u7ec3\u7684\u7f51\u7edc\u4e2d\u540c\u65f6\u6dfb\u52a0\u5377\u79ef\u5c42\u548c\u8fde\u63a5\u5c42\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd[29]\u3002 \u6309\u7167\u4ed6\u4eec\u7684\u4f8b\u5b50\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u56db\u4e2a\u5377\u79ef\u5c42\u548c\u4e24\u4e2a\u5177\u6709\u968f\u673a\u521d\u59cb\u5316\u6743\u503c\u7684\u5b8c\u5168\u8fde\u63a5\u5c42\u3002\u68c0\u6d4b\u901a\u5e38\u9700\u8981\u7ec6\u7c92\u5ea6\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u56e0\u6b64\u6211\u4eec\u5c06\u7f51\u7edc\u7684\u8f93\u5165\u5206\u8fa8\u7387\u4ece \\(224 \u00d7 224\\) \u63d0\u9ad8\u5230 \\(448 \u00d7 448\\) \u3002 \u2003 \u6211\u4eec\u7684\u6700\u540e\u4e00\u5c42\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u548c\u8fb9\u754c\u6846\u5750\u6807\u3002\u6211\u4eec\u901a\u8fc7\u56fe\u50cf\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u6765\u5f52\u4e00\u5316\u8fb9\u754c\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u4f7f\u5b83\u4eec\u843d\u57280\u548c1\u4e4b\u95f4\u3002\u6211\u4eec\u5c06\u8fb9\u754c\u6846x\u548cy\u5750\u6807\u53c2\u6570\u5316\u4e3a\u7279\u5b9a\u7f51\u683c\u5355\u5143\u4f4d\u7f6e\u7684\u504f\u79fb\u91cf\uff0c\u56e0\u6b64\u5b83\u4eec\u8fb9\u754c\u4e5f\u57280\u548c1\u4e4b\u95f4\u3002 \u2003 \u6211\u4eec\u5bf9\u6700\u540e\u4e00\u5c42\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u6240\u6709\u5176\u5b83\u5c42\u4f7f\u7528\u4e0b\u9762\u7684leaky ReLU\u6fc0\u6d3b\u51fd\u6570: \\(\\phi(x)=\\left\\{\\begin{array}{ll} x, & \\text { if } x>0 \\\\ 0.1 x, & \\text { otherwise } \\end{array}\\right.\\) (2) \u6211\u4eec\u4f18\u5316\u4e86\u6a21\u578b\u8f93\u51fa\u7684\u5e73\u65b9\u548c\u8bef\u5dee\u3002\u6211\u4eec\u4f7f\u7528\u5e73\u65b9\u548c\u8bef\u5dee\u662f\u56e0\u4e3a\u5b83\u5f88\u5bb9\u6613\u8fdb\u884c\u4f18\u5316\uff0c\u4f46\u662f\u5b83\u5e76\u4e0d\u5b8c\u5168\u7b26\u5408\u6211\u4eec\u6700\u5927\u5316\u5e73\u5747\u7cbe\u5ea6\u7684\u76ee\u6807\u3002\u5206\u7c7b\u8bef\u5dee\u4e0e\u5b9a\u4f4d\u8bef\u5dee\u7684\u6743\u91cd\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u53ef\u80fd\u5e76\u4e0d\u7406\u60f3\u3002\u53e6\u5916\uff0c\u5728\u6bcf\u5f20\u56fe\u50cf\u4e2d\uff0c\u8bb8\u591a\u7f51\u683c\u5355\u5143\u4e0d\u5305\u542b\u4efb\u4f55\u5bf9\u8c61\u3002\u8fd9\u5c06\u5bfc\u81f4\u8fd9\u4e9b\u5355\u5143\u683c\u7684 \\(\"\u7f6e\u4fe1\u5ea6\"\\) \u5206\u6570\u4e3a\u96f6\uff0c\u901a\u5e38\u538b\u5012\u4e86\u5305\u542b\u76ee\u6807\u7684\u5355\u5143\u683c\u7684\u68af\u5ea6\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u4ece\u800c\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u65e9\u53d1\u6563\u3002 \u2003\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u589e\u52a0\u4e86\u8fb9\u754c\u6846\u5750\u6807\u9884\u6d4b\u7684\u635f\u5931\uff0c\u51cf\u5c11\u4e86\u4e0d\u5305\u542b\u76ee\u6807\u7684\u6846\u7684\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u7684\u635f\u5931\u3002\u6211\u4eec\u4f7f\u7528\u4e24\u4e2a\u53c2\u6570\uff0c \\(\\lambda_{coord}\\) \u548c \\(\\lambda{noobj}\\) \u6765\u5b8c\u6210\u8fd9\u4e2a\u4efb\u52a1\u3002\u6211\u4eec\u8bbe\u7f6e \\(\\lambda_{coord} = 5\\) , \\(\\lambda_{noobj} = 0.5\\) \u3002 \u2003 \u5e73\u65b9\u548c\u8bef\u5dee\u5728\u5927\u65b9\u6846\u548c\u5c0f\u65b9\u6846\u4e2d\u7684\u6743\u91cd\u76f8\u540c\u3002\u6211\u4eec\u7684\u8bef\u5dee\u5ea6\u91cf\u5e94\u8be5\u53cd\u6620\u5927\u65b9\u6846\u91cc\u7684\u5c0f\u504f\u5dee\u6bd4\u5c0f\u65b9\u6846\u91cc\u7684\u5f71\u54cd\u5c0f\u3002\u4e3a\u4e86\u90e8\u5206\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u9884\u6d4b\u8fb9\u754c\u6846\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5e73\u65b9\u6839\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u3002\u4e3a\u4e86\u7f13\u548c\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u9884\u6d4b\u8fb9\u754c\u6846\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u7684\u5e73\u65b9\u6839\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u3002 \u2003 \\(YOLO\\) \u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u6709\u9884\u6d4b\u591a\u4e2a\u8fb9\u754c\u6846\u3002\u5728\u8bad\u7ec3\u65f6\uff0c\u6bcf\u4e2a\u76ee\u6807\u6211\u4eec\u53ea\u9700\u8981\u4e00\u4e2a\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u6765\u8d1f\u8d23\u3002\u6211\u4eec\u6839\u636e\u54ea\u4e2a\u9884\u6d4b\u5668\u7684\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u5177\u6709\u5f53\u524d\u6700\u9ad8\u7684 \\(IOU\\) \u6765\u6307\u5b9a\u54ea\u4e2a\u9884\u6d4b\u5668 \u8d1f\u8d23 \u9884\u6d4b\u8be5\u76ee\u6807\u3002\u8fd9\u5bfc\u81f4\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u4e4b\u95f4\u7684\u4e13\u4e00\u5316\u3002\u6bcf\u4e2a\u9884\u6d4b\u5668\u53ef\u4ee5\u66f4\u597d\u5730\u9884\u6d4b\u7279\u5b9a\u5927\u5c0f\u3001\u957f\u5bbd\u6bd4\u6216\u76ee\u6807\u7684\u7c7b\u522b\uff0c\u4ece\u800c\u6539\u5584\u6574\u4f53\u53ec\u56de\u7387\u3002 \u2003\u5728\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u4f18\u5316\u4ee5\u4e0b\u7531\u591a\u90e8\u5206\u7ec4\u6210\u7684\u635f\u5931\u51fd\u6570\uff1a \\(\\begin{array}{c} \\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(x_{i}-\\hat{x}_{i}\\right)^{2}+\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\\right] \\\\ +\\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(\\sqrt{w_{i}}-\\sqrt{\\hat{w}_{i}}\\right)^{2}+\\left(\\sqrt{h_{i}}-\\sqrt{\\hat{h}_{i}}\\right)^{2}\\right] \\\\ +\\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {obj }}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ +\\lambda_{\\text {noobj }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\text {noobj }}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ +\\sum_{i=0}^{S^{2}} \\mathbb{1}_{i}^{\\text {obj }} \\sum_{c \\in \\text { classes }}\\left(p_{i}(c)-\\hat{p}_{i}(c)\\right)^{2} \\end{array}\\) (3) \u5176\u4e2d \\(\\mathbb{1}_{i}^{\\mathrm{obj}}\\) \u8868\u793a\u5982\u679c\u76ee\u6807\u51fa\u73b0\u5728\u5355\u5143\u683c \\(i\\) \u5e76\u4e14 \\(\\mathbb{1}_{i j}^{\\mathrm{obj}}\\) \u8868\u793a\u7b2c \\(j\\) \u4e2a\u8fb9\u754c\u6846\u8d1f\u8d23\u5728\u5355\u5143\u683c \\(i\\) \u9884\u6d4b \u3002 \u2003 \u6ce8\u610f\uff0c\u5982\u679c\u76ee\u6807\u5b58\u5728\u4e8e\u8be5\u7f51\u683c\u5355\u5143\u4e2d\uff08\u524d\u9762\u8ba8\u8bba\u7684\u6761\u4ef6\u7c7b\u522b\u6982\u7387\uff09\uff0c\u5219\u635f\u5931\u51fd\u6570\u60e9\u7f5a\u5206\u7c7b\u8bef\u5dee\u3002\u5982\u679c\u9884\u6d4b\u5668 \\(\"\u8d1f\u8d23\"\\) \u771f\u5b9e\u8fb9\u754c\u6846\uff08\u5373\u8be5\u7f51\u683c\u5355\u5143\u4e2d\u5177\u6709\u6700\u9ad8 \\(IOU\\) \u7684\u9884\u6d4b\u5668\uff09\uff0c\u5219\u5b83\u4e5f\u4ec5\u60e9\u7f5a\u8fb9\u754c\u6846\u5750\u6807\u8bef\u5dee\u3002 \u2003 \u6211\u4eec\u5728 \\(Pascal \\ VOC \\ 2007\\) \u548c \\(2012\\) \u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5927\u7ea6 \\(135\\) \u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u7f51\u7edc\u8bad\u7ec3\u3002 \u5728 \\(Pascal \\ VOC \\ 2012\\) \u4e0a\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c\u6211\u4eec\u7684\u8bad\u7ec3\u8fd8\u5305\u542b\u4e86 \\(P0ascal \\ VOC \\ 2007\\) \u7684\u6d4b\u8bd5\u6570\u636e\u3002\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e86batch-size = 64 ( \u6279\u5927\u5c0f )\uff0cmomentum = 0.9 ( \u52a8\u91cf )\u548c decay = 0.0005 ( \u8870\u51cf\u7387 )\u3002 \u2003 \u6211\u4eec\u7684\u5b66\u4e60\u7387\u65b9\u6848\u5982\u4e0b\uff1a\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u8fed\u4ee3\u5468\u671f\uff0c\u6211\u4eec\u6162\u6162\u5730\u5c06\u5b66\u4e60\u7387\u4ece \\(10^{-3}\\) \u63d0\u9ad8\u5230 \\(10^{-2}\\) \u3002\u5982\u679c\u6211\u4eec\u4ece\u9ad8\u5b66\u4e60\u7387\u5f00\u59cb\uff0c\u6211\u4eec\u7684\u6a21\u578b\u5f80\u5f80\u4f1a\u7531\u4e8e\u68af\u5ea6\u4e0d\u7a33\u5b9a\u800c\u53d1\u6563\u3002\u6211\u4eec\u7ee7\u7eed\u4ee5 \\(10^{-2}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 \\(75\\) \u4e2a epochs( \u5373\u8fed\u4ee3\u5468\u671f )\uff0c\u7136\u540e\u7528 \\(10^{-3}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 \\(30\\) \u4e2aepochs\uff0c\u6700\u540e\u7528 \\(10^{-4}\\) \u7684\u5b66\u4e60\u7387\u8bad\u7ec3 30\u4e2aepochs\u3002 \u2003 \u4e3a\u4e86\u907f\u514d\u8fc7\u5ea6\u62df\u5408\uff0c\u6211\u4eec\u4f7f\u7528 \\(dropout\\) \u548c \u5e7f\u6cdb\u7684\u6570\u636e\u589e\u5f3a\u3002\u5728\u7b2c\u4e00\u4e2a\u8fde\u63a5\u5c42\u4e4b\u540e\u6211\u4eec\u4e22\u5f03\u5177\u6709\u901f\u7387=0.5\u7684\u5c42\uff0c\u9632\u6b62\u5c42\u4e4b\u95f4\u7684\uff08\u76f8\u4e92\u5f71\u54cd\uff09\u3002\u5bf9\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u6211\u4eec\u5f15\u5165\u968f\u673a\u7f29\u653e\u548c\u6700\u591a\u539f\u59cb\u56fe\u50cf\u5927\u5c0f\u768420%\u7684translations\u3002\u6211\u4eec\u8fd8\u968f\u673a\u8c03\u6574\u66dd\u5149\u548c\u9971\u548c\u5ea6\u7684\u56fe\u50cf\u591a\u8fbe1.5\u500d\u7684HSV\u989c\u8272\u7a7a\u95f4\u3002 \u2003\u5728\u7b2c\u4e00\u4e2a\u8fde\u63a5\u5c42\u4e4b\u540e\uff0c \\(dropout\\) \u5c42\u4f7f\u7528rate=0.5\u7684\u6bd4\u4f8b\uff0c\u9632\u6b62\u5c42\u4e4b\u95f4\u7684\u76f8\u4e92\u5f71\u54cd( co-adaptation )[18]\u3002\u5bf9\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u6211\u4eec\u5f15\u5165\u9ad8\u8fbe\u539f\u59cb\u56fe\u50cf20%\u5927\u5c0f\u7684\u968f\u673a\u7f29\u653e\u548c\u8f6c\u6362\u3002\u6211\u4eec\u8fd8\u5728HSV\u8272\u5f69\u7a7a\u95f4\u4e2d\u4f7f\u7528\u9ad8\u8fbe1.5\u7684\u56e0\u5b50\u6765\u968f\u673a\u8c03\u6574\u56fe\u50cf\u7684\u66dd\u5149\u548c\u9971\u548c\u5ea6\u3002","title":"2.2 \u8bad\u7ec3"},{"location":"thesis_interpretation/01_yolo.html#23","text":"\u4e0e\u8bad\u7ec3\u65f6\u4e00\u6837\uff0c\u9884\u6d4b\u6d4b\u8bd5\u56fe\u50cf\u7684\u68c0\u6d4b\u53ea\u9700\u8981\u4e00\u6b21\u7f51\u7edc\u8bc4\u4f30\u3002\u5728 \\(Pascal \\ VOC\\) \u4e0a\uff0c\u6bcf\u5f20\u56fe\u50cf\u4e0a\u7f51\u7edc\u9884\u6d4b98\u4e2a\u8fb9\u754c\u6846\uff08 \u8bd1\u8005\u6ce8\uff1a\u6bcf\u5f20\u56fe\u50cf\u88ab\u5212\u5206\u62107 7\u7684\u683c\u5b50\uff0c\u6bcf\u4e2a\u683c\u5b50\u9884\u6d4b\u4e24\u4e2a\u8fb9\u754c\u6846\uff0c\u603b\u517198\u4e2a\u8fb9\u754c\u6846*\uff09\u548c\u6bcf\u4e2a\u6846\u7684\u7c7b\u522b\u6982\u7387\u3002\u4e0e\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c \\(YOLO\\) \u5728\u6d4b\u8bd5\u65f6\u975e\u5e38\u5feb\uff0c\u56e0\u4e3a\u5b83\u53ea\u9700\u8981\u8fd0\u884c\u4e00\u6b21\u7f51\u7edc\u8bc4\u4f30\u3002 \u2003\u7f51\u683c\u8bbe\u8ba1\u52a0\u5f3a\u4e86\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u7a7a\u95f4\u591a\u6837\u6027\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u76ee\u6807\u843d\u5728\u54ea\u4e2a\u7f51\u683c\u5355\u5143\u683c\u4e2d\u662f\u5f88\u6e05\u695a\u7684\uff0c\u7f51\u7edc\u9884\u6d4b\u7684\u6bcf\u4e2a\u76ee\u6807\u5bf9\u5e94\u4e00\u4e2a\u6846\u3002\u4e00\u4e9b\u5927\u7684\u76ee\u6807\u6216\u9760\u8fd1\u591a\u4e2a\u7f51\u683c\u5355\u5143\u8fb9\u754c\u7684\u76ee\u6807\u53ef\u4ee5\u88ab\u591a\u4e2a\u7f51\u683c\u5355\u5143\u5f88\u597d\u5730\u5b9a\u4f4d\u3002\u975e\u6781\u5927\u503c\u6291\u5236\uff08 \u5373NMS \uff09\u53ef\u4ee5\u7528\u6765\u4fee\u6b63\u8fd9\u4e9b\u591a\u91cd\u68c0\u6d4b\u3002\u867d\u7136\u4e0d\u50cf \\(R-CNN\\) \u6216 \\(DPM\\) \u90a3\u6837\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u975e\u6700\u5927\u6291\u5236\u589e\u52a0\u4e862~3%\u7684 \\(mAP\\) \u3002","title":"2.3 \u63a8\u7406"},{"location":"thesis_interpretation/01_yolo.html#24-yolo","text":"YOLO\u5bf9\u8fb9\u754c\u6846\u9884\u6d4b\u65bd\u52a0\u4e86\u5f88\u5f3a\u7684\u7a7a\u95f4\u7ea6\u675f\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u683c\u53ea\u80fd\u9884\u6d4b\u4e24\u4e2a\u6846\uff0c\u5e76\u4e14\u53ea\u80fd\u6709\u4e00\u4e2a\u7c7b\u3002\u8fd9\u79cd\u7a7a\u95f4\u7ea6\u675f\u9650\u5236\u4e86\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u9884\u6d4b\u7684\u9644\u8fd1\u7269\u4f53\u7684\u6570\u91cf\u3002\u6211\u4eec\u7684\u6a21\u578b\u5f88\u96be\u5904\u7406\u6210\u7fa4\u51fa\u73b0\u7684\u5c0f\u7269\u4f53\uff0c\u6bd4\u5982\u9e1f\u7fa4\u3002 \u2003 \u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u5b66\u4e60\u4ece\u6570\u636e\u4e2d\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u56e0\u6b64\u5b83\u5f88\u96be\u6cdb\u5316\u5230\u65b0\u7684\u3001\u4e0d\u5e38\u89c1\u7684\u957f\u5bbd\u6bd4\u6216\u914d\u7f6e\u4e2d\u7684\u76ee\u6807\u3002\u6211\u4eec\u7684\u6a21\u578b\u4e5f\u4f7f\u7528\u76f8\u5bf9\u8f83\u7c97\u7cd9\u7684\u7279\u5f81\u6765\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u56e0\u4e3a\u6211\u4eec\u7684\u67b6\u6784\u5177\u6709\u6765\u81ea\u8f93\u5165\u56fe\u50cf\u7684\u591a\u4e2a\u4e0b\u91c7\u6837\u5c42\u3002 \u2003\u6700\u540e\uff0c\u5f53\u6211\u4eec\u8bad\u7ec3\u4e00\u4e2a\u8fd1\u4f3c\u68c0\u6d4b\u6027\u80fd\u7684\u635f\u5931\u51fd\u6570\u65f6\uff0c\u6211\u4eec\u7684\u635f\u5931\u51fd\u6570\u5bf9\u5f85\u5c0f\u8fb9\u754c\u6846\u4e0e\u5927\u8fb9\u754c\u6846\u7684\u4f1a\u6709\u540c\u6837\u7684\u8bef\u5dee\u3002\u5927\u8fb9\u754c\u6846\u7684\u5c0f\u8bef\u5dee\u901a\u5e38\u662f\u826f\u6027\u7684\uff0c\u4f46\u5c0f\u8fb9\u754c\u6846\u7684\u5c0f\u8bef\u5dee\u5bf9 \\(IOU\\) \u7684\u5f71\u54cd\u8981\u5927\u5f97\u591a\u3002\u6211\u4eec\u7684\u4e3b\u8981\u8bef\u5dee\u6765\u6e90\u662f\u5b9a\u4f4d\u8bef\u5dee\u3002","title":"2.4 YOLO\u7684\u5c40\u9650\u6027"},{"location":"thesis_interpretation/01_yolo.html#3","text":"\u76ee\u6807\u68c0\u6d4b\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u6838\u5fc3\u95ee\u9898\u3002\u68c0\u6d4b\u6d41\u7a0b\u901a\u5e38\u4ece\u8f93\u5165\u56fe\u50cf\u4e0a\u63d0\u53d6\u4e00\u7ec4\u5065\u58ee\u7684\u7279\u5f81\uff08 \\(Haar\\) [25]\uff0c \\(SIFT\\) [23]\uff0c \\(HOG\\) [4]\uff0c\u5377\u79ef\u7279\u5f81[6]\uff09\u5f00\u59cb\u3002\u7136\u540e\uff0c\u5206\u7c7b\u5668[36,21,13,10]\u6216\u5b9a\u4f4d\u5668[1,32]\u88ab\u7528\u6765\u8bc6\u522b\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u76ee\u6807\u3002 \u8fd9\u4e9b\u5206\u7c7b\u5668\u6216\u5b9a\u4f4d\u5668\u4ee5\u6ed1\u52a8\u7a97\u53e3\u7684\u65b9\u5f0f\u5728\u6574\u4e2a\u56fe\u50cf\u4e0a\u8fd0\u884c,\u6216\u8005\u5728\u56fe\u50cf\u4e2d\u7684\u4e00\u4e9b\u533a\u57df\u7684\u5b50\u96c6[35,15,39]\u4e0a\u3002 \u6211\u4eec\u5c06 \\(YOLO\\) \u68c0\u6d4b\u7cfb\u7edf\u4e0e\u51e0\u79cd\u9876\u7ea7\u68c0\u6d4b\u6846\u67b6\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u7a81\u51fa\u4e86\u4e3b\u8981\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\u3002 \u2003 \u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b \uff08 Deformable parts models \uff09\u3002\u53ef\u53d8\u5f62\u96f6\u4ef6\u6a21\u578b\uff08 \\(DPM\\) \uff09\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b[10]\u3002DPM\u4f7f\u7528\u4e0d\u76f8\u4ea4\u7684\u6d41\u7a0b\u6765\u63d0\u53d6\u9759\u6001\u7279\u5f81\uff0c\u5bf9\u533a\u57df\u8fdb\u884c\u5206\u7c7b\uff0c\u9884\u6d4b\u9ad8\u8bc4\u5206\u533a\u57df\u7684\u8fb9\u754c\u6846\u7b49\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u7528\u5355\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u66ff\u6362\u6240\u6709\u8fd9\u4e9b\u4e0d\u540c\u7684\u90e8\u5206\u3002\u7f51\u7edc\u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3001\u8fb9\u754c\u6846\u9884\u6d4b\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u3002\u7f51\u7edc\u5185\u5d4c\u8bad\u7ec3\u7279\u5f81\u800c\u4e0d\u662f\u9759\u6001\u7279\u5f81\uff0c\u5e76\u4f18\u5316\u5b83\u4eec\u5b8c\u6210\u68c0\u6d4b\u4efb\u52a1\u3002\u6211\u4eec\u7684\u7edf\u4e00\u67b6\u6784\u83b7\u5f97\u4e86\u6bd4DPM\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u6a21\u578b\u3002 \u2003 \\(R-CNN\\) \u53ca\u5176\u53d8\u79cd\u4f7f\u7528 \\(region \\ proposals\\) \u800c\u4e0d\u662f\u6ed1\u52a8\u7a97\u53e3\u6765\u67e5\u627e\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u3002Selective Search[35]\u4ea7\u751f\u6f5c\u5728\u7684\u8fb9\u754c\u6846\u3001\u5377\u79ef\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\u3001 \\(SVM\\) \u5bf9\u8fb9\u754c\u6846\u8fdb\u884c\u8bc4\u5206\u3001\u7ebf\u6027\u6a21\u578b\u8c03\u6574\u8fb9\u754c\u6846\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u6d88\u9664\u91cd\u590d\u68c0\u6d4b\u3002\u8fd9\u4e2a\u590d\u6742\u6d41\u7a0b\u7684\u6bcf\u4e2a\u9636\u6bb5\u90fd\u5fc5\u987b\u72ec\u7acb\u5730\u8fdb\u884c\u7cbe\u786e\u8c03\u6574\uff0c\u6240\u5f97\u5230\u7684\u7cfb\u7edf\u975e\u5e38\u6162\uff0c\u6d4b\u8bd5\u65f6\u6bcf\u5f20\u56fe\u50cf\u9700\u8981\u8d85\u8fc740\u79d2[14]\u3002 \\(YOLO\\) \u4e0e $R-CNN $ \u6709\u4e00\u4e9b\u76f8\u4f3c\u4e4b\u5904\u3002\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u63d0\u51fa\u6f5c\u5728\u7684\u8fb9\u754c\u6846\u5e76\u4f7f\u7528\u5377\u79ef\u7279\u5f81\u5bf9\u8fd9\u4e9b\u6846\u8fdb\u884c\u8bc4\u5206\u3002\u4f46\u662f\u6211\u4eec\u7684\u7cfb\u7edf\u5bf9\u7f51\u683c\u5355\u5143\u63d0\u51fa\u8fdb\u884c\u4e86\u7a7a\u95f4\u9650\u5236\uff0c\u8fd9\u6709\u52a9\u4e8e\u7f13\u89e3\u5bf9\u540c\u4e00\u76ee\u6807\u7684\u591a\u6b21\u68c0\u6d4b\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u8fd8\u63d0\u51fa\u4e86\u66f4\u5c11\u7684\u8fb9\u754c\u6846\uff0c\u6bcf\u5f20\u56fe\u50cf\u53ea\u6709 \\(98\\) \u4e2a\uff0c\u800c \\(Selective Search\\) \u5219\u9700\u8981 \\(2000\\) \u4e2a\u5de6\u53f3\u3002\u6700\u540e\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u5c06\u8fd9\u4e9b\u5355\u72ec\u7684\u7ec4\u4ef6\u7ec4\u5408\u6210\u4e00\u4e2a\u5355\u4e00\u7684\u3001\u5171\u540c\u4f18\u5316\u7684\u6a21\u578b\u3002 \u2003 \u5176\u5b83\u5feb\u901f\u68c0\u6d4b\u5668( Other Fast Detectors ) \u3002 \\(Fast\\) \u548c \\(Faster \\ R-CNN\\) \u901a\u8fc7\u5171\u4eab\u8ba1\u7b97\u548c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3 \\(Selective \\ Search\\) \u6765\u63d0\u51fa\u533a\u57df\u52a0\u901f \\(R-CNN\\) \u6846\u67b6[14][28]\u3002\u867d\u7136\u5b83\u4eec\u63d0\u4f9b\u4e86\u6bd4 \\(R-CNN\\) \u66f4\u5feb\u7684\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u5ea6\uff0c\u4f46\u4e24\u8005\u4ecd\u7136\u4e0d\u80fd\u8fbe\u5230\u5b9e\u65f6\u6027\u80fd\u3002 \u2003\u8bb8\u591a\u7814\u7a76\u5de5\u4f5c\u96c6\u4e2d\u5728\u52a0\u5feb \\(DPM\\) \u6d41\u7a0b\u4e0a[31][38][5]\u3002\u5b83\u4eec\u52a0\u901f \\(HOG\\) \u8ba1\u7b97\uff0c\u4f7f\u7528\u7ea7\u8054\uff0c\u5e76\u5c06\u8ba1\u7b97\u63a8\u52a8\u5230 \\(GPU\\) \u4e0a\u3002\u4f46\u662f\uff0c\u5b9e\u9645\u4e0a \\(DPM\\) [31]\u5b9e\u65f6\u8fd0\u884c\u53ea\u8fbe\u5230 \\(30Hz\\) \u3002 \u2003 \\(YOLO\\) \u4e0d\u662f\u8bd5\u56fe\u4f18\u5316\u5927\u578b\u68c0\u6d4b\u6d41\u7a0b\u7684\u5355\u4e2a\u7ec4\u4ef6\uff0c\u800c\u662f\u5b8c\u5168\u629b\u5f03\u6d41\u7a0b\uff0c\u4e3a\u63d0\u5347\u68c0\u6d4b\u901f\u5ea6\u800c\u91cd\u65b0\u8bbe\u8ba1\u3002 \u2003\u50cf\u4eba\u8138\u6216\u884c\u4eba\u7b49\u5355\u7c7b\u522b\u7684\u68c0\u6d4b\u5668\u53ef\u4ee5\u88ab\u9ad8\u5ea6\u4f18\u5316\uff0c\u56e0\u4e3a\u4ed6\u4eec\u53ea\u9700\u5904\u7406\u66f4\u5c11\u7684\u591a\u6837\u6027[37]\u3002 \\(YOLO\\) \u662f\u4e00\u79cd\u901a\u7528\u7684\u68c0\u6d4b\u5668\uff0c\u53ef\u4ee5\u5b66\u4e60\u540c\u65f6\u68c0\u6d4b\u5404\u79cd\u76ee\u6807\u3002 \u2003 Deep MultiBox :\u4e0eR-CNN\u4e0d\u540c\uff0cSzegedy\u7b49\u4eba\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u611f\u5174\u8da3\u533a\u57df\uff08 ROI \uff09[8]\uff0c\u800c\u4e0d\u662f\u4f7f\u7528 \\(Selective \\ Search\\) \u3002MultiBox\u8fd8\u53ef\u4ee5\u901a\u8fc7\u7528\u5355\u7c7b\u522b\u9884\u6d4b\u66ff\u6362\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u6765\u6267\u884c\u5355\u76ee\u6807\u68c0\u6d4b\u3002\u7136\u800c\uff0c \\(MultiBox\\) \u65e0\u6cd5\u6267\u884c\u901a\u7528\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u5e76\u4e14\u4ecd\u7136\u53ea\u662f\u4e00\u4e2a\u8f83\u5927\u7684\u68c0\u6d4b\u6d41\u7a0b\u4e2d\u7684\u4e00\u90e8\u5206\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u5bf9\u56fe\u50cf\u5757\u8fdb\u884c\u5206\u7c7b\u3002 \\(YOLO\\) \u548c \\(MultiBox\\) \u90fd\u4f7f\u7528\u5377\u79ef\u7f51\u7edc\u6765\u9884\u6d4b\u56fe\u50cf\u4e2d\u7684\u8fb9\u754c\u6846\uff0c\u4f46\u662f \\(YOLO\\) \u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002 \u2003 \\(OverFeat\\) :Sermanet\u7b49\u4eba\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u5b9a\u4f4d\u5de5\u4f5c\uff0c\u5e76\u4f7f\u8be5\u5b9a\u4f4d\u5668\u8fdb\u884c\u68c0\u6d4b[32]\u3002 \\(OverFeat\\) \u53ef\u4ee5\u9ad8\u6548\u5730\u6267\u884c\u6ed1\u52a8\u7a97\u53e3\u68c0\u6d4b\uff0c\u4f46\u5b83\u4ecd\u7136\u662f\u4e00\u4e2a\u4e0d\u8fde\u8d2f\u7684\u7cfb\u7edf\u3002 \\(OverFeat\\) \u4f18\u5316\u4e86\u5b9a\u4f4d\uff0c\u800c\u4e0d\u662f\u68c0\u6d4b\u6027\u80fd\u3002\u50cf \\(DPM\\) \u4e00\u6837\uff0c\u5b9a\u4f4d\u5668\u5728\u8fdb\u884c\u9884\u6d4b\u65f6\u53ea\u80fd\u770b\u5230\u5c40\u90e8\u4fe1\u606f\u3002 \\(OverFeat\\) \u4e0d\u80fd\u63a8\u7406\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u56e0\u6b64\u9700\u8981\u5927\u91cf\u7684\u540e\u5904\u7406\u6765\u4ea7\u751f\u4e00\u81f4\u7684\u68c0\u6d4b\u3002 \u2003 \\(MultiGrasp\\) : \u6211\u4eec\u7684\u5de5\u4f5c\u5728\u8bbe\u8ba1\u4e0a\u7c7b\u4f3c\u4e8e \\(Redmon\\) \u7b49[27]\u7684 \\(grasp\\) \u68c0\u6d4b\u3002\u6211\u4eec\u5bf9\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u7f51\u683c\u65b9\u6cd5\u662f\u57fa\u4e8e \\(MultiGrasp\\) \u7cfb\u7edf\u5bf9\u4e8e \\(grasp\u68c0\u6d4b\\) \u7684\u56de\u5f52\u5206\u6790\u3002\u7136\u800c\uff0c \\(grasp\\) \u68c0\u6d4b\u6bd4\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u8981\u7b80\u5355\u5f97\u591a\u3002 \\(MultiGrasp\\) \u53ea\u9700\u8981\u4e3a\u5305\u542b\u4e00\u4e2a\u76ee\u6807\u7684\u56fe\u50cf\u9884\u6d4b\u4e00\u4e2a\u53ef\u4ee5 \\(grasp\\) \u7684\u533a\u57df( \u5373\u9002\u5408\u6293\u53d6\u7684\u533a\u57df )\u3002\u4e0d\u5fc5\u4f30\u8ba1\u76ee\u6807\u7684\u5927\u5c0f\u3001\u4f4d\u7f6e\u6216\u76ee\u6807\u8fb9\u754c\u6216\u9884\u6d4b\u76ee\u6807\u7684\u7c7b\u522b\uff0c\u53ea\u9700\u8981\u627e\u5230\u9002\u5408\u6293\u53d6\u7684\u533a\u57df\u3002 \\(YOLO\\) \u53ef\u4ee5\u9884\u6d4b\u56fe\u50cf\u4e2d\u591a\u4e2a\u7c7b\u522b\u7684\u591a\u4e2a\u76ee\u6807\u7684\u8fb9\u754c\u6846\u548c\u7c7b\u522b\u6982\u7387\u3002","title":"3. \u4e0e\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u7684\u6bd4\u8f83"},{"location":"thesis_interpretation/01_yolo.html#4","text":"\u9996\u5148\uff0c\u6211\u4eec\u5728 \\(PASCAL \\ VOC \\ 2007\\) \u4e0a\u6bd4\u8f83\u4e86 \\(YOLO\\) \u548c\u5176\u5b83\u7684\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf\u3002\u4e3a\u4e86\u7406\u89e3 \\(YOLO\\) \u548c \\(R-CNN\\) \u53d8\u79cd\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u63a2\u7d22\u4e86 \\(YOLO\\) \u548c \\(R-CNN\\) \u6027\u80fd\u6700\u9ad8\u7684\u7248\u672c\u4e4b\u4e00 \\(Fast\\ R-CNN\\) [14]\u5728 \\(VOC \\ 2007\\) \u4e0a\u9519\u8bef\u7387\u3002\u6839\u636e\u4e0d\u540c\u7684\u8bef\u5dee\u66f2\u7ebf\uff0c\u6211\u4eec\u7684\u7814\u7a76\u663e\u793a \\(YOLO\\) \u53ef\u4ee5\u7528\u6765\u91cd\u65b0\u8bc4\u4f30 \\(Fast \\ R-CNN\\) \u68c0\u6d4b\uff0c\u5e76\u51cf\u5c11\u80cc\u666f\u5047\u9633\u6027\u5e26\u6765\u7684\u8bef\u5dee\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u5728 \\(VOC \\ 2012\\) \u4e0a\u7684\u7ed3\u679c\uff0c\u5e76\u4e0e\u76ee\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u6bd4\u8f83\u4e86 \\(mAP\\) \u3002\u6700\u540e\uff0c\u5728\u4e24\u4e2a\u827a\u672f\u54c1\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86\u6211\u4eec \\(YOLO\\) \u6bd4\u5176\u4ed6\u68c0\u6d4b\u5668\u66f4\u80fd\u6cdb\u5316\u5230\u65b0\u7684\u9886\u57df\u3002","title":"4. \u6d4b\u8bd5\u5b9e\u9a8c"},{"location":"thesis_interpretation/01_yolo.html#41","text":"\u76ee\u6807\u68c0\u6d4b\u65b9\u9762\u7684\u8bb8\u591a\u7814\u7a76\u5de5\u4f5c\u90fd\u96c6\u4e2d\u5728\u5bf9\u6807\u51c6\u68c0\u6d4b\u6d41\u7a0b[5]\uff0c[38]\uff0c[31]\uff0c[14]\uff0c[17]\uff0c[28]\u63d0\u5347\u901f\u5ea6\u4e0a\u3002\u7136\u800c\uff0c\u53ea\u6709Sadeghi\u7b49\u771f\u6b63\u7814\u7a76\u51fa\u4e86\u4e00\u4e2a\u5b9e\u65f6\u8fd0\u884c\u7684\u68c0\u6d4b\u7cfb\u7edf\uff08\u6bcf\u79d230\u5e27\u6216\u66f4\u597d\uff09[31]\u3002\u6211\u4eec\u5c06YOLO\u4e0e\u4ed6\u4eecDPM\u7684GPU\u5b9e\u73b0\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5176\u572830Hz\u6216100Hz\u4e0b\u8fd0\u884c\u3002\u867d\u7136\u5176\u5b83\u7684\u7814\u7a76\u5de5\u4f5c\u6ca1\u6709\u8fbe\u5230\u5b9e\u65f6\u68c0\u6d4b\u7684\u6807\u51c6\uff0c\u6211\u4eec\u4e5f\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u76f8\u5bf9mAP\u548c\u901f\u5ea6\u6765\u68c0\u67e5\u76ee\u6807\u68c0\u6d4b\u7cfb\u7edf\u4e2d\u7cbe\u5ea6\u2014\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002 \u2003 \\(Fast \\ YOLO\\) \u662f \\(PASCAL\\) \u4e0a\u6700\u5feb\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5;\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u662f\u73b0\u5b58\u901f\u5ea6\u6700\u5feb\u7684\u7269\u4f53\u63a2\u6d4b\u5668\u3002 \\(mAP\\) \u7684\u51c6\u786e\u7387\u4e3a \\(52.7%\\) \uff0c\u662f\u4e4b\u524d\u5b9e\u65f6\u68c0\u6d4b\u5de5\u4f5c\u7684\u4e24\u500d\u591a\u3002 \\(YOLO\\) \u5c06 \\(mAP\\) \u63a8\u81f3 \\(63.4%\\) \uff0c\u540c\u65f6\u4ecd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002 \u2003\u6211\u4eec\u4e5f\u4f7f\u7528 \\(VGG-16\\) \u8bad\u7ec3\u4e86 \\(YOLO\\) \u3002\uff08 \u8bd1\u8005\u6ce8\uff1aYOLO\u4f7f\u7528\u4e86\u4f5c\u8005\u81ea\u5df1\u5f00\u53d1\u7684DarkNet\u6a21\u578b\u4e3abaseline \uff09\u8fd9\u4e2a\u6a21\u578b\u6bd4 \\(YOLO\\) \u66f4\u51c6\u786e\uff0c\u4f46\u901f\u5ea6\u6162\u5f97\u591a\u3002\u8fd9\u4e2a\u6a21\u578b\u53ef\u4ee5\u7528\u6765\u4e0e\u4f9d\u8d56\u4e8e \\(VGG-16\\) \u7684\u5176\u5b83\u68c0\u6d4b\u7cfb\u7edf\u4f5c\u6bd4\u8f83\uff0c\u4f46\u7531\u4e8e\u5b83\u6bd4\u5b9e\u65f6\u7684 \\(YOLO\\) \u66f4\u6162\uff0c\u672c\u6587\u7684\u5176\u4f59\u90e8\u5206\u4e3b\u8981\u5173\u6ce8\u6211\u4eec\u66f4\u5feb\u7684\u6a21\u578b\u3002 \u2003 \\(Fastest \\ DPM\\) \u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u592a\u591a \\(mAP\\) \u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5730\u52a0\u901f \\(DPM\\) \uff0c\u4f46\u5b83\u4ecd\u7136\u4f1a\u5c06\u5b9e\u65f6\u6027\u80fd\u964d\u4f4e2\u500d[38]\u3002\u4e0e\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u76f8\u6bd4\uff0c \\(DPM\\) \u76f8\u5bf9\u8f83\u4f4e\u7684\u68c0\u6d4b\u7cbe\u5ea6\u4e5f\u662f\u5176\u9650\u5236\u3002 \\(\\begin{array}{lrrr} \\text { Real-Time Detectors } & \\text { Train } & \\text { mAP } & \\text { FPS } \\\\ \\hline \\text { 100Hz DPM [31] } & 2007 & 16.0 & 100 \\\\ \\text { 30Hz DPM [31] } & 2007 & 26.1 & 30 \\\\ \\text { Fast YOLO } & 2007+2012 & 52.7 & \\mathbf{1 5 5} \\\\ \\text { YOLO } & 2007+2012 & \\mathbf{6 3 . 4} & 45 \\\\ \\hline \\hline \\text { Less Than Real-Time } & & & \\\\ \\hline \\text { Fastest DPM [38] } & 2007 & 30.4 & 15 \\\\ \\text { R-CNN Minus R [20] } & 2007 & 53.5 & 6 \\\\ \\text { Fast R-CNN [14] } & 2007+2012 & 70.0 & 0.5 \\\\ \\text { Faster R-CNN VGG-16[28] } & 2007+2012 & 73.2 & 7 \\\\ \\text { Faster R-CNN ZF [28] } & 2007+2012 & 62.1 & 18 \\\\ \\text { YOLO VGG-16 } & 2007+2012 & 66.4 & 21 \\end{array}\\) \u88681\uff1aPASCAL VOC 2007 \u7684\u5b9e\u65f6\u7cfb\u7edf \u6bd4\u8f83\u5feb\u901f\u63a2\u6d4b\u5668\u7684\u6027\u80fd\u548c\u901f\u5ea6\u3002 \\(Fast \\ YOLO\\) \u662f \\(PASCAL \\ VOC\\) \u68c0\u6d4b\u8bb0\u5f55\u4e2d\u6700\u5feb\u7684\u68c0\u6d4b\u5668\uff0c\u51c6\u786e\u6027\u4ecd\u7136\u662f\u4efb\u4f55\u5176\u4ed6\u5b9e\u65f6\u68c0\u6d4b\u5668\u7684\u4e24\u500d\u3002 \\(YOLO\\) \u6bd4\u5feb\u901f\u7248\u672c\u66f4\u7cbe\u786e \\(10mAP\\) \uff0c\u540c\u65f6\u5b9e\u65f6\u901f\u5ea6\u8fdc\u8fdc\u9ad8\u4e8e\u5176\u4ed6\u68c0\u6d4b\u5668\u3002 \u2003 \\(R-CNN \\ minnus \\ R\\) \u5c06\u9009\u62e9\u6027\u641c\u7d22\u66ff\u6362\u4e3a\u9759\u6001\u8fb9\u754c\u6846proposals [20]\u3002\u867d\u7136\u901f\u5ea6\u6bd4R-CNN\u66f4\u5feb\uff0c\u4f46\u4ecd\u7136\u8fbe\u4e0d\u5230\u5b9e\u65f6\uff0c\u5e76\u4e14\u7531\u4e8e\u6ca1\u6709\u597d\u7684\u8fb9\u754c\u6846proposals\uff0c\u51c6\u786e\u6027\u53d7\u5230\u4e86\u4e25\u91cd\u5f71\u54cd\u3002 \u2003 \\(Fast \\ R-CNN\\) \u52a0\u5feb\u4e86 \\(R-CNN\\) \u7684\u5206\u7c7b\u9636\u6bb5\uff0c\u4f46\u662f\u4ecd\u7136\u4f9d\u8d56selective search\uff0c\u6bcf\u5f20\u56fe\u50cf\u9700\u8981\u82b1\u8d39\u5927\u7ea62\u79d2\u6765\u751f\u6210\u8fb9\u754c\u6846proposals\u3002\u56e0\u6b64\uff0c\u5b83\u5177\u6709\u5f88\u9ad8\u7684mAP\uff0c\u4f46\u662f0.5 fps\u7684\u901f\u5ea6\u4ecd\u79bb\u5b9e\u65f6\u6027\u5f88\u8fdc\u3002 \u2003 \u6700\u8fd1 \\(Faster \\ R-CNN\\) \u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u4e86selective search\u6765\u63d0\u51fa\u8fb9\u754c\u6846\uff0c\u7c7b\u4f3c\u4e8eSzegedy\u7b49[8]\u3002\u5728\u6211\u4eec\u7684\u6d4b\u8bd5\u4e2d\uff0c\u4ed6\u4eec\u6700\u7cbe\u786e\u7684\u6a21\u578b\u8fbe\u5230\u4e867fps\uff0c\u800c\u8f83\u5c0f\u7684\u3001\u4e0d\u592a\u7cbe\u786e\u7684\u6a21\u578b\u8fd0\u884c\u901f\u5ea6\u8fbe\u523018fps\u3002 \\(VGG-16\\) \u7248\u672c\u7684 \\(Faster \\ R-CNN\\) \u8981\u9ad8\u51fa \\(10mAP\\) \uff0c\u4f46\u901f\u5ea6\u6bd4 \\(YOLO\\) \u6162 \\(6\\) \u500d\u3002ZeilerFergus\u7684 \\(Faster \\ R-CNN\\) \u53ea\u6bd4 \\(YOLO\\) \u6162\u4e862.5\u500d\uff0c\u4f46\u4e5f\u4e0d\u592a\u51c6\u786e\u3002","title":"4.1 \u4e0e\u5176\u4ed6\u5b9e\u65f6\u7cfb\u7edf\u7684\u6bd4\u8f83"},{"location":"thesis_interpretation/01_yolo.html#42-voc-2007","text":"\u4e3a\u4e86\u8fdb\u4e00\u6b65\u68c0\u67e5 \\(YOLO\\) \u548c\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u8be6\u7ec6\u5206\u6790\u4e86 \\(VOC \\ 2007\\) \u7684\u7ed3\u679c\u3002\u6211\u4eec\u5c06 \\(YOLO\\) \u4e0e \\(Fast \\ R-CNN\\) \u8fdb\u884c\u6bd4\u8f83\uff0c\u56e0\u4e3a \\(Fast \\ R-CNN\\) \u662f \\(PASCAL\\) \u4e0a\u6027\u80fd\u6700\u9ad8\u7684\u68c0\u6d4b\u5668\u4e4b\u4e00\u5e76\u4e14\u5b83\u7684\u68c0\u6d4b\u4ee3\u7801\u662f\u53ef\u516c\u5f00\u5f97\u5230\u7684\u3002 \u2003\u6211\u4eec\u4f7f\u7528Hoiem\u7b49\u4eba[19]\u7684\u65b9\u6cd5\u548c\u5de5\u5177\u3002\u5bf9\u4e8e\u6d4b\u8bd5\u65f6\u7684\u6bcf\u4e2a\u7c7b\u522b\uff0c\u6211\u4eec\u53ea\u5173\u6ce8\u8fd9\u4e2a\u7c7b\u522b\u7684\u524dN\u4e2a\u9884\u6d4b\u3002\u6bcf\u4e2a\u9884\u6d4b\u8981\u4e48\u5f52\u4e3a\u6b63\u786e\uff0c\u8981\u4e48\u6839\u636e\u9519\u8bef\u7c7b\u578b\u8fdb\u884c\u5f52\u7c7b\uff1a Correct\uff1a\u5206\u7c7b\u6b63\u786e\u4e14 \\(IOU >0.5\\) \u3002 Localization\uff1a\u5206\u7c7b\u6b63\u786e\u4f46 \\(0.1<IOU<0.5\\) \u3002 Similar\uff1a\u5206\u7c7b\u7684\u7c7b\u522b\u76f8\u4f3c\u4e14 \\(IOU>0.1\\) \u3002 Other\uff1a\u7c7b\u522b\u9519\u8bef\uff0c \\(IOU>0.1\\) \u3002 Background\uff1a\u5206\u7c7b\u4e3a\u5176\u5b83\u4efb\u4f55\u76ee\u6807\uff0c \\(IOU<0.1\\) \u3002 \u56fe4\uff1a\u9519\u8bef\u5206\u6790: \\(Fast \\ R-CNN\\) vs. \\(YOLO\\) \u8fd9\u4e9b\u56fe\u8868\u663e\u793a\u4e86\u5404\u79cd\u7c7b\u522b\u7684\u524dN\u4e2a\u68c0\u6d4b\u4e2d\u5b9a\u4f4d\u548c\u80cc\u666f\u9519\u8bef\u7684\u767e\u5206\u6bd4(N = #\u8be5\u7c7b\u522b\u4e2d\u7684\u76ee\u6807\u6570) \u2003 \\(YOLO\\) \u5f88\u96be\u6b63\u786e\u6b63\u786e\u5b9a\u4f4d\u76ee\u6807\u3002\u5b9a\u4f4d\u8bef\u5dee\u6bd4\u5176\u5b83\u8bef\u5dee\u9519\u8bef\u6765\u6e90\u603b\u5408\u90fd\u591a\u3002 \\(Fast \\ R-CNN\\) \u5b9a\u4f4d\u8bef\u5dee\u5c11\u5f88\u591a\uff0c\u4f46\u80cc\u666f\u8bef\u5dee\u66f4\u591a\u3002\u5b83\u7684\u68c0\u6d4b\u7ed3\u679c\u4e2d \\(13.6%\\) \u662f\u4e0d\u5305\u542b\u4efb\u4f55\u76ee\u6807\u7684\u5047\u9633\u6027\u3002 \\(Fast \\ R-CNN\\) \u4e0e \\(YOLO\\) \u76f8\u6bd4\uff0c\u5c06\u80cc\u666f\u9884\u6d4b\u6210\u76ee\u6807\u7684\u53ef\u80fd\u6027\u9ad8\u51fa\u8fd13\u500d\u3002\uff08 \u8bd1\u8005\u6ce8\uff1a\u6839\u636e\u56fe4\uff0c13.6/4.75=2.86 \uff09","title":"4.2 \u5728VOC 2007\u4e0a\u7684\u8bef\u5dee\u5206\u6790"},{"location":"thesis_interpretation/01_yolo.html#43-fast-r-cnn-yolo","text":"\\(YOLO\\) \u6bd4 \\(Fast \\ R-CNN\\) \u7684\u80cc\u666f\u8bef\u68c0\u8981\u5c11\u5f97\u591a\u3002\u901a\u8fc7\u4f7f\u7528 \\(YOLO\\) \u6d88\u9664 \\(Fast \\ R-CNN\\) \u7684\u80cc\u666f\u68c0\u6d4b\uff0c\u6211\u4eec\u83b7\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u5bf9\u4e8e \\(RCNN\\) \u9884\u6d4b\u7684\u6bcf\u4e2a\u8fb9\u754c\u6846\uff0c\u6211\u4eec\u68c0\u67e5 \\(YOLO\\) \u662f\u5426\u9884\u6d4b\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u7684\u6846\u3002\u5982\u679c\u662f\u8fd9\u6837\uff0c\u6211\u4eec\u6839\u636e \\(YOLO\\) \u9884\u6d4b\u7684\u6982\u7387\u548c\u4e24\u4e2a\u76d2\u5b50\u4e4b\u95f4\u7684\u91cd\u53e0\u6765\u5bf9\u8fd9\u4e2a\u9884\u6d4b\u8fdb\u884c\u6539\u8fdb\u3002 \u2003\u6700\u597d\u7684 \\(Fast \\ R-CNN\\) \u6a21\u578b\u5728 \\(VOC \\ 2007\\) \u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230\u4e86 71.8%\u7684 \\(mAP\\) \u3002\u5f53\u4e0e \\(YOLO\\) \u7ed3\u5408\u65f6\uff0c\u5176 \\(mAP\\) \u589e\u52a0\u4e86 3.2% \u8fbe\u5230\u4e86 75.0% \u3002\u6211\u4eec\u4e5f\u5c1d\u8bd5\u5c06\u6700\u597d\u7684 \\(Fast \\ R-CNN\\) \u6a21\u578b\u4e0e\u5176\u5b83\u51e0\u4e2a\u7248\u672c\u7684 \\(Fast \\ R-CNN\\) \u7ed3\u5408\u8d77\u6765\u3002\u8fd9\u4e9b\u6a21\u578b\u7ec4\u5408\u4ea7\u751f\u4e860.3-0.6%\u7684\u5c0f\u5e45\u589e\u52a0\uff0c\u8be6\u89c1\u88682\u3002 \\(\\begin{array}{lrrr} & \\text { mAP } & \\text { Combined } & \\text { Gain } \\\\ \\hline \\text { Fast R-CNN } & 71.8 & - & - \\\\ \\hline \\text { Fast R-CNN (2007 data) } & \\mathbf{6 6 . 9} & 72.4 & .6 \\\\ \\text { Fast R-CNN (VGG-M) } & 59.2 & 72.4 & .6 \\\\ \\text { Fast R-CNN (CaffeNet) } & 57.1 & 72.1 & .3 \\\\ \\text { YOLO } & 63.4 & \\mathbf{7 5 . 0} & \\mathbf{3 . 2} \\end{array}\\) \u88682:VOC 2007\u7684\u6a21\u578b\u7ec4\u5408\u8bd5\u9a8c\u3002\u6211\u4eec\u7528 \\(Fast \\ R-CNN\\) \u7684\u6700\u4f73\u7248\u672c\u6765\u68c0\u9a8c\u5404\u79cd\u6a21\u578b\u7684\u7ec4\u5408\u6548\u679c\u3002 \\(Fast \\ R-CNN\\) \u7684\u5176\u4ed6\u7248\u672c\u53ea\u6539\u5584\u4e86\u5f88\u5c0f\u7684\u6027\u80fd\uff0c\u800c \\(YOLO\\) \u63d0\u4f9b\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002 \u88683:PASCAL VOC 2012\u6392\u884c\u699c\u30022015\u5e7411\u67086\u65e5\uff0cYOLO\u4e0e\u5b8c\u6574comp4(\u5141\u8bb8\u5916\u90e8\u6570\u636e)\u516c\u5f00\u6392\u884c\u699c\u7684\u5bf9\u6bd4\u3002 \\(mAP\\) \u548c \u6bcf\u4e2a\u7c7bAP \u90fd\u663e\u793a\u5728\u5404\u79cd\u68c0\u6d4b\u65b9\u6cd5\u3002 \\(YOLO\\) \u662f\u552f\u4e00\u7684\u5b9e\u65f6\u68c0\u6d4b\u5668\u3002 \\(Fast \\ R-CNN + YOLO\\) \u662f\u7b2c\u56db\u9ad8\u7684\u5f97\u5206\u65b9\u6cd5\uff0c\u6bd4 \\(Fast \\ R-CNN\\) \u63d0\u9ad8\u4e862.3%\u7684 \\(mAP\\) \u3002 \u2003\u6765\u81eaYOLO\u7684\u63d0\u5347\u4e0d\u4ec5\u4ec5\u662f\u6a21\u578b\u96c6\u6210\u7684\u526f\u4ea7\u54c1\uff0c\u56e0\u4e3a\u7ec4\u5408\u4e0d\u540c\u7248\u672c\u7684Fast R-CNN\u51e0\u4e4e\u6ca1\u6709\u4ec0\u4e48\u6539\u8fdb\u3002\u76f8\u53cd\uff0c\u6b63\u662f\u56e0\u4e3a \\(YOLO\\) \u5728\u6d4b\u8bd5\u65f6\u51fa\u73b0\u4e86\u5404\u79cd\u5404\u6837\u7684\u8bef\u5dee\uff0c\u6240\u4ee5\u5728\u63d0\u9ad8 \\(Fast \\ R-CNN\\) \u7684\u6027\u80fd\u65b9\u9762\u975e\u5e38\u6709\u6548\u3002 \u2003\u9057\u61be\u7684\u662f\uff0c\u8fd9\u4e2a\u7ec4\u5408\u5e76\u6ca1\u6709\u4ece \\(YOLO\\) \u7684\u901f\u5ea6\u4e2d\u53d7\u76ca\uff0c\u56e0\u4e3a\u6211\u4eec\u5206\u522b\u8fd0\u884c\u6bcf\u4e2a\u6a21\u578b\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u7ec4\u5408\u8d77\u6765\u3002\u4f46\u662f\uff0c\u7531\u4e8e \\(YOLO\\) \u901f\u5ea6\u5982\u6b64\u4e4b\u5feb\uff0c\u4e0e \\(Fast \\ R-CNN\\) \u76f8\u6bd4\uff0c\u4e0d\u4f1a\u663e\u8457\u7684\u589e\u52a0\u4efb\u4f55\u8ba1\u7b97\u65f6\u95f4\u3002","title":"4.3 \u7ed3\u5408 \\(Fast \\ R-CNN\\) \u548c \\(YOLO\\)"},{"location":"thesis_interpretation/01_yolo.html#44-voc-2012","text":"\u5728 \\(VOC \\ 2012\\) \u6d4b\u8bd5\u96c6\u4e0a\uff0c \\(YOLO\\) \u83b7\u5f97\u4e8657.9% \u7684 \\(mAP\\) \u3002\u8fd9\u4f4e\u4e8e\u73b0\u6709\u7684\u6700\u597d\u6280\u672f\uff0c\u5982\u88683\u6240\u793a\u5176\u63a5\u8fd1\u4e8e\u4f7f\u7528VGG-16\u7684\u539f\u59cbR-CNN\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u4e0e\u5176\u6700\u63a5\u8fd1\u7684\u7ade\u4e89\u5bf9\u624b\u76f8\u6bd4\uff0c\u9700\u8981\u6539\u5584\u5728\u5c0f\u76ee\u6807\u4e0a\u7684\u68c0\u6d4b\u3002\u5728\u6c34\u74f6\u3001\u7ef5\u7f8a\u548c\u7535\u89c6/\u663e\u793a\u5668\u7b49\u7c7b\u522b\u4e0a\uff0cYOLO\u7684\u5f97\u5206\u6bd4R-CNN\u6216Feature Edit\u4f4e8\u221210%\u3002\u7136\u800c\uff0c\u5728\u732b\u548c\u706b\u8f66\u7b49\u5176\u5b83\u7c7b\u522b\u4e0aYOLO\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u3002 \u2003\u6211\u4eec\u8054\u5408\u7684 \\(Fast \\ R-CNN+YOLO\\) \u6a21\u578b\u662f\u6027\u80fd\u6700\u9ad8\u7684\u68c0\u6d4b\u65b9\u6cd5\u4e4b\u4e00\u3002 \\(Fast \\ R-CNN\\) \u548c \\(YOLO\\) \u7684\u7ec4\u5408\u4e2d\u83b7\u5f97\u4e862.3%\u7684\u63d0\u9ad8\uff0c\u5728\u516c\u5f00\u6392\u884c\u699c\u4e0a\u63d0\u5347\u4e865\u4e2a\u540d\u6b21\u3002","title":"4.4 VOC 2012\u6761\u7ed3\u679c"},{"location":"thesis_interpretation/01_yolo.html#45","text":"\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u672f\u6570\u636e\u96c6\u4ee5\u76f8\u540c\u5206\u5e03\u83b7\u53d6\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u3002\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u4e2d\uff0c\u5f88\u96be\u9884\u6d4b\u6240\u6709\u53ef\u80fd\u7684\u6837\u672c\uff0c\u800c\u4e14\u6d4b\u8bd5\u6570\u636e\u53ef\u80fd\u4e0e\u7cfb\u7edf\u4e4b\u524d\u770b\u5230\u7684\u4e0d\u540c[3]\u3002( \u56e0\u4e3a\u6d4b\u8bd5\u6570\u636e\u4e0e\u6a21\u578b\u8bad\u7ec3\u7684\u6570\u636e\u53ef\u80fd\u5728\u98ce\u683c\u3001\u6a21\u5f0f\u3001\u76ee\u6807\u8868\u73b0\u5f62\u5f0f\u7b49\u65b9\u9762\u6709\u5f88\u5927\u7684\u533a\u522b\uff0c\u4f8b\u5982\u6a21\u578b\u8bad\u7ec3\u65f6\u7684\u6570\u636e\u662f\u7528\u76f8\u673a\u62cd\u6444\u7684\u56fe\u50cf\uff0c\u800c\u6d4b\u8bd5\u65f6\u7528\u6cb9\u753b\u4f5c\u54c1\u56fe\u50cf\uff0c\u6b64\u65f6\u7531\u4e8e\u6cb9\u753b\u4f5c\u54c1\u6bd4\u8f83\u62bd\u8c61\uff0c\u6a21\u578b\u5c31\u53ef\u80fd\u65e0\u6cd5\u5f88\u597d\u5730\u8bc6\u522b\u5176\u4e2d\u7684\u76ee\u6807 ) \u6211\u4eec\u5728 \\(Picasso\\) \u6570\u636e\u96c6\u4e0a[12]\u548c \\(People-Art\\) \u6570\u636e\u96c6[3]\u4e0a\u5c06 \\(YOLO\\) \u4e0e\u5176\u5b83\u7684\u68c0\u6d4b\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\uff0c\u4e24\u4e2a\u6570\u636e\u96c6\u7528\u4e8e\u827a\u672f\u54c1\u4e0a\u7684\u4eba\u7269\u68c0\u6d4b\u3002 \u2003\u56fe5\u6240\u793a\u4e3a \\(YOLO\\) \u548c\u5176\u5b83\u68c0\u6d4b\u65b9\u6cd5\u4e4b\u95f4\u6027\u80fd\u6bd4\u8f83\u7684\u7ed3\u679c\u3002\u4f5c\u4e3a\u53c2\u8003\uff0c\u6211\u4eec\u5728person\u4e0a\u63d0\u4f9b \\(VOC \\ 2007\\) \u7684\u68c0\u6d4b \\(AP\\) \uff0c\u5176\u4e2d\u6240\u6709\u6a21\u578b\u4ec5\u5728 \\(VOC \\ 2007\\) \u6570\u636e\u4e0a\u8bad\u7ec3\u3002\u5728Picasso\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u7684\u6a21\u578b\u4f7f\u7528 \\(VOC \\ 2012\\) \u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u800c \\(People-Art\\) \u6570\u636e\u96c6\u6d4b\u8bd5\u7684\u6a21\u578b\u4f7f\u7528 \\(VOC \\ 2010\\) \u8fdb\u884c\u4e86\u8bad\u7ec3\u3002 \u2003 \\(R-CNN\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u7684 \\(AP\\) \u5f88\u9ad8\u3002\u4f46\u662f\u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u7cbe\u5ea6\u4e0b\u964d\u4e86\u5f88\u591a\u3002 \\(R-CNN\\) \u4f7f\u7528Selective Search\u6765\u751f\u6210\u5019\u9009\u8fb9\u754c\u6846\uff0c\u73b0\u5728\u6362\u4e3a\u81ea\u7136\u56fe\u7247\u3002\u5728\u5206\u7c7b\u65f6\u53ea\u80fd\u770b\u5230\u56fe\u7247\u7684\u4e00\u4e2a\u5c0f\u533a\u57df\uff0c\u9700\u8981\u8d28\u91cf\u5f88\u9ad8\u7684\u5019\u9009\u624d\u53ef\u4ee5\u3002 \u2003 \\(DPM\\) \u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u540e \\(AP\\) \u8fd8\u4fdd\u6301\u7684\u4e0d\u9519\u3002\u4e4b\u524d\u7684\u5de5\u4f5c\u7406\u8bba \\(DPM\\) \u8868\u73b0\u4e0d\u9519\u7684\u539f\u56e0\u662f\u5b83\u5bf9\u4e8e\u7269\u4f53\u7684\u5f62\u72b6\u548c\u5e03\u5c40\u6709\u5f88\u5f3a\u7684\u7a7a\u95f4\u6a21\u578b\u3002\u867d\u7136 \\(DPM\\) \u6ca1\u6709\u50cf \\(R-CNN\\) \u90a3\u6837\u7cbe\u5ea6\u4e0b\u964d\u5f88\u591a\uff0c\u4f46\u662f\u5b83\u7684 \\(AP\\) \u672c\u6765\u5c31\u6bd4\u8f83\u4f4e\u3002 \u2003 \\(YOLO\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u7684\u8868\u73b0\u4e0d\u9519\uff0c\u5f53\u5e94\u7528\u5230\u827a\u672f\u54c1\u4e0a\u65f6\u6bd4\u5176\u4ed6\u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\u7684\u5c11\u3002\u4e0e \\(DPM\\) \u7c7b\u4f3c\uff0c \\(YOLO\\) \u5bf9\u7269\u4f53\u7684\u5927\u5c0f\u548c\u5f62\u72b6\u8fdb\u884c\u5efa\u6a21\uff0c\u8fd8\u6709\u7269\u4f53\u548c\u7269\u4f53\u901a\u5e38\u51fa\u73b0\u7684\u4f4d\u7f6e\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u827a\u672f\u54c1\u548c\u81ea\u7136\u56fe\u7247\u5728\u50cf\u7d20\u7ea7\u522b\u4e0a\u5dee\u5f02\u5f88\u5927\uff0c\u4f46\u662f\u7269\u4f53\u7684\u5927\u5c0f\u548c\u5f62\u72b6\u662f\u7c7b\u4f3c\u7684\uff0c\u56e0\u6b64 \\(YOLO\\) \u4ecd\u7136\u53ef\u4ee5\u5f88\u597d\u7684\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u68c0\u6d4b\u7269\u4f53\u3002 \u56fe5\uff1aPicasso \u548c People-Art \u6570\u636e\u96c6\u7efc\u5408\u7684\u7ed3\u679c\u3002 (a): \u5728Picasso\u6570\u636e\u96c6\u4e0a\u7684PR\u66f2\u7ebf\u3002 (b): \u5728 VOC 2007, Picasso, \u548c People-Art \u7684\u7ed3\u679c\u6570\u636e\u3002Picasso \u6570\u636e\u96c6\u8bc4\u4f30AP\u548c\u6700\u4f73 \\(F_1\\) \u5206\u6570\u3002 \u56fe6\uff1a\u68c0\u6d4b\u7684\u7ed3\u679c\u3002 \\(YOLO\\) \u8fd0\u884c\u7684\u6837\u672c\u827a\u672f\u4f5c\u54c1 \u548c \u6765\u81ea\u4e92\u8054\u7f51\u7684\u81ea\u7136\u56fe\u50cf\u3002\u867d\u7136\u5b83\u786e\u5b9e\u8ba4\u4e3a\u4e00\u4e2a\u4eba\u662f\u4e00\u67b6\u98de\u673a\uff0c\u4f46\u5b83\u57fa\u672c\u4e0a\u662f\u51c6\u786e\u7684\u3002","title":"4.5 \u6cdb\u5316\u80fd\u529b\uff1a\u827a\u672f\u54c1\u4e2d\u7684\u4eba\u7269\u68c0\u6d4b"},{"location":"thesis_interpretation/01_yolo.html#5","text":"\\(YOLO\\) \u662f\u4e00\u79cd\u5feb\u901f\u3001\u7cbe\u786e\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u975e\u5e38\u9002\u5408\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u3002\u6211\u4eec\u5c06 \\(YOLO\\) \u8fde\u63a5\u5230\u7f51\u7edc\u6444\u50cf\u5934\uff0c\u5e76\u9a8c\u8bc1\u5b83\u662f\u5426\u80fd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\uff0c\u5305\u62ec\u4ece\u6444\u50cf\u5934\u83b7\u53d6\u56fe\u50cf\u5e76\u663e\u793a\u68c0\u6d4b\u7ed3\u679c\u7684\u65f6\u95f4\u3002 \u2003\u6700\u7ec8\u7684\u7cfb\u7edf\u662f\u4ea4\u4e92\u5f0f\u7684\u5e76\u4e14\u662f\u53c2\u4e0e\u5f0f\u7684\u3002\u867d\u7136 \\(YOLO\\) \u5355\u72ec\u5730\u5904\u7406\u56fe\u50cf\uff0c\u4f46\u5f53\u8fde\u63a5\u5230\u7f51\u7edc\u6444\u50cf\u5934\u65f6\uff0c\u5176\u529f\u80fd\u7c7b\u4f3c\u4e8e\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u53ef\u5728\u76ee\u6807\u79fb\u52a8\u548c\u5916\u89c2\u53d8\u5316\u65f6\u68c0\u6d4b\u76ee\u6807\u3002\u7cfb\u7edf\u6f14\u793a\u548c\u6e90\u4ee3\u7801\u53ef\u4ee5\u5728\u6211\u4eec\u7684\u9879\u76ee\u7f51\u7ad9\u4e0a\u627e\u5230\uff1ahttp://pjreddie.com/yolo/\u3002","title":"5.\u91ce\u5916\u5b9e\u65f6\u68c0\u6d4b"},{"location":"thesis_interpretation/01_yolo.html#6","text":"\u6211\u4eec\u4ecb\u7ecd\u4e86 \\(YOLO\\) \uff0c\u4e00\u79cd\u7edf\u4e00\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u3002\u6211\u4eec\u7684\u6a21\u578b\u6784\u5efa\u7b80\u5355\uff0c\u53ef\u4ee5\u76f4\u63a5\u5728\u6574\u5f20\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u4e0e\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c \\(YOLO\\) \u76f4\u63a5\u5728\u5bf9\u5e94\u68c0\u6d4b\u6027\u80fd\u7684\u635f\u5931\u51fd\u6570\u4e0a\u8bad\u7ec3\uff0c\u5e76\u4e14\u6574\u4e2a\u6a21\u578b\u7edf\u4e00\u8bad\u7ec3\u3002 \\(Fast \\ YOLO\\) \u662f\u6587\u732e\u4e2d\u6700\u5feb\u7684\u901a\u7528\u76ee\u7684\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c \\(YOLO\\) \u63a8\u52a8\u4e86\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7684\u6700\u65b0\u6280\u672f\u3002 \\(YOLO\\) \u8fd8\u5f88\u597d\u5730\u6cdb\u5316\u5230\u65b0\u9886\u57df\uff0c\u4f7f\u5176\u6210\u4e3a\u8981\u6c42\u5feb\u901f\u3001\u5f3a\u5927\u76ee\u6807\u68c0\u6d4b\u5e94\u7528\u7684\u7406\u60f3\u9009\u62e9\u3002 Acknowledgements : This work is partially supported by ONR N00014-13-1-0720, NSF IIS-1338054, and The Allen Distinguished Investigator Award.","title":"6.\u603b\u7ed3"},{"location":"thesis_interpretation/01_yolo.html#references","text":"[1] M. B. Blaschko and C. H. Lampert. Learning to localize objects with structured output regression. In Computer Vision\u2013ECCV 2008, pages 2\u201315. Springer, 2008. 4 [2] L. Bourdev and J. Malik. Poselets: Body part detectors trained using 3d human pose annotations. In International Conference on Computer Vision (ICCV), 2009. 8 [3] H. Cai, Q. Wu, T. Corradi, and P. Hall. The cross-depiction problem: Computer vision algorithms for recognising objects in artwork and in photographs. arXiv preprint arXiv:1505.00110, 2015. 7 [4] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conferenceon, volume 1, pages 886\u2013893. IEEE, 2005. 4, 8 [5] T. Dean, M. Ruzon, M. Segal, J. Shlens, S. Vijayanarasimhan, J. Yagnik, et al. Fast, accurate detection of 100,000 object classes on a single machine. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pages 1814\u20131821. IEEE, 2013. 5 [6] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. arXiv preprint arXiv:1310.1531, 2013. 4 [7] J. Dong, Q. Chen, S. Yan, and A. Yuille. Towards unified object detection and semantic segmentation. In Computer Vision\u2013ECCV 2014, pages 299\u2013314. Springer, 2014. 7 [8] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov. Scalable object detection using deep neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2155\u20132162. IEEE, 2014. 5, 6 [9] M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The pascal visual object classes challenge: A retrospective. International Journal of Computer Vision, 111(1):98\u2013136, Jan. 2015. 2 [10] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9):1627\u20131645, 2010. 1, 4 [11] S. Gidaris and N. Komodakis. Object detection via a multiregion & semantic segmentation-aware CNN model. CoRR, abs/1505.01749, 2015. 7 [12] S. Ginosar, D. Haas, T. Brown, and J. Malik. Detecting people in cubist art. In Computer Vision-ECCV 2014 Workshops, pages 101\u2013116. Springer, 2014. 7 [13] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 580\u2013587. IEEE, 2014. 1, 4, 7 [14] R. B. Girshick. Fast R-CNN. CoRR, abs/1504.08083, 2015. 2, 5, 6, 7 [15] S. Gould, T. Gao, and D. Koller. Region-based segmentation and object detection. In Advances in neural information processing systems, pages 655\u2013663, 2009. 4 [16] B. Hariharan, P. Arbel\u00e1ez, R. Girshick, and J. Malik. Simultaneous detection and segmentation. In Computer Vision\u2013ECCV 2014, pages 297\u2013312. Springer, 2014. 7 [17] K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling in deep convolutional networks for visual recognition. arXiv preprint arXiv:1406.4729, 2014. 5 [18] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580, 2012. 4 [19] D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error in object detectors. In Computer Vision\u2013ECCV 2012, pages 340\u2013353. Springer, 2012. 6 [20] K. Lenc and A. Vedaldi. R-cnn minus r. arXiv preprint arXiv:1506.06981, 2015. 5, 6 [21] R. Lienhart and J. Maydt. An extended set of haar-like features for rapid object detection. In Image Processing. 2002. Proceedings. 2002 International Conference on, volume 1, pages I\u2013900. IEEE, 2002. 4 [22] M. Lin, Q. Chen, and S. Yan. Network in network. CoRR, abs/1312.4400, 2013. 2 [23] D. G. Lowe. Object recognition from local scale-invariant features. In Computer vision, 1999. The proceedings of the seventh IEEE international conference on, volume 2, pages 1150\u20131157. Ieee, 1999. 4 [24] D. Mishkin. Models accuracy on imagenet 2012 val. https://github.com/BVLC/caffe/wiki/Models-accuracy-on-ImageNet-2012-val. Ac-cessed: 2015-10-2. 3 [25] C. P. Papageorgiou, M. Oren, and T. Poggio. A general framework for object detection. In Computer vision, 1998. sixth international conference on, pages 555\u2013562. IEEE,1998. 4 [26] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 3 [27] J. Redmon and A. Angelova. Real-time grasp detection using convolutional neural networks. CoRR, abs/1412.3128, 2014.5 [28] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497, 2015. 5, 6, 7 [29] S. Ren, K. He, R. B. Girshick, X. Zhang, and J. Sun. Object detection networks on convolutional feature maps. CoRR, abs/1504.06066, 2015. 3, 7 [30] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. 3 [31] M. A. Sadeghi and D. Forsyth. 30hz object detection with dpm v5. In Computer Vision\u2013ECCV 2014, pages 65\u201379. Springer, 2014. 5, 6 [32] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. LeCun. Overfeat: Integrated recognition, localization and detection using convolutional networks. CoRR, abs/1312.6229, 2013. 4, 5- [33] Z. Shen and X. Xue. Do more dropouts in pool5 feature maps for better object detection. arXiv preprint arXiv:1409.6911, 2014. 7 [34] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. CoRR, abs/1409.4842, 2014. 2 [35] J. R. Uijlings, K. E. van de Sande, T. Gevers, and A. W. Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154\u2013171, 2013. 4, 5 [36] P. Viola and M. Jones. Robust real-time object detection. International Journal of Computer Vision, 4:34\u201347, 2001. 4 [37] P. Viola and M. J. Jones. Robust real-time face detection. International journal of computer vision, 57(2):137\u2013154, 2004. 5 [38] J. Yan, Z. Lei, L. Wen, and S. Z. Li. The fastest deformable part model for object detection. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 2497\u20132504. IEEE, 2014. 5, 6 [39] C. L. Zitnick and P. Doll\u00e1r. Edge boxes: Locating object proposals from edges. In Computer Vision\u2013ECCV 2014, pages 391\u2013405. Springer, 2014. 4","title":"References"},{"location":"thesis_interpretation/02_yolo.html","text":"\u672c\u6587\u7ffb\u8bd1\u81ea: https://arxiv.org/pdf/1612.08242.pdf \\(YOLO9000\\) : Better, Faster, Stronger Joseph Redmon\u2217\u2020, Ali Farhadi\u2217\u2020 University of Washington\u2217, Allen Institute for AI\u2020 http://pjreddie.com/yolo9000/ \u6458\u8981 \u2003\u6211\u4eec\u63a8\u51fa\u7684 \\(YOLO9000\\) \u662f\u4e00\u6b3e\u5148\u8fdb\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7cfb\u7edf\uff0c\u53ef\u68c0\u6d4b9000\u591a\u79cd\u76ee\u6807\u7c7b\u522b\u3002\u9996\u5148\uff0c\u6211\u4eec\u63d0\u51fa\u5bf9 \\(YOLO\\) \u68c0\u6d4b\u65b9\u6cd5\u7684\u5404\u79cd\u6539\u8fdb\uff0c\u8fd9\u4e9b\u6539\u8fdb\u6709\u72ec\u521b\u7684\uff0c\u4e5f\u6709\u7684\u662f\u6765\u6e90\u4e8e\u4ee5\u524d\u7684\u7814\u7a76\u3002\u6539\u8fdb\u540e\u7684\u6a21\u578b \\(YOLOv2\\) \u5728 \\(PASCAL VOC\\) \u548c \\(COCO\\) \u7b49\u6807\u51c6\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5904\u4e8e\u6280\u672f\u9886\u5148\u5730\u4f4d\u3002\u901a\u8fc7\u4f7f\u7528\u4e00\u79cd\u65b0\u9896\u7684\u591a\u5c3a\u5ea6\u8bad\u7ec3\u65b9\u6cd5\uff0c\u540c\u6837\u7684 \\(YOLOv2\\) \u6a21\u578b\u53ef\u4ee5\u4ee5\u4e0d\u540c\u7684\u5c3a\u5bf8\u8fd0\u884c\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u6298\u8877\u3002\u5728 \\(67 FPS\\) \u65f6\uff0c \\(YOLOv2\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u83b7\u5f97\u4e8676.8 \\(mAP\\) \u3002\u5728 \\(40FPS\\) \u65f6\uff0c \\(YOLOv2\\) \u83b7\u5f97\u4e8678.6 \\(mAP\\) \uff0c\u8d85\u8d8a\u4e86\u91c7\u7528 \\(ResNet\\) \u548c \\(SSD\u7684Faster \\ R-CNN\\) \u7b49\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u8fd0\u884c\u901f\u5ea6\u4ecd\u7136\u66f4\u5feb\u3002\u6700\u540e\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u8054\u5408\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u548c\u5206\u7c7b\u7684\u65b9\u6cd5\u3002\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u5728 \\(COCO\\) \u68c0\u6d4b\u6570\u636e\u96c6\u548c \\(ImageNet\\) \u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u540c\u65f6\u8bad\u7ec3 \\(YOLO9000\\) \u3002\u6211\u4eec\u7684\u8054\u5408\u8bad\u7ec3\u4f7f \\(YOLO9000\\) \u80fd\u591f\u9884\u6d4b\u672a\u6807\u6ce8\u68c0\u6d4b\u6570\u636e\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u5e76\u4e14\u6211\u4eec\u5728 \\(ImageNet\\) \u68c0\u6d4b\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u3002 \\(YOLO9000\\) \u5728 \\(ImageNet\\) \u68c0\u6d4b\u9a8c\u8bc1\u96c6\u4e0a\u83b7\u5f9719.7 \\(mAP\\) \uff0c\u5c3d\u7ba1200\u4e2a\u7c7b\u4e2d\u53ea\u670944\u4e2a\u5177\u6709\u68c0\u6d4b\u6570\u636e\u3002\u5728 \\(COCO\\) \u4e0a\u6ca1\u6709\u7684156\u79cd\u7c7b\u4e0a\uff0c \\(YOLO9000\\) \u5f97\u5230 16.0 \\(mAP\\) \uff0c\u4f46\u662f \\(YOLO\\) \u53ef\u4ee5\u68c0\u6d4b\u8d85\u8fc7200\u4e2a\u79cd\u7c7b;\u5b83\u9884\u6d4b\u8d85\u8fc79000 \u591a\u79cd\u4e0d\u540c\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u800c\u4e14\u5b83\u4ecd\u7136\u662f\u5b9e\u65f6\u8fd0\u884c\u7684\u3002 \u56fe1: \\(YOLO9000\\) \u3002 \\(YOLO9000\\) \u53ef\u4ee5\u5b9e\u65f6\u68c0\u6d4b\u5404\u79cd\u5404\u6837\u7684\u76ee\u6807\u7c7b\u522b\u3002 1.\u5f15\u8a00 \u2003\u901a\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u5e94\u8be5\u5feb\u901f\uff0c\u51c6\u786e\uff0c\u5e76\u4e14\u80fd\u591f\u8bc6\u522b\u5404\u79cd\u5404\u6837\u7684\u76ee\u6807\u3002\u81ea\u4ece\u5f15\u5165\u795e\u7ecf\u7f51\u7edc\uff0c\u68c0\u6d4b\u6846\u67b6\u53d8\u5f97\u8d8a\u6765\u8d8a\u5feb\u901f\u548c\u51c6\u786e\u3002\u4f46\u662f\uff0c\u5927\u591a\u6570\u68c0\u6d4b\u65b9\u6cd5\u4ec5\u9650\u4e8e\u68c0\u6d4b\u4e00\u5c0f\u90e8\u5206\u76ee\u6807\u3002 \u2003\u4e0e\u5206\u7c7b\u548c\u6807\u8bb0\u7b49\u5176\u4ed6\u4efb\u52a1\u7684\u6570\u636e\u96c6\u76f8\u6bd4\uff0c\u76ee\u524d\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u662f\u6709\u9650\u7684\u3002\u6700\u5e38\u89c1\u7684\u68c0\u6d4b\u6570\u636e\u96c6\u5305\u542b\u6210\u5343\u4e0a\u4e07\u5230\u6570\u5341\u4e07\u5f20\u5177\u6709\u6210\u767e\u4e0a\u5343\u4e2a\u6807\u7b7e\u7684\u56fe\u50cf[3][10][2]\u3002\u800c\u5206\u7c7b\u6570\u636e\u96c6\u6709\u6570\u4ee5\u767e\u4e07\u8ba1\u7684\u56fe\u50cf\uff0c\u6570\u5341\u6216\u6570\u767e\u4e07\u4e2a\u7c7b\u522b[20][2]\u3002 \u2003\u6211\u4eec\u5e0c\u671b\u68c0\u6d4b\u7684\u7c7b\u522b\u80fd\u591f\u6269\u5c55\u5230\u76ee\u6807\u5206\u7c7b\u7684\u7ea7\u522b\u3002\u4f46\u662f\uff0c\u6807\u6ce8\u68c0\u6d4b\u56fe\u50cf\u8981\u6bd4\u6807\u6ce8\u5206\u7c7b\u6216\u8d34\u6807\u7b7e\u8981\u6602\u8d35\u5f97\u591a\uff08 \u6807\u7b7e\u901a\u5e38\u662f\u7528\u6237\u514d\u8d39\u63d0\u4f9b ) \u3002\u56e0\u6b64\uff0c\u6211\u4eec\u4e0d\u592a\u53ef\u80fd\u5728\u8fd1\u671f\u5185\u770b\u5230\u4e0e\u5206\u7c7b\u6570\u636e\u96c6\u76f8\u540c\u89c4\u6a21\u7684\u68c0\u6d4b\u6570\u636e\u96c6\u3002 \u2003\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u2014\u2014\u901a\u8fc7\u5229\u7528\u6211\u4eec\u5df2\u6709\u7684\u5927\u91cf\u5206\u7c7b\u6570\u636e\u6765\u6269\u5927\u5f53\u524d\u68c0\u6d4b\u7cfb\u7edf\u7684\u8303\u56f4\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u76ee\u6807\u5206\u7c7b\u7684\u5206\u5c42\u89c6\u56fe\uff0c\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u5c06\u4e0d\u540c\u7684\u6570\u636e\u96c6\u7ec4\u5408\u5728\u4e00\u8d77\u3002 \u2003\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5b83\u5141\u8bb8\u6211\u4eec\u5728\u68c0\u6d4b\u548c\u5206\u7c7b\u6570\u636e\u4e0a\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u5668\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u6807\u8bb0\u68c0\u6d4b\u56fe\u50cf\u6765\u5b66\u4e60\u7cbe\u786e\u5b9a\u4f4d\u76ee\u6807\uff0c\u540c\u65f6\u4f7f\u7528\u5206\u7c7b\u56fe\u50cf\u6765\u589e\u52a0\u8bcd\u6c47\u91cf\u548c\u9c81\u68d2\u6027\u3002 \u2003\u6211\u4eec\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8bad\u7ec3 \\(YOLO9000\\) b\u4e00\u79cd\u53ef\u4ee5\u68c0\u6d4b\u8d85\u8fc79000\u79cd\u4e0d\u540c\u7684\u76ee\u6807\u7c7b\u522b\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u3002 \u9996\u5148\uff0c\u6211\u4eec\u6539\u8fdbYOLO\u57fa\u7840\u68c0\u6d4b\u7cfb\u7edf\uff0c\u751f\u6210\u6700\u5148\u8fdb\u7684\u5b9e\u65f6\u68c0\u6d4b\u5668 \\(YOLOv2\\) \u3002 \u7136\u540e\uff0c\u91c7\u7528\u6211\u4eec\u7684\u6570\u636e\u96c6\u7ec4\u5408\u65b9\u6cd5\u548c\u8054\u5408\u8bad\u7ec3\u7b97\u6cd5\uff0c\u4f7f\u7528\u6765\u81ea \\(ImageNet\\) \u76849000\u591a\u4e2a\u7c7b\u4ee5\u53ca \\(COCO\\) \u7684\u68c0\u6d4b\u6570\u636e\u6765\u8bad\u7ec3\u6a21\u578b\u3002 \u6211\u4eec\u6240\u6709\u4ee3\u7801\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u90fd\u53ef\u5728\u7ebf\u83b7\u5f97\uff1ahttp://pjreddie.com/yolo9000/\u3002 2.\u66f4\u597d \u2003\u4e0e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\uff0c \\(YOLO\\) \u5b58\u5728\u5404\u79cd\u7f3a\u70b9\u3002 \\(YOLO\\) \u4e0e \\(Fast \\ R-CNN\\) \u7684\u8bef\u5dee\u6bd4\u8f83\u5206\u6790\u8868\u660e\uff0c \\(YOLO\\) \u4ea7\u751f\u4e86\u5927\u91cf\u7684\u5b9a\u4f4d\u9519\u8bef\u3002\u6b64\u5916\uff0c\u4e0e\u751f\u6210\u5019\u9009\u533a\u57df\u65b9\u6cd5\u76f8\u6bd4\uff0c \\(YOLO\\) \u53ec\u56de\u7387( recall )\u76f8\u5bf9\u8f83\u4f4e\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u4e3b\u8981\u5173\u6ce8\u6539\u5584\u53ec\u56de\u7387\u548c\u5b9a\u4f4d\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u7c7b\u51c6\u786e\u6027\u3002 \u2003\u8ba1\u7b97\u673a\u89c6\u89c9\u901a\u5e38\u8d8b\u5411\u4e8e\u66f4\u5927\u66f4\u6df1\u7684\u7f51\u7edc[6] [18] [17]\u3002 \u66f4\u597d\u7684\u6027\u80fd\u901a\u5e38\u53d6\u51b3\u4e8e\u8bad\u7ec3\u66f4\u5927\u7684\u7f51\u7edc\u6216\u5c06\u591a\u4e2a\u6a21\u578b\u7ec4\u5408\u5728\u4e00\u8d77\u3002 \u4f46\u662f\uff0c\u5bf9\u4e8e \\(YOLOv2\\) \uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u66f4\u7cbe\u786e\u7684\u68c0\u6d4b\u5668\uff0c\u800c\u4e14\u4fdd\u6301\u5f88\u5feb\u7684\u901f\u5ea6\u3002 \u6211\u4eec\u4e0d\u662f\u8981\u6269\u5927\u7f51\u7edc\uff0c\u800c\u662f\u7b80\u5316\u7f51\u7edc\uff0c\u7136\u540e\u8ba9\u8868\u5f81( \u5373\u76ee\u6807\u7279\u5f81 )\u66f4\u6613\u4e8e\u5b66\u4e60\u3002 \u6211\u4eec\u5c06\u4ee5\u5f80\u5de5\u4f5c\u4e2d\u7684\u5404\u79cd\u521b\u610f\u4e0e\u6211\u4eec\u81ea\u5df1\u65b0\u9896\u7684\u65b9\u6cd5\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u63d0\u9ad8 \\(YOLO\\) \u7684\u6027\u80fd\u3002 \u7ed3\u679c\u6c47\u603b\u89c1 \u88682\u3002 \u2003 \u6279\u91cf\u6807\u51c6\u5316 \uff08Batch Normalization\uff09\u3002\u6279\u91cf\u6807\u51c6\u5316\u53ef\u4ee5\u663e\u7740\u6539\u5584\u6536\u655b\u6027\uff0c\u800c\u4e14\u4e0d\u518d\u9700\u8981\u5176\u4ed6\u5f62\u5f0f\u7684\u6b63\u5219\u5316[7]\u3002 \u901a\u8fc7\u5728 \\(YOLO\\) \u4e2d\u7684\u6240\u6709\u5377\u79ef\u5c42\u4e0a\u6dfb\u52a0\u6279\u91cf\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u5728 \\(mAP\\) \u4e2d\u83b7\u5f97 2\uff05\u4ee5\u4e0a\u7684\u6539\u8fdb\u3002 \u6279\u91cf\u6807\u51c6\u5316\u4e5f\u6709\u52a9\u4e8e\u89c4\u8303\u6a21\u578b\u3002 \u901a\u8fc7\u6279\u91cf\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u4ece\u6a21\u578b\u4e2d\u5220\u9664 \\(dropout\\) \u800c\u4e0d\u4f1a\u53d1\u751f\u8fc7\u62df\u5408\u3002 \u2003 \u9ad8\u5206\u8fa8\u7387\u5206\u7c7b\u5668 \uff08High Resolution Classifier\uff09\u3002\u6240\u6709\u7684\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u65b9\u6cd5\u90fd\u4f7f\u7528\u5728 \\(ImageNet\\) \u4e0a\u9884\u5148\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668[16]\u3002 \u4eceAlexNet\u5f00\u59cb\uff0c\u5927\u591a\u6570\u5206\u7c7b\u5668\u7528\u5c0f\u4e8e \\(256\u00d7256\\) \u7684\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165[8]\u3002 \u6700\u521d\u7684 \\(YOLO\\) \u4ee5 \\(224\u00d7224\\) \u7684\u56fe\u50cf\u8bad\u7ec3\u5206\u7c7b\u5668\u7f51\u7edc\uff0c\u5e76\u5c06\u5206\u8fa8\u7387\u63d0\u9ad8\u5230 \\(448\\) \u4ee5\u8fdb\u884c\u68c0\u6d4b\u8bad\u7ec3\u3002 \u8fd9\u610f\u5473\u7740\u7f51\u7edc\u5fc5\u987b\u5207\u6362\u5230\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u4e60\uff0c\u540c\u65f6\u80fd\u8c03\u6574\u5230\u65b0\u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002 \u2003\u5bf9\u4e8e \\(YOLOv2\\) \uff0c\u6211\u4eec\u9996\u5148\u4ee5 \\(448\u00d7448\\) \u7684\u5168\u5206\u8fa8\u7387\u5728 \\(ImageNet\\) \u4e0a\u8fdb\u884c \\(10\\) \u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u5fae\u8c03\u3002\u8fd9\u7ed9\u4e88\u7f51\u7edc\u4e00\u4e9b\u65f6\u95f4\uff0c\u4ee5\u8c03\u6574\u5176\u6ee4\u6ce2\u5668\u6765\u66f4\u597d\u5730\u5904\u7406\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8f93\u5165\u3002\u7136\u540e\uff0c\u6211\u4eec\u518d\u5bf9\u8be5\u68c0\u6d4b\u7f51\u7edc\u8fdb\u884c\u5fae\u8c03\u3002 \u8fd9\u4e2a\u9ad8\u5206\u8fa8\u7387\u7684\u5206\u7c7b\u7f51\u7edc\u4f7f \\(mAP\\) \u589e\u52a0\u4e86\u8fd14\uff05\u3002 \u2003 \u5377\u79ef\u4e0e\u951a\u6846 \u3002 \\(YOLO\\) \u76f4\u63a5\u4f7f\u7528\u5377\u79ef\u7279\u5f81\u63d0\u53d6\u5668\u9876\u90e8\u7684\u5168\u8fde\u63a5\u5c42\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u7684\u5750\u6807\u3002\u800c \\(Fast \\ R-CNN\\) \u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5750\u6807\uff0c\u662f\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684\u5148\u9a8c\u6765\u9884\u6d4b\u8fb9\u754c\u6846[15]\u3002\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5750\u6807 \\(Fast \\ R-CNN\\) \u9884\u6d4b\u8fb9\u754c\u6846\u4f7f\u7528\u624b\u5de5\u6311\u9009\u7684\u5148\u9a8c\u533a\u57df[15]\u3002 Faster R-CNN\u4e2d\u7684\u5019\u9009\u533a\u57df\u751f\u6210\u7f51\u7edc\uff08RPN\uff09\u4ec5\u4f7f\u7528\u5377\u79ef\u5c42\u6765\u9884\u6d4b\u951a\u6846\u7684\u504f\u79fb\u548c\u7f6e\u4fe1\u5ea6\u3002\u7531\u4e8e\u9884\u6d4b\u5c42\u662f\u5377\u79ef\u7684\uff0c\u6240\u4ee5RPN\u53ef\u4ee5\u5728\u7279\u5f81\u56fe\u4e2d\u7684\u6bcf\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u8fd9\u4e9b\u504f\u79fb\u3002\u4f7f\u7528\u9884\u6d4b\u504f\u79fb\u4ee3\u66ff\u5750\u6807\uff0c\u53ef\u4ee5\u7b80\u5316\u95ee\u9898\u5e76\u4f7f\u7f51\u7edc\u66f4\u6613\u4e8e\u5b66\u4e60\u3002 \u2003\u6211\u4eec\u4ece \\(YOLO\\) \u4e2d\u79fb\u9664\u5168\u8fde\u63a5\u5c42\uff0c\u5e76\u4f7f\u7528\u951a\u6846\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u3002 \u9996\u5148\u6211\u4eec\u6d88\u9664\u4e00\u4e2a\u6c60\u5316\u5c42\uff0c\u4ee5\u4f7f\u7f51\u7edc\u5377\u79ef\u5c42\u7684\u8f93\u51fa\u5177\u6709\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u3002 \u6211\u4eec\u8fd8\u7f29\u5c0f\u7f51\u7edc\uff0c\u4f7f\u5176\u5728\u5206\u8fa8\u7387\u4e3a \\(416X416\\) \u7684\u8f93\u5165\u56fe\u50cf\u4e0a\u8fd0\u884c\uff0c\u800c\u4e0d\u662f \\(448\u00d7448\\) \u3002\u6211\u4eec\u8fd9\u6837\u505a\u662f\u56e0\u4e3a\u6211\u4eec\u60f3\u8981\u5728\u7279\u5f81\u56fe\u4e2d\u6709\u5947\u6570\u4e2a\u4f4d\u7f6e\uff0c\u4ece\u800c\u6709\u4e00\u4e2a\u5355\u4e00\u7684\u4e2d\u5fc3\u5355\u5143\u683c\u3002\u76ee\u6807\uff0c\u5c24\u5176\u662f\u5927\u7684\u76ee\u6807\uff0c\u5f80\u5f80\u5360\u636e\u56fe\u50cf\u7684\u4e2d\u5fc3\uff0c\u6240\u4ee5\u6700\u597d\u5728\u6b63\u4e2d\u5fc3\u62e5\u6709\u5355\u72ec\u4e00\u4e2a\u4f4d\u7f6e\u6765\u9884\u6d4b\u8fd9\u4e9b\u76ee\u6807\uff0c\u800c\u4e0d\u662f\u5728\u4e2d\u5fc3\u9644\u8fd1\u7684\u56db\u4e2a\u4f4d\u7f6e\u3002 \\(YOLO\\) \u7684\u5377\u79ef\u5c42\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e86 \\(32\\) \u500d\u7684\u91c7\u6837\uff0c\u6240\u4ee5\u901a\u8fc7\u4f7f\u7528 \\(416\\) \u7684\u8f93\u5165\u56fe\u50cf\uff0c\u6211\u4eec\u5f97\u5230 \\(13\u00d713\\) \u7684\u8f93\u51fa\u7279\u5f81\u56fe\u3002 \u2003\u5f53\u6211\u4eec\u79fb\u52a8\u5230\u951a\u6846\u65f6\uff0c\u6211\u4eec\u5c06\u7c7b\u9884\u6d4b\u673a\u5236\u4e0e\u7a7a\u95f4\u4f4d\u7f6e\u5206\u5f00\u5904\u7406\uff0c\u5355\u72ec\u9884\u6d4b\u6bcf\u4e2a\u951a\u6846\u7684\u7c7b\u53ca\u5176\u76ee\u6807\u3002 \u9075\u5faa\u539f\u6765\u7684 \\(YOLO\\) \u7684\u505a\u6cd5\uff0c\u76ee\u6807\u9884\u6d4b\u4f9d\u7136\u9884\u6d4b\u4e86\u771f\u5b9e\u6807\u7b7e\u6846\uff08ground truth box\uff09\u548c\u5019\u9009\u6846\u7684 \\(IOU\\) \uff0c\u800c\u7c7b\u522b\u9884\u6d4b\u4e5f\u662f\u9884\u6d4b\u4e86\u5f53\u6709\u76ee\u6807\u5b58\u5728\u65f6\uff0c\u8be5\u7c7b\u522b\u7684\u6761\u4ef6\u6982\u7387\u3002 \u2003\u4f7f\u7528\u951a\u6846\uff0c\u7cbe\u5ea6\u503c\u4f1a\u5c0f\u5e45\u4e0b\u964d\u3002\u56e0\u4e3a\u539f\u59cb\u7684 \\(YOLO\\) \u4ec5\u4e3a\u6bcf\u4e2a\u56fe\u7247\u9884\u6d4b98\u4e2a\u6846\uff0c\u4f46\u4f7f\u7528\u951a\u6846\u540e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u9884\u6d4b\u7684\u6846\u6570\u8d85\u8fc7 1000 \u4e2a\u3002 \u5728\u6ca1\u6709\u951a\u6846\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u7684\u4e2d\u7b49\u6a21\u578b\u5c06\u83b7\u5f97 69.5 \u7684 \\(mAP\\) \uff0c\u53ec\u56de\u7387\u4e3a81\uff05\u3002 \u4f7f\u7528\u951a\u6846\u540e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u83b7\u5f97\u4e86 \\(69.2\\) \u7684 \\(mAP\\) \uff0c\u53ec\u56de\u7387\u4e3a88\uff05\u3002\u5c3d\u7ba1 \\(mAP\\) \u51cf\u5c11\uff0c\u4f46\u53ec\u56de\u7387\u7684\u589e\u52a0\u610f\u5473\u7740\u6211\u4eec\u7684\u6a21\u578b\u6709\u66f4\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002 \u56fe2\uff1a \\(VOC\\) \u548c \\(COCO\\) \u4e0a\u7684\u805a\u7c7b\u6846\u5c3a\u5bf8\u3002\u6211\u4eec\u5728\u8fb9\u754c\u6846\u7684\u7ef4\u4e0a\u8fd0\u884c \\(k-means\\) \u805a\u7c7b\uff0c\u4ee5\u83b7\u5f97\u6211\u4eec\u6a21\u578b\u7684\u826f\u597d\u5148\u9a8c\u3002\u5de6\u56fe\u663e\u793a\u4e86\u6211\u4eec\u901a\u8fc7k\u7684\u5404\u79cd\u9009\u62e9\u83b7\u5f97\u7684\u5e73\u5747 \\(IOU\\) \u3002\u6211\u4eec\u53d1\u73b0 \\(k = 5\\) \u4e3a\u53ec\u56de\u4e0e\u6a21\u578b\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6298\u4e2d\u3002\u53f3\u56fe\u663e\u793a\u4e86 \\(VOC\\) \u548c \\(COCO\\) \u7684\u76f8\u5bf9\u8d28\u5fc3\u3002\u8fd9\u4e24\u79cd\u65b9\u6848\u90fd\u559c\u6b22\u66f4\u8584\uff0c\u66f4\u9ad8\u7684\u6846\uff0c\u5e76\u4e14 \\(COCO\\) \u7684\u5c3a\u5bf8\u7684\u53d8\u5316\u6bd4 \\(VOC\\) \u66f4\u5927\u3002 \\(k-means\\) \u7b97\u6cd5: \\(K-means\\) \u7b97\u6cd5\u662f\u5f88\u5178\u578b\u7684\u57fa\u4e8e\u8ddd\u79bb\u7684\u805a\u7c7b\u7b97\u6cd5\uff0c\u91c7\u7528\u8ddd\u79bb\u4f5c\u4e3a\u76f8\u4f3c\u6027\u7684\u8bc4\u4ef7\u6307\u6807\uff0c\u5373\u8ba4\u4e3a\u4e24\u4e2a\u5bf9\u8c61\u7684\u8ddd\u79bb\u8d8a\u8fd1\uff0c\u5176\u76f8\u4f3c\u5ea6\u5c31\u8d8a\u5927\u3002\u8be5\u7b97\u6cd5\u8ba4\u4e3a\u7c07\u662f\u7531\u8ddd\u79bb\u9760\u8fd1\u7684\u5bf9\u8c61\u7ec4\u6210\u7684\uff0c\u56e0\u6b64\u628a\u5f97\u5230\u7d27\u51d1\u4e14\u72ec\u7acb\u7684\u7c07\u4f5c\u4e3a\u6700\u7ec8\u76ee\u6807\u3002 \u2003 \u7ef4\u5ea6\u805a\u7c7b \uff08Dimension Clusters\uff09\u3002\u5f53\u628a\u951a\u6846\u4e0eYOLO\u4e00\u8d77\u4f7f\u7528\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u4e24\u4e2a\u95ee\u9898\u3002 \u9996\u5148\u662f\u6846\u7684\u5c3a\u5bf8\u662f\u624b\u5de5\u6311\u9009\u7684\u3002\u867d\u7136\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u9002\u5f53\u5730\u8c03\u6574\u65b9\u6846\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u4ece\u4e00\u5f00\u59cb\u5c31\u4e3a\u7f51\u7edc\u9009\u62e9\u66f4\u597d\u7684\u5148\u9a8c\u6846\uff0c\u5c31\u53ef\u4ee5\u8ba9\u7f51\u7edc\u66f4\u5bb9\u6613\u5b66\u4e60\u5230\u66f4\u597d\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u2003\u6211\u4eec\u4e0d\u7528\u624b\u5de5\u9009\u62e9\u5148\u9a8c\u6846\uff0c\u800c\u662f\u5728\u8bad\u7ec3\u96c6\u7684\u8fb9\u754c\u6846\u4e0a\u8fd0\u884ck-means\u805a\u7c7b\uff0c\u81ea\u52a8\u627e\u5230\u826f\u597d\u7684\u5148\u9a8c\u6846\u3002 \u5982\u679c\u6211\u4eec\u4f7f\u7528\u5177\u6709\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u6807\u51c6 \\(k-means\\) \uff0c\u90a3\u4e48\u8f83\u5927\u7684\u6846\u6bd4\u8f83\u5c0f\u7684\u6846\u4ea7\u751f\u66f4\u591a\u7684\u8bef\u5dee\u3002 \u7136\u800c\uff0c\u6211\u4eec\u771f\u6b63\u60f3\u8981\u7684\u662f\u72ec\u7acb\u4e8e\u6846\u7684\u5927\u5c0f\u7684\uff0c\u80fd\u83b7\u5f97\u826f\u597d\u7684 \\(IOU\\) \u5206\u6570\u7684\u5148\u9a8c\u6846\u3002 \u56e0\u6b64\u5bf9\u4e8e\u8ddd\u79bb\u5ea6\u91cf\u6211\u4eec\u4f7f\u7528: \\(d(\\text { box, centroid }) = 1-\\operatorname{IOU}(\\text { box }, \\text { centroid })\\) \u2003\u6211\u4eec\u7528\u4e0d\u540c\u7684 \\(k\\) \u503c\u8fd0\u884c \\(k-means\\) \uff0c\u5e76\u7ed8\u5236\u6700\u63a5\u8fd1\u8d28\u5fc3\u7684\u5e73\u5747 \\(IOU\\) \uff08\u89c1\u56fe2\uff09\u3002\u4e3a\u4e86\u5728\u6a21\u578b\u590d\u6742\u5ea6\u548c\u9ad8\u53ec\u56de\u7387\u4e4b\u95f4\u7684\u826f\u597d\u6298\u8877\uff0c\u6211\u4eec\u9009\u62e9 \\(k = 5\\) \u3002\u805a\u7c7b\u7684\u8d28\u5fc3\u4e0e\u624b\u5de5\u9009\u53d6\u7684\u951a\u6846\u663e\u7740\u4e0d\u540c\uff0c\u5b83\u6709\u66f4\u5c11\u7684\u77ed\u4e14\u5bbd\u7684\u6846\uff0c\u800c\u4e14\u6709\u66f4\u591a\u65e2\u957f\u53c8\u7a84\u7684\u6846\u3002 \u2003\u88681\u4e2d\uff0c\u6211\u4eec\u5c06\u805a\u7c7b\u7b56\u7565\u7684\u5148\u9a8c\u6846\u4e2d\u5fc3\u6570\u548c\u624b\u5de5\u9009\u53d6\u7684\u951a\u6846\u6570\u5728\u6700\u63a5\u8fd1\u7684\u5e73\u5747 \\(IOU\\) \u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002\u4ec55\u4e2a\u5148\u9a8c\u6846\u4e2d\u5fc3\u7684\u5e73\u5747 \\(IOU\\) \u4e3a61.0\uff0c\u5176\u6027\u80fd\u7c7b\u4f3c\u4e8e9\u4e2a\u951a\u6846\u768460.9\u3002 \u4f7f\u75289\u4e2a\u8d28\u5fc3\u4f1a\u5f97\u5230\u66f4\u9ad8\u7684\u5e73\u5747 \\(IOU\\) \u3002\u8fd9\u8868\u660e\u4f7f\u7528 \\(k-means\\) \u751f\u6210\u8fb9\u754c\u6846\u53ef\u4ee5\u66f4\u597d\u5730\u8868\u793a\u6a21\u578b\u5e76\u4f7f\u5176\u66f4\u5bb9\u6613\u5b66\u4e60\u3002 \\(\\begin{array}{lcc} \\text { Box Generation } & \\# & \\text { Avg IOU } \\\\ \\hline \\text { Cluster SSE } & 5 & 58.7 \\\\ \\text { Cluster IOU } & 5 & 61.0 \\\\ \\text { Anchor Boxes [15] } & 9 & 60.9 \\\\ \\text { Cluster IOU } & 9 & 67.2 \\end{array}\\) \u88681\uff1a \\(VOC \\ 2007\\) \u6700\u63a5\u8fd1\u5148\u9a8c\u7684\u6846\u7684\u5e73\u5747 \\(IOU\\) \u3002 \\(VOC \\ 2007\\) \u4e0a\u7684\u76ee\u6807\u7684\u5e73\u5747IOU\u4e0e\u5176\u6700\u63a5\u8fd1\u7684\uff0c\u672a\u7ecf\u4fee\u6539\u7684\u4f7f\u7528\u4e0d\u540c\u751f\u6210\u65b9\u6cd5\u7684\u76ee\u6807\u4e4b\u95f4\u7684\u5e73\u5747 \\(IOU\\) \u3002\u805a\u7c7b\u5f97\u7ed3\u679c\u6bd4\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684\u5148\u9a8c\u6846\u7ed3\u679c\u8981\u597d\u5f97\u591a\u3002 \u2003 \u76f4\u63a5\u4f4d\u7f6e\u9884\u6d4b \uff08Direct location prediction\uff09\u3002\u5f53\u5728 \\(YOLO\\) \u4e2d\u4f7f\u7528\u951a\u6846\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff1a\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u5c24\u5176\u662f\u5728\u65e9\u671f\u8fed\u4ee3\u7684\u8fc7\u7a0b\u4e2d\u3002 \u5927\u591a\u6570\u4e0d\u7a33\u5b9a\u6765\u81ea\u4e8e\u9884\u6d4b\u6846\u7684 \\((x,y)\\) \u4f4d\u7f6e\u3002 \u5728\u5019\u9009\u533a\u57df\u7f51\u7edc\u4e2d\uff0c\u7f51\u7edc\u9884\u6d4b\u7684 \\(t_x,t_y\\) \uff0c\u548c\u4e2d\u5fc3\u5750\u6807 \\((x,y)\\) \u8ba1\u7b97\u5982\u4e0b\uff1a \\(\\huge\\begin{array}{l} x=\\left(t_{x} * w_{a}\\right)-x_{a} \\\\ y=\\left(t_{y} * h_{a}\\right)-y_{a} \\end{array}\\) \u2003\u4f8b\u5982\uff0c\u9884\u6d4b \\(t_x = 1\\) \u4f1a\u4f7f\u8be5\u6846\u5411\u53f3\u79fb\u52a8\u951a\u6846\u7684\u5bbd\u5ea6\uff0c\u800c\u9884\u6d4b \\(t_x = -1\\) \u4f1a\u5c06\u5176\u5411\u5de6\u79fb\u52a8\u76f8\u540c\u7684\u5bbd\u5ea6\u3002 \u2003\u8fd9\u4e2a\u516c\u5f0f\u662f\u4e0d\u53d7\u7ea6\u675f\u7684\uff0c\u6240\u4ee5\u4efb\u4f55\u951a\u6846\u90fd\u53ef\u4ee5\u5728\u56fe\u50cf\u4e2d\u7684\u4efb\u4f55\u4e00\u70b9\u7ed3\u675f\uff0c\u800c\u4e0d\u7ba1\u951a\u6846\u662f\u5728\u54ea\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u7684\u3002\u968f\u673a\u521d\u59cb\u5316\u6a21\u578b\u9700\u8981\u5f88\u957f\u65f6\u95f4\u624d\u80fd\u7a33\u5b9a\u5230\u9884\u6d4b\u5408\u7406\u7684\u504f\u79fb\u91cf\u3002 \u2003\u6211\u4eec\u6ca1\u6709\u9884\u6d4b\u504f\u79fb\uff0c\u800c\u662f\u9075\u5faa \\(YOLO\\) \u7684\u65b9\u6cd5\uff0c\u9884\u6d4b\u76f8\u5bf9\u4e8e\u7f51\u683c\u5355\u5143\u4f4d\u7f6e\u7684\u4f4d\u7f6e\u5750\u6807\u3002\u8fd9\u4f7f\u5f97\u771f\u5b9e\u503c\u7684\u754c\u9650\u57280\u52301\u4e4b\u95f4\u3002\u6211\u4eec\u4f7f\u7528\u903b\u8f91\u6fc0\u6d3b\u6765\u9650\u5236\u7f51\u7edc\u7684\u9884\u6d4b\u843d\u5728\u8fd9\u4e2a\u8303\u56f4\u5185\u3002 \u2003\u7f51\u7edc\u4e3a\u7279\u5f81\u56fe\u7684\u8f93\u51fa\u7684\u6bcf\u4e2a\u5355\u5143\u9884\u6d4b5\u4e2a\u8fb9\u754c\u6846\u3002\u7f51\u7edc\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u76845\u4e2a\u5750\u6807 \\(t_x,t_y,t_w,t_h\u548ct_o\\) \u3002\u5982\u679c\u5355\u5143\u683c\u4ece\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u504f\u79fb\u4e86,\u5e76\u4e14\u4e4b\u524d\u7684\u8fb9\u754c\u6846\u5177\u6709\u5bbd\u5ea6\u548c\u9ad8\u5ea6 \\(p_w,p_h\\) \u5219\u9884\u6d4b\u5bf9\u5e94\u4e8e\uff1a \\(\\begin{aligned} b_{x} &=\\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} &=\\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} &=p_{w} e^{t_{w}} \\\\ b_{h} &=p_{h} e^{t_{h}} \\\\ \\operatorname{Pr}(\\text { object }) * \\operatorname{IOU}(b, \\text { object }) &=\\sigma\\left(t_{o}\\right) \\end{aligned}\\) \u2003\u7531\u4e8e\u6211\u4eec\u9650\u5236\u4e86\u4f4d\u7f6e\u9884\u6d4b\uff0c\u4f7f\u5f97\u53c2\u6570\u5316\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u66f4\u52a0\u7a33\u5b9a\u3002\u4f7f\u7528\u7ef4\u5ea6\u96c6\u7fa4\u4ee5\u53ca\u76f4\u63a5\u9884\u6d4b\u8fb9\u754c\u6846\u4e2d\u5fc3\u4f4d\u7f6e\uff0c\u53ef\u4ee5\u4f7f \\(YOLO\\) \u6bd4\u951a\u6846\u7684\u7248\u672c\u63d0\u9ad8\u8fd15\uff05\u3002 \u56fe3\uff1a\u5177\u6709\u7ef4\u5ea6\u5148\u9a8c\u548c\u4f4d\u7f6e\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u3002\u6211\u4eec\u9884\u6d4b\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4f5c\u4e3a\u805a\u7c7b\u8d28\u5fc3\u7684\u504f\u79fb\u91cf\u3002\u6211\u4eec\u4f7f\u7528sigmoid\u51fd\u6570\u9884\u6d4b\u76f8\u5bf9\u4e8e\u6ee4\u6ce2\u5668\u5e94\u7528\u4f4d\u7f6e\u7684\u6846\u7684\u4e2d\u5fc3\u5750\u6807\u3002 \u2003 \u7ec6\u7c92\u5ea6\u529f\u80fd \uff08Fine-Grained Features\uff09\u3002\u4fee\u6539\u540e\u7684YOLO\u5728 \\(13\u00d713\\) \u7279\u5f81\u56fe\u4e0a\u9884\u6d4b\u68c0\u6d4b\u7ed3\u679c\u3002 \u867d\u7136\u8fd9\u5bf9\u4e8e\u5927\u578b\u7269\u4f53\u662f\u8db3\u591f\u7684\uff0c\u4f46\u4f7f\u7528\u66f4\u7ec6\u7c92\u5ea6\u7279\u5f81\u5bf9\u5b9a\u4f4d\u8f83\u5c0f\u7269\u4f53\u6709\u597d\u5904\u3002Faster R-CNN\u548cSSD\u90fd\u5728\u7f51\u7edc\u4e2d\u7684\u5404\u79cd\u7279\u5f81\u56fe\u4e0a\u8fd0\u884c\u7f51\u7edc\uff0c\u4ee5\u83b7\u5f97\u591a\u4e2a\u5206\u8fa8\u7387\u3002 \u6211\u4eec\u91c7\u53d6\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u53ea\u9700\u6dfb\u52a0\u4e00\u4e2a\u76f4\u901a\u5c42\uff0c\u4ee5 \\(26\u00d726\\) \u7684\u5206\u8fa8\u7387\u4ece\u8f83\u65e9\u7684\u5c42\u4e2d\u63d0\u53d6\u7279\u5f81\u3002 \u2003\u76f4\u901a\u5c42\u5c06\u9ad8\u5206\u8fa8\u7387\u7279\u5f81\u4e0e\u4f4e\u5206\u8fa8\u7387\u7279\u5f81\u8fde\u63a5\u8d77\u6765\uff0c\u5c06\u76f8\u90bb\u7279\u5f81\u53e0\u52a0\u5230\u4e0d\u540c\u7684\u901a\u9053\u4e2d\uff0c\u800c\u4e0d\u662f\u7a7a\u95f4\u4f4d\u7f6e\u4e0a\uff0c\u7c7b\u4f3c\u4e8e \\(ResNet\\) \u4e2d\u7684\u6052\u7b49\u6620\u5c04\u3002\u5c06 \\(26\u00d726\u00d7512\\) \u7684\u7279\u5f81\u56fe\u53d8\u4e3a \\(13\u00d713\u00d72048\\) \u7684\u7279\u5f81\u56fe\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u4e0e\u539f\u6765\u7684\u7279\u5f81\u8fde\u63a5\u3002\u6211\u4eec\u7684\u68c0\u6d4b\u5668\u8fd0\u884c\u5728\u8fd9\u5f20\u6269\u5c55\u7684\u7279\u5f81\u56fe\u7684\u9876\u90e8\uff0c\u4ee5\u4fbf\u5b83\u53ef\u4ee5\u8bbf\u95ee\u7ec6\u7c92\u5ea6\u7684\u529f\u80fd\u3002\u8fd9\u4f7f\u6027\u80fd\u63d0\u9ad8\u4e861\uff05\u3002 \u2003 \u591a\u5c3a\u5ea6\u8bad\u7ec3 \uff08Multi-Scale Training\uff09\u3002\u539f\u6765\u7684 \\(YOLO\\) \u4f7f\u7528 \\(448\u00d7448\\) \u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002\u901a\u8fc7\u6dfb\u52a0\u951a\u6846\uff0c\u6211\u4eec\u5c06\u5206\u8fa8\u7387\u66f4\u6539\u4e3a \\(416\u00d7416\\) \u3002\u4f46\u662f\uff0c\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u4ec5\u4f7f\u7528\u5377\u79ef\u5c42\u548c\u6c60\u5316\u5c42\uff0c\u56e0\u6b64\u53ef\u4ee5\u5b9e\u65f6\u8c03\u6574\u5927\u5c0f\u3002\u6211\u4eec\u5e0c\u671b \\(YOLOv2\\) \u80fd\u591f\u5728\u4e0d\u540c\u5c3a\u5bf8\u7684\u56fe\u50cf\u4e0a\u8fd0\u884c\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u591a\u5c3a\u5ea6\u8bad\u7ec3\u5e94\u5230\u6a21\u578b\u4e2d\u3002 \u2003\u6211\u4eec\u4e0d\u9700\u8981\u4fee\u6539\u8f93\u5165\u56fe\u50cf\u5927\u5c0f\uff0c\u800c\u662f\u6bcf\u9694\u51e0\u6b21\u8fed\u4ee3\u5c31\u6539\u53d8\u4e00\u6b21\u7f51\u7edc\u3002\u6bcf \\(10\\) \u4e2a\u6279\u6b21\u6211\u4eec\u7684\u7f51\u7edc\u4f1a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u65b0\u7684\u56fe\u50cf\u5c3a\u5bf8\u5927\u5c0f\u3002\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u7f29\u51cf\u4e86 \\(32\\) \u500d\uff0c\u6240\u4ee5\u6211\u4eec\u4ece \\(32\\) \u7684\u500d\u6570\u4e2d\u62bd\u53d6\uff1a \\({320,352\uff0c\u2026\uff0c608}\\) \u3002\u56e0\u6b64\uff0c\u6700\u5c0f\u7684\u9009\u9879\u662f \\(320\u00d7320\\) \uff0c\u6700\u5927\u7684\u662f \\(608\u00d7608\\) \u3002\u6211\u4eec\u8c03\u6574\u7f51\u7edc\u7684\u5c3a\u5bf8\u5230\u90a3\u4e2a\u7ef4\u5ea6\u5e76\u7ee7\u7eed\u8bad\u7ec3\u3002 \u2003\u8fd9\u4e2a\u673a\u5236\u8feb\u4f7f\u7f51\u7edc\u5b66\u4e60\u5982\u4f55\u5728\u5404\u79cd\u8f93\u5165\u7ef4\u5ea6\u4e0a\u505a\u597d\u9884\u6d4b\u3002\u8fd9\u610f\u5473\u7740\u540c\u4e00\u4e2a\u7f51\u7edc\u53ef\u4ee5\u9884\u6d4b\u4e0d\u540c\u5206\u8fa8\u7387\u4e0b\u7684\u68c0\u6d4b\u7ed3\u679c\u3002\u7f51\u7edc\u5728\u8f83\u5c0f\u7684\u5c3a\u5bf8\u4e0b\u8fd0\u884c\u901f\u5ea6\u66f4\u5feb\uff0c\u56e0\u6b64 \\(YOLOv2\\) \u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u677e\u7684\u6298\u4e2d\u3002 \u2003 \u5728\u4f4e\u5206\u8fa8\u7387\u4e0b\uff0c \\(YOLOv2\\) \u4f5c\u4e3a\u4e00\u79cd\u4fbf\u5b9c\u4f46\u76f8\u5f53\u51c6\u786e\u7684\u68c0\u6d4b\u5668\u5de5\u4f5c\u3002 \u5728 \\(288\u00d7288\\) \u60c5\u51b5\u4e0b\uff0c\u5b83\u7684\u8fd0\u884c\u901f\u5ea6\u8d85\u8fc7 90 FPS\uff0c\u800c \\(mAP\\) \u51e0\u4e4e\u4e0e \\(Fast \\ R-CNN\\) \u4e00\u6837\u597d\u3002\u8fd9\u4f7f\u5176\u6210\u4e3a\u5c0f\u578b \\(GPU\\) \uff0c\u9ad8\u5e27\u7387\u89c6\u9891\u6216\u591a\u89c6\u9891\u6d41\u7684\u7406\u60f3\u9009\u62e9\u3002 \u2003\u5728\u9ad8\u5206\u8fa8\u7387\u4e0b\uff0c \\(YOLOv2\\) \u662f\u4e00\u6b3e\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5728VOC2007\u4e0a\u83b7\u5f97\u4e8678.6\u7684 \\(mAP\\) \uff0c\u540c\u65f6\u4ecd\u4ee5\u9ad8\u4e8e\u5b9e\u65f6\u901f\u5ea6\u8fd0\u884c\u3002\u8bf7\u53c2\u9605\u88683\uff0c\u4e86\u89e3 \\(YOLOv2\\) \u4e0e\u5176\u4ed6\u6846\u67b6\u5728 \\(VOC \\ 2007\\) \u4e0a\u7684\u6bd4\u8f83 \u56fe4\u3002 \u56fe4\uff1a \\(VOC \\ 2007\\) \u4e0a\u7684\u7cbe\u5ea6\u548c\u901f\u5ea6 \u2003 \u8fdb\u4e00\u6b65\u7684\u5b9e\u9a8c \uff08Further Experiments\uff09\u3002 \u6211\u4eec\u5728 \\(VOC \\ 2012\\) \u4e0a\u8bad\u7ec3\u4e86 \\(YOLOv2\\) \u8fdb\u884c\u68c0\u6d4b\u3002\u88684 \u663e\u793a\u4e86 \\(YOLOv2\\) \u4e0e\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u7684\u6027\u80fd\u6bd4\u8f83\u3002 \\(YOLOv2\\) \u8fd0\u884c\u901f\u5ea6\u8fdc\u9ad8\u4e8e\u5bf9\u624b\uff0c\u4e14\u7cbe\u5ea6\u8fbe\u5230 73.4 \\(mAP\\) \u3002 \u6211\u4eec\u8fd8\u5728 \\(COCO\\) \u4e0a\u8bad\u7ec3\uff0c\u5e76\u4e0e\u88685\u4e2d\u7684\u5176\u4ed6\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002\u4f7f\u7528 \\(VOC\\) \u5ea6\u91cf\uff08 \\(IOU = 0.5\\) \uff09\uff0c \\(YOLOv2\\) \u83b7\u5f9744.0 \\(mAP\\) \uff0c\u4e0e \\(SSD\\) \u548c \\(Faster \\ R-CNN\\) \u76f8\u5f53\u3002 \\(\\begin{array}{lrrr} \\text { Detection Frameworks } & \\text { Train } & \\text { mAP } & \\text { FPS } \\\\ \\hline \\text { Fast R-CNN [5] } & 2007+2012 & 70.0 & 0.5 \\\\ \\text { Faster R-CNN VGG-16[15] } & 2007+2012 & 73.2 & 7 \\\\ \\text { Faster R-CNN ResNet[6] } & 2007+2012 & 76.4 & 5 \\\\ \\text { YOLO [14] } & 2007+2012 & 63.4 & 45 \\\\ \\text { SSD300 [11] } & 2007+2012 & 74.3 & 46 \\\\ \\text { SSD500 [11] } & 2007+2012 & 76.8 & 19 \\\\ \\hline \\text { YOLOv2 288 } \\times 288 & 2007+2012 & 69.0 & 91 \\\\ \\text { YOLOv2 352 } \\times 352 & 2007+2012 & 73.7 & 81 \\\\ \\text { YOLOv2 416 } \\times 416 & 2007+2012 & 76.8 & 67 \\\\ \\text { YOLOv2 480 } \\times 480 & 2007+2012 & 77.8 & 59 \\\\ \\text { YOLOv2 } 544 \\times 544 & 2007+2012 & \\mathbf{7 8 . 6} & 40 \\end{array}\\) \u88683\uff1a \\(PA S C A L \\ VOC \\ 2007\\) \u7684\u68c0\u6d4b\u6846\u67b6\u3002 \\(YOLOv2\\) \u6bd4\u4ee5\u524d\u7684\u68c0\u6d4b\u65b9\u6cd5\u66f4\u5feb\uff0c\u66f4\u51c6\u786e\u3002\u5b83\u4e5f\u53ef\u4ee5\u4ee5\u4e0d\u540c\u7684\u5206\u8fa8\u7387\u8fd0\u884c\uff0c\u4ee5\u4fbf\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u8f7b\u677e\u6298\u8877\u3002\u6bcf\u4e2a \\(YOLOv2\\) \u9879\u5b9e\u9645\u4e0a\u90fd\u662f\u5177\u6709\u76f8\u540c\u6743\u91cd\u7684\u76f8\u540c\u8bad\u7ec3\u6a21\u578b\uff0c\u53ea\u662f\u4ee5\u4e0d\u540c\u7684\u5927\u5c0f\u8fdb\u884c\u8bc4\u4f30\u3002\u6240\u6709\u7684\u65f6\u95f4\u7684\u6d4b\u8bd5\u90fd\u8fd0\u884c\u5728Geforce GTX Titan X\uff08\u539f\u59cb\u7684\uff0c\u800c\u4e0d\u662fPascal\u6a21\u578b\uff09 3.\u66f4\u5feb \u2003\u6211\u4eec\u5e0c\u671b\u68c0\u6d4b\u7ed3\u679c\u51c6\u786e\uff0c\u4f46\u6211\u4eec\u4e5f\u5e0c\u671b\u68c0\u6d4b\u901f\u5ea6\u66f4\u5feb\u3002 \u5927\u591a\u6570\u7528\u4e8e\u68c0\u6d4b\u7684\u5e94\u7528\u7a0b\u5e8f\uff08\u5982\u673a\u5668\u4eba\u6216\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff09\u90fd\u4f9d\u8d56\u4e8e\u4f4e\u5ef6\u8fdf\u9884\u6d4b\u3002 \u4e3a\u4e86\u6700\u5927\u9650\u5ea6\u5730\u63d0\u9ad8\u6027\u80fd\uff0c\u6211\u4eec\u5c06 \\(YOLOv2\\) \u8bbe\u8ba1\u4ece\u5934\u5230\u5c3e\u90fd\u975e\u5e38\u5feb \u3002 \u88682\uff1a\u4ece \\(YOLO\\) \u5230 \\(YOLOv2\\) \u7684\u8def\u5f84\u3002\u5927\u591a\u6570\u5217\u51fa\u7684\u8bbe\u8ba1\u51b3\u7b56\u90fd\u4f1a\u5bfc\u81f4 \\(MAP\\) \u663e\u7740\u589e\u52a0\u3002\u6709\u4e24\u4e2a\u4f8b\u5916\u60c5\u51b5\u662f\uff1a\u5207\u6362\u5230\u5e26\u6709\u951a\u6846\u7684\u5168\u5377\u79ef\u7f51\u7edc\u548c\u4f7f\u7528\u65b0\u7f51\u7edc\u3002\u5207\u6362\u5230\u951a\u6846\u65b9\u6cd5\u589e\u52a0\u53ec\u56de\u7387\uff0c\u800c\u4e0d\u6539\u53d8 \\(mAP\\) \uff0c\u800c\u4f7f\u7528\u65b0\u7f51\u7edc\u524a\u51cf33\uff05\u7684\u8ba1\u7b97\u3002 \u88684\uff1aPASCAL VOC2012\u6d4b\u8bd5\u68c0\u6d4b\u7ed3\u679c\u3002 \\(YOLOv2\\) \u4e0e\u91c7\u7528ResNet\u548cSSD512\u7684Faster R-CNN\u7b49\u5148\u8fdb\u68c0\u6d4b\u5668\u6027\u80fd\u76f8\u5f53\uff0c\u901f\u5ea6\u63d0\u9ad82\u81f310\u500d\u3002 \u2003\u5927\u591a\u6570\u68c0\u6d4b\u6846\u67b6\u4f9d\u8d56\u4e8eVGG-16\u4f5c\u4e3a\u57fa\u672c\u7279\u5f81\u63d0\u53d6\u5668[17]\u3002 \\(VGG-16\\) \u662f\u4e00\u4e2a\u529f\u80fd\u5f3a\u5927\uff0c\u51c6\u786e\u7684\u5206\u7c7b\u7f51\u7edc\uff0c\u4f46\u5b83\u6709\u4e0d\u5fc5\u8981\u7684\u590d\u6742\u5ea6\u3002 \\(VGG-16\\) \u7684\u5377\u79ef\u5c42\u5728\u4e00\u4e2a \\(224\u00d7224\\) \u5206\u8fa8\u7387\u5355\u4e2a\u56fe\u50cf\u4e0a\u8fd0\u884c\u4e00\u6b21\u9700\u8981 \\(306.90\\) \u4ebf\u6d6e\u70b9\u8fd0\u7b97\u3002 \u2003 \\(YOLO\\) \u6846\u67b6\u4f7f\u7528\u57fa\u4e8e \\(Googlenet\\) \u67b6\u6784\u7684\u81ea\u5b9a\u4e49\u7f51\u7edc[19]\u3002\u8fd9\u4e2a\u7f51\u7edc\u6bd4 \\(VGG-16\\) \u66f4\u5feb\uff0c\u4e00\u6b21\u524d\u5411\u4f20\u64ad\u53ea\u8981 \\(85.2\\) \u4ebf\u6b21\u8fd0\u884c\u3002\u7136\u800c\uff0c\u5b83\u7684\u51c6\u786e\u6027\u7565\u4f4e\u4e8e \\(VGG-16\\) \u3002\u5728 \\(ImageNet\\) \u4e0a\uff0c\u7528 \\(224\u00d7224\\) \u7684\u5355\u5f20\u88c1\u526a\u56fe\u50cf\uff0c \\(YOLO\\) \u7684\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u7cbe\u5ea6\u4e3a88.0\uff05\u800c \\(VGG-16\\) \u5219\u4e3a90.0\uff05\u3002 \u2003 \\(Darknet-19\\) \u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5206\u7c7b\u6a21\u578b\u4f5c\u4e3a \\(YOLOv2\\) \u7684\u57fa\u7840\u3002\u6211\u4eec\u7684\u6a21\u578b\u5efa\u7acb\u5728\u7f51\u7edc\u8bbe\u8ba1\u7684\u5148\u524d\u5de5\u4f5c\u4ee5\u53ca\u8be5\u9886\u57df\u7684\u5e38\u8bc6\u4e0a\u3002\u4e0e \\(VGG\\) \u6a21\u578b\u7c7b\u4f3c\uff0c\u6211\u4eec\u5927\u591a\u4f7f\u7528 \\(3\u00d73\\) \u6ee4\u6ce2\u5668\uff0c\u5e76\u4e14\u5728\u6c60\u5316\u5c42\u6b65\u9aa4\u540e\u4f7f\u7528\u4e24\u500d\u7684\u901a\u9053\u6570[17]\u3002\u6309\u7167Network in Network\uff08NIN\uff09\u7684\u65b9\u6cd5\uff0c\u6211\u4eec\u4f7f\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u6765\u505a\u9884\u6d4b\uff0c\u5e76\u4f7f\u75281\u00d71\u6ee4\u6ce2\u5668\u6765\u538b\u7f293\u00d73\u5377\u79ef\u7684\u7279\u5f81\u8868\u793a[9]\u3002\u6211\u4eec\u4f7f\u7528\u6279\u91cf\u5f52\u4e00\u5316\u6765\u7a33\u5b9a\u8bad\u7ec3\uff0c\u52a0\u901f\u6536\u655b\uff0c\u5e76\u89c4\u8303\u6a21\u578b[7]\u3002 \u2003\u6700\u7ec8\u7684\u6a21\u578b\u53eb\u505aDarknet-19\uff0c\u5b83\u670919\u4e2a\u5377\u79ef\u5c42\u548c5\u4e2aMaxpool\u5c42\u3002 \\(Darknet-19\\) \u53ea\u9700\u898155.8\u4ebf\u6b21\u64cd\u4f5c\u6765\u5904\u7406\u56fe\u50cf\uff0c\u4f46\u5728 \\(ImageNet\\) \u4e0a\u5b9e\u73b0\u4e8672.9\uff05\u7684top-1\u7cbe\u5ea6\u548c91.2\uff05\u7684top-5\u7cbe\u5ea6\u3002 \u2003 \u5206\u7c7b\u8bad\u7ec3 \uff08Training for classification\uff09\u3002\u6211\u4eec\u4f7f\u7528 \\(DarkNet\\) \u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u4f7f\u7528\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0c\u521d\u59cb\u5b66\u4e60\u7387\u4e3a0.1\uff0c\u591a\u9879\u5f0f\u901f\u7387\u8870\u51cf\u4e3a4\uff0c\u6743\u91cd\u8870\u51cf\u4e3a0.0005\uff0c\u52a8\u91cf\u4e3a0.9\uff0c\u5728\u6807\u51c6 \\(ImageNet\\) 1000\u7c7b\u522b\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u5bf9\u7f51\u7edc\u8fdb\u884c160\u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u8bad\u7ec3[13]\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u6807\u51c6\u6570\u636e\u589e\u5f3a\u6280\u5de7\uff0c\u5305\u62ec\u968f\u673a\u622a\u53d6\uff0c\u65cb\u8f6c\u548c\u6539\u53d8\u8272\u76f8\uff0c\u9971\u548c\u5ea6\u548c\u66dd\u5149\u3002 \u2003 \u5982\u4e0a\u6240\u8ff0\uff0c\u5728\u6211\u4eec\u5bf9 \\(224\u00d7224\\) \u56fe\u50cf\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3\u4e4b\u540e\uff0c\u6211\u4eec\u7528\u66f4\u5927\u7684\u5206\u8fa8\u7387448\u5bf9\u7f51\u7edc\u8fdb\u884c\u4e86\u5fae\u8c03\u3002\u5fae\u8c03\u65f6\uff0c\u6211\u4eec\u4f7f\u7528\u4e0a\u8ff0\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u4ec5\u752810\u4e2a\u5468\u671f\uff0c\u5e76\u4e14\u5f00\u59cb\u65f6\u7684\u5b66\u4e60\u7387\u4e3a10-3\u3002\u5728\u8fd9\u4e2a\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u4e0b\uff0c\u6211\u4eec\u7684\u7f51\u7edc\u5b9e\u73b0\u4e8676.5\uff05\u7684 \\(top-1\\) \u7cbe\u5ea6\u548c93.3\uff05\u7684 \\(top-5\\) \u7cbe\u5ea6\u3002 \u2003 \u68c0\u6d4b\u8bad\u7ec3 \uff08Training for detection\uff09\u3002\u6211\u4eec\u8fd9\u6837\u4fee\u6539\u7f51\u7edc\uff1a\u53bb\u9664\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u53d6\u800c\u4ee3\u4e4b\u7684\u662f\u6dfb\u52a0\u4e09\u4e2a \\(3 \u00d7 3\\) \u7684\u5377\u79ef\u5c42\uff0c\u6bcf\u4e2a\u5c42\u6709 \\(1024\\) \u4e2a\u8fc7\u6ee4\u5668\uff0c\u7136\u540e\u5728\u6700\u540e\u6dfb\u52a0 \\(1\u00d71\\) \u5377\u79ef\u5c42\uff0c\u8be5\u5c42\u7684\u6ee4\u6ce2\u5668\u6570\u91cf\u662f\u68c0\u6d4b\u9700\u8981\u7684\u8f93\u51fa\u6570\u91cf\u3002 \u5bf9\u4e8e \\(VOC\\) \uff0c\u6211\u4eec\u9884\u6d4b \\(05\\) \u4e2a\u8fb9\u754c\u6846\uff0c\u6bcf\u4e2a\u8fb9\u754c\u6846\u6709 5\u4e2a\u5750\u6807\u548c20\u4e2a\u7c7b\u522b\uff0c\u6240\u4ee5\u6709125\u4e2a\u6ee4\u6ce2\u5668\u3002\u6211\u4eec\u8fd8\u6dfb\u52a0\u4e86\u4ece\u6700\u540e\u7684 \\(3\u00d73\u00d7512\\) \u5c42\u5230\u5012\u6570\u7b2c\u4e8c\u5c42\u5377\u79ef\u5c42\u7684\u76f4\u901a\u5c42\uff0c\u4ee5\u4fbf\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u4f7f\u7528\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002 \u2003\u6211\u4eec\u8bad\u7ec3\u7f51\u7edc160\u4e2a\u8fed\u4ee3\u5468\u671f\uff0c\u521d\u59cb\u5b66\u4e60\u7387\u4e3a \\(10^{-3}\\) \uff0c\u572860\u548c90\u5468\u671f\u540c\u65f6\u9664\u4ee510\u3002\u6211\u4eec\u4f7f\u7528 \\(0.0005\\) \u7684\u6743\u503c\u8870\u51cf\u548c 0.9 \u7684\u52a8\u91cf( momentum )\u3002\u6211\u4eec\u5bf9 \\(YOLO\\) \u548c \\(SSD\\) \u8fdb\u884c\u7c7b\u4f3c\u7684\u6570\u636e\u589e\u5f3a\uff0c\u968f\u673a\u88c1\u526a\uff0c\u8272\u5f69\u4fee\u6539\u7b49\u3002\u6211\u4eec\u5728 \\(COCO\\) \u548c \\(VOC\\) \u4f7f\u7528\u76f8\u540c\u7684\u8bad\u7ec3\u7b56\u7565\u3002 \\(\\begin{array}{l|c|cccc|ccc|ccc|ccc} & & 0.5: 0.95 & 0.5 & 0.75 & \\mathrm{~S} & \\mathrm{M} & \\mathrm{L} & 1 & 10 & 100 & \\mathrm{~S} & \\mathrm{M} & \\mathrm{L} \\\\ \\hline \\text { Fast R-CNN [5] } & \\text { train } & 19.7 & 35.9 & - & - & - & - & - & - & - & - & - & - \\\\ \\text { Fast R-CNN[1] } & \\text { train } & 20.5 & 39.9 & 19.4 & 4.1 & 20.0 & 35.8 & 21.3 & 29.5 & 30.1 & 7.3 & 32.1 & 52 .0 \\\\ \\text { Faster R-CNN[15] } & \\text { trainval } & 21.9 & 42.7 & - & - & - & - & - & - & - & - & - & - \\\\ \\text { ION [1] } & \\text { train } & 23.6 & 43.2 & 23.6 & 6.4 & 24.1 & 38.3 & 23.2 & 32.7 & 33.5 & 10.1 & 37.7 & 53.6 \\\\ \\text { Faster R-CNN[10] } & \\text { trainval } & 24.2 & 45.3 & 23.5 & 7.7 & 26.4 & 37.1 & 23.8 & 34.0 & 34.6 & 12.0 & 38.5 & 54.4 \\\\ \\text { SSD300 [11] } & \\text { trainval35k } & 23.2 & 41.2 & 23.4 & 5.3 & 23.2 & 39.6 & 22.5 & 33.2 & 35.3 & 9.6 & 37.6 & 56.5 \\\\ \\text { SSD512 [11] } & \\text { trainval35k } & \\mathbf{26.8} & \\mathbf{4 6 . 5} & \\mathbf{2 7 . 8} & \\mathbf{9 . 0} & \\mathbf{2 8 . 9} & 41.9 & \\mathbf{2 4 . 8} & 37.5 & \\mathbf{3 9 . 8} & \\mathbf{1 4 . 0} & 43.5 & 59.0 \\\\ \\hline \\text { YOLOv2 [11] } & \\text { trainval35k } & 21.6 & 44.0 & 19.2 & 5.0 & 22.4 & 35.5 & 20.7 & 31.6 & 33.3 & 9.8 & 36.5 & 54 .4 \\end{array}\\) \u88685\uff1a \\(COCO\\) test-dev\u96c6\u4e0a\u7684\u7ed3\u679c\uff0c\u6765\u6e90\u4e8e\u8bba\u6587[11] 4.\u66f4\u5f3a \u2003\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u5408\u8bad\u7ec3\u5206\u7c7b\u548c\u68c0\u6d4b\u6570\u636e\u7684\u673a\u5236\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u4e86\u7528\u4e8e\u68c0\u6d4b\u7684\u56fe\u50cf\u6765\u5b66\u4e60\u68c0\u6d4b\u7279\u5b9a\u4fe1\u606f\uff0c\u5982\u8fb9\u754c\u6846\u5750\u6807\u9884\u6d4b\u548c\u76ee\u6807\u4ee5\u53ca\u5982\u4f55\u5bf9\u5e38\u89c1\u76ee\u6807\u8fdb\u884c\u5206\u7c7b\u3002\u901a\u8fc7\u4f7f\u7528\u4ec5\u5177\u6709\u7c7b\u6807\u7b7e\u7684\u56fe\u50cf\u6765\u6269\u5c55\u5176\u53ef\u68c0\u6d4b\u7c7b\u522b\u7684\u6570\u91cf\u3002 \u2003\u5728\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u6df7\u5408\u6765\u81ea\u68c0\u6d4b\u548c\u5206\u7c7b\u6570\u636e\u96c6\u7684\u56fe\u50cf\u3002 \u5f53\u6211\u4eec\u7684\u7f51\u7edc\u770b\u5230\u6807\u8bb0\u4e3a\u68c0\u6d4b\u7684\u56fe\u50cf\u65f6\uff0c\u53ef\u4ee5\u6839\u636e\u5b8c\u6574\u7684 \\(YOLOv2\\) \u635f\u5931\u51fd\u6570\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3002 \u5f53\u5b83\u770b\u5230\u5206\u7c7b\u56fe\u50cf\u65f6\uff0c\u53ea\u4f1a\u53cd\u5411\u4f20\u64ad\u5206\u7c7b\u90e8\u5206\u7684\u635f\u5931\u3002 \\(\\begin{array}{l|c|c|c} \\text { Type } & \\text { Filters } & \\text { Size/Stride } & \\text { Output } \\\\ \\hline \\text { Convolutional } & 32 & 3 \\times 3 & 224 \\times 224 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 112 \\times 112 \\\\ \\text { Convolutional } & 64 & 3 \\times 3 & 112 \\times 112 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 56 \\times 56 \\\\ \\text { Convolutional } & 128 & 3 \\times 3 & 56 \\times 56 \\\\ \\text { Convolutional } & 64 & 1 \\times 1 & 56 \\times 56 \\\\ \\text { Convolutional } & 128 & 3 \\times 3 & 56 \\times 56 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 28 \\times 28 \\\\ \\text { Convolutional } & 256 & 3 \\times 3 & 28 \\times 28 \\\\ \\text { Convolutional } & 128 & 1 \\times 1 & 28 \\times 28 \\\\ \\text { Convolutional } & 256 & 3 \\times 3 & 28 \\times 28 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Convolutional } & 256 & 1 \\times 1 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Convolutional } & 256 & 1 \\times 1 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\text { Convolutional } & 512 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\text { Convolutional } & 512 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\hline \\hline \\text { Convolutional } & 1000 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Avgpool } & & \\text { Global } & 1000 \\\\ \\text { Softmax } & & & \\end{array}\\) \u88686\uff1aDarknet-19 \u2003\u8fd9\u79cd\u65b9\u6cd5\u5e26\u6765\u4e86\u4e00\u4e9b\u96be\u9898\u3002\u68c0\u6d4b\u6570\u636e\u96c6\u53ea\u6709\u5e38\u7528\u7684\u76ee\u6807\u548c\u901a\u7528\u7684\u6807\u7b7e\uff0c\u5982\u201c\u72d7\u201d\u6216\u201c\u8239\u201d\u3002\u5206\u7c7b\u6570\u636e\u96c6\u5177\u6709\u66f4\u5e7f\u6cdb\u548c\u66f4\u6df1\u5165\u7684\u6807\u7b7e\u8303\u56f4\u3002 \\(ImageNet\\) \u62e5\u6709\u591a\u79cd\u72ac\u79cd\uff0c\u5305\u62ecNorfolk terrier\uff0cYorkshire terrier\u548cBedlington terrier\u3002\u5982\u679c\u6211\u4eec\u60f3\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5219\u9700\u8981\u91c7\u7528\u4e00\u81f4\u7684\u65b9\u5f0f\u6765\u5408\u5e76\u8fd9\u4e9b\u6807\u7b7e\u3002 \u2003\u5927\u591a\u6570\u5206\u7c7b\u65b9\u6cd5\u4f7f\u7528\u6db5\u76d6\u6240\u6709\u53ef\u80fd\u7c7b\u522b\u7684 \\(softmax\\) \u5c42\u6765\u8ba1\u7b97\u6700\u7ec8\u6982\u7387\u5206\u5e03\u3002\u4f7f\u7528 \\(softmax\\) \uff0c\u610f\u5473\u7740\u7c7b\u662f\u76f8\u4e92\u6392\u65a5\u7684\u3002\u8fd9\u7ed9\u7ec4\u5408\u6570\u636e\u96c6\u5e26\u6765\u4e86\u95ee\u9898\uff0c\u4f8b\u5982\uff0c\u4f60\u4e0d\u80fd\u7528\u8fd9\u4e2a\u6a21\u578b\u6765\u7ec4\u5408 \\(ImageNet\\) \u548c \\(COCO\\) \uff0c\u56e0\u4e3a\u7c7b\u522b \\(Norfolk \\ terrier\u548cdog\\) \u4e0d\u662f\u4e92\u65a5\u7684\u3002 \u2003\u76f8\u53cd\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u591a\u6807\u7b7e\u6a21\u578b\u6765\u7ec4\u5408\u4e0d\u4f1a\u4e92\u76f8\u6392\u65a5\u7684\u6570\u636e\u96c6\u3002\u8fd9\u4e2a\u65b9\u6cd5\u5ffd\u7565\u4e86\u6211\u4eec\u6240\u77e5\u9053\u7684\u5173\u4e8e\u6570\u636e\u7684\u6240\u6709\u7ed3\u6784\uff0c\u4f8b\u5982\u6240\u6709\u7684 \\(COCO\\) \u7c7b\u90fd\u662f\u76f8\u4e92\u72ec\u7acb\u7684\u3002 \u2003 \u5206\u5c42\u5206\u7c7b \uff08Hierarchical classification\uff09\u3002 \\(ImageNet\\) \u6807\u7b7e\u662f\u4ece \\(WordNet\\) \u4e2d\u63d0\u53d6\u7684\uff0c \\(WordNet\\) \u662f\u4e00\u4e2a\u6784\u5efa\u6982\u5ff5\u53ca\u5176\u76f8\u4e92\u5173\u7cfb\u7684\u8bed\u8a00\u6570\u636e\u5e93[12]\u3002 Norfolk terrier\u548cYorkshire terrier\u90fd\u662fterrier\u7684\u4e0b\u4e49\u8bcd\uff0cterrier\u662f\u4e00\u79cdhunting dog\uff0chunting dog\u662fdog\uff0cdog\u662fcanine\u7b49\u3002\u5927\u591a\u6570\u5206\u7c7b\u7684\u65b9\u6cd5\u5047\u8bbe\u6807\u7b7e\u662f\u4e00\u4e2a\u6241\u5e73\u7ed3\u6784\uff0c\u4f46\u662f\u5bf9\u4e8e\u7ec4\u5408\u6570\u636e\u96c6\uff0c\u7ed3\u6784\u6b63\u662f\u6211\u4eec\u6240\u9700\u8981\u7684\u3002 \u2003 \\(WordNet\\) \u7684\u7ed3\u6784\u662f\u6709\u5411\u56fe\uff0c\u800c\u4e0d\u662f\u6811\uff0c\u56e0\u4e3a\u8bed\u8a00\u5f88\u590d\u6742\u3002 \u4f8b\u5982\uff0c\u201c\u72d7\u201d\u65e2\u662f\u4e00\u79cd\u201c\u72ac\u201d\u53c8\u662f\u4e00\u79cd\u201c\u5bb6\u517b\u52a8\u7269\u201d\uff0c\u5b83\u4eec\u90fd\u662f \\(WordNet\\) \u4e2d\u7684\u540c\u4e49\u8bcd\u3002 \u6211\u4eec\u4e0d\u4f7f\u7528\u5b8c\u6574\u7684\u56fe\u7ed3\u6784\uff0c\u800c\u662f\u901a\u8fc7\u4ece \\(ImageNet\\) \u4e2d\u7684\u6982\u5ff5\u6784\u5efa\u5206\u5c42\u6811\u6765\u7b80\u5316\u95ee\u9898\u3002 \u2003WordNet\u7684\u7ed3\u6784\u662f\u6709\u5411\u56fe\uff0c\u800c\u4e0d\u662f\u6811\uff0c\u56e0\u4e3a\u8bed\u8a00\u5f88\u590d\u6742\u3002\u4f8b\u5982\uff0c\u4e00\u53ea\u72d7\u65e2\u662f\u4e00\u79cd\u72ac\u79d1\u52a8\u7269\uff0c\u53c8\u662f\u4e00\u79cd\u5bb6\u517b\u52a8\u7269\uff0c\u5b83\u4eec\u90fd\u662fWordNet\u4e2d\u7684\u540c\u79cd\u52a8\u7269\u3002\u6211\u4eec\u6ca1\u6709\u4f7f\u7528\u5b8c\u6574\u7684\u56fe\u7ed3\u6784\uff0c\u800c\u662f\u901a\u8fc7\u4ece \\(ImageNet\\) \u4e2d\u7684\u6982\u5ff5\u6784\u5efa\u5206\u5c42\u6811\u6765\u7b80\u5316\u95ee\u9898\u3002 \u2003\u4e3a\u4e86\u6784\u5efa\u8fd9\u68f5\u6811\uff0c\u6211\u4eec\u68c0\u67e5 \\(ImageNet\\) \u4e2d\u7684\u89c6\u89c9\u540d\u8bcd\uff0c\u5e76\u67e5\u770b\u5b83\u4eec\u901a\u8fc7 \\(WordNet\\) \u56fe\u5230\u6839\u8282\u70b9\u7684\u8def\u5f84\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u662f\u201c\u7269\u7406\u76ee\u6807\u201d\u3002 \u8bb8\u591a\u540c\u4e49\u8bcd\u53ea\u6709\u5728\u56fe\u4e0a\u4e00\u6761\u8def\u5f84\uff0c\u6240\u4ee5\u9996\u5148\u6211\u4eec\u5c06\u6240\u6709\u8fd9\u4e9b\u8def\u5f84\u6dfb\u52a0\u5230\u6211\u4eec\u7684\u6811\u4e2d\u3002 \u7136\u540e\uff0c\u6211\u4eec\u53cd\u590d\u68c0\u67e5\u6211\u4eec\u7559\u4e0b\u7684\u6982\u5ff5\uff0c\u5e76\u5c3d\u53ef\u80fd\u5c11\u5730\u6dfb\u52a0\u751f\u6210\u6811\u7684\u8def\u5f84\u3002 \u6240\u4ee5\u5982\u679c\u4e00\u4e2a\u6982\u5ff5\u6709\u4e24\u6761\u901a\u5411\u6839\u7684\u8def\u5f84\uff0c\u4e00\u6761\u8def\u5f84\u4f1a\u4e3a\u6211\u4eec\u7684\u6811\u589e\u52a0\u4e09\u6761\u8fb9\uff0c\u53e6\u4e00\u6761\u8def\u53ea\u589e\u52a0\u4e00\u6761\u8fb9\uff0c\u6211\u4eec\u9009\u62e9\u8f83\u77ed\u7684\u8def\u5f84\u3002 \u2003 \u6700\u7ec8\u7684\u7ed3\u679c\u662f \\(WordTree\\) \uff0c\u4e00\u4e2a\u89c6\u89c9\u6982\u5ff5\u7684\u5206\u5c42\u6a21\u578b\u3002\u4e3a\u4e86\u4f7f\u7528 \\(WordTree\\) \u8fdb\u884c\u5206\u7c7b\uff0c\u6211\u4eec\u9884\u6d4b\u6bcf\u4e2a\u8282\u70b9\u7684\u6761\u4ef6\u6982\u7387\uff0c\u4ee5\u5f97\u5230\u540c\u4e49\u8bcd\u96c6\u5408\u4e2d\u6bcf\u4e2a\u540c\u4e49\u8bcd\u4e0b\u4e49\u8bcd\u7684\u6982\u7387\u3002\u4f8b\u5982\uff0c\u5728terrier\u8282\u70b9\u6211\u4eec\u9884\u6d4b\uff1a \\(\\large\\operatorname{Pr} (Norfolk \\ terrier|terrier) \\\\ \\operatorname{Pr} (Yorkshire \\ terrier|terrier) \\\\ \\operatorname{Pr}( Bedlington \\ terrier|terrier )\\) \u2003\u5982\u679c\u6211\u4eec\u60f3\u8981\u8ba1\u7b97\u4e00\u4e2a\u7279\u5b9a\u8282\u70b9\u7684\u7edd\u5bf9\u6982\u7387\uff0c\u6211\u4eec\u53ea\u9700\u6cbf\u7740\u901a\u8fc7\u6811\u5230\u8fbe\u6839\u8282\u70b9\u7684\u8def\u5f84\uff0c\u518d\u4e58\u4ee5\u6761\u4ef6\u6982\u7387\u3002\u6240\u4ee5\u5982\u679c\u6211\u4eec\u60f3\u77e5\u9053\u4e00\u5f20\u56fe\u7247\u662f\u5426\u662fNorfolk terrier\uff0c\u6211\u4eec\u8ba1\u7b97\uff1a \\(\\operatorname{Pr}(\\text { Norfolk terrier }) = \\operatorname{Pr}(\\text { Norfolk terrier } \\mid \\text { terrier })\\) \\(\\quad * \\operatorname{Pr}(\\text { terrier } \\mid \\text { hunting dog })\\) \\(* \\ldots * \\\\\\) \\(* \\operatorname{Pr}(\\text { mammal } \\mid \\operatorname{Pr}(\\text { animal })\\) \\(* \\operatorname{Pr}(\\text { animal } \\mid \\text { physical object })\\) \u2003\u4e3a\u4e86\u5b9e\u73b0\u5206\u7c7b\uff0c\u6211\u4eec\u5047\u5b9a\u56fe\u50cf\u5305\u542b\u4e00\u4e2a\u76ee\u6807\uff1a \\(P r(physical object) = 1\\) \u3002 \u2003\u4e3a\u4e86\u9a8c\u8bc1\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u5728\u4f7f\u75281000\u7c7b \\(ImageNet\\) \u6784\u5efa\u7684 \\(WordTree\\) \u4e0a\u8bad\u7ec3 \\(Darknet-19\\) \u6a21\u578b\u3002 \u4e3a\u4e86\u6784\u5efa \\(WordTree1k\\) \uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u6240\u6709\u4e2d\u95f4\u8282\u70b9\uff0c\u5c06\u6807\u7b7e\u7a7a\u95f4\u4ece \\(1000\\) \u6269\u5c55\u5230 \\(1369\\) \u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u6211\u4eec\u5c06\u771f\u5b9e\u6807\u7b7e\u5411\u6811\u4e0a\u9762\u4f20\u64ad\uff0c\u4ee5\u4fbf\u5982\u679c\u56fe\u50cf\u88ab\u6807\u8bb0\u4e3aNorfolk terrier\uff0c\u5219\u5b83\u4e5f\u88ab\u6807\u8bb0\u4e3adog\u548cmamal\u7b49\u3002\u4e3a\u4e86\u8ba1\u7b97\u6761\u4ef6\u6982\u7387\uff0c\u6211\u4eec\u7684\u6a21\u578b\u9884\u6d4b\u4e861369\u4e2a\u503c\u7684\u5411\u91cf\uff0c\u5e76\u4e14\u6211\u4eec\u8ba1\u7b97\u4e86\u76f8\u540c\u6982\u5ff5\u7684\u4e0b\u4e49\u8bcd\u5728\u6240\u6709\u540c\u4e49\u8bcd\u96c6\u4e0a\u7684softmax\uff0c\u89c1\u56fe5\u3002 \u2003\u4f7f\u7528\u4e0e\u4ee5\u524d\u76f8\u540c\u7684\u8bad\u7ec3\u53c2\u6570\uff0c\u6211\u4eec\u7684\u5206\u5c42Darknet-19\u8fbe\u5230\u4e8671.9\uff05\u7684 \\(top-1\\) \u7cbe\u5ea6\u548c90.4\uff05\u7684 \\(top-5\\) \u7cbe\u5ea6\u3002 \u5c3d\u7ba1\u589e\u52a0\u4e86369\u4e2a\u9644\u52a0\u6982\u5ff5\uff0c\u5e76\u4e14\u8ba9\u6211\u4eec\u7684\u7f51\u7edc\u9884\u6d4b\u4e86\u6811\u72b6\u7ed3\u6784\uff0c\u4f46\u6211\u4eec\u7684\u7cbe\u5ea6\u4ec5\u7565\u6709\u4e0b\u964d\u3002 \u4ee5\u8fd9\u79cd\u65b9\u5f0f\u8fdb\u884c\u5206\u7c7b\u4e5f\u6709\u82e5\u5e72\u597d\u5904\u3002 \u5728\u65b0\u7684\u6216\u672a\u77e5\u7684\u76ee\u6807\u7c7b\u522b\u4e0a\uff0c\u6027\u80fd\u4f1a\u4f18\u96c5\u4f4e\u964d\u4f4e\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u7f51\u7edc\u770b\u5230\u4e00\u5f20\u72d7\u7684\u7167\u7247\uff0c\u4f46\u4e0d\u786e\u5b9a\u5b83\u662f\u4ec0\u4e48\u7c7b\u578b\u7684\u72d7\uff0c\u5b83\u4ecd\u7136\u4f1a\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u201cdog\u201d\uff0c\u53ea\u662f\u5728\u4e0b\u4e49\u8bcd\u4f1a\u6709\u8f83\u4f4e\u7684\u7f6e\u4fe1\u5ea6\u3002 \u2003\u8be5\u65b9\u6cd5\u4e5f\u9002\u7528\u4e8e\u68c0\u6d4b\u3002\u73b0\u5728\uff0c\u6211\u4eec\u4e0d\u7528\u5047\u5b9a\u6bcf\u4e2a\u56fe\u50cf\u90fd\u6709\u4e00\u4e2a\u76ee\u6807\u7269\u4f53\uff0c\u800c\u662f\u4f7f\u7528 \\(YOLOv2\\) \u7684\u76ee\u6807\u9884\u6d4b\u5668\u7ed9\u51faP r\uff08\u76ee\u6807\u7269\u4f53\uff09\u7684\u503c\u3002\u68c0\u6d4b\u5668\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u6982\u7387\u6811\u3002\u6211\u4eec\u904d\u5386\u6811\uff0c\u5728\u6bcf\u6b21\u5206\u5272\u4e2d\u9009\u53d6\u5177\u6709\u6700\u9ad8\u7684\u7f6e\u4fe1\u5ea6\u7684\u8def\u5f84\uff0c\u76f4\u5230\u8fbe\u5230\u67d0\u4e2a\u9608\u503c\uff0c\u7136\u540e\u6211\u4eec\u5f97\u5230\u8be5\u76ee\u6807\u7684\u7c7b\u522b\u3002 \u2003 \u6570\u636e\u96c6\u4e0e \\(WordTree\\) \u7684\u7ec4\u5408 (Dataset combination with WordTree)\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \\(WordTree\\) \u4ee5\u53ef\u884c\u7684\u65b9\u5f0f\u5c06\u591a\u4e2a\u6570\u636e\u96c6\u7ec4\u5408\u5728\u4e00\u8d77\u3002\u6211\u4eec\u53ea\u9700\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u6620\u5c04\u5230\u6811\u4e2d\u7684synsets\u5373\u53ef\u3002\u56fe6\u663e\u793a\u4e86\u4e00\u4e2a\u4f7f\u7528 \\(WordTree\\) \u7ec4\u5408\u6765\u81ea \\(ImageNet\\) \u548c \\(COCO\\) \u7684\u6807\u7b7e\u7684\u793a\u4f8b\u3002 WordNet\u975e\u5e38\u591a\u6837\u5316\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u8fd9\u79cd\u6280\u672f\u7528\u4e8e\u5927\u591a\u6570\u6570\u636e\u96c6\u3002 \u56fe5\uff1a\u5bf9 \\(ImageNet\\) \u4e0e \\(WordTree\\) \u7684\u9884\u6d4b\u3002\u5927\u591a\u6570ImaNet\u6a21\u578b\u4f7f\u7528\u4e00\u4e2a\u5927\u7684softmax\u6765\u9884\u6d4b\u6982\u7387\u5206\u5e03\u3002\u4f7f\u7528 \\(WordTree\\) \uff0c\u6211\u4eec\u901a\u8fc7\u5171\u540c\u7684\u4e0b\u4f4d\u8bcd\u6267\u884c\u591a\u4e2asoftmax\u64cd\u4f5c\u3002 \u2003 \u8054\u5408\u5206\u7c7b\u548c\u68c0\u6d4b (Joint classification and detection)\u3002\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \\(WordTree\\) \u7ec4\u5408\u6570\u636e\u96c6\uff0c\u5728\u5206\u7c7b\u548c\u68c0\u6d4b\u4e0a\u8bad\u7ec3\u8054\u5408\u6a21\u578b\u3002\u6211\u4eec\u60f3\u8981\u8bad\u7ec3\u4e00\u4e2a\u975e\u5e38\u5927\u89c4\u6a21\u7684\u68c0\u6d4b\u5668\uff0c\u6240\u4ee5\u4f7f\u7528 \\(COCO\\) \u68c0\u6d4b\u6570\u636e\u96c6\u548c\u5b8c\u6574 \\(ImageNet\\) \u7248\u672c\u4e2d\u7684\u524d9000\u7c7b\u521b\u5efa\u6211\u4eec\u7684\u7ec4\u5408\u6570\u636e\u96c6\u3002\u6211\u4eec\u8fd8\u9700\u8981\u8bc4\u4f30\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u4ee5\u4fbf\u4ece \\(ImageNet\\) \u68c0\u6d4b\u6311\u6218\u4e2d\u6dfb\u52a0\u4efb\u4f55\u5c1a\u672a\u5305\u542b\u7684\u7c7b\u3002\u8be5\u6570\u636e\u96c6\u7684\u76f8\u5e94 \\(WordTree\\) \u5177\u67099418\u4e2a\u7c7b\u3002 \\(ImageNet\\) \u6709\u66f4\u5927\u7684\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u901a\u8fc7\u5bf9 \\(COCO\\) \u8fdb\u884c\u8fc7\u91c7\u6837\u6765\u5e73\u8861\u6570\u636e\u96c6\uff0c\u4f7f\u5f97 \\(ImageNet\\) \u4e0e \\(COCO\\) \u7684\u6bd4\u4f8b\u7565\u5927\u4e8e \\(4:1\\) \u3002 \u2003\u6211\u4eec\u4f7f\u7528\u4e0a\u8ff0\u7684\u6570\u636e\u96c6\u8bad\u7ec3 \\(YOLO9000\\) \u3002 \u6211\u4eec\u4f7f\u7528\u57fa\u672c\u7684 \\(YOLOv2\\) \u67b6\u6784\uff0c\u4f46\u53ea\u67093\u4e2a\u5148\u9a8c\u6846\u800c\u4e0d\u662f5\u4e2a\u6765\u9650\u5236\u8f93\u51fa\u5927\u5c0f\u3002\u5f53\u6211\u4eec\u7684\u7f51\u7edc\u5904\u7406\u68c0\u6d4b\u56fe\u50cf\u65f6\uff0c\u6211\u4eec\u4f1a\u50cf\u5e73\u5e38\u4e00\u6837\u53cd\u5411\u4f20\u64ad\u635f\u5931\u3002\u5bf9\u4e8e\u5206\u7c7b\u635f\u5931\uff0c\u6211\u4eec\u53ea\u662f\u5c06\u635f\u5931\u53cd\u5411\u4f20\u64ad\u5230\u6807\u7b7e\u76f8\u5e94\u7ea7\u522b\u6216\u66f4\u9ad8\u7684\u7ea7\u522b\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u6807\u7b7e\u662f\u72d7\uff0c\u6211\u4eec\u4e0d\u4f1a\u5c06\u4efb\u4f55\u9519\u8bef\u7ed9\u6811\u505a\u8fdb\u4e00\u6b65\u9884\u6d4b\uff0c\u5982\u5fb7\u56fd\u7267\u7f8a\u72ac\u4e0e\u9ec4\u91d1\u730e\u72ac\uff0c\u56e0\u4e3a\u6211\u4eec\u6ca1\u6709\u8fd9\u4e9b\u4fe1\u606f\u3002 \u56fe6\uff1a\u4f7f\u7528 \\(WordTree\\) \u5c42\u6b21\u7ed3\u6784\u7ec4\u5408\u6570\u636e\u96c6\u3002\u4f7f\u7528WordNet\u6982\u5ff5\u56fe\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u89c6\u89c9\u6982\u5ff5\u7684\u5206\u5c42\u6811\u3002\u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u6620\u5c04\u5230\u6811\u4e2d\u7684synsets\u6765\u5408\u5e76\u6570\u636e\u96c6\u3002\u51fa\u4e8e\u8bf4\u660e\u76ee\u7684\uff0c\u8fd9\u662f \\(WordTree\\) \u7684\u7b80\u5316\u89c6\u56fe\u3002 \u2003\u5f53\u7f51\u7edc\u5904\u7406\u5206\u7c7b\u56fe\u50cf\u65f6\uff0c\u6211\u4eec\u53ea\u662f\u53cd\u5411\u4f20\u64ad\u5206\u7c7b\u635f\u5931\u3002\u8981\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ea\u9700\u627e\u5230\u9884\u6d4b\u8be5\u7c7b\u522b\u6700\u9ad8\u6982\u7387\u7684\u8fb9\u754c\u6846\uff0c\u7136\u540e\u5728\u9884\u6d4b\u7684\u6811\u4e0a\u8ba1\u7b97\u635f\u5931\u3002\u6211\u4eec\u8fd8\u5047\u8bbe\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u7684 \\(IOU\\) \u81f3\u5c11\u4e3a0.3\uff0c\u5e76\u4e14\u57fa\u4e8e\u8fd9\u4e2a\u5047\u8bbe\u6211\u4eec\u53cd\u5411\u4f20\u64ad\u76ee\u6807\u635f\u5931\u3002 \u2003\u901a\u8fc7\u8fd9\u79cd\u8054\u5408\u8bad\u7ec3\uff0c \\(YOLO9000\\) \u5b66\u4e60\u4f7f\u7528 \\(COCO\\) \u4e2d\u7684\u68c0\u6d4b\u6570\u636e\u6765\u67e5\u627e\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff0c\u5e76\u5b66\u4e60\u4f7f\u7528\u6765\u81ea \\(ImageNet\\) \u7684\u6570\u636e\u5bf9\u5404\u79cd\u8fd9\u4e9b\u76ee\u6807\u8fdb\u884c\u5206\u7c7b\u3002 \u2003\u6211\u4eec\u5728 \\(ImageNet\\) \u68c0\u6d4b\u4efb\u52a1\u4e0a\u8bc4\u4f30 \\(YOLO9000\\) \u3002 \\(ImageNet\\) \u7684\u68c0\u6d4b\u4efb\u52a1\u4e0e \\(COCO\\) \u5171\u4eab44\u4e2a\u76ee\u6807\u7c7b\u522b\uff0c\u8fd9\u610f\u5473\u7740 \\(YOLO9000\\) \u770b\u5230\u7684\u6d4b\u8bd5\u56fe\u50cf\u5927\u591a\u6570\u662f\u5206\u7c7b\u6570\u636e\uff0c\u800c\u4e0d\u662f\u68c0\u6d4b\u6570\u636e\u3002 \\(YOLO9000\\) \u7684\u603b \\(mAP\\) \u662f19.7 \\(mAP\\) \uff0c\u5176\u4e2d\u5728\u4e0d\u76f8\u4ea4\u7684156\u4e2a\u76ee\u6807\u7c7b\u4e0a\uff0c \\(YOLO9000\\) \u4ece\u672a\u89c1\u8fc7\u8fd9\u4e9b\u7c7b\u7684\u4efb\u4f55\u68c0\u6d4b\u6570\u636e\u7684\u6807\u7b7e\uff0c\u4ecd\u83b7\u5f97\u4e8616.0 \\(mAP\\) \u3002\u8fd9\u4e2a \\(mAP\\) \u9ad8\u4e8eDPM\u7684\u7ed3\u679c\uff0c\u4f46 \\(YOLO9000\\) \u662f\u5728\u90e8\u5206\u76d1\u7763[4]\u7684\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u3002\u800c\u4e14\u5b83\u80fd\u540c\u65f6\u68c0\u6d4b9000\u4e2a\u5176\u4ed6\u76ee\u6807\u7c7b\u522b\uff0c\u6240\u6709\u7684\u68c0\u6d4b\u90fd\u662f\u5b9e\u65f6\u7684\u3002 \u2003\u5728\u5206\u6790 \\(YOLO9000\\) \u5728 \\(ImageNet\\) \u4e0a\u7684\u8868\u73b0\u65f6\uff0c\u6211\u4eec\u53d1\u73b0\u5b83\u5f88\u597d\u5730\u5b66\u4e60\u4e86\u65b0\u7684\u52a8\u7269\u79cd\u7c7b\uff0c\u4f46\u662f\u5728\u50cf\u670d\u88c5\u548c\u8bbe\u5907\u8fd9\u6837\u7684\u5b66\u4e60\u7c7b\u522b\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u65b0\u52a8\u7269\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u56e0\u4e3a\u76ee\u6807\u9884\u6d4b\u53ef\u4ee5\u4ece \\(COCO\\) \u4e2d\u7684\u52a8\u7269\u6cdb\u5316\u7684\u5f88\u597d\u3002\u76f8\u53cd\uff0c \\(COCO\\) \u6ca1\u6709\u4efb\u4f55\u7c7b\u578b\u7684\u8863\u670d\u7684\u8fb9\u754c\u6846\u6807\u7b7e\uff0c\u53ea\u9488\u5bf9\u4eba\uff0c\u56e0\u6b64 \\(YOLO9000\\) \u5728\u5206\u7c7b\u201c\u58a8\u955c\u201d\u6216\u201c\u6cf3\u88e4\u201d\u7b49\u7c7b\u522b\u4e0a\u5b58\u5728\u56f0\u96be\u3002 \\(\\begin{array}{ll} \\text { diaper } & 0.0 \\\\ \\text { horizontal bar } & 0.0 \\\\ \\text { rubber eraser } & 0.0 \\\\ \\text { sunglasses } & 0.0 \\\\ \\text { swimming trunks } & 0.0 \\\\ \\ldots & \\\\ \\text { red panda } & 50.7 \\\\ \\text { fox } & 52.1 \\\\ \\text { koala bear } & 54.3 \\\\ \\text { tiger } & 61.0 \\\\ \\text { armadillo } & 61.7 \\end{array}\\) \u88687\uff1a \\(ImageNet\\) \u4e0a\u7684 \\(YOLO9000\\) \u6700\u4f73\u548c\u6700\u5dee\u7c7b\u522b\u3002 156\u4e2a\u5f31\u76d1\u7763\u7c7b\u7684AP\u6700\u9ad8\u548c\u6700\u4f4e\u7684\u7c7b\u3002 \\(YOLO9000\\) \u6a21\u578b\u5f88\u597d\u5730\u9884\u6d4b\u5404\u79cd\u5404\u6837\u7684\u52a8\u7269\uff0c\u4f46\u4e0d\u64c5\u957f\u9884\u6d4b\u8bf8\u5982\u670d\u88c5\u6216\u8bbe\u5907\u7b49\u7684\u65b0\u7c7b\u3002 5.\u603b\u7ed3 \u2003\u6211\u4eec\u4ecb\u7ecd\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf \\(YOLOv2\\) \u548c \\(YOLO9000\\) \u3002 \\(YOLOv2\\) \u5728\u5404\u79cd\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u90fd\u662f\u6700\u5148\u8fdb\u7684\uff0c\u5e76\u4e14\u6bd4\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u66f4\u5feb\u3002\u6b64\u5916\uff0c\u5b83\u53ef\u4ee5\u5728\u5404\u79cd\u56fe\u50cf\u5c3a\u5bf8\u4e0b\u8fd0\u884c\uff0c\u4ee5\u63d0\u4f9b\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5e73\u6ed1\u6298\u4e2d\u3002 \u2003 \\(YOLO9000\\) \u662f\u4e00\u4e2a\u901a\u8fc7\u8054\u5408\u4f18\u5316\u68c0\u6d4b\u548c\u5206\u7c7b\u6765\u68c0\u6d4b\u8d85\u8fc79000\u4e2a\u76ee\u6807\u7c7b\u522b\u7684\u5b9e\u65f6\u6846\u67b6\u3002\u6211\u4eec\u4f7f\u7528 \\(WordTree\\) \u5c06\u5404\u79cd\u6765\u6e90\u7684\u6570\u636e\u548c\u6211\u4eec\u7684\u8054\u5408\u4f18\u5316\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u5728 \\(ImageNet\\) \u548c \\(COCO\\) \u4e0a\u540c\u65f6\u8fdb\u884c\u8bad\u7ec3\u3002 \\(YOLO9000\\) \u5411\u7f29\u5c0f\u68c0\u6d4b\u548c\u5206\u7c7b\u4e4b\u95f4\u7684\u6570\u636e\u96c6\u5927\u5c0f\u7684\u5dee\u8ddd\u8fc8\u51fa\u4e86\u575a\u5b9e\u7684\u4e00\u6b65\u3002 \u2003\u6211\u4eec\u7684\u8bb8\u591a\u6280\u672f\u90fd\u662f\u6cdb\u5316\u5230\u76ee\u6807\u68c0\u6d4b\u4e4b\u5916\u7684\u9886\u57df\u3002 \\(ImageNet\\) \u7684 \\(WordTree\\) \u8868\u793a\u65b9\u6cd5\u4e3a\u56fe\u50cf\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\uff0c\u66f4\u8be6\u7ec6\u7684\u8f93\u51fa\u7a7a\u95f4\u3002\u4f7f\u7528\u5206\u5c42\u5206\u7c7b\u7684\u6570\u636e\u96c6\u7ec4\u5408\u5728\u5206\u7c7b\u548c\u5206\u5272\u9886\u57df\u5c06\u4f1a\u5f88\u6709\u7528\u3002\u50cf\u591a\u5c3a\u5ea6\u8bad\u7ec3\u8fd9\u6837\u7684\u8bad\u7ec3\u6280\u672f\u53ef\u4ee5\u4e3a\u5404\u79cd\u89c6\u89c9\u4efb\u52a1\u63d0\u4f9b\u5e2e\u52a9\u3002 \u2003\u5bf9\u4e8e\u672a\u6765\u7684\u5de5\u4f5c\uff0c\u6211\u4eec\u5e0c\u671b\u4f7f\u7528\u7c7b\u4f3c\u7684\u6280\u672f\u8fdb\u884c\u5f31\u76d1\u7763\u56fe\u50cf\u5206\u5272\u3002\u6211\u4eec\u8fd8\u8ba1\u5212\u4f7f\u7528\u66f4\u5f3a\u5927\u7684\u5339\u914d\u7b56\u7565\u6765\u6539\u5584\u6211\u4eec\u7684\u68c0\u6d4b\u7ed3\u679c\uff0c\u4ee5\u5728\u8bad\u7ec3\u671f\u95f4\u5c06\u5f31\u6807\u7b7e\u5206\u914d\u7ed9\u5206\u7c7b\u6570\u636e\u3002\u8ba1\u7b97\u673a\u89c6\u89c9\u62e5\u6709\u5927\u91cf\u7684\u6807\u8bb0\u6570\u636e\u3002\u6211\u4eec\u5c06\u7ee7\u7eed\u5bfb\u627e\u65b9\u6cd5\uff0c\u5c06\u4e0d\u540c\u7684\u6570\u636e\u6765\u6e90\u548c\u6570\u636e\u7ed3\u6784\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u5f62\u6210\u66f4\u5f3a\u5927\u7684\u89c6\u89c9\u4e16\u754c\u6a21\u578b\u3002 References [1] S. Bell, C. L. Zitnick, K. Bala, and R. Girshick. Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks. arXiv preprint arXiv:1512.04143, 2015. 6 [2] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 248\u2013255. IEEE, 2009. 1 [3] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) chal-lenge. International journal of computer vision, 88(2):303\u2013338, 2010. 1 [4] P. F. Felzenszwalb, R. B. Girshick, and D. McAllester. Discriminatively trained deformable part models, release 4. http://people.cs.uchicago.edu/ pff/latent-release4/. 8 [5] R. B. Girshick. Fast R-CNN. CoRR, abs/1504.08083, 2015. 4, 5, 6 [6] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learn-ing for image recognition. arXiv preprint arXiv:1512.03385, 2015. 2, 4, 5 [7] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015. 2, 5 [8] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097\u20131105, 2012. 2 [9] M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.4400, 2013. 5 [10] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ra-manan, P. Doll\u00b4ar, and C. L. Zitnick. Microsoft coco: Com-mon objects in context. In European Conference on Com-puter Vision, pages 740\u2013755. Springer, 2014. 1, 6 [11] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, and S. E. Reed. SSD: single shot multibox detector. CoRR, abs/1512.02325, 2015. 4, 5, 6 [12] G. A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. J. Miller. Introduction to wordnet: An on-line lexical database. International journal of lexicography, 3(4):235\u2013244, 1990. 6 [13] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 5 [14] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. arXiv preprint arXiv:1506.02640, 2015. 4, 5 [15] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: To-wards real-time object detection with region proposal net-works. arXiv preprint arXiv:1506.01497, 2015. 2, 3, 4, 5, 6 [16] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. 2 [17] K. Simonyan and A. Zisserman. V ery deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. 2, 5 [18] C. Szegedy, S. Ioffe, and V . V anhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR, abs/1602.07261, 2016. 2 [19] C. Szegedy, W. Liu, Y . Jia, P . Sermanet, S. Reed, D. Anguelov, D. Erhan, V . V anhoucke, and A. Rabinovich.Going deeper with convolutions. CoRR, abs/1409.4842, 2014. 5 [20] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):64\u201373, 2016. 1","title":"YOLOv2"},{"location":"thesis_interpretation/02_yolo.html#_1","text":"\u6211\u4eec\u63a8\u51fa\u7684 \\(YOLO9000\\) \u662f\u4e00\u6b3e\u5148\u8fdb\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7cfb\u7edf\uff0c\u53ef\u68c0\u6d4b9000\u591a\u79cd\u76ee\u6807\u7c7b\u522b\u3002\u9996\u5148\uff0c\u6211\u4eec\u63d0\u51fa\u5bf9 \\(YOLO\\) \u68c0\u6d4b\u65b9\u6cd5\u7684\u5404\u79cd\u6539\u8fdb\uff0c\u8fd9\u4e9b\u6539\u8fdb\u6709\u72ec\u521b\u7684\uff0c\u4e5f\u6709\u7684\u662f\u6765\u6e90\u4e8e\u4ee5\u524d\u7684\u7814\u7a76\u3002\u6539\u8fdb\u540e\u7684\u6a21\u578b \\(YOLOv2\\) \u5728 \\(PASCAL VOC\\) \u548c \\(COCO\\) \u7b49\u6807\u51c6\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5904\u4e8e\u6280\u672f\u9886\u5148\u5730\u4f4d\u3002\u901a\u8fc7\u4f7f\u7528\u4e00\u79cd\u65b0\u9896\u7684\u591a\u5c3a\u5ea6\u8bad\u7ec3\u65b9\u6cd5\uff0c\u540c\u6837\u7684 \\(YOLOv2\\) \u6a21\u578b\u53ef\u4ee5\u4ee5\u4e0d\u540c\u7684\u5c3a\u5bf8\u8fd0\u884c\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u6298\u8877\u3002\u5728 \\(67 FPS\\) \u65f6\uff0c \\(YOLOv2\\) \u5728 \\(VOC \\ 2007\\) \u4e0a\u83b7\u5f97\u4e8676.8 \\(mAP\\) \u3002\u5728 \\(40FPS\\) \u65f6\uff0c \\(YOLOv2\\) \u83b7\u5f97\u4e8678.6 \\(mAP\\) \uff0c\u8d85\u8d8a\u4e86\u91c7\u7528 \\(ResNet\\) \u548c \\(SSD\u7684Faster \\ R-CNN\\) \u7b49\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u8fd0\u884c\u901f\u5ea6\u4ecd\u7136\u66f4\u5feb\u3002\u6700\u540e\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u8054\u5408\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u548c\u5206\u7c7b\u7684\u65b9\u6cd5\u3002\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u5728 \\(COCO\\) \u68c0\u6d4b\u6570\u636e\u96c6\u548c \\(ImageNet\\) \u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u540c\u65f6\u8bad\u7ec3 \\(YOLO9000\\) \u3002\u6211\u4eec\u7684\u8054\u5408\u8bad\u7ec3\u4f7f \\(YOLO9000\\) \u80fd\u591f\u9884\u6d4b\u672a\u6807\u6ce8\u68c0\u6d4b\u6570\u636e\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u5e76\u4e14\u6211\u4eec\u5728 \\(ImageNet\\) \u68c0\u6d4b\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u3002 \\(YOLO9000\\) \u5728 \\(ImageNet\\) \u68c0\u6d4b\u9a8c\u8bc1\u96c6\u4e0a\u83b7\u5f9719.7 \\(mAP\\) \uff0c\u5c3d\u7ba1200\u4e2a\u7c7b\u4e2d\u53ea\u670944\u4e2a\u5177\u6709\u68c0\u6d4b\u6570\u636e\u3002\u5728 \\(COCO\\) \u4e0a\u6ca1\u6709\u7684156\u79cd\u7c7b\u4e0a\uff0c \\(YOLO9000\\) \u5f97\u5230 16.0 \\(mAP\\) \uff0c\u4f46\u662f \\(YOLO\\) \u53ef\u4ee5\u68c0\u6d4b\u8d85\u8fc7200\u4e2a\u79cd\u7c7b;\u5b83\u9884\u6d4b\u8d85\u8fc79000 \u591a\u79cd\u4e0d\u540c\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u800c\u4e14\u5b83\u4ecd\u7136\u662f\u5b9e\u65f6\u8fd0\u884c\u7684\u3002 \u56fe1: \\(YOLO9000\\) \u3002 \\(YOLO9000\\) \u53ef\u4ee5\u5b9e\u65f6\u68c0\u6d4b\u5404\u79cd\u5404\u6837\u7684\u76ee\u6807\u7c7b\u522b\u3002","title":"\u6458\u8981"},{"location":"thesis_interpretation/02_yolo.html#1","text":"\u901a\u7528\u7684\u76ee\u6807\u68c0\u6d4b\u5e94\u8be5\u5feb\u901f\uff0c\u51c6\u786e\uff0c\u5e76\u4e14\u80fd\u591f\u8bc6\u522b\u5404\u79cd\u5404\u6837\u7684\u76ee\u6807\u3002\u81ea\u4ece\u5f15\u5165\u795e\u7ecf\u7f51\u7edc\uff0c\u68c0\u6d4b\u6846\u67b6\u53d8\u5f97\u8d8a\u6765\u8d8a\u5feb\u901f\u548c\u51c6\u786e\u3002\u4f46\u662f\uff0c\u5927\u591a\u6570\u68c0\u6d4b\u65b9\u6cd5\u4ec5\u9650\u4e8e\u68c0\u6d4b\u4e00\u5c0f\u90e8\u5206\u76ee\u6807\u3002 \u2003\u4e0e\u5206\u7c7b\u548c\u6807\u8bb0\u7b49\u5176\u4ed6\u4efb\u52a1\u7684\u6570\u636e\u96c6\u76f8\u6bd4\uff0c\u76ee\u524d\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u662f\u6709\u9650\u7684\u3002\u6700\u5e38\u89c1\u7684\u68c0\u6d4b\u6570\u636e\u96c6\u5305\u542b\u6210\u5343\u4e0a\u4e07\u5230\u6570\u5341\u4e07\u5f20\u5177\u6709\u6210\u767e\u4e0a\u5343\u4e2a\u6807\u7b7e\u7684\u56fe\u50cf[3][10][2]\u3002\u800c\u5206\u7c7b\u6570\u636e\u96c6\u6709\u6570\u4ee5\u767e\u4e07\u8ba1\u7684\u56fe\u50cf\uff0c\u6570\u5341\u6216\u6570\u767e\u4e07\u4e2a\u7c7b\u522b[20][2]\u3002 \u2003\u6211\u4eec\u5e0c\u671b\u68c0\u6d4b\u7684\u7c7b\u522b\u80fd\u591f\u6269\u5c55\u5230\u76ee\u6807\u5206\u7c7b\u7684\u7ea7\u522b\u3002\u4f46\u662f\uff0c\u6807\u6ce8\u68c0\u6d4b\u56fe\u50cf\u8981\u6bd4\u6807\u6ce8\u5206\u7c7b\u6216\u8d34\u6807\u7b7e\u8981\u6602\u8d35\u5f97\u591a\uff08 \u6807\u7b7e\u901a\u5e38\u662f\u7528\u6237\u514d\u8d39\u63d0\u4f9b ) \u3002\u56e0\u6b64\uff0c\u6211\u4eec\u4e0d\u592a\u53ef\u80fd\u5728\u8fd1\u671f\u5185\u770b\u5230\u4e0e\u5206\u7c7b\u6570\u636e\u96c6\u76f8\u540c\u89c4\u6a21\u7684\u68c0\u6d4b\u6570\u636e\u96c6\u3002 \u2003\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u2014\u2014\u901a\u8fc7\u5229\u7528\u6211\u4eec\u5df2\u6709\u7684\u5927\u91cf\u5206\u7c7b\u6570\u636e\u6765\u6269\u5927\u5f53\u524d\u68c0\u6d4b\u7cfb\u7edf\u7684\u8303\u56f4\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u76ee\u6807\u5206\u7c7b\u7684\u5206\u5c42\u89c6\u56fe\uff0c\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u5c06\u4e0d\u540c\u7684\u6570\u636e\u96c6\u7ec4\u5408\u5728\u4e00\u8d77\u3002 \u2003\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5b83\u5141\u8bb8\u6211\u4eec\u5728\u68c0\u6d4b\u548c\u5206\u7c7b\u6570\u636e\u4e0a\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u5668\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u6807\u8bb0\u68c0\u6d4b\u56fe\u50cf\u6765\u5b66\u4e60\u7cbe\u786e\u5b9a\u4f4d\u76ee\u6807\uff0c\u540c\u65f6\u4f7f\u7528\u5206\u7c7b\u56fe\u50cf\u6765\u589e\u52a0\u8bcd\u6c47\u91cf\u548c\u9c81\u68d2\u6027\u3002 \u2003\u6211\u4eec\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8bad\u7ec3 \\(YOLO9000\\) b\u4e00\u79cd\u53ef\u4ee5\u68c0\u6d4b\u8d85\u8fc79000\u79cd\u4e0d\u540c\u7684\u76ee\u6807\u7c7b\u522b\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u3002 \u9996\u5148\uff0c\u6211\u4eec\u6539\u8fdbYOLO\u57fa\u7840\u68c0\u6d4b\u7cfb\u7edf\uff0c\u751f\u6210\u6700\u5148\u8fdb\u7684\u5b9e\u65f6\u68c0\u6d4b\u5668 \\(YOLOv2\\) \u3002 \u7136\u540e\uff0c\u91c7\u7528\u6211\u4eec\u7684\u6570\u636e\u96c6\u7ec4\u5408\u65b9\u6cd5\u548c\u8054\u5408\u8bad\u7ec3\u7b97\u6cd5\uff0c\u4f7f\u7528\u6765\u81ea \\(ImageNet\\) \u76849000\u591a\u4e2a\u7c7b\u4ee5\u53ca \\(COCO\\) \u7684\u68c0\u6d4b\u6570\u636e\u6765\u8bad\u7ec3\u6a21\u578b\u3002 \u6211\u4eec\u6240\u6709\u4ee3\u7801\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u90fd\u53ef\u5728\u7ebf\u83b7\u5f97\uff1ahttp://pjreddie.com/yolo9000/\u3002","title":"1.\u5f15\u8a00"},{"location":"thesis_interpretation/02_yolo.html#2","text":"\u4e0e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\uff0c \\(YOLO\\) \u5b58\u5728\u5404\u79cd\u7f3a\u70b9\u3002 \\(YOLO\\) \u4e0e \\(Fast \\ R-CNN\\) \u7684\u8bef\u5dee\u6bd4\u8f83\u5206\u6790\u8868\u660e\uff0c \\(YOLO\\) \u4ea7\u751f\u4e86\u5927\u91cf\u7684\u5b9a\u4f4d\u9519\u8bef\u3002\u6b64\u5916\uff0c\u4e0e\u751f\u6210\u5019\u9009\u533a\u57df\u65b9\u6cd5\u76f8\u6bd4\uff0c \\(YOLO\\) \u53ec\u56de\u7387( recall )\u76f8\u5bf9\u8f83\u4f4e\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u4e3b\u8981\u5173\u6ce8\u6539\u5584\u53ec\u56de\u7387\u548c\u5b9a\u4f4d\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u7c7b\u51c6\u786e\u6027\u3002 \u2003\u8ba1\u7b97\u673a\u89c6\u89c9\u901a\u5e38\u8d8b\u5411\u4e8e\u66f4\u5927\u66f4\u6df1\u7684\u7f51\u7edc[6] [18] [17]\u3002 \u66f4\u597d\u7684\u6027\u80fd\u901a\u5e38\u53d6\u51b3\u4e8e\u8bad\u7ec3\u66f4\u5927\u7684\u7f51\u7edc\u6216\u5c06\u591a\u4e2a\u6a21\u578b\u7ec4\u5408\u5728\u4e00\u8d77\u3002 \u4f46\u662f\uff0c\u5bf9\u4e8e \\(YOLOv2\\) \uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u66f4\u7cbe\u786e\u7684\u68c0\u6d4b\u5668\uff0c\u800c\u4e14\u4fdd\u6301\u5f88\u5feb\u7684\u901f\u5ea6\u3002 \u6211\u4eec\u4e0d\u662f\u8981\u6269\u5927\u7f51\u7edc\uff0c\u800c\u662f\u7b80\u5316\u7f51\u7edc\uff0c\u7136\u540e\u8ba9\u8868\u5f81( \u5373\u76ee\u6807\u7279\u5f81 )\u66f4\u6613\u4e8e\u5b66\u4e60\u3002 \u6211\u4eec\u5c06\u4ee5\u5f80\u5de5\u4f5c\u4e2d\u7684\u5404\u79cd\u521b\u610f\u4e0e\u6211\u4eec\u81ea\u5df1\u65b0\u9896\u7684\u65b9\u6cd5\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u63d0\u9ad8 \\(YOLO\\) \u7684\u6027\u80fd\u3002 \u7ed3\u679c\u6c47\u603b\u89c1 \u88682\u3002 \u2003 \u6279\u91cf\u6807\u51c6\u5316 \uff08Batch Normalization\uff09\u3002\u6279\u91cf\u6807\u51c6\u5316\u53ef\u4ee5\u663e\u7740\u6539\u5584\u6536\u655b\u6027\uff0c\u800c\u4e14\u4e0d\u518d\u9700\u8981\u5176\u4ed6\u5f62\u5f0f\u7684\u6b63\u5219\u5316[7]\u3002 \u901a\u8fc7\u5728 \\(YOLO\\) \u4e2d\u7684\u6240\u6709\u5377\u79ef\u5c42\u4e0a\u6dfb\u52a0\u6279\u91cf\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u5728 \\(mAP\\) \u4e2d\u83b7\u5f97 2\uff05\u4ee5\u4e0a\u7684\u6539\u8fdb\u3002 \u6279\u91cf\u6807\u51c6\u5316\u4e5f\u6709\u52a9\u4e8e\u89c4\u8303\u6a21\u578b\u3002 \u901a\u8fc7\u6279\u91cf\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u4ece\u6a21\u578b\u4e2d\u5220\u9664 \\(dropout\\) \u800c\u4e0d\u4f1a\u53d1\u751f\u8fc7\u62df\u5408\u3002 \u2003 \u9ad8\u5206\u8fa8\u7387\u5206\u7c7b\u5668 \uff08High Resolution Classifier\uff09\u3002\u6240\u6709\u7684\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u65b9\u6cd5\u90fd\u4f7f\u7528\u5728 \\(ImageNet\\) \u4e0a\u9884\u5148\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668[16]\u3002 \u4eceAlexNet\u5f00\u59cb\uff0c\u5927\u591a\u6570\u5206\u7c7b\u5668\u7528\u5c0f\u4e8e \\(256\u00d7256\\) \u7684\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165[8]\u3002 \u6700\u521d\u7684 \\(YOLO\\) \u4ee5 \\(224\u00d7224\\) \u7684\u56fe\u50cf\u8bad\u7ec3\u5206\u7c7b\u5668\u7f51\u7edc\uff0c\u5e76\u5c06\u5206\u8fa8\u7387\u63d0\u9ad8\u5230 \\(448\\) \u4ee5\u8fdb\u884c\u68c0\u6d4b\u8bad\u7ec3\u3002 \u8fd9\u610f\u5473\u7740\u7f51\u7edc\u5fc5\u987b\u5207\u6362\u5230\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u4e60\uff0c\u540c\u65f6\u80fd\u8c03\u6574\u5230\u65b0\u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002 \u2003\u5bf9\u4e8e \\(YOLOv2\\) \uff0c\u6211\u4eec\u9996\u5148\u4ee5 \\(448\u00d7448\\) \u7684\u5168\u5206\u8fa8\u7387\u5728 \\(ImageNet\\) \u4e0a\u8fdb\u884c \\(10\\) \u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u5fae\u8c03\u3002\u8fd9\u7ed9\u4e88\u7f51\u7edc\u4e00\u4e9b\u65f6\u95f4\uff0c\u4ee5\u8c03\u6574\u5176\u6ee4\u6ce2\u5668\u6765\u66f4\u597d\u5730\u5904\u7406\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8f93\u5165\u3002\u7136\u540e\uff0c\u6211\u4eec\u518d\u5bf9\u8be5\u68c0\u6d4b\u7f51\u7edc\u8fdb\u884c\u5fae\u8c03\u3002 \u8fd9\u4e2a\u9ad8\u5206\u8fa8\u7387\u7684\u5206\u7c7b\u7f51\u7edc\u4f7f \\(mAP\\) \u589e\u52a0\u4e86\u8fd14\uff05\u3002 \u2003 \u5377\u79ef\u4e0e\u951a\u6846 \u3002 \\(YOLO\\) \u76f4\u63a5\u4f7f\u7528\u5377\u79ef\u7279\u5f81\u63d0\u53d6\u5668\u9876\u90e8\u7684\u5168\u8fde\u63a5\u5c42\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u7684\u5750\u6807\u3002\u800c \\(Fast \\ R-CNN\\) \u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5750\u6807\uff0c\u662f\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684\u5148\u9a8c\u6765\u9884\u6d4b\u8fb9\u754c\u6846[15]\u3002\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u5750\u6807 \\(Fast \\ R-CNN\\) \u9884\u6d4b\u8fb9\u754c\u6846\u4f7f\u7528\u624b\u5de5\u6311\u9009\u7684\u5148\u9a8c\u533a\u57df[15]\u3002 Faster R-CNN\u4e2d\u7684\u5019\u9009\u533a\u57df\u751f\u6210\u7f51\u7edc\uff08RPN\uff09\u4ec5\u4f7f\u7528\u5377\u79ef\u5c42\u6765\u9884\u6d4b\u951a\u6846\u7684\u504f\u79fb\u548c\u7f6e\u4fe1\u5ea6\u3002\u7531\u4e8e\u9884\u6d4b\u5c42\u662f\u5377\u79ef\u7684\uff0c\u6240\u4ee5RPN\u53ef\u4ee5\u5728\u7279\u5f81\u56fe\u4e2d\u7684\u6bcf\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u8fd9\u4e9b\u504f\u79fb\u3002\u4f7f\u7528\u9884\u6d4b\u504f\u79fb\u4ee3\u66ff\u5750\u6807\uff0c\u53ef\u4ee5\u7b80\u5316\u95ee\u9898\u5e76\u4f7f\u7f51\u7edc\u66f4\u6613\u4e8e\u5b66\u4e60\u3002 \u2003\u6211\u4eec\u4ece \\(YOLO\\) \u4e2d\u79fb\u9664\u5168\u8fde\u63a5\u5c42\uff0c\u5e76\u4f7f\u7528\u951a\u6846\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u3002 \u9996\u5148\u6211\u4eec\u6d88\u9664\u4e00\u4e2a\u6c60\u5316\u5c42\uff0c\u4ee5\u4f7f\u7f51\u7edc\u5377\u79ef\u5c42\u7684\u8f93\u51fa\u5177\u6709\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u3002 \u6211\u4eec\u8fd8\u7f29\u5c0f\u7f51\u7edc\uff0c\u4f7f\u5176\u5728\u5206\u8fa8\u7387\u4e3a \\(416X416\\) \u7684\u8f93\u5165\u56fe\u50cf\u4e0a\u8fd0\u884c\uff0c\u800c\u4e0d\u662f \\(448\u00d7448\\) \u3002\u6211\u4eec\u8fd9\u6837\u505a\u662f\u56e0\u4e3a\u6211\u4eec\u60f3\u8981\u5728\u7279\u5f81\u56fe\u4e2d\u6709\u5947\u6570\u4e2a\u4f4d\u7f6e\uff0c\u4ece\u800c\u6709\u4e00\u4e2a\u5355\u4e00\u7684\u4e2d\u5fc3\u5355\u5143\u683c\u3002\u76ee\u6807\uff0c\u5c24\u5176\u662f\u5927\u7684\u76ee\u6807\uff0c\u5f80\u5f80\u5360\u636e\u56fe\u50cf\u7684\u4e2d\u5fc3\uff0c\u6240\u4ee5\u6700\u597d\u5728\u6b63\u4e2d\u5fc3\u62e5\u6709\u5355\u72ec\u4e00\u4e2a\u4f4d\u7f6e\u6765\u9884\u6d4b\u8fd9\u4e9b\u76ee\u6807\uff0c\u800c\u4e0d\u662f\u5728\u4e2d\u5fc3\u9644\u8fd1\u7684\u56db\u4e2a\u4f4d\u7f6e\u3002 \\(YOLO\\) \u7684\u5377\u79ef\u5c42\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e86 \\(32\\) \u500d\u7684\u91c7\u6837\uff0c\u6240\u4ee5\u901a\u8fc7\u4f7f\u7528 \\(416\\) \u7684\u8f93\u5165\u56fe\u50cf\uff0c\u6211\u4eec\u5f97\u5230 \\(13\u00d713\\) \u7684\u8f93\u51fa\u7279\u5f81\u56fe\u3002 \u2003\u5f53\u6211\u4eec\u79fb\u52a8\u5230\u951a\u6846\u65f6\uff0c\u6211\u4eec\u5c06\u7c7b\u9884\u6d4b\u673a\u5236\u4e0e\u7a7a\u95f4\u4f4d\u7f6e\u5206\u5f00\u5904\u7406\uff0c\u5355\u72ec\u9884\u6d4b\u6bcf\u4e2a\u951a\u6846\u7684\u7c7b\u53ca\u5176\u76ee\u6807\u3002 \u9075\u5faa\u539f\u6765\u7684 \\(YOLO\\) \u7684\u505a\u6cd5\uff0c\u76ee\u6807\u9884\u6d4b\u4f9d\u7136\u9884\u6d4b\u4e86\u771f\u5b9e\u6807\u7b7e\u6846\uff08ground truth box\uff09\u548c\u5019\u9009\u6846\u7684 \\(IOU\\) \uff0c\u800c\u7c7b\u522b\u9884\u6d4b\u4e5f\u662f\u9884\u6d4b\u4e86\u5f53\u6709\u76ee\u6807\u5b58\u5728\u65f6\uff0c\u8be5\u7c7b\u522b\u7684\u6761\u4ef6\u6982\u7387\u3002 \u2003\u4f7f\u7528\u951a\u6846\uff0c\u7cbe\u5ea6\u503c\u4f1a\u5c0f\u5e45\u4e0b\u964d\u3002\u56e0\u4e3a\u539f\u59cb\u7684 \\(YOLO\\) \u4ec5\u4e3a\u6bcf\u4e2a\u56fe\u7247\u9884\u6d4b98\u4e2a\u6846\uff0c\u4f46\u4f7f\u7528\u951a\u6846\u540e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u9884\u6d4b\u7684\u6846\u6570\u8d85\u8fc7 1000 \u4e2a\u3002 \u5728\u6ca1\u6709\u951a\u6846\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u7684\u4e2d\u7b49\u6a21\u578b\u5c06\u83b7\u5f97 69.5 \u7684 \\(mAP\\) \uff0c\u53ec\u56de\u7387\u4e3a81\uff05\u3002 \u4f7f\u7528\u951a\u6846\u540e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u83b7\u5f97\u4e86 \\(69.2\\) \u7684 \\(mAP\\) \uff0c\u53ec\u56de\u7387\u4e3a88\uff05\u3002\u5c3d\u7ba1 \\(mAP\\) \u51cf\u5c11\uff0c\u4f46\u53ec\u56de\u7387\u7684\u589e\u52a0\u610f\u5473\u7740\u6211\u4eec\u7684\u6a21\u578b\u6709\u66f4\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002 \u56fe2\uff1a \\(VOC\\) \u548c \\(COCO\\) \u4e0a\u7684\u805a\u7c7b\u6846\u5c3a\u5bf8\u3002\u6211\u4eec\u5728\u8fb9\u754c\u6846\u7684\u7ef4\u4e0a\u8fd0\u884c \\(k-means\\) \u805a\u7c7b\uff0c\u4ee5\u83b7\u5f97\u6211\u4eec\u6a21\u578b\u7684\u826f\u597d\u5148\u9a8c\u3002\u5de6\u56fe\u663e\u793a\u4e86\u6211\u4eec\u901a\u8fc7k\u7684\u5404\u79cd\u9009\u62e9\u83b7\u5f97\u7684\u5e73\u5747 \\(IOU\\) \u3002\u6211\u4eec\u53d1\u73b0 \\(k = 5\\) \u4e3a\u53ec\u56de\u4e0e\u6a21\u578b\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6298\u4e2d\u3002\u53f3\u56fe\u663e\u793a\u4e86 \\(VOC\\) \u548c \\(COCO\\) \u7684\u76f8\u5bf9\u8d28\u5fc3\u3002\u8fd9\u4e24\u79cd\u65b9\u6848\u90fd\u559c\u6b22\u66f4\u8584\uff0c\u66f4\u9ad8\u7684\u6846\uff0c\u5e76\u4e14 \\(COCO\\) \u7684\u5c3a\u5bf8\u7684\u53d8\u5316\u6bd4 \\(VOC\\) \u66f4\u5927\u3002 \\(k-means\\) \u7b97\u6cd5: \\(K-means\\) \u7b97\u6cd5\u662f\u5f88\u5178\u578b\u7684\u57fa\u4e8e\u8ddd\u79bb\u7684\u805a\u7c7b\u7b97\u6cd5\uff0c\u91c7\u7528\u8ddd\u79bb\u4f5c\u4e3a\u76f8\u4f3c\u6027\u7684\u8bc4\u4ef7\u6307\u6807\uff0c\u5373\u8ba4\u4e3a\u4e24\u4e2a\u5bf9\u8c61\u7684\u8ddd\u79bb\u8d8a\u8fd1\uff0c\u5176\u76f8\u4f3c\u5ea6\u5c31\u8d8a\u5927\u3002\u8be5\u7b97\u6cd5\u8ba4\u4e3a\u7c07\u662f\u7531\u8ddd\u79bb\u9760\u8fd1\u7684\u5bf9\u8c61\u7ec4\u6210\u7684\uff0c\u56e0\u6b64\u628a\u5f97\u5230\u7d27\u51d1\u4e14\u72ec\u7acb\u7684\u7c07\u4f5c\u4e3a\u6700\u7ec8\u76ee\u6807\u3002 \u2003 \u7ef4\u5ea6\u805a\u7c7b \uff08Dimension Clusters\uff09\u3002\u5f53\u628a\u951a\u6846\u4e0eYOLO\u4e00\u8d77\u4f7f\u7528\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u4e24\u4e2a\u95ee\u9898\u3002 \u9996\u5148\u662f\u6846\u7684\u5c3a\u5bf8\u662f\u624b\u5de5\u6311\u9009\u7684\u3002\u867d\u7136\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u9002\u5f53\u5730\u8c03\u6574\u65b9\u6846\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u4ece\u4e00\u5f00\u59cb\u5c31\u4e3a\u7f51\u7edc\u9009\u62e9\u66f4\u597d\u7684\u5148\u9a8c\u6846\uff0c\u5c31\u53ef\u4ee5\u8ba9\u7f51\u7edc\u66f4\u5bb9\u6613\u5b66\u4e60\u5230\u66f4\u597d\u7684\u68c0\u6d4b\u7ed3\u679c\u3002 \u2003\u6211\u4eec\u4e0d\u7528\u624b\u5de5\u9009\u62e9\u5148\u9a8c\u6846\uff0c\u800c\u662f\u5728\u8bad\u7ec3\u96c6\u7684\u8fb9\u754c\u6846\u4e0a\u8fd0\u884ck-means\u805a\u7c7b\uff0c\u81ea\u52a8\u627e\u5230\u826f\u597d\u7684\u5148\u9a8c\u6846\u3002 \u5982\u679c\u6211\u4eec\u4f7f\u7528\u5177\u6709\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u6807\u51c6 \\(k-means\\) \uff0c\u90a3\u4e48\u8f83\u5927\u7684\u6846\u6bd4\u8f83\u5c0f\u7684\u6846\u4ea7\u751f\u66f4\u591a\u7684\u8bef\u5dee\u3002 \u7136\u800c\uff0c\u6211\u4eec\u771f\u6b63\u60f3\u8981\u7684\u662f\u72ec\u7acb\u4e8e\u6846\u7684\u5927\u5c0f\u7684\uff0c\u80fd\u83b7\u5f97\u826f\u597d\u7684 \\(IOU\\) \u5206\u6570\u7684\u5148\u9a8c\u6846\u3002 \u56e0\u6b64\u5bf9\u4e8e\u8ddd\u79bb\u5ea6\u91cf\u6211\u4eec\u4f7f\u7528: \\(d(\\text { box, centroid }) = 1-\\operatorname{IOU}(\\text { box }, \\text { centroid })\\) \u2003\u6211\u4eec\u7528\u4e0d\u540c\u7684 \\(k\\) \u503c\u8fd0\u884c \\(k-means\\) \uff0c\u5e76\u7ed8\u5236\u6700\u63a5\u8fd1\u8d28\u5fc3\u7684\u5e73\u5747 \\(IOU\\) \uff08\u89c1\u56fe2\uff09\u3002\u4e3a\u4e86\u5728\u6a21\u578b\u590d\u6742\u5ea6\u548c\u9ad8\u53ec\u56de\u7387\u4e4b\u95f4\u7684\u826f\u597d\u6298\u8877\uff0c\u6211\u4eec\u9009\u62e9 \\(k = 5\\) \u3002\u805a\u7c7b\u7684\u8d28\u5fc3\u4e0e\u624b\u5de5\u9009\u53d6\u7684\u951a\u6846\u663e\u7740\u4e0d\u540c\uff0c\u5b83\u6709\u66f4\u5c11\u7684\u77ed\u4e14\u5bbd\u7684\u6846\uff0c\u800c\u4e14\u6709\u66f4\u591a\u65e2\u957f\u53c8\u7a84\u7684\u6846\u3002 \u2003\u88681\u4e2d\uff0c\u6211\u4eec\u5c06\u805a\u7c7b\u7b56\u7565\u7684\u5148\u9a8c\u6846\u4e2d\u5fc3\u6570\u548c\u624b\u5de5\u9009\u53d6\u7684\u951a\u6846\u6570\u5728\u6700\u63a5\u8fd1\u7684\u5e73\u5747 \\(IOU\\) \u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002\u4ec55\u4e2a\u5148\u9a8c\u6846\u4e2d\u5fc3\u7684\u5e73\u5747 \\(IOU\\) \u4e3a61.0\uff0c\u5176\u6027\u80fd\u7c7b\u4f3c\u4e8e9\u4e2a\u951a\u6846\u768460.9\u3002 \u4f7f\u75289\u4e2a\u8d28\u5fc3\u4f1a\u5f97\u5230\u66f4\u9ad8\u7684\u5e73\u5747 \\(IOU\\) \u3002\u8fd9\u8868\u660e\u4f7f\u7528 \\(k-means\\) \u751f\u6210\u8fb9\u754c\u6846\u53ef\u4ee5\u66f4\u597d\u5730\u8868\u793a\u6a21\u578b\u5e76\u4f7f\u5176\u66f4\u5bb9\u6613\u5b66\u4e60\u3002 \\(\\begin{array}{lcc} \\text { Box Generation } & \\# & \\text { Avg IOU } \\\\ \\hline \\text { Cluster SSE } & 5 & 58.7 \\\\ \\text { Cluster IOU } & 5 & 61.0 \\\\ \\text { Anchor Boxes [15] } & 9 & 60.9 \\\\ \\text { Cluster IOU } & 9 & 67.2 \\end{array}\\) \u88681\uff1a \\(VOC \\ 2007\\) \u6700\u63a5\u8fd1\u5148\u9a8c\u7684\u6846\u7684\u5e73\u5747 \\(IOU\\) \u3002 \\(VOC \\ 2007\\) \u4e0a\u7684\u76ee\u6807\u7684\u5e73\u5747IOU\u4e0e\u5176\u6700\u63a5\u8fd1\u7684\uff0c\u672a\u7ecf\u4fee\u6539\u7684\u4f7f\u7528\u4e0d\u540c\u751f\u6210\u65b9\u6cd5\u7684\u76ee\u6807\u4e4b\u95f4\u7684\u5e73\u5747 \\(IOU\\) \u3002\u805a\u7c7b\u5f97\u7ed3\u679c\u6bd4\u4f7f\u7528\u624b\u5de5\u9009\u53d6\u7684\u5148\u9a8c\u6846\u7ed3\u679c\u8981\u597d\u5f97\u591a\u3002 \u2003 \u76f4\u63a5\u4f4d\u7f6e\u9884\u6d4b \uff08Direct location prediction\uff09\u3002\u5f53\u5728 \\(YOLO\\) \u4e2d\u4f7f\u7528\u951a\u6846\u65f6\uff0c\u6211\u4eec\u4f1a\u9047\u5230\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff1a\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u5c24\u5176\u662f\u5728\u65e9\u671f\u8fed\u4ee3\u7684\u8fc7\u7a0b\u4e2d\u3002 \u5927\u591a\u6570\u4e0d\u7a33\u5b9a\u6765\u81ea\u4e8e\u9884\u6d4b\u6846\u7684 \\((x,y)\\) \u4f4d\u7f6e\u3002 \u5728\u5019\u9009\u533a\u57df\u7f51\u7edc\u4e2d\uff0c\u7f51\u7edc\u9884\u6d4b\u7684 \\(t_x,t_y\\) \uff0c\u548c\u4e2d\u5fc3\u5750\u6807 \\((x,y)\\) \u8ba1\u7b97\u5982\u4e0b\uff1a \\(\\huge\\begin{array}{l} x=\\left(t_{x} * w_{a}\\right)-x_{a} \\\\ y=\\left(t_{y} * h_{a}\\right)-y_{a} \\end{array}\\) \u2003\u4f8b\u5982\uff0c\u9884\u6d4b \\(t_x = 1\\) \u4f1a\u4f7f\u8be5\u6846\u5411\u53f3\u79fb\u52a8\u951a\u6846\u7684\u5bbd\u5ea6\uff0c\u800c\u9884\u6d4b \\(t_x = -1\\) \u4f1a\u5c06\u5176\u5411\u5de6\u79fb\u52a8\u76f8\u540c\u7684\u5bbd\u5ea6\u3002 \u2003\u8fd9\u4e2a\u516c\u5f0f\u662f\u4e0d\u53d7\u7ea6\u675f\u7684\uff0c\u6240\u4ee5\u4efb\u4f55\u951a\u6846\u90fd\u53ef\u4ee5\u5728\u56fe\u50cf\u4e2d\u7684\u4efb\u4f55\u4e00\u70b9\u7ed3\u675f\uff0c\u800c\u4e0d\u7ba1\u951a\u6846\u662f\u5728\u54ea\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u7684\u3002\u968f\u673a\u521d\u59cb\u5316\u6a21\u578b\u9700\u8981\u5f88\u957f\u65f6\u95f4\u624d\u80fd\u7a33\u5b9a\u5230\u9884\u6d4b\u5408\u7406\u7684\u504f\u79fb\u91cf\u3002 \u2003\u6211\u4eec\u6ca1\u6709\u9884\u6d4b\u504f\u79fb\uff0c\u800c\u662f\u9075\u5faa \\(YOLO\\) \u7684\u65b9\u6cd5\uff0c\u9884\u6d4b\u76f8\u5bf9\u4e8e\u7f51\u683c\u5355\u5143\u4f4d\u7f6e\u7684\u4f4d\u7f6e\u5750\u6807\u3002\u8fd9\u4f7f\u5f97\u771f\u5b9e\u503c\u7684\u754c\u9650\u57280\u52301\u4e4b\u95f4\u3002\u6211\u4eec\u4f7f\u7528\u903b\u8f91\u6fc0\u6d3b\u6765\u9650\u5236\u7f51\u7edc\u7684\u9884\u6d4b\u843d\u5728\u8fd9\u4e2a\u8303\u56f4\u5185\u3002 \u2003\u7f51\u7edc\u4e3a\u7279\u5f81\u56fe\u7684\u8f93\u51fa\u7684\u6bcf\u4e2a\u5355\u5143\u9884\u6d4b5\u4e2a\u8fb9\u754c\u6846\u3002\u7f51\u7edc\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u76845\u4e2a\u5750\u6807 \\(t_x,t_y,t_w,t_h\u548ct_o\\) \u3002\u5982\u679c\u5355\u5143\u683c\u4ece\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u504f\u79fb\u4e86,\u5e76\u4e14\u4e4b\u524d\u7684\u8fb9\u754c\u6846\u5177\u6709\u5bbd\u5ea6\u548c\u9ad8\u5ea6 \\(p_w,p_h\\) \u5219\u9884\u6d4b\u5bf9\u5e94\u4e8e\uff1a \\(\\begin{aligned} b_{x} &=\\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} &=\\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} &=p_{w} e^{t_{w}} \\\\ b_{h} &=p_{h} e^{t_{h}} \\\\ \\operatorname{Pr}(\\text { object }) * \\operatorname{IOU}(b, \\text { object }) &=\\sigma\\left(t_{o}\\right) \\end{aligned}\\) \u2003\u7531\u4e8e\u6211\u4eec\u9650\u5236\u4e86\u4f4d\u7f6e\u9884\u6d4b\uff0c\u4f7f\u5f97\u53c2\u6570\u5316\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u66f4\u52a0\u7a33\u5b9a\u3002\u4f7f\u7528\u7ef4\u5ea6\u96c6\u7fa4\u4ee5\u53ca\u76f4\u63a5\u9884\u6d4b\u8fb9\u754c\u6846\u4e2d\u5fc3\u4f4d\u7f6e\uff0c\u53ef\u4ee5\u4f7f \\(YOLO\\) \u6bd4\u951a\u6846\u7684\u7248\u672c\u63d0\u9ad8\u8fd15\uff05\u3002 \u56fe3\uff1a\u5177\u6709\u7ef4\u5ea6\u5148\u9a8c\u548c\u4f4d\u7f6e\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u3002\u6211\u4eec\u9884\u6d4b\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4f5c\u4e3a\u805a\u7c7b\u8d28\u5fc3\u7684\u504f\u79fb\u91cf\u3002\u6211\u4eec\u4f7f\u7528sigmoid\u51fd\u6570\u9884\u6d4b\u76f8\u5bf9\u4e8e\u6ee4\u6ce2\u5668\u5e94\u7528\u4f4d\u7f6e\u7684\u6846\u7684\u4e2d\u5fc3\u5750\u6807\u3002 \u2003 \u7ec6\u7c92\u5ea6\u529f\u80fd \uff08Fine-Grained Features\uff09\u3002\u4fee\u6539\u540e\u7684YOLO\u5728 \\(13\u00d713\\) \u7279\u5f81\u56fe\u4e0a\u9884\u6d4b\u68c0\u6d4b\u7ed3\u679c\u3002 \u867d\u7136\u8fd9\u5bf9\u4e8e\u5927\u578b\u7269\u4f53\u662f\u8db3\u591f\u7684\uff0c\u4f46\u4f7f\u7528\u66f4\u7ec6\u7c92\u5ea6\u7279\u5f81\u5bf9\u5b9a\u4f4d\u8f83\u5c0f\u7269\u4f53\u6709\u597d\u5904\u3002Faster R-CNN\u548cSSD\u90fd\u5728\u7f51\u7edc\u4e2d\u7684\u5404\u79cd\u7279\u5f81\u56fe\u4e0a\u8fd0\u884c\u7f51\u7edc\uff0c\u4ee5\u83b7\u5f97\u591a\u4e2a\u5206\u8fa8\u7387\u3002 \u6211\u4eec\u91c7\u53d6\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u53ea\u9700\u6dfb\u52a0\u4e00\u4e2a\u76f4\u901a\u5c42\uff0c\u4ee5 \\(26\u00d726\\) \u7684\u5206\u8fa8\u7387\u4ece\u8f83\u65e9\u7684\u5c42\u4e2d\u63d0\u53d6\u7279\u5f81\u3002 \u2003\u76f4\u901a\u5c42\u5c06\u9ad8\u5206\u8fa8\u7387\u7279\u5f81\u4e0e\u4f4e\u5206\u8fa8\u7387\u7279\u5f81\u8fde\u63a5\u8d77\u6765\uff0c\u5c06\u76f8\u90bb\u7279\u5f81\u53e0\u52a0\u5230\u4e0d\u540c\u7684\u901a\u9053\u4e2d\uff0c\u800c\u4e0d\u662f\u7a7a\u95f4\u4f4d\u7f6e\u4e0a\uff0c\u7c7b\u4f3c\u4e8e \\(ResNet\\) \u4e2d\u7684\u6052\u7b49\u6620\u5c04\u3002\u5c06 \\(26\u00d726\u00d7512\\) \u7684\u7279\u5f81\u56fe\u53d8\u4e3a \\(13\u00d713\u00d72048\\) \u7684\u7279\u5f81\u56fe\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u4e0e\u539f\u6765\u7684\u7279\u5f81\u8fde\u63a5\u3002\u6211\u4eec\u7684\u68c0\u6d4b\u5668\u8fd0\u884c\u5728\u8fd9\u5f20\u6269\u5c55\u7684\u7279\u5f81\u56fe\u7684\u9876\u90e8\uff0c\u4ee5\u4fbf\u5b83\u53ef\u4ee5\u8bbf\u95ee\u7ec6\u7c92\u5ea6\u7684\u529f\u80fd\u3002\u8fd9\u4f7f\u6027\u80fd\u63d0\u9ad8\u4e861\uff05\u3002 \u2003 \u591a\u5c3a\u5ea6\u8bad\u7ec3 \uff08Multi-Scale Training\uff09\u3002\u539f\u6765\u7684 \\(YOLO\\) \u4f7f\u7528 \\(448\u00d7448\\) \u7684\u8f93\u5165\u5206\u8fa8\u7387\u3002\u901a\u8fc7\u6dfb\u52a0\u951a\u6846\uff0c\u6211\u4eec\u5c06\u5206\u8fa8\u7387\u66f4\u6539\u4e3a \\(416\u00d7416\\) \u3002\u4f46\u662f\uff0c\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u4ec5\u4f7f\u7528\u5377\u79ef\u5c42\u548c\u6c60\u5316\u5c42\uff0c\u56e0\u6b64\u53ef\u4ee5\u5b9e\u65f6\u8c03\u6574\u5927\u5c0f\u3002\u6211\u4eec\u5e0c\u671b \\(YOLOv2\\) \u80fd\u591f\u5728\u4e0d\u540c\u5c3a\u5bf8\u7684\u56fe\u50cf\u4e0a\u8fd0\u884c\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u591a\u5c3a\u5ea6\u8bad\u7ec3\u5e94\u5230\u6a21\u578b\u4e2d\u3002 \u2003\u6211\u4eec\u4e0d\u9700\u8981\u4fee\u6539\u8f93\u5165\u56fe\u50cf\u5927\u5c0f\uff0c\u800c\u662f\u6bcf\u9694\u51e0\u6b21\u8fed\u4ee3\u5c31\u6539\u53d8\u4e00\u6b21\u7f51\u7edc\u3002\u6bcf \\(10\\) \u4e2a\u6279\u6b21\u6211\u4eec\u7684\u7f51\u7edc\u4f1a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u65b0\u7684\u56fe\u50cf\u5c3a\u5bf8\u5927\u5c0f\u3002\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u7f29\u51cf\u4e86 \\(32\\) \u500d\uff0c\u6240\u4ee5\u6211\u4eec\u4ece \\(32\\) \u7684\u500d\u6570\u4e2d\u62bd\u53d6\uff1a \\({320,352\uff0c\u2026\uff0c608}\\) \u3002\u56e0\u6b64\uff0c\u6700\u5c0f\u7684\u9009\u9879\u662f \\(320\u00d7320\\) \uff0c\u6700\u5927\u7684\u662f \\(608\u00d7608\\) \u3002\u6211\u4eec\u8c03\u6574\u7f51\u7edc\u7684\u5c3a\u5bf8\u5230\u90a3\u4e2a\u7ef4\u5ea6\u5e76\u7ee7\u7eed\u8bad\u7ec3\u3002 \u2003\u8fd9\u4e2a\u673a\u5236\u8feb\u4f7f\u7f51\u7edc\u5b66\u4e60\u5982\u4f55\u5728\u5404\u79cd\u8f93\u5165\u7ef4\u5ea6\u4e0a\u505a\u597d\u9884\u6d4b\u3002\u8fd9\u610f\u5473\u7740\u540c\u4e00\u4e2a\u7f51\u7edc\u53ef\u4ee5\u9884\u6d4b\u4e0d\u540c\u5206\u8fa8\u7387\u4e0b\u7684\u68c0\u6d4b\u7ed3\u679c\u3002\u7f51\u7edc\u5728\u8f83\u5c0f\u7684\u5c3a\u5bf8\u4e0b\u8fd0\u884c\u901f\u5ea6\u66f4\u5feb\uff0c\u56e0\u6b64 \\(YOLOv2\\) \u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u677e\u7684\u6298\u4e2d\u3002 \u2003 \u5728\u4f4e\u5206\u8fa8\u7387\u4e0b\uff0c \\(YOLOv2\\) \u4f5c\u4e3a\u4e00\u79cd\u4fbf\u5b9c\u4f46\u76f8\u5f53\u51c6\u786e\u7684\u68c0\u6d4b\u5668\u5de5\u4f5c\u3002 \u5728 \\(288\u00d7288\\) \u60c5\u51b5\u4e0b\uff0c\u5b83\u7684\u8fd0\u884c\u901f\u5ea6\u8d85\u8fc7 90 FPS\uff0c\u800c \\(mAP\\) \u51e0\u4e4e\u4e0e \\(Fast \\ R-CNN\\) \u4e00\u6837\u597d\u3002\u8fd9\u4f7f\u5176\u6210\u4e3a\u5c0f\u578b \\(GPU\\) \uff0c\u9ad8\u5e27\u7387\u89c6\u9891\u6216\u591a\u89c6\u9891\u6d41\u7684\u7406\u60f3\u9009\u62e9\u3002 \u2003\u5728\u9ad8\u5206\u8fa8\u7387\u4e0b\uff0c \\(YOLOv2\\) \u662f\u4e00\u6b3e\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5728VOC2007\u4e0a\u83b7\u5f97\u4e8678.6\u7684 \\(mAP\\) \uff0c\u540c\u65f6\u4ecd\u4ee5\u9ad8\u4e8e\u5b9e\u65f6\u901f\u5ea6\u8fd0\u884c\u3002\u8bf7\u53c2\u9605\u88683\uff0c\u4e86\u89e3 \\(YOLOv2\\) \u4e0e\u5176\u4ed6\u6846\u67b6\u5728 \\(VOC \\ 2007\\) \u4e0a\u7684\u6bd4\u8f83 \u56fe4\u3002 \u56fe4\uff1a \\(VOC \\ 2007\\) \u4e0a\u7684\u7cbe\u5ea6\u548c\u901f\u5ea6 \u2003 \u8fdb\u4e00\u6b65\u7684\u5b9e\u9a8c \uff08Further Experiments\uff09\u3002 \u6211\u4eec\u5728 \\(VOC \\ 2012\\) \u4e0a\u8bad\u7ec3\u4e86 \\(YOLOv2\\) \u8fdb\u884c\u68c0\u6d4b\u3002\u88684 \u663e\u793a\u4e86 \\(YOLOv2\\) \u4e0e\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u7cfb\u7edf\u7684\u6027\u80fd\u6bd4\u8f83\u3002 \\(YOLOv2\\) \u8fd0\u884c\u901f\u5ea6\u8fdc\u9ad8\u4e8e\u5bf9\u624b\uff0c\u4e14\u7cbe\u5ea6\u8fbe\u5230 73.4 \\(mAP\\) \u3002 \u6211\u4eec\u8fd8\u5728 \\(COCO\\) \u4e0a\u8bad\u7ec3\uff0c\u5e76\u4e0e\u88685\u4e2d\u7684\u5176\u4ed6\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002\u4f7f\u7528 \\(VOC\\) \u5ea6\u91cf\uff08 \\(IOU = 0.5\\) \uff09\uff0c \\(YOLOv2\\) \u83b7\u5f9744.0 \\(mAP\\) \uff0c\u4e0e \\(SSD\\) \u548c \\(Faster \\ R-CNN\\) \u76f8\u5f53\u3002 \\(\\begin{array}{lrrr} \\text { Detection Frameworks } & \\text { Train } & \\text { mAP } & \\text { FPS } \\\\ \\hline \\text { Fast R-CNN [5] } & 2007+2012 & 70.0 & 0.5 \\\\ \\text { Faster R-CNN VGG-16[15] } & 2007+2012 & 73.2 & 7 \\\\ \\text { Faster R-CNN ResNet[6] } & 2007+2012 & 76.4 & 5 \\\\ \\text { YOLO [14] } & 2007+2012 & 63.4 & 45 \\\\ \\text { SSD300 [11] } & 2007+2012 & 74.3 & 46 \\\\ \\text { SSD500 [11] } & 2007+2012 & 76.8 & 19 \\\\ \\hline \\text { YOLOv2 288 } \\times 288 & 2007+2012 & 69.0 & 91 \\\\ \\text { YOLOv2 352 } \\times 352 & 2007+2012 & 73.7 & 81 \\\\ \\text { YOLOv2 416 } \\times 416 & 2007+2012 & 76.8 & 67 \\\\ \\text { YOLOv2 480 } \\times 480 & 2007+2012 & 77.8 & 59 \\\\ \\text { YOLOv2 } 544 \\times 544 & 2007+2012 & \\mathbf{7 8 . 6} & 40 \\end{array}\\) \u88683\uff1a \\(PA S C A L \\ VOC \\ 2007\\) \u7684\u68c0\u6d4b\u6846\u67b6\u3002 \\(YOLOv2\\) \u6bd4\u4ee5\u524d\u7684\u68c0\u6d4b\u65b9\u6cd5\u66f4\u5feb\uff0c\u66f4\u51c6\u786e\u3002\u5b83\u4e5f\u53ef\u4ee5\u4ee5\u4e0d\u540c\u7684\u5206\u8fa8\u7387\u8fd0\u884c\uff0c\u4ee5\u4fbf\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u8f7b\u677e\u6298\u8877\u3002\u6bcf\u4e2a \\(YOLOv2\\) \u9879\u5b9e\u9645\u4e0a\u90fd\u662f\u5177\u6709\u76f8\u540c\u6743\u91cd\u7684\u76f8\u540c\u8bad\u7ec3\u6a21\u578b\uff0c\u53ea\u662f\u4ee5\u4e0d\u540c\u7684\u5927\u5c0f\u8fdb\u884c\u8bc4\u4f30\u3002\u6240\u6709\u7684\u65f6\u95f4\u7684\u6d4b\u8bd5\u90fd\u8fd0\u884c\u5728Geforce GTX Titan X\uff08\u539f\u59cb\u7684\uff0c\u800c\u4e0d\u662fPascal\u6a21\u578b\uff09","title":"2.\u66f4\u597d"},{"location":"thesis_interpretation/02_yolo.html#3","text":"\u6211\u4eec\u5e0c\u671b\u68c0\u6d4b\u7ed3\u679c\u51c6\u786e\uff0c\u4f46\u6211\u4eec\u4e5f\u5e0c\u671b\u68c0\u6d4b\u901f\u5ea6\u66f4\u5feb\u3002 \u5927\u591a\u6570\u7528\u4e8e\u68c0\u6d4b\u7684\u5e94\u7528\u7a0b\u5e8f\uff08\u5982\u673a\u5668\u4eba\u6216\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff09\u90fd\u4f9d\u8d56\u4e8e\u4f4e\u5ef6\u8fdf\u9884\u6d4b\u3002 \u4e3a\u4e86\u6700\u5927\u9650\u5ea6\u5730\u63d0\u9ad8\u6027\u80fd\uff0c\u6211\u4eec\u5c06 \\(YOLOv2\\) \u8bbe\u8ba1\u4ece\u5934\u5230\u5c3e\u90fd\u975e\u5e38\u5feb \u3002 \u88682\uff1a\u4ece \\(YOLO\\) \u5230 \\(YOLOv2\\) \u7684\u8def\u5f84\u3002\u5927\u591a\u6570\u5217\u51fa\u7684\u8bbe\u8ba1\u51b3\u7b56\u90fd\u4f1a\u5bfc\u81f4 \\(MAP\\) \u663e\u7740\u589e\u52a0\u3002\u6709\u4e24\u4e2a\u4f8b\u5916\u60c5\u51b5\u662f\uff1a\u5207\u6362\u5230\u5e26\u6709\u951a\u6846\u7684\u5168\u5377\u79ef\u7f51\u7edc\u548c\u4f7f\u7528\u65b0\u7f51\u7edc\u3002\u5207\u6362\u5230\u951a\u6846\u65b9\u6cd5\u589e\u52a0\u53ec\u56de\u7387\uff0c\u800c\u4e0d\u6539\u53d8 \\(mAP\\) \uff0c\u800c\u4f7f\u7528\u65b0\u7f51\u7edc\u524a\u51cf33\uff05\u7684\u8ba1\u7b97\u3002 \u88684\uff1aPASCAL VOC2012\u6d4b\u8bd5\u68c0\u6d4b\u7ed3\u679c\u3002 \\(YOLOv2\\) \u4e0e\u91c7\u7528ResNet\u548cSSD512\u7684Faster R-CNN\u7b49\u5148\u8fdb\u68c0\u6d4b\u5668\u6027\u80fd\u76f8\u5f53\uff0c\u901f\u5ea6\u63d0\u9ad82\u81f310\u500d\u3002 \u2003\u5927\u591a\u6570\u68c0\u6d4b\u6846\u67b6\u4f9d\u8d56\u4e8eVGG-16\u4f5c\u4e3a\u57fa\u672c\u7279\u5f81\u63d0\u53d6\u5668[17]\u3002 \\(VGG-16\\) \u662f\u4e00\u4e2a\u529f\u80fd\u5f3a\u5927\uff0c\u51c6\u786e\u7684\u5206\u7c7b\u7f51\u7edc\uff0c\u4f46\u5b83\u6709\u4e0d\u5fc5\u8981\u7684\u590d\u6742\u5ea6\u3002 \\(VGG-16\\) \u7684\u5377\u79ef\u5c42\u5728\u4e00\u4e2a \\(224\u00d7224\\) \u5206\u8fa8\u7387\u5355\u4e2a\u56fe\u50cf\u4e0a\u8fd0\u884c\u4e00\u6b21\u9700\u8981 \\(306.90\\) \u4ebf\u6d6e\u70b9\u8fd0\u7b97\u3002 \u2003 \\(YOLO\\) \u6846\u67b6\u4f7f\u7528\u57fa\u4e8e \\(Googlenet\\) \u67b6\u6784\u7684\u81ea\u5b9a\u4e49\u7f51\u7edc[19]\u3002\u8fd9\u4e2a\u7f51\u7edc\u6bd4 \\(VGG-16\\) \u66f4\u5feb\uff0c\u4e00\u6b21\u524d\u5411\u4f20\u64ad\u53ea\u8981 \\(85.2\\) \u4ebf\u6b21\u8fd0\u884c\u3002\u7136\u800c\uff0c\u5b83\u7684\u51c6\u786e\u6027\u7565\u4f4e\u4e8e \\(VGG-16\\) \u3002\u5728 \\(ImageNet\\) \u4e0a\uff0c\u7528 \\(224\u00d7224\\) \u7684\u5355\u5f20\u88c1\u526a\u56fe\u50cf\uff0c \\(YOLO\\) \u7684\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u7cbe\u5ea6\u4e3a88.0\uff05\u800c \\(VGG-16\\) \u5219\u4e3a90.0\uff05\u3002 \u2003 \\(Darknet-19\\) \u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5206\u7c7b\u6a21\u578b\u4f5c\u4e3a \\(YOLOv2\\) \u7684\u57fa\u7840\u3002\u6211\u4eec\u7684\u6a21\u578b\u5efa\u7acb\u5728\u7f51\u7edc\u8bbe\u8ba1\u7684\u5148\u524d\u5de5\u4f5c\u4ee5\u53ca\u8be5\u9886\u57df\u7684\u5e38\u8bc6\u4e0a\u3002\u4e0e \\(VGG\\) \u6a21\u578b\u7c7b\u4f3c\uff0c\u6211\u4eec\u5927\u591a\u4f7f\u7528 \\(3\u00d73\\) \u6ee4\u6ce2\u5668\uff0c\u5e76\u4e14\u5728\u6c60\u5316\u5c42\u6b65\u9aa4\u540e\u4f7f\u7528\u4e24\u500d\u7684\u901a\u9053\u6570[17]\u3002\u6309\u7167Network in Network\uff08NIN\uff09\u7684\u65b9\u6cd5\uff0c\u6211\u4eec\u4f7f\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u6765\u505a\u9884\u6d4b\uff0c\u5e76\u4f7f\u75281\u00d71\u6ee4\u6ce2\u5668\u6765\u538b\u7f293\u00d73\u5377\u79ef\u7684\u7279\u5f81\u8868\u793a[9]\u3002\u6211\u4eec\u4f7f\u7528\u6279\u91cf\u5f52\u4e00\u5316\u6765\u7a33\u5b9a\u8bad\u7ec3\uff0c\u52a0\u901f\u6536\u655b\uff0c\u5e76\u89c4\u8303\u6a21\u578b[7]\u3002 \u2003\u6700\u7ec8\u7684\u6a21\u578b\u53eb\u505aDarknet-19\uff0c\u5b83\u670919\u4e2a\u5377\u79ef\u5c42\u548c5\u4e2aMaxpool\u5c42\u3002 \\(Darknet-19\\) \u53ea\u9700\u898155.8\u4ebf\u6b21\u64cd\u4f5c\u6765\u5904\u7406\u56fe\u50cf\uff0c\u4f46\u5728 \\(ImageNet\\) \u4e0a\u5b9e\u73b0\u4e8672.9\uff05\u7684top-1\u7cbe\u5ea6\u548c91.2\uff05\u7684top-5\u7cbe\u5ea6\u3002 \u2003 \u5206\u7c7b\u8bad\u7ec3 \uff08Training for classification\uff09\u3002\u6211\u4eec\u4f7f\u7528 \\(DarkNet\\) \u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u4f7f\u7528\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0c\u521d\u59cb\u5b66\u4e60\u7387\u4e3a0.1\uff0c\u591a\u9879\u5f0f\u901f\u7387\u8870\u51cf\u4e3a4\uff0c\u6743\u91cd\u8870\u51cf\u4e3a0.0005\uff0c\u52a8\u91cf\u4e3a0.9\uff0c\u5728\u6807\u51c6 \\(ImageNet\\) 1000\u7c7b\u522b\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u5bf9\u7f51\u7edc\u8fdb\u884c160\u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u8bad\u7ec3[13]\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u6807\u51c6\u6570\u636e\u589e\u5f3a\u6280\u5de7\uff0c\u5305\u62ec\u968f\u673a\u622a\u53d6\uff0c\u65cb\u8f6c\u548c\u6539\u53d8\u8272\u76f8\uff0c\u9971\u548c\u5ea6\u548c\u66dd\u5149\u3002 \u2003 \u5982\u4e0a\u6240\u8ff0\uff0c\u5728\u6211\u4eec\u5bf9 \\(224\u00d7224\\) \u56fe\u50cf\u8fdb\u884c\u521d\u59cb\u8bad\u7ec3\u4e4b\u540e\uff0c\u6211\u4eec\u7528\u66f4\u5927\u7684\u5206\u8fa8\u7387448\u5bf9\u7f51\u7edc\u8fdb\u884c\u4e86\u5fae\u8c03\u3002\u5fae\u8c03\u65f6\uff0c\u6211\u4eec\u4f7f\u7528\u4e0a\u8ff0\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u4ec5\u752810\u4e2a\u5468\u671f\uff0c\u5e76\u4e14\u5f00\u59cb\u65f6\u7684\u5b66\u4e60\u7387\u4e3a10-3\u3002\u5728\u8fd9\u4e2a\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u4e0b\uff0c\u6211\u4eec\u7684\u7f51\u7edc\u5b9e\u73b0\u4e8676.5\uff05\u7684 \\(top-1\\) \u7cbe\u5ea6\u548c93.3\uff05\u7684 \\(top-5\\) \u7cbe\u5ea6\u3002 \u2003 \u68c0\u6d4b\u8bad\u7ec3 \uff08Training for detection\uff09\u3002\u6211\u4eec\u8fd9\u6837\u4fee\u6539\u7f51\u7edc\uff1a\u53bb\u9664\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u53d6\u800c\u4ee3\u4e4b\u7684\u662f\u6dfb\u52a0\u4e09\u4e2a \\(3 \u00d7 3\\) \u7684\u5377\u79ef\u5c42\uff0c\u6bcf\u4e2a\u5c42\u6709 \\(1024\\) \u4e2a\u8fc7\u6ee4\u5668\uff0c\u7136\u540e\u5728\u6700\u540e\u6dfb\u52a0 \\(1\u00d71\\) \u5377\u79ef\u5c42\uff0c\u8be5\u5c42\u7684\u6ee4\u6ce2\u5668\u6570\u91cf\u662f\u68c0\u6d4b\u9700\u8981\u7684\u8f93\u51fa\u6570\u91cf\u3002 \u5bf9\u4e8e \\(VOC\\) \uff0c\u6211\u4eec\u9884\u6d4b \\(05\\) \u4e2a\u8fb9\u754c\u6846\uff0c\u6bcf\u4e2a\u8fb9\u754c\u6846\u6709 5\u4e2a\u5750\u6807\u548c20\u4e2a\u7c7b\u522b\uff0c\u6240\u4ee5\u6709125\u4e2a\u6ee4\u6ce2\u5668\u3002\u6211\u4eec\u8fd8\u6dfb\u52a0\u4e86\u4ece\u6700\u540e\u7684 \\(3\u00d73\u00d7512\\) \u5c42\u5230\u5012\u6570\u7b2c\u4e8c\u5c42\u5377\u79ef\u5c42\u7684\u76f4\u901a\u5c42\uff0c\u4ee5\u4fbf\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u4f7f\u7528\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002 \u2003\u6211\u4eec\u8bad\u7ec3\u7f51\u7edc160\u4e2a\u8fed\u4ee3\u5468\u671f\uff0c\u521d\u59cb\u5b66\u4e60\u7387\u4e3a \\(10^{-3}\\) \uff0c\u572860\u548c90\u5468\u671f\u540c\u65f6\u9664\u4ee510\u3002\u6211\u4eec\u4f7f\u7528 \\(0.0005\\) \u7684\u6743\u503c\u8870\u51cf\u548c 0.9 \u7684\u52a8\u91cf( momentum )\u3002\u6211\u4eec\u5bf9 \\(YOLO\\) \u548c \\(SSD\\) \u8fdb\u884c\u7c7b\u4f3c\u7684\u6570\u636e\u589e\u5f3a\uff0c\u968f\u673a\u88c1\u526a\uff0c\u8272\u5f69\u4fee\u6539\u7b49\u3002\u6211\u4eec\u5728 \\(COCO\\) \u548c \\(VOC\\) \u4f7f\u7528\u76f8\u540c\u7684\u8bad\u7ec3\u7b56\u7565\u3002 \\(\\begin{array}{l|c|cccc|ccc|ccc|ccc} & & 0.5: 0.95 & 0.5 & 0.75 & \\mathrm{~S} & \\mathrm{M} & \\mathrm{L} & 1 & 10 & 100 & \\mathrm{~S} & \\mathrm{M} & \\mathrm{L} \\\\ \\hline \\text { Fast R-CNN [5] } & \\text { train } & 19.7 & 35.9 & - & - & - & - & - & - & - & - & - & - \\\\ \\text { Fast R-CNN[1] } & \\text { train } & 20.5 & 39.9 & 19.4 & 4.1 & 20.0 & 35.8 & 21.3 & 29.5 & 30.1 & 7.3 & 32.1 & 52 .0 \\\\ \\text { Faster R-CNN[15] } & \\text { trainval } & 21.9 & 42.7 & - & - & - & - & - & - & - & - & - & - \\\\ \\text { ION [1] } & \\text { train } & 23.6 & 43.2 & 23.6 & 6.4 & 24.1 & 38.3 & 23.2 & 32.7 & 33.5 & 10.1 & 37.7 & 53.6 \\\\ \\text { Faster R-CNN[10] } & \\text { trainval } & 24.2 & 45.3 & 23.5 & 7.7 & 26.4 & 37.1 & 23.8 & 34.0 & 34.6 & 12.0 & 38.5 & 54.4 \\\\ \\text { SSD300 [11] } & \\text { trainval35k } & 23.2 & 41.2 & 23.4 & 5.3 & 23.2 & 39.6 & 22.5 & 33.2 & 35.3 & 9.6 & 37.6 & 56.5 \\\\ \\text { SSD512 [11] } & \\text { trainval35k } & \\mathbf{26.8} & \\mathbf{4 6 . 5} & \\mathbf{2 7 . 8} & \\mathbf{9 . 0} & \\mathbf{2 8 . 9} & 41.9 & \\mathbf{2 4 . 8} & 37.5 & \\mathbf{3 9 . 8} & \\mathbf{1 4 . 0} & 43.5 & 59.0 \\\\ \\hline \\text { YOLOv2 [11] } & \\text { trainval35k } & 21.6 & 44.0 & 19.2 & 5.0 & 22.4 & 35.5 & 20.7 & 31.6 & 33.3 & 9.8 & 36.5 & 54 .4 \\end{array}\\) \u88685\uff1a \\(COCO\\) test-dev\u96c6\u4e0a\u7684\u7ed3\u679c\uff0c\u6765\u6e90\u4e8e\u8bba\u6587[11]","title":"3.\u66f4\u5feb"},{"location":"thesis_interpretation/02_yolo.html#4","text":"\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u5408\u8bad\u7ec3\u5206\u7c7b\u548c\u68c0\u6d4b\u6570\u636e\u7684\u673a\u5236\u3002 \u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u4e86\u7528\u4e8e\u68c0\u6d4b\u7684\u56fe\u50cf\u6765\u5b66\u4e60\u68c0\u6d4b\u7279\u5b9a\u4fe1\u606f\uff0c\u5982\u8fb9\u754c\u6846\u5750\u6807\u9884\u6d4b\u548c\u76ee\u6807\u4ee5\u53ca\u5982\u4f55\u5bf9\u5e38\u89c1\u76ee\u6807\u8fdb\u884c\u5206\u7c7b\u3002\u901a\u8fc7\u4f7f\u7528\u4ec5\u5177\u6709\u7c7b\u6807\u7b7e\u7684\u56fe\u50cf\u6765\u6269\u5c55\u5176\u53ef\u68c0\u6d4b\u7c7b\u522b\u7684\u6570\u91cf\u3002 \u2003\u5728\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u6df7\u5408\u6765\u81ea\u68c0\u6d4b\u548c\u5206\u7c7b\u6570\u636e\u96c6\u7684\u56fe\u50cf\u3002 \u5f53\u6211\u4eec\u7684\u7f51\u7edc\u770b\u5230\u6807\u8bb0\u4e3a\u68c0\u6d4b\u7684\u56fe\u50cf\u65f6\uff0c\u53ef\u4ee5\u6839\u636e\u5b8c\u6574\u7684 \\(YOLOv2\\) \u635f\u5931\u51fd\u6570\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3002 \u5f53\u5b83\u770b\u5230\u5206\u7c7b\u56fe\u50cf\u65f6\uff0c\u53ea\u4f1a\u53cd\u5411\u4f20\u64ad\u5206\u7c7b\u90e8\u5206\u7684\u635f\u5931\u3002 \\(\\begin{array}{l|c|c|c} \\text { Type } & \\text { Filters } & \\text { Size/Stride } & \\text { Output } \\\\ \\hline \\text { Convolutional } & 32 & 3 \\times 3 & 224 \\times 224 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 112 \\times 112 \\\\ \\text { Convolutional } & 64 & 3 \\times 3 & 112 \\times 112 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 56 \\times 56 \\\\ \\text { Convolutional } & 128 & 3 \\times 3 & 56 \\times 56 \\\\ \\text { Convolutional } & 64 & 1 \\times 1 & 56 \\times 56 \\\\ \\text { Convolutional } & 128 & 3 \\times 3 & 56 \\times 56 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 28 \\times 28 \\\\ \\text { Convolutional } & 256 & 3 \\times 3 & 28 \\times 28 \\\\ \\text { Convolutional } & 128 & 1 \\times 1 & 28 \\times 28 \\\\ \\text { Convolutional } & 256 & 3 \\times 3 & 28 \\times 28 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Convolutional } & 256 & 1 \\times 1 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Convolutional } & 256 & 1 \\times 1 & 14 \\times 14 \\\\ \\text { Convolutional } & 512 & 3 \\times 3 & 14 \\times 14 \\\\ \\text { Maxpool } & & 2 \\times 2 / 2 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\text { Convolutional } & 512 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\text { Convolutional } & 512 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Convolutional } & 1024 & 3 \\times 3 & 7 \\times 7 \\\\ \\hline \\hline \\text { Convolutional } & 1000 & 1 \\times 1 & 7 \\times 7 \\\\ \\text { Avgpool } & & \\text { Global } & 1000 \\\\ \\text { Softmax } & & & \\end{array}\\) \u88686\uff1aDarknet-19 \u2003\u8fd9\u79cd\u65b9\u6cd5\u5e26\u6765\u4e86\u4e00\u4e9b\u96be\u9898\u3002\u68c0\u6d4b\u6570\u636e\u96c6\u53ea\u6709\u5e38\u7528\u7684\u76ee\u6807\u548c\u901a\u7528\u7684\u6807\u7b7e\uff0c\u5982\u201c\u72d7\u201d\u6216\u201c\u8239\u201d\u3002\u5206\u7c7b\u6570\u636e\u96c6\u5177\u6709\u66f4\u5e7f\u6cdb\u548c\u66f4\u6df1\u5165\u7684\u6807\u7b7e\u8303\u56f4\u3002 \\(ImageNet\\) \u62e5\u6709\u591a\u79cd\u72ac\u79cd\uff0c\u5305\u62ecNorfolk terrier\uff0cYorkshire terrier\u548cBedlington terrier\u3002\u5982\u679c\u6211\u4eec\u60f3\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5219\u9700\u8981\u91c7\u7528\u4e00\u81f4\u7684\u65b9\u5f0f\u6765\u5408\u5e76\u8fd9\u4e9b\u6807\u7b7e\u3002 \u2003\u5927\u591a\u6570\u5206\u7c7b\u65b9\u6cd5\u4f7f\u7528\u6db5\u76d6\u6240\u6709\u53ef\u80fd\u7c7b\u522b\u7684 \\(softmax\\) \u5c42\u6765\u8ba1\u7b97\u6700\u7ec8\u6982\u7387\u5206\u5e03\u3002\u4f7f\u7528 \\(softmax\\) \uff0c\u610f\u5473\u7740\u7c7b\u662f\u76f8\u4e92\u6392\u65a5\u7684\u3002\u8fd9\u7ed9\u7ec4\u5408\u6570\u636e\u96c6\u5e26\u6765\u4e86\u95ee\u9898\uff0c\u4f8b\u5982\uff0c\u4f60\u4e0d\u80fd\u7528\u8fd9\u4e2a\u6a21\u578b\u6765\u7ec4\u5408 \\(ImageNet\\) \u548c \\(COCO\\) \uff0c\u56e0\u4e3a\u7c7b\u522b \\(Norfolk \\ terrier\u548cdog\\) \u4e0d\u662f\u4e92\u65a5\u7684\u3002 \u2003\u76f8\u53cd\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u591a\u6807\u7b7e\u6a21\u578b\u6765\u7ec4\u5408\u4e0d\u4f1a\u4e92\u76f8\u6392\u65a5\u7684\u6570\u636e\u96c6\u3002\u8fd9\u4e2a\u65b9\u6cd5\u5ffd\u7565\u4e86\u6211\u4eec\u6240\u77e5\u9053\u7684\u5173\u4e8e\u6570\u636e\u7684\u6240\u6709\u7ed3\u6784\uff0c\u4f8b\u5982\u6240\u6709\u7684 \\(COCO\\) \u7c7b\u90fd\u662f\u76f8\u4e92\u72ec\u7acb\u7684\u3002 \u2003 \u5206\u5c42\u5206\u7c7b \uff08Hierarchical classification\uff09\u3002 \\(ImageNet\\) \u6807\u7b7e\u662f\u4ece \\(WordNet\\) \u4e2d\u63d0\u53d6\u7684\uff0c \\(WordNet\\) \u662f\u4e00\u4e2a\u6784\u5efa\u6982\u5ff5\u53ca\u5176\u76f8\u4e92\u5173\u7cfb\u7684\u8bed\u8a00\u6570\u636e\u5e93[12]\u3002 Norfolk terrier\u548cYorkshire terrier\u90fd\u662fterrier\u7684\u4e0b\u4e49\u8bcd\uff0cterrier\u662f\u4e00\u79cdhunting dog\uff0chunting dog\u662fdog\uff0cdog\u662fcanine\u7b49\u3002\u5927\u591a\u6570\u5206\u7c7b\u7684\u65b9\u6cd5\u5047\u8bbe\u6807\u7b7e\u662f\u4e00\u4e2a\u6241\u5e73\u7ed3\u6784\uff0c\u4f46\u662f\u5bf9\u4e8e\u7ec4\u5408\u6570\u636e\u96c6\uff0c\u7ed3\u6784\u6b63\u662f\u6211\u4eec\u6240\u9700\u8981\u7684\u3002 \u2003 \\(WordNet\\) \u7684\u7ed3\u6784\u662f\u6709\u5411\u56fe\uff0c\u800c\u4e0d\u662f\u6811\uff0c\u56e0\u4e3a\u8bed\u8a00\u5f88\u590d\u6742\u3002 \u4f8b\u5982\uff0c\u201c\u72d7\u201d\u65e2\u662f\u4e00\u79cd\u201c\u72ac\u201d\u53c8\u662f\u4e00\u79cd\u201c\u5bb6\u517b\u52a8\u7269\u201d\uff0c\u5b83\u4eec\u90fd\u662f \\(WordNet\\) \u4e2d\u7684\u540c\u4e49\u8bcd\u3002 \u6211\u4eec\u4e0d\u4f7f\u7528\u5b8c\u6574\u7684\u56fe\u7ed3\u6784\uff0c\u800c\u662f\u901a\u8fc7\u4ece \\(ImageNet\\) \u4e2d\u7684\u6982\u5ff5\u6784\u5efa\u5206\u5c42\u6811\u6765\u7b80\u5316\u95ee\u9898\u3002 \u2003WordNet\u7684\u7ed3\u6784\u662f\u6709\u5411\u56fe\uff0c\u800c\u4e0d\u662f\u6811\uff0c\u56e0\u4e3a\u8bed\u8a00\u5f88\u590d\u6742\u3002\u4f8b\u5982\uff0c\u4e00\u53ea\u72d7\u65e2\u662f\u4e00\u79cd\u72ac\u79d1\u52a8\u7269\uff0c\u53c8\u662f\u4e00\u79cd\u5bb6\u517b\u52a8\u7269\uff0c\u5b83\u4eec\u90fd\u662fWordNet\u4e2d\u7684\u540c\u79cd\u52a8\u7269\u3002\u6211\u4eec\u6ca1\u6709\u4f7f\u7528\u5b8c\u6574\u7684\u56fe\u7ed3\u6784\uff0c\u800c\u662f\u901a\u8fc7\u4ece \\(ImageNet\\) \u4e2d\u7684\u6982\u5ff5\u6784\u5efa\u5206\u5c42\u6811\u6765\u7b80\u5316\u95ee\u9898\u3002 \u2003\u4e3a\u4e86\u6784\u5efa\u8fd9\u68f5\u6811\uff0c\u6211\u4eec\u68c0\u67e5 \\(ImageNet\\) \u4e2d\u7684\u89c6\u89c9\u540d\u8bcd\uff0c\u5e76\u67e5\u770b\u5b83\u4eec\u901a\u8fc7 \\(WordNet\\) \u56fe\u5230\u6839\u8282\u70b9\u7684\u8def\u5f84\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u662f\u201c\u7269\u7406\u76ee\u6807\u201d\u3002 \u8bb8\u591a\u540c\u4e49\u8bcd\u53ea\u6709\u5728\u56fe\u4e0a\u4e00\u6761\u8def\u5f84\uff0c\u6240\u4ee5\u9996\u5148\u6211\u4eec\u5c06\u6240\u6709\u8fd9\u4e9b\u8def\u5f84\u6dfb\u52a0\u5230\u6211\u4eec\u7684\u6811\u4e2d\u3002 \u7136\u540e\uff0c\u6211\u4eec\u53cd\u590d\u68c0\u67e5\u6211\u4eec\u7559\u4e0b\u7684\u6982\u5ff5\uff0c\u5e76\u5c3d\u53ef\u80fd\u5c11\u5730\u6dfb\u52a0\u751f\u6210\u6811\u7684\u8def\u5f84\u3002 \u6240\u4ee5\u5982\u679c\u4e00\u4e2a\u6982\u5ff5\u6709\u4e24\u6761\u901a\u5411\u6839\u7684\u8def\u5f84\uff0c\u4e00\u6761\u8def\u5f84\u4f1a\u4e3a\u6211\u4eec\u7684\u6811\u589e\u52a0\u4e09\u6761\u8fb9\uff0c\u53e6\u4e00\u6761\u8def\u53ea\u589e\u52a0\u4e00\u6761\u8fb9\uff0c\u6211\u4eec\u9009\u62e9\u8f83\u77ed\u7684\u8def\u5f84\u3002 \u2003 \u6700\u7ec8\u7684\u7ed3\u679c\u662f \\(WordTree\\) \uff0c\u4e00\u4e2a\u89c6\u89c9\u6982\u5ff5\u7684\u5206\u5c42\u6a21\u578b\u3002\u4e3a\u4e86\u4f7f\u7528 \\(WordTree\\) \u8fdb\u884c\u5206\u7c7b\uff0c\u6211\u4eec\u9884\u6d4b\u6bcf\u4e2a\u8282\u70b9\u7684\u6761\u4ef6\u6982\u7387\uff0c\u4ee5\u5f97\u5230\u540c\u4e49\u8bcd\u96c6\u5408\u4e2d\u6bcf\u4e2a\u540c\u4e49\u8bcd\u4e0b\u4e49\u8bcd\u7684\u6982\u7387\u3002\u4f8b\u5982\uff0c\u5728terrier\u8282\u70b9\u6211\u4eec\u9884\u6d4b\uff1a \\(\\large\\operatorname{Pr} (Norfolk \\ terrier|terrier) \\\\ \\operatorname{Pr} (Yorkshire \\ terrier|terrier) \\\\ \\operatorname{Pr}( Bedlington \\ terrier|terrier )\\) \u2003\u5982\u679c\u6211\u4eec\u60f3\u8981\u8ba1\u7b97\u4e00\u4e2a\u7279\u5b9a\u8282\u70b9\u7684\u7edd\u5bf9\u6982\u7387\uff0c\u6211\u4eec\u53ea\u9700\u6cbf\u7740\u901a\u8fc7\u6811\u5230\u8fbe\u6839\u8282\u70b9\u7684\u8def\u5f84\uff0c\u518d\u4e58\u4ee5\u6761\u4ef6\u6982\u7387\u3002\u6240\u4ee5\u5982\u679c\u6211\u4eec\u60f3\u77e5\u9053\u4e00\u5f20\u56fe\u7247\u662f\u5426\u662fNorfolk terrier\uff0c\u6211\u4eec\u8ba1\u7b97\uff1a \\(\\operatorname{Pr}(\\text { Norfolk terrier }) = \\operatorname{Pr}(\\text { Norfolk terrier } \\mid \\text { terrier })\\) \\(\\quad * \\operatorname{Pr}(\\text { terrier } \\mid \\text { hunting dog })\\) \\(* \\ldots * \\\\\\) \\(* \\operatorname{Pr}(\\text { mammal } \\mid \\operatorname{Pr}(\\text { animal })\\) \\(* \\operatorname{Pr}(\\text { animal } \\mid \\text { physical object })\\) \u2003\u4e3a\u4e86\u5b9e\u73b0\u5206\u7c7b\uff0c\u6211\u4eec\u5047\u5b9a\u56fe\u50cf\u5305\u542b\u4e00\u4e2a\u76ee\u6807\uff1a \\(P r(physical object) = 1\\) \u3002 \u2003\u4e3a\u4e86\u9a8c\u8bc1\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u5728\u4f7f\u75281000\u7c7b \\(ImageNet\\) \u6784\u5efa\u7684 \\(WordTree\\) \u4e0a\u8bad\u7ec3 \\(Darknet-19\\) \u6a21\u578b\u3002 \u4e3a\u4e86\u6784\u5efa \\(WordTree1k\\) \uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u6240\u6709\u4e2d\u95f4\u8282\u70b9\uff0c\u5c06\u6807\u7b7e\u7a7a\u95f4\u4ece \\(1000\\) \u6269\u5c55\u5230 \\(1369\\) \u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u6211\u4eec\u5c06\u771f\u5b9e\u6807\u7b7e\u5411\u6811\u4e0a\u9762\u4f20\u64ad\uff0c\u4ee5\u4fbf\u5982\u679c\u56fe\u50cf\u88ab\u6807\u8bb0\u4e3aNorfolk terrier\uff0c\u5219\u5b83\u4e5f\u88ab\u6807\u8bb0\u4e3adog\u548cmamal\u7b49\u3002\u4e3a\u4e86\u8ba1\u7b97\u6761\u4ef6\u6982\u7387\uff0c\u6211\u4eec\u7684\u6a21\u578b\u9884\u6d4b\u4e861369\u4e2a\u503c\u7684\u5411\u91cf\uff0c\u5e76\u4e14\u6211\u4eec\u8ba1\u7b97\u4e86\u76f8\u540c\u6982\u5ff5\u7684\u4e0b\u4e49\u8bcd\u5728\u6240\u6709\u540c\u4e49\u8bcd\u96c6\u4e0a\u7684softmax\uff0c\u89c1\u56fe5\u3002 \u2003\u4f7f\u7528\u4e0e\u4ee5\u524d\u76f8\u540c\u7684\u8bad\u7ec3\u53c2\u6570\uff0c\u6211\u4eec\u7684\u5206\u5c42Darknet-19\u8fbe\u5230\u4e8671.9\uff05\u7684 \\(top-1\\) \u7cbe\u5ea6\u548c90.4\uff05\u7684 \\(top-5\\) \u7cbe\u5ea6\u3002 \u5c3d\u7ba1\u589e\u52a0\u4e86369\u4e2a\u9644\u52a0\u6982\u5ff5\uff0c\u5e76\u4e14\u8ba9\u6211\u4eec\u7684\u7f51\u7edc\u9884\u6d4b\u4e86\u6811\u72b6\u7ed3\u6784\uff0c\u4f46\u6211\u4eec\u7684\u7cbe\u5ea6\u4ec5\u7565\u6709\u4e0b\u964d\u3002 \u4ee5\u8fd9\u79cd\u65b9\u5f0f\u8fdb\u884c\u5206\u7c7b\u4e5f\u6709\u82e5\u5e72\u597d\u5904\u3002 \u5728\u65b0\u7684\u6216\u672a\u77e5\u7684\u76ee\u6807\u7c7b\u522b\u4e0a\uff0c\u6027\u80fd\u4f1a\u4f18\u96c5\u4f4e\u964d\u4f4e\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u7f51\u7edc\u770b\u5230\u4e00\u5f20\u72d7\u7684\u7167\u7247\uff0c\u4f46\u4e0d\u786e\u5b9a\u5b83\u662f\u4ec0\u4e48\u7c7b\u578b\u7684\u72d7\uff0c\u5b83\u4ecd\u7136\u4f1a\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u201cdog\u201d\uff0c\u53ea\u662f\u5728\u4e0b\u4e49\u8bcd\u4f1a\u6709\u8f83\u4f4e\u7684\u7f6e\u4fe1\u5ea6\u3002 \u2003\u8be5\u65b9\u6cd5\u4e5f\u9002\u7528\u4e8e\u68c0\u6d4b\u3002\u73b0\u5728\uff0c\u6211\u4eec\u4e0d\u7528\u5047\u5b9a\u6bcf\u4e2a\u56fe\u50cf\u90fd\u6709\u4e00\u4e2a\u76ee\u6807\u7269\u4f53\uff0c\u800c\u662f\u4f7f\u7528 \\(YOLOv2\\) \u7684\u76ee\u6807\u9884\u6d4b\u5668\u7ed9\u51faP r\uff08\u76ee\u6807\u7269\u4f53\uff09\u7684\u503c\u3002\u68c0\u6d4b\u5668\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u6982\u7387\u6811\u3002\u6211\u4eec\u904d\u5386\u6811\uff0c\u5728\u6bcf\u6b21\u5206\u5272\u4e2d\u9009\u53d6\u5177\u6709\u6700\u9ad8\u7684\u7f6e\u4fe1\u5ea6\u7684\u8def\u5f84\uff0c\u76f4\u5230\u8fbe\u5230\u67d0\u4e2a\u9608\u503c\uff0c\u7136\u540e\u6211\u4eec\u5f97\u5230\u8be5\u76ee\u6807\u7684\u7c7b\u522b\u3002 \u2003 \u6570\u636e\u96c6\u4e0e \\(WordTree\\) \u7684\u7ec4\u5408 (Dataset combination with WordTree)\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \\(WordTree\\) \u4ee5\u53ef\u884c\u7684\u65b9\u5f0f\u5c06\u591a\u4e2a\u6570\u636e\u96c6\u7ec4\u5408\u5728\u4e00\u8d77\u3002\u6211\u4eec\u53ea\u9700\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u6620\u5c04\u5230\u6811\u4e2d\u7684synsets\u5373\u53ef\u3002\u56fe6\u663e\u793a\u4e86\u4e00\u4e2a\u4f7f\u7528 \\(WordTree\\) \u7ec4\u5408\u6765\u81ea \\(ImageNet\\) \u548c \\(COCO\\) \u7684\u6807\u7b7e\u7684\u793a\u4f8b\u3002 WordNet\u975e\u5e38\u591a\u6837\u5316\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u8fd9\u79cd\u6280\u672f\u7528\u4e8e\u5927\u591a\u6570\u6570\u636e\u96c6\u3002 \u56fe5\uff1a\u5bf9 \\(ImageNet\\) \u4e0e \\(WordTree\\) \u7684\u9884\u6d4b\u3002\u5927\u591a\u6570ImaNet\u6a21\u578b\u4f7f\u7528\u4e00\u4e2a\u5927\u7684softmax\u6765\u9884\u6d4b\u6982\u7387\u5206\u5e03\u3002\u4f7f\u7528 \\(WordTree\\) \uff0c\u6211\u4eec\u901a\u8fc7\u5171\u540c\u7684\u4e0b\u4f4d\u8bcd\u6267\u884c\u591a\u4e2asoftmax\u64cd\u4f5c\u3002 \u2003 \u8054\u5408\u5206\u7c7b\u548c\u68c0\u6d4b (Joint classification and detection)\u3002\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \\(WordTree\\) \u7ec4\u5408\u6570\u636e\u96c6\uff0c\u5728\u5206\u7c7b\u548c\u68c0\u6d4b\u4e0a\u8bad\u7ec3\u8054\u5408\u6a21\u578b\u3002\u6211\u4eec\u60f3\u8981\u8bad\u7ec3\u4e00\u4e2a\u975e\u5e38\u5927\u89c4\u6a21\u7684\u68c0\u6d4b\u5668\uff0c\u6240\u4ee5\u4f7f\u7528 \\(COCO\\) \u68c0\u6d4b\u6570\u636e\u96c6\u548c\u5b8c\u6574 \\(ImageNet\\) \u7248\u672c\u4e2d\u7684\u524d9000\u7c7b\u521b\u5efa\u6211\u4eec\u7684\u7ec4\u5408\u6570\u636e\u96c6\u3002\u6211\u4eec\u8fd8\u9700\u8981\u8bc4\u4f30\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u4ee5\u4fbf\u4ece \\(ImageNet\\) \u68c0\u6d4b\u6311\u6218\u4e2d\u6dfb\u52a0\u4efb\u4f55\u5c1a\u672a\u5305\u542b\u7684\u7c7b\u3002\u8be5\u6570\u636e\u96c6\u7684\u76f8\u5e94 \\(WordTree\\) \u5177\u67099418\u4e2a\u7c7b\u3002 \\(ImageNet\\) \u6709\u66f4\u5927\u7684\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u901a\u8fc7\u5bf9 \\(COCO\\) \u8fdb\u884c\u8fc7\u91c7\u6837\u6765\u5e73\u8861\u6570\u636e\u96c6\uff0c\u4f7f\u5f97 \\(ImageNet\\) \u4e0e \\(COCO\\) \u7684\u6bd4\u4f8b\u7565\u5927\u4e8e \\(4:1\\) \u3002 \u2003\u6211\u4eec\u4f7f\u7528\u4e0a\u8ff0\u7684\u6570\u636e\u96c6\u8bad\u7ec3 \\(YOLO9000\\) \u3002 \u6211\u4eec\u4f7f\u7528\u57fa\u672c\u7684 \\(YOLOv2\\) \u67b6\u6784\uff0c\u4f46\u53ea\u67093\u4e2a\u5148\u9a8c\u6846\u800c\u4e0d\u662f5\u4e2a\u6765\u9650\u5236\u8f93\u51fa\u5927\u5c0f\u3002\u5f53\u6211\u4eec\u7684\u7f51\u7edc\u5904\u7406\u68c0\u6d4b\u56fe\u50cf\u65f6\uff0c\u6211\u4eec\u4f1a\u50cf\u5e73\u5e38\u4e00\u6837\u53cd\u5411\u4f20\u64ad\u635f\u5931\u3002\u5bf9\u4e8e\u5206\u7c7b\u635f\u5931\uff0c\u6211\u4eec\u53ea\u662f\u5c06\u635f\u5931\u53cd\u5411\u4f20\u64ad\u5230\u6807\u7b7e\u76f8\u5e94\u7ea7\u522b\u6216\u66f4\u9ad8\u7684\u7ea7\u522b\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u6807\u7b7e\u662f\u72d7\uff0c\u6211\u4eec\u4e0d\u4f1a\u5c06\u4efb\u4f55\u9519\u8bef\u7ed9\u6811\u505a\u8fdb\u4e00\u6b65\u9884\u6d4b\uff0c\u5982\u5fb7\u56fd\u7267\u7f8a\u72ac\u4e0e\u9ec4\u91d1\u730e\u72ac\uff0c\u56e0\u4e3a\u6211\u4eec\u6ca1\u6709\u8fd9\u4e9b\u4fe1\u606f\u3002 \u56fe6\uff1a\u4f7f\u7528 \\(WordTree\\) \u5c42\u6b21\u7ed3\u6784\u7ec4\u5408\u6570\u636e\u96c6\u3002\u4f7f\u7528WordNet\u6982\u5ff5\u56fe\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u89c6\u89c9\u6982\u5ff5\u7684\u5206\u5c42\u6811\u3002\u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u6620\u5c04\u5230\u6811\u4e2d\u7684synsets\u6765\u5408\u5e76\u6570\u636e\u96c6\u3002\u51fa\u4e8e\u8bf4\u660e\u76ee\u7684\uff0c\u8fd9\u662f \\(WordTree\\) \u7684\u7b80\u5316\u89c6\u56fe\u3002 \u2003\u5f53\u7f51\u7edc\u5904\u7406\u5206\u7c7b\u56fe\u50cf\u65f6\uff0c\u6211\u4eec\u53ea\u662f\u53cd\u5411\u4f20\u64ad\u5206\u7c7b\u635f\u5931\u3002\u8981\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ea\u9700\u627e\u5230\u9884\u6d4b\u8be5\u7c7b\u522b\u6700\u9ad8\u6982\u7387\u7684\u8fb9\u754c\u6846\uff0c\u7136\u540e\u5728\u9884\u6d4b\u7684\u6811\u4e0a\u8ba1\u7b97\u635f\u5931\u3002\u6211\u4eec\u8fd8\u5047\u8bbe\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u7684 \\(IOU\\) \u81f3\u5c11\u4e3a0.3\uff0c\u5e76\u4e14\u57fa\u4e8e\u8fd9\u4e2a\u5047\u8bbe\u6211\u4eec\u53cd\u5411\u4f20\u64ad\u76ee\u6807\u635f\u5931\u3002 \u2003\u901a\u8fc7\u8fd9\u79cd\u8054\u5408\u8bad\u7ec3\uff0c \\(YOLO9000\\) \u5b66\u4e60\u4f7f\u7528 \\(COCO\\) \u4e2d\u7684\u68c0\u6d4b\u6570\u636e\u6765\u67e5\u627e\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\uff0c\u5e76\u5b66\u4e60\u4f7f\u7528\u6765\u81ea \\(ImageNet\\) \u7684\u6570\u636e\u5bf9\u5404\u79cd\u8fd9\u4e9b\u76ee\u6807\u8fdb\u884c\u5206\u7c7b\u3002 \u2003\u6211\u4eec\u5728 \\(ImageNet\\) \u68c0\u6d4b\u4efb\u52a1\u4e0a\u8bc4\u4f30 \\(YOLO9000\\) \u3002 \\(ImageNet\\) \u7684\u68c0\u6d4b\u4efb\u52a1\u4e0e \\(COCO\\) \u5171\u4eab44\u4e2a\u76ee\u6807\u7c7b\u522b\uff0c\u8fd9\u610f\u5473\u7740 \\(YOLO9000\\) \u770b\u5230\u7684\u6d4b\u8bd5\u56fe\u50cf\u5927\u591a\u6570\u662f\u5206\u7c7b\u6570\u636e\uff0c\u800c\u4e0d\u662f\u68c0\u6d4b\u6570\u636e\u3002 \\(YOLO9000\\) \u7684\u603b \\(mAP\\) \u662f19.7 \\(mAP\\) \uff0c\u5176\u4e2d\u5728\u4e0d\u76f8\u4ea4\u7684156\u4e2a\u76ee\u6807\u7c7b\u4e0a\uff0c \\(YOLO9000\\) \u4ece\u672a\u89c1\u8fc7\u8fd9\u4e9b\u7c7b\u7684\u4efb\u4f55\u68c0\u6d4b\u6570\u636e\u7684\u6807\u7b7e\uff0c\u4ecd\u83b7\u5f97\u4e8616.0 \\(mAP\\) \u3002\u8fd9\u4e2a \\(mAP\\) \u9ad8\u4e8eDPM\u7684\u7ed3\u679c\uff0c\u4f46 \\(YOLO9000\\) \u662f\u5728\u90e8\u5206\u76d1\u7763[4]\u7684\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u3002\u800c\u4e14\u5b83\u80fd\u540c\u65f6\u68c0\u6d4b9000\u4e2a\u5176\u4ed6\u76ee\u6807\u7c7b\u522b\uff0c\u6240\u6709\u7684\u68c0\u6d4b\u90fd\u662f\u5b9e\u65f6\u7684\u3002 \u2003\u5728\u5206\u6790 \\(YOLO9000\\) \u5728 \\(ImageNet\\) \u4e0a\u7684\u8868\u73b0\u65f6\uff0c\u6211\u4eec\u53d1\u73b0\u5b83\u5f88\u597d\u5730\u5b66\u4e60\u4e86\u65b0\u7684\u52a8\u7269\u79cd\u7c7b\uff0c\u4f46\u662f\u5728\u50cf\u670d\u88c5\u548c\u8bbe\u5907\u8fd9\u6837\u7684\u5b66\u4e60\u7c7b\u522b\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u65b0\u52a8\u7269\u66f4\u5bb9\u6613\u5b66\u4e60\uff0c\u56e0\u4e3a\u76ee\u6807\u9884\u6d4b\u53ef\u4ee5\u4ece \\(COCO\\) \u4e2d\u7684\u52a8\u7269\u6cdb\u5316\u7684\u5f88\u597d\u3002\u76f8\u53cd\uff0c \\(COCO\\) \u6ca1\u6709\u4efb\u4f55\u7c7b\u578b\u7684\u8863\u670d\u7684\u8fb9\u754c\u6846\u6807\u7b7e\uff0c\u53ea\u9488\u5bf9\u4eba\uff0c\u56e0\u6b64 \\(YOLO9000\\) \u5728\u5206\u7c7b\u201c\u58a8\u955c\u201d\u6216\u201c\u6cf3\u88e4\u201d\u7b49\u7c7b\u522b\u4e0a\u5b58\u5728\u56f0\u96be\u3002 \\(\\begin{array}{ll} \\text { diaper } & 0.0 \\\\ \\text { horizontal bar } & 0.0 \\\\ \\text { rubber eraser } & 0.0 \\\\ \\text { sunglasses } & 0.0 \\\\ \\text { swimming trunks } & 0.0 \\\\ \\ldots & \\\\ \\text { red panda } & 50.7 \\\\ \\text { fox } & 52.1 \\\\ \\text { koala bear } & 54.3 \\\\ \\text { tiger } & 61.0 \\\\ \\text { armadillo } & 61.7 \\end{array}\\) \u88687\uff1a \\(ImageNet\\) \u4e0a\u7684 \\(YOLO9000\\) \u6700\u4f73\u548c\u6700\u5dee\u7c7b\u522b\u3002 156\u4e2a\u5f31\u76d1\u7763\u7c7b\u7684AP\u6700\u9ad8\u548c\u6700\u4f4e\u7684\u7c7b\u3002 \\(YOLO9000\\) \u6a21\u578b\u5f88\u597d\u5730\u9884\u6d4b\u5404\u79cd\u5404\u6837\u7684\u52a8\u7269\uff0c\u4f46\u4e0d\u64c5\u957f\u9884\u6d4b\u8bf8\u5982\u670d\u88c5\u6216\u8bbe\u5907\u7b49\u7684\u65b0\u7c7b\u3002","title":"4.\u66f4\u5f3a"},{"location":"thesis_interpretation/02_yolo.html#5","text":"\u6211\u4eec\u4ecb\u7ecd\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf \\(YOLOv2\\) \u548c \\(YOLO9000\\) \u3002 \\(YOLOv2\\) \u5728\u5404\u79cd\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u90fd\u662f\u6700\u5148\u8fdb\u7684\uff0c\u5e76\u4e14\u6bd4\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u66f4\u5feb\u3002\u6b64\u5916\uff0c\u5b83\u53ef\u4ee5\u5728\u5404\u79cd\u56fe\u50cf\u5c3a\u5bf8\u4e0b\u8fd0\u884c\uff0c\u4ee5\u63d0\u4f9b\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5e73\u6ed1\u6298\u4e2d\u3002 \u2003 \\(YOLO9000\\) \u662f\u4e00\u4e2a\u901a\u8fc7\u8054\u5408\u4f18\u5316\u68c0\u6d4b\u548c\u5206\u7c7b\u6765\u68c0\u6d4b\u8d85\u8fc79000\u4e2a\u76ee\u6807\u7c7b\u522b\u7684\u5b9e\u65f6\u6846\u67b6\u3002\u6211\u4eec\u4f7f\u7528 \\(WordTree\\) \u5c06\u5404\u79cd\u6765\u6e90\u7684\u6570\u636e\u548c\u6211\u4eec\u7684\u8054\u5408\u4f18\u5316\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u5728 \\(ImageNet\\) \u548c \\(COCO\\) \u4e0a\u540c\u65f6\u8fdb\u884c\u8bad\u7ec3\u3002 \\(YOLO9000\\) \u5411\u7f29\u5c0f\u68c0\u6d4b\u548c\u5206\u7c7b\u4e4b\u95f4\u7684\u6570\u636e\u96c6\u5927\u5c0f\u7684\u5dee\u8ddd\u8fc8\u51fa\u4e86\u575a\u5b9e\u7684\u4e00\u6b65\u3002 \u2003\u6211\u4eec\u7684\u8bb8\u591a\u6280\u672f\u90fd\u662f\u6cdb\u5316\u5230\u76ee\u6807\u68c0\u6d4b\u4e4b\u5916\u7684\u9886\u57df\u3002 \\(ImageNet\\) \u7684 \\(WordTree\\) \u8868\u793a\u65b9\u6cd5\u4e3a\u56fe\u50cf\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\uff0c\u66f4\u8be6\u7ec6\u7684\u8f93\u51fa\u7a7a\u95f4\u3002\u4f7f\u7528\u5206\u5c42\u5206\u7c7b\u7684\u6570\u636e\u96c6\u7ec4\u5408\u5728\u5206\u7c7b\u548c\u5206\u5272\u9886\u57df\u5c06\u4f1a\u5f88\u6709\u7528\u3002\u50cf\u591a\u5c3a\u5ea6\u8bad\u7ec3\u8fd9\u6837\u7684\u8bad\u7ec3\u6280\u672f\u53ef\u4ee5\u4e3a\u5404\u79cd\u89c6\u89c9\u4efb\u52a1\u63d0\u4f9b\u5e2e\u52a9\u3002 \u2003\u5bf9\u4e8e\u672a\u6765\u7684\u5de5\u4f5c\uff0c\u6211\u4eec\u5e0c\u671b\u4f7f\u7528\u7c7b\u4f3c\u7684\u6280\u672f\u8fdb\u884c\u5f31\u76d1\u7763\u56fe\u50cf\u5206\u5272\u3002\u6211\u4eec\u8fd8\u8ba1\u5212\u4f7f\u7528\u66f4\u5f3a\u5927\u7684\u5339\u914d\u7b56\u7565\u6765\u6539\u5584\u6211\u4eec\u7684\u68c0\u6d4b\u7ed3\u679c\uff0c\u4ee5\u5728\u8bad\u7ec3\u671f\u95f4\u5c06\u5f31\u6807\u7b7e\u5206\u914d\u7ed9\u5206\u7c7b\u6570\u636e\u3002\u8ba1\u7b97\u673a\u89c6\u89c9\u62e5\u6709\u5927\u91cf\u7684\u6807\u8bb0\u6570\u636e\u3002\u6211\u4eec\u5c06\u7ee7\u7eed\u5bfb\u627e\u65b9\u6cd5\uff0c\u5c06\u4e0d\u540c\u7684\u6570\u636e\u6765\u6e90\u548c\u6570\u636e\u7ed3\u6784\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u5f62\u6210\u66f4\u5f3a\u5927\u7684\u89c6\u89c9\u4e16\u754c\u6a21\u578b\u3002","title":"5.\u603b\u7ed3"},{"location":"thesis_interpretation/02_yolo.html#references","text":"[1] S. Bell, C. L. Zitnick, K. Bala, and R. Girshick. Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks. arXiv preprint arXiv:1512.04143, 2015. 6 [2] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 248\u2013255. IEEE, 2009. 1 [3] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) chal-lenge. International journal of computer vision, 88(2):303\u2013338, 2010. 1 [4] P. F. Felzenszwalb, R. B. Girshick, and D. McAllester. Discriminatively trained deformable part models, release 4. http://people.cs.uchicago.edu/ pff/latent-release4/. 8 [5] R. B. Girshick. Fast R-CNN. CoRR, abs/1504.08083, 2015. 4, 5, 6 [6] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learn-ing for image recognition. arXiv preprint arXiv:1512.03385, 2015. 2, 4, 5 [7] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015. 2, 5 [8] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097\u20131105, 2012. 2 [9] M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.4400, 2013. 5 [10] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ra-manan, P. Doll\u00b4ar, and C. L. Zitnick. Microsoft coco: Com-mon objects in context. In European Conference on Com-puter Vision, pages 740\u2013755. Springer, 2014. 1, 6 [11] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, and S. E. Reed. SSD: single shot multibox detector. CoRR, abs/1512.02325, 2015. 4, 5, 6 [12] G. A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. J. Miller. Introduction to wordnet: An on-line lexical database. International journal of lexicography, 3(4):235\u2013244, 1990. 6 [13] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 5 [14] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. arXiv preprint arXiv:1506.02640, 2015. 4, 5 [15] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: To-wards real-time object detection with region proposal net-works. arXiv preprint arXiv:1506.01497, 2015. 2, 3, 4, 5, 6 [16] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. 2 [17] K. Simonyan and A. Zisserman. V ery deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. 2, 5 [18] C. Szegedy, S. Ioffe, and V . V anhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR, abs/1602.07261, 2016. 2 [19] C. Szegedy, W. Liu, Y . Jia, P . Sermanet, S. Reed, D. Anguelov, D. Erhan, V . V anhoucke, and A. Rabinovich.Going deeper with convolutions. CoRR, abs/1409.4842, 2014. 5 [20] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):64\u201373, 2016. 1","title":"References"},{"location":"thesis_interpretation/03_yolo.html","text":"\u539f\u6587\u5730\u5740 : https://arxiv.org/pdf/1804.02767v1.pdf \\(YOLOv3\\) : An Incremental Improvement \\(YOLOv3\\) \uff1a\u589e\u91cf\u5f0f\u7684\u6539\u8fdb Joseph Redmon Ali Farhadi University of Washington \u6458\u8981 \u6211\u4eec\u5bf9YOLO\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u66f4\u65b0\uff01\u5b83\u5305\u542b\u4e00\u5806\u5c0f\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u4f7f\u7cfb\u7edf\u7684\u6027\u80fd\u5f97\u5230\u66f4\u65b0\u3002\u6211\u4eec\u4e5f\u8bad\u7ec3\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u6bd4\u8f83\u5927\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u867d\u7136\u6bd4\u4e0a\u4e00\u7248\u66f4\u5927\u4e00\u4e9b\uff0c\u4f46\u662f\u7cbe\u5ea6\u4e5f\u63d0\u9ad8\u4e86\u3002\u4e0d\u7528\u62c5\u5fc3\uff0c\u5b83\u7684\u901f\u5ea6\u4f9d\u7136\u5f88\u5feb\u3002 \\(YOLOv3\\) \u5728 \\(320\u00d7320\\) \u8f93\u5165\u56fe\u50cf\u4e0a\u8fd0\u884c\u65f6\u53ea\u9700 \\(22ms\\) \uff0c\u5e76\u80fd\u8fbe\u5230 \\(28.2mAP\\) \uff0c\u5176\u7cbe\u5ea6\u548c \\(SSD\\) \u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u8981\u5feb\u4e0a \\(3\\) \u500d\u3002\u4f7f\u7528\u4e4b\u524d \\(0.5 \\ IOU \\ mAP\\) \u7684\u68c0\u6d4b\u6307\u6807\uff0c \\(YOLOv3\\) \u7684\u6548\u679c\u662f\u76f8\u5f53\u4e0d\u9519\u3002 \\(YOLOv3\\) \u4f7f\u7528Titan X GPU\uff0c\u5b83\u5728 \\(51ms\\) \u68c0\u6d4b\u7cbe\u5ea6\u8fbe\u5230 \\(57.9 \\ AP50\\) \uff0c\u7136\u800c\u4e0e \\(RetinaNet\\) \u76f8\u6bd4 \uff0c\u5176\u7cbe\u5ea6\u53ea\u6709 \\(57.5 \\ AP50\\) \uff0c\u4f46\u5374\u8017\u65f6 \\(198ms\\) \uff0c\u76f8\u540c\u6027\u80fd\u7684\u60c5\u51b5\u4e0b \\(YOLOv3\\) \u901f\u5ea6\u6bd4 \\(RetinaNet\\) \u5feb \\(3.8\\) \u500d\u3002\u4e0e\u4e4b\u524d\u4e00\u6837\uff0c\u6240\u6709\u4ee3\u7801\u5728\u7f51\u5740\uff1ahttps://pjreddie.com/yolo/\u3002 1.\u5f15\u8a00 \u2003\u6709\u65f6\u5019\uff0c\u4e00\u5e74\u5185\u4f60\u4e3b\u8981\u90fd\u5728\u73a9\u624b\u673a\uff0c\u4f60\u77e5\u9053\u5417\uff1f\u4eca\u5e74\u6211\u6ca1\u6709\u505a\u5f88\u591a\u7814\u7a76\u3002\u6211\u5728 \\(Twitter\\) \u4e0a\u82b1\u4e86\u5f88\u591a\u65f6\u95f4,\u5728GANs\u4e0a\u73a9\u4e86\u70b9\u5c0f\u6e38\u620f\u3002\u53bb\u5e74\u6211\u7559\u4e0b\u4e86\u4e00\u70b9\u70b9\u7684\u7cbe\u529b [12] [1]\uff1b\u6211\u8bbe\u6cd5\u5bf9 \\(YOLO\\) \u8fdb\u884c\u4e86\u4e00\u4e9b\u6539\u8fdb\u3002\u4f46\u662f\uff0c\u5b9e\u8bdd\u5b9e\u8bf4\uff0c\u4ec5\u4ec5\u4e00\u4e9b\u5c0f\u7684\u6539\u53d8\u4f7f\u5f97\u5b83\u53d8\u5f97\u66f4\u597d\uff0c\u6ca1\u6709\u4ec0\u4e48\u8d85\u7ea7\u6709\u8da3\u7684\u4e8b\u60c5\u3002\u6211\u4e5f\u7a0d\u5fae\u5e2e\u52a9\u4e86\u5176\u4ed6\u4eba\u7684\u4e00\u4e9b\u7814\u7a76\u3002 \u2003\u4e8b\u5b9e\u4e0a\uff0c\u8fd9\u5c31\u662f\u6211\u4eec\u4eca\u5929\u6765\u8fd9\u91cc\u7684\u539f\u56e0\u3002\u6211\u4eec\u6709\u4e00\u7bc7\u8bba\u6587\u5feb\u622a\u7a3f\u4e86\uff0c\u5e76\u4e14\u6211\u4eec\u8fd8\u7f3a\u4e00\u7bc7\u5173\u4e8e \\(YOLO\\) \u66f4\u65b0\u5185\u5bb9\u7684\u6587\u7ae0\u4f5c\u4e3a\u5f15\u7528\uff0c\u4f46\u662f\u6211\u4eec\u6ca1\u6709\u5f15\u7528\u6765\u6e90\u3002\u6240\u4ee5\uff0c\u51c6\u5907\u597d\u8fce\u63a5\u79d1\u6280\u62a5\u9053\u5427! \u2003\u6280\u672f\u62a5\u544a\u6700\u68d2\u7684\u4e00\u70b9\u5c31\u662f\u4ed6\u4eec\u4e0d\u9700\u8981\u4ecb\u7ecd\uff0c\u4f60\u4eec\u90fd\u77e5\u9053\u6211\u4eec\u4e3a\u4ec0\u4e48\u5728\u8fd9\u91cc\u3002\u56e0\u6b64\uff0c\u8fd9\u7bc7\u4ecb\u7ecd\u7684\u7ed3\u5c3e\u5c06\u4e3a\u672c\u6587\u7684\u5176\u4f59\u90e8\u5206\u6307\u660e\u65b9\u5411\u3002\u9996\u5148\u6211\u4eec\u4f1a\u544a\u8bc9\u4f60 \\(YOLOv3\\) \u7684\u65b9\u6848\u3002\u5176\u6b21\u6211\u4eec\u4f1a\u544a\u8bc9\u4f60\u6211\u4eec\u662f\u5982\u4f55\u5b9e\u73b0\u7684\u3002\u6211\u4eec\u4e5f\u4f1a\u544a\u8bc9\u4f60\u6211\u4eec\u5c1d\u8bd5\u8fc7\u4f46\u5e76\u4e0d\u594f\u6548\u7684\u4e00\u4e9b\u4e8b\u60c5\u3002\u6700\u540e\u6211\u4eec\u5c06\u63a2\u8ba8\u8fd9\u4e9b\u7684\u610f\u4e49\u3002 2.\u65b9\u6848 \u2003\u8fd9\u8282\u4e3b\u8981\u4ecb\u7ecd \\(YOLOv3\\) \u7684\u66f4\u65b0\u65b9\u6848\uff1a\u6211\u4eec\u4e3b\u8981\u4ece\u5176\u4ed6\u4eba\u7684\u7814\u7a76\u5de5\u4f5c\u91cc\u83b7\u5f97\u4e86\u4e00\u4e9b\u597d\u601d\u8def\u3001\u597d\u60f3\u6cd5\u3002\u6211\u4eec\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u6bd4\u5176\u4ed6\u7f51\u7edc\u66f4\u597d\u7684\u5206\u7c7b\u7f51\u7edc\u3002\u4e3a\u4e86\u65b9\u4fbf\u7406\u89e3\uff0c\u8ba9\u6211\u4eec\u4ece\u5934\u5f00\u59cb\u6162\u6162\u4ecb\u7ecd\u6574\u4e2a\u6a21\u578b\u7cfb\u7edf\u3002 \u56fe1. \u6e90\u81ea \\(Focal \\ Loss\\) \u8bba\u6587[9]\u3002 \\(YOLOv3\\) \u7684\u8fd0\u884c\u901f\u5ea6\u660e\u663e\u5feb\u4e8e\u5176\u4ed6\u6027\u80fd\u76f8\u5f53\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002\u68c0\u6d4b\u65f6\u95f4\u57fa\u4e8e \\(M40\\) \u6216 \\(Titan \\ X\\) \uff08 \u5176\u4e2d \\(M40,Titan X\\) \u662f\u76f8\u4f3c\u7684\u4e24\u79cd \\(GPU\\) \uff09\u3002 2.1 \u8fb9\u754c\u6846\u9884\u6d4b \u2003\u548c \\(YOLO9000\\) \u4e00\u6837\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u4e5f\u4f7f\u7528\u7ef4\u5ea6\u805a\u7c7b\u7b97\u6cd5\u751f\u6210\u7684\u951a\u6846\uff08 anchor boxes \uff09[15] \u6765\u9884\u6d4b\u8fb9\u754c\u6846\u3002\u7f51\u7edc\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u76844\u4e2a\u5750\u6807\uff1a \\(t_x\u3001t_y\u3001t_w\u3001t_h\\) \u3002\u5047\u8bbe\u683c\u5b50\u8ddd\u79bb\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u504f\u79fb\u91cf\u4e3a \\((c_x\uff0cc_y)\\) \uff0c\u4e14\u4e4b\u524d\u7684\u8fb9\u754c\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e3a \\(p_w, p_h\\) \uff0c\u5219\u9884\u6d4b\u7ed3\u679c: \\[ {\\large \\begin{align} b_{x} & = \\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} & = \\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} & = p_{w} e^{t_{w}} \\\\ b_{h} & = p_{h} e^{t_{h}} \\end{align}} \\] \u2003\u5728\u8bad\u7ec3\u4e2d\u6211\u4eec\u4f7f\u7528\u8bef\u5dee\u5e73\u65b9\u548c\u635f\u5931\u8ba1\u7b97\u3002\u5982\u679c\u67d0\u4e2a\u9884\u6d4b\u5750\u6807\u7684 \\(ground \\ truth\\) \u662f \\(\\hat{t}_*\\) \uff0c\u90a3\u4e48\u5bf9\u5e94\u7684\u68af\u5ea6\u5c31\u662f \\(ground \\ truth \\ value\\) \uff08\u7531 \\(ground \\ truth \\ box\\) \u8ba1\u7b97\u800c\u5f97\uff09\u548c\u9884\u6d4b\u503c\u4e4b\u5dee\uff1a \\(\\hat{t}_* - t_*\\) \u3002\u901a\u8fc7\u53d8\u6362\u4e0a\u8ff0\u516c\u5f0f\u8ba1\u7b97,\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5f97\u5230 \\(ground \\ truth \\ value\\) \u3002 \u56fe2\uff1a \u7ef4\u5ea6\u5148\u9a8c\u548c\u4f4d\u7f6e\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u3002 \\(\\large{\\sigma(t_x)}\\) , \\(\\large{\\sigma(t_y)}\\) \u662f\u57fa\u4e8e\u77e9\u5f62\u6846\u4e2d\u5fc3\u70b9\u5de6\u4e0a\u89d2\u683c\u70b9\u5750\u6807\u7684\u504f\u79fb\u91cf\uff0c \\(\\large{\\sigma}\\) \u662f\u6fc0\u6d3b\u51fd\u6570\uff0c\u8bba\u6587\u4e2d\u4f5c\u8005\u4f7f\u7528 sigmoid [15]\u3002 \\(\\large{P_w,P_h}\\) \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u3001\u9ad8\uff0c\u901a\u8fc7\u4e0a\u8ff0\u516c\u5f0f\uff0c\u8ba1\u7b97\u51fa\u5b9e\u9645\u9884\u6d4b\u6846\u7684\u5bbd\u9ad8 \u3002 \u2003 \\(YOLOv3\\) \u4f7f\u7528\u903b\u8f91\u56de\u5f52\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u662f\u76ee\u6807\u7684\u5206\u6570\u3002\u5982\u679c\u771f\u5b9e\u6807\u7b7e\u6846\u4e0e\u67d0\u4e2a\u8fb9\u754c\u6846\u91cd\u53e0\u7684\u9762\u79ef\u6bd4\u4e0e\u5176\u4ed6\u4efb\u4f55\u8fb9\u754c\u6846\u90fd\u5927\uff0c\u90a3\u4e48\u8fd9\u4e2a\u5148\u9a8c\u8fb9\u754c\u6846\u5f97\u5206\u4e3a1\u3002\u6309\u7167[17]\u7684\u505a\u6cd5\uff0c\u5982\u679c\u5148\u9a8c\u8fb9\u754c\u6846\u4e0d\u662f\u6700\u597d\u7684\uff0c\u4f46\u662f\u786e\u5b9e\u4e0e\u76ee\u6807\u7684\u771f\u5b9e\u6807\u7b7e\u6846\u91cd\u53e0\u7684\u9762\u79ef\u5927\u4e8e\u9608\u503c\uff0c\u6211\u4eec\u4e5f\u4f1a\u5ffd\u7565\u8fd9\u4e2a\u9884\u6d4b\u3002\u6211\u4eec\u4f7f\u7528\u9608\u503c\u4e3a0.5\u3002\u4e0e[17]\u4e0d\u540c\u7684\u662f\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u53ea\u4e3a\u6bcf\u4e2a\u771f\u5b9e\u76ee\u6807\u5206\u914d\u4e00\u4e2a\u8fb9\u754c\u6846\u3002\u5982\u679c\u5148\u9a8c\u8fb9\u754c\u6846\u672a\u5206\u914d\u5230\u771f\u5b9e\u76ee\u6807\uff0c\u5219\u4e0d\u4f1a\u4ea7\u751f\u5750\u6807\u6216\u7c7b\u522b\u9884\u6d4b\u7684\u635f\u5931\uff0c\u53ea\u4f1a\u4ea7\u751f\u662f\u5426\u662f\u76ee\u6807\u7684\u635f\u5931\u3002 2.2 \u5206\u7c7b\u9884\u6d4b \u2003\u6bcf\u4e2a\u8fb9\u754c\u6846\u90fd\u4f1a\u4f7f\u7528\u591a\u6807\u7b7e\u5206\u7c7b\u6765\u9884\u6d4b\u6846\u4e2d\u53ef\u80fd\u5305\u542b\u7684\u7c7b\u3002\u6211\u4eec\u4e0d\u7528 \\(softmax\\) \uff0c\u800c\u662f\u7528\u5355\u72ec\u7684\u903b\u8f91\u5206\u7c7b\u5668\uff0c\u56e0\u4e3a\u6211\u4eec\u53d1\u73b0\u524d\u8005\u5bf9\u4e8e\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u6ca1\u4ec0\u4e48\u4f5c\u7528\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u7528binary cross-entropy\uff08\u4e8c\u5143\u4ea4\u53c9\u71b5\uff09\u635f\u5931\u6765\u9884\u6d4b\u7c7b\u522b\u3002 \u2003\u5f53\u6211\u4eec\u8f6c\u5411\u66f4\u590d\u6742\u7684\u9886\u57df\uff0c\u4f8b\u5982 \\(Open \\ Images \\ Dataset\\) [7]\uff0c\u4e0a\u9762\u7684\u8fd9\u79cd\u6539\u53d8\u5c06\u53d8\u5f97\u5f88\u6709\u7528\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u4e2d\u6709\u8bb8\u591a\u91cd\u53e0\u7684\u6807\u7b7e\uff08\u4f8b\u5982\u5973\u6027\u548c\u4eba\uff09\u3002\u4f7f\u7528 \\(softmax\\) \u4f1a\u5047\u5b9a\u6bcf\u4e2a\u6846\u53ea\u5305\u542b\u4e00\u4e2a\u7c7b\uff0c\u4f46\u901a\u5e38\u60c5\u51b5\u5e76\u975e\u5982\u6b64\u3002\u591a\u6807\u7b7e\u7684\u65b9\u5f0f\u53ef\u4ee5\u66f4\u597d\u5730\u5bf9\u6570\u636e\u8fdb\u884c\u5efa\u6a21\u3002 2.3 \u8de8\u5c3a\u5ea6\u9884\u6d4b \u2003 \\(YOLOv3\\) \u5728 3 \u79cd\u4e0d\u540c\u5c3a\u5ea6\u4e0a\u9884\u6d4b\u6846\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u4f7f\u7528\u7c7b\u4f3c\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc\u7684\u76f8\u4f3c\u6982\u5ff5( \u8be6\u7ec6\u53ef\u89c1\u8bba\u6587\uff1ahttps://arxiv.org/pdf/1612.03144.pdf )\uff0c\u5e76\u4ece\u8fd9\u4e9b\u5c3a\u5ea6\u4e2d\u63d0\u53d6\u7279\u5f81[8]\u3002\u6211\u4eec\u5728\u57fa\u7840\u7279\u5f81\u63d0\u53d6\u5668\u4e0a\u6dfb\u52a0\u4e86\u51e0\u4e2a\u5377\u79ef\u5c42\u3002\u5176\u4e2d\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42 \u9884\u6d4b\u4e86\u4e00\u4e2a\u7f16\u7801\u8fb9\u754c\u6846\u3001\u662f\u5426\u662f\u76ee\u6807\u548c\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c \u7684\u4e09\u7ef4\u5f20\u91cf\u3002\u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c[8]\u4e2d\uff0c\u6211\u4eec\u4e3a\u6bcf\u4e2a\u5c3a\u5ea6\u9884\u6d4b3\u4e2a\u6846\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u8fb9\u754c\u6846\u6709 4\u4e2a\u504f\u79fb\u91cf\u30011\u4e2a\u76ee\u6807\u9884\u6d4b\u548c80\u4e2a\u7c7b\u522b\u9884\u6d4b\uff0c\u6700\u7ec8\u7684\u5f20\u91cf\u5927\u5c0f\u4e3a \\(N\u00d7N\u00d7[3\u00d7(4+1+80)]\\) \u3002 \u2003\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4ece\u524d\u9762\u76842\u4e2a\u5c42\u4e2d\u63d0\u53d6\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u5176\u4e0a\u91c7\u68372\u500d\u3002\u6211\u4eec\u8fd8\u4ece\u7f51\u7edc\u4e2d\u7684\u8f83\u524d\u7684\u5c42\u4e2d\u83b7\u53d6\u4e00\u4e2a\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u5176\u4e0e\u6211\u4eec\u7684\u4e0a\u91c7\u6837\u7279\u5f81\u56fe\u8fdb\u884c\u62fc\u63a5\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u6211\u4eec\u80fd\u591f\u4ece\u4e0a\u91c7\u6837\u7684\u7279\u5f81\u56fe\u4e2d\u83b7\u5f97\u66f4\u6709\u610f\u4e49\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u540c\u65f6\u53ef\u4ee5\u4ece\u66f4\u524d\u7684\u5c42\u4e2d\u83b7\u53d6\u66f4\u7ec6\u7c92\u5ea6\u7684\u4fe1\u606f\u3002\u7136\u540e\uff0c\u6211\u4eec\u6dfb\u52a0\u51e0\u4e2a\u5377\u79ef\u5c42\u6765\u5904\u7406\u8fd9\u4e2a\u7279\u5f81\u6620\u5c04\u7ec4\u5408\uff0c\u5e76\u6700\u7ec8\u9884\u6d4b\u51fa\u4e00\u4e2a\u76f8\u4f3c\u7684\u3001\u5927\u5c0f\u662f\u539f\u5148\u4e24\u500d\u7684\u5f20\u91cf\u3002 \u2003\u6211\u4eec\u518d\u6b21\u4f7f\u7528\u76f8\u540c\u7684\u8bbe\u8ba1\u6765\u9884\u6d4b\u6700\u7ec8\u5c3a\u5bf8\u7684\u8fb9\u754c\u6846\u3002\u56e0\u6b64\uff0c\u7b2c\u4e09\u4e2a\u5c3a\u5bf8\u7684\u9884\u6d4b\u5c06\u65e2\u80fd\u4ece\u6240\u6709\u5148\u524d\u7684\u8ba1\u7b97\uff0c\u53c8\u80fd\u4ece\u7f51\u7edc\u524d\u9762\u7684\u5c42\u4e2d\u7684\u7ec6\u7c92\u5ea6\u7684\u7279\u5f81\u4e2d\u83b7\u76ca\u3002 \u2003\u6211\u4eec\u4ecd\u7136\u4f7f\u7528k-means\u805a\u7c7b\u7b97\u6cd5\u6765\u786e\u5b9a\u6211\u4eec\u7684\u5148\u9a8c\u8fb9\u754c\u6846\u3002\u6211\u4eec\u53ea\u662f\u9009\u62e9\u4e869\u4e2a\u805a\u7c7b( clusters )\u548c3\u4e2a\u4efb\u610f\u7684\u5c3a\u5ea6( scales arbitrarily )\uff0c \u7136\u540e\u5728\u5c3a\u5ea6\u4e0a\u5c06\u805a\u7c7b\u5747\u5300\u5730\u5212\u5206\u805a\u7c7b\u3002 \u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\uff0c9\u4e2a\u805a\u7c7b\u5206\u522b \u4e3a \\((10\u00d713)\u3001(16\u00d730)\u3001(33\u00d723)\u3001(30\u00d761)\u3001(62\u00d745)\u3001(59\u00d7119)\u3001(116 \u00d7 90)\u3001(156 \u00d7 198)\u3001(373 \u00d7 326)\\) \u3002 2.4 \u7279\u5f81\u63d0\u53d6\u5668 \u2003\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u65b0\u7684\u7f51\u7edc\u6765\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002\u6211\u4eec\u7684\u65b0\u7f51\u7edc\u878d\u5408\u4e86 \\(YOLOv2\u3001Darknet-19\\) \u548c\u65b0\u53d1\u660e\u7684\u6b8b\u5dee\u7f51\u7edc\u7684\u601d\u60f3\u3002\u6211\u4eec\u7684\u7f51\u7edc\u4f7f\u7528\u8fde\u7eed\u7684 \\(3\u00d73\\) \u548c \\(1\u00d71\\) \u5377\u79ef\u5c42\u548c\u6dfb\u52a0\u4e86\u4e00\u4e9b\u5feb\u6377\u8fde\u63a5\uff08shortcut connetction\uff09\uff0c\u4ece\u800c\u89c4\u6a21\u66f4\u5927\uff0c\u76ee\u524d\u5b83\u670953\u4e2a\u5377\u79ef\u5c42\uff0c\u6240\u4ee5\u6211\u4eec\u79f0\u4e4b\u4e3a... \\(Darknet-53!\\) \u88681. Darknet-53. \u6211\u4eec\u7684\u7f51\u7edc\u5728\u6027\u80fd\u4e0a\u8fdc\u8d85Darknet-19\uff0c\u5728\u6548\u7387\u4e0a\u4e5f\u4f18\u4e8eResNet-101\u548cResNet-152\u3002\u8fd9\u91cc\u662f\u4e00\u4e9b\u7f51\u7edc\u5728ImageNet\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\uff1a \\[ \\begin{eqnarray} \\text { Backbone } & \\text { Top-1 } & \\text { Top-5 } & \\text { Bn Ops } & \\text { BFLOP/s } & \\text { FPS } \\\\ \\hline \\text { Darknet-19[15] } & 74.1 & 91.8 & 7.29 & 1246 & \\mathbf{1 7 1} \\\\ \\text { ResNet-101[5] } & 77.1 & 93.7 & 19.7 & 1039 & 53 \\\\ \\text { ResNet-152[5] } & \\mathbf{7 7 . 6} & \\mathbf{9 3 . 8} & 29.4 & 1090 & 37 \\\\ \\text { Darknet-53 } & 77.2 & \\mathbf{9 3 . 8} & 18.7 & \\mathbf{1 4 5 7} & 78 \\end{eqnarray} \\] \u88682.\u7f51\u7edc\u7684\u6bd4\u8f83\u3002\u4e0d\u540cbackbones\u7684\u5404\u79cd\u7f51\u7edc\u5728\u51c6\u786e\u5ea6\u3001Bn Ops\uff08\u5341\u4ebf\u64cd\u4f5c\u6570\uff09\u3001BFLOP/s\uff08\u6bcf\u79d2\u5341\u4ebf\u6d6e\u70b9\u64cd\u4f5c\uff09\u548cFPS\u4e0a\u7684\u6bd4\u8f83\u3002 \u2003\u6bcf\u4e2a\u7f51\u7edc\u90fd\u5728\u76f8\u540c\u7684\u914d\u7f6e\u4e0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5747\u7528 \\(256 \u00d7256\\) \u7684\u56fe\u7247\u4e0a\u8fdb\u884c\u5355\u7cbe\u5ea6\u6d4b\u8bd5\u3002\u8fd0\u884c\u65f6\u95f4\u901a\u8fc7\u5728 \\(Titan \\ X\\) \u4e0a\u5904\u7406 \\(256 \u00d7 256\\) \u56fe\u7247\u6d4b\u51fa\u3002\u4ece\u88682\u53ef\u4ee5\u770b\u51fa\uff0c \\(Darknet-53\\) \u4e0d\u4ec5\u7cbe\u5ea6\u53ef\u4ee5\u5ab2\u7f8e\u6700\u5148\u8fdb\u7684\u5206\u7c7b\u5668\uff0c\u800c\u4e14\u5b83\u6709\u8f83\u5c11\u6d6e\u70b9\u8fd0\u7b97\u64cd\u4f5c\uff0c\u66f4\u5feb\u7684\u901f\u5ea6\u3002 \\(Darknet-53\\) \u6bd4 \\(ResNet-101\\) \u6027\u80fd\u66f4\u597d\u800c\u4e14\u8981\u5feb1.5\u500d\u3002 \\(Darknet-53\\) \u6027\u80fd\u4e0e \\(ResNet-152\\) \u76f8\u8fd1\uff0c\u4f46\u662f\u8981\u6bd4\u5b83\u5feb2\u500d\u3002 \u2003 \\(Darknet-53\\) \u4e5f\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u6bcf\u79d2\u6d6e\u70b9\u8fd0\u7b97\u6d4b\u91cf\u3002\u8fd9\u610f\u5473\u7740\u7f51\u7edc\u7ed3\u6784\u53ef\u4ee5\u66f4\u597d\u5730\u5229\u7528GPU\uff0c\u4f7f\u5176\u9884\u6d4b\u6548\u7387\u66f4\u9ad8\uff0c\u901f\u5ea6\u66f4\u5feb\u3002ResNets\u66f4\u6162\uff0c\u5927\u62b5\u662f\u56e0\u4e3a\u5176\u5c42\u6570\u592a\u591a\uff0c\u6240\u4ee5\u4e0d\u662f\u90a3\u4e48\u6709\u6548\u7387\u3002 2.5 \u8bad\u7ec3 \u2003\u6211\u4eec\u4f9d\u65e7\u53ea\u662f\u8bad\u7ec3\u5b8c\u6574\u7684\u56fe\u50cf\uff0c\u6ca1\u6709\u5c06\u96be\u4ee5\u6b63\u786e\u5206\u7c7b\u7684\u6837\u672c\u53cd\u590d\u8bad\u7ec3\uff0c\u4e5f\u6ca1\u6709\u8fdb\u884c\u5176\u4ed6\u4efb\u4f55\u64cd\u4f5c\u3002\u6211\u4eec\u4f7f\u7528\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u4f7f\u7528\u5927\u91cf\u7684\u6570\u636e\u589e\u5f3a\u3001\u6279\u91cf\u6807\u51c6\u5316\u7b49\u6807\u51c6\u7684\u64cd\u4f5c\u3002\u6211\u4eec\u4f7f\u7528 \\(Darknet\\) \u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5[12]\u3002 \\(YOLOv3\\) is pretty good! See table 3. In terms of COCOs weird average mean AP metric it is on par with the SSD variants but is 3\u00d7 faster. It is still quite a bit behind other models like RetinaNet in this metric though. Table 3. I\u2019m seriously just stealing all these tables from [9] they take soooo long to make from scratch. Ok, \\(YOLOv3\\) is doing alright. Keep in mind that RetinaNet has like 3.8\u00d7 longer to process an image. \\(YOLOv3\\) is much better than SSD variants and comparable to state-of-the-art models on the AP50 metric. 3 \u6211\u4eec\u662f\u5982\u4f55\u505a\u7684 \\(YOLOv3\\) \u8868\u73b0\u975e\u5e38\u597d\uff01\u8bf7\u770b\u88683\u3002\u5c31COCO\u7684\u5e73\u5747AP\u6307\u6807\u800c\u8a00\uff0c\u5b83\u4e0eSSD\u7c7b\u7684\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u63d0\u9ad8\u4e863\u500d\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u5b83\u4ecd\u7136\u5728\u8fd9\u4e2a\u6307\u6807\u4e0a\u6bd4\u50cfRetinaNet\u8fd9\u6837\u7684\u5176\u4ed6\u6a21\u578b\u5dee\u4e9b\u3002 \u88683.\u6211\u5f88\u8ba4\u771f\u5730\u4ece[9]\u4e2d \\(\u201c\u7a83\u53d6\u201d\\) \u4e86\u4ed6\u4eec\u82b1\u4e86\u5f88\u957f\u65f6\u95f4\u624d\u4ece\u5934\u5f00\u59cb\u5236\u4f5c\u8fd9\u4e9b\u8868\u683c\u3002\u597d\u7684\uff0c \\(YOLOv3\\) \u6ca1\u95ee\u9898\u3002\u8bf7\u8bb0\u4f4f\uff0c \\(RetinaNet\\) \u5904\u7406\u4e00\u5f20\u56fe\u50cf\u7684\u65f6\u95f4\u662f \\(YOLOv3\\) \u7684 \\(3.8\\) \u500d\u3002 \\(YOLOv3\\) \u6bd4 \\(SSD\\) \u8981\u597d\u5f97\u591a\uff0c\u5e76\u4e14\u5728 \\(AP50\\) \u6807\u51c6\u4e0b\u53ef\u4ee5\u4e0e\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5ab2\u7f8e\uff01 \u2003\u7136\u800c\uff0c\u5f53\u6211\u4eec\u4f7f\u7528 \\(\u201c\u65e7\u7684\u201d\\) \u68c0\u6d4b\u6307\u6807\u2014\u2014\u5728 \\(IOU=0.5\u7684mAP\\) \uff08\u6216\u56fe\u8868\u4e2d\u7684 \\(AP50\\) \uff09\u65f6\uff0c \\(YOLOv3\\) \u975e\u5e38\u5f3a\u5927\u3002\u5176\u6027\u80fd\u51e0\u4e4e\u4e0eRetinaNet\u76f8\u5f53\uff0c\u5e76\u4e14\u8fdc\u5f3a\u4e8e \\(SSD\\) \u3002\u8fd9\u8868\u660e \\(YOLOv3\\) \u662f\u4e00\u4e2a\u975e\u5e38\u5f3a\u5927\u7684\u68c0\u6d4b\u5668\uff0c\u64c5\u957f\u4e3a\u76ee\u6807\u751f\u6210\u6070\u5f53\u7684\u6846\u3002\u7136\u800c\uff0c\u968f\u7740 \\(IOU\\) \u9608\u503c\u589e\u52a0\uff0c\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8fd9\u8868\u660e \\(YOLOv3\\) \u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4e0e\u76ee\u6807\u4e0d\u80fd\u5b8c\u7f8e\u5bf9\u9f50\u3002 Figure 3. Again adapted from the [9], this time displaying speed/accuracy tradeoff on the mAP at .5 IOU metric. You can tell \\(YOLOv3\\) is good because it\u2019s very high and far to the left. Can you cite your own paper? Guess who\u2019s going to try, this guy ! [16]. Oh, I forgot, we also fix a data loading bug in YOLOv2, that helped by like 2 mAP. Just sneaking this in here to not throw off layout. \u56fe3. \u518d\u6b21\u6539\u7f16\u81ea[9]\uff0c\u8fd9\u6b21\u663e\u793a\u7684\u662f\u5728 \\(0.5 \\ IOU\\) \u6307\u6807\u4e0a\u901f\u5ea6/\u51c6\u786e\u5ea6\u7684\u6743\u8861\u3002\u4f60\u53ef\u4ee5\u8bf4 \\(YOLOv3\\) \u662f\u597d\u7684\uff0c\u56e0\u4e3a\u5b83\u975e\u5e38\u9ad8\u5e76\u4e14\u5728\u5de6\u8fb9\u5f88\u8fdc\u3002 \u4f60\u80fd\u5f15\u7528\u4f60\u81ea\u5df1\u7684\u8bba\u6587\u5417\uff1f\u731c\u731c\u8c01\u4f1a\u53bb\u5c1d\u8bd5\uff0c\u8fd9\u4e2a\u4eba\u2192[16]\u3002\u54e6\uff0c\u6211\u5fd8\u4e86\uff0c\u6211\u4eec\u8fd8\u4fee\u590d\u4e86YOLOv2\u4e2d\u7684\u6570\u636e\u52a0\u8f7dbug\uff0c\u8be5bug\u7684\u4fee\u590d\u63d0\u5347\u4e862 mAP, \u53ea\u662f\u5728\u8fd9\u91cc\u5077\u5077\u63d0\u4e00\u4e0b\uff0c\u8fd9\u4e0d\u662f\u91cd\u70b9\u3002 \u2003\u5728\u4e4b\u524d\u7684 \\(YOLO\\) \u4e0d\u64c5\u957f\u68c0\u6d4b\u5c0f\u7269\u4f53\u3002\u4f46\u662f\uff0c\u73b0\u5728\u6211\u4eec\u770b\u5230\u4e86\u8fd9\u79cd\u8d8b\u52bf\u7684\u9006\u8f6c\u3002\u968f\u7740\u65b0\u7684\u591a\u5c3a\u5ea6\u9884\u6d4b\uff0c\u6211\u4eec\u770b\u5230 \\(YOLOv3\\) \u5177\u6709\u76f8\u5bf9\u8f83\u9ad8\u7684 \\(APS\\) \u6027\u80fd\u3002\u4f46\u662f\uff0c\u5b83\u5728\u4e2d\u578b\u548c\u5927\u578b\u7269\u4f53\u68c0\u6d4b\u4e0a\u7684\u6027\u80fd\u8fd8\u76f8\u5bf9\u8f83\u5dee\u3002\u8fd9\u53ef\u80fd\u9700\u8981\u66f4\u591a\u7684\u8c03\u7814\u548c\u5b9e\u9a8c\u624d\u80fd\u77e5\u9053\u5982\u4f55\u53bb\u6539\u8fdb\u8fd9\u4e00\u70b9\u3002 \u2003\u5f53\u6211\u4eec\u5728 \\(AP50\\) \u6307\u6807\u4e0a\u7ed8\u5236\u51c6\u786e\u5ea6\u548c\u901f\u5ea6\u5173\u7cfb\u56fe\u65f6\uff08\u8bf7\u89c1\u56fe3\uff09\uff0c\u6211\u4eec\u770b\u5230 \\(YOLOv3\\) \u4e0e\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\u5177\u6709\u663e\u7740\u7684\u4f18\u52bf\u3002\u4e5f\u5c31\u662f\u8bf4 \\(YOLOv3\\) \uff0c\u901f\u5ea6\u66f4\u5feb\u3001\u6027\u80fd\u66f4\u597d\u3002 4 \u5931\u8d25\u7684\u5c1d\u8bd5 \u2003\u6211\u4eec\u5728\u5b9e\u73b0 \\(YOLOv3\\) \u7684\u8fc7\u7a0b\u4e2d\u5c1d\u8bd5\u4e86\u5f88\u591a\u4e1c\u897f\uff0c\u4f46\u662f\u5f88\u591a\u90fd\u5931\u8d25\u4e86\uff0c\u4ee5\u4e0b\u662f\u6211\u4eec\u8fd8\u8bb0\u5f97\u7684\u4e00\u4e9b\u5931\u8d25\u7684\u5c1d\u8bd5\u3002 \u2003 Anchor\u6846\u7684x\u3001y\u504f\u79fb\u9884\u6d4b \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528\u5e38\u89c4\u7684Anchor\u6846\u9884\u6d4b\u673a\u5236\uff0c\u6bd4\u5982\u5229\u7528\u7ebf\u6027\u6fc0\u6d3b\u5c06\u5750\u6807x\u3001y\u7684\u504f\u79fb\u7a0b\u5ea6\u9884\u6d4b\u4e3a\u8fb9\u754c\u6846\u5bbd\u5ea6\u6216\u9ad8\u5ea6\u7684\u500d\u6570\u3002\u4f46\u6211\u4eec\u53d1\u73b0\u8fd9\u79cd\u65b9\u6cd5\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u4e14\u6548\u679c\u4e0d\u4f73\u3002 \u2003 \u7528\u7ebf\u6027\u6fc0\u6d3b\u4ee3\u66ff\u903b\u8f91\u6fc0\u6d3b\u51fd\u6570\u8fdb\u884cx\u3001y\u9884\u6d4b \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u4ee3\u66ff\u903b\u8f91\u6fc0\u6d3b\u6765\u76f4\u63a5\u9884\u6d4bx\u3001y\u504f\u79fb\u3002\u8fd9\u4e2a\u6539\u53d8\u5bfc\u81f4mAP\u4e0b\u964d\u4e86\u51e0\u4e2a\u70b9\u3002 \u2003 focal loss \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528focal loss\u3002\u5b83\u4f7f\u5f97mAP\u4e0b\u964d2\u4e2a\u70b9\u3002 \\(YOLOv3\\) \u53ef\u80fd\u5df2\u7ecf\u5bf9focal loss \u8bd5\u56fe\u89e3\u51b3\u7684\u95ee\u9898\u5177\u6709\u76f8\u5f53\u7684\u9c81\u68d2\u6027\uff0c\u56e0\u4e3a\u5b83\u5177\u6709\u5355\u72ec\u7684\u76ee\u6807\u9884\u6d4b\u548c\u6761\u4ef6\u7c7b\u522b\u9884\u6d4b\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u5927\u591a\u6570\u6837\u672c\u6765\u8bf4\uff0c\u7c7b\u522b\u9884\u6d4b\u6ca1\u6709\u635f\u5931\uff1f\u6216\u8005\u6709\u4e00\u4e9b\uff1f\u6211\u4eec\u5e76\u4e0d\u5b8c\u5168\u786e\u5b9a\u3002 \u2003 \u53ccIOU\u9608\u503c\u548c\u771f\u503c\u5206\u914d \u3002 \\(Faster \\ R-CNN\\) \u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528\u4e24\u4e2a \\(IOU\\) \u9608\u503c\u3002\u5982\u679c\u4e00\u4e2a\u9884\u6d4b\u4e0e\u771f\u5b9e\u6807\u7b7e\u6846\u91cd\u53e0\u8d85\u8fc7 \\(0.7\\) \uff0c\u5b83\u5c31\u662f\u4e00\u4e2a\u6b63\u6837\u672c\uff0c\u82e5\u91cd\u53e0\u5728 \\([0.3\uff0c0.7]\\) \u4e4b\u95f4\uff0c\u90a3\u4e48\u5b83\u4f1a\u88ab\u5ffd\u7565\uff0c\u82e5\u5b83\u4e0e\u6240\u6709\u7684\u771f\u5b9e\u6807\u7b7e\u6846\u7684 \\(IOU\\) \u5c0f\u4e8e0.3\uff0c\u90a3\u4e48\u5c31\u4f1a\u88ab\u5224\u5b9a\u4e3a\u4e00\u4e2a\u8d1f\u6837\u672c\u3002\u6211\u4eec\u5c1d\u8bd5\u4e86\u7c7b\u4f3c\u7684\u7b56\u7565\uff0c\u4f46\u6700\u7ec8\u7684\u6548\u679c\u5e76\u4e0d\u597d\u3002 \u2003\u6211\u4eec\u975e\u5e38\u559c\u6b22\u76ee\u524d\u7684\u6a21\u578b\uff0c\u5b83\u81f3\u5c11\u5728\u5c40\u90e8\u8fbe\u5230\u4e86\u6700\u4f73\u3002\u4e0a\u8ff0\u7684\u6709\u4e9b\u6280\u672f\u53ef\u80fd\u4f1a\u4f7f\u6211\u4eec\u7684\u6a21\u578b\u66f4\u597d\uff0c\u4f46\u6211\u4eec\u53ef\u80fd\u8fd8\u9700\u8981\u5bf9\u4ed6\u4eec\u505a\u4e00\u4e9b\u8c03\u6574\u3002 5 \u8fd9\u4e00\u5207\u610f\u5473\u7740\u4ec0\u4e48 \u2003 \\(YOLOv3\\) \u662f\u4e00\u4e2a\u5f88\u68d2\u7684\u68c0\u6d4b\u5668\uff0c\u5b83\u7531\u51c6\u53c8\u5feb\u3002\u867d\u7136\u5b83\u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\uff0c0.3\u548c0.95 IOU \u4e0b\u7684\u5e73\u5747AP\u5e76\u4e0d\u597d\uff0c\u4f46\u5728\u65e7\u7684 0.5 IOU\u7684\u68c0\u6d4b\u6307\u6807\u4e0b\uff0c\u5b83\u8fd8\u662f\u975e\u5e38\u4e0d\u9519\u7684\u3002 \u2003 \u4e3a\u4ec0\u4e48\u6211\u4eec\u8981\u6539\u53d8\u6307\u6807\uff1f \\(COCO\\) \u7684\u539f\u8bba\u6587\u6709\u8fd9\u6837\u4e00\u53e5\u542b\u7cca\u4e0d\u6e05\u7684\u53e5\u5b50\uff1a \\(\u201cA \\ full \\ discussion \\ of \\ evaluation \\ metrics \\ will \\ be \\ added \\ once \\ the \\ evaluation \\ server \\ is \\ complete\u201d\\) \u3002Russakovsky\u7b49\u4eba\u7684\u62a5\u544a\u4e2d\u8bf4\uff0c\u4eba\u4eec\u5f88\u96be\u533a\u52060.3\u548c0.5\u7684IOU\u3002\u201c\u8bad\u7ec3\u4eba\u7c7b\u7528\u89c6\u89c9\u68c0\u67e50.3 IOU\u7684\u8fb9\u754c\u6846\uff0c\u5e76\u4e14\u4e0e0.5 IOU\u7684\u6846\u533a\u522b\u5f00\u6765\u662f\u975e\u5e38\u56f0\u96be\u7684\u3002\u201c[16]\u5982\u679c\u4eba\u7c7b\u5f88\u96be\u8bf4\u51fa\u5dee\u5f02\uff0c\u90a3\u4e48\u5b83\u4e5f\u6ca1\u6709\u591a\u91cd\u8981\u5427\uff1f \u2003\u4e5f\u8bb8\u6709\u4e2a\u66f4\u597d\u7684\u95ee\u9898\u503c\u5f97\u6211\u4eec\u63a2\u8ba8\u201c\u6211\u4eec\u7528\u5b83\u6765\u5e72\u4ec0\u4e48\u201d\u8bb8\u591a\u4ece\u4e8b\u8fd9\u9879\u7814\u7a76\u7684\u4eba\u90fd\u5728Google\u548cFacebook\uff0c\u6211\u60f3\u81f3\u5c11\u6211\u4eec\u77e5\u9053\u8fd9\u4e2a\u6280\u672f\u662f\u638c\u63e1\u5728\u597d\u4eba\u624b\u91cc\uff0c\u7edd\u5bf9\u4e0d\u4f1a\u628a\u5b83\u7528\u6765\u6536\u96c6\u4f60\u7684\u4e2a\u4eba\u4fe1\u606f\u7136\u540e\u5356\u7ed9\u2026\u2026\u7b49\u7b49\uff0c\u4f60\u7a76\u7adf\u60f3\u7528\u5b83\u6765\u5e72\u561b\uff01\uff01\u5662\u3002 \u2003\u5176\u4ed6\u82b1\u5927\u94b1\u8d44\u52a9\u89c6\u89c9\u7814\u7a76\u7684\u4eba\u8fd8\u6709\u519b\u65b9\uff0c\u4ed6\u4eec\u4ece\u6765\u6ca1\u6709\u505a\u8fc7\u4efb\u4f55\u53ef\u6015\u7684\u4e8b\u60c5\uff0c\u4f8b\u5982\u7528\u65b0\u6280\u672f\u6740\u6b7b\u5f88\u591a\u4eba\uff0c\u7b49\u7b49..... \u6211\u5f3a\u70c8\u5730\u5e0c\u671b\uff0c\u5927\u591a\u6570\u4f7f\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u4eba\u90fd\u7528\u5b83\u6765\u505a\u4e00\u4e9b\u5feb\u4e50\u4e14\u6709\u76ca\u7684\u4e8b\u60c5\uff0c\u6bd4\u5982\u8ba1\u7b97\u4e00\u4e2a\u56fd\u5bb6\u516c\u56ed\u91cc\u6591\u9a6c\u7684\u6570\u91cf[13]\uff0c\u6216\u8005\u8ffd\u8e2a\u5728\u9644\u8fd1\u5f98\u5f8a\u7684\u732b[19]\u3002\u4f46\u8ba1\u7b97\u673a\u89c6\u89c9\u5df2\u7ecf\u88ab\u7528\u4e8e\u503c\u5f97\u6000\u7591\u7684\u7528\u9014\uff0c\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\uff0c\u6211\u4eec\u6709\u8d23\u4efb\u8003\u8651\u6211\u4eec\u7684\u5de5\u4f5c\u53ef\u80fd\u9020\u6210\u7684\u635f\u5bb3\uff0c\u5e76\u601d\u8003\u5982\u4f55\u51cf\u8f7b\u5b83\u7684\u5f71\u54cd\u3002\u6211\u4eec\u6b20\u8fd9\u4e2a\u4e16\u754c\u592a\u591a\u3002 \u6700\u540e\uff0c\u4e0d\u8981\u518d@\u6211\u4e86\u3002\uff08\u56e0\u4e3a\u6211\u5df2\u7ecf\u9000\u51faTwitter\u8fd9\u4e2a\u662f\u975e\u4e4b\u5730\u4e86\uff09\u3002 In closing, do not@me. (Because I finally quit Twitter). References [1] Analogy. Wikipedia, Mar 2018. 1 [2] M. Everingham, L. V an Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) challenge. International journal of computer vision, 88(2):303\u2013 338, 2010. 6 [3] C.-Y . Fu, W. Liu, A. Ranga, A. Tyagi, and A. C. Berg. Dssd: Deconvolutional single shot detector. arXiv preprint arXiv:1701.06659, 2017. 3 [4] D. Gordon, A. Kembhavi, M. Rastegari, J. Redmon, D. Fox, and A. Farhadi. Iqa: Visual question answering in interactive environments. arXiv preprint arXiv:1712.03316, 2017. 1 [5] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016. 3 [6] J. Huang, V . Rathod, C. Sun, M. Zhu, A. Korattikara, A. Fathi, I. Fischer, Z. Wojna, Y . Song, S. Guadarrama, et al Speed/accuracy trade-offs for modern convolutional object detectors. 3 [7] I. Krasin, T. Duerig, N. Alldrin, V . Ferrari, S. Abu-El-Haija, A. Kuznetsova, H. Rom, J. Uijlings, S. Popov, A. V eit, S. Belongie, V . Gomes, A. Gupta, C. Sun, G. Chechik, D. Cai, Z. Feng, D. Narayanan, and K. Murphy. Openimages: A public dataset for large-scale multi-label and multi-class image classification. Dataset available from https://github.com/openimages, 2017. 2 [8] T.-Y . Lin, P . Dollar, R. Girshick, K. He, B. Hariharan, and S. Belongie. Feature pyramid networks for object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2117\u20132125, 2017. 2, 3 [9] T.-Y . Lin, P . Goyal, R. Girshick, K. He, and P . Doll\u00e1r. Focal loss for dense object detection. arXiv preprint arXiv:1708.02002, 2017. 1, 3, 4 [10] T.-Y . Lin, M. Maire, S. Belongie, J. Hays, P . Perona, D. Ramanan, P . Doll\u00e1r, and C. L. Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision, pages 740\u2013755. Springer, 2014. 2 [11] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.Y . Fu, and A. C. Berg. Ssd: Single shot multibox detector. In European conference on computer vision, pages 21\u201337. Springer, 2016. 3 [12] I. Newton. Philosophiae naturalis principia mathematica. William Dawson & Sons Ltd., London, 1687. 1 [13] J. Parham, J. Crall, C. Stewart, T. Berger-Wolf, and D. Rubenstein. Animal population censusing at scale with citizen science and photographic identification. 2017. 4 [14] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 3 [15] J. Redmon and A. Farhadi. Y olo9000: Better, faster, stronger. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pages 6517\u20136525. IEEE, 2017. 1, 2, 3 [16] J. Redmon and A. Farhadi. Y olov3: An incremental improvement. arXiv, 2018. 4 [17] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497, 2015. 2 [18] O. Russakovsky, L.-J. Li, and L. Fei-Fei. Best of both worlds: human-machine collaboration for object annotation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2121\u20132131, 2015. 4 [19] M. Scott. Smart camera gimbal bot scanlime:027, Dec 2017. 4 [20] A. Shrivastava, R. Sukthankar, J. Malik, and A. Gupta. Be- yond skip connections: Top-down modulation for object de- tection. arXiv preprint arXiv:1612.06851, 2016. 3 [21] C. Szegedy, S. Ioffe, V . V anhoucke, and A. A. Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. 2017. 3","title":"YOLOv3"},{"location":"thesis_interpretation/03_yolo.html#_1","text":"\u6211\u4eec\u5bf9YOLO\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u66f4\u65b0\uff01\u5b83\u5305\u542b\u4e00\u5806\u5c0f\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u4f7f\u7cfb\u7edf\u7684\u6027\u80fd\u5f97\u5230\u66f4\u65b0\u3002\u6211\u4eec\u4e5f\u8bad\u7ec3\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u6bd4\u8f83\u5927\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u867d\u7136\u6bd4\u4e0a\u4e00\u7248\u66f4\u5927\u4e00\u4e9b\uff0c\u4f46\u662f\u7cbe\u5ea6\u4e5f\u63d0\u9ad8\u4e86\u3002\u4e0d\u7528\u62c5\u5fc3\uff0c\u5b83\u7684\u901f\u5ea6\u4f9d\u7136\u5f88\u5feb\u3002 \\(YOLOv3\\) \u5728 \\(320\u00d7320\\) \u8f93\u5165\u56fe\u50cf\u4e0a\u8fd0\u884c\u65f6\u53ea\u9700 \\(22ms\\) \uff0c\u5e76\u80fd\u8fbe\u5230 \\(28.2mAP\\) \uff0c\u5176\u7cbe\u5ea6\u548c \\(SSD\\) \u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u8981\u5feb\u4e0a \\(3\\) \u500d\u3002\u4f7f\u7528\u4e4b\u524d \\(0.5 \\ IOU \\ mAP\\) \u7684\u68c0\u6d4b\u6307\u6807\uff0c \\(YOLOv3\\) \u7684\u6548\u679c\u662f\u76f8\u5f53\u4e0d\u9519\u3002 \\(YOLOv3\\) \u4f7f\u7528Titan X GPU\uff0c\u5b83\u5728 \\(51ms\\) \u68c0\u6d4b\u7cbe\u5ea6\u8fbe\u5230 \\(57.9 \\ AP50\\) \uff0c\u7136\u800c\u4e0e \\(RetinaNet\\) \u76f8\u6bd4 \uff0c\u5176\u7cbe\u5ea6\u53ea\u6709 \\(57.5 \\ AP50\\) \uff0c\u4f46\u5374\u8017\u65f6 \\(198ms\\) \uff0c\u76f8\u540c\u6027\u80fd\u7684\u60c5\u51b5\u4e0b \\(YOLOv3\\) \u901f\u5ea6\u6bd4 \\(RetinaNet\\) \u5feb \\(3.8\\) \u500d\u3002\u4e0e\u4e4b\u524d\u4e00\u6837\uff0c\u6240\u6709\u4ee3\u7801\u5728\u7f51\u5740\uff1ahttps://pjreddie.com/yolo/\u3002","title":"\u6458\u8981"},{"location":"thesis_interpretation/03_yolo.html#1","text":"\u6709\u65f6\u5019\uff0c\u4e00\u5e74\u5185\u4f60\u4e3b\u8981\u90fd\u5728\u73a9\u624b\u673a\uff0c\u4f60\u77e5\u9053\u5417\uff1f\u4eca\u5e74\u6211\u6ca1\u6709\u505a\u5f88\u591a\u7814\u7a76\u3002\u6211\u5728 \\(Twitter\\) \u4e0a\u82b1\u4e86\u5f88\u591a\u65f6\u95f4,\u5728GANs\u4e0a\u73a9\u4e86\u70b9\u5c0f\u6e38\u620f\u3002\u53bb\u5e74\u6211\u7559\u4e0b\u4e86\u4e00\u70b9\u70b9\u7684\u7cbe\u529b [12] [1]\uff1b\u6211\u8bbe\u6cd5\u5bf9 \\(YOLO\\) \u8fdb\u884c\u4e86\u4e00\u4e9b\u6539\u8fdb\u3002\u4f46\u662f\uff0c\u5b9e\u8bdd\u5b9e\u8bf4\uff0c\u4ec5\u4ec5\u4e00\u4e9b\u5c0f\u7684\u6539\u53d8\u4f7f\u5f97\u5b83\u53d8\u5f97\u66f4\u597d\uff0c\u6ca1\u6709\u4ec0\u4e48\u8d85\u7ea7\u6709\u8da3\u7684\u4e8b\u60c5\u3002\u6211\u4e5f\u7a0d\u5fae\u5e2e\u52a9\u4e86\u5176\u4ed6\u4eba\u7684\u4e00\u4e9b\u7814\u7a76\u3002 \u2003\u4e8b\u5b9e\u4e0a\uff0c\u8fd9\u5c31\u662f\u6211\u4eec\u4eca\u5929\u6765\u8fd9\u91cc\u7684\u539f\u56e0\u3002\u6211\u4eec\u6709\u4e00\u7bc7\u8bba\u6587\u5feb\u622a\u7a3f\u4e86\uff0c\u5e76\u4e14\u6211\u4eec\u8fd8\u7f3a\u4e00\u7bc7\u5173\u4e8e \\(YOLO\\) \u66f4\u65b0\u5185\u5bb9\u7684\u6587\u7ae0\u4f5c\u4e3a\u5f15\u7528\uff0c\u4f46\u662f\u6211\u4eec\u6ca1\u6709\u5f15\u7528\u6765\u6e90\u3002\u6240\u4ee5\uff0c\u51c6\u5907\u597d\u8fce\u63a5\u79d1\u6280\u62a5\u9053\u5427! \u2003\u6280\u672f\u62a5\u544a\u6700\u68d2\u7684\u4e00\u70b9\u5c31\u662f\u4ed6\u4eec\u4e0d\u9700\u8981\u4ecb\u7ecd\uff0c\u4f60\u4eec\u90fd\u77e5\u9053\u6211\u4eec\u4e3a\u4ec0\u4e48\u5728\u8fd9\u91cc\u3002\u56e0\u6b64\uff0c\u8fd9\u7bc7\u4ecb\u7ecd\u7684\u7ed3\u5c3e\u5c06\u4e3a\u672c\u6587\u7684\u5176\u4f59\u90e8\u5206\u6307\u660e\u65b9\u5411\u3002\u9996\u5148\u6211\u4eec\u4f1a\u544a\u8bc9\u4f60 \\(YOLOv3\\) \u7684\u65b9\u6848\u3002\u5176\u6b21\u6211\u4eec\u4f1a\u544a\u8bc9\u4f60\u6211\u4eec\u662f\u5982\u4f55\u5b9e\u73b0\u7684\u3002\u6211\u4eec\u4e5f\u4f1a\u544a\u8bc9\u4f60\u6211\u4eec\u5c1d\u8bd5\u8fc7\u4f46\u5e76\u4e0d\u594f\u6548\u7684\u4e00\u4e9b\u4e8b\u60c5\u3002\u6700\u540e\u6211\u4eec\u5c06\u63a2\u8ba8\u8fd9\u4e9b\u7684\u610f\u4e49\u3002","title":"1.\u5f15\u8a00"},{"location":"thesis_interpretation/03_yolo.html#2","text":"\u8fd9\u8282\u4e3b\u8981\u4ecb\u7ecd \\(YOLOv3\\) \u7684\u66f4\u65b0\u65b9\u6848\uff1a\u6211\u4eec\u4e3b\u8981\u4ece\u5176\u4ed6\u4eba\u7684\u7814\u7a76\u5de5\u4f5c\u91cc\u83b7\u5f97\u4e86\u4e00\u4e9b\u597d\u601d\u8def\u3001\u597d\u60f3\u6cd5\u3002\u6211\u4eec\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u6bd4\u5176\u4ed6\u7f51\u7edc\u66f4\u597d\u7684\u5206\u7c7b\u7f51\u7edc\u3002\u4e3a\u4e86\u65b9\u4fbf\u7406\u89e3\uff0c\u8ba9\u6211\u4eec\u4ece\u5934\u5f00\u59cb\u6162\u6162\u4ecb\u7ecd\u6574\u4e2a\u6a21\u578b\u7cfb\u7edf\u3002 \u56fe1. \u6e90\u81ea \\(Focal \\ Loss\\) \u8bba\u6587[9]\u3002 \\(YOLOv3\\) \u7684\u8fd0\u884c\u901f\u5ea6\u660e\u663e\u5feb\u4e8e\u5176\u4ed6\u6027\u80fd\u76f8\u5f53\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002\u68c0\u6d4b\u65f6\u95f4\u57fa\u4e8e \\(M40\\) \u6216 \\(Titan \\ X\\) \uff08 \u5176\u4e2d \\(M40,Titan X\\) \u662f\u76f8\u4f3c\u7684\u4e24\u79cd \\(GPU\\) \uff09\u3002","title":"2.\u65b9\u6848"},{"location":"thesis_interpretation/03_yolo.html#21","text":"\u548c \\(YOLO9000\\) \u4e00\u6837\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u4e5f\u4f7f\u7528\u7ef4\u5ea6\u805a\u7c7b\u7b97\u6cd5\u751f\u6210\u7684\u951a\u6846\uff08 anchor boxes \uff09[15] \u6765\u9884\u6d4b\u8fb9\u754c\u6846\u3002\u7f51\u7edc\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u76844\u4e2a\u5750\u6807\uff1a \\(t_x\u3001t_y\u3001t_w\u3001t_h\\) \u3002\u5047\u8bbe\u683c\u5b50\u8ddd\u79bb\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u504f\u79fb\u91cf\u4e3a \\((c_x\uff0cc_y)\\) \uff0c\u4e14\u4e4b\u524d\u7684\u8fb9\u754c\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e3a \\(p_w, p_h\\) \uff0c\u5219\u9884\u6d4b\u7ed3\u679c: \\[ {\\large \\begin{align} b_{x} & = \\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} & = \\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} & = p_{w} e^{t_{w}} \\\\ b_{h} & = p_{h} e^{t_{h}} \\end{align}} \\] \u2003\u5728\u8bad\u7ec3\u4e2d\u6211\u4eec\u4f7f\u7528\u8bef\u5dee\u5e73\u65b9\u548c\u635f\u5931\u8ba1\u7b97\u3002\u5982\u679c\u67d0\u4e2a\u9884\u6d4b\u5750\u6807\u7684 \\(ground \\ truth\\) \u662f \\(\\hat{t}_*\\) \uff0c\u90a3\u4e48\u5bf9\u5e94\u7684\u68af\u5ea6\u5c31\u662f \\(ground \\ truth \\ value\\) \uff08\u7531 \\(ground \\ truth \\ box\\) \u8ba1\u7b97\u800c\u5f97\uff09\u548c\u9884\u6d4b\u503c\u4e4b\u5dee\uff1a \\(\\hat{t}_* - t_*\\) \u3002\u901a\u8fc7\u53d8\u6362\u4e0a\u8ff0\u516c\u5f0f\u8ba1\u7b97,\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5f97\u5230 \\(ground \\ truth \\ value\\) \u3002 \u56fe2\uff1a \u7ef4\u5ea6\u5148\u9a8c\u548c\u4f4d\u7f6e\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u3002 \\(\\large{\\sigma(t_x)}\\) , \\(\\large{\\sigma(t_y)}\\) \u662f\u57fa\u4e8e\u77e9\u5f62\u6846\u4e2d\u5fc3\u70b9\u5de6\u4e0a\u89d2\u683c\u70b9\u5750\u6807\u7684\u504f\u79fb\u91cf\uff0c \\(\\large{\\sigma}\\) \u662f\u6fc0\u6d3b\u51fd\u6570\uff0c\u8bba\u6587\u4e2d\u4f5c\u8005\u4f7f\u7528 sigmoid [15]\u3002 \\(\\large{P_w,P_h}\\) \u662f\u5148\u9a8c\u6846\u7684\u5bbd\u3001\u9ad8\uff0c\u901a\u8fc7\u4e0a\u8ff0\u516c\u5f0f\uff0c\u8ba1\u7b97\u51fa\u5b9e\u9645\u9884\u6d4b\u6846\u7684\u5bbd\u9ad8 \u3002 \u2003 \\(YOLOv3\\) \u4f7f\u7528\u903b\u8f91\u56de\u5f52\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u662f\u76ee\u6807\u7684\u5206\u6570\u3002\u5982\u679c\u771f\u5b9e\u6807\u7b7e\u6846\u4e0e\u67d0\u4e2a\u8fb9\u754c\u6846\u91cd\u53e0\u7684\u9762\u79ef\u6bd4\u4e0e\u5176\u4ed6\u4efb\u4f55\u8fb9\u754c\u6846\u90fd\u5927\uff0c\u90a3\u4e48\u8fd9\u4e2a\u5148\u9a8c\u8fb9\u754c\u6846\u5f97\u5206\u4e3a1\u3002\u6309\u7167[17]\u7684\u505a\u6cd5\uff0c\u5982\u679c\u5148\u9a8c\u8fb9\u754c\u6846\u4e0d\u662f\u6700\u597d\u7684\uff0c\u4f46\u662f\u786e\u5b9e\u4e0e\u76ee\u6807\u7684\u771f\u5b9e\u6807\u7b7e\u6846\u91cd\u53e0\u7684\u9762\u79ef\u5927\u4e8e\u9608\u503c\uff0c\u6211\u4eec\u4e5f\u4f1a\u5ffd\u7565\u8fd9\u4e2a\u9884\u6d4b\u3002\u6211\u4eec\u4f7f\u7528\u9608\u503c\u4e3a0.5\u3002\u4e0e[17]\u4e0d\u540c\u7684\u662f\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u53ea\u4e3a\u6bcf\u4e2a\u771f\u5b9e\u76ee\u6807\u5206\u914d\u4e00\u4e2a\u8fb9\u754c\u6846\u3002\u5982\u679c\u5148\u9a8c\u8fb9\u754c\u6846\u672a\u5206\u914d\u5230\u771f\u5b9e\u76ee\u6807\uff0c\u5219\u4e0d\u4f1a\u4ea7\u751f\u5750\u6807\u6216\u7c7b\u522b\u9884\u6d4b\u7684\u635f\u5931\uff0c\u53ea\u4f1a\u4ea7\u751f\u662f\u5426\u662f\u76ee\u6807\u7684\u635f\u5931\u3002","title":"2.1 \u8fb9\u754c\u6846\u9884\u6d4b"},{"location":"thesis_interpretation/03_yolo.html#22","text":"\u6bcf\u4e2a\u8fb9\u754c\u6846\u90fd\u4f1a\u4f7f\u7528\u591a\u6807\u7b7e\u5206\u7c7b\u6765\u9884\u6d4b\u6846\u4e2d\u53ef\u80fd\u5305\u542b\u7684\u7c7b\u3002\u6211\u4eec\u4e0d\u7528 \\(softmax\\) \uff0c\u800c\u662f\u7528\u5355\u72ec\u7684\u903b\u8f91\u5206\u7c7b\u5668\uff0c\u56e0\u4e3a\u6211\u4eec\u53d1\u73b0\u524d\u8005\u5bf9\u4e8e\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u6ca1\u4ec0\u4e48\u4f5c\u7528\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u7528binary cross-entropy\uff08\u4e8c\u5143\u4ea4\u53c9\u71b5\uff09\u635f\u5931\u6765\u9884\u6d4b\u7c7b\u522b\u3002 \u2003\u5f53\u6211\u4eec\u8f6c\u5411\u66f4\u590d\u6742\u7684\u9886\u57df\uff0c\u4f8b\u5982 \\(Open \\ Images \\ Dataset\\) [7]\uff0c\u4e0a\u9762\u7684\u8fd9\u79cd\u6539\u53d8\u5c06\u53d8\u5f97\u5f88\u6709\u7528\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u4e2d\u6709\u8bb8\u591a\u91cd\u53e0\u7684\u6807\u7b7e\uff08\u4f8b\u5982\u5973\u6027\u548c\u4eba\uff09\u3002\u4f7f\u7528 \\(softmax\\) \u4f1a\u5047\u5b9a\u6bcf\u4e2a\u6846\u53ea\u5305\u542b\u4e00\u4e2a\u7c7b\uff0c\u4f46\u901a\u5e38\u60c5\u51b5\u5e76\u975e\u5982\u6b64\u3002\u591a\u6807\u7b7e\u7684\u65b9\u5f0f\u53ef\u4ee5\u66f4\u597d\u5730\u5bf9\u6570\u636e\u8fdb\u884c\u5efa\u6a21\u3002","title":"2.2 \u5206\u7c7b\u9884\u6d4b"},{"location":"thesis_interpretation/03_yolo.html#23","text":"\\(YOLOv3\\) \u5728 3 \u79cd\u4e0d\u540c\u5c3a\u5ea6\u4e0a\u9884\u6d4b\u6846\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u4f7f\u7528\u7c7b\u4f3c\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc\u7684\u76f8\u4f3c\u6982\u5ff5( \u8be6\u7ec6\u53ef\u89c1\u8bba\u6587\uff1ahttps://arxiv.org/pdf/1612.03144.pdf )\uff0c\u5e76\u4ece\u8fd9\u4e9b\u5c3a\u5ea6\u4e2d\u63d0\u53d6\u7279\u5f81[8]\u3002\u6211\u4eec\u5728\u57fa\u7840\u7279\u5f81\u63d0\u53d6\u5668\u4e0a\u6dfb\u52a0\u4e86\u51e0\u4e2a\u5377\u79ef\u5c42\u3002\u5176\u4e2d\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42 \u9884\u6d4b\u4e86\u4e00\u4e2a\u7f16\u7801\u8fb9\u754c\u6846\u3001\u662f\u5426\u662f\u76ee\u6807\u548c\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c \u7684\u4e09\u7ef4\u5f20\u91cf\u3002\u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c[8]\u4e2d\uff0c\u6211\u4eec\u4e3a\u6bcf\u4e2a\u5c3a\u5ea6\u9884\u6d4b3\u4e2a\u6846\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u8fb9\u754c\u6846\u6709 4\u4e2a\u504f\u79fb\u91cf\u30011\u4e2a\u76ee\u6807\u9884\u6d4b\u548c80\u4e2a\u7c7b\u522b\u9884\u6d4b\uff0c\u6700\u7ec8\u7684\u5f20\u91cf\u5927\u5c0f\u4e3a \\(N\u00d7N\u00d7[3\u00d7(4+1+80)]\\) \u3002 \u2003\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4ece\u524d\u9762\u76842\u4e2a\u5c42\u4e2d\u63d0\u53d6\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u5176\u4e0a\u91c7\u68372\u500d\u3002\u6211\u4eec\u8fd8\u4ece\u7f51\u7edc\u4e2d\u7684\u8f83\u524d\u7684\u5c42\u4e2d\u83b7\u53d6\u4e00\u4e2a\u7279\u5f81\u56fe\uff0c\u5e76\u5c06\u5176\u4e0e\u6211\u4eec\u7684\u4e0a\u91c7\u6837\u7279\u5f81\u56fe\u8fdb\u884c\u62fc\u63a5\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u6211\u4eec\u80fd\u591f\u4ece\u4e0a\u91c7\u6837\u7684\u7279\u5f81\u56fe\u4e2d\u83b7\u5f97\u66f4\u6709\u610f\u4e49\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u540c\u65f6\u53ef\u4ee5\u4ece\u66f4\u524d\u7684\u5c42\u4e2d\u83b7\u53d6\u66f4\u7ec6\u7c92\u5ea6\u7684\u4fe1\u606f\u3002\u7136\u540e\uff0c\u6211\u4eec\u6dfb\u52a0\u51e0\u4e2a\u5377\u79ef\u5c42\u6765\u5904\u7406\u8fd9\u4e2a\u7279\u5f81\u6620\u5c04\u7ec4\u5408\uff0c\u5e76\u6700\u7ec8\u9884\u6d4b\u51fa\u4e00\u4e2a\u76f8\u4f3c\u7684\u3001\u5927\u5c0f\u662f\u539f\u5148\u4e24\u500d\u7684\u5f20\u91cf\u3002 \u2003\u6211\u4eec\u518d\u6b21\u4f7f\u7528\u76f8\u540c\u7684\u8bbe\u8ba1\u6765\u9884\u6d4b\u6700\u7ec8\u5c3a\u5bf8\u7684\u8fb9\u754c\u6846\u3002\u56e0\u6b64\uff0c\u7b2c\u4e09\u4e2a\u5c3a\u5bf8\u7684\u9884\u6d4b\u5c06\u65e2\u80fd\u4ece\u6240\u6709\u5148\u524d\u7684\u8ba1\u7b97\uff0c\u53c8\u80fd\u4ece\u7f51\u7edc\u524d\u9762\u7684\u5c42\u4e2d\u7684\u7ec6\u7c92\u5ea6\u7684\u7279\u5f81\u4e2d\u83b7\u76ca\u3002 \u2003\u6211\u4eec\u4ecd\u7136\u4f7f\u7528k-means\u805a\u7c7b\u7b97\u6cd5\u6765\u786e\u5b9a\u6211\u4eec\u7684\u5148\u9a8c\u8fb9\u754c\u6846\u3002\u6211\u4eec\u53ea\u662f\u9009\u62e9\u4e869\u4e2a\u805a\u7c7b( clusters )\u548c3\u4e2a\u4efb\u610f\u7684\u5c3a\u5ea6( scales arbitrarily )\uff0c \u7136\u540e\u5728\u5c3a\u5ea6\u4e0a\u5c06\u805a\u7c7b\u5747\u5300\u5730\u5212\u5206\u805a\u7c7b\u3002 \u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\uff0c9\u4e2a\u805a\u7c7b\u5206\u522b \u4e3a \\((10\u00d713)\u3001(16\u00d730)\u3001(33\u00d723)\u3001(30\u00d761)\u3001(62\u00d745)\u3001(59\u00d7119)\u3001(116 \u00d7 90)\u3001(156 \u00d7 198)\u3001(373 \u00d7 326)\\) \u3002","title":"2.3 \u8de8\u5c3a\u5ea6\u9884\u6d4b"},{"location":"thesis_interpretation/03_yolo.html#24","text":"\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u65b0\u7684\u7f51\u7edc\u6765\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u3002\u6211\u4eec\u7684\u65b0\u7f51\u7edc\u878d\u5408\u4e86 \\(YOLOv2\u3001Darknet-19\\) \u548c\u65b0\u53d1\u660e\u7684\u6b8b\u5dee\u7f51\u7edc\u7684\u601d\u60f3\u3002\u6211\u4eec\u7684\u7f51\u7edc\u4f7f\u7528\u8fde\u7eed\u7684 \\(3\u00d73\\) \u548c \\(1\u00d71\\) \u5377\u79ef\u5c42\u548c\u6dfb\u52a0\u4e86\u4e00\u4e9b\u5feb\u6377\u8fde\u63a5\uff08shortcut connetction\uff09\uff0c\u4ece\u800c\u89c4\u6a21\u66f4\u5927\uff0c\u76ee\u524d\u5b83\u670953\u4e2a\u5377\u79ef\u5c42\uff0c\u6240\u4ee5\u6211\u4eec\u79f0\u4e4b\u4e3a... \\(Darknet-53!\\) \u88681. Darknet-53. \u6211\u4eec\u7684\u7f51\u7edc\u5728\u6027\u80fd\u4e0a\u8fdc\u8d85Darknet-19\uff0c\u5728\u6548\u7387\u4e0a\u4e5f\u4f18\u4e8eResNet-101\u548cResNet-152\u3002\u8fd9\u91cc\u662f\u4e00\u4e9b\u7f51\u7edc\u5728ImageNet\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\uff1a \\[ \\begin{eqnarray} \\text { Backbone } & \\text { Top-1 } & \\text { Top-5 } & \\text { Bn Ops } & \\text { BFLOP/s } & \\text { FPS } \\\\ \\hline \\text { Darknet-19[15] } & 74.1 & 91.8 & 7.29 & 1246 & \\mathbf{1 7 1} \\\\ \\text { ResNet-101[5] } & 77.1 & 93.7 & 19.7 & 1039 & 53 \\\\ \\text { ResNet-152[5] } & \\mathbf{7 7 . 6} & \\mathbf{9 3 . 8} & 29.4 & 1090 & 37 \\\\ \\text { Darknet-53 } & 77.2 & \\mathbf{9 3 . 8} & 18.7 & \\mathbf{1 4 5 7} & 78 \\end{eqnarray} \\] \u88682.\u7f51\u7edc\u7684\u6bd4\u8f83\u3002\u4e0d\u540cbackbones\u7684\u5404\u79cd\u7f51\u7edc\u5728\u51c6\u786e\u5ea6\u3001Bn Ops\uff08\u5341\u4ebf\u64cd\u4f5c\u6570\uff09\u3001BFLOP/s\uff08\u6bcf\u79d2\u5341\u4ebf\u6d6e\u70b9\u64cd\u4f5c\uff09\u548cFPS\u4e0a\u7684\u6bd4\u8f83\u3002 \u2003\u6bcf\u4e2a\u7f51\u7edc\u90fd\u5728\u76f8\u540c\u7684\u914d\u7f6e\u4e0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5747\u7528 \\(256 \u00d7256\\) \u7684\u56fe\u7247\u4e0a\u8fdb\u884c\u5355\u7cbe\u5ea6\u6d4b\u8bd5\u3002\u8fd0\u884c\u65f6\u95f4\u901a\u8fc7\u5728 \\(Titan \\ X\\) \u4e0a\u5904\u7406 \\(256 \u00d7 256\\) \u56fe\u7247\u6d4b\u51fa\u3002\u4ece\u88682\u53ef\u4ee5\u770b\u51fa\uff0c \\(Darknet-53\\) \u4e0d\u4ec5\u7cbe\u5ea6\u53ef\u4ee5\u5ab2\u7f8e\u6700\u5148\u8fdb\u7684\u5206\u7c7b\u5668\uff0c\u800c\u4e14\u5b83\u6709\u8f83\u5c11\u6d6e\u70b9\u8fd0\u7b97\u64cd\u4f5c\uff0c\u66f4\u5feb\u7684\u901f\u5ea6\u3002 \\(Darknet-53\\) \u6bd4 \\(ResNet-101\\) \u6027\u80fd\u66f4\u597d\u800c\u4e14\u8981\u5feb1.5\u500d\u3002 \\(Darknet-53\\) \u6027\u80fd\u4e0e \\(ResNet-152\\) \u76f8\u8fd1\uff0c\u4f46\u662f\u8981\u6bd4\u5b83\u5feb2\u500d\u3002 \u2003 \\(Darknet-53\\) \u4e5f\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u6bcf\u79d2\u6d6e\u70b9\u8fd0\u7b97\u6d4b\u91cf\u3002\u8fd9\u610f\u5473\u7740\u7f51\u7edc\u7ed3\u6784\u53ef\u4ee5\u66f4\u597d\u5730\u5229\u7528GPU\uff0c\u4f7f\u5176\u9884\u6d4b\u6548\u7387\u66f4\u9ad8\uff0c\u901f\u5ea6\u66f4\u5feb\u3002ResNets\u66f4\u6162\uff0c\u5927\u62b5\u662f\u56e0\u4e3a\u5176\u5c42\u6570\u592a\u591a\uff0c\u6240\u4ee5\u4e0d\u662f\u90a3\u4e48\u6709\u6548\u7387\u3002","title":"2.4 \u7279\u5f81\u63d0\u53d6\u5668"},{"location":"thesis_interpretation/03_yolo.html#25","text":"\u6211\u4eec\u4f9d\u65e7\u53ea\u662f\u8bad\u7ec3\u5b8c\u6574\u7684\u56fe\u50cf\uff0c\u6ca1\u6709\u5c06\u96be\u4ee5\u6b63\u786e\u5206\u7c7b\u7684\u6837\u672c\u53cd\u590d\u8bad\u7ec3\uff0c\u4e5f\u6ca1\u6709\u8fdb\u884c\u5176\u4ed6\u4efb\u4f55\u64cd\u4f5c\u3002\u6211\u4eec\u4f7f\u7528\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u4f7f\u7528\u5927\u91cf\u7684\u6570\u636e\u589e\u5f3a\u3001\u6279\u91cf\u6807\u51c6\u5316\u7b49\u6807\u51c6\u7684\u64cd\u4f5c\u3002\u6211\u4eec\u4f7f\u7528 \\(Darknet\\) \u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5[12]\u3002 \\(YOLOv3\\) is pretty good! See table 3. In terms of COCOs weird average mean AP metric it is on par with the SSD variants but is 3\u00d7 faster. It is still quite a bit behind other models like RetinaNet in this metric though. Table 3. I\u2019m seriously just stealing all these tables from [9] they take soooo long to make from scratch. Ok, \\(YOLOv3\\) is doing alright. Keep in mind that RetinaNet has like 3.8\u00d7 longer to process an image. \\(YOLOv3\\) is much better than SSD variants and comparable to state-of-the-art models on the AP50 metric.","title":"2.5 \u8bad\u7ec3"},{"location":"thesis_interpretation/03_yolo.html#3","text":"\\(YOLOv3\\) \u8868\u73b0\u975e\u5e38\u597d\uff01\u8bf7\u770b\u88683\u3002\u5c31COCO\u7684\u5e73\u5747AP\u6307\u6807\u800c\u8a00\uff0c\u5b83\u4e0eSSD\u7c7b\u7684\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u63d0\u9ad8\u4e863\u500d\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u5b83\u4ecd\u7136\u5728\u8fd9\u4e2a\u6307\u6807\u4e0a\u6bd4\u50cfRetinaNet\u8fd9\u6837\u7684\u5176\u4ed6\u6a21\u578b\u5dee\u4e9b\u3002 \u88683.\u6211\u5f88\u8ba4\u771f\u5730\u4ece[9]\u4e2d \\(\u201c\u7a83\u53d6\u201d\\) \u4e86\u4ed6\u4eec\u82b1\u4e86\u5f88\u957f\u65f6\u95f4\u624d\u4ece\u5934\u5f00\u59cb\u5236\u4f5c\u8fd9\u4e9b\u8868\u683c\u3002\u597d\u7684\uff0c \\(YOLOv3\\) \u6ca1\u95ee\u9898\u3002\u8bf7\u8bb0\u4f4f\uff0c \\(RetinaNet\\) \u5904\u7406\u4e00\u5f20\u56fe\u50cf\u7684\u65f6\u95f4\u662f \\(YOLOv3\\) \u7684 \\(3.8\\) \u500d\u3002 \\(YOLOv3\\) \u6bd4 \\(SSD\\) \u8981\u597d\u5f97\u591a\uff0c\u5e76\u4e14\u5728 \\(AP50\\) \u6807\u51c6\u4e0b\u53ef\u4ee5\u4e0e\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5ab2\u7f8e\uff01 \u2003\u7136\u800c\uff0c\u5f53\u6211\u4eec\u4f7f\u7528 \\(\u201c\u65e7\u7684\u201d\\) \u68c0\u6d4b\u6307\u6807\u2014\u2014\u5728 \\(IOU=0.5\u7684mAP\\) \uff08\u6216\u56fe\u8868\u4e2d\u7684 \\(AP50\\) \uff09\u65f6\uff0c \\(YOLOv3\\) \u975e\u5e38\u5f3a\u5927\u3002\u5176\u6027\u80fd\u51e0\u4e4e\u4e0eRetinaNet\u76f8\u5f53\uff0c\u5e76\u4e14\u8fdc\u5f3a\u4e8e \\(SSD\\) \u3002\u8fd9\u8868\u660e \\(YOLOv3\\) \u662f\u4e00\u4e2a\u975e\u5e38\u5f3a\u5927\u7684\u68c0\u6d4b\u5668\uff0c\u64c5\u957f\u4e3a\u76ee\u6807\u751f\u6210\u6070\u5f53\u7684\u6846\u3002\u7136\u800c\uff0c\u968f\u7740 \\(IOU\\) \u9608\u503c\u589e\u52a0\uff0c\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8fd9\u8868\u660e \\(YOLOv3\\) \u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4e0e\u76ee\u6807\u4e0d\u80fd\u5b8c\u7f8e\u5bf9\u9f50\u3002 Figure 3. Again adapted from the [9], this time displaying speed/accuracy tradeoff on the mAP at .5 IOU metric. You can tell \\(YOLOv3\\) is good because it\u2019s very high and far to the left. Can you cite your own paper? Guess who\u2019s going to try, this guy ! [16]. Oh, I forgot, we also fix a data loading bug in YOLOv2, that helped by like 2 mAP. Just sneaking this in here to not throw off layout. \u56fe3. \u518d\u6b21\u6539\u7f16\u81ea[9]\uff0c\u8fd9\u6b21\u663e\u793a\u7684\u662f\u5728 \\(0.5 \\ IOU\\) \u6307\u6807\u4e0a\u901f\u5ea6/\u51c6\u786e\u5ea6\u7684\u6743\u8861\u3002\u4f60\u53ef\u4ee5\u8bf4 \\(YOLOv3\\) \u662f\u597d\u7684\uff0c\u56e0\u4e3a\u5b83\u975e\u5e38\u9ad8\u5e76\u4e14\u5728\u5de6\u8fb9\u5f88\u8fdc\u3002 \u4f60\u80fd\u5f15\u7528\u4f60\u81ea\u5df1\u7684\u8bba\u6587\u5417\uff1f\u731c\u731c\u8c01\u4f1a\u53bb\u5c1d\u8bd5\uff0c\u8fd9\u4e2a\u4eba\u2192[16]\u3002\u54e6\uff0c\u6211\u5fd8\u4e86\uff0c\u6211\u4eec\u8fd8\u4fee\u590d\u4e86YOLOv2\u4e2d\u7684\u6570\u636e\u52a0\u8f7dbug\uff0c\u8be5bug\u7684\u4fee\u590d\u63d0\u5347\u4e862 mAP, \u53ea\u662f\u5728\u8fd9\u91cc\u5077\u5077\u63d0\u4e00\u4e0b\uff0c\u8fd9\u4e0d\u662f\u91cd\u70b9\u3002 \u2003\u5728\u4e4b\u524d\u7684 \\(YOLO\\) \u4e0d\u64c5\u957f\u68c0\u6d4b\u5c0f\u7269\u4f53\u3002\u4f46\u662f\uff0c\u73b0\u5728\u6211\u4eec\u770b\u5230\u4e86\u8fd9\u79cd\u8d8b\u52bf\u7684\u9006\u8f6c\u3002\u968f\u7740\u65b0\u7684\u591a\u5c3a\u5ea6\u9884\u6d4b\uff0c\u6211\u4eec\u770b\u5230 \\(YOLOv3\\) \u5177\u6709\u76f8\u5bf9\u8f83\u9ad8\u7684 \\(APS\\) \u6027\u80fd\u3002\u4f46\u662f\uff0c\u5b83\u5728\u4e2d\u578b\u548c\u5927\u578b\u7269\u4f53\u68c0\u6d4b\u4e0a\u7684\u6027\u80fd\u8fd8\u76f8\u5bf9\u8f83\u5dee\u3002\u8fd9\u53ef\u80fd\u9700\u8981\u66f4\u591a\u7684\u8c03\u7814\u548c\u5b9e\u9a8c\u624d\u80fd\u77e5\u9053\u5982\u4f55\u53bb\u6539\u8fdb\u8fd9\u4e00\u70b9\u3002 \u2003\u5f53\u6211\u4eec\u5728 \\(AP50\\) \u6307\u6807\u4e0a\u7ed8\u5236\u51c6\u786e\u5ea6\u548c\u901f\u5ea6\u5173\u7cfb\u56fe\u65f6\uff08\u8bf7\u89c1\u56fe3\uff09\uff0c\u6211\u4eec\u770b\u5230 \\(YOLOv3\\) \u4e0e\u5176\u4ed6\u68c0\u6d4b\u7cfb\u7edf\u76f8\u6bd4\u5177\u6709\u663e\u7740\u7684\u4f18\u52bf\u3002\u4e5f\u5c31\u662f\u8bf4 \\(YOLOv3\\) \uff0c\u901f\u5ea6\u66f4\u5feb\u3001\u6027\u80fd\u66f4\u597d\u3002","title":"3 \u6211\u4eec\u662f\u5982\u4f55\u505a\u7684"},{"location":"thesis_interpretation/03_yolo.html#4","text":"\u6211\u4eec\u5728\u5b9e\u73b0 \\(YOLOv3\\) \u7684\u8fc7\u7a0b\u4e2d\u5c1d\u8bd5\u4e86\u5f88\u591a\u4e1c\u897f\uff0c\u4f46\u662f\u5f88\u591a\u90fd\u5931\u8d25\u4e86\uff0c\u4ee5\u4e0b\u662f\u6211\u4eec\u8fd8\u8bb0\u5f97\u7684\u4e00\u4e9b\u5931\u8d25\u7684\u5c1d\u8bd5\u3002 \u2003 Anchor\u6846\u7684x\u3001y\u504f\u79fb\u9884\u6d4b \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528\u5e38\u89c4\u7684Anchor\u6846\u9884\u6d4b\u673a\u5236\uff0c\u6bd4\u5982\u5229\u7528\u7ebf\u6027\u6fc0\u6d3b\u5c06\u5750\u6807x\u3001y\u7684\u504f\u79fb\u7a0b\u5ea6\u9884\u6d4b\u4e3a\u8fb9\u754c\u6846\u5bbd\u5ea6\u6216\u9ad8\u5ea6\u7684\u500d\u6570\u3002\u4f46\u6211\u4eec\u53d1\u73b0\u8fd9\u79cd\u65b9\u6cd5\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u4e14\u6548\u679c\u4e0d\u4f73\u3002 \u2003 \u7528\u7ebf\u6027\u6fc0\u6d3b\u4ee3\u66ff\u903b\u8f91\u6fc0\u6d3b\u51fd\u6570\u8fdb\u884cx\u3001y\u9884\u6d4b \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528\u7ebf\u6027\u6fc0\u6d3b\u4ee3\u66ff\u903b\u8f91\u6fc0\u6d3b\u6765\u76f4\u63a5\u9884\u6d4bx\u3001y\u504f\u79fb\u3002\u8fd9\u4e2a\u6539\u53d8\u5bfc\u81f4mAP\u4e0b\u964d\u4e86\u51e0\u4e2a\u70b9\u3002 \u2003 focal loss \u3002\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528focal loss\u3002\u5b83\u4f7f\u5f97mAP\u4e0b\u964d2\u4e2a\u70b9\u3002 \\(YOLOv3\\) \u53ef\u80fd\u5df2\u7ecf\u5bf9focal loss \u8bd5\u56fe\u89e3\u51b3\u7684\u95ee\u9898\u5177\u6709\u76f8\u5f53\u7684\u9c81\u68d2\u6027\uff0c\u56e0\u4e3a\u5b83\u5177\u6709\u5355\u72ec\u7684\u76ee\u6807\u9884\u6d4b\u548c\u6761\u4ef6\u7c7b\u522b\u9884\u6d4b\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u5927\u591a\u6570\u6837\u672c\u6765\u8bf4\uff0c\u7c7b\u522b\u9884\u6d4b\u6ca1\u6709\u635f\u5931\uff1f\u6216\u8005\u6709\u4e00\u4e9b\uff1f\u6211\u4eec\u5e76\u4e0d\u5b8c\u5168\u786e\u5b9a\u3002 \u2003 \u53ccIOU\u9608\u503c\u548c\u771f\u503c\u5206\u914d \u3002 \\(Faster \\ R-CNN\\) \u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528\u4e24\u4e2a \\(IOU\\) \u9608\u503c\u3002\u5982\u679c\u4e00\u4e2a\u9884\u6d4b\u4e0e\u771f\u5b9e\u6807\u7b7e\u6846\u91cd\u53e0\u8d85\u8fc7 \\(0.7\\) \uff0c\u5b83\u5c31\u662f\u4e00\u4e2a\u6b63\u6837\u672c\uff0c\u82e5\u91cd\u53e0\u5728 \\([0.3\uff0c0.7]\\) \u4e4b\u95f4\uff0c\u90a3\u4e48\u5b83\u4f1a\u88ab\u5ffd\u7565\uff0c\u82e5\u5b83\u4e0e\u6240\u6709\u7684\u771f\u5b9e\u6807\u7b7e\u6846\u7684 \\(IOU\\) \u5c0f\u4e8e0.3\uff0c\u90a3\u4e48\u5c31\u4f1a\u88ab\u5224\u5b9a\u4e3a\u4e00\u4e2a\u8d1f\u6837\u672c\u3002\u6211\u4eec\u5c1d\u8bd5\u4e86\u7c7b\u4f3c\u7684\u7b56\u7565\uff0c\u4f46\u6700\u7ec8\u7684\u6548\u679c\u5e76\u4e0d\u597d\u3002 \u2003\u6211\u4eec\u975e\u5e38\u559c\u6b22\u76ee\u524d\u7684\u6a21\u578b\uff0c\u5b83\u81f3\u5c11\u5728\u5c40\u90e8\u8fbe\u5230\u4e86\u6700\u4f73\u3002\u4e0a\u8ff0\u7684\u6709\u4e9b\u6280\u672f\u53ef\u80fd\u4f1a\u4f7f\u6211\u4eec\u7684\u6a21\u578b\u66f4\u597d\uff0c\u4f46\u6211\u4eec\u53ef\u80fd\u8fd8\u9700\u8981\u5bf9\u4ed6\u4eec\u505a\u4e00\u4e9b\u8c03\u6574\u3002","title":"4 \u5931\u8d25\u7684\u5c1d\u8bd5"},{"location":"thesis_interpretation/03_yolo.html#5","text":"\\(YOLOv3\\) \u662f\u4e00\u4e2a\u5f88\u68d2\u7684\u68c0\u6d4b\u5668\uff0c\u5b83\u7531\u51c6\u53c8\u5feb\u3002\u867d\u7136\u5b83\u5728 \\(COCO\\) \u6570\u636e\u96c6\u4e0a\uff0c0.3\u548c0.95 IOU \u4e0b\u7684\u5e73\u5747AP\u5e76\u4e0d\u597d\uff0c\u4f46\u5728\u65e7\u7684 0.5 IOU\u7684\u68c0\u6d4b\u6307\u6807\u4e0b\uff0c\u5b83\u8fd8\u662f\u975e\u5e38\u4e0d\u9519\u7684\u3002 \u2003 \u4e3a\u4ec0\u4e48\u6211\u4eec\u8981\u6539\u53d8\u6307\u6807\uff1f \\(COCO\\) \u7684\u539f\u8bba\u6587\u6709\u8fd9\u6837\u4e00\u53e5\u542b\u7cca\u4e0d\u6e05\u7684\u53e5\u5b50\uff1a \\(\u201cA \\ full \\ discussion \\ of \\ evaluation \\ metrics \\ will \\ be \\ added \\ once \\ the \\ evaluation \\ server \\ is \\ complete\u201d\\) \u3002Russakovsky\u7b49\u4eba\u7684\u62a5\u544a\u4e2d\u8bf4\uff0c\u4eba\u4eec\u5f88\u96be\u533a\u52060.3\u548c0.5\u7684IOU\u3002\u201c\u8bad\u7ec3\u4eba\u7c7b\u7528\u89c6\u89c9\u68c0\u67e50.3 IOU\u7684\u8fb9\u754c\u6846\uff0c\u5e76\u4e14\u4e0e0.5 IOU\u7684\u6846\u533a\u522b\u5f00\u6765\u662f\u975e\u5e38\u56f0\u96be\u7684\u3002\u201c[16]\u5982\u679c\u4eba\u7c7b\u5f88\u96be\u8bf4\u51fa\u5dee\u5f02\uff0c\u90a3\u4e48\u5b83\u4e5f\u6ca1\u6709\u591a\u91cd\u8981\u5427\uff1f \u2003\u4e5f\u8bb8\u6709\u4e2a\u66f4\u597d\u7684\u95ee\u9898\u503c\u5f97\u6211\u4eec\u63a2\u8ba8\u201c\u6211\u4eec\u7528\u5b83\u6765\u5e72\u4ec0\u4e48\u201d\u8bb8\u591a\u4ece\u4e8b\u8fd9\u9879\u7814\u7a76\u7684\u4eba\u90fd\u5728Google\u548cFacebook\uff0c\u6211\u60f3\u81f3\u5c11\u6211\u4eec\u77e5\u9053\u8fd9\u4e2a\u6280\u672f\u662f\u638c\u63e1\u5728\u597d\u4eba\u624b\u91cc\uff0c\u7edd\u5bf9\u4e0d\u4f1a\u628a\u5b83\u7528\u6765\u6536\u96c6\u4f60\u7684\u4e2a\u4eba\u4fe1\u606f\u7136\u540e\u5356\u7ed9\u2026\u2026\u7b49\u7b49\uff0c\u4f60\u7a76\u7adf\u60f3\u7528\u5b83\u6765\u5e72\u561b\uff01\uff01\u5662\u3002 \u2003\u5176\u4ed6\u82b1\u5927\u94b1\u8d44\u52a9\u89c6\u89c9\u7814\u7a76\u7684\u4eba\u8fd8\u6709\u519b\u65b9\uff0c\u4ed6\u4eec\u4ece\u6765\u6ca1\u6709\u505a\u8fc7\u4efb\u4f55\u53ef\u6015\u7684\u4e8b\u60c5\uff0c\u4f8b\u5982\u7528\u65b0\u6280\u672f\u6740\u6b7b\u5f88\u591a\u4eba\uff0c\u7b49\u7b49..... \u6211\u5f3a\u70c8\u5730\u5e0c\u671b\uff0c\u5927\u591a\u6570\u4f7f\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u4eba\u90fd\u7528\u5b83\u6765\u505a\u4e00\u4e9b\u5feb\u4e50\u4e14\u6709\u76ca\u7684\u4e8b\u60c5\uff0c\u6bd4\u5982\u8ba1\u7b97\u4e00\u4e2a\u56fd\u5bb6\u516c\u56ed\u91cc\u6591\u9a6c\u7684\u6570\u91cf[13]\uff0c\u6216\u8005\u8ffd\u8e2a\u5728\u9644\u8fd1\u5f98\u5f8a\u7684\u732b[19]\u3002\u4f46\u8ba1\u7b97\u673a\u89c6\u89c9\u5df2\u7ecf\u88ab\u7528\u4e8e\u503c\u5f97\u6000\u7591\u7684\u7528\u9014\uff0c\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\uff0c\u6211\u4eec\u6709\u8d23\u4efb\u8003\u8651\u6211\u4eec\u7684\u5de5\u4f5c\u53ef\u80fd\u9020\u6210\u7684\u635f\u5bb3\uff0c\u5e76\u601d\u8003\u5982\u4f55\u51cf\u8f7b\u5b83\u7684\u5f71\u54cd\u3002\u6211\u4eec\u6b20\u8fd9\u4e2a\u4e16\u754c\u592a\u591a\u3002 \u6700\u540e\uff0c\u4e0d\u8981\u518d@\u6211\u4e86\u3002\uff08\u56e0\u4e3a\u6211\u5df2\u7ecf\u9000\u51faTwitter\u8fd9\u4e2a\u662f\u975e\u4e4b\u5730\u4e86\uff09\u3002 In closing, do not@me. (Because I finally quit Twitter).","title":"5 \u8fd9\u4e00\u5207\u610f\u5473\u7740\u4ec0\u4e48"},{"location":"thesis_interpretation/03_yolo.html#references","text":"[1] Analogy. Wikipedia, Mar 2018. 1 [2] M. Everingham, L. V an Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) challenge. International journal of computer vision, 88(2):303\u2013 338, 2010. 6 [3] C.-Y . Fu, W. Liu, A. Ranga, A. Tyagi, and A. C. Berg. Dssd: Deconvolutional single shot detector. arXiv preprint arXiv:1701.06659, 2017. 3 [4] D. Gordon, A. Kembhavi, M. Rastegari, J. Redmon, D. Fox, and A. Farhadi. Iqa: Visual question answering in interactive environments. arXiv preprint arXiv:1712.03316, 2017. 1 [5] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016. 3 [6] J. Huang, V . Rathod, C. Sun, M. Zhu, A. Korattikara, A. Fathi, I. Fischer, Z. Wojna, Y . Song, S. Guadarrama, et al Speed/accuracy trade-offs for modern convolutional object detectors. 3 [7] I. Krasin, T. Duerig, N. Alldrin, V . Ferrari, S. Abu-El-Haija, A. Kuznetsova, H. Rom, J. Uijlings, S. Popov, A. V eit, S. Belongie, V . Gomes, A. Gupta, C. Sun, G. Chechik, D. Cai, Z. Feng, D. Narayanan, and K. Murphy. Openimages: A public dataset for large-scale multi-label and multi-class image classification. Dataset available from https://github.com/openimages, 2017. 2 [8] T.-Y . Lin, P . Dollar, R. Girshick, K. He, B. Hariharan, and S. Belongie. Feature pyramid networks for object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2117\u20132125, 2017. 2, 3 [9] T.-Y . Lin, P . Goyal, R. Girshick, K. He, and P . Doll\u00e1r. Focal loss for dense object detection. arXiv preprint arXiv:1708.02002, 2017. 1, 3, 4 [10] T.-Y . Lin, M. Maire, S. Belongie, J. Hays, P . Perona, D. Ramanan, P . Doll\u00e1r, and C. L. Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision, pages 740\u2013755. Springer, 2014. 2 [11] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.Y . Fu, and A. C. Berg. Ssd: Single shot multibox detector. In European conference on computer vision, pages 21\u201337. Springer, 2016. 3 [12] I. Newton. Philosophiae naturalis principia mathematica. William Dawson & Sons Ltd., London, 1687. 1 [13] J. Parham, J. Crall, C. Stewart, T. Berger-Wolf, and D. Rubenstein. Animal population censusing at scale with citizen science and photographic identification. 2017. 4 [14] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013\u20132016. 3 [15] J. Redmon and A. Farhadi. Y olo9000: Better, faster, stronger. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pages 6517\u20136525. IEEE, 2017. 1, 2, 3 [16] J. Redmon and A. Farhadi. Y olov3: An incremental improvement. arXiv, 2018. 4 [17] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497, 2015. 2 [18] O. Russakovsky, L.-J. Li, and L. Fei-Fei. Best of both worlds: human-machine collaboration for object annotation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2121\u20132131, 2015. 4 [19] M. Scott. Smart camera gimbal bot scanlime:027, Dec 2017. 4 [20] A. Shrivastava, R. Sukthankar, J. Malik, and A. Gupta. Be- yond skip connections: Top-down modulation for object de- tection. arXiv preprint arXiv:1612.06851, 2016. 3 [21] C. Szegedy, S. Ioffe, V . V anhoucke, and A. A. Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. 2017. 3","title":"References"},{"location":"thesis_interpretation/04_yolo.html","text":"[2004.10934] YOLOv4: Optimal Speed and Accuracy of Object Detection (arxiv.org) Abstract \u6458\u8981 \u2003There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is re- quired. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and com- bine some of them to achieve state-of-the-art results: 43.5% AP (65.7% AP50) for the MS COCO dataset at a real- time speed of \u223c65 FPS on Tesla V100. Source code is at https://github.com/AlexeyAB/darknet. \u636e\u8bf4\u6709\u5927\u91cf\u7279\u5f81\u53ef\u4ee5\u63d0\u9ad8\u5377\u79ef\u795e\u7ecf\u7f51\u7edc (CNN) \u7684\u51c6\u786e\u6027\u3002 \u9700\u8981\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u5bf9\u8fd9\u4e9b\u7279\u5f81\u7684\u7ec4\u5408\u8fdb\u884c\u5b9e\u9645\u6d4b\u8bd5\uff0c\u5e76\u5bf9\u7ed3\u679c\u8fdb\u884c\u7406\u8bba\u8bba\u8bc1\u3002 \u67d0\u4e9b\u7279\u5f81\u4e13\u95e8\u9488\u5bf9\u67d0\u4e9b\u6a21\u578b\uff0c\u4e13\u95e8\u9488\u5bf9\u67d0\u4e9b\u95ee\u9898\uff0c\u6216\u4ec5\u9488\u5bf9\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\uff1b \u800c\u4e00\u4e9b\u7279\u6027\uff0c\u5982\u6279\u91cf\u5f52\u4e00\u5316\u548c\u6b8b\u5dee\u8fde\u63a5\uff0c\u9002\u7528\u4e8e\u5927\u591a\u6570\u6a21\u578b\u3001\u4efb\u52a1\u548c\u6570\u636e\u96c6\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u901a\u7528\uff08universal\uff09\u7279\u5f81\u5305\u62ec\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5 (WRC)\u3001\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5 (CSP)\u3001\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3001\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u548c Mish \u6fc0\u6d3b\u3002 \u6211\u4eec\u4f7f\u7528\u65b0\u529f\u80fd\uff1aWRC\u3001CSP\u3001CmBN\u3001SAT\u3001Mish \u6fc0\u6d3b\u3001Mosaic \u6570\u636e\u589e\u5f3a\u3001DropBlock \u6b63\u5219\u5316\u548c CIoU \u635f\u5931\uff0c\u5e76\u7ed3\u5408\u5176\u4e2d\u7684\u4e00\u4e9b\u6765\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff1a\u5728 Tesla V100 \u4e0a\u4ee5 ~65 FPS \u7684\u5b9e\u65f6\u901f\u5ea6\u7528\u4e8e MS COCO \u6570\u636e\u96c6\uff0c\u7ed3\u679c\u4e3a43.5% AP\uff0865.7 % AP50) \u3002 \u6e90\u4ee3\u7801\u4f4d\u4e8e https://github.com/AlexeyAB/darknet\u3002 Introduction \u5f15\u8a00 \u2003The majority of CNN-based object detectors are largely applicable only for recommendation systems. For example, searching for free parking spaces via urban video cameras is executed by slow accurate models, whereas car collision warning is related to fast inaccurate models. Improving the real-time object detector accuracy enables using them not only for hint generating recommendation systems, but also for stand-alone process management and human input reduction. Real-time object detector operation on conven- tional Graphics Processing Units (GPU) allows their mass usage at an affordable price. The most accurate modern neural networks do not operate in real time and require large number of GPUs for training with a large mini-batch-size. We address such problems through creating a CNN that op- erates in real-time on a conventional GPU, and for which training requires only one conventional GPU. \u2003\u5927\u591a\u6570\u57fa\u4e8e CNN \u7684\u5bf9\u8c61\u68c0\u6d4b\u5668\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4ec5\u9002\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\uff08recommendation system\uff09\u3002 \u4f8b\u5982\uff0c\u901a\u8fc7\u57ce\u5e02\u6444\u50cf\u673a\u641c\u7d22\u514d\u8d39\u505c\u8f66\u4f4d\u662f\u7531\u6162\u901f\u51c6\u786e\u6a21\u578b\u6267\u884c\u7684\uff0c\u800c\u6c7d\u8f66\u78b0\u649e\u8b66\u544a\u4e0e\u5feb\u901f\u4e0d\u51c6\u786e\u6a21\u578b\u6709\u5173\u3002 \u63d0\u9ad8\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u4e0d\u4ec5\u53ef\u4ee5\u5c06\u5b83\u4eec\u7528\u4e8e\u63d0\u793a\u751f\u6210\u63a8\u8350\u7cfb\u7edf\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u72ec\u7acb\u6d41\u7a0b\u7ba1\u7406\uff08stand-alone process management\uff09\u548c\u51cf\u5c11\u4eba\u5de5\u8f93\u5165\u3002 \u4f20\u7edf\u56fe\u5f62\u5904\u7406\u5355\u5143 (GPU) \u4e0a\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u64cd\u4f5c\u5141\u8bb8\u4ee5\u5b9e\u60e0\u7684\u4ef7\u683c\u5927\u89c4\u6a21\u4f7f\u7528\u3002 \u6700\u7cbe\u786e\u7684\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u65e0\u6cd5\u5b9e\u65f6\u8fd0\u884c\uff0c\u5e76\u4e14\u9700\u8981\u5927\u91cf\u7684 GPU \u8fdb\u884c\u5927\u578b\u5c0f\u578b\u6279\u5904\u7406\u5927\u5c0f\u7684\u8bad\u7ec3\u3002\u6211\u4eec\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a\u5728\u4f20\u7edf GPU \u4e0a\u5b9e\u65f6\u8fd0\u884c\u7684 CNN \u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4e3a\u6b64\u8bad\u7ec3\u53ea\u9700\u8981\u4e00\u4e2a\u5e38\u89c4 GPU\u3002 Figure 1: Comparison of the proposed YOLOv4 and other state-of-the-art object detectors. YOLOv4 runs twice faster than EfficientDet with comparable performance. Improves YOLOv3\u2019s AP and FPS by 10% and 12%, respectively. \u56fe1\uff1a\u5bf9YOLOv4\u548c\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u8fdb\u884c\u6bd4\u8f83\u3002\u5177\u6709\u540c\u7b49\u7684\u6027\u80fd\u60c5\u51b5\u4e0b\uff0cYOLOv4\u7684\u901f\u5ea6\u662f EfficientDet \u7684\u4e24\u500d\u3002\u5e76\u4e14 YOLOv4 \u5c06YOLOv3 \u7684 AP \u548c FPS \u5206\u522b\u63d0\u9ad8\u4e86 10% \u548c 12%\u3002 \u2003The main goal of this work is designing a fast operating speed of an object detector in production systems and opti- mization for parallel computations, rather than the low com- putation volume theoretical indicator (BFLOP). We hope that the designed object can be easily trained and used. For example, anyone who uses a conventional GPU to train and test can achieve real-time, high quality, and convincing ob- ject detection results, as the YOLOv4 results shown in Fig- ure 1. Our contributions are summarized as follows: \u2003\u8fd9\u9879\u5de5\u4f5c\u7684\u4e3b\u8981\u76ee\u6807\u662f\u8bbe\u8ba1\u751f\u4ea7\u7cfb\u7edf\u4e2d\u8fd0\u884c\u901f\u5ea6\u8f83\u5feb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5e76\u4f18\u5316\u5e76\u884c\u8ba1\u7b97\uff0c\u800c\u4e0d\u662f\u4f4e\u8ba1\u7b97\u91cf\u7406\u8bba\u6307\u6807 \uff08BFLOP\uff09\u3002\u6211\u4eec\u5e0c\u671b\u8bbe\u8ba1\u7684\u68c0\u6d4b\u5668\u80fd\u591f\u8f7b\u677e\u8bad\u7ec3\u548c\u4f7f\u7528\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u4efb\u4f55\u4f20\u7edf GPU \u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u4eba\u90fd\u53ef\u4ee5\u83b7\u5f97\u5b9e\u65f6\u3001\u9ad8\u8d28\u91cf\u548c\u4ee4\u4eba\u4fe1\u670d\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\uff0c\u5982\u56fe 1 \u6240\u793a\u7684 YOLOv4 \u7ed3\u679c\u6240\u793a\u3002\u6211\u4eec\u7684\u8d21\u732e\u603b\u7ed3\u5982\u4e0b\uff1a 1\uff09 We develope an efficient and powerful object detection model. It makes everyone can use a 1080 Ti or 2080 Ti GPU to train a super fast and accurate object detector. 1\uff09\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u9ad8\u6548\u800c\u5f3a\u5927\u7684\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u3002 \u5b83\u4f7f\u6bcf\u4e2a\u4eba\u90fd\u53ef\u4ee5\u4f7f\u7528 1080 Ti \u6216 2080 Ti GPU \u6765\u8bad\u7ec3\u4e00\u4e2a\u8d85\u5feb\u901f\u548c\u51c6\u786e\u7684\u76ee\u6807 \u68c0\u6d4b\u5668\u3002 2\uff09We verify the influence of state-of-the-art Bag-of- Freebies and Bag-of-Specials methods of object detec- tion during the detector training. 2\uff09\u5728\u68c0\u6d4b\u5668\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u9a8c\u8bc1\u4e86\u6700\u5148\u8fdb\u7684 Bag-of-Freebies \u548c Bag-of-Specials \u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u7684\u5f71\u54cd\u3002 3\uff09We modify state-of-the-art methods and make them more effecient and suitable for single GPU training, including CBN [89], PAN [49], SAM [85], etc. 3\uff09\u6211\u4eec\u4fee\u6539\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u66f4\u6709\u6548\uff0c\u66f4\u9002\u5408\u5355 GPU \u8bad\u7ec3\uff0c\u65b9\u6cd5\u5305\u62ec CBN [89]\u3001PAN [49]\u3001SAM [85] \u7b49\u3002 \u56fe2\uff1a\u76ee\u6807\u68c0\u6d4b\u5668 2. Related work \u76f8\u5173\u5de5\u4f5c 2.1. Object detection models \u76ee\u6807\u68c0\u6d4b\u6a21\u578b \u2003A modern detector is usually composed of two parts,a backbone which is pre-trained on ImageNet and a head which is used to predict classes and bounding boxes of objects.For those detectors running on GPU platform, their backbone could be VGG [68], ResNet [26], ResNeXt [86], or DenseNet [30]. For those detectors running on CPU platform, their backbone could be SqueezeNet [31], MobileNet [28, 66, 27, 74], or ShuffleNet [97, 53]. As to the head part, it is usually categorized into two kinds, i.e., one-stage object detector and two-stage object detector. The most representative two-stage object detector is the R-CNN [19] series, including fast R-CNN [18], faster R-CNN [64], R-FCN [9], and Libra R-CNN [58]. It is also possible to make a two- stage object detector an anchor-free object detector, such as RepPoints [87]. As for one-stage object detector, the most representative models are YOLO [61, 62, 63], SSD [50], and RetinaNet [45]. In recent years, anchor-free one-stage object detectors are developed. The detectors of this sort are CenterNet [13], CornerNet [37, 38], FCOS [78], etc. Object detectors developed in recent years often insert some layers between backbone and head, and these layers are usually used to collect feature maps from different stages. We can call it the neck of an object detector. Usually, a neck is composed of several bottom-up paths and several topdown paths. Networks equipped with this mechanism include Feature Pyramid Network (FPN) [44], Path Aggregation Network (PAN) [49], BiFPN [77], and NAS-FPN [17]. \u2003\u73b0\u4ee3\u68c0\u6d4b\u5668\u901a\u5e38\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u4e00\u4e2a\u662f\u5728 ImageNet \u4e0a\u9884\u5148\u8bad\u7ec3\u7684\u9aa8\u5e72\u7f51\uff0c\u53e6\u4e00\u4e2a\u662f\u7528\u4e8e\u9884\u6d4b\u7269\u4f53\u7684\u7c7b\u548c\u8fb9\u754c\u6846\u7684\u5934\u90e8\u3002\u5bf9\u4e8e\u5728 GPU \u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u4e3b\u5e72\u53ef\u4ee5\u662f VGG [68]\u3001ResNet [26]\u3001ResNeXt [86]\u6216DenseNet [30]\u3002\u5bf9\u4e8e\u5728 CPU \u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u4e3b\u5e72\u53ef\u4ee5\u662fSqueezeNet [31], MobileNet [28, 66, 27, 74], \u6216 ShuffleNet [97, 53].\u3002\u81f3\u4e8e\u5934\u90e8\u90e8\u5206\uff0c\u901a\u5e38\u5206\u4e3a\u4e24\u7c7b \uff0c \u5373\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u548c\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668 \u3002\u6700\u5177\u4ee3\u8868\u6027\u7684\u4e24\u7ea7\u76ee\u6807\u68c0\u6d4b\u5668\u662fR-CNN[19]\u7cfb\u5217\uff0c\u5305\u62ecfast R-CNN [18], faster R-CNN [64], R-FCN [9], \u548c Libra R-CNN [58] \u3002\u4e5f\u53ef\u4ee5\u4f7f\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u6210\u4e3a\u65e0\u951a\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5982 RepPoints [87]\u3002\u81f3\u4e8e\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u6700\u5177\u4ee3\u8868\u6027\u7684\u578b\u53f7\u662fYOLO[61\u300162\u300163]\u3001SSD[50]\u548cRetinaNet[45]\u3002\u8fd1\u5e74\u6765\uff0c\u7814\u5236\u4e86\u65e0\u951a\u5f0f\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u3002\u6b64\u7c7b\u68c0\u6d4b\u5668\u6709 CenterNet [13]\u3001CornerNet [37\u3001 38]\u3001FCOS [78]\u7b49\u3002\u8fd1\u5e74\u6765\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u7814\u53d1\u901a\u5e38\u662f\u5728\u9aa8\u5e72\u548c\u5934\u90e8\u4e4b\u95f4\u7684\u6dfb\u52a0\u4e00\u4e9b\u5c42\uff0c\u8fd9\u4e9b\u5c42\u901a\u5e38\u7528\u4e8e\u6536\u96c6\u4e0d\u540c\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u3002\u6211\u4eec\u53ef\u4ee5\u79f0\u5b83\u4e3a\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u8116\u5b50\u3002\u901a\u5e38\uff0c\u9888\u90e8\u7531\u51e0\u4e2a\u81ea\u4e0b\u800c\u4e0a\u7684\u8def\u5f84\u548c\u51e0\u4e2a\u81ea\u4e0a\u800c\u4e0b\u7684\u8def\u5f84\u7ec4\u6210\u3002\u914d\u5907\u6b64\u673a\u5236\u7684\u7f51\u7edc\u5305\u62ec\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc \uff08FPN\uff09 [44]\u3001\u8def\u5f84\u805a\u5408\u7f51\u7edc \uff08PAN\uff09 [49]\u3001BiFPN [77]\u548c NAS-FPN [17]\u3002 \u2003In addition to the above models, some researchers put their emphasis on directly building a new backbone (DetNet [43], DetNAS [7]) or a new whole model (SpineNet [12], HitDetector [20]) for object detection. \u2003\u9664\u4e86\u4e0a\u8ff0\u6a21\u578b\u5916\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u8fd8\u628a\u91cd\u70b9\u76f4\u63a5\u653e\u5728\u6784\u5efa\u4e00\u4e2a\u65b0\u7684\u4e3b\u5e72\uff08DetNet [43]\uff0cDetNAS [7]\uff09\u6216\u65b0\u7684\u5b8c\u6574\u6a21\u578b\uff08SpineNet [12]\uff0cHitDetector [20]\uff09\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u3002 \u2003To sum up, an ordinary object detector is composed of several parts: \u2003\u7efc\u4e0a\u6240\u8ff0\uff0c\u4e00\u4e2a\u666e\u901a\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u7531\u5982\u4e0b\u90e8\u5206\u7ec4\u6210\uff1a Input: Image, Patches, Image Pyramid Backbones: VGG16 [68], ResNet-50 [26], SpineNet [12], EfficientNet-B0/B7 [75], CSPResNeXt50 [81], CSPDarknet53 [81] Neck: Additional blocks: SPP [25], ASPP [5], RFB [47], SAM [85] Path-aggregation blocks: FPN [44], PAN [49], NAS-FPN [17], Fully-connected FPN, BiFPN [77], ASFF [48], SFAM [98] Heads: Dense Prediction (one-stage): RPN [64], SSD [50], YOLO [61], RetinaNet [45] (anchor based) CornerNet [37], CenterNet [13], MatrixNet [60], FCOS [78] (anchor free) Sparse Prediction (two-stage): Faster R-CNN [64], R-FCN [9], Mask R-CNN [23] (anchor based) RepPoints [87] (anchor free) 2.2. Bag of freebies \u2003Usually, a conventional object detector is trained offline. Therefore, researchers always like to take this advantage and develop better training methods which can make the object detector receive better accuracy without increasing the inference cost. We call these methods that only change the training strategy or only increase the training cost as \u201cbag of freebies.\u201d What is often adopted by object detection methods and meets the definition of bag of freebies is data augmentation. The purpose of data augmentation is to increase the variability of the input images, so that the designed object detection model has higher robustness to the images obtained from different environments. For examples, photometric distortions and geometric distortions are two commonly used data augmentation method and they definitely benefit the object detection task. In dealing with photometric distortion, we adjust the brightness, contrast, hue, saturation, and noise of an image. For geometric distortion, we add random scaling, cropping, flipping, and rotating. \u2003\u901a\u5e38\uff0c\u4f20\u7edf\u7684\u7269\u4f53\u68c0\u6d4b\u5668\u662f\u79bb\u7ebf\u8bad\u7ec3\u7684\u3002 \u56e0\u6b64\uff0c\u7814\u7a76\u4eba\u5458\u603b\u662f\u559c\u6b22\u5229\u7528\u8fd9\u4e00\u4f18\u52bf\uff0c\u5f00\u53d1\u66f4\u597d\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u76ee\u6807\u68c0\u6d4b\u5668\u5728\u4e0d\u589e\u52a0\u63a8\u7406\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u66f4\u597d\u7684\u51c6\u786e\u6027\u3002\u6211\u4eec\u5c06\u8fd9\u4e9b\u53ea\u4f1a\u6539\u53d8\u8bad\u7ec3\u7b56\u7565\u6216\u53ea\u4f1a\u589e\u52a0\u8bad\u7ec3\u6210\u672c\u7684\u65b9\u6cd5\u79f0\u4e3a \u201cbag of freebies\u201d\u3002\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u7ecf\u5e38\u91c7\u7528\u4e14\u7b26\u5408bag of freebies \u5b9a\u4e49\u7684\u662f\u6570\u636e\u589e\u5f3a\uff08data augmentation\uff09\u3002\u6570\u636e\u589e\u5f3a\u7684\u76ee\u7684\u662f\u589e\u52a0\u8f93\u5165\u56fe\u50cf\u7684\u53ef\u53d8\u6027\uff08variability\uff09\uff0c\u4f7f\u8bbe\u8ba1\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u5bf9\u4e0d\u540c\u73af\u5883\u4e0b\u83b7\u5f97\u7684\u56fe\u50cf\u5177\u6709\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002\u4f8b\u5982\uff0c\u5149\u5ea6\u5931\u771f\uff08photometric distortion\uff09\u548c\u51e0\u4f55\u5931\u771f\uff08geometric distortion\uff09\u662f\u4e24\u79cd\u5e38\u7528\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b83\u4eec\u7edd\u5bf9\u6709\u5229\u4e8e\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u3002\u5728\u5904\u7406\u5149\u5ea6\u5931\u771f\u65f6\uff0c\u6211\u4eec\u8c03\u6574\u56fe\u50cf\u7684\u4eae\u5ea6\uff08brightness\uff09\u3001\u5bf9\u6bd4\u5ea6\uff08contrast\uff09\u3001\u8272\u8c03\uff08hue\uff09\u3001\u9971\u548c\u5ea6\uff08saturation\uff09\u548c\u566a\u58f0\uff08noise\uff09\u3002 \u5bf9\u4e8e\u51e0\u4f55\u5931\u771f\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u968f\u673a\u7f29\u653e\uff08random scale\uff09\u3001\u88c1\u526a\uff08crop\uff09\u3001\u7ffb\u8f6c\uff08flip\uff09\u548c\u65cb\u8f6c\uff08rotate\uff09\u3002 \u2003The data augmentation methods mentioned above are all pixel-wise adjustments, and all original pixel information in the adjusted area is retained. In addition, some researchers engaged in data augmentation put their emphasis on sim- ulating object occlusion issues. They have achieved good results in image classification and object detection. For ex- ample, random erase [100] and CutOut [11] can randomly select the rectangle region in an image and fill in a random or complementary value of zero. As for hide-and-seek [69] and grid mask [6], they randomly or evenly select multiple rectangle regions in an image and replace them to all ze- ros. If similar concepts are applied to feature maps, there are DropOut [71], DropConnect [80], and DropBlock [16] methods. In addition, some researchers have proposed the methods of using multiple images together to perform data augmentation. For example, MixUp [92] uses two images to multiply and superimpose with different coefficient ra- tios, and then adjusts the label with these superimposed ra- tios. As for CutMix [91], it is to cover the cropped image to rectangle region of other images, and adjusts the label according to the size of the mix area. In addition to the above mentioned methods, style transfer GAN [15] is also used for data augmentation, and such usage can effectively reduce the texture bias learned by CNN. \u2003\u4e0a\u9762\u63d0\u5230\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u90fd\u662f\u9010\u50cf\u7d20\uff08pixel-wise\uff09\u8c03\u6574\u7684\uff0c\u5e76\u4e14\u4fdd\u7559\u4e86\u8c03\u6574\u533a\u57df\u5185\u7684\u6240\u6709\u539f\u59cb\u50cf\u7d20\u4fe1\u606f\u3002 \u6b64\u5916\uff0c\u4e00\u4e9b\u4ece\u4e8b\u6570\u636e\u589e\u5f3a\u7684\u7814\u7a76\u4eba\u5458\u5c06\u91cd\u70b9\u653e\u5728\u6a21\u62df\u5bf9\u8c61\u906e\u6321\uff08occlusion\uff09\u95ee\u9898\u4e0a\u3002\u4ed6\u4eec\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u76ee\u6807\u68c0\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u5f88\u597d\u7684\u6548\u679c\u3002 \u4f8b\u5982\uff0c\u968f\u673a\u64e6\u9664[100]\u548cCutOut[11]\u53ef\u4ee5\u968f\u673a\u9009\u62e9\u56fe\u50cf\u4e2d\u7684\u77e9\u5f62\u533a\u57df\u5e76\u586b\u5145\u968f\u673a\u503c\u6216\u4e92\u8865\u503c\u96f6\uff08complementary value of zero\uff09\u3002\u81f3\u4e8e\u6349\u8ff7\u85cf\uff08hide-and-seek\uff09 [69] \u548c\u7f51\u683c\u8499\u7248\uff08grid mask\uff09 [6]\uff0c\u5b83\u4eec\u968f\u673a\u6216\u5747\u5300\u5730\u9009\u62e9\u56fe\u50cf\u4e2d\u7684\u591a\u4e2a\u77e9\u5f62\u533a\u57df\u5e76\u5c06\u5b83\u4eec\u5168\u66ff\u6362\u4e3a\u96f6\u3002 \u5982\u679c\u5c06\u7c7b\u4f3c\u7684\u6982\u5ff5\u5e94\u7528\u4e8e\u7279\u5f81\u56fe\uff0c\u5219\u6709 DropOut [71]\u3001DropConnect [80] \u548c DropBlock [16] \u65b9\u6cd5\u3002 \u6b64\u5916\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u5c06\u591a\u4e2a\u56fe\u50cf\u4e00\u8d77\u4f7f\u7528\u6765\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u65b9\u6cd5\u3002 \u4f8b\u5982\uff0cMixUp [92] \u4f7f\u7528\u4e24\u5e45\u56fe\u50cf\u6765\u4f7f\u4e0d\u540c\u7684\u7cfb\u6570\u6bd4\u4f8b\uff08coefficient ratio\uff09\u76f8\u4e58\u53e0\u52a0\uff08superimpose\uff09\uff0c\u7136\u540e\u7528\u8fd9\u4e9b\u53e0\u52a0\u6bd4\u4f8b\u8c03\u6574\u6807\u7b7e\u3002\u81f3\u4e8eCutMix [91]\uff0c\u5c31\u662f\u5c06\u88c1\u526a\u540e\u7684\u56fe\u50cf\u8986\u76d6\u5230\u5176\u4ed6\u56fe\u50cf\u7684\u77e9\u5f62\u533a\u57df\uff0c\u5e76\u6839\u636e\u6df7\u5408\u533a\u57df\u7684\u5927\u5c0f\u8c03\u6574\u6807\u7b7e\u3002 \u9664\u4e86\u4e0a\u8ff0\u65b9\u6cd5\u5916\uff0c\u98ce\u683c\u8fc1\u79fb GAN [15] \u4e5f\u88ab\u7528\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u8fd9\u79cd\u7528\u6cd5\u53ef\u4ee5\u6709\u6548\u51cf\u5c11 CNN \u5b66\u4e60\u5230\u7684\u7eb9\u7406\uff08texture\uff09\u504f\u5dee\u3002 \u2003Different from the various approaches proposed above, some other bag of freebies methods are dedicated to solving the problem that the semantic distribution in the dataset may have bias. In dealing with the problem of semantic distribution bias, a very important issue is that there is a problem of data imbalance between different classes, and this problem is often solved by hard negative example mining [72] or online hard example mining [67] in two-stage object detector. But the example mining method is not applicable to one-stage object detector, because this kind of detector belongs to the dense prediction architecture. Therefore Lin et al. [45] proposed focal loss to deal with the problem of data imbalance existing between various classes. Another very important issue is that it is difficult to express the relationship of the degree of association between different categories with the one-hot hard representation. This representation scheme is often used when executing labeling. The label smoothing proposed in [73] is to convert hard label into soft label for training, which can make model more robust. In order to obtain a better soft label, Islam et al. [33] introduced the concept of knowledge distillation to design the label refinement network. \u2003\u4e0e\u4e0a\u9762\u63d0\u51fa\u7684\u5404\u79cd\u65b9\u6cd5\u4e0d\u540c\uff0c\u5176\u4ed6\u4e00\u4e9bbag of freebies\u65b9\u6cd5\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3\u6570\u636e\u96c6\u4e2d\u8bed\u4e49\u5206\u5e03\uff08semantic distribution\uff09\u53ef\u80fd\u5b58\u5728\u504f\u5dee\u7684\u95ee\u9898\u3002\u5728\u5904\u7406\u8bed\u4e49\u5206\u5e03\u504f\u5dee\u95ee\u9898\u65f6\uff0c\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u662f\u4e0d\u540c\u7c7b\u4e4b\u95f4\u5b58\u5728\u6570\u636e\u4e0d\u5e73\u8861\uff08data imbalance\uff09\u7684\u95ee\u9898\u3002 \u8fd9\u4e2a\u95ee\u9898\u901a\u5e38\u901a\u8fc7\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u4e2d\u7684\u786c\u53cd\u4f8b\u6316\u6398\uff08hard negative example mining\uff09[72]\u6216\u5728\u7ebf\u786c\u793a\u4f8b\u6316\u6398\uff08online hard example mining\uff09[67]\u6765\u89e3\u51b3\u3002 \u4f46\u662f\u793a\u4f8b\u6316\u6398\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u56e0\u4e3a\u8fd9\u79cd\u68c0\u6d4b\u5668\u5c5e\u4e8e\u5bc6\u96c6\u9884\u6d4b\u67b6\u6784\u3002\u56e0\u6b64 Lin \u7b49\u4eba [45] \u63d0\u51fa\u4e86focal loss \u6765\u5904\u7406\u5404\u4e2a\u7c7b\u4e4b\u95f4\u5b58\u5728\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002 \u53e6\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u662f\uff0c\u4f7f\u7528one-hot hard\u8868\u793a\u5f88\u96be\u8868\u8fbe\u4e0d\u540c\u7c7b\u522b\u4e4b\u95f4\u7684\u5173\u8054\u7a0b\u5ea6\u7684\u5173\u7cfb\u3002 \u8fd9\u79cd\u8868\u793a\u65b9\u6848\u5728\u8fdb\u884c\u6807\u6ce8\u65f6\u7ecf\u5e38\u4f7f\u7528\u3002[73]\u4e2d\u63d0\u51fa\u7684\u6807\u7b7e\u5e73\u6ed1\uff08label smoothing\uff09\u662f\u5c06\u786c\u6807\u7b7e\uff08hard label\uff09\u8f6c\u6362\u4e3a\u8f6f\u6807\u7b7e\uff08soft label\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u4ee5\u4f7f\u6a21\u578b\u66f4\u52a0\u9c81\u68d2\u3002 \u4e3a\u4e86\u83b7\u5f97\u66f4\u597d\u7684\u8f6f\u6807\u7b7e\uff0cIslam\u7b49[33]\u5f15\u5165\u4e86\u77e5\u8bc6\u84b8\u998f\uff08knowledge distillation\uff09\u7684\u6982\u5ff5\u6765\u8bbe\u8ba1\u6807\u7b7e\u7ec6\u5316\u7f51\u7edc\uff08label refinement network\uff09\u3002 \u2003The last bag of freebies is the objective function of Bounding Box (BBox) regression. The traditional object detector usually uses Mean Square Error (MSE) to directly perform regression on the center point coordinates and height and width of the BBox, i.e., \\({x_{center}, y_{center}, w, h}\\) , or the upper left point and the lower right point, i.e., \\({x_{top-left}, y_{top-left}, x_{bottom-right}, y_{bottom-right} }\\) . As for anchor-based method, it is to estimate the corresponding offset, for example \\({x_{center-offset}, y_{center-offset},w_{offset}, h_{offset}}\\) and \\({x_{top-left-offset}, y_{top-left-offset},x_{bottom-right-offset}, y_{bottom-right-offset}}\\) . However, to directly estimate the coordinate values of each point of the BBox is to treat these points as independent variables, but in fact does not consider the integrity of the object itself. In order to make this issue processed better, some researchers recently proposed IoU loss [90], which puts the coverage of predicted BBox area and ground truth BBox area into consideration. The IoU loss computing process will trigger the calculation of the four coordinate points of the BBox by executing IoU with the ground truth, and then connecting the generated results into a whole code. Because IoU is a scale invariant representation, it can solve the problem that when traditional methods calculate the \\(l_1\\) or \\(l_2\\) loss of \\({x, y, w,h}\\) , the loss will increase with the scale. Recently, some researchers have continued to improve IoU loss. For example, GIoU loss [65] is to include the shape and orientation of object in addition to the coverage area. They proposed to find the smallest area BBox that can simultaneously cover the predicted BBox and ground truth BBox, and use this BBox as the denominator to replace the denominator originally used in IoU loss. As for DIoU loss [99], it additionally considers the distance of the center of an object, and CIoU loss [99], on the other hand simultaneously considers the overlapping area, the distance between center points, and the aspect ratio. CIoU can achieve better convergence speed and accuracy on the BBox regression problem. \u2003\u6700\u540e\u4e00\u4e9b bag of freebies \u662f\u8fb9\u754c\u6846 (BBox) \u56de\u5f52\u7684\u76ee\u6807\u51fd\u6570\u3002 \u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u901a\u5e38\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u76f4\u63a5\u5bf9BBox\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u8fdb\u884c\u56de\u5f52\uff0c\u5373 \\({x_{center}, y_{center},w, h}\\) \uff0c\u6216\u5de6\u4e0a\u70b9\u548c\u53f3\u4e0b\u70b9\uff0c\u5373 \\({x_{top-left}, y_{top-left}, x_{bottom-right}, y_{bottom-right} }\\) \u3002\u5bf9\u4e8eanchor-based\u65b9\u6cd5\uff0c\u5c31\u662f\u4f30\u8ba1\u5bf9\u5e94\u7684offset\uff0c\u4f8b\u5982 \\({x_{center-offset}, y_{center-offset},w_{offset}, h_{offset}}\\) \u548c \\({x_{top-left-offset}, y_{top-left-offset},x_{bottom-right-offset}, y_{bottom-right-offset}}\\) \u3002\u4f46\u662f\uff0c\u76f4\u63a5\u4f30\u8ba1BBox\u6bcf\u4e2a\u70b9\u7684\u5750\u6807\u503c\uff0c\u5c31\u662f\u628a\u8fd9\u4e9b\u70b9\u5f53\u6210\u81ea\u53d8\u91cf\uff08independent variable\uff09\uff0c\u5b9e\u9645\u4e0a\u5e76\u6ca1\u6709\u8003\u8651\u5bf9\u8c61\u672c\u8eab\u7684\u5b8c\u6574\u6027\u3002 \u4e3a\u4e86\u66f4\u597d\u5730\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff0c\u6700\u8fd1\u6709\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86 IoU loss [90]\uff0c\u5b83\u8003\u8651\u4e86\u9884\u6d4b BBox \u533a\u57df\u548c\u771f\u5b9eBBox \u533a\u57df\u7684\u8986\u76d6\u8303\u56f4\u3002IoU \u635f\u5931\u8ba1\u7b97\u8fc7\u7a0b\u901a\u8fc7\u4f7f\u7528\u771f\u5b9e\u503c\u8ba1\u7b97IoU \u6765\u89e6\u53d1BBox \u56db\u4e2a\u5750\u6807\u70b9\u7684\u8ba1\u7b97\uff0c\u7136\u540e\u5c06\u751f\u6210\u7684\u7ed3\u679c\u8fde\u63a5\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u4ee3\u7801\u3002\u7531\u4e8eIoU\u662f\u6bd4\u4f8b\u4e0d\u53d8\u7684\u8868\u793a\uff0c\u53ef\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97 \\({x,y,w,h}\\) \u7684 \\(l_1\\) \u6216 \\(l_2\\) \u635f\u5931\u65f6\uff0c\u635f\u5931\u4f1a\u968f\u7740\u6bd4\u4f8b\u589e\u52a0\u7684\u95ee\u9898\u3002\u6700\u8fd1\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u7ee7\u7eed\u6539\u8fdb IoU \u635f\u5931\u3002\u4f8b\u5982\uff0cGIoU loss[65]\u9664\u4e86\u8986\u76d6\u533a\u57df\u5916\uff0c\u8fd8\u5305\u62ec\u7269\u4f53\u7684\u5f62\u72b6\u548c\u65b9\u5411\uff08orientation\uff09\u3002\u4ed6\u4eec\u63d0\u51fa\u5bfb\u627e\u53ef\u540c\u65f6\u8986\u76d6\u9884\u6d4bBBox\u548c\u771f\u5b9eBBox\u7684\u6700\u5c0f\u9762\u79efBBox\uff0c\u5e76\u7528\u8fd9\u4e2aBBox\u4f5c\u4e3a\u5206\u6bcd\uff08denominator\uff09\u6765\u4ee3\u66ff\u539f\u6765\u5728IoU loss\u4e2d\u4f7f\u7528\u7684\u5206\u6bcd\u3002\u81f3\u4e8eDIoU loss [99]\uff0c\u5b83\u989d\u5916\u8003\u8651\u4e86\u7269\u4f53\u4e2d\u5fc3\u7684\u8ddd\u79bb\uff0c\u800cCIoU loss [99]\uff0c\u53e6\u4e00\u65b9\u9762\u540c\u65f6\u8003\u8651\u4e86\u91cd\u53e0\u533a\u57df\u3001\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u548c\u5bbd\u9ad8\u6bd4\u3002CIoU \u5728 BBox \u56de\u5f52\u95ee\u9898\u4e0a\u53ef\u4ee5\u8fbe\u5230\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u7cbe\u5ea6\u3002 2.3. Bag of specials \u2003For those plugin modules and post-processing methods that only increase the inference cost by a small amount but can significantly improve the accuracy of object detection, we call them \u201cbag of specials\u201d. Generally speaking, these plugin modules are for enhancing certain attributes in a model, such as enlarging receptive field, introducing attention mechanism, or strengthening feature integration capability, etc., and post-processing is a method for screening model prediction results. \u2003\u5bf9\u4e8e\u90a3\u4e9b\u53ea\u589e\u52a0\u5c11\u91cf\u63a8\u7406\u6210\u672c\u4f46\u53ef\u4ee5\u663e\u7740\u63d0\u9ad8\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u7684\u63d2\u4ef6\u6a21\u5757\uff08plugin module\uff09\u548c\u540e\u5904\u7406\uff08post-processing\uff09\u65b9\u6cd5\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a\u201cbag of specials\u201d\u3002 \u4e00\u822c\u6765\u8bf4\uff0c\u8fd9\u4e9b\u63d2\u4ef6\u6a21\u5757\u662f\u4e3a\u4e86\u589e\u5f3a\u6a21\u578b\u4e2d\u7684\u67d0\u4e9b\u5c5e\u6027\uff08attribute\uff09\uff0c\u6bd4\u5982\u6269\u5927\u611f\u53d7\u91ce\uff08receptive field\uff09\u3001\u5f15\u5165\u6ce8\u610f\u529b\u673a\u5236\uff08attention mechanism\uff09\u3001\u6216\u8005\u52a0\u5f3a\u7279\u5f81\u6574\u5408\uff08integration\uff09\u80fd\u529b\u7b49\uff0c\u540e\u5904\u7406\u662f\u4e00\u79cd\u7b5b\u9009\uff08screen\uff09\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u65b9\u6cd5\u3002 \u2003Common modules that can be used to enhance receptive field are SPP [25], ASPP [5], and RFB [47]. The SPP module was originated from Spatial Pyramid Matching (SPM) [39], and SPMs original method was to split feature map into several d \u00d7 d equal blocks, where d can be \\({1, 2, 3, ...}\\) , thus forming spatial pyramid, and then extracting bag-of-word features. SPP integrates SPM into CNN and use max-pooling operation instead of bag-of-word operation. Since the SPP module proposed by He et al. [25] will output one dimensional feature vector, it is infeasible to be applied in Fully Convolutional Network (FCN). Thus in the design of YOLOv3 [63], Redmon and Farhadi improve SPP module to the concatenation of max-pooling outputs with kernel size \\(k \u00d7 k\\) , where \\(k = {1, 5, 9, 13}\\) , and stride equals to 1. Under this design, a relatively large k \u00d7 k maxpooling effectively increase the receptive field of backbone feature. After adding the improved version of SPP module, YOLOv3-608 upgrades AP50 by 2.7% on the MS COCO object detection task at the cost of 0.5% extra computation. The difference in operation between ASPP [5] module and improved SPP module is mainly from the original k\u00d7k kernel size, max-pooling of stride equals to 1 to several \\(3 \u00d7 3\\) kernel size, dilated ratio equals to k, and stride equals to 1 in dilated convolution operation. RFB module is to use several dilated convolutions of k\u00d7k kernel, dilated ratio equals to k, and stride equals to 1 to obtain a more comprehensive spatial coverage than ASPP . RFB [47] only costs 7% extra inference time to increase the AP50 of SSD on MS COCO by 5.7%. \u2003\u53ef\u7528\u4e8e\u589e\u5f3a\u611f\u53d7\u91ce\u7684\u5e38\u89c1\u6a21\u5757\u6709 SPP [25]\u3001ASPP [5] \u548c RFB [47]\u3002SPP\u6a21\u5757\u8d77\u6e90\u4e8eSpatial Pyramid Matching\uff08SPM\uff09[39]\uff0cSPM\u7684\u539f\u59cb\u65b9\u6cd5\u662f\u5c06\u7279\u5f81\u56fe\u5206\u5272\u6210\u51e0\u4e2a \\(d \u00d7 d\\) \u76f8\u7b49\u7684\u5757\uff0c\u5176\u4e2d \\(d\\) \u53ef\u4ee5\u662f \\({1, 2, 3, ...}\\) \uff0c\u56e0\u6b64\u5f62\u6210\u7a7a\u95f4\u91d1\u5b57\u5854\uff0c\u7136\u540e\u63d0\u53d6\u8bcd\u888b\uff08bag-of-word\uff09\u7279\u5f81\u3002SPP \u5c06 SPM \u96c6\u6210\u5230 CNN \u4e2d\u5e76\u4f7f\u7528\u6700\u5927\u6c60\u5316\u64cd\u4f5c\u800c\u4e0d\u662f\u8bcd\u888b\u64cd\u4f5c\u3002\u7531\u4e8eHe\u7b49\u4eba[25]\u63d0\u51fa\u7684SPP\u6a21\u5757\u4f1a\u8f93\u51fa\u4e00\u7ef4\u7279\u5f81\u5411\u91cf\uff0c\u56e0\u6b64\u4e0d\u9002\u7528\u4e8e\u5168\u5377\u79ef\u7f51\u7edc\uff08FCN\uff09\u3002\u56e0\u6b64\uff0c\u5728 YOLOv3 [63] \u7684\u8bbe\u8ba1\u4e2d\uff0cRedmon \u548c Farhadi \u5c06 SPP \u6a21\u5757\u6539\u8fdb\u4e3a \u5185\u6838\u5927\u5c0f\u4e3a \\(k \u00d7 k\\) \u7684\u6700\u5927\u6c60\u5316\u8f93\u51fa\u7684\u4e32\u8054\uff0c\u5176\u4e2d \\(k = {1, 5, 9, 13}\\) \uff0c\u6b65\u5e45\u7b49\u4e8e 1\u3002 \u5728\u8fd9\u79cd\u8bbe\u8ba1\u4e0b\uff0c\u76f8\u5bf9\u8f83\u5927\u7684 \\(k \u00d7 k\\) \u6700\u5927\u6c60\u5316\u6709\u6548\u5730\u589e\u52a0\u4e86\u4e3b\u5e72\uff08backbone\uff09\u7279\u5f81\u7684\u611f\u53d7\u91ce\u3002\u6dfb\u52a0\u6539\u8fdb\u7248SPP\u6a21\u5757\u540e\uff0cYOLOv3-608\u5728MS COCO\u7269\u4f53\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4ee50.5%\u7684\u989d\u5916\u8ba1\u7b97\u4e3a\u4ee3\u4ef7\u5c06AP50\u63d0\u5347\u4e862.7%\u3002ASPP [5] \u6a21\u5757\u548c\u6539\u8fdb\u7684 SPP \u6a21\u5757\u5728\u64cd\u4f5c\u4e0a\u7684\u533a\u522b\u4e3b\u8981\u662f\u539f\u59cb\u7684 \\(k\u00d7k\\) \u6838\u5927\u5c0f\uff0c\u6700\u5927\u6c60\u5316\u7684\u6b65\u5e45\u7b49\u4e8e1 \u5230\u51e0\u4e2a \\(3\u00d73\\) \u6838\u5927\u5c0f\uff0c\u6269\u5f20\u6bd4\uff08dilated ratio\uff09\u7b49\u4e8e k\uff0c\u5728\u6269\u5f20\u5377\u79ef\uff08dilated convolution\uff09\u64cd\u4f5c\u4e2d\u6b65\u5e45\u7b49\u4e8e 1\u3002RFB\u6a21\u5757\u662f\u4f7f\u7528\u51e0\u4e2ak\u00d7k\u6838\u7684\u6269\u5f20\u5377\u79ef\uff0c\u6269\u5f20\u6bd4\u7b49\u4e8ek\uff0c\u6b65\u5e45\u7b49\u4e8e1\uff0c\u4ee5\u83b7\u5f97\u6bd4ASPP\u66f4\u5168\u9762\u7684\u7a7a\u95f4\u8986\u76d6\u3002RFB [47] \u4ec5\u82b1\u8d39 7% \u7684\u989d\u5916\u63a8\u7406\u65f6\u95f4\u5373\u53ef\u5bf9 MS COCO \u4e0a SSD \u7684 AP50 \u63d0\u9ad8 5.7%\u3002 \u2003The attention module that is often used in object detection is mainly divided into channel-wise attention and point-wise attention, and the representatives of these two attention models are Squeeze-and-Excitation (SE) [29] and Spatial Attention Module (SAM) [85], respectively. Although SE module can improve the power of ResNet50 in the ImageNet image classification task 1% top-1 accuracy at the cost of only increasing the computational effort by 2%, but on a GPU usually it will increase the inference time by about 10%, so it is more appropriate to be used in mobile devices. But for SAM, it only needs to pay 0.1% extra calculation and it can improve ResNet50-SE 0.5% top-1 accuracy on the ImageNet image classification task. Best of all, it does not affect the speed of inference on the GPU at all. \u2003\u76ee\u6807\u68c0\u6d4b\u4e2d\u7ecf\u5e38\u4f7f\u7528\u7684\u6ce8\u610f\u529b\u6a21\u5757\uff08attention module\uff09\u4e3b\u8981\u5206\u4e3a\u9010\u901a\u9053\u6ce8\u610f\u529b\uff08channel-wise attention\uff09\u548c\u9010\u70b9\u6ce8\u610f\u529b\uff08point-wise attention\uff09\uff0c\u8fd9\u4e24\u79cd\u6ce8\u610f\u529b\u6a21\u578b\u7684\u4ee3\u8868\u5206\u522b\u662fSqueeze-and-Excitation\uff08SE\uff09[29]\u548cSpatial Attention Module\uff08SAM\uff09[85]\u3002\u867d\u7136 SE \u6a21\u5757\u53ef\u4ee5\u5c06 ResNet50 \u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u63d0\u9ad8 1% \\(top-1\\) \u51c6\u786e\u7387\uff0c\u4ee3\u4ef7\u662f\u53ea\u589e\u52a0 2% \u7684\u8ba1\u7b97\u91cf\uff0c\u4f46\u5728 GPU \u4e0a\u901a\u5e38\u4f1a\u589e\u52a0\u5927\u7ea6 10% \u7684\u63a8\u7406\u65f6\u95f4\uff0c \u6240\u4ee5\u66f4\u9002\u5408\u7528\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u3002\u4f46\u5bf9\u4e8e SAM \u6765\u8bf4\uff0c\u5b83\u53ea\u9700\u8981\u989d\u5916\u4ed8\u51fa 0.1% \u7684\u8ba1\u7b97\uff0c\u5c31\u53ef\u4ee5\u5c06 ResNet50-SE \u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684 \\(top-1\\) \u51c6\u786e\u7387\u63d0\u9ad8 0.5%\u3002 \u6700\u91cd\u8981\u7684\u662f\uff0c\u5b83\u4e0d\u4f1a\u5f71\u54cd GPU \u4e0a\u7684\u63a8\u7406\u901f\u5ea6\u3002 \u2003In terms of feature integration, the early practice is to use skip connection [51] or hyper-column [22] to integrate low- level physical feature to high-level semantic feature. Since multi-scale prediction methods such as FPN have become popular, many lightweight modules that integrate different feature pyramid have been proposed. The modules of this sort include SFAM [98], ASFF [48], and BiFPN [77]. The main idea of SFAM is to use SE module to execute channel- wise level re-weighting on multi-scale concatenated feature maps. As for ASFF, it uses softmax as point-wise level re- weighting and then adds feature maps of different scales. In BiFPN, the multi-input weighted residual connections is proposed to execute scale-wise level re-weighting, and then add feature maps of different scales. \u2003\u5728\u7279\u5f81\u6574\u5408\uff08feature integration\uff09\u65b9\u9762\uff0c\u65e9\u671f\u7684\u505a\u6cd5\u662f\u4f7f\u7528\u8df3\u8fc7\u8fde\u63a5\uff08skip connection\uff09[51]\u6216\u8d85\u5217\uff08hyper-column\uff09[22]\u5c06\u4f4e\u7ea7\u7269\u7406\u7279\u5f81\u6574\u5408\u5230\u9ad8\u7ea7\u8bed\u4e49\u7279\u5f81\uff08semantic feature\uff09\u3002 \u968f\u7740FPN\u7b49\u591a\u6bd4\u4f8b\uff08multi-scale\uff09\u9884\u6d4b\u65b9\u6cd5\u7684\u6d41\u884c\uff0c\u8bb8\u591a\u96c6\u6210\u4e0d\u540c\u7279\u5f81\u91d1\u5b57\u5854\u7684\u8f7b\u91cf\u7ea7\u6a21\u5757\u88ab\u63d0\u51fa\u3002 \u8fd9\u7c7b\u6a21\u5757\u5305\u62ec SFAM [98]\u3001ASFF [48] \u548c BiFPN [77]\u3002 SFAM \u7684\u4e3b\u8981\u601d\u60f3\u662f\u4f7f\u7528 SE \u6a21\u5757\u5728\u591a\u6bd4\u4f8b\u7ea7\u8054\uff08multi-scale concatenated\uff09\u7279\u5f81\u56fe\u4e0a\u6267\u884c\u9010\u901a\u9053\u6c34\u5e73\u7684\u91cd\u65b0\u52a0\u6743\uff08channel-wise level re-weighting\uff09\u3002 \u81f3\u4e8eASFF\uff0c\u5b83\u4f7f\u7528softmax\u4f5c\u4e3a\u9010\u70b9\u7ea7\u91cd\u52a0\u6743\uff08point-wise level re-weighting\uff09\uff0c\u7136\u540e\u6dfb\u52a0\u4e0d\u540c\u6bd4\u4f8b\u7684\u7279\u5f81\u56fe\u3002 \u5728 BiFPN \u4e2d\uff0c\u63d0\u51fa\u4e86\u4f7f\u7528\u591a\u8f93\u5165\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\uff08multi-input weighted residual connections\uff09\u6765\u6267\u884c\u6309\u5c3a\u5ea6\u7ea7\u522b\u91cd\u65b0\u52a0\u6743\uff08scale-wise level re-weighting\uff09\uff0c\u7136\u540e\u6dfb\u52a0\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u3002 \u2003In the research of deep learning, some people put their focus on searching for good activation function. A good activation function can make the gradient more efficiently propagated, and at the same time it will not cause too much extra computational cost. In 2010, Nair and Hin- ton [56] propose ReLU to substantially solve the gradient vanish problem which is frequently encountered in tradi- tional tanh and sigmoid activation function. Subsequently, LReLU [54], PReLU [24], ReLU6 [28], Scaled Exponential Linear Unit (SELU) [35], Swish [59], hard-Swish [27], and Mish [55], etc., which are also used to solve the gradient vanish problem, have been proposed. The main purpose of LReLU and PReLU is to solve the problem that the gradi- ent of ReLU is zero when the output is less than zero. As for ReLU6 and hard-Swish, they are specially designed for quantization networks. For self-normalizing a neural net- work, the SELU activation function is proposed to satisfy the goal. One thing to be noted is that both Swish and Mish are continuously differentiable activation function. \u2003\u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\u4e2d\uff0c\u6709\u4eba\u628a\u91cd\u70b9\u653e\u5728\u5bfb\u627e\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u4e0a\u3002\u4e00\u4e2a\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u53ef\u4ee5\u8ba9\u68af\u5ea6\u66f4\u6709\u6548\u5730\u4f20\u64ad\uff0c\u540c\u65f6\u4e0d\u4f1a\u9020\u6210\u592a\u591a\u989d\u5916\u7684\u8ba1\u7b97\u6210\u672c\u30022010 \u5e74\uff0cNair \u548c Hinton [56] \u63d0\u51fa ReLU \u6765\u5b9e\u8d28\u6027\u5730\u89e3\u51b3\u4f20\u7edf tanh \u548c sigmoid \u6fc0\u6d3b\u51fd\u6570\u4e2d\u7ecf\u5e38\u9047\u5230\u7684\u68af\u5ea6\u6d88\u5931\uff08gradient vanish\uff09\u95ee\u9898\u3002\u968f\u540e\uff0cLReLU [54]\u3001PReLU [24]\u3001ReLU6 [28]\u3001Scaled Exponential Linear Unit (SELU) [35]\u3001Swish [59]\u3001hard-Swish [27] \u548c Mish [55] \u7b49\u88ab\u63d0\u51fa\uff0c\u4e5f\u7528\u4e8e\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002LReLU\u548cPReLU\u7684\u4e3b\u8981\u76ee\u7684\u662f\u89e3\u51b3\u8f93\u51fa\u5c0f\u4e8e\u96f6\u65f6ReLU\u68af\u5ea6\u4e3a\u96f6\u7684\u95ee\u9898\u3002\u81f3\u4e8e ReLU6 \u548c hard-Swish\uff0c\u5b83\u4eec\u662f\u4e13\u95e8\u4e3a\u91cf\u5316\uff08quantization\uff09\u7f51\u7edc\u8bbe\u8ba1\u7684\u3002\u4e3a\u4e86\u81ea\u5f52\u4e00\u5316\uff08self-normalize\uff09\u795e\u7ecf\u7f51\u7edc\uff0cSELU \u6fc0\u6d3b\u51fd\u6570\u88ab\u63d0\u51fa\u4ee5\u5b9e\u73b0\u8be5\u76ee\u6807\u3002\u9700\u8981\u6ce8\u610f\u7684\u4e00\u4ef6\u4e8b\u662f Swish \u548c Mish \u90fd\u662f\u8fde\u7eed\u53ef\u5fae\uff08continuously differentiable\uff09\u7684\u6fc0\u6d3b\u51fd\u6570\u3002 \u2003The post-processing method commonly used in deep- learning-based object detection is NMS, which can be used to filter those BBoxes that badly predict the same ob- ject, and only retain the candidate BBoxes with higher re- sponse. The way NMS tries to improve is consistent with the method of optimizing an objective function. The orig- inal method proposed by NMS does not consider the con- text information, so Girshick et al. [19] added classification confidence score in R-CNN as a reference, and according to the order of confidence score, greedy NMS was performed in the order of high score to low score. As for soft NMS [1], it considers the problem that the occlusion of an object may cause the degradation of confidence score in greedy NMS with IoU score. The DIoU NMS [99] developers way of thinking is to add the information of the center point dis- tance to the BBox screening process on the basis of soft NMS. It is worth mentioning that, since none of above post- processing methods directly refer to the captured image fea- tures, post-processing is no longer required in the subse- quent development of an anchor-free method. \u2003\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7269\u4f53\u68c0\u6d4b\u5e38\u7528\u7684\u540e\u5904\u7406\uff08post-processing\uff09\u65b9\u6cd5\u662fNMS\uff0c\u5b83\u53ef\u4ee5\u7528\u6765\u8fc7\u6ee4\u90a3\u4e9b\u5bf9\u540c\u4e00\u7269\u4f53\u9884\u6d4b\u4e0d\u597d\u7684BBox\uff0c\u53ea\u4fdd\u7559\u54cd\u5e94\u8f83\u9ad8\u7684\u5019\u9009BBox\u3002NMS \u5c1d\u8bd5\u6539\u8fdb\u7684\u65b9\u5f0f\u4e0e\u4f18\u5316\u76ee\u6807\u51fd\u6570\u7684\u65b9\u6cd5\u4e00\u81f4\u3002 NMS \u63d0\u51fa\u7684\u539f\u59cb\u65b9\u6cd5\u6ca1\u6709\u8003\u8651\u4e0a\u4e0b\u6587\uff08context\uff09\u4fe1\u606f\uff0c\u56e0\u6b64 Girshick \u7b49\u4eba [19] \u5728 R-CNN \u4e2d\u6dfb\u52a0\u4e86\u5206\u7c7b\u7f6e\u4fe1\u5ea6\uff08classification confidence score\uff09\u5206\u6570\u4f5c\u4e3a\u53c2\u8003\uff0c\u5e76\u6309\u7167\u7f6e\u4fe1\u5ea6\u5f97\u5206\u7684\u987a\u5e8f\uff0c\u4ece\u9ad8\u5206\u5230\u4f4e\u5206\u7684\u987a\u5e8f\u8fdb\u884c\u8d2a\u5a6a\uff08greedy\uff09NMS\u3002\u5bf9\u4e8e soft NMS [1]\uff0c\u5b83\u8003\u8651\u4e86\u5728\u5177\u6709 IoU \u5206\u6570\u7684 greedy NMS \u4e2d\u5bf9\u8c61\u7684\u906e\u6321\uff08occlusion\uff09\u53ef\u80fd\u5bfc\u81f4\u7f6e\u4fe1\u5ea6\u4e0b\u964d\u7684\u95ee\u9898\u3002 DIoU NMS [99] \u5f00\u53d1\u8005\u7684\u601d\u8def\u662f\u5728\u8f6f NMS \u7684\u57fa\u7840\u4e0a\uff0c\u5728 BBox \u7b5b\u9009\uff08screen\uff09\u8fc7\u7a0b\u4e2d\u52a0\u5165\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u4fe1\u606f\u3002 \u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u7531\u4e8e\u4e0a\u8ff0\u540e\u5904\u7406\u65b9\u6cd5\u90fd\u6ca1\u6709\u76f4\u63a5\u53c2\u8003\u6355\u83b7\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u56e0\u6b64\u5728\u540e\u7eed\u5f00\u53d1anchor-free\u65b9\u6cd5\u65f6\u4e0d\u518d\u9700\u8981\u8fdb\u884c\u540e\u5904\u7406\u3002 3. Methodology \u65b9\u6cd5\u8bba \u2003The basic aim is fast operating speed of neural network, in production systems and optimization for parallel compu- tations, rather than the low computation volume theoreti- cal indicator (BFLOP). We present two options of real-time neural networks: \u2003\u57fa\u672c\u76ee\u6807\u662f\u795e\u7ecf\u7f51\u7edc\u5728\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u5feb\u901f\u8fd0\u884c\u548c\u5e76\u884c\u8ba1\u7b97\uff08parallel computation\uff09\u7684\u4f18\u5316\uff0c\u800c\u4e0d\u662f\u4f4e\u8ba1\u7b97\u91cf\u7406\u8bba\u6307\u6807\uff08low computation volume theoretical indicator\uff09\uff08BFLOP\uff09\u3002 \u6211\u4eec\u63d0\u4f9b\u4e86\u4e24\u79cd\u5b9e\u65f6\u795e\u7ecf\u7f51\u7edc\u9009\u9879\uff1a For GPU we use a small number of groups (1 - 8) in convolutional layers: CSPResNeXt50 / CSPDarknet53 \u5bf9\u4e8e GPU\uff0c\u6211\u4eec\u5728\u5377\u79ef\u5c42\u4e2d\u4f7f\u7528\u5c11\u91cf\u7ec4 (1 - 8)\uff1aCSPResNeXt50 / CSPDarknet53 For VPU - we use grouped-convolution, but we refrain from using Squeeze-and-excitement (SE) blocks specifically this includes the following models: EfficientNet-lite / MixNet [76] / GhostNet [21] / Mo-bileNetV3 \u5bf9\u4e8e VPU - \u6211\u4eec\u4f7f\u7528\u5206\u7ec4\u5377\u79ef\uff0c\u4f46\u6211\u4eec\u907f\u514d\u4f7f\u7528 Squeeze-and-excitement (SE) \u5757 , - \u5177\u4f53\u5305\u62ec\u6a21\u578b\uff1aEfficientNet-lite / MixNet [76] / GhostNet [21] / MobileNetV3 3.1. Selection of architecture \u67b6\u6784\u9009\u62e9 \u2003Our objective is to find the optimal balance among the in- put network resolution, the convolutional layer number, the parameter number \\((filter size^2 * filters * channel / groups)\\) , and the number of layer outputs (filters). For instance, our numerous studies demonstrate that the CSPResNext50 is considerably better compared to CSPDarknet53 in terms of object classification on the ILSVRC2012 (ImageNet) dataset [10]. However, conversely, the CSPDarknet53 is better compared to CSPResNext50 in terms of detecting ob- jects on the MS COCO dataset [46]. \u2003\u6211\u4eec\u7684\u76ee\u6807\u662f\u5728\u8f93\u5165\u7f51\u7edc\u5206\u8fa8\u7387\u3001\u5377\u79ef\u5c42\u6570\u3001\u53c2\u6570\u6570\u91cf \\((filter size^2 * filters * channel / groups)\\) \u548c\u5c42\u8f93\u51fa\u6570\uff08\u8fc7\u6ee4\u5668\uff09\u4e4b\u95f4\u627e\u5230\u6700\u4f73\u5e73\u8861\u3002 \u4f8b\u5982\uff0c\u6211\u4eec\u7684\u5927\u91cf\u7814\u7a76\u8868\u660e\uff0c\u5728 ILSVRC2012 (ImageNet) \u6570\u636e\u96c6 [10] \u4e0a\u7684\u5bf9\u8c61\u5206\u7c7b\u65b9\u9762\uff0cCSPResNext50 \u4e0e CSPDarknet53 \u76f8\u6bd4\u8981\u597d\u5f97\u591a\u3002 \u7136\u800c\uff0c\u76f8\u53cd\uff0c\u5728 MS COCO \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0cCSPDarknet53 \u6bd4 CSPResNext50 \u66f4\u597d [46]\u3002 \u2003The next objective is to select additional blocks for increasing the receptive field and the best method of parameter aggregation from different backbone levels for different detector levels: e.g. FPN, PAN, ASFF, BiFPN. \u2003\u4e0b\u4e00\u4e2a\u76ee\u6807\u662f\u9009\u62e9\u989d\u5916\u7684\u5757\u6765\u589e\u52a0\u611f\u53d7\u91ce\uff0c\u4ee5\u53ca\u4ece\u4e0d\u540c\u7684\u4e3b\u5e72\u7ea7\u522b\u4e3a\u4e0d\u540c\u7684\u68c0\u6d4b\u5668\u7ea7\u522b\u9009\u62e9\u53c2\u6570\u805a\u5408\uff08parameter aggregation\uff09\u7684\u6700\u4f73\u65b9\u6cd5\uff1a\u4f8b\u5982 FPN\u3001PAN\u3001ASFF\u3001BiFPN\u3002 \u2003A reference model which is optimal for classification is not always optimal for a detector. In contrast to the classifier, the detector requires the following: \u2003\u5bf9\u4e8e\u5206\u7c7b\u800c\u8a00\u6700\u4f73\u7684\u53c2\u8003\u6a21\u578b\u5bf9\u4e8e\u68c0\u6d4b\u5668\u800c\u8a00\u5e76\u4e0d\u603b\u662f\u6700\u4f73\u7684\u3002 \u4e0e\u5206\u7c7b\u5668\u76f8\u6bd4\uff0c\u68c0\u6d4b\u5668\u9700\u8981\u4ee5\u4e0b\u5185\u5bb9\uff1a Higher input network size (resolution) \u2013 for detecting multiple small-sized objects \u66f4\u9ad8\u7684\u8f93\u5165\u7f51\u7edc\u5c3a\u5bf8\uff08\u5206\u8fa8\u7387\uff09\u2014\u2014 \u7528\u4e8e\u68c0\u6d4b\u591a\u4e2a\u5c0f\u5c3a\u5bf8\u7269\u4f53 More layers \u2013 for a higher receptive field to cover the increased size of input network \u66f4\u591a\u5c42\u2014\u2014\u7528\u4e8e\u66f4\u9ad8\u7684\u611f\u53d7\u91ce\u4ee5\u8986\u76d6\u589e\u52a0\u7684\u8f93\u5165\u7f51\u7edc\u5927\u5c0f More parameters \u2013 for greater capacity of a model to detect multiple objects of different sizes in a single im- age \u66f4\u591a\u53c2\u6570\u2014\u2014\u4f7f\u6a21\u578b\u6709\u66f4\u5927\u7684\u80fd\u529b\u5728\u5355\u4e2a\u56fe\u50cf\u4e2d\u68c0\u6d4b\u591a\u4e2a\u4e0d\u540c\u5927\u5c0f\u7684\u5bf9\u8c61 \\(\\text { \u8868 1: \u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u3002 }\\) \u2003Hypothetically speaking, we can assume that a model with a larger receptive field size (with a larger number of convolutional layers \\(3 \u00d7 3\\) ) and a larger number of parameters should be selected as the backbone. Table 1 shows the information of CSPResNeXt50, CSPDarknet53, and EfficientNet B3. The CSPResNext50 contains only 16 convolutional layers \\(3 \u00d7 3\\) , a \\(425 \u00d7 425\\) receptive field and 20.6 M parameters, while CSPDarknet53 contains 29 convolu- tional layers \\(3 \u00d7 3\\) , a \\(725 \u00d7 725\\) receptive field and 27.6 M parameters. This theoretical justification, together with our numerous experiments, show that CSPDarknet53 neural network is the optimal model of the two as the backbone for a detector. \u2003\u5047\u8bbe\u5730\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u5047\u8bbe\u5e94\u8be5\u9009\u62e9\u5177\u6709\u66f4\u5927\u611f\u53d7\u91ce\u5927\u5c0f\uff08\u5177\u6709\u66f4\u591a\u5377\u79ef\u5c42 3 \u00d7 3\uff09\u548c\u66f4\u591a\u53c2\u6570\u7684\u6a21\u578b\u4f5c\u4e3a\u4e3b\u5e72\u3002 \u8868 1 \u663e\u793a\u4e86 CSPResNeXt50\u3001CSPDarknet53 \u548c EfficientNet B3 \u7684\u4fe1\u606f\u3002 CSPResNext50 \u4ec5\u5305\u542b 16 \u4e2a 3 \u00d7 3 \u5377\u79ef\u5c42\u3001425 \u00d7 425 \u611f\u53d7\u91ce\u548c 20.6 M \u53c2\u6570\uff0c\u800c CSPDarknet53 \u5305\u542b 29 \u4e2a\u5377\u79ef\u5c42 3 \u00d7 3\u3001725 \u00d7 725 \u611f\u53d7\u91ce\u548c 27.6 M \u53c2\u6570\u3002 \u8fd9\u4e2a\u7406\u8bba\u8bc1\u660e\uff0c\u52a0\u4e0a\u6211\u4eec\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u8868\u660e CSPDarknet53 \u795e\u7ecf\u7f51\u7edc\u662f\u4e24\u8005\u7684\u6700\u4f73\u6a21\u578b\uff0c\u4f5c\u4e3a\u68c0\u6d4b\u5668\u7684\u4e3b\u5e72\u3002 \u2003The influence of the receptive field with different sizes is summarized as follows: \u2003\u4e0d\u540c\u5927\u5c0f\u7684\u611f\u53d7\u91ce\u7684\u5f71\u54cd\u603b\u7ed3\u5982\u4e0b: Up to the object size - allows viewing the entire object \u6700\u591a\u5230\u5bf9\u8c61\u5927\u5c0f \u2013 \u5141\u8bb8\u67e5\u770b\u6574\u4e2a\u5bf9\u8c61 Up to network size - allows viewing the context around the object \u6700\u591a\u7f51\u7edc\u5927\u5c0f \u2013 \u5141\u8bb8\u67e5\u770b\u5bf9\u8c61\u5468\u56f4\u7684\u4e0a\u4e0b\u6587 Exceeding the network size - increases the number of connections between the image point and the final activation \u8d85\u8fc7\u7f51\u7edc\u5927\u5c0f \u2013 \u589e\u52a0\u56fe\u50cf\u70b9\u548c\u6700\u7ec8\u6fc0\u6d3b\u4e4b\u95f4\u7684\u8fde\u63a5\u6570 \u2003 We add the SPP block over the CSPDarknet53, since it significantly increases the receptive field, separates out the most significant context features and causes almost no reduction of the network operation speed. We use PANet as the method of parameter aggregation from different backbone levels for different detector levels, instead of the FPN used in YOLOv3. \u2003\u6211\u4eec\u5728 CSPDarknet53 \u4e0a\u6dfb\u52a0\u4e86 SPP \u5757\uff0c\u56e0\u4e3a\u5b83\u663e\u7740\u589e\u52a0\u4e86\u611f\u53d7\u91ce\uff0c\u5206\u79bb\u51fa\u6700\u91cd\u8981\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u5e76\u4e14\u51e0\u4e4e\u4e0d\u4f1a\u964d\u4f4e\u7f51\u7edc\u8fd0\u884c\u901f\u5ea6\u3002 \u6211\u4eec\u4f7f\u7528 PANet \u4f5c\u4e3a\u6765\u81ea\u4e0d\u540c\u4e3b\u5e72\u7ea7\u522b\u7684\u5bf9\u4e0d\u540c\u68c0\u6d4b\u5668\u7ea7\u522b\u7684\u53c2\u6570\u805a\u5408\u65b9\u6cd5\uff0c\u800c\u4e0d\u662f YOLOv3 \u4e2d\u4f7f\u7528\u7684 FPN\u3002 \u2003Finally, we choose CSPDarknet53 backbone, SPP additional module, PANet path-aggregation neck, and YOLOv3 (anchor based) head as the architecture of YOLOv4. \u2003\u6700\u540e\uff0c\u6211\u4eec\u9009\u62e9 CSPDarknet53 \u4e3b\u5e72\u3001SPP \u9644\u52a0\u6a21\u5757\u3001PANet \u8def\u5f84\u805a\u5408\u9888\u90e8\u548c YOLOv3\uff08(anchor based\uff09\u5934\u90e8\u4f5c\u4e3a YOLOv4 \u7684\u67b6\u6784\u3002 \u2003n the future we plan to expand significantly the content of Bag of Freebies (BoF) for the detector, which theoreti- cally can address some problems and increase the detector accuracy, and sequentially check the influence of each fea- ture in an experimental fashion. \u2003\u672a\u6765\u6211\u4eec\u8ba1\u5212\u5927\u529b\u6269\u5c55\u68c0\u6d4b\u5668\u7684Bag of Freebies (BoF) \u5185\u5bb9\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u89e3\u51b3\u4e00\u4e9b\u95ee\u9898\u5e76\u63d0\u9ad8\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4ee5\u5b9e\u9a8c\u65b9\u5f0f\u4f9d\u6b21\u68c0\u67e5\u6bcf\u4e2a\u7279\u5f81\u7684\u5f71\u54cd\u3002 \u2003We do not use Cross-GPU Batch Normalization (CGBN or SyncBN) or expensive specialized devices. This al- lows anyone to reproduce our state-of-the-art outcomes on a conventional graphic processor e.g. GTX 1080Ti or RTX 2080Ti. \u2003\u6211\u4eec\u4e0d\u4f7f\u7528\u8de8 GPU\uff08Cross-GPU\uff09\u6279\u91cf\u5f52\u4e00\u5316\uff08CGBN \u6216 SyncBN\uff09\u6216\u6602\u8d35\u7684\u4e13\u7528\u8bbe\u5907\u3002 \u8fd9\u5141\u8bb8\u4efb\u4f55\u4eba\u5728\u4f20\u7edf\u56fe\u5f62\u5904\u7406\u5668\u4e0a\u91cd\u73b0\u6211\u4eec\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u4f8b\u5982 GTX 1080Ti \u6216 RTX 2080Ti\u3002 3.2. Selection of BoF and BoS \u2003For improving the object detection training, a CNN usu- ally uses the following: \u2003\u4e3a\u4e86\u6539\u8fdb\u76ee\u6807\u68c0\u6d4b\u8bad\u7ec3\uff0cCNN \u901a\u5e38\u4f7f\u7528\u4ee5\u4e0b\u5185\u5bb9\uff1a Activations: ReLU, leaky-ReLU, parametric-ReLU, ReLU6, SELU, Swish, or Mish \u6fc0\u6d3b\uff1aReLU\u3001leaky-ReLU\u3001\u53c2\u6570\u5316 ReLU\uff08parametric-ReLU\uff09\u3001ReLU6\u3001SELU\u3001Swish \u6216 Mish Bounding box regression loss: MSE, IoU, GIoU,CIoU, DIoU \u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\uff1aMSE\u3001IoU\u3001GIoU\u3001CIoU\u3001DIoU Data augmentation: CutOut, MixUp, CutMix \u6570\u636e\u589e\u5f3a\uff1aCutOut\u3001MixUp\u3001CutMix Regularization method: DropOut, DropPath [36],Spatial DropOut [79], or DropBlock \u6b63\u5219\u5316\u65b9\u6cd5\uff1aDropOut\u3001DropPath [36]\u3001Spatial DropOut [79] \u6216 DropBlock Normalization of the network activations by their mean and variance: Batch Normalization (BN) [32], Cross-GPU Batch Normalization (CGBN or SyncBN)[93], Filter Response Normalization (FRN) [70], or Cross-Iteration Batch Normalization (CBN) [89] \u901a\u8fc7\u5747\u503c\u548c\u65b9\u5dee\u5bf9\u7f51\u7edc\u6fc0\u6d3b\u8fdb\u884c\u5f52\u4e00\u5316\uff1a\u6279\u5f52\u4e00\u5316 (BN) [32]\u3001Cross-GPU \u6279\u5f52\u4e00\u5316\uff08CGBN \u6216 SyncBN\uff09[93]\u3001\u6ee4\u6ce2\u5668\u54cd\u5e94\uff08Filter Response\uff09\u5f52\u4e00\u5316 (FRN) [70] \u6216\u4ea4\u53c9\u8fed\u4ee3\uff08Cross-Iteration\uff09\u6279\u5f52\u4e00\u5316 (CBN) [89] Skip-connections: Residual connections, Weighted residual connections, Multi-input weighted residual connections, or Cross stage partial connections (CSP) \u8df3\u8fc7\u8fde\u63a5\uff08Skip-connections\uff09\uff1a\u6b8b\u5dee\u8fde\u63a5\uff08Residual connection\uff09\u3001\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\u3001\u591a\u8f93\u5165\uff08Multi-input\uff09\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\u6216\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5\uff08Cross stage partial connections\uff09 (CSP) \u2003As for training activation function, since PReLU and SELU are more difficult to train, and ReLU6 is specifically designed for quantization network, we therefore remove the above activation functions from the candidate list. In the method of reqularization, the people who published Drop- Block have compared their method with other methods in detail, and their regularization method has won a lot. There- fore, we did not hesitate to choose DropBlock as our reg- ularization method. As for the selection of normalization method, since we focus on a training strategy that uses only one GPU, syncBN is not considered. \u2003\u81f3\u4e8e\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\uff0c\u7531\u4e8e PReLU \u548c SELU \u66f4\u96be\u8bad\u7ec3\uff0c\u800c ReLU6 \u662f\u4e13\u95e8\u4e3a\u91cf\u5316\uff08quantization\uff09\u7f51\u7edc\u8bbe\u8ba1\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u4ece\u5019\u9009\u5217\u8868\u4e2d\u5220\u9664\u4e86\u4e0a\u8ff0\u6fc0\u6d3b\u51fd\u6570\u3002 \u5728\u6b63\u5219\u5316\u7684\u65b9\u6cd5\u4e0a\uff0c\u53d1\u8868Drop-Block\u7684\u4eba\u8be6\u7ec6\u5bf9\u6bd4\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\u548c\u5176\u4ed6\u65b9\u6cd5\uff0c\u4ed6\u4eec\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u8d62\u5f97\u4e86\u5f88\u591a\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u6beb\u4e0d\u72b9\u8c6b\u5730\u9009\u62e9 DropBlock \u4f5c\u4e3a\u6211\u4eec\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002 \u81f3\u4e8e\u5f52\u4e00\u5316\u65b9\u6cd5\u7684\u9009\u62e9\uff0c\u7531\u4e8e\u6211\u4eec\u4e13\u6ce8\u4e8e\u4ec5\u4f7f\u7528\u4e00\u4e2a GPU \u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u56e0\u6b64\u6ca1\u6709\u8003\u8651 syncBN\u3002 3.3. Additional improvements \u2003In order to make the designed detector more suitable for training on single GPU, we made additional design and im- provement as follows: \u2003\u4e3a\u4e86\u4f7f\u6240\u8bbe\u8ba1\u7684\u68c0\u6d4b\u5668\u66f4\u9002\u5408\u5728\u5355\u4e00GPU\u4e0a\u8bad\u7ec3\uff0c\u6211\u4eec\u505a\u4e86\u5982\u4e0b\u989d\u5916\u7684\u8bbe\u8ba1\u548c\u6539\u8fdb: We introduce a new method of data augmentation Mosaic, and Self-Adversarial Training (SA T) \u6211\u4eec\u5f15\u5165\u4e86\u6570\u636e\u589e\u5f3a\u9a6c\u8d5b\u514b\uff08Mosaic\uff09\u548c\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u7684\u65b0\u65b9\u6cd5 We select optimal hyper-parameters while applying genetic algorithms \u6211\u4eec\u5728\u5e94\u7528\u9057\u4f20\u7b97\u6cd5\uff08genetic algorithm\uff09\u7684\u540c\u65f6\u9009\u62e9\u6700\u4f73\u8d85\u53c2\u6570 We modify some exsiting methods to make our design suitble for efficient training and detection - modified SAM, modified PAN, and Cross mini-Batch Normalization (CmBN) \u6211\u4eec\u4fee\u6539\u4e86\u4e00\u4e9b\u73b0\u6709\u7684\u65b9\u6cd5\uff0c\u4f7f\u6211\u4eec\u7684\u8bbe\u8ba1\u9002\u5408\u9ad8\u6548\u7684\u8bad\u7ec3\u548c\u68c0\u6d4b\u2014\u2014\u4fee\u6539\u7684 SAM\u3001\u4fee\u6539\u7684 PAN \u548c\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN) \u2003Mosaic represents a new data augmentation method that mixes 4 training images. Thus 4 different contexts are mixed, while CutMix mixes only 2 input images. This al- lows detection of objects outside their normal context. In addition, batch normalization calculates activation statistics from 4 different images on each layer. This significantly reduces the need for a large mini-batch size. \u2003Mosaic \u4ee3\u8868\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b83\u6df7\u5408\u4e86 4 \u4e2a\u8bad\u7ec3\u56fe\u50cf\u3002 \u56e0\u6b64\u6df7\u5408\u4e86 4 \u4e2a\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\uff0c\u800c CutMix \u4ec5\u6df7\u5408\u4e86 2 \u4e2a\u8f93\u5165\u56fe\u50cf\u3002 \u8fd9\u5141\u8bb8\u68c0\u6d4b\u6b63\u5e38\u4e0a\u4e0b\u6587\u4e4b\u5916\u7684\u5bf9\u8c61\u3002 \u6b64\u5916\uff0c\u6279\u91cf\u5f52\u4e00\u5316\u8ba1\u7b97\u6bcf\u5c42 4 \u4e2a\u4e0d\u540c\u56fe\u50cf\u7684\u6fc0\u6d3b\u7edf\u8ba1\u6570\u636e\u3002 \u8fd9\u663e\u7740\u51cf\u5c11\u4e86\u5bf9\u5927\u5c3a\u5bf8 mini-batch \u7684\u9700\u6c42\u3002 Figure 3: Mosaic represents a new method of data augmentation. \u56fe3:\u9a6c\u8d5b\u514b\u8868\u793a\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u7684\u65b0\u65b9\u6cd5\u3002 \u2003Self-Adversarial Training (SAT) also represents a new data augmentation technique that operates in 2 forward backward stages. In the 1st stage the neural network alters the original image instead of the network weights. In this way the neural network executes an adversarial attack on it- self, altering the original image to create the deception that there is no desired object on the image. In the 2nd stage, the neural network is trained to detect an object on this modified image in the normal way. \u2003 \u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u4e5f\u4ee3\u8868\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u5b83\u5728 2 \u4e2a\u524d\u5411\u548c\u540e\u5411\u9636\u6bb5\u4e2d\u8fd0\u884c\u3002 \u5728\u7b2c\u4e00\u9636\u6bb5\uff0c\u795e\u7ecf\u7f51\u7edc\u6539\u53d8\u539f\u59cb\u56fe\u50cf\u800c\u4e0d\u662f\u7f51\u7edc\u6743\u91cd\u3002 \u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u795e\u7ecf\u7f51\u7edc\u5bf9\u81ea\u8eab\u6267\u884c\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u6539\u53d8\u539f\u59cb\u56fe\u50cf \u4ee5\u5236\u9020\u56fe\u50cf\u4e0a\u6ca1\u6709\u6240\u9700\u5bf9\u8c61\u7684\u6b3a\u9a97\uff08deception\uff09\u3002 \u5728\u7b2c\u4e8c\u9636\u6bb5\uff0c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4ee5\u6b63\u5e38\u65b9\u5f0f\u68c0\u6d4b\u6b64\u4fee\u6539\u56fe\u50cf\u4e0a\u7684\u5bf9\u8c61\u3002 Figure 4: Cross mini-Batch Normalization. \u56fe 4\uff1a\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316\u3002 \u2003CmBN represents a CBN modified version, as shown in Figure 4, defined as Cross mini-Batch Normalization (CmBN). This collects statistics only between mini-batches within a single batch. \u2003 CmBN \u8868\u793a CBN \u4fee\u6539\u7248\u672c\uff0c\u5982\u56fe 4 \u6240\u793a\uff0c\u5b9a\u4e49\u4e3a\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3002 \u8fd9\u4ec5\u5728\u5355\u4e2a\u6279\u6b21\u5185\u7684\u5c0f\u6279\u6b21\u4e4b\u95f4\u6536\u96c6\u7edf\u8ba1\u4fe1\u606f\u3002 \u2003 We modify SAM from spatial-wise attention to point- wise attention, and replace shortcut connection of PAN to concatenation, as shown in Figure 5 and Figure 6, respec- tively. \u2003 \u6211\u4eec\u5c06 SAM \u4ece\u6309\u7a7a\u95f4\u6ce8\u610f\uff08spatial-wise attention\uff09\u4fee\u6539\u4e3a\u9010\u70b9\u6ce8\u610f\uff08point-wise attention\uff09\uff0c\u5e76\u5c06 PAN \u7684\u5feb\u6377\u8fde\u63a5\uff08shortcut connection\uff09\u66ff\u6362\u4e3a\u4e32\u8054\uff08concatenation\uff09\uff0c\u5206\u522b\u5982\u56fe 5 \u548c\u56fe 6 \u6240\u793a\u3002 3.4. YOLOv4 In this section, we shall elaborate the details of YOLOv4. \u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u8be6\u7ec6\u9610\u8ff0YOLOv4\u7684\u7ec6\u8282\u3002 YOLOv4 consists of: YOLOv4 \u5305\u62ec\uff1a Backbone: CSPDarknet53 [81] Neck: SPP [25], PAN [49] Head: YOLOv3 [63] YOLO v4 uses: YOLO v4 \u4f7f\u7528: Bag of Freebies (BoF) for backbone: CutMix and Mosaic data augmentation, DropBlock regularization, Class label smoothing \u9aa8\u5e72\u7684BoF\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u3001DropBlock \u6b63\u5219\u5316\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\uff08Class label smoothing\uff09 Bag of Specials (BoS) for backbone: Mish activation, Cross-stage partial connections (CSP), Multiinput weighted residual connections (MiWRC) \u9aa8\u5e72\u7684BoS\uff1aMish \u6fc0\u6d3b\u3001\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5 (CSP)\u3001\u591a\u8f93\u5165\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5 (MiWRC) Bag of Freebies (BoF) for detector: CIoU-loss, CmBN, DropBlock regularization, Mosaic data augmentation, Self-Adversarial Training, Eliminate grid sensitivity, Using multiple anchors for a single ground truth, Cosine annealing scheduler [52], Optimal hyperparameters, Random training shapes \u68c0\u6d4b\u5668\u7684BoF\uff1aCIoU-loss\u3001CmBN\u3001DropBlock \u6b63\u5219\u5316\u3001Mosaic \u6570\u636e\u589e\u5f3a\u3001\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3\uff08SAT\uff09\u3001\u6d88\u9664\u7f51\u683c\u654f\u611f\u6027\uff08Eliminate grid sensitivity\uff09\u3001\u4f7f\u7528\u591a\u4e2a\u951a\u70b9\uff08multiple anchors\uff09\u83b7\u53d6\u5355\u4e2a\u771f\u5b9e\u503c\u3001\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\u7a0b\u5e8f\uff08Cosine annealing scheduler\uff09 [52]\u3001\u6700\u4f18\u8d85\u53c2\u6570\uff0c\u968f\u673a\u8bad\u7ec3\u5f62\u72b6 Bag of Specials (BoS) for detector: Mish activation, SPP-block, SAM-block, PAN path-aggregation block,DIoU-NMS \u7528\u4e8e\u68c0\u6d4b\u5668\u7684\u7279\u6709\u5305 \uff08BoS\uff09\uff1a \u8bef\u533a\u6fc0\u6d3b\u3001 SPP \u5757\u3001 SAM \u5757\u3001 PAN \u8def\u5f84\u805a\u5408\u5757\u3001 DIoU-NMS 4. Experiments \u5b9e\u9a8c \u2003We test the influence of different training improvement techniques on accuracy of the classifier on ImageNet (ILSVRC 2012 val) dataset, and then on the accuracy of the detector on MS COCO (test-dev 2017) dataset. \u2003\u6211\u4eec\u5728 ImageNet (ILSVRC 2012 val) \u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u4e0d\u540c\u8bad\u7ec3\u6539\u8fdb\u6280\u672f\u5bf9\u5206\u7c7b\u5668\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u7136\u540e\u5728 MS COCO (test-dev 2017) \u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u3002 4.1. Experimental setup \u5b9e\u9a8c\u8bbe\u7f6e \u2003In ImageNet image classification experiments, the default hyper-parameters are as follows: the training steps is 8,000,000; the batch size and the mini-batch size are 128 and 32, respectively; the polynomial decay learning rate scheduling strategy is adopted with initial learning rate 0.1; the warm-up steps is 1000; the momentum and weight decay are respectively set as 0.9 and 0.005. All of our BoS experiments use the same hyper-parameter as the default setting, and in the BoF experiments, we add an additional 50% training steps. In the BoF experiments, we verify MixUp, CutMix, Mosaic, Bluring data augmentation, and label smoothing regularization methods. In the BoS experiments, we compared the effects of LReLU, Swish, and Mish activation function. All experiments are trained with a 1080 Ti or 2080 Ti GPU. \u2003\u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u5b9e\u9a8c\u4e2d\uff0c\u9ed8\u8ba4\u8d85\u53c2\u6570\u5982\u4e0b\uff1a\u8bad\u7ec3\u6b65\u6570\u4e3a 8,000,000\uff1b \u5927\u6279\u91cf\u548c\u5c0f\u6279\u91cf\u5927\u5c0f\u5206\u522b\u4e3a 128 \u548c 32\uff1b \u91c7\u7528\u591a\u9879\u5f0f\u8870\u51cf\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08polynomial decay learning rate scheduling strategy\uff09\uff0c\u521d\u59cb\u5b66\u4e60\u73870.1\uff1b \u9884\u70ed\uff08warm-up\uff09\u6b65\u6570\u4e3a1000\uff1b \u52a8\u91cf\u8870\u51cf\u548c\u6743\u91cd\u8870\u51cf\u5206\u522b\u8bbe\u7f6e\u4e3a 0.9 \u548c 0.005\u3002\u6211\u4eec\u6240\u6709\u7684 BoS \u5b9e\u9a8c\u90fd\u4f7f\u7528\u4e0e\u9ed8\u8ba4\u8bbe\u7f6e\u76f8\u540c\u7684\u8d85\u53c2\u6570\uff0c\u5e76\u4e14\u5728 BoF \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u989d\u5916\u7684 50% \u8bad\u7ec3\u6b65\u6570\u3002 \u5728 BoF \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u9a8c\u8bc1\u4e86 MixUp\u3001CutMix\u3001Mosaic\u3001Bluring \u6570\u636e\u589e\u5f3a\u548c\u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316\uff08label smoothing regularization\uff09\u65b9\u6cd5\u3002 \u5728 BoS \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6bd4\u8f83\u4e86 LReLU\u3001Swish \u548c Mish \u6fc0\u6d3b\u51fd\u6570\u7684\u6548\u679c\u3002 \u6240\u6709\u5b9e\u9a8c\u5747\u4f7f\u7528 1080 Ti \u6216 2080 Ti GPU \u8fdb\u884c\u8bad\u7ec3\u3002 \u2003In MS COCO object detection experiments, the default hyper-parameters are as follows: the training steps is 500,500; the step decay learning rate scheduling strategy is adopted with initial learning rate 0.01 and multiply with a factor 0.1 at the 400,000 steps and the 450,000 steps, respectively; The momentum and weight decay are respec- tively set as 0.9 and 0.0005. All architectures use a single GPU to execute multi-scale training in the batch size of 64 while mini-batch size is 8 or 4 depend on the architectures and GPU memory limitation. Except for us- ing genetic algorithm for hyper-parameter search experiments, all other experiments use default setting. Genetic algorithm used YOLOv3-SPP to train with GIoU loss and search 300 epochs for min-val 5k sets. We adopt searched learning rate 0.00261, momentum 0.949, IoU threshold for assigning ground truth 0.213, and loss normalizer 0.07 for genetic algorithm experiments. We have verified a large number of BoF, including grid sensitivity elimination, mosaic data augmentation, IoU threshold, genetic algorithm, class label smoothing, cross mini-batch normalization, self-adversarial training, cosine annealing scheduler, dynamic mini-batch size, DropBlock, Optimized Anchors, different kind of IoU losses. We also conduct experiments on various BoS, including Mish, SPP, SAM, RFB, BiFPN, and Gaus-sian YOLO [8]. For all experiments, we only use one GPU for training, so techniques such as syncBN that optimizes multiple GPUs are not used. \u2003\u5728 MS COCO \u6570\u636e\u96c6\u4e0a\u76ee\u6807\u68c0\u6d4b\u5b9e\u9a8c\u4e2d\uff0c\u9ed8\u8ba4\u8d85\u53c2\u6570\u5982\u4e0b\uff1a\u8bad\u7ec3\u6b65\u6570\u4e3a 500,500\uff1b \u91c7\u7528\u6b65\u957f\u8870\u51cf\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08step decay learning rate scheduling strategy\uff09\uff0c\u521d\u59cb\u5b66\u4e60\u73870.01\uff0c\u5206\u522b\u572840\u4e07\u6b65\u548c45\u4e07\u6b65\u4e58\u4ee5\u56e0\u5b500.1\uff1b \u52a8\u91cf\u548c\u6743\u91cd\u8870\u51cf\u5206\u522b\u8bbe\u7f6e\u4e3a 0.9 \u548c 0.0005\u3002\u6240\u6709\u67b6\u6784\uff08architecture\uff09\u90fd\u4f7f\u7528\u5355\u4e2a GPU \u4ee5 64 \u7684\u6279\u91cf\u5927\u5c0f\u6267\u884c\u591a\u6bd4\u4f8b\uff08multi-scale\uff09\u8bad\u7ec3\uff0c\u800c\u5c0f\u6279\u91cf\u5927\u5c0f\u4e3a 8 \u6216 4\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u67b6\u6784\u548c GPU \u5185\u5b58\u9650\u5236\u3002 \u9664\u4e86\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u8d85\u53c2\u6570\u641c\u7d22\u5b9e\u9a8c\u5916\uff0c\u5176\u4ed6\u6240\u6709\u5b9e\u9a8c\u5747\u4f7f\u7528\u9ed8\u8ba4\u8bbe\u7f6e\u3002 \u9057\u4f20\u7b97\u6cd5\u4f7f\u7528 YOLOv3-SPP \u8bad\u7ec3 GIoU\u635f\u5931\u5e76\u641c\u7d22 300 \u4e2a epoch \u4ee5\u83b7\u53d6min-val 5k \u96c6\u3002 \u6211\u4eec\u91c7\u7528\u641c\u7d22\u5b66\u4e60\u7387 0.00261\uff0c\u52a8\u91cf 0.949\uff0c\u5206\u914d\u771f\u5b9e\u503c\u7684 IoU \u9608\u503c 0.213\uff0c\u9057\u4f20\u7b97\u6cd5\u5b9e\u9a8c\u7684\u635f\u5931\u5f52\u4e00\u5316\u5668 0.07\u3002 \u6211\u4eec\u5df2\u7ecf\u9a8c\u8bc1\u4e86\u5927\u91cf\u7684 BoF\uff0c\u5305\u62ec\u7f51\u683c\u654f\u611f\u6027\u6d88\u9664\uff08grid sensitivity elimination\uff09\u3001\u9a6c\u8d5b\u514b\u6570\u636e\u589e\u5f3a\u3001IoU \u9608\u503c\u3001\u9057\u4f20\u7b97\u6cd5\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\u3001\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3001\u81ea\u5bf9\u6297\u8bad\u7ec3\u3001\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\u5668\u3001\u52a8\u6001\u5c0f\u6279\u91cf\u5927\u5c0f\u3001DropBlock , \u4f18\u5316\u7684\u951a\u70b9\uff08Optimized Anchor\uff09\uff0c\u4e0d\u540c\u79cd\u7c7b\u7684 IoU \u635f\u5931\u3002 \u6211\u4eec\u8fd8\u5bf9\u5404\u79cd BoS \u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5305\u62ec Mish\u3001SPP\u3001SAM\u3001RFB\u3001BiFPN \u548cGaussian YOLO [8]\u3002 \u5bf9\u4e8e\u6240\u6709\u5b9e\u9a8c\uff0c\u6211\u4eec\u53ea\u4f7f\u7528\u4e00\u4e2a GPU \u8fdb\u884c\u8bad\u7ec3\uff0c\u56e0\u6b64\u6ca1\u6709\u4f7f\u7528\u4f18\u5316\u591a\u4e2a GPU \u7684\u540c\u6b65BN\uff08syncBN\uff09 \u7b49\u6280\u672f\u3002 4.2. Influence of different features on Classifier \u4e0d\u540c\u7279\u5f81\u5bf9\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u5f71\u54cd \u2003First, we study the influence of different features on classifier training; specifically, the influence of Class la- bel smoothing, the influence of different data augmentation techniques, bilateral blurring, MixUp, CutMix and Mosaic, as shown in Fugure 7, and the influence of different activa- tions, such as Leaky-ReLU (by default), Swish, and Mish. \u2003\u9996\u5148\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u4e0d\u540c\u7279\u5f81\u5bf9\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u5f71\u54cd\uff1b \u5177\u4f53\u6765\u8bf4\uff0cClass label smoothing\u7684\u5f71\u54cd\uff0c\u4e0d\u540c\u6570\u636e\u589e\u5f3a\u6280\u672f\u7684\u5f71\u54cd\uff0c\u53cc\u8fb9\u6a21\u7cca\uff08bilateral blurring\uff09\uff0cMixUp\uff0cCutMix\u548cMosaic\uff0c\u5982Fugure 7\u6240\u793a\uff0c\u4ee5\u53ca\u4e0d\u540c\u6fc0\u6d3b\u7684\u5f71\u54cd\uff0c\u4f8b\u5982Leaky-ReLU\uff08\u9ed8\u8ba4\uff09\uff0cSwish \uff0c\u548cMish\u3002 Figure 7: V arious method of data augmentation. \u56fe7:\u5404\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002 \u2003In our experiments, as illustrated in Table 2, the classifier\u2019s accuracy is improved by introducing the features such as: CutMix and Mosaic data augmentation, Class label smoothing, and Mish activation. As a result, our BoF-backbone (Bag of Freebies) for classifier training includes the following: CutMix and Mosaic data augmentation and Class label smoothing. In addition we use Mish activation as a complementary option, as shown in Table 2 and Table \u2003 \u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5982\u8868 2 \u6240\u793a\uff0c\u901a\u8fc7\u5f15\u5165\u4ee5\u4e0b\u7279\u5f81\u6765\u63d0\u9ad8\u5206\u7c7b\u5668\u7684\u51c6\u786e\u6027\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\u548c Mish \u6fc0\u6d3b\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u7528\u4e8e\u5206\u7c7b\u5668\u8bad\u7ec3\u7684 BoF-backbone\uff08Bag of Freebies\uff09\u5305\u62ec\u4ee5\u4e0b\u5185\u5bb9\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u4ee5\u53ca\u7c7b\u6807\u7b7e\u5e73\u6ed1\u3002 \u6b64\u5916\uff0c\u6211\u4eec\u4f7f\u7528 Mish \u6fc0\u6d3b\u4f5c\u4e3a\u8865\u5145\u9009\u9879\uff08complementary option\uff09\uff0c\u5982\u8868 2 \u548c\u8868 3 \u6240\u793a\u3002 Table 2: Influence of BoF and Mish on the CSPResNeXt-50 classifier accuracy. \u88682:BoF\u548cMish\u5bf9CSPResNeXt-50\u5206\u7c7b\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002 Table 3: Influence of BoF and Mish on the CSPDarknet-53 classifier accuracy. \u88683:BoF\u548cMish\u5bf9CSPDarknet-53\u5206\u7c7b\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002 4.3. Influence of different features on Detector \u2003Further study concerns the influence of different Bag-of-Freebies (BoF-detector) on the detector training accuracy, as shown in Table 4. We significantly expand the BoF list through studying different features that increase the detector accuracy without affecting FPS: \u2003\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u6d89\u53ca\u4e0d\u540c\u7684\u514d\u8d39\u888b(BOF\u63a2\u6d4b\u5668)\u5bf9\u63a2\u6d4b\u5668\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u5982\u88684\u6240\u793a\u3002\u6211\u4eec\u901a\u8fc7\u7814\u7a76\u5728\u4e0d\u5f71\u54cdFPS\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u63a2\u6d4b\u5668\u7cbe\u5ea6\u7684\u4e0d\u540c\u7279\u6027\uff0c\u663e\u8457\u6269\u5c55\u4e86BOF\u5217\u8868\uff1a S: Eliminate grid sensitivity the equation \\(b_x = \u03c3(t_x )+ c_x , b_y = \u03c3(t_y )+c_y\\) , where \\(c_x\\) and \\(c_y\\) are always whole numbers, is used in YOLOv3 for evaluating the object coordinates, therefore, extremely high \\(t_x\\) absolute values are required for the \\(b_x\\) value approaching the \\(c_x \\ or \\ c_{ x} + 1\\) values. We solve this problem through multiplying the sigmoid by a factor exceeding 1.0, so eliminating the effect of grid on which the object is undetectable. S\uff1a \u6d88\u9664\u7f51\u683c\u7075\u654f\u5ea6\u65b9\u7a0b \\(b_x = \u03c3(t_x )+ c_x , b_y = \u03c3(t_y )+c_y\\) \uff0c \u5176\u4e2d \\(c_x\\) \u548c \\(c_y\\) \u59cb\u7ec8\u4e3a\u6574\u6570\uff0c \u5728 YOLOv3 \u4e2d\u4f7f\u7528\u7528\u4e8e\u8bc4\u4f30\u76ee\u6807\u5750\u6807\uff0c \u56e0\u6b64\uff0c\u63a5\u8fd1 \\(c_x \\ or \\ c_{ x} + 1\\) \u503c\u7684 \\(b_x\\) \u503c\u9700\u8981\u6781\u9ad8\u7684 \\(t_x\\) \u7edd\u5bf9\u503c\u3002\u6211\u4eec\u901a\u8fc7\u5c06 sigmoid \u4e58\u4ee5\u8d85\u8fc7 1.0 \u7684\u56e0\u5b50\u6765\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u5bf9\u8c61\u65e0\u6cd5\u68c0\u6d4b\u5230\u7684\u7f51\u683c\u7684\u5f71\u54cd\u3002 M: Mosaic data augmentation \u2013 using the 4-image mosaic during training instead of single image M\uff1a\u9a6c\u8d5b\u514b\u6570\u636e\u6269\u589e \u2013 \u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528 4 \u56fe\u50cf\u9576\u5d4c\uff0c\u800c\u4e0d\u662f\u5355\u4e2a\u56fe\u50cf IT: IoU threshold \u2013 using multiple anchors for a single ground truth IoU (truth, anchor) > IoU-threshold IT\uff1aIoU \u9608\u503c \u2013 \u4f7f\u7528\u591a\u4e2a\u951a\u70b9\u8fdb\u884c\u5355\u4e2a\u63a5\u5730\u771f\u76f8 IoU\uff08\u771f\u3001\u951a\uff09\u548c IoU \u9608\u503c | GA: Genetic algorithms \u2013 using genetic algorithms for selecting the optimal hyperparameters during network training on the \ufb01rst 10% of time periods GA\uff1a\u9057\u4f20\u7b97\u6cd5 \u2013 \u5728\u524d 10% \u7684\u65f6\u95f4\u6bb5\u7684\u7f51\u7edc\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u9009\u62e9\u6700\u4f73\u8d85\u53c2\u6570* LS: Class label smoothing \u2013 using class label smoothing for sigmoid activation LS\uff1a\u7c7b\u6807\u7b7e\u5e73\u6ed1 \u2013 \u4f7f\u7528\u7c7b\u6807\u7b7e\u5e73\u6ed1\u8fdb\u884c sigmoid \u6fc0\u6d3b CBN: CmBN \u2013 using Cross mini-Batch Normalization for collecting statistics inside the entire batch, instead of collecting statistics inside a single mini-batch CBN\uff1a CmBN \u2013 \u4f7f\u7528\u4ea4\u53c9\u5c0f\u6279\u5904\u7406\u89c4\u8303\u5316\u6536\u96c6\u6574\u4e2a\u6279\u5904\u7406\u4e2d\u7684\u7edf\u8ba1\u4fe1\u606f\uff0c\u800c\u4e0d\u662f\u5728\u5355\u4e2a\u5c0f\u6279\u5904\u7406\u4e2d\u6536\u96c6\u7edf\u8ba1\u4fe1\u606f* CA: Cosine annealing scheduler \u2013 altering the learning rate during sinusoid training CA\uff1a\u534f\u548c\u7d20\u9000\u706b\u8c03\u5ea6\u5668 \u2013 \u6539\u53d8\u6b63\u5f26\u8bad\u7ec3\u4e2d\u7684\u5b66\u4e60\u901f\u7387* DM: Dynamic mini-batch size \u2013 automatic increase of mini-batch size during small resolution training by using Random training shapes DM\uff1a\u52a8\u6001\u5c0f\u6279\u91cf\u5c3a\u5bf8 \u2013 \u4f7f\u7528\u968f\u673a\u8bad\u7ec3\u5f62\u72b6\u5728\u5c0f\u5206\u8fa8\u7387\u8bad\u7ec3\u671f\u95f4\u81ea\u52a8\u589e\u52a0\u5c0f\u6279\u91cf\u5927\u5c0f OA: Optimized Anchors \u2013 using the optimized anchors for training with the 512\u00d7512 network resolution OA\uff1a\u4f18\u5316\u7684\u951a\u70b9 \u2013 \u4f7f\u7528\u4f18\u5316\u7684\u951a\u70b9\u8fdb\u884c 512\u00d7512 \u7f51\u7edc\u5206\u8fa8\u7387\u7684\u8bad\u7ec3* GIoU, CIoU, DIoU, MSE \u2013 using different loss algorithms for bounded box regression GIoU\u3001CIoU\u3001DIoU\u3001MSE \u2013 \u5bf9\u8fb9\u754c\u6846\u56de\u5f52\u4f7f\u7528\u4e0d\u540c\u7684\u635f\u5931\u7b97\u6cd5 \u2003Further study concerns the in\ufb02uence of different Bagof-Specials (BoS-detector) on the detector training accuracy, including PAN, RFB, SAM, Gaussian YOLO (G), and ASFF, as shown in Table 5. In our experiments, the detector gets best performance when using SPP, PAN, and SAM. \u2003\u8fdb\u4e00\u6b65\u7814\u7a76\u6d89\u53ca\u4e0d\u540c\u7684\u5df4\u6208\u592b\u7279\u8f91\uff08BoS-\u68c0\u6d4b\u5668\uff09\u5bf9\u68c0\u6d4b\u5668\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u5305\u62ecPAN\u3001RFB\u3001SAM\u3001\u9ad8\u65afYOLO\uff08G\uff09\u548cASFF\uff0c\u5982\u88685\u6240\u793a\u3002\u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u68c0\u6d4b\u5668\u5728\u4f7f\u7528 SPP\u3001PAN \u548c SAM \u65f6\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002 Table 4: Ablation Studies of Bag-of-Freebies. (CSPResNeXt50-PANet-SPP , 512x512). Table 5: Ablation Studies of Bag-of-Specials. (Size 512x512). 4.4. Influence of different backbones and pretrained weightings on Detector training \u2003Further on we study the influence of different backbone models on the detector accuracy, as shown in Table 6. We notice that the model characterized with the best classifica- tion accuracy is not always the best in terms of the detector accuracy. \u2003 \u6700\u540e\uff0c\u6211\u4eec\u5206\u6790\u4e86\u5728\u4e0d\u540c\u6700\u5c0f\u6279\u91cf\u5927\u5c0f\u4e0b\u8bad\u7ec3\u7684\u6a21\u578b\u6240\u83b7\u5f97\u7684\u7ed3\u679c\uff0c\u7ed3\u679c\u5982\u88687\u6240\u793a\u3002\u4ece\u88687\u6240\u793a\u7684\u7ed3\u679c\u4e2d\uff0c\u6211\u4eec\u53d1\u73b0\u5728\u6dfb\u52a0BoF\u548cBoS\u8bad\u7ec3\u7b56\u7565\u4e4b\u540e\uff0c\u6700\u5c0f\u6279\u91cf\u5927\u5c0f\u51e0\u4e4e\u6ca1\u6709\u5f71\u54cd\u5728\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u4e0a\u3002\u8be5\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5f15\u5165BoF\u548cBoS\u4e4b\u540e\uff0c\u4e0d\u518d\u9700\u8981\u4f7f\u7528\u6602\u8d35\u7684GPU\u8fdb\u884c\u8bad\u7ec3\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u4efb\u4f55\u4eba\u90fd\u53ea\u80fd\u4f7f\u7528\u4f20\u7edf\u7684GPU\u6765\u8bad\u7ec3\u51fa\u8272\u7684\u63a2\u6d4b\u5668\u3002 Table 7: Using different mini-batch size for detector training. \u88687\uff1a\u4f7f\u7528\u4e0d\u540c\u7684\u5c0f\u6279\u91cf\u5bf9\u4e8e\u68c0\u6d4b\u5668\u8bad\u7ec3\u3002 5.Results \u2003Comparison of the results obtained with other state-of-the-art object detectors are shown in Figure 8. Our YOLOv4 are located on the Pareto optimality curve and are superior to the fastest and most accurate detectors in terms of both speed and accuracy. \u2003\u5f97\u5230\u7684\u7ed3\u679c\u4e0e\u5176\u4ed6\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u6bd4\u8f83\u5982\u56fe8\u6240\u793a\u3002\u6211\u4eec\u7684yolo4\u4f4d\u4e8ePareto optimality\u66f2\u7ebf\u4e0a\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u90fd\u4f18\u4e8e\u6700\u5feb\u548c\u6700\u7cbe\u786e\u7684\u63a2\u6d4b\u5668\u3002 \u2003Since different methods use GPUs of different architectures for inference time verification, we operate YOLOv4 on commonly adopted GPUs of Maxwell, Pascal, and Volta architectures, and compare them with other state-of-the-art methods. Table 8 lists the frame rate comparison results of using Maxwell GPU, and it can be GTX Titan X (Maxwell) or Tesla M40 GPU. Table 9 lists the frame rate comparison results of using Pascal GPU, and it can be Titan X (Pascal), Titan Xp, GTX 1080 Ti, or Tesla P100 GPU. As for Table 10, it lists the frame rate comparison results of using V olta GPU, and it can be Titan V olta or Tesla V100 GPU. \u2003\u7531\u4e8e\u4e0d\u540c\u7684\u65b9\u6cd5\u4f7f\u7528\u4e0d\u540c\u4f53\u7cfb\u7ed3\u6784\u7684GPU\u8fdb\u884c\u63a8\u7406\u65f6\u95f4\u9a8c\u8bc1\uff0c\u6211\u4eec\u5728\u5e38\u7528\u7684Maxwell\u3001Pascal\u548cVoltaArchitecture\u4f53\u7cfb\u7ed3\u6784\u7684GPU\u4e0a\u8fd0\u884cYOLOv4\uff0c\u5e76\u5c06\u5b83\u4eec\u4e0e\u5176\u4ed6\u5148\u8fdb\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u88688\u5217\u51fa\u4e86\u4f7f\u7528Maxwell GPU\u7684\u5e27\u7387\u6bd4\u8f83\u7ed3\u679c\uff0c\u53ef\u4ee5\u662fGTX Titan X(Maxwell)\u6216Tesla M40 GPU\u3002\u88689\u5217\u51fa\u4e86\u4f7f\u7528Pascal GPU\u7684\u5e27\u7387\u6bd4\u8f83\u7ed3\u679c\uff0c\u5b83\u53ef\u4ee5\u662fTitan X(Pascal)\u3001Titan XP\u3001GTX 1080 Ti\u6216Tesla P100 GPU\u3002\u886810\u5217\u51fa\u4e86\u4f7f\u7528VoltaGPU\u7684\u5e27\u7387\u5bf9\u6bd4\u7ed3\u679c\uff0c\u53ef\u4ee5\u662fTitan Volta\uff0c\u4e5f\u53ef\u4ee5\u662fTesla V100 GPU\u3002 6. Conclusions We offer a state-of-the-art detector which is faster (FPS) and more accurate (MS COCO \\(AP_{50...95}\\) and \\(AP_{50}\\) ) than all available alternative detectors. The detector described can be trained and used on a conventional GPU with 8-16 GB-VRAM this makes its broad use possible. The original concept of one-stage anchor-based detectors has proven its viability. We have verified a large number of features, and selected for use such of them for improving the accuracy of both the classifier and the detector. These features can be used as best-practice for future studies and developments. \u2003\u6211\u4eec\u63d0\u4f9b\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u901f\u5ea6\uff08FPS\uff09\u548c\u51c6\u786e\u5ea6\uff08MS COCO \\(AP_{50 ... 95}\\) \u548c \\(AP_{50}\\) \uff09\u6bd4\u6240\u6709\u53ef\u7528\u7684\u66ff\u4ee3\u68c0\u6d4b\u5668\u90fd\u9ad8\u3002\u6240\u63cf\u8ff0\u7684\u68c0\u6d4b\u5668\u53ef\u4ee5\u5728\u5177\u67098-16GB-VRAM\u7684\u5e38\u89c4GPU\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u4f7f\u7528\uff0c\u8fd9\u4f7f\u5f97\u5b83\u7684\u5e7f\u6cdb\u4f7f\u7528\u6210\u4e3a\u53ef\u80fd\u3002\u5355\u9636\u6bb5\u57fa\u4e8e\u951a\u6846\u7684\u68c0\u6d4b\u5668\u7684\u539f\u59cb\u6982\u5ff5\u5df2\u8bc1\u660e\u5176\u53ef\u884c\u6027\u3002\u6211\u4eec\u5df2\u7ecf\u9a8c\u8bc1\u4e86\u5927\u91cf\u7279\u5f81\uff0c\u5e76\u9009\u62e9\u4f7f\u7528\u5176\u4e2d\u7684\u4e00\u4e9b\u7279\u5f81\u4ee5\u63d0\u9ad8\u5206\u7c7b\u5668\u548c\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u3002\u8fd9\u4e9b\u529f\u80fd\u53ef\u4ee5\u7528\u4f5c\u5c06\u6765\u7814\u7a76\u548c\u5f00\u53d1\u7684\u6700\u4f73\u5b9e\u8df5\u3002 7. Acknowledgements \u2003The authors wish to thank Glenn Jocher for the ideas of Mosaic data augmentation, the selection of hyper-parameters by using genetic algorithms and solving the grid sensitivity problem https://github.com/ultralytics/yolov3. \u2003\u4f5c\u8005\u8981\u611f\u8c22Glenn Jocher\u8fdb\u884cMosaic\u6570\u636e\u589e\u5f3a\u7684\u60f3\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u9009\u62e9\u8d85\u53c2\u6570\u5e76\u89e3\u51b3\u7f51\u683c\u654f\u611f\u6027\u95ee\u9898\u7684\u65b9\u6cd5https://github.com/ultralytics/yolov3.10\u3002","title":"YOLOv4"},{"location":"thesis_interpretation/04_yolo.html#abstract","text":"There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is re- quired. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and com- bine some of them to achieve state-of-the-art results: 43.5% AP (65.7% AP50) for the MS COCO dataset at a real- time speed of \u223c65 FPS on Tesla V100. Source code is at https://github.com/AlexeyAB/darknet. \u636e\u8bf4\u6709\u5927\u91cf\u7279\u5f81\u53ef\u4ee5\u63d0\u9ad8\u5377\u79ef\u795e\u7ecf\u7f51\u7edc (CNN) \u7684\u51c6\u786e\u6027\u3002 \u9700\u8981\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u5bf9\u8fd9\u4e9b\u7279\u5f81\u7684\u7ec4\u5408\u8fdb\u884c\u5b9e\u9645\u6d4b\u8bd5\uff0c\u5e76\u5bf9\u7ed3\u679c\u8fdb\u884c\u7406\u8bba\u8bba\u8bc1\u3002 \u67d0\u4e9b\u7279\u5f81\u4e13\u95e8\u9488\u5bf9\u67d0\u4e9b\u6a21\u578b\uff0c\u4e13\u95e8\u9488\u5bf9\u67d0\u4e9b\u95ee\u9898\uff0c\u6216\u4ec5\u9488\u5bf9\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\uff1b \u800c\u4e00\u4e9b\u7279\u6027\uff0c\u5982\u6279\u91cf\u5f52\u4e00\u5316\u548c\u6b8b\u5dee\u8fde\u63a5\uff0c\u9002\u7528\u4e8e\u5927\u591a\u6570\u6a21\u578b\u3001\u4efb\u52a1\u548c\u6570\u636e\u96c6\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u901a\u7528\uff08universal\uff09\u7279\u5f81\u5305\u62ec\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5 (WRC)\u3001\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5 (CSP)\u3001\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3001\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u548c Mish \u6fc0\u6d3b\u3002 \u6211\u4eec\u4f7f\u7528\u65b0\u529f\u80fd\uff1aWRC\u3001CSP\u3001CmBN\u3001SAT\u3001Mish \u6fc0\u6d3b\u3001Mosaic \u6570\u636e\u589e\u5f3a\u3001DropBlock \u6b63\u5219\u5316\u548c CIoU \u635f\u5931\uff0c\u5e76\u7ed3\u5408\u5176\u4e2d\u7684\u4e00\u4e9b\u6765\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff1a\u5728 Tesla V100 \u4e0a\u4ee5 ~65 FPS \u7684\u5b9e\u65f6\u901f\u5ea6\u7528\u4e8e MS COCO \u6570\u636e\u96c6\uff0c\u7ed3\u679c\u4e3a43.5% AP\uff0865.7 % AP50) \u3002 \u6e90\u4ee3\u7801\u4f4d\u4e8e https://github.com/AlexeyAB/darknet\u3002","title":"Abstract \u6458\u8981"},{"location":"thesis_interpretation/04_yolo.html#introduction","text":"The majority of CNN-based object detectors are largely applicable only for recommendation systems. For example, searching for free parking spaces via urban video cameras is executed by slow accurate models, whereas car collision warning is related to fast inaccurate models. Improving the real-time object detector accuracy enables using them not only for hint generating recommendation systems, but also for stand-alone process management and human input reduction. Real-time object detector operation on conven- tional Graphics Processing Units (GPU) allows their mass usage at an affordable price. The most accurate modern neural networks do not operate in real time and require large number of GPUs for training with a large mini-batch-size. We address such problems through creating a CNN that op- erates in real-time on a conventional GPU, and for which training requires only one conventional GPU. \u2003\u5927\u591a\u6570\u57fa\u4e8e CNN \u7684\u5bf9\u8c61\u68c0\u6d4b\u5668\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4ec5\u9002\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\uff08recommendation system\uff09\u3002 \u4f8b\u5982\uff0c\u901a\u8fc7\u57ce\u5e02\u6444\u50cf\u673a\u641c\u7d22\u514d\u8d39\u505c\u8f66\u4f4d\u662f\u7531\u6162\u901f\u51c6\u786e\u6a21\u578b\u6267\u884c\u7684\uff0c\u800c\u6c7d\u8f66\u78b0\u649e\u8b66\u544a\u4e0e\u5feb\u901f\u4e0d\u51c6\u786e\u6a21\u578b\u6709\u5173\u3002 \u63d0\u9ad8\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u4e0d\u4ec5\u53ef\u4ee5\u5c06\u5b83\u4eec\u7528\u4e8e\u63d0\u793a\u751f\u6210\u63a8\u8350\u7cfb\u7edf\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u72ec\u7acb\u6d41\u7a0b\u7ba1\u7406\uff08stand-alone process management\uff09\u548c\u51cf\u5c11\u4eba\u5de5\u8f93\u5165\u3002 \u4f20\u7edf\u56fe\u5f62\u5904\u7406\u5355\u5143 (GPU) \u4e0a\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u5668\u64cd\u4f5c\u5141\u8bb8\u4ee5\u5b9e\u60e0\u7684\u4ef7\u683c\u5927\u89c4\u6a21\u4f7f\u7528\u3002 \u6700\u7cbe\u786e\u7684\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u65e0\u6cd5\u5b9e\u65f6\u8fd0\u884c\uff0c\u5e76\u4e14\u9700\u8981\u5927\u91cf\u7684 GPU \u8fdb\u884c\u5927\u578b\u5c0f\u578b\u6279\u5904\u7406\u5927\u5c0f\u7684\u8bad\u7ec3\u3002\u6211\u4eec\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a\u5728\u4f20\u7edf GPU \u4e0a\u5b9e\u65f6\u8fd0\u884c\u7684 CNN \u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4e3a\u6b64\u8bad\u7ec3\u53ea\u9700\u8981\u4e00\u4e2a\u5e38\u89c4 GPU\u3002 Figure 1: Comparison of the proposed YOLOv4 and other state-of-the-art object detectors. YOLOv4 runs twice faster than EfficientDet with comparable performance. Improves YOLOv3\u2019s AP and FPS by 10% and 12%, respectively. \u56fe1\uff1a\u5bf9YOLOv4\u548c\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u8fdb\u884c\u6bd4\u8f83\u3002\u5177\u6709\u540c\u7b49\u7684\u6027\u80fd\u60c5\u51b5\u4e0b\uff0cYOLOv4\u7684\u901f\u5ea6\u662f EfficientDet \u7684\u4e24\u500d\u3002\u5e76\u4e14 YOLOv4 \u5c06YOLOv3 \u7684 AP \u548c FPS \u5206\u522b\u63d0\u9ad8\u4e86 10% \u548c 12%\u3002 \u2003The main goal of this work is designing a fast operating speed of an object detector in production systems and opti- mization for parallel computations, rather than the low com- putation volume theoretical indicator (BFLOP). We hope that the designed object can be easily trained and used. For example, anyone who uses a conventional GPU to train and test can achieve real-time, high quality, and convincing ob- ject detection results, as the YOLOv4 results shown in Fig- ure 1. Our contributions are summarized as follows: \u2003\u8fd9\u9879\u5de5\u4f5c\u7684\u4e3b\u8981\u76ee\u6807\u662f\u8bbe\u8ba1\u751f\u4ea7\u7cfb\u7edf\u4e2d\u8fd0\u884c\u901f\u5ea6\u8f83\u5feb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5e76\u4f18\u5316\u5e76\u884c\u8ba1\u7b97\uff0c\u800c\u4e0d\u662f\u4f4e\u8ba1\u7b97\u91cf\u7406\u8bba\u6307\u6807 \uff08BFLOP\uff09\u3002\u6211\u4eec\u5e0c\u671b\u8bbe\u8ba1\u7684\u68c0\u6d4b\u5668\u80fd\u591f\u8f7b\u677e\u8bad\u7ec3\u548c\u4f7f\u7528\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u4efb\u4f55\u4f20\u7edf GPU \u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7684\u4eba\u90fd\u53ef\u4ee5\u83b7\u5f97\u5b9e\u65f6\u3001\u9ad8\u8d28\u91cf\u548c\u4ee4\u4eba\u4fe1\u670d\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\uff0c\u5982\u56fe 1 \u6240\u793a\u7684 YOLOv4 \u7ed3\u679c\u6240\u793a\u3002\u6211\u4eec\u7684\u8d21\u732e\u603b\u7ed3\u5982\u4e0b\uff1a 1\uff09 We develope an efficient and powerful object detection model. It makes everyone can use a 1080 Ti or 2080 Ti GPU to train a super fast and accurate object detector. 1\uff09\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u9ad8\u6548\u800c\u5f3a\u5927\u7684\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u3002 \u5b83\u4f7f\u6bcf\u4e2a\u4eba\u90fd\u53ef\u4ee5\u4f7f\u7528 1080 Ti \u6216 2080 Ti GPU \u6765\u8bad\u7ec3\u4e00\u4e2a\u8d85\u5feb\u901f\u548c\u51c6\u786e\u7684\u76ee\u6807 \u68c0\u6d4b\u5668\u3002 2\uff09We verify the influence of state-of-the-art Bag-of- Freebies and Bag-of-Specials methods of object detec- tion during the detector training. 2\uff09\u5728\u68c0\u6d4b\u5668\u8bad\u7ec3\u671f\u95f4\uff0c\u6211\u4eec\u9a8c\u8bc1\u4e86\u6700\u5148\u8fdb\u7684 Bag-of-Freebies \u548c Bag-of-Specials \u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u7684\u5f71\u54cd\u3002 3\uff09We modify state-of-the-art methods and make them more effecient and suitable for single GPU training, including CBN [89], PAN [49], SAM [85], etc. 3\uff09\u6211\u4eec\u4fee\u6539\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u66f4\u6709\u6548\uff0c\u66f4\u9002\u5408\u5355 GPU \u8bad\u7ec3\uff0c\u65b9\u6cd5\u5305\u62ec CBN [89]\u3001PAN [49]\u3001SAM [85] \u7b49\u3002 \u56fe2\uff1a\u76ee\u6807\u68c0\u6d4b\u5668","title":"Introduction \u5f15\u8a00"},{"location":"thesis_interpretation/04_yolo.html#2-related-work","text":"","title":"2. Related work \u76f8\u5173\u5de5\u4f5c"},{"location":"thesis_interpretation/04_yolo.html#21-object-detection-models","text":"A modern detector is usually composed of two parts,a backbone which is pre-trained on ImageNet and a head which is used to predict classes and bounding boxes of objects.For those detectors running on GPU platform, their backbone could be VGG [68], ResNet [26], ResNeXt [86], or DenseNet [30]. For those detectors running on CPU platform, their backbone could be SqueezeNet [31], MobileNet [28, 66, 27, 74], or ShuffleNet [97, 53]. As to the head part, it is usually categorized into two kinds, i.e., one-stage object detector and two-stage object detector. The most representative two-stage object detector is the R-CNN [19] series, including fast R-CNN [18], faster R-CNN [64], R-FCN [9], and Libra R-CNN [58]. It is also possible to make a two- stage object detector an anchor-free object detector, such as RepPoints [87]. As for one-stage object detector, the most representative models are YOLO [61, 62, 63], SSD [50], and RetinaNet [45]. In recent years, anchor-free one-stage object detectors are developed. The detectors of this sort are CenterNet [13], CornerNet [37, 38], FCOS [78], etc. Object detectors developed in recent years often insert some layers between backbone and head, and these layers are usually used to collect feature maps from different stages. We can call it the neck of an object detector. Usually, a neck is composed of several bottom-up paths and several topdown paths. Networks equipped with this mechanism include Feature Pyramid Network (FPN) [44], Path Aggregation Network (PAN) [49], BiFPN [77], and NAS-FPN [17]. \u2003\u73b0\u4ee3\u68c0\u6d4b\u5668\u901a\u5e38\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u4e00\u4e2a\u662f\u5728 ImageNet \u4e0a\u9884\u5148\u8bad\u7ec3\u7684\u9aa8\u5e72\u7f51\uff0c\u53e6\u4e00\u4e2a\u662f\u7528\u4e8e\u9884\u6d4b\u7269\u4f53\u7684\u7c7b\u548c\u8fb9\u754c\u6846\u7684\u5934\u90e8\u3002\u5bf9\u4e8e\u5728 GPU \u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u4e3b\u5e72\u53ef\u4ee5\u662f VGG [68]\u3001ResNet [26]\u3001ResNeXt [86]\u6216DenseNet [30]\u3002\u5bf9\u4e8e\u5728 CPU \u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u4e3b\u5e72\u53ef\u4ee5\u662fSqueezeNet [31], MobileNet [28, 66, 27, 74], \u6216 ShuffleNet [97, 53].\u3002\u81f3\u4e8e\u5934\u90e8\u90e8\u5206\uff0c\u901a\u5e38\u5206\u4e3a\u4e24\u7c7b \uff0c \u5373\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u548c\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668 \u3002\u6700\u5177\u4ee3\u8868\u6027\u7684\u4e24\u7ea7\u76ee\u6807\u68c0\u6d4b\u5668\u662fR-CNN[19]\u7cfb\u5217\uff0c\u5305\u62ecfast R-CNN [18], faster R-CNN [64], R-FCN [9], \u548c Libra R-CNN [58] \u3002\u4e5f\u53ef\u4ee5\u4f7f\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u6210\u4e3a\u65e0\u951a\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5982 RepPoints [87]\u3002\u81f3\u4e8e\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u6700\u5177\u4ee3\u8868\u6027\u7684\u578b\u53f7\u662fYOLO[61\u300162\u300163]\u3001SSD[50]\u548cRetinaNet[45]\u3002\u8fd1\u5e74\u6765\uff0c\u7814\u5236\u4e86\u65e0\u951a\u5f0f\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u3002\u6b64\u7c7b\u68c0\u6d4b\u5668\u6709 CenterNet [13]\u3001CornerNet [37\u3001 38]\u3001FCOS [78]\u7b49\u3002\u8fd1\u5e74\u6765\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u7814\u53d1\u901a\u5e38\u662f\u5728\u9aa8\u5e72\u548c\u5934\u90e8\u4e4b\u95f4\u7684\u6dfb\u52a0\u4e00\u4e9b\u5c42\uff0c\u8fd9\u4e9b\u5c42\u901a\u5e38\u7528\u4e8e\u6536\u96c6\u4e0d\u540c\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u3002\u6211\u4eec\u53ef\u4ee5\u79f0\u5b83\u4e3a\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u8116\u5b50\u3002\u901a\u5e38\uff0c\u9888\u90e8\u7531\u51e0\u4e2a\u81ea\u4e0b\u800c\u4e0a\u7684\u8def\u5f84\u548c\u51e0\u4e2a\u81ea\u4e0a\u800c\u4e0b\u7684\u8def\u5f84\u7ec4\u6210\u3002\u914d\u5907\u6b64\u673a\u5236\u7684\u7f51\u7edc\u5305\u62ec\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc \uff08FPN\uff09 [44]\u3001\u8def\u5f84\u805a\u5408\u7f51\u7edc \uff08PAN\uff09 [49]\u3001BiFPN [77]\u548c NAS-FPN [17]\u3002 \u2003In addition to the above models, some researchers put their emphasis on directly building a new backbone (DetNet [43], DetNAS [7]) or a new whole model (SpineNet [12], HitDetector [20]) for object detection. \u2003\u9664\u4e86\u4e0a\u8ff0\u6a21\u578b\u5916\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u8fd8\u628a\u91cd\u70b9\u76f4\u63a5\u653e\u5728\u6784\u5efa\u4e00\u4e2a\u65b0\u7684\u4e3b\u5e72\uff08DetNet [43]\uff0cDetNAS [7]\uff09\u6216\u65b0\u7684\u5b8c\u6574\u6a21\u578b\uff08SpineNet [12]\uff0cHitDetector [20]\uff09\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u3002 \u2003To sum up, an ordinary object detector is composed of several parts: \u2003\u7efc\u4e0a\u6240\u8ff0\uff0c\u4e00\u4e2a\u666e\u901a\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u7531\u5982\u4e0b\u90e8\u5206\u7ec4\u6210\uff1a Input: Image, Patches, Image Pyramid Backbones: VGG16 [68], ResNet-50 [26], SpineNet [12], EfficientNet-B0/B7 [75], CSPResNeXt50 [81], CSPDarknet53 [81] Neck: Additional blocks: SPP [25], ASPP [5], RFB [47], SAM [85] Path-aggregation blocks: FPN [44], PAN [49], NAS-FPN [17], Fully-connected FPN, BiFPN [77], ASFF [48], SFAM [98] Heads: Dense Prediction (one-stage): RPN [64], SSD [50], YOLO [61], RetinaNet [45] (anchor based) CornerNet [37], CenterNet [13], MatrixNet [60], FCOS [78] (anchor free) Sparse Prediction (two-stage): Faster R-CNN [64], R-FCN [9], Mask R-CNN [23] (anchor based) RepPoints [87] (anchor free)","title":"2.1. Object detection models  \u76ee\u6807\u68c0\u6d4b\u6a21\u578b"},{"location":"thesis_interpretation/04_yolo.html#22-bag-of-freebies","text":"Usually, a conventional object detector is trained offline. Therefore, researchers always like to take this advantage and develop better training methods which can make the object detector receive better accuracy without increasing the inference cost. We call these methods that only change the training strategy or only increase the training cost as \u201cbag of freebies.\u201d What is often adopted by object detection methods and meets the definition of bag of freebies is data augmentation. The purpose of data augmentation is to increase the variability of the input images, so that the designed object detection model has higher robustness to the images obtained from different environments. For examples, photometric distortions and geometric distortions are two commonly used data augmentation method and they definitely benefit the object detection task. In dealing with photometric distortion, we adjust the brightness, contrast, hue, saturation, and noise of an image. For geometric distortion, we add random scaling, cropping, flipping, and rotating. \u2003\u901a\u5e38\uff0c\u4f20\u7edf\u7684\u7269\u4f53\u68c0\u6d4b\u5668\u662f\u79bb\u7ebf\u8bad\u7ec3\u7684\u3002 \u56e0\u6b64\uff0c\u7814\u7a76\u4eba\u5458\u603b\u662f\u559c\u6b22\u5229\u7528\u8fd9\u4e00\u4f18\u52bf\uff0c\u5f00\u53d1\u66f4\u597d\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u76ee\u6807\u68c0\u6d4b\u5668\u5728\u4e0d\u589e\u52a0\u63a8\u7406\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u66f4\u597d\u7684\u51c6\u786e\u6027\u3002\u6211\u4eec\u5c06\u8fd9\u4e9b\u53ea\u4f1a\u6539\u53d8\u8bad\u7ec3\u7b56\u7565\u6216\u53ea\u4f1a\u589e\u52a0\u8bad\u7ec3\u6210\u672c\u7684\u65b9\u6cd5\u79f0\u4e3a \u201cbag of freebies\u201d\u3002\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u7ecf\u5e38\u91c7\u7528\u4e14\u7b26\u5408bag of freebies \u5b9a\u4e49\u7684\u662f\u6570\u636e\u589e\u5f3a\uff08data augmentation\uff09\u3002\u6570\u636e\u589e\u5f3a\u7684\u76ee\u7684\u662f\u589e\u52a0\u8f93\u5165\u56fe\u50cf\u7684\u53ef\u53d8\u6027\uff08variability\uff09\uff0c\u4f7f\u8bbe\u8ba1\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u5bf9\u4e0d\u540c\u73af\u5883\u4e0b\u83b7\u5f97\u7684\u56fe\u50cf\u5177\u6709\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002\u4f8b\u5982\uff0c\u5149\u5ea6\u5931\u771f\uff08photometric distortion\uff09\u548c\u51e0\u4f55\u5931\u771f\uff08geometric distortion\uff09\u662f\u4e24\u79cd\u5e38\u7528\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b83\u4eec\u7edd\u5bf9\u6709\u5229\u4e8e\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u3002\u5728\u5904\u7406\u5149\u5ea6\u5931\u771f\u65f6\uff0c\u6211\u4eec\u8c03\u6574\u56fe\u50cf\u7684\u4eae\u5ea6\uff08brightness\uff09\u3001\u5bf9\u6bd4\u5ea6\uff08contrast\uff09\u3001\u8272\u8c03\uff08hue\uff09\u3001\u9971\u548c\u5ea6\uff08saturation\uff09\u548c\u566a\u58f0\uff08noise\uff09\u3002 \u5bf9\u4e8e\u51e0\u4f55\u5931\u771f\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u968f\u673a\u7f29\u653e\uff08random scale\uff09\u3001\u88c1\u526a\uff08crop\uff09\u3001\u7ffb\u8f6c\uff08flip\uff09\u548c\u65cb\u8f6c\uff08rotate\uff09\u3002 \u2003The data augmentation methods mentioned above are all pixel-wise adjustments, and all original pixel information in the adjusted area is retained. In addition, some researchers engaged in data augmentation put their emphasis on sim- ulating object occlusion issues. They have achieved good results in image classification and object detection. For ex- ample, random erase [100] and CutOut [11] can randomly select the rectangle region in an image and fill in a random or complementary value of zero. As for hide-and-seek [69] and grid mask [6], they randomly or evenly select multiple rectangle regions in an image and replace them to all ze- ros. If similar concepts are applied to feature maps, there are DropOut [71], DropConnect [80], and DropBlock [16] methods. In addition, some researchers have proposed the methods of using multiple images together to perform data augmentation. For example, MixUp [92] uses two images to multiply and superimpose with different coefficient ra- tios, and then adjusts the label with these superimposed ra- tios. As for CutMix [91], it is to cover the cropped image to rectangle region of other images, and adjusts the label according to the size of the mix area. In addition to the above mentioned methods, style transfer GAN [15] is also used for data augmentation, and such usage can effectively reduce the texture bias learned by CNN. \u2003\u4e0a\u9762\u63d0\u5230\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u90fd\u662f\u9010\u50cf\u7d20\uff08pixel-wise\uff09\u8c03\u6574\u7684\uff0c\u5e76\u4e14\u4fdd\u7559\u4e86\u8c03\u6574\u533a\u57df\u5185\u7684\u6240\u6709\u539f\u59cb\u50cf\u7d20\u4fe1\u606f\u3002 \u6b64\u5916\uff0c\u4e00\u4e9b\u4ece\u4e8b\u6570\u636e\u589e\u5f3a\u7684\u7814\u7a76\u4eba\u5458\u5c06\u91cd\u70b9\u653e\u5728\u6a21\u62df\u5bf9\u8c61\u906e\u6321\uff08occlusion\uff09\u95ee\u9898\u4e0a\u3002\u4ed6\u4eec\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u76ee\u6807\u68c0\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u5f88\u597d\u7684\u6548\u679c\u3002 \u4f8b\u5982\uff0c\u968f\u673a\u64e6\u9664[100]\u548cCutOut[11]\u53ef\u4ee5\u968f\u673a\u9009\u62e9\u56fe\u50cf\u4e2d\u7684\u77e9\u5f62\u533a\u57df\u5e76\u586b\u5145\u968f\u673a\u503c\u6216\u4e92\u8865\u503c\u96f6\uff08complementary value of zero\uff09\u3002\u81f3\u4e8e\u6349\u8ff7\u85cf\uff08hide-and-seek\uff09 [69] \u548c\u7f51\u683c\u8499\u7248\uff08grid mask\uff09 [6]\uff0c\u5b83\u4eec\u968f\u673a\u6216\u5747\u5300\u5730\u9009\u62e9\u56fe\u50cf\u4e2d\u7684\u591a\u4e2a\u77e9\u5f62\u533a\u57df\u5e76\u5c06\u5b83\u4eec\u5168\u66ff\u6362\u4e3a\u96f6\u3002 \u5982\u679c\u5c06\u7c7b\u4f3c\u7684\u6982\u5ff5\u5e94\u7528\u4e8e\u7279\u5f81\u56fe\uff0c\u5219\u6709 DropOut [71]\u3001DropConnect [80] \u548c DropBlock [16] \u65b9\u6cd5\u3002 \u6b64\u5916\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u5c06\u591a\u4e2a\u56fe\u50cf\u4e00\u8d77\u4f7f\u7528\u6765\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u65b9\u6cd5\u3002 \u4f8b\u5982\uff0cMixUp [92] \u4f7f\u7528\u4e24\u5e45\u56fe\u50cf\u6765\u4f7f\u4e0d\u540c\u7684\u7cfb\u6570\u6bd4\u4f8b\uff08coefficient ratio\uff09\u76f8\u4e58\u53e0\u52a0\uff08superimpose\uff09\uff0c\u7136\u540e\u7528\u8fd9\u4e9b\u53e0\u52a0\u6bd4\u4f8b\u8c03\u6574\u6807\u7b7e\u3002\u81f3\u4e8eCutMix [91]\uff0c\u5c31\u662f\u5c06\u88c1\u526a\u540e\u7684\u56fe\u50cf\u8986\u76d6\u5230\u5176\u4ed6\u56fe\u50cf\u7684\u77e9\u5f62\u533a\u57df\uff0c\u5e76\u6839\u636e\u6df7\u5408\u533a\u57df\u7684\u5927\u5c0f\u8c03\u6574\u6807\u7b7e\u3002 \u9664\u4e86\u4e0a\u8ff0\u65b9\u6cd5\u5916\uff0c\u98ce\u683c\u8fc1\u79fb GAN [15] \u4e5f\u88ab\u7528\u4e8e\u6570\u636e\u589e\u5f3a\uff0c\u8fd9\u79cd\u7528\u6cd5\u53ef\u4ee5\u6709\u6548\u51cf\u5c11 CNN \u5b66\u4e60\u5230\u7684\u7eb9\u7406\uff08texture\uff09\u504f\u5dee\u3002 \u2003Different from the various approaches proposed above, some other bag of freebies methods are dedicated to solving the problem that the semantic distribution in the dataset may have bias. In dealing with the problem of semantic distribution bias, a very important issue is that there is a problem of data imbalance between different classes, and this problem is often solved by hard negative example mining [72] or online hard example mining [67] in two-stage object detector. But the example mining method is not applicable to one-stage object detector, because this kind of detector belongs to the dense prediction architecture. Therefore Lin et al. [45] proposed focal loss to deal with the problem of data imbalance existing between various classes. Another very important issue is that it is difficult to express the relationship of the degree of association between different categories with the one-hot hard representation. This representation scheme is often used when executing labeling. The label smoothing proposed in [73] is to convert hard label into soft label for training, which can make model more robust. In order to obtain a better soft label, Islam et al. [33] introduced the concept of knowledge distillation to design the label refinement network. \u2003\u4e0e\u4e0a\u9762\u63d0\u51fa\u7684\u5404\u79cd\u65b9\u6cd5\u4e0d\u540c\uff0c\u5176\u4ed6\u4e00\u4e9bbag of freebies\u65b9\u6cd5\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3\u6570\u636e\u96c6\u4e2d\u8bed\u4e49\u5206\u5e03\uff08semantic distribution\uff09\u53ef\u80fd\u5b58\u5728\u504f\u5dee\u7684\u95ee\u9898\u3002\u5728\u5904\u7406\u8bed\u4e49\u5206\u5e03\u504f\u5dee\u95ee\u9898\u65f6\uff0c\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u662f\u4e0d\u540c\u7c7b\u4e4b\u95f4\u5b58\u5728\u6570\u636e\u4e0d\u5e73\u8861\uff08data imbalance\uff09\u7684\u95ee\u9898\u3002 \u8fd9\u4e2a\u95ee\u9898\u901a\u5e38\u901a\u8fc7\u4e24\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u4e2d\u7684\u786c\u53cd\u4f8b\u6316\u6398\uff08hard negative example mining\uff09[72]\u6216\u5728\u7ebf\u786c\u793a\u4f8b\u6316\u6398\uff08online hard example mining\uff09[67]\u6765\u89e3\u51b3\u3002 \u4f46\u662f\u793a\u4f8b\u6316\u6398\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u56e0\u4e3a\u8fd9\u79cd\u68c0\u6d4b\u5668\u5c5e\u4e8e\u5bc6\u96c6\u9884\u6d4b\u67b6\u6784\u3002\u56e0\u6b64 Lin \u7b49\u4eba [45] \u63d0\u51fa\u4e86focal loss \u6765\u5904\u7406\u5404\u4e2a\u7c7b\u4e4b\u95f4\u5b58\u5728\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002 \u53e6\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u95ee\u9898\u662f\uff0c\u4f7f\u7528one-hot hard\u8868\u793a\u5f88\u96be\u8868\u8fbe\u4e0d\u540c\u7c7b\u522b\u4e4b\u95f4\u7684\u5173\u8054\u7a0b\u5ea6\u7684\u5173\u7cfb\u3002 \u8fd9\u79cd\u8868\u793a\u65b9\u6848\u5728\u8fdb\u884c\u6807\u6ce8\u65f6\u7ecf\u5e38\u4f7f\u7528\u3002[73]\u4e2d\u63d0\u51fa\u7684\u6807\u7b7e\u5e73\u6ed1\uff08label smoothing\uff09\u662f\u5c06\u786c\u6807\u7b7e\uff08hard label\uff09\u8f6c\u6362\u4e3a\u8f6f\u6807\u7b7e\uff08soft label\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u4ee5\u4f7f\u6a21\u578b\u66f4\u52a0\u9c81\u68d2\u3002 \u4e3a\u4e86\u83b7\u5f97\u66f4\u597d\u7684\u8f6f\u6807\u7b7e\uff0cIslam\u7b49[33]\u5f15\u5165\u4e86\u77e5\u8bc6\u84b8\u998f\uff08knowledge distillation\uff09\u7684\u6982\u5ff5\u6765\u8bbe\u8ba1\u6807\u7b7e\u7ec6\u5316\u7f51\u7edc\uff08label refinement network\uff09\u3002 \u2003The last bag of freebies is the objective function of Bounding Box (BBox) regression. The traditional object detector usually uses Mean Square Error (MSE) to directly perform regression on the center point coordinates and height and width of the BBox, i.e., \\({x_{center}, y_{center}, w, h}\\) , or the upper left point and the lower right point, i.e., \\({x_{top-left}, y_{top-left}, x_{bottom-right}, y_{bottom-right} }\\) . As for anchor-based method, it is to estimate the corresponding offset, for example \\({x_{center-offset}, y_{center-offset},w_{offset}, h_{offset}}\\) and \\({x_{top-left-offset}, y_{top-left-offset},x_{bottom-right-offset}, y_{bottom-right-offset}}\\) . However, to directly estimate the coordinate values of each point of the BBox is to treat these points as independent variables, but in fact does not consider the integrity of the object itself. In order to make this issue processed better, some researchers recently proposed IoU loss [90], which puts the coverage of predicted BBox area and ground truth BBox area into consideration. The IoU loss computing process will trigger the calculation of the four coordinate points of the BBox by executing IoU with the ground truth, and then connecting the generated results into a whole code. Because IoU is a scale invariant representation, it can solve the problem that when traditional methods calculate the \\(l_1\\) or \\(l_2\\) loss of \\({x, y, w,h}\\) , the loss will increase with the scale. Recently, some researchers have continued to improve IoU loss. For example, GIoU loss [65] is to include the shape and orientation of object in addition to the coverage area. They proposed to find the smallest area BBox that can simultaneously cover the predicted BBox and ground truth BBox, and use this BBox as the denominator to replace the denominator originally used in IoU loss. As for DIoU loss [99], it additionally considers the distance of the center of an object, and CIoU loss [99], on the other hand simultaneously considers the overlapping area, the distance between center points, and the aspect ratio. CIoU can achieve better convergence speed and accuracy on the BBox regression problem. \u2003\u6700\u540e\u4e00\u4e9b bag of freebies \u662f\u8fb9\u754c\u6846 (BBox) \u56de\u5f52\u7684\u76ee\u6807\u51fd\u6570\u3002 \u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u901a\u5e38\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u76f4\u63a5\u5bf9BBox\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u8fdb\u884c\u56de\u5f52\uff0c\u5373 \\({x_{center}, y_{center},w, h}\\) \uff0c\u6216\u5de6\u4e0a\u70b9\u548c\u53f3\u4e0b\u70b9\uff0c\u5373 \\({x_{top-left}, y_{top-left}, x_{bottom-right}, y_{bottom-right} }\\) \u3002\u5bf9\u4e8eanchor-based\u65b9\u6cd5\uff0c\u5c31\u662f\u4f30\u8ba1\u5bf9\u5e94\u7684offset\uff0c\u4f8b\u5982 \\({x_{center-offset}, y_{center-offset},w_{offset}, h_{offset}}\\) \u548c \\({x_{top-left-offset}, y_{top-left-offset},x_{bottom-right-offset}, y_{bottom-right-offset}}\\) \u3002\u4f46\u662f\uff0c\u76f4\u63a5\u4f30\u8ba1BBox\u6bcf\u4e2a\u70b9\u7684\u5750\u6807\u503c\uff0c\u5c31\u662f\u628a\u8fd9\u4e9b\u70b9\u5f53\u6210\u81ea\u53d8\u91cf\uff08independent variable\uff09\uff0c\u5b9e\u9645\u4e0a\u5e76\u6ca1\u6709\u8003\u8651\u5bf9\u8c61\u672c\u8eab\u7684\u5b8c\u6574\u6027\u3002 \u4e3a\u4e86\u66f4\u597d\u5730\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff0c\u6700\u8fd1\u6709\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86 IoU loss [90]\uff0c\u5b83\u8003\u8651\u4e86\u9884\u6d4b BBox \u533a\u57df\u548c\u771f\u5b9eBBox \u533a\u57df\u7684\u8986\u76d6\u8303\u56f4\u3002IoU \u635f\u5931\u8ba1\u7b97\u8fc7\u7a0b\u901a\u8fc7\u4f7f\u7528\u771f\u5b9e\u503c\u8ba1\u7b97IoU \u6765\u89e6\u53d1BBox \u56db\u4e2a\u5750\u6807\u70b9\u7684\u8ba1\u7b97\uff0c\u7136\u540e\u5c06\u751f\u6210\u7684\u7ed3\u679c\u8fde\u63a5\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u4ee3\u7801\u3002\u7531\u4e8eIoU\u662f\u6bd4\u4f8b\u4e0d\u53d8\u7684\u8868\u793a\uff0c\u53ef\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97 \\({x,y,w,h}\\) \u7684 \\(l_1\\) \u6216 \\(l_2\\) \u635f\u5931\u65f6\uff0c\u635f\u5931\u4f1a\u968f\u7740\u6bd4\u4f8b\u589e\u52a0\u7684\u95ee\u9898\u3002\u6700\u8fd1\uff0c\u4e00\u4e9b\u7814\u7a76\u4eba\u5458\u7ee7\u7eed\u6539\u8fdb IoU \u635f\u5931\u3002\u4f8b\u5982\uff0cGIoU loss[65]\u9664\u4e86\u8986\u76d6\u533a\u57df\u5916\uff0c\u8fd8\u5305\u62ec\u7269\u4f53\u7684\u5f62\u72b6\u548c\u65b9\u5411\uff08orientation\uff09\u3002\u4ed6\u4eec\u63d0\u51fa\u5bfb\u627e\u53ef\u540c\u65f6\u8986\u76d6\u9884\u6d4bBBox\u548c\u771f\u5b9eBBox\u7684\u6700\u5c0f\u9762\u79efBBox\uff0c\u5e76\u7528\u8fd9\u4e2aBBox\u4f5c\u4e3a\u5206\u6bcd\uff08denominator\uff09\u6765\u4ee3\u66ff\u539f\u6765\u5728IoU loss\u4e2d\u4f7f\u7528\u7684\u5206\u6bcd\u3002\u81f3\u4e8eDIoU loss [99]\uff0c\u5b83\u989d\u5916\u8003\u8651\u4e86\u7269\u4f53\u4e2d\u5fc3\u7684\u8ddd\u79bb\uff0c\u800cCIoU loss [99]\uff0c\u53e6\u4e00\u65b9\u9762\u540c\u65f6\u8003\u8651\u4e86\u91cd\u53e0\u533a\u57df\u3001\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u548c\u5bbd\u9ad8\u6bd4\u3002CIoU \u5728 BBox \u56de\u5f52\u95ee\u9898\u4e0a\u53ef\u4ee5\u8fbe\u5230\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u7cbe\u5ea6\u3002","title":"2.2. Bag of freebies"},{"location":"thesis_interpretation/04_yolo.html#23-bag-of-specials","text":"For those plugin modules and post-processing methods that only increase the inference cost by a small amount but can significantly improve the accuracy of object detection, we call them \u201cbag of specials\u201d. Generally speaking, these plugin modules are for enhancing certain attributes in a model, such as enlarging receptive field, introducing attention mechanism, or strengthening feature integration capability, etc., and post-processing is a method for screening model prediction results. \u2003\u5bf9\u4e8e\u90a3\u4e9b\u53ea\u589e\u52a0\u5c11\u91cf\u63a8\u7406\u6210\u672c\u4f46\u53ef\u4ee5\u663e\u7740\u63d0\u9ad8\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u7684\u63d2\u4ef6\u6a21\u5757\uff08plugin module\uff09\u548c\u540e\u5904\u7406\uff08post-processing\uff09\u65b9\u6cd5\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a\u201cbag of specials\u201d\u3002 \u4e00\u822c\u6765\u8bf4\uff0c\u8fd9\u4e9b\u63d2\u4ef6\u6a21\u5757\u662f\u4e3a\u4e86\u589e\u5f3a\u6a21\u578b\u4e2d\u7684\u67d0\u4e9b\u5c5e\u6027\uff08attribute\uff09\uff0c\u6bd4\u5982\u6269\u5927\u611f\u53d7\u91ce\uff08receptive field\uff09\u3001\u5f15\u5165\u6ce8\u610f\u529b\u673a\u5236\uff08attention mechanism\uff09\u3001\u6216\u8005\u52a0\u5f3a\u7279\u5f81\u6574\u5408\uff08integration\uff09\u80fd\u529b\u7b49\uff0c\u540e\u5904\u7406\u662f\u4e00\u79cd\u7b5b\u9009\uff08screen\uff09\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u65b9\u6cd5\u3002 \u2003Common modules that can be used to enhance receptive field are SPP [25], ASPP [5], and RFB [47]. The SPP module was originated from Spatial Pyramid Matching (SPM) [39], and SPMs original method was to split feature map into several d \u00d7 d equal blocks, where d can be \\({1, 2, 3, ...}\\) , thus forming spatial pyramid, and then extracting bag-of-word features. SPP integrates SPM into CNN and use max-pooling operation instead of bag-of-word operation. Since the SPP module proposed by He et al. [25] will output one dimensional feature vector, it is infeasible to be applied in Fully Convolutional Network (FCN). Thus in the design of YOLOv3 [63], Redmon and Farhadi improve SPP module to the concatenation of max-pooling outputs with kernel size \\(k \u00d7 k\\) , where \\(k = {1, 5, 9, 13}\\) , and stride equals to 1. Under this design, a relatively large k \u00d7 k maxpooling effectively increase the receptive field of backbone feature. After adding the improved version of SPP module, YOLOv3-608 upgrades AP50 by 2.7% on the MS COCO object detection task at the cost of 0.5% extra computation. The difference in operation between ASPP [5] module and improved SPP module is mainly from the original k\u00d7k kernel size, max-pooling of stride equals to 1 to several \\(3 \u00d7 3\\) kernel size, dilated ratio equals to k, and stride equals to 1 in dilated convolution operation. RFB module is to use several dilated convolutions of k\u00d7k kernel, dilated ratio equals to k, and stride equals to 1 to obtain a more comprehensive spatial coverage than ASPP . RFB [47] only costs 7% extra inference time to increase the AP50 of SSD on MS COCO by 5.7%. \u2003\u53ef\u7528\u4e8e\u589e\u5f3a\u611f\u53d7\u91ce\u7684\u5e38\u89c1\u6a21\u5757\u6709 SPP [25]\u3001ASPP [5] \u548c RFB [47]\u3002SPP\u6a21\u5757\u8d77\u6e90\u4e8eSpatial Pyramid Matching\uff08SPM\uff09[39]\uff0cSPM\u7684\u539f\u59cb\u65b9\u6cd5\u662f\u5c06\u7279\u5f81\u56fe\u5206\u5272\u6210\u51e0\u4e2a \\(d \u00d7 d\\) \u76f8\u7b49\u7684\u5757\uff0c\u5176\u4e2d \\(d\\) \u53ef\u4ee5\u662f \\({1, 2, 3, ...}\\) \uff0c\u56e0\u6b64\u5f62\u6210\u7a7a\u95f4\u91d1\u5b57\u5854\uff0c\u7136\u540e\u63d0\u53d6\u8bcd\u888b\uff08bag-of-word\uff09\u7279\u5f81\u3002SPP \u5c06 SPM \u96c6\u6210\u5230 CNN \u4e2d\u5e76\u4f7f\u7528\u6700\u5927\u6c60\u5316\u64cd\u4f5c\u800c\u4e0d\u662f\u8bcd\u888b\u64cd\u4f5c\u3002\u7531\u4e8eHe\u7b49\u4eba[25]\u63d0\u51fa\u7684SPP\u6a21\u5757\u4f1a\u8f93\u51fa\u4e00\u7ef4\u7279\u5f81\u5411\u91cf\uff0c\u56e0\u6b64\u4e0d\u9002\u7528\u4e8e\u5168\u5377\u79ef\u7f51\u7edc\uff08FCN\uff09\u3002\u56e0\u6b64\uff0c\u5728 YOLOv3 [63] \u7684\u8bbe\u8ba1\u4e2d\uff0cRedmon \u548c Farhadi \u5c06 SPP \u6a21\u5757\u6539\u8fdb\u4e3a \u5185\u6838\u5927\u5c0f\u4e3a \\(k \u00d7 k\\) \u7684\u6700\u5927\u6c60\u5316\u8f93\u51fa\u7684\u4e32\u8054\uff0c\u5176\u4e2d \\(k = {1, 5, 9, 13}\\) \uff0c\u6b65\u5e45\u7b49\u4e8e 1\u3002 \u5728\u8fd9\u79cd\u8bbe\u8ba1\u4e0b\uff0c\u76f8\u5bf9\u8f83\u5927\u7684 \\(k \u00d7 k\\) \u6700\u5927\u6c60\u5316\u6709\u6548\u5730\u589e\u52a0\u4e86\u4e3b\u5e72\uff08backbone\uff09\u7279\u5f81\u7684\u611f\u53d7\u91ce\u3002\u6dfb\u52a0\u6539\u8fdb\u7248SPP\u6a21\u5757\u540e\uff0cYOLOv3-608\u5728MS COCO\u7269\u4f53\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4ee50.5%\u7684\u989d\u5916\u8ba1\u7b97\u4e3a\u4ee3\u4ef7\u5c06AP50\u63d0\u5347\u4e862.7%\u3002ASPP [5] \u6a21\u5757\u548c\u6539\u8fdb\u7684 SPP \u6a21\u5757\u5728\u64cd\u4f5c\u4e0a\u7684\u533a\u522b\u4e3b\u8981\u662f\u539f\u59cb\u7684 \\(k\u00d7k\\) \u6838\u5927\u5c0f\uff0c\u6700\u5927\u6c60\u5316\u7684\u6b65\u5e45\u7b49\u4e8e1 \u5230\u51e0\u4e2a \\(3\u00d73\\) \u6838\u5927\u5c0f\uff0c\u6269\u5f20\u6bd4\uff08dilated ratio\uff09\u7b49\u4e8e k\uff0c\u5728\u6269\u5f20\u5377\u79ef\uff08dilated convolution\uff09\u64cd\u4f5c\u4e2d\u6b65\u5e45\u7b49\u4e8e 1\u3002RFB\u6a21\u5757\u662f\u4f7f\u7528\u51e0\u4e2ak\u00d7k\u6838\u7684\u6269\u5f20\u5377\u79ef\uff0c\u6269\u5f20\u6bd4\u7b49\u4e8ek\uff0c\u6b65\u5e45\u7b49\u4e8e1\uff0c\u4ee5\u83b7\u5f97\u6bd4ASPP\u66f4\u5168\u9762\u7684\u7a7a\u95f4\u8986\u76d6\u3002RFB [47] \u4ec5\u82b1\u8d39 7% \u7684\u989d\u5916\u63a8\u7406\u65f6\u95f4\u5373\u53ef\u5bf9 MS COCO \u4e0a SSD \u7684 AP50 \u63d0\u9ad8 5.7%\u3002 \u2003The attention module that is often used in object detection is mainly divided into channel-wise attention and point-wise attention, and the representatives of these two attention models are Squeeze-and-Excitation (SE) [29] and Spatial Attention Module (SAM) [85], respectively. Although SE module can improve the power of ResNet50 in the ImageNet image classification task 1% top-1 accuracy at the cost of only increasing the computational effort by 2%, but on a GPU usually it will increase the inference time by about 10%, so it is more appropriate to be used in mobile devices. But for SAM, it only needs to pay 0.1% extra calculation and it can improve ResNet50-SE 0.5% top-1 accuracy on the ImageNet image classification task. Best of all, it does not affect the speed of inference on the GPU at all. \u2003\u76ee\u6807\u68c0\u6d4b\u4e2d\u7ecf\u5e38\u4f7f\u7528\u7684\u6ce8\u610f\u529b\u6a21\u5757\uff08attention module\uff09\u4e3b\u8981\u5206\u4e3a\u9010\u901a\u9053\u6ce8\u610f\u529b\uff08channel-wise attention\uff09\u548c\u9010\u70b9\u6ce8\u610f\u529b\uff08point-wise attention\uff09\uff0c\u8fd9\u4e24\u79cd\u6ce8\u610f\u529b\u6a21\u578b\u7684\u4ee3\u8868\u5206\u522b\u662fSqueeze-and-Excitation\uff08SE\uff09[29]\u548cSpatial Attention Module\uff08SAM\uff09[85]\u3002\u867d\u7136 SE \u6a21\u5757\u53ef\u4ee5\u5c06 ResNet50 \u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u63d0\u9ad8 1% \\(top-1\\) \u51c6\u786e\u7387\uff0c\u4ee3\u4ef7\u662f\u53ea\u589e\u52a0 2% \u7684\u8ba1\u7b97\u91cf\uff0c\u4f46\u5728 GPU \u4e0a\u901a\u5e38\u4f1a\u589e\u52a0\u5927\u7ea6 10% \u7684\u63a8\u7406\u65f6\u95f4\uff0c \u6240\u4ee5\u66f4\u9002\u5408\u7528\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u3002\u4f46\u5bf9\u4e8e SAM \u6765\u8bf4\uff0c\u5b83\u53ea\u9700\u8981\u989d\u5916\u4ed8\u51fa 0.1% \u7684\u8ba1\u7b97\uff0c\u5c31\u53ef\u4ee5\u5c06 ResNet50-SE \u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684 \\(top-1\\) \u51c6\u786e\u7387\u63d0\u9ad8 0.5%\u3002 \u6700\u91cd\u8981\u7684\u662f\uff0c\u5b83\u4e0d\u4f1a\u5f71\u54cd GPU \u4e0a\u7684\u63a8\u7406\u901f\u5ea6\u3002 \u2003In terms of feature integration, the early practice is to use skip connection [51] or hyper-column [22] to integrate low- level physical feature to high-level semantic feature. Since multi-scale prediction methods such as FPN have become popular, many lightweight modules that integrate different feature pyramid have been proposed. The modules of this sort include SFAM [98], ASFF [48], and BiFPN [77]. The main idea of SFAM is to use SE module to execute channel- wise level re-weighting on multi-scale concatenated feature maps. As for ASFF, it uses softmax as point-wise level re- weighting and then adds feature maps of different scales. In BiFPN, the multi-input weighted residual connections is proposed to execute scale-wise level re-weighting, and then add feature maps of different scales. \u2003\u5728\u7279\u5f81\u6574\u5408\uff08feature integration\uff09\u65b9\u9762\uff0c\u65e9\u671f\u7684\u505a\u6cd5\u662f\u4f7f\u7528\u8df3\u8fc7\u8fde\u63a5\uff08skip connection\uff09[51]\u6216\u8d85\u5217\uff08hyper-column\uff09[22]\u5c06\u4f4e\u7ea7\u7269\u7406\u7279\u5f81\u6574\u5408\u5230\u9ad8\u7ea7\u8bed\u4e49\u7279\u5f81\uff08semantic feature\uff09\u3002 \u968f\u7740FPN\u7b49\u591a\u6bd4\u4f8b\uff08multi-scale\uff09\u9884\u6d4b\u65b9\u6cd5\u7684\u6d41\u884c\uff0c\u8bb8\u591a\u96c6\u6210\u4e0d\u540c\u7279\u5f81\u91d1\u5b57\u5854\u7684\u8f7b\u91cf\u7ea7\u6a21\u5757\u88ab\u63d0\u51fa\u3002 \u8fd9\u7c7b\u6a21\u5757\u5305\u62ec SFAM [98]\u3001ASFF [48] \u548c BiFPN [77]\u3002 SFAM \u7684\u4e3b\u8981\u601d\u60f3\u662f\u4f7f\u7528 SE \u6a21\u5757\u5728\u591a\u6bd4\u4f8b\u7ea7\u8054\uff08multi-scale concatenated\uff09\u7279\u5f81\u56fe\u4e0a\u6267\u884c\u9010\u901a\u9053\u6c34\u5e73\u7684\u91cd\u65b0\u52a0\u6743\uff08channel-wise level re-weighting\uff09\u3002 \u81f3\u4e8eASFF\uff0c\u5b83\u4f7f\u7528softmax\u4f5c\u4e3a\u9010\u70b9\u7ea7\u91cd\u52a0\u6743\uff08point-wise level re-weighting\uff09\uff0c\u7136\u540e\u6dfb\u52a0\u4e0d\u540c\u6bd4\u4f8b\u7684\u7279\u5f81\u56fe\u3002 \u5728 BiFPN \u4e2d\uff0c\u63d0\u51fa\u4e86\u4f7f\u7528\u591a\u8f93\u5165\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\uff08multi-input weighted residual connections\uff09\u6765\u6267\u884c\u6309\u5c3a\u5ea6\u7ea7\u522b\u91cd\u65b0\u52a0\u6743\uff08scale-wise level re-weighting\uff09\uff0c\u7136\u540e\u6dfb\u52a0\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u3002 \u2003In the research of deep learning, some people put their focus on searching for good activation function. A good activation function can make the gradient more efficiently propagated, and at the same time it will not cause too much extra computational cost. In 2010, Nair and Hin- ton [56] propose ReLU to substantially solve the gradient vanish problem which is frequently encountered in tradi- tional tanh and sigmoid activation function. Subsequently, LReLU [54], PReLU [24], ReLU6 [28], Scaled Exponential Linear Unit (SELU) [35], Swish [59], hard-Swish [27], and Mish [55], etc., which are also used to solve the gradient vanish problem, have been proposed. The main purpose of LReLU and PReLU is to solve the problem that the gradi- ent of ReLU is zero when the output is less than zero. As for ReLU6 and hard-Swish, they are specially designed for quantization networks. For self-normalizing a neural net- work, the SELU activation function is proposed to satisfy the goal. One thing to be noted is that both Swish and Mish are continuously differentiable activation function. \u2003\u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\u4e2d\uff0c\u6709\u4eba\u628a\u91cd\u70b9\u653e\u5728\u5bfb\u627e\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u4e0a\u3002\u4e00\u4e2a\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u53ef\u4ee5\u8ba9\u68af\u5ea6\u66f4\u6709\u6548\u5730\u4f20\u64ad\uff0c\u540c\u65f6\u4e0d\u4f1a\u9020\u6210\u592a\u591a\u989d\u5916\u7684\u8ba1\u7b97\u6210\u672c\u30022010 \u5e74\uff0cNair \u548c Hinton [56] \u63d0\u51fa ReLU \u6765\u5b9e\u8d28\u6027\u5730\u89e3\u51b3\u4f20\u7edf tanh \u548c sigmoid \u6fc0\u6d3b\u51fd\u6570\u4e2d\u7ecf\u5e38\u9047\u5230\u7684\u68af\u5ea6\u6d88\u5931\uff08gradient vanish\uff09\u95ee\u9898\u3002\u968f\u540e\uff0cLReLU [54]\u3001PReLU [24]\u3001ReLU6 [28]\u3001Scaled Exponential Linear Unit (SELU) [35]\u3001Swish [59]\u3001hard-Swish [27] \u548c Mish [55] \u7b49\u88ab\u63d0\u51fa\uff0c\u4e5f\u7528\u4e8e\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002LReLU\u548cPReLU\u7684\u4e3b\u8981\u76ee\u7684\u662f\u89e3\u51b3\u8f93\u51fa\u5c0f\u4e8e\u96f6\u65f6ReLU\u68af\u5ea6\u4e3a\u96f6\u7684\u95ee\u9898\u3002\u81f3\u4e8e ReLU6 \u548c hard-Swish\uff0c\u5b83\u4eec\u662f\u4e13\u95e8\u4e3a\u91cf\u5316\uff08quantization\uff09\u7f51\u7edc\u8bbe\u8ba1\u7684\u3002\u4e3a\u4e86\u81ea\u5f52\u4e00\u5316\uff08self-normalize\uff09\u795e\u7ecf\u7f51\u7edc\uff0cSELU \u6fc0\u6d3b\u51fd\u6570\u88ab\u63d0\u51fa\u4ee5\u5b9e\u73b0\u8be5\u76ee\u6807\u3002\u9700\u8981\u6ce8\u610f\u7684\u4e00\u4ef6\u4e8b\u662f Swish \u548c Mish \u90fd\u662f\u8fde\u7eed\u53ef\u5fae\uff08continuously differentiable\uff09\u7684\u6fc0\u6d3b\u51fd\u6570\u3002 \u2003The post-processing method commonly used in deep- learning-based object detection is NMS, which can be used to filter those BBoxes that badly predict the same ob- ject, and only retain the candidate BBoxes with higher re- sponse. The way NMS tries to improve is consistent with the method of optimizing an objective function. The orig- inal method proposed by NMS does not consider the con- text information, so Girshick et al. [19] added classification confidence score in R-CNN as a reference, and according to the order of confidence score, greedy NMS was performed in the order of high score to low score. As for soft NMS [1], it considers the problem that the occlusion of an object may cause the degradation of confidence score in greedy NMS with IoU score. The DIoU NMS [99] developers way of thinking is to add the information of the center point dis- tance to the BBox screening process on the basis of soft NMS. It is worth mentioning that, since none of above post- processing methods directly refer to the captured image fea- tures, post-processing is no longer required in the subse- quent development of an anchor-free method. \u2003\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7269\u4f53\u68c0\u6d4b\u5e38\u7528\u7684\u540e\u5904\u7406\uff08post-processing\uff09\u65b9\u6cd5\u662fNMS\uff0c\u5b83\u53ef\u4ee5\u7528\u6765\u8fc7\u6ee4\u90a3\u4e9b\u5bf9\u540c\u4e00\u7269\u4f53\u9884\u6d4b\u4e0d\u597d\u7684BBox\uff0c\u53ea\u4fdd\u7559\u54cd\u5e94\u8f83\u9ad8\u7684\u5019\u9009BBox\u3002NMS \u5c1d\u8bd5\u6539\u8fdb\u7684\u65b9\u5f0f\u4e0e\u4f18\u5316\u76ee\u6807\u51fd\u6570\u7684\u65b9\u6cd5\u4e00\u81f4\u3002 NMS \u63d0\u51fa\u7684\u539f\u59cb\u65b9\u6cd5\u6ca1\u6709\u8003\u8651\u4e0a\u4e0b\u6587\uff08context\uff09\u4fe1\u606f\uff0c\u56e0\u6b64 Girshick \u7b49\u4eba [19] \u5728 R-CNN \u4e2d\u6dfb\u52a0\u4e86\u5206\u7c7b\u7f6e\u4fe1\u5ea6\uff08classification confidence score\uff09\u5206\u6570\u4f5c\u4e3a\u53c2\u8003\uff0c\u5e76\u6309\u7167\u7f6e\u4fe1\u5ea6\u5f97\u5206\u7684\u987a\u5e8f\uff0c\u4ece\u9ad8\u5206\u5230\u4f4e\u5206\u7684\u987a\u5e8f\u8fdb\u884c\u8d2a\u5a6a\uff08greedy\uff09NMS\u3002\u5bf9\u4e8e soft NMS [1]\uff0c\u5b83\u8003\u8651\u4e86\u5728\u5177\u6709 IoU \u5206\u6570\u7684 greedy NMS \u4e2d\u5bf9\u8c61\u7684\u906e\u6321\uff08occlusion\uff09\u53ef\u80fd\u5bfc\u81f4\u7f6e\u4fe1\u5ea6\u4e0b\u964d\u7684\u95ee\u9898\u3002 DIoU NMS [99] \u5f00\u53d1\u8005\u7684\u601d\u8def\u662f\u5728\u8f6f NMS \u7684\u57fa\u7840\u4e0a\uff0c\u5728 BBox \u7b5b\u9009\uff08screen\uff09\u8fc7\u7a0b\u4e2d\u52a0\u5165\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u4fe1\u606f\u3002 \u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u7531\u4e8e\u4e0a\u8ff0\u540e\u5904\u7406\u65b9\u6cd5\u90fd\u6ca1\u6709\u76f4\u63a5\u53c2\u8003\u6355\u83b7\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u56e0\u6b64\u5728\u540e\u7eed\u5f00\u53d1anchor-free\u65b9\u6cd5\u65f6\u4e0d\u518d\u9700\u8981\u8fdb\u884c\u540e\u5904\u7406\u3002","title":"2.3. Bag of specials"},{"location":"thesis_interpretation/04_yolo.html#3-methodology","text":"The basic aim is fast operating speed of neural network, in production systems and optimization for parallel compu- tations, rather than the low computation volume theoreti- cal indicator (BFLOP). We present two options of real-time neural networks: \u2003\u57fa\u672c\u76ee\u6807\u662f\u795e\u7ecf\u7f51\u7edc\u5728\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u5feb\u901f\u8fd0\u884c\u548c\u5e76\u884c\u8ba1\u7b97\uff08parallel computation\uff09\u7684\u4f18\u5316\uff0c\u800c\u4e0d\u662f\u4f4e\u8ba1\u7b97\u91cf\u7406\u8bba\u6307\u6807\uff08low computation volume theoretical indicator\uff09\uff08BFLOP\uff09\u3002 \u6211\u4eec\u63d0\u4f9b\u4e86\u4e24\u79cd\u5b9e\u65f6\u795e\u7ecf\u7f51\u7edc\u9009\u9879\uff1a For GPU we use a small number of groups (1 - 8) in convolutional layers: CSPResNeXt50 / CSPDarknet53 \u5bf9\u4e8e GPU\uff0c\u6211\u4eec\u5728\u5377\u79ef\u5c42\u4e2d\u4f7f\u7528\u5c11\u91cf\u7ec4 (1 - 8)\uff1aCSPResNeXt50 / CSPDarknet53 For VPU - we use grouped-convolution, but we refrain from using Squeeze-and-excitement (SE) blocks specifically this includes the following models: EfficientNet-lite / MixNet [76] / GhostNet [21] / Mo-bileNetV3 \u5bf9\u4e8e VPU - \u6211\u4eec\u4f7f\u7528\u5206\u7ec4\u5377\u79ef\uff0c\u4f46\u6211\u4eec\u907f\u514d\u4f7f\u7528 Squeeze-and-excitement (SE) \u5757 , - \u5177\u4f53\u5305\u62ec\u6a21\u578b\uff1aEfficientNet-lite / MixNet [76] / GhostNet [21] / MobileNetV3","title":"3. Methodology \u65b9\u6cd5\u8bba"},{"location":"thesis_interpretation/04_yolo.html#31-selection-of-architecture","text":"Our objective is to find the optimal balance among the in- put network resolution, the convolutional layer number, the parameter number \\((filter size^2 * filters * channel / groups)\\) , and the number of layer outputs (filters). For instance, our numerous studies demonstrate that the CSPResNext50 is considerably better compared to CSPDarknet53 in terms of object classification on the ILSVRC2012 (ImageNet) dataset [10]. However, conversely, the CSPDarknet53 is better compared to CSPResNext50 in terms of detecting ob- jects on the MS COCO dataset [46]. \u2003\u6211\u4eec\u7684\u76ee\u6807\u662f\u5728\u8f93\u5165\u7f51\u7edc\u5206\u8fa8\u7387\u3001\u5377\u79ef\u5c42\u6570\u3001\u53c2\u6570\u6570\u91cf \\((filter size^2 * filters * channel / groups)\\) \u548c\u5c42\u8f93\u51fa\u6570\uff08\u8fc7\u6ee4\u5668\uff09\u4e4b\u95f4\u627e\u5230\u6700\u4f73\u5e73\u8861\u3002 \u4f8b\u5982\uff0c\u6211\u4eec\u7684\u5927\u91cf\u7814\u7a76\u8868\u660e\uff0c\u5728 ILSVRC2012 (ImageNet) \u6570\u636e\u96c6 [10] \u4e0a\u7684\u5bf9\u8c61\u5206\u7c7b\u65b9\u9762\uff0cCSPResNext50 \u4e0e CSPDarknet53 \u76f8\u6bd4\u8981\u597d\u5f97\u591a\u3002 \u7136\u800c\uff0c\u76f8\u53cd\uff0c\u5728 MS COCO \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0cCSPDarknet53 \u6bd4 CSPResNext50 \u66f4\u597d [46]\u3002 \u2003The next objective is to select additional blocks for increasing the receptive field and the best method of parameter aggregation from different backbone levels for different detector levels: e.g. FPN, PAN, ASFF, BiFPN. \u2003\u4e0b\u4e00\u4e2a\u76ee\u6807\u662f\u9009\u62e9\u989d\u5916\u7684\u5757\u6765\u589e\u52a0\u611f\u53d7\u91ce\uff0c\u4ee5\u53ca\u4ece\u4e0d\u540c\u7684\u4e3b\u5e72\u7ea7\u522b\u4e3a\u4e0d\u540c\u7684\u68c0\u6d4b\u5668\u7ea7\u522b\u9009\u62e9\u53c2\u6570\u805a\u5408\uff08parameter aggregation\uff09\u7684\u6700\u4f73\u65b9\u6cd5\uff1a\u4f8b\u5982 FPN\u3001PAN\u3001ASFF\u3001BiFPN\u3002 \u2003A reference model which is optimal for classification is not always optimal for a detector. In contrast to the classifier, the detector requires the following: \u2003\u5bf9\u4e8e\u5206\u7c7b\u800c\u8a00\u6700\u4f73\u7684\u53c2\u8003\u6a21\u578b\u5bf9\u4e8e\u68c0\u6d4b\u5668\u800c\u8a00\u5e76\u4e0d\u603b\u662f\u6700\u4f73\u7684\u3002 \u4e0e\u5206\u7c7b\u5668\u76f8\u6bd4\uff0c\u68c0\u6d4b\u5668\u9700\u8981\u4ee5\u4e0b\u5185\u5bb9\uff1a Higher input network size (resolution) \u2013 for detecting multiple small-sized objects \u66f4\u9ad8\u7684\u8f93\u5165\u7f51\u7edc\u5c3a\u5bf8\uff08\u5206\u8fa8\u7387\uff09\u2014\u2014 \u7528\u4e8e\u68c0\u6d4b\u591a\u4e2a\u5c0f\u5c3a\u5bf8\u7269\u4f53 More layers \u2013 for a higher receptive field to cover the increased size of input network \u66f4\u591a\u5c42\u2014\u2014\u7528\u4e8e\u66f4\u9ad8\u7684\u611f\u53d7\u91ce\u4ee5\u8986\u76d6\u589e\u52a0\u7684\u8f93\u5165\u7f51\u7edc\u5927\u5c0f More parameters \u2013 for greater capacity of a model to detect multiple objects of different sizes in a single im- age \u66f4\u591a\u53c2\u6570\u2014\u2014\u4f7f\u6a21\u578b\u6709\u66f4\u5927\u7684\u80fd\u529b\u5728\u5355\u4e2a\u56fe\u50cf\u4e2d\u68c0\u6d4b\u591a\u4e2a\u4e0d\u540c\u5927\u5c0f\u7684\u5bf9\u8c61 \\(\\text { \u8868 1: \u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u3002 }\\) \u2003Hypothetically speaking, we can assume that a model with a larger receptive field size (with a larger number of convolutional layers \\(3 \u00d7 3\\) ) and a larger number of parameters should be selected as the backbone. Table 1 shows the information of CSPResNeXt50, CSPDarknet53, and EfficientNet B3. The CSPResNext50 contains only 16 convolutional layers \\(3 \u00d7 3\\) , a \\(425 \u00d7 425\\) receptive field and 20.6 M parameters, while CSPDarknet53 contains 29 convolu- tional layers \\(3 \u00d7 3\\) , a \\(725 \u00d7 725\\) receptive field and 27.6 M parameters. This theoretical justification, together with our numerous experiments, show that CSPDarknet53 neural network is the optimal model of the two as the backbone for a detector. \u2003\u5047\u8bbe\u5730\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u5047\u8bbe\u5e94\u8be5\u9009\u62e9\u5177\u6709\u66f4\u5927\u611f\u53d7\u91ce\u5927\u5c0f\uff08\u5177\u6709\u66f4\u591a\u5377\u79ef\u5c42 3 \u00d7 3\uff09\u548c\u66f4\u591a\u53c2\u6570\u7684\u6a21\u578b\u4f5c\u4e3a\u4e3b\u5e72\u3002 \u8868 1 \u663e\u793a\u4e86 CSPResNeXt50\u3001CSPDarknet53 \u548c EfficientNet B3 \u7684\u4fe1\u606f\u3002 CSPResNext50 \u4ec5\u5305\u542b 16 \u4e2a 3 \u00d7 3 \u5377\u79ef\u5c42\u3001425 \u00d7 425 \u611f\u53d7\u91ce\u548c 20.6 M \u53c2\u6570\uff0c\u800c CSPDarknet53 \u5305\u542b 29 \u4e2a\u5377\u79ef\u5c42 3 \u00d7 3\u3001725 \u00d7 725 \u611f\u53d7\u91ce\u548c 27.6 M \u53c2\u6570\u3002 \u8fd9\u4e2a\u7406\u8bba\u8bc1\u660e\uff0c\u52a0\u4e0a\u6211\u4eec\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u8868\u660e CSPDarknet53 \u795e\u7ecf\u7f51\u7edc\u662f\u4e24\u8005\u7684\u6700\u4f73\u6a21\u578b\uff0c\u4f5c\u4e3a\u68c0\u6d4b\u5668\u7684\u4e3b\u5e72\u3002 \u2003The influence of the receptive field with different sizes is summarized as follows: \u2003\u4e0d\u540c\u5927\u5c0f\u7684\u611f\u53d7\u91ce\u7684\u5f71\u54cd\u603b\u7ed3\u5982\u4e0b: Up to the object size - allows viewing the entire object \u6700\u591a\u5230\u5bf9\u8c61\u5927\u5c0f \u2013 \u5141\u8bb8\u67e5\u770b\u6574\u4e2a\u5bf9\u8c61 Up to network size - allows viewing the context around the object \u6700\u591a\u7f51\u7edc\u5927\u5c0f \u2013 \u5141\u8bb8\u67e5\u770b\u5bf9\u8c61\u5468\u56f4\u7684\u4e0a\u4e0b\u6587 Exceeding the network size - increases the number of connections between the image point and the final activation \u8d85\u8fc7\u7f51\u7edc\u5927\u5c0f \u2013 \u589e\u52a0\u56fe\u50cf\u70b9\u548c\u6700\u7ec8\u6fc0\u6d3b\u4e4b\u95f4\u7684\u8fde\u63a5\u6570 \u2003 We add the SPP block over the CSPDarknet53, since it significantly increases the receptive field, separates out the most significant context features and causes almost no reduction of the network operation speed. We use PANet as the method of parameter aggregation from different backbone levels for different detector levels, instead of the FPN used in YOLOv3. \u2003\u6211\u4eec\u5728 CSPDarknet53 \u4e0a\u6dfb\u52a0\u4e86 SPP \u5757\uff0c\u56e0\u4e3a\u5b83\u663e\u7740\u589e\u52a0\u4e86\u611f\u53d7\u91ce\uff0c\u5206\u79bb\u51fa\u6700\u91cd\u8981\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u5e76\u4e14\u51e0\u4e4e\u4e0d\u4f1a\u964d\u4f4e\u7f51\u7edc\u8fd0\u884c\u901f\u5ea6\u3002 \u6211\u4eec\u4f7f\u7528 PANet \u4f5c\u4e3a\u6765\u81ea\u4e0d\u540c\u4e3b\u5e72\u7ea7\u522b\u7684\u5bf9\u4e0d\u540c\u68c0\u6d4b\u5668\u7ea7\u522b\u7684\u53c2\u6570\u805a\u5408\u65b9\u6cd5\uff0c\u800c\u4e0d\u662f YOLOv3 \u4e2d\u4f7f\u7528\u7684 FPN\u3002 \u2003Finally, we choose CSPDarknet53 backbone, SPP additional module, PANet path-aggregation neck, and YOLOv3 (anchor based) head as the architecture of YOLOv4. \u2003\u6700\u540e\uff0c\u6211\u4eec\u9009\u62e9 CSPDarknet53 \u4e3b\u5e72\u3001SPP \u9644\u52a0\u6a21\u5757\u3001PANet \u8def\u5f84\u805a\u5408\u9888\u90e8\u548c YOLOv3\uff08(anchor based\uff09\u5934\u90e8\u4f5c\u4e3a YOLOv4 \u7684\u67b6\u6784\u3002 \u2003n the future we plan to expand significantly the content of Bag of Freebies (BoF) for the detector, which theoreti- cally can address some problems and increase the detector accuracy, and sequentially check the influence of each fea- ture in an experimental fashion. \u2003\u672a\u6765\u6211\u4eec\u8ba1\u5212\u5927\u529b\u6269\u5c55\u68c0\u6d4b\u5668\u7684Bag of Freebies (BoF) \u5185\u5bb9\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u89e3\u51b3\u4e00\u4e9b\u95ee\u9898\u5e76\u63d0\u9ad8\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4ee5\u5b9e\u9a8c\u65b9\u5f0f\u4f9d\u6b21\u68c0\u67e5\u6bcf\u4e2a\u7279\u5f81\u7684\u5f71\u54cd\u3002 \u2003We do not use Cross-GPU Batch Normalization (CGBN or SyncBN) or expensive specialized devices. This al- lows anyone to reproduce our state-of-the-art outcomes on a conventional graphic processor e.g. GTX 1080Ti or RTX 2080Ti. \u2003\u6211\u4eec\u4e0d\u4f7f\u7528\u8de8 GPU\uff08Cross-GPU\uff09\u6279\u91cf\u5f52\u4e00\u5316\uff08CGBN \u6216 SyncBN\uff09\u6216\u6602\u8d35\u7684\u4e13\u7528\u8bbe\u5907\u3002 \u8fd9\u5141\u8bb8\u4efb\u4f55\u4eba\u5728\u4f20\u7edf\u56fe\u5f62\u5904\u7406\u5668\u4e0a\u91cd\u73b0\u6211\u4eec\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u4f8b\u5982 GTX 1080Ti \u6216 RTX 2080Ti\u3002","title":"3.1. Selection of architecture \u67b6\u6784\u9009\u62e9"},{"location":"thesis_interpretation/04_yolo.html#32-selection-of-bof-and-bos","text":"For improving the object detection training, a CNN usu- ally uses the following: \u2003\u4e3a\u4e86\u6539\u8fdb\u76ee\u6807\u68c0\u6d4b\u8bad\u7ec3\uff0cCNN \u901a\u5e38\u4f7f\u7528\u4ee5\u4e0b\u5185\u5bb9\uff1a Activations: ReLU, leaky-ReLU, parametric-ReLU, ReLU6, SELU, Swish, or Mish \u6fc0\u6d3b\uff1aReLU\u3001leaky-ReLU\u3001\u53c2\u6570\u5316 ReLU\uff08parametric-ReLU\uff09\u3001ReLU6\u3001SELU\u3001Swish \u6216 Mish Bounding box regression loss: MSE, IoU, GIoU,CIoU, DIoU \u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\uff1aMSE\u3001IoU\u3001GIoU\u3001CIoU\u3001DIoU Data augmentation: CutOut, MixUp, CutMix \u6570\u636e\u589e\u5f3a\uff1aCutOut\u3001MixUp\u3001CutMix Regularization method: DropOut, DropPath [36],Spatial DropOut [79], or DropBlock \u6b63\u5219\u5316\u65b9\u6cd5\uff1aDropOut\u3001DropPath [36]\u3001Spatial DropOut [79] \u6216 DropBlock Normalization of the network activations by their mean and variance: Batch Normalization (BN) [32], Cross-GPU Batch Normalization (CGBN or SyncBN)[93], Filter Response Normalization (FRN) [70], or Cross-Iteration Batch Normalization (CBN) [89] \u901a\u8fc7\u5747\u503c\u548c\u65b9\u5dee\u5bf9\u7f51\u7edc\u6fc0\u6d3b\u8fdb\u884c\u5f52\u4e00\u5316\uff1a\u6279\u5f52\u4e00\u5316 (BN) [32]\u3001Cross-GPU \u6279\u5f52\u4e00\u5316\uff08CGBN \u6216 SyncBN\uff09[93]\u3001\u6ee4\u6ce2\u5668\u54cd\u5e94\uff08Filter Response\uff09\u5f52\u4e00\u5316 (FRN) [70] \u6216\u4ea4\u53c9\u8fed\u4ee3\uff08Cross-Iteration\uff09\u6279\u5f52\u4e00\u5316 (CBN) [89] Skip-connections: Residual connections, Weighted residual connections, Multi-input weighted residual connections, or Cross stage partial connections (CSP) \u8df3\u8fc7\u8fde\u63a5\uff08Skip-connections\uff09\uff1a\u6b8b\u5dee\u8fde\u63a5\uff08Residual connection\uff09\u3001\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\u3001\u591a\u8f93\u5165\uff08Multi-input\uff09\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5\u6216\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5\uff08Cross stage partial connections\uff09 (CSP) \u2003As for training activation function, since PReLU and SELU are more difficult to train, and ReLU6 is specifically designed for quantization network, we therefore remove the above activation functions from the candidate list. In the method of reqularization, the people who published Drop- Block have compared their method with other methods in detail, and their regularization method has won a lot. There- fore, we did not hesitate to choose DropBlock as our reg- ularization method. As for the selection of normalization method, since we focus on a training strategy that uses only one GPU, syncBN is not considered. \u2003\u81f3\u4e8e\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\uff0c\u7531\u4e8e PReLU \u548c SELU \u66f4\u96be\u8bad\u7ec3\uff0c\u800c ReLU6 \u662f\u4e13\u95e8\u4e3a\u91cf\u5316\uff08quantization\uff09\u7f51\u7edc\u8bbe\u8ba1\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u4ece\u5019\u9009\u5217\u8868\u4e2d\u5220\u9664\u4e86\u4e0a\u8ff0\u6fc0\u6d3b\u51fd\u6570\u3002 \u5728\u6b63\u5219\u5316\u7684\u65b9\u6cd5\u4e0a\uff0c\u53d1\u8868Drop-Block\u7684\u4eba\u8be6\u7ec6\u5bf9\u6bd4\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\u548c\u5176\u4ed6\u65b9\u6cd5\uff0c\u4ed6\u4eec\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u8d62\u5f97\u4e86\u5f88\u591a\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u6beb\u4e0d\u72b9\u8c6b\u5730\u9009\u62e9 DropBlock \u4f5c\u4e3a\u6211\u4eec\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002 \u81f3\u4e8e\u5f52\u4e00\u5316\u65b9\u6cd5\u7684\u9009\u62e9\uff0c\u7531\u4e8e\u6211\u4eec\u4e13\u6ce8\u4e8e\u4ec5\u4f7f\u7528\u4e00\u4e2a GPU \u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u56e0\u6b64\u6ca1\u6709\u8003\u8651 syncBN\u3002","title":"3.2. Selection of BoF and BoS"},{"location":"thesis_interpretation/04_yolo.html#33-additional-improvements","text":"In order to make the designed detector more suitable for training on single GPU, we made additional design and im- provement as follows: \u2003\u4e3a\u4e86\u4f7f\u6240\u8bbe\u8ba1\u7684\u68c0\u6d4b\u5668\u66f4\u9002\u5408\u5728\u5355\u4e00GPU\u4e0a\u8bad\u7ec3\uff0c\u6211\u4eec\u505a\u4e86\u5982\u4e0b\u989d\u5916\u7684\u8bbe\u8ba1\u548c\u6539\u8fdb: We introduce a new method of data augmentation Mosaic, and Self-Adversarial Training (SA T) \u6211\u4eec\u5f15\u5165\u4e86\u6570\u636e\u589e\u5f3a\u9a6c\u8d5b\u514b\uff08Mosaic\uff09\u548c\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u7684\u65b0\u65b9\u6cd5 We select optimal hyper-parameters while applying genetic algorithms \u6211\u4eec\u5728\u5e94\u7528\u9057\u4f20\u7b97\u6cd5\uff08genetic algorithm\uff09\u7684\u540c\u65f6\u9009\u62e9\u6700\u4f73\u8d85\u53c2\u6570 We modify some exsiting methods to make our design suitble for efficient training and detection - modified SAM, modified PAN, and Cross mini-Batch Normalization (CmBN) \u6211\u4eec\u4fee\u6539\u4e86\u4e00\u4e9b\u73b0\u6709\u7684\u65b9\u6cd5\uff0c\u4f7f\u6211\u4eec\u7684\u8bbe\u8ba1\u9002\u5408\u9ad8\u6548\u7684\u8bad\u7ec3\u548c\u68c0\u6d4b\u2014\u2014\u4fee\u6539\u7684 SAM\u3001\u4fee\u6539\u7684 PAN \u548c\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN) \u2003Mosaic represents a new data augmentation method that mixes 4 training images. Thus 4 different contexts are mixed, while CutMix mixes only 2 input images. This al- lows detection of objects outside their normal context. In addition, batch normalization calculates activation statistics from 4 different images on each layer. This significantly reduces the need for a large mini-batch size. \u2003Mosaic \u4ee3\u8868\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b83\u6df7\u5408\u4e86 4 \u4e2a\u8bad\u7ec3\u56fe\u50cf\u3002 \u56e0\u6b64\u6df7\u5408\u4e86 4 \u4e2a\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\uff0c\u800c CutMix \u4ec5\u6df7\u5408\u4e86 2 \u4e2a\u8f93\u5165\u56fe\u50cf\u3002 \u8fd9\u5141\u8bb8\u68c0\u6d4b\u6b63\u5e38\u4e0a\u4e0b\u6587\u4e4b\u5916\u7684\u5bf9\u8c61\u3002 \u6b64\u5916\uff0c\u6279\u91cf\u5f52\u4e00\u5316\u8ba1\u7b97\u6bcf\u5c42 4 \u4e2a\u4e0d\u540c\u56fe\u50cf\u7684\u6fc0\u6d3b\u7edf\u8ba1\u6570\u636e\u3002 \u8fd9\u663e\u7740\u51cf\u5c11\u4e86\u5bf9\u5927\u5c3a\u5bf8 mini-batch \u7684\u9700\u6c42\u3002 Figure 3: Mosaic represents a new method of data augmentation. \u56fe3:\u9a6c\u8d5b\u514b\u8868\u793a\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u7684\u65b0\u65b9\u6cd5\u3002 \u2003Self-Adversarial Training (SAT) also represents a new data augmentation technique that operates in 2 forward backward stages. In the 1st stage the neural network alters the original image instead of the network weights. In this way the neural network executes an adversarial attack on it- self, altering the original image to create the deception that there is no desired object on the image. In the 2nd stage, the neural network is trained to detect an object on this modified image in the normal way. \u2003 \u81ea\u6211\u5bf9\u6297\u8bad\u7ec3 (SAT) \u4e5f\u4ee3\u8868\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u5b83\u5728 2 \u4e2a\u524d\u5411\u548c\u540e\u5411\u9636\u6bb5\u4e2d\u8fd0\u884c\u3002 \u5728\u7b2c\u4e00\u9636\u6bb5\uff0c\u795e\u7ecf\u7f51\u7edc\u6539\u53d8\u539f\u59cb\u56fe\u50cf\u800c\u4e0d\u662f\u7f51\u7edc\u6743\u91cd\u3002 \u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u795e\u7ecf\u7f51\u7edc\u5bf9\u81ea\u8eab\u6267\u884c\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u6539\u53d8\u539f\u59cb\u56fe\u50cf \u4ee5\u5236\u9020\u56fe\u50cf\u4e0a\u6ca1\u6709\u6240\u9700\u5bf9\u8c61\u7684\u6b3a\u9a97\uff08deception\uff09\u3002 \u5728\u7b2c\u4e8c\u9636\u6bb5\uff0c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4ee5\u6b63\u5e38\u65b9\u5f0f\u68c0\u6d4b\u6b64\u4fee\u6539\u56fe\u50cf\u4e0a\u7684\u5bf9\u8c61\u3002 Figure 4: Cross mini-Batch Normalization. \u56fe 4\uff1a\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316\u3002 \u2003CmBN represents a CBN modified version, as shown in Figure 4, defined as Cross mini-Batch Normalization (CmBN). This collects statistics only between mini-batches within a single batch. \u2003 CmBN \u8868\u793a CBN \u4fee\u6539\u7248\u672c\uff0c\u5982\u56fe 4 \u6240\u793a\uff0c\u5b9a\u4e49\u4e3a\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3002 \u8fd9\u4ec5\u5728\u5355\u4e2a\u6279\u6b21\u5185\u7684\u5c0f\u6279\u6b21\u4e4b\u95f4\u6536\u96c6\u7edf\u8ba1\u4fe1\u606f\u3002 \u2003 We modify SAM from spatial-wise attention to point- wise attention, and replace shortcut connection of PAN to concatenation, as shown in Figure 5 and Figure 6, respec- tively. \u2003 \u6211\u4eec\u5c06 SAM \u4ece\u6309\u7a7a\u95f4\u6ce8\u610f\uff08spatial-wise attention\uff09\u4fee\u6539\u4e3a\u9010\u70b9\u6ce8\u610f\uff08point-wise attention\uff09\uff0c\u5e76\u5c06 PAN \u7684\u5feb\u6377\u8fde\u63a5\uff08shortcut connection\uff09\u66ff\u6362\u4e3a\u4e32\u8054\uff08concatenation\uff09\uff0c\u5206\u522b\u5982\u56fe 5 \u548c\u56fe 6 \u6240\u793a\u3002","title":"3.3. Additional improvements"},{"location":"thesis_interpretation/04_yolo.html#34-yolov4","text":"In this section, we shall elaborate the details of YOLOv4. \u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u8be6\u7ec6\u9610\u8ff0YOLOv4\u7684\u7ec6\u8282\u3002 YOLOv4 consists of: YOLOv4 \u5305\u62ec\uff1a Backbone: CSPDarknet53 [81] Neck: SPP [25], PAN [49] Head: YOLOv3 [63] YOLO v4 uses: YOLO v4 \u4f7f\u7528: Bag of Freebies (BoF) for backbone: CutMix and Mosaic data augmentation, DropBlock regularization, Class label smoothing \u9aa8\u5e72\u7684BoF\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u3001DropBlock \u6b63\u5219\u5316\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\uff08Class label smoothing\uff09 Bag of Specials (BoS) for backbone: Mish activation, Cross-stage partial connections (CSP), Multiinput weighted residual connections (MiWRC) \u9aa8\u5e72\u7684BoS\uff1aMish \u6fc0\u6d3b\u3001\u8de8\u9636\u6bb5\u90e8\u5206\u8fde\u63a5 (CSP)\u3001\u591a\u8f93\u5165\u52a0\u6743\u6b8b\u5dee\u8fde\u63a5 (MiWRC) Bag of Freebies (BoF) for detector: CIoU-loss, CmBN, DropBlock regularization, Mosaic data augmentation, Self-Adversarial Training, Eliminate grid sensitivity, Using multiple anchors for a single ground truth, Cosine annealing scheduler [52], Optimal hyperparameters, Random training shapes \u68c0\u6d4b\u5668\u7684BoF\uff1aCIoU-loss\u3001CmBN\u3001DropBlock \u6b63\u5219\u5316\u3001Mosaic \u6570\u636e\u589e\u5f3a\u3001\u81ea\u6211\u5bf9\u6297\u8bad\u7ec3\uff08SAT\uff09\u3001\u6d88\u9664\u7f51\u683c\u654f\u611f\u6027\uff08Eliminate grid sensitivity\uff09\u3001\u4f7f\u7528\u591a\u4e2a\u951a\u70b9\uff08multiple anchors\uff09\u83b7\u53d6\u5355\u4e2a\u771f\u5b9e\u503c\u3001\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\u7a0b\u5e8f\uff08Cosine annealing scheduler\uff09 [52]\u3001\u6700\u4f18\u8d85\u53c2\u6570\uff0c\u968f\u673a\u8bad\u7ec3\u5f62\u72b6 Bag of Specials (BoS) for detector: Mish activation, SPP-block, SAM-block, PAN path-aggregation block,DIoU-NMS \u7528\u4e8e\u68c0\u6d4b\u5668\u7684\u7279\u6709\u5305 \uff08BoS\uff09\uff1a \u8bef\u533a\u6fc0\u6d3b\u3001 SPP \u5757\u3001 SAM \u5757\u3001 PAN \u8def\u5f84\u805a\u5408\u5757\u3001 DIoU-NMS","title":"3.4. YOLOv4"},{"location":"thesis_interpretation/04_yolo.html#4-experiments","text":"We test the influence of different training improvement techniques on accuracy of the classifier on ImageNet (ILSVRC 2012 val) dataset, and then on the accuracy of the detector on MS COCO (test-dev 2017) dataset. \u2003\u6211\u4eec\u5728 ImageNet (ILSVRC 2012 val) \u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u4e0d\u540c\u8bad\u7ec3\u6539\u8fdb\u6280\u672f\u5bf9\u5206\u7c7b\u5668\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u7136\u540e\u5728 MS COCO (test-dev 2017) \u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u3002","title":"4. Experiments  \u5b9e\u9a8c"},{"location":"thesis_interpretation/04_yolo.html#41-experimental-setup","text":"In ImageNet image classification experiments, the default hyper-parameters are as follows: the training steps is 8,000,000; the batch size and the mini-batch size are 128 and 32, respectively; the polynomial decay learning rate scheduling strategy is adopted with initial learning rate 0.1; the warm-up steps is 1000; the momentum and weight decay are respectively set as 0.9 and 0.005. All of our BoS experiments use the same hyper-parameter as the default setting, and in the BoF experiments, we add an additional 50% training steps. In the BoF experiments, we verify MixUp, CutMix, Mosaic, Bluring data augmentation, and label smoothing regularization methods. In the BoS experiments, we compared the effects of LReLU, Swish, and Mish activation function. All experiments are trained with a 1080 Ti or 2080 Ti GPU. \u2003\u5728 ImageNet \u56fe\u50cf\u5206\u7c7b\u5b9e\u9a8c\u4e2d\uff0c\u9ed8\u8ba4\u8d85\u53c2\u6570\u5982\u4e0b\uff1a\u8bad\u7ec3\u6b65\u6570\u4e3a 8,000,000\uff1b \u5927\u6279\u91cf\u548c\u5c0f\u6279\u91cf\u5927\u5c0f\u5206\u522b\u4e3a 128 \u548c 32\uff1b \u91c7\u7528\u591a\u9879\u5f0f\u8870\u51cf\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08polynomial decay learning rate scheduling strategy\uff09\uff0c\u521d\u59cb\u5b66\u4e60\u73870.1\uff1b \u9884\u70ed\uff08warm-up\uff09\u6b65\u6570\u4e3a1000\uff1b \u52a8\u91cf\u8870\u51cf\u548c\u6743\u91cd\u8870\u51cf\u5206\u522b\u8bbe\u7f6e\u4e3a 0.9 \u548c 0.005\u3002\u6211\u4eec\u6240\u6709\u7684 BoS \u5b9e\u9a8c\u90fd\u4f7f\u7528\u4e0e\u9ed8\u8ba4\u8bbe\u7f6e\u76f8\u540c\u7684\u8d85\u53c2\u6570\uff0c\u5e76\u4e14\u5728 BoF \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u989d\u5916\u7684 50% \u8bad\u7ec3\u6b65\u6570\u3002 \u5728 BoF \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u9a8c\u8bc1\u4e86 MixUp\u3001CutMix\u3001Mosaic\u3001Bluring \u6570\u636e\u589e\u5f3a\u548c\u6807\u7b7e\u5e73\u6ed1\u6b63\u5219\u5316\uff08label smoothing regularization\uff09\u65b9\u6cd5\u3002 \u5728 BoS \u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u6bd4\u8f83\u4e86 LReLU\u3001Swish \u548c Mish \u6fc0\u6d3b\u51fd\u6570\u7684\u6548\u679c\u3002 \u6240\u6709\u5b9e\u9a8c\u5747\u4f7f\u7528 1080 Ti \u6216 2080 Ti GPU \u8fdb\u884c\u8bad\u7ec3\u3002 \u2003In MS COCO object detection experiments, the default hyper-parameters are as follows: the training steps is 500,500; the step decay learning rate scheduling strategy is adopted with initial learning rate 0.01 and multiply with a factor 0.1 at the 400,000 steps and the 450,000 steps, respectively; The momentum and weight decay are respec- tively set as 0.9 and 0.0005. All architectures use a single GPU to execute multi-scale training in the batch size of 64 while mini-batch size is 8 or 4 depend on the architectures and GPU memory limitation. Except for us- ing genetic algorithm for hyper-parameter search experiments, all other experiments use default setting. Genetic algorithm used YOLOv3-SPP to train with GIoU loss and search 300 epochs for min-val 5k sets. We adopt searched learning rate 0.00261, momentum 0.949, IoU threshold for assigning ground truth 0.213, and loss normalizer 0.07 for genetic algorithm experiments. We have verified a large number of BoF, including grid sensitivity elimination, mosaic data augmentation, IoU threshold, genetic algorithm, class label smoothing, cross mini-batch normalization, self-adversarial training, cosine annealing scheduler, dynamic mini-batch size, DropBlock, Optimized Anchors, different kind of IoU losses. We also conduct experiments on various BoS, including Mish, SPP, SAM, RFB, BiFPN, and Gaus-sian YOLO [8]. For all experiments, we only use one GPU for training, so techniques such as syncBN that optimizes multiple GPUs are not used. \u2003\u5728 MS COCO \u6570\u636e\u96c6\u4e0a\u76ee\u6807\u68c0\u6d4b\u5b9e\u9a8c\u4e2d\uff0c\u9ed8\u8ba4\u8d85\u53c2\u6570\u5982\u4e0b\uff1a\u8bad\u7ec3\u6b65\u6570\u4e3a 500,500\uff1b \u91c7\u7528\u6b65\u957f\u8870\u51cf\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08step decay learning rate scheduling strategy\uff09\uff0c\u521d\u59cb\u5b66\u4e60\u73870.01\uff0c\u5206\u522b\u572840\u4e07\u6b65\u548c45\u4e07\u6b65\u4e58\u4ee5\u56e0\u5b500.1\uff1b \u52a8\u91cf\u548c\u6743\u91cd\u8870\u51cf\u5206\u522b\u8bbe\u7f6e\u4e3a 0.9 \u548c 0.0005\u3002\u6240\u6709\u67b6\u6784\uff08architecture\uff09\u90fd\u4f7f\u7528\u5355\u4e2a GPU \u4ee5 64 \u7684\u6279\u91cf\u5927\u5c0f\u6267\u884c\u591a\u6bd4\u4f8b\uff08multi-scale\uff09\u8bad\u7ec3\uff0c\u800c\u5c0f\u6279\u91cf\u5927\u5c0f\u4e3a 8 \u6216 4\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u67b6\u6784\u548c GPU \u5185\u5b58\u9650\u5236\u3002 \u9664\u4e86\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u8d85\u53c2\u6570\u641c\u7d22\u5b9e\u9a8c\u5916\uff0c\u5176\u4ed6\u6240\u6709\u5b9e\u9a8c\u5747\u4f7f\u7528\u9ed8\u8ba4\u8bbe\u7f6e\u3002 \u9057\u4f20\u7b97\u6cd5\u4f7f\u7528 YOLOv3-SPP \u8bad\u7ec3 GIoU\u635f\u5931\u5e76\u641c\u7d22 300 \u4e2a epoch \u4ee5\u83b7\u53d6min-val 5k \u96c6\u3002 \u6211\u4eec\u91c7\u7528\u641c\u7d22\u5b66\u4e60\u7387 0.00261\uff0c\u52a8\u91cf 0.949\uff0c\u5206\u914d\u771f\u5b9e\u503c\u7684 IoU \u9608\u503c 0.213\uff0c\u9057\u4f20\u7b97\u6cd5\u5b9e\u9a8c\u7684\u635f\u5931\u5f52\u4e00\u5316\u5668 0.07\u3002 \u6211\u4eec\u5df2\u7ecf\u9a8c\u8bc1\u4e86\u5927\u91cf\u7684 BoF\uff0c\u5305\u62ec\u7f51\u683c\u654f\u611f\u6027\u6d88\u9664\uff08grid sensitivity elimination\uff09\u3001\u9a6c\u8d5b\u514b\u6570\u636e\u589e\u5f3a\u3001IoU \u9608\u503c\u3001\u9057\u4f20\u7b97\u6cd5\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\u3001\u4ea4\u53c9\u5c0f\u6279\u91cf\u5f52\u4e00\u5316 (CmBN)\u3001\u81ea\u5bf9\u6297\u8bad\u7ec3\u3001\u4f59\u5f26\u9000\u706b\u8c03\u5ea6\u5668\u3001\u52a8\u6001\u5c0f\u6279\u91cf\u5927\u5c0f\u3001DropBlock , \u4f18\u5316\u7684\u951a\u70b9\uff08Optimized Anchor\uff09\uff0c\u4e0d\u540c\u79cd\u7c7b\u7684 IoU \u635f\u5931\u3002 \u6211\u4eec\u8fd8\u5bf9\u5404\u79cd BoS \u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5305\u62ec Mish\u3001SPP\u3001SAM\u3001RFB\u3001BiFPN \u548cGaussian YOLO [8]\u3002 \u5bf9\u4e8e\u6240\u6709\u5b9e\u9a8c\uff0c\u6211\u4eec\u53ea\u4f7f\u7528\u4e00\u4e2a GPU \u8fdb\u884c\u8bad\u7ec3\uff0c\u56e0\u6b64\u6ca1\u6709\u4f7f\u7528\u4f18\u5316\u591a\u4e2a GPU \u7684\u540c\u6b65BN\uff08syncBN\uff09 \u7b49\u6280\u672f\u3002","title":"4.1. Experimental setup \u5b9e\u9a8c\u8bbe\u7f6e"},{"location":"thesis_interpretation/04_yolo.html#42-influence-of-different-features-on-classifier","text":"First, we study the influence of different features on classifier training; specifically, the influence of Class la- bel smoothing, the influence of different data augmentation techniques, bilateral blurring, MixUp, CutMix and Mosaic, as shown in Fugure 7, and the influence of different activa- tions, such as Leaky-ReLU (by default), Swish, and Mish. \u2003\u9996\u5148\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u4e0d\u540c\u7279\u5f81\u5bf9\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u5f71\u54cd\uff1b \u5177\u4f53\u6765\u8bf4\uff0cClass label smoothing\u7684\u5f71\u54cd\uff0c\u4e0d\u540c\u6570\u636e\u589e\u5f3a\u6280\u672f\u7684\u5f71\u54cd\uff0c\u53cc\u8fb9\u6a21\u7cca\uff08bilateral blurring\uff09\uff0cMixUp\uff0cCutMix\u548cMosaic\uff0c\u5982Fugure 7\u6240\u793a\uff0c\u4ee5\u53ca\u4e0d\u540c\u6fc0\u6d3b\u7684\u5f71\u54cd\uff0c\u4f8b\u5982Leaky-ReLU\uff08\u9ed8\u8ba4\uff09\uff0cSwish \uff0c\u548cMish\u3002 Figure 7: V arious method of data augmentation. \u56fe7:\u5404\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002 \u2003In our experiments, as illustrated in Table 2, the classifier\u2019s accuracy is improved by introducing the features such as: CutMix and Mosaic data augmentation, Class label smoothing, and Mish activation. As a result, our BoF-backbone (Bag of Freebies) for classifier training includes the following: CutMix and Mosaic data augmentation and Class label smoothing. In addition we use Mish activation as a complementary option, as shown in Table 2 and Table \u2003 \u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5982\u8868 2 \u6240\u793a\uff0c\u901a\u8fc7\u5f15\u5165\u4ee5\u4e0b\u7279\u5f81\u6765\u63d0\u9ad8\u5206\u7c7b\u5668\u7684\u51c6\u786e\u6027\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u3001\u7c7b\u6807\u7b7e\u5e73\u6ed1\u548c Mish \u6fc0\u6d3b\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u7528\u4e8e\u5206\u7c7b\u5668\u8bad\u7ec3\u7684 BoF-backbone\uff08Bag of Freebies\uff09\u5305\u62ec\u4ee5\u4e0b\u5185\u5bb9\uff1aCutMix \u548c Mosaic \u6570\u636e\u589e\u5f3a\u4ee5\u53ca\u7c7b\u6807\u7b7e\u5e73\u6ed1\u3002 \u6b64\u5916\uff0c\u6211\u4eec\u4f7f\u7528 Mish \u6fc0\u6d3b\u4f5c\u4e3a\u8865\u5145\u9009\u9879\uff08complementary option\uff09\uff0c\u5982\u8868 2 \u548c\u8868 3 \u6240\u793a\u3002 Table 2: Influence of BoF and Mish on the CSPResNeXt-50 classifier accuracy. \u88682:BoF\u548cMish\u5bf9CSPResNeXt-50\u5206\u7c7b\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002 Table 3: Influence of BoF and Mish on the CSPDarknet-53 classifier accuracy. \u88683:BoF\u548cMish\u5bf9CSPDarknet-53\u5206\u7c7b\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002","title":"4.2. Influence of different features on Classifier \u4e0d\u540c\u7279\u5f81\u5bf9\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u5f71\u54cd"},{"location":"thesis_interpretation/04_yolo.html#43-influence-of-different-features-on-detector","text":"Further study concerns the influence of different Bag-of-Freebies (BoF-detector) on the detector training accuracy, as shown in Table 4. We significantly expand the BoF list through studying different features that increase the detector accuracy without affecting FPS: \u2003\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u6d89\u53ca\u4e0d\u540c\u7684\u514d\u8d39\u888b(BOF\u63a2\u6d4b\u5668)\u5bf9\u63a2\u6d4b\u5668\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u5982\u88684\u6240\u793a\u3002\u6211\u4eec\u901a\u8fc7\u7814\u7a76\u5728\u4e0d\u5f71\u54cdFPS\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u63a2\u6d4b\u5668\u7cbe\u5ea6\u7684\u4e0d\u540c\u7279\u6027\uff0c\u663e\u8457\u6269\u5c55\u4e86BOF\u5217\u8868\uff1a S: Eliminate grid sensitivity the equation \\(b_x = \u03c3(t_x )+ c_x , b_y = \u03c3(t_y )+c_y\\) , where \\(c_x\\) and \\(c_y\\) are always whole numbers, is used in YOLOv3 for evaluating the object coordinates, therefore, extremely high \\(t_x\\) absolute values are required for the \\(b_x\\) value approaching the \\(c_x \\ or \\ c_{ x} + 1\\) values. We solve this problem through multiplying the sigmoid by a factor exceeding 1.0, so eliminating the effect of grid on which the object is undetectable. S\uff1a \u6d88\u9664\u7f51\u683c\u7075\u654f\u5ea6\u65b9\u7a0b \\(b_x = \u03c3(t_x )+ c_x , b_y = \u03c3(t_y )+c_y\\) \uff0c \u5176\u4e2d \\(c_x\\) \u548c \\(c_y\\) \u59cb\u7ec8\u4e3a\u6574\u6570\uff0c \u5728 YOLOv3 \u4e2d\u4f7f\u7528\u7528\u4e8e\u8bc4\u4f30\u76ee\u6807\u5750\u6807\uff0c \u56e0\u6b64\uff0c\u63a5\u8fd1 \\(c_x \\ or \\ c_{ x} + 1\\) \u503c\u7684 \\(b_x\\) \u503c\u9700\u8981\u6781\u9ad8\u7684 \\(t_x\\) \u7edd\u5bf9\u503c\u3002\u6211\u4eec\u901a\u8fc7\u5c06 sigmoid \u4e58\u4ee5\u8d85\u8fc7 1.0 \u7684\u56e0\u5b50\u6765\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u5bf9\u8c61\u65e0\u6cd5\u68c0\u6d4b\u5230\u7684\u7f51\u683c\u7684\u5f71\u54cd\u3002 M: Mosaic data augmentation \u2013 using the 4-image mosaic during training instead of single image M\uff1a\u9a6c\u8d5b\u514b\u6570\u636e\u6269\u589e \u2013 \u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528 4 \u56fe\u50cf\u9576\u5d4c\uff0c\u800c\u4e0d\u662f\u5355\u4e2a\u56fe\u50cf IT: IoU threshold \u2013 using multiple anchors for a single ground truth IoU (truth, anchor) > IoU-threshold IT\uff1aIoU \u9608\u503c \u2013 \u4f7f\u7528\u591a\u4e2a\u951a\u70b9\u8fdb\u884c\u5355\u4e2a\u63a5\u5730\u771f\u76f8 IoU\uff08\u771f\u3001\u951a\uff09\u548c IoU \u9608\u503c | GA: Genetic algorithms \u2013 using genetic algorithms for selecting the optimal hyperparameters during network training on the \ufb01rst 10% of time periods GA\uff1a\u9057\u4f20\u7b97\u6cd5 \u2013 \u5728\u524d 10% \u7684\u65f6\u95f4\u6bb5\u7684\u7f51\u7edc\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u9009\u62e9\u6700\u4f73\u8d85\u53c2\u6570* LS: Class label smoothing \u2013 using class label smoothing for sigmoid activation LS\uff1a\u7c7b\u6807\u7b7e\u5e73\u6ed1 \u2013 \u4f7f\u7528\u7c7b\u6807\u7b7e\u5e73\u6ed1\u8fdb\u884c sigmoid \u6fc0\u6d3b CBN: CmBN \u2013 using Cross mini-Batch Normalization for collecting statistics inside the entire batch, instead of collecting statistics inside a single mini-batch CBN\uff1a CmBN \u2013 \u4f7f\u7528\u4ea4\u53c9\u5c0f\u6279\u5904\u7406\u89c4\u8303\u5316\u6536\u96c6\u6574\u4e2a\u6279\u5904\u7406\u4e2d\u7684\u7edf\u8ba1\u4fe1\u606f\uff0c\u800c\u4e0d\u662f\u5728\u5355\u4e2a\u5c0f\u6279\u5904\u7406\u4e2d\u6536\u96c6\u7edf\u8ba1\u4fe1\u606f* CA: Cosine annealing scheduler \u2013 altering the learning rate during sinusoid training CA\uff1a\u534f\u548c\u7d20\u9000\u706b\u8c03\u5ea6\u5668 \u2013 \u6539\u53d8\u6b63\u5f26\u8bad\u7ec3\u4e2d\u7684\u5b66\u4e60\u901f\u7387* DM: Dynamic mini-batch size \u2013 automatic increase of mini-batch size during small resolution training by using Random training shapes DM\uff1a\u52a8\u6001\u5c0f\u6279\u91cf\u5c3a\u5bf8 \u2013 \u4f7f\u7528\u968f\u673a\u8bad\u7ec3\u5f62\u72b6\u5728\u5c0f\u5206\u8fa8\u7387\u8bad\u7ec3\u671f\u95f4\u81ea\u52a8\u589e\u52a0\u5c0f\u6279\u91cf\u5927\u5c0f OA: Optimized Anchors \u2013 using the optimized anchors for training with the 512\u00d7512 network resolution OA\uff1a\u4f18\u5316\u7684\u951a\u70b9 \u2013 \u4f7f\u7528\u4f18\u5316\u7684\u951a\u70b9\u8fdb\u884c 512\u00d7512 \u7f51\u7edc\u5206\u8fa8\u7387\u7684\u8bad\u7ec3* GIoU, CIoU, DIoU, MSE \u2013 using different loss algorithms for bounded box regression GIoU\u3001CIoU\u3001DIoU\u3001MSE \u2013 \u5bf9\u8fb9\u754c\u6846\u56de\u5f52\u4f7f\u7528\u4e0d\u540c\u7684\u635f\u5931\u7b97\u6cd5 \u2003Further study concerns the in\ufb02uence of different Bagof-Specials (BoS-detector) on the detector training accuracy, including PAN, RFB, SAM, Gaussian YOLO (G), and ASFF, as shown in Table 5. In our experiments, the detector gets best performance when using SPP, PAN, and SAM. \u2003\u8fdb\u4e00\u6b65\u7814\u7a76\u6d89\u53ca\u4e0d\u540c\u7684\u5df4\u6208\u592b\u7279\u8f91\uff08BoS-\u68c0\u6d4b\u5668\uff09\u5bf9\u68c0\u6d4b\u5668\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u5305\u62ecPAN\u3001RFB\u3001SAM\u3001\u9ad8\u65afYOLO\uff08G\uff09\u548cASFF\uff0c\u5982\u88685\u6240\u793a\u3002\u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u68c0\u6d4b\u5668\u5728\u4f7f\u7528 SPP\u3001PAN \u548c SAM \u65f6\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002 Table 4: Ablation Studies of Bag-of-Freebies. (CSPResNeXt50-PANet-SPP , 512x512). Table 5: Ablation Studies of Bag-of-Specials. (Size 512x512).","title":"4.3. Influence of different features on Detector"},{"location":"thesis_interpretation/04_yolo.html#44-influence-of-different-backbones-and-pretrained-weightings-on-detector-training","text":"Further on we study the influence of different backbone models on the detector accuracy, as shown in Table 6. We notice that the model characterized with the best classifica- tion accuracy is not always the best in terms of the detector accuracy. \u2003 \u6700\u540e\uff0c\u6211\u4eec\u5206\u6790\u4e86\u5728\u4e0d\u540c\u6700\u5c0f\u6279\u91cf\u5927\u5c0f\u4e0b\u8bad\u7ec3\u7684\u6a21\u578b\u6240\u83b7\u5f97\u7684\u7ed3\u679c\uff0c\u7ed3\u679c\u5982\u88687\u6240\u793a\u3002\u4ece\u88687\u6240\u793a\u7684\u7ed3\u679c\u4e2d\uff0c\u6211\u4eec\u53d1\u73b0\u5728\u6dfb\u52a0BoF\u548cBoS\u8bad\u7ec3\u7b56\u7565\u4e4b\u540e\uff0c\u6700\u5c0f\u6279\u91cf\u5927\u5c0f\u51e0\u4e4e\u6ca1\u6709\u5f71\u54cd\u5728\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u4e0a\u3002\u8be5\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5f15\u5165BoF\u548cBoS\u4e4b\u540e\uff0c\u4e0d\u518d\u9700\u8981\u4f7f\u7528\u6602\u8d35\u7684GPU\u8fdb\u884c\u8bad\u7ec3\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u4efb\u4f55\u4eba\u90fd\u53ea\u80fd\u4f7f\u7528\u4f20\u7edf\u7684GPU\u6765\u8bad\u7ec3\u51fa\u8272\u7684\u63a2\u6d4b\u5668\u3002 Table 7: Using different mini-batch size for detector training. \u88687\uff1a\u4f7f\u7528\u4e0d\u540c\u7684\u5c0f\u6279\u91cf\u5bf9\u4e8e\u68c0\u6d4b\u5668\u8bad\u7ec3\u3002","title":"4.4. Influence of different backbones and pretrained weightings on Detector training"},{"location":"thesis_interpretation/04_yolo.html#5results","text":"Comparison of the results obtained with other state-of-the-art object detectors are shown in Figure 8. Our YOLOv4 are located on the Pareto optimality curve and are superior to the fastest and most accurate detectors in terms of both speed and accuracy. \u2003\u5f97\u5230\u7684\u7ed3\u679c\u4e0e\u5176\u4ed6\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u6bd4\u8f83\u5982\u56fe8\u6240\u793a\u3002\u6211\u4eec\u7684yolo4\u4f4d\u4e8ePareto optimality\u66f2\u7ebf\u4e0a\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u90fd\u4f18\u4e8e\u6700\u5feb\u548c\u6700\u7cbe\u786e\u7684\u63a2\u6d4b\u5668\u3002 \u2003Since different methods use GPUs of different architectures for inference time verification, we operate YOLOv4 on commonly adopted GPUs of Maxwell, Pascal, and Volta architectures, and compare them with other state-of-the-art methods. Table 8 lists the frame rate comparison results of using Maxwell GPU, and it can be GTX Titan X (Maxwell) or Tesla M40 GPU. Table 9 lists the frame rate comparison results of using Pascal GPU, and it can be Titan X (Pascal), Titan Xp, GTX 1080 Ti, or Tesla P100 GPU. As for Table 10, it lists the frame rate comparison results of using V olta GPU, and it can be Titan V olta or Tesla V100 GPU. \u2003\u7531\u4e8e\u4e0d\u540c\u7684\u65b9\u6cd5\u4f7f\u7528\u4e0d\u540c\u4f53\u7cfb\u7ed3\u6784\u7684GPU\u8fdb\u884c\u63a8\u7406\u65f6\u95f4\u9a8c\u8bc1\uff0c\u6211\u4eec\u5728\u5e38\u7528\u7684Maxwell\u3001Pascal\u548cVoltaArchitecture\u4f53\u7cfb\u7ed3\u6784\u7684GPU\u4e0a\u8fd0\u884cYOLOv4\uff0c\u5e76\u5c06\u5b83\u4eec\u4e0e\u5176\u4ed6\u5148\u8fdb\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u88688\u5217\u51fa\u4e86\u4f7f\u7528Maxwell GPU\u7684\u5e27\u7387\u6bd4\u8f83\u7ed3\u679c\uff0c\u53ef\u4ee5\u662fGTX Titan X(Maxwell)\u6216Tesla M40 GPU\u3002\u88689\u5217\u51fa\u4e86\u4f7f\u7528Pascal GPU\u7684\u5e27\u7387\u6bd4\u8f83\u7ed3\u679c\uff0c\u5b83\u53ef\u4ee5\u662fTitan X(Pascal)\u3001Titan XP\u3001GTX 1080 Ti\u6216Tesla P100 GPU\u3002\u886810\u5217\u51fa\u4e86\u4f7f\u7528VoltaGPU\u7684\u5e27\u7387\u5bf9\u6bd4\u7ed3\u679c\uff0c\u53ef\u4ee5\u662fTitan Volta\uff0c\u4e5f\u53ef\u4ee5\u662fTesla V100 GPU\u3002","title":"5.Results"},{"location":"thesis_interpretation/04_yolo.html#6-conclusions","text":"We offer a state-of-the-art detector which is faster (FPS) and more accurate (MS COCO \\(AP_{50...95}\\) and \\(AP_{50}\\) ) than all available alternative detectors. The detector described can be trained and used on a conventional GPU with 8-16 GB-VRAM this makes its broad use possible. The original concept of one-stage anchor-based detectors has proven its viability. We have verified a large number of features, and selected for use such of them for improving the accuracy of both the classifier and the detector. These features can be used as best-practice for future studies and developments. \u2003\u6211\u4eec\u63d0\u4f9b\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5176\u901f\u5ea6\uff08FPS\uff09\u548c\u51c6\u786e\u5ea6\uff08MS COCO \\(AP_{50 ... 95}\\) \u548c \\(AP_{50}\\) \uff09\u6bd4\u6240\u6709\u53ef\u7528\u7684\u66ff\u4ee3\u68c0\u6d4b\u5668\u90fd\u9ad8\u3002\u6240\u63cf\u8ff0\u7684\u68c0\u6d4b\u5668\u53ef\u4ee5\u5728\u5177\u67098-16GB-VRAM\u7684\u5e38\u89c4GPU\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u4f7f\u7528\uff0c\u8fd9\u4f7f\u5f97\u5b83\u7684\u5e7f\u6cdb\u4f7f\u7528\u6210\u4e3a\u53ef\u80fd\u3002\u5355\u9636\u6bb5\u57fa\u4e8e\u951a\u6846\u7684\u68c0\u6d4b\u5668\u7684\u539f\u59cb\u6982\u5ff5\u5df2\u8bc1\u660e\u5176\u53ef\u884c\u6027\u3002\u6211\u4eec\u5df2\u7ecf\u9a8c\u8bc1\u4e86\u5927\u91cf\u7279\u5f81\uff0c\u5e76\u9009\u62e9\u4f7f\u7528\u5176\u4e2d\u7684\u4e00\u4e9b\u7279\u5f81\u4ee5\u63d0\u9ad8\u5206\u7c7b\u5668\u548c\u68c0\u6d4b\u5668\u7684\u51c6\u786e\u6027\u3002\u8fd9\u4e9b\u529f\u80fd\u53ef\u4ee5\u7528\u4f5c\u5c06\u6765\u7814\u7a76\u548c\u5f00\u53d1\u7684\u6700\u4f73\u5b9e\u8df5\u3002","title":"6. Conclusions"},{"location":"thesis_interpretation/04_yolo.html#7-acknowledgements","text":"The authors wish to thank Glenn Jocher for the ideas of Mosaic data augmentation, the selection of hyper-parameters by using genetic algorithms and solving the grid sensitivity problem https://github.com/ultralytics/yolov3. \u2003\u4f5c\u8005\u8981\u611f\u8c22Glenn Jocher\u8fdb\u884cMosaic\u6570\u636e\u589e\u5f3a\u7684\u60f3\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u9009\u62e9\u8d85\u53c2\u6570\u5e76\u89e3\u51b3\u7f51\u683c\u654f\u611f\u6027\u95ee\u9898\u7684\u65b9\u6cd5https://github.com/ultralytics/yolov3.10\u3002","title":"7. Acknowledgements"},{"location":"thesis_interpretation/06_yolo.html","text":"\u8bba\u6587\uff1aYOLOv6: A Single-Stage Object Detection Framework for Industrial Applications \u4ee3\u7801\uff1ahttps://github.com/meituan/YOLOv6 \u5b98\u65b9\u535a\u6587\uff1ahttps://blog.csdn.net/MeituanTech/article/details/125437630","title":"YOLOv6"},{"location":"tutorials/00_chapter/optim_speed_version1.html","text":"\u6d88\u8d39\u7ea7\u663e\u5361\u7684\u6625\u5929\uff0cGTX 3090 YOLOv5s\u5355\u5361\u5b8c\u6574\u8bad\u7ec3COCO\u6570\u636e\u96c6\u7f29\u77ed11.35\u4e2a\u5c0f\u65f6\u3002 0x0. \u524d\u8a00 \u5927\u5bb6\u597d\uff0c\u5f88\u9ad8\u5174\u53c8\u53ef\u4ee5\u4e3a\u5927\u5bb6\u5e26\u6765One-YOLOv5\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5728 One-YOLOv5 \u53d1\u5e03\uff0c\u4e00\u4e2a\u8bad\u5f97\u66f4\u5feb\u7684YOLOv5 \u53d1\u5e03\u540e\u6536\u5230\u4e86\u5f88\u591a\u7b97\u6cd5\u884c\u4e1a\u670b\u53cb\u7684\u5173\u6ce8\uff0c\u5341\u5206\u611f\u8c22\u3002\u4f46\u53ef\u80fd\u5927\u5bb6\u90fd\u5728\u601d\u8003\u4e00\u4e2a\u95ee\u9898\uff0c\u867d\u7136OneFlow\u7684\u517c\u5bb9\u6027\u505a\u5f97\u5f88\u597d\uff0c\u53ef\u4ee5\u5f88\u65b9\u4fbf\u7684\u79fb\u690dYOLOv5\u5e76\u4f7f\u7528OneFlow\u540e\u7aef\u6765\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u6211\u4e3a\u4ec0\u4e48\u8981\u7528\u4f60\u5462\uff1f\u80fd\u5e2e\u6211\u7f29\u77ed\u6a21\u578b\u5f00\u53d1\u5468\u671f\u5417\uff1f\u5e2e\u6211\u89e3\u51b3\u4e86\u4efb\u4f55\u75db\u70b9\u5417\uff1f\u672c\u7bc7\u6587\u7ae0\u5c06\u5c1d\u8bd5\u56de\u7b54\u8fd9\u51e0\u4e2a\u95ee\u9898\u3002 \u4e5f\u8bb8\u719f\u6089\u6211\u7684\u670b\u53cb\u77e5\u9053\u6211\u5728\u5165\u804c\u4e00\u6d41\u79d1\u6280\u4e4b\u524d\u4e5f\u662f\u4e00\u540d\u7b97\u6cd5\u5de5\u7a0b\u5e08\uff0c\u6211\u4e4b\u524d\u7684\u5f00\u53d1\u673a\u5668\u4e5f\u53ea\u6709\u4e24\u5f20GTX 3090\u6d88\u8d39\u7ea7\u663e\u5361\u800c\u5df2\u3002\u4f46\u5b9e\u9645\u4e0a\u516c\u53f8\u5927\u591a\u6570\u7531\u6211\u4e0a\u7ebf\u7684\u68c0\u6d4b\u4ea7\u54c1\u57fa\u672c\u4e0a\u4e5f\u5c31\u662f\u9760\u8fd91\u5f20\u6216\u80052\u5f20GTX 3090\u5b8c\u6210\u7684\u3002\u7531\u4e8e\u6210\u672c\u95ee\u9898\uff0c\u5f88\u591a\u4e2d\u5c0f\u516c\u53f8\u6ca1\u6709\u7ec4\u4e00\u4e2aA100\u96c6\u7fa4\u6216\u8005\u76f4\u63a5\u4e0a\u6570\u5341\u5f20\u5361\u6765\u8bad\u7ec3\u68c0\u6d4b\u6a21\u578b\u7684\u5b9e\u529b\uff0c\u6240\u4ee5\u8fd9\u4e2a\u65f6\u5019\u5728\u5355\u5361\u6216\u80052\u5361\u4e0a\u5c06\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u505a\u5feb\u5c31\u5c24\u4e3a\u91cd\u8981\u4e86\u3002\u628a\u6a21\u578b\u8bad\u7ec3\u505a\u5feb\u4e4b\u540e\u662f\u771f\u7684\u53ef\u4ee5\u964d\u672c\u589e\u6548\uff0c\u63d0\u9ad8\u6a21\u578b\u751f\u4ea7\u7387\u7684\u3002 \u6240\u4ee5\uff0c\u8fd1\u671f\u6211\u548c\u5b9e\u4e60\u751f\u5c0f\u4f19\u4f34\u4e00\u8d77\u505a\u4e86\u8fd9\u4e48\u4e00\u4ef6\u4e8b\u60c5\uff0c\u6211\u4eec\u5728\u5355\u5361\u4e0a\u51ed\u501f\u5bf9YOLOv5\u7684\u6027\u80fd\u5206\u6790\u4ee5\u53ca\u51e0\u4e2a\u7b80\u5355\u7684\u4f18\u5316\u5c06GTX 3090 FP32 YOLOv5s\u7684\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u4e86\u8fd120%\u3002\u5bf9\u4e8e\u9700\u8981\u8fed\u4ee3300\u4e2aEpoch\u7684COCO\u6570\u636e\u96c6\u6765\u8bf4\u76f8\u6bd4 ultralytics/yolov5 \u6211\u4eec\u7f29\u77ed\u4e8611.35\u4e2a\u5c0f\u65f6\u7684\u8bad\u7ec3\u65f6\u95f4\u3002\u6211\u4eec\u51b3\u5b9a\u5728\u672c\u6587\u5206\u4eab\u6211\u4eec\u7684\u6240\u6709\u4f18\u5316\u6280\u672f\uff0c\u5982\u679c\u4f60\u662f\u4e00\u540dPyTorch\u548cOneFlow\u7684\u7231\u597d\u8005\uff0c\u7279\u522b\u7684\u5982\u679c\u4f60\u662f\u4e00\u540d\u65e5\u5e38\u548c\u68c0\u6d4b\u6a21\u578b\u6253\u4ea4\u9053\u4f46\u8d44\u6e90\u76f8\u5bf9\u53d7\u9650\uff0c\u90a3\u4e48\u672c\u6587\u7684\u4f18\u5316\u65b9\u6cd5\u5c06\u5bf9\u4f60\u4ea7\u751f\u4e00\u5b9a\u5f71\u54cd\u3002 \u6700\u540e\uff0c\u5982\u679c\u672c\u6587\u5e2e\u52a9\u5230\u4e86\u4f60\uff0c\u8bf7\u4e00\u5b9a\u7ed9\u6211\u4eec\u70b9\u4e2astar\uff0c\u6211\u548c OneFlow \u4e5f\u4f1a\u7528\u66f4\u591a\u7684\u9ad8\u8d28\u91cf\u6280\u672f\u5206\u4eab\u6765\u56de\u9988\u5927\u5bb6\u3002 one-yolov5\u94fe\u63a5\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 \u5bf9 One-YOLOv5 \u611f\u5174\u8da3\u7684\u4f19\u4f34\u53ef\u4ee5\u6dfb\u52a0 bbuf23333 \u8fdb\u5165 One-YOLOv5 \u5fae\u4fe1\u4ea4\u6d41\u7fa4\u3002 0x1. \u7ed3\u679c\u5c55\u793a \u6211\u4eec\u5c55\u793a\u4e00\u4e0b\u5206\u522b\u4f7f\u7528One-YOLOv5\u4ee5\u53ca ultralytics/yolov5 \u5728GTX 3090\u5355\u5361\u4e0a\u4f7f\u7528YOLOv5s FP32\u6a21\u578b\u8bad\u7ec3COCO\u6570\u636e\u96c6\u4e00\u4e2aEpoch\u6240\u9700\u7684\u8017\u65f6\uff1a \u53ef\u4ee5\u770b\u5230\u5728\u5355\u5361\u6a21\u5f0f\u4e0b\uff0c\u7ecf\u8fc7\u6211\u4eec\u7684\u4f18\u5316\u76f8\u6bd4\u4e8e ultralytics/yolov5 \u7684\u8bad\u7ec3\u901f\u5ea6\uff0c\u6211\u4eec\u63d0\u5347\u4e86 20% \u5de6\u53f3\u3002 \u7136\u540e\u6211\u4eec\u518d\u5c55\u793a\u4e00\u4e0b2\u5361DDP\u6a21\u5f0fYOLOv5s FP32\u6a21\u578b\u8bad\u7ec3COCO\u6570\u636e\u96c6\u4e00\u4e2aEpoch\u6240\u9700\u7684\u8017\u65f6\uff1a \u5728DDP\u6a21\u5f0f\u4e0b\u7684\u6027\u80fd\u63d0\u5347\u5e45\u5ea6\u6ca1\u6709\u5355\u5361\u8fd9\u4e48\u591a\uff0c\u731c\u6d4b\u53ef\u80fd\u662f\u901a\u4fe1\u90e8\u5206\u7684\u5f00\u9500\u6bd4\u8f83\u5927\uff0c\u540e\u7eed\u6211\u4eec\u4f1a\u518d\u7814\u7a76\u4e00\u4e0b\u3002 0x2. \u4f18\u5316\u624b\u6bb5 \u6211\u4eec\u5728\u8fd9\u4e00\u8282\u5b8c\u6210\u6280\u672f\u63ed\u79d8\u3002\u6211\u4eec\u6df1\u5ea6\u5206\u6790\u4e86PyTorch\u7684YOLOv5\u7684\u6267\u884c\u5e8f\u5217\uff0c\u6211\u4eec\u53d1\u73b0\u5f53\u524dYOLOv5\u4e3b\u8981\u5b58\u57283\u4e2a\u4f18\u5316\u70b9\u3002\u7b2c\u4e00\u4e2a\u5c31\u662f\u5bf9\u4e8eUpsample\u7b97\u5b50\u7684\u6539\u8fdb\uff0c\u7531\u4e8eYOLOv5\u4f7f\u7528\u4e0a\u91c7\u6837\u662f\u89c4\u6574\u7684\u6700\u8fd1\u90bb2\u500d\u63d2\u503c\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u5b9e\u73b0\u4e00\u4e2a\u7279\u6b8aKernel\u964d\u4f4e\u8ba1\u7b97\u91cf\u5e76\u63d0\u5347\u5e26\u5bbd\u3002\u7b2c\u4e8c\u4e2a\u5c31\u662f\u5728YOLOv5\u4e2d\u5b58\u5728\u4e00\u4e2a\u6ed1\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570\u7684\u64cd\u4f5c\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u542f\u52a8\u4e86\u5f88\u591a\u788e\u7684CUDA Kernel\uff0c\u800c\u6bcf\u4e2aCUDA Kernel\u7684\u6267\u884c\u65f6\u95f4\u90fd\u975e\u5e38\u77ed\uff0c\u6240\u4ee5\u542f\u52a8\u5f00\u9500\u4e0d\u80fd\u5ffd\u7565\u3002\u6211\u4eec\u4f7f\u7528\u6c34\u5e73\u5e76\u884cCUDA Kernel\u7684\u65b9\u5f0f\uff08MultiTensor\uff09\u5bf9\u5176\u5b8c\u6210\u4e86\u4f18\u5316\uff0c\u57fa\u4e8e\u8fd9\u4e2a\u4f18\u5316One-YOLOv5\u83b7\u5f97\u4e869%\u7684\u52a0\u901f\u3002\u7b2c\u4e09\u4e2a\u4f18\u5316\u70b9\u6765\u6e90\u4e8e\u5bf9YOLOv5 nsys\u6267\u884c\u5e8f\u5217\u7684\u89c2\u5bdf\uff0c\u6211\u4eec\u53d1\u73b0\u5728ComputeLoss\u90e8\u5206\u51fa\u73b0\u7684bbox_iou\u662f\u6574\u4e2aLoss\u8ba1\u7b97\u90e8\u5206\u4e00\u4e2a\u6bd4\u8f83\u5927\u7684\u74f6\u9888\uff0c\u6211\u4eec\u5728bbox_iou\u51fd\u6570\u90e8\u5206\u5b8c\u6210\u4e86\u591a\u4e2a\u5782\u76f4\u7684Kernel Fuse\uff0c\u4f7f\u5f97\u5b83\u7684\u5f00\u9500\u4ece\u6700\u521d\u76843.xms\u964d\u4f4e\u5230\u4e86\u51e0\u767e\u4e2aus\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5206\u522b\u8be6\u7ec6\u9610\u8ff0\u8fd9\u51e0\u79cd\u4f18\u5316\uff1a 0x2.1 \u5bf9UpsampleNearest2D\u7684\u7279\u5316\u6539\u8fdb \u4e3a\u4e86\u4e0d\u5199\u5f97\u5570\u55e6\uff0c\u6211\u8fd9\u91cc\u76f4\u63a5\u5c55\u793a\u6211\u4eec\u5bf9UpsampleNearest2D\u8fdb\u884c\u8c03\u4f18\u7684\u6280\u672f\u603b\u7ed3\uff0c\u5927\u5bb6\u53ef\u4ee5\u7ed3\u5408\u4e0b\u9762\u7684 pr \u94fe\u63a5\u6765\u5bf9\u5e94\u4e0b\u9762\u7684\u77e5\u8bc6\u70b9\u603b\u7ed3\u3002\u6211\u4eec\u5728A100 40G\u4e0a\u6d4b\u8bd5 UpsampleNearest2D \u7b97\u5b50\u7684\u6027\u80fd\u8868\u73b0\u3002\u8fd9\u5757\u5361\u7684\u5cf0\u503c\u5e26\u5bbd\u57281555Gb/s , \u6211\u4eec\u4f7f\u7528\u7684CUDA\u7248\u672c\u4e3a11.8\u3002 \u8fdb\u884c Profile \u7684\u7a0b\u5e8f\u5982\u4e0b\uff1a import oneflow as flow x = flow . randn ( 16 , 32 , 80 , 80 , device = \"cuda\" , dtype = flow . float32 ) . requires_grad_ () m = flow . nn . Upsample ( scale_factor = 2.0 , mode = \"nearest\" ) y = m ( x ) print ( y . device ) y . sum () . backward () https://github.com/Oneflow-Inc/oneflow/pull/9415 & https://github.com/Oneflow-Inc/oneflow/pull/9424 \u8fd9\u4e24\u4e2a PR \u5206\u522b\u9488\u5bf9 UpsampleNearest2D \u8fd9\u4e2a\u7b97\u5b50\uff08\u8fd9\u4e2a\u7b97\u5b50\u662f YOLO \u7cfb\u5217\u7b97\u6cd5\u5927\u91cf\u4f7f\u7528\u7684\uff09\u7684\u524d\u540e\u5411\u8fdb\u884c\u4e86\u8c03\u4f18\uff0c\u4e0b\u9762\u5c55\u793a\u4e86\u5728 A100 \u4e0a\u8c03\u4f18\u524d\u540e\u7684\u5e26\u5bbd\u5360\u7528\u548c\u8ba1\u7b97\u65f6\u95f4\u6bd4\u8f83\uff1a \u6846\u67b6 \u6570\u636e\u7c7b\u578b Op\u7c7b\u578b \u5e26\u5bbd\u5229\u7528\u7387 \u8017\u65f6 PyTorch Float32 UpsampleNearest2D forward 28.30% 111.42us PyTorch Float32 UpsampleNearest2D backward 60.16% 65.12us OneFlow \u672a\u4f18\u5316 Float32 UpsampleNearest2D forward 12.54% 265.82us OneFlow \u672a\u4f18\u5316 Float32 UpsampleNearest2D backward 18.4% 260.22us OneFlow \u4f18\u5316\u540e Float32 UpsampleNearest2D forward 52.18% 61.44us OneFlow \u4f18\u5316\u540e Float32 UpsampleNearest2D backward 77.66% 50.56us PyTorch Float16 UpsampleNearest2D forward 16.99% 100.38us PyTorch Float16 UpsampleNearest2D backward 31.56% 57.38us OneFlow \u672a\u4f18\u5316 Float16 UpsampleNearest2D forward 7.07% 262.82us OneFlow \u672a\u4f18\u5316 Float16 UpsampleNearest2D backward 41.04% 558.88us OneFlow \u4f18\u5316\u540e Float16 UpsampleNearest2D forward 43.26% 35.36us OneFlow \u4f18\u5316\u540e Float16 UpsampleNearest2D backward 44.82% 40.26us \u4e0a\u8ff0\u7ed3\u679c\u4f7f\u7528 /usr/local/cuda/bin/ncu -o torch_upsample /home/python3 debug.py \u5f97\u5230profile\u6587\u4ef6\u540e\u4f7f\u7528Nsight Compute\u6253\u5f00\u8bb0\u5f55\u3002 \u57fa\u4e8e\u4e0a\u8ff0\u5bf9 UpsampleNearest2D \u7684\u4f18\u5316\uff0cOneFlow \u5728 FP32 \u548c FP16 \u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u548c\u5e26\u5bbd\u90fd\u5927\u5e45\u8d85\u8d8a\u4e4b\u524d\u672a\u7ecf\u4f18\u5316\u7684\u7248\u672c\uff0c\u5e76\u4e14\u76f8\u6bd4\u4e8e PyTorch \u4e5f\u6709\u8f83\u5927\u5e45\u5ea6\u7684\u9886\u5148\u3002 \u672c\u6b21\u4f18\u5316\u6d89\u53ca\u5230\u7684 \u77e5\u8bc6\u70b9\u603b\u7ed3 \u5982\u4e0b\uff08by OneFlow \u67f3\u4fca\u4e1e\uff09\uff1a \u4e3a\u5e38\u89c1\u7684\u60c5\u51b5\u5199\u7279\u4f8b\uff0c\u6bd4\u5982\u8fd9\u91cc\u5c31\u662f\u4e3a\u91c7\u6837\u500d\u6570\u4e3a2\u7684Nearest\u63d2\u503c\u5199\u7279\u4f8b\uff0c\u907f\u514d\u4f7f\u7528NdIndexHelper\u5e26\u6765\u7684\u989d\u5916\u8ba1\u7b97\u5f00\u9500\uff0c\u4e0d\u7528\u8ffd\u6c42\u518d\u4e00\u4e2akernel\u5b9e\u73b0\u4e2d\u540c\u65f6\u62e5\u6709\u901a\u7528\u578b\u548c\u9ad8\u6548\u6027\uff1b \u6574\u6570\u9664\u6cd5\u5f00\u9500\u5927\uff08\u4f46\u662f\u7f16\u8bd1\u5668\u6709\u7684\u65f6\u5019\u4f1a\u4f18\u5316\u6389\u4e00\u4e9b\u9664\u6cd5\uff09\uff0cnchw\u4e2d\u7684nc\u4e0d\u9700\u8981\u5206\u5f00\uff0c\u5408\u5e76\u5728\u4e00\u8d77\u8ba1\u7b97\u51cf\u5c11\u8ba1\u7b97\u91cf\uff1b int64_t \u9664\u6cd5\u7684\u5f00\u9500\u66f4\u5927\uff0c\u7528int32\u6ee1\u8db3\u5927\u90e8\u5206\u9700\u6c42\uff0c\u5176\u5b9e\u8fd9\u91cc\u8fd8\u6709\u4e00\u4e2a\u5feb\u901f\u6574\u6570\u9664\u6cd5\u7684\u95ee\u9898\uff1b \u53cd\u5411 Kernel \u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u5faa\u73af dx \u76f8\u6bd4 \u5faa\u73af dy \uff0c\u5b9e\u9645\u4e0a\u5c06\u5750\u6807\u6362\u7b97\u7684\u5f00\u9500\u51cf\u5c11\u5230\u539f\u6765\u7684 1/4\uff1b CUDA GMEM \u7684\u5f00\u9500\u7684\u4e5f\u6bd4\u8f83\u5927\uff0c\u867d\u7136\u7f16\u8bd1\u5668\u6709\u53ef\u80fd\u505a\u4f18\u5316\uff0c\u4f46\u662f\u663e\u5f0f\u7684\u4f7f\u7528\u5c40\u90e8\u53d8\u91cf\u66f4\u597d\uff1b \u4e00\u6b21 Memset \u7684\u5f00\u9500\u4e5f\u5f88\u5927\uff0c\u548c\u5199\u4e00\u6b21\u4e00\u6837\uff0c\u6240\u4ee5\u53cd\u5411 Kernel \u4e2d\u5bf9 dx \u4f7f\u7528Memset \u6e05\u96f6\u7684\u65f6\u673a\u9700\u8981\u6ce8\u610f\uff1b atomicAdd \u5f00\u9500\u5f88\u5927\uff0c\u5373\u4f7f\u629b\u5f00\u4e3a\u4e86\u5b9e\u73b0\u539f\u5b50\u6027\u53ef\u80fd\u9700\u8981\u7684\u9501\u603b\u7ebf\u7b49\uff0catomicAdd \u9700\u8981\u628a\u539f\u6765\u7684\u503c\u5148\u8bfb\u51fa\u6765\uff0c\u518d\u5199\u56de\u53bb\uff1b\u53e6\u5916\uff0chalf\u7684atomicAdd \u5de8\u6162\u65e0\u6bd4\uff0c\u6162\u5230\u5982\u679c\u4e00\u4e2a\u7b97\u6cd5\u9700\u8981\u7528\u5230 atomicAdd\uff0c\u90a3\u4e48\u76f8\u6bd4\u4e8e\u7528 half \uff0c\u8f6c\u6210 float \uff0c\u518datomicAdd\uff0c\u518d\u8f6c\u56de\u53bb\u8fd8\u8981\u6162\u5f88\u591a\uff1b \u5411\u91cf\u5316\u8bbf\u5b58\uff1b \u5bf9\u8fd9\u4e2a Kernel \u8fdb\u884c\u7279\u5316\u662f\u4f18\u5316\u7684\u7b2c\u4e00\u6b65\uff0c\u57fa\u4e8e\u8fd9\u4e2a\u4f18\u5316\u53ef\u4ee5\u7ed9 YOLOv5 \u7684\u5355\u5361 PipLine \u5e26\u67651%\u7684\u63d0\u5347\u3002 0x2.2 \u5bf9bbox_iou\u51fd\u6570\u8fdb\u884c\u4f18\u5316 (\u5782\u76f4Fuse\u4f18\u5316) \u901a\u8fc7\u5bf9nsys\u7684\u5206\u6790\uff0c\u6211\u4eec\u53d1\u73b0\u65e0\u8bba\u662fone-yolov5\u8fd8\u662fultralytics/yolov5\uff0c\u5728\u8ba1\u7b97Loss\u7684\u9636\u6bb5\u90fd\u6709\u4e00\u4e2a\u8017\u65f6\u6bd4\u8f83\u4e25\u91cd\u7684bbox_iou\u51fd\u6570\uff0c\u6211\u4eec\u8fd9\u91cc\u5148\u8d34\u4e00\u4e0bbbox_iou\u90e8\u5206\u7684\u4ee3\u7801\uff1a def bbox_iou ( box1 , box2 , xywh = True , GIoU = False , DIoU = False , CIoU = False , eps = 1e-7 ): # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4) # Get the coordinates of bounding boxes if xywh : # transform from xywh to xyxy ( x1 , y1 , w1 , h1 ), ( x2 , y2 , w2 , h2 ) = box1 . chunk ( 4 , - 1 ), box2 . chunk ( 4 , - 1 ) w1_ , h1_ , w2_ , h2_ = w1 / 2 , h1 / 2 , w2 / 2 , h2 / 2 b1_x1 , b1_x2 , b1_y1 , b1_y2 = x1 - w1_ , x1 + w1_ , y1 - h1_ , y1 + h1_ b2_x1 , b2_x2 , b2_y1 , b2_y2 = x2 - w2_ , x2 + w2_ , y2 - h2_ , y2 + h2_ else : # x1, y1, x2, y2 = box1 b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 . chunk ( 4 , - 1 ) b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 . chunk ( 4 , - 1 ) w1 , h1 = b1_x2 - b1_x1 , ( b1_y2 - b1_y1 ) . clamp ( eps ) w2 , h2 = b2_x2 - b2_x1 , ( b2_y2 - b2_y1 ) . clamp ( eps ) # Intersection area inter = ( b1_x2 . minimum ( b2_x2 ) - b1_x1 . maximum ( b2_x1 )) . clamp ( 0 ) * \\ ( b1_y2 . minimum ( b2_y2 ) - b1_y1 . maximum ( b2_y1 )) . clamp ( 0 ) # Union Area union = w1 * h1 + w2 * h2 - inter + eps # IoU iou = inter / union if CIoU or DIoU or GIoU : cw = b1_x2 . maximum ( b2_x2 ) - b1_x1 . minimum ( b2_x1 ) # convex (smallest enclosing box) width ch = b1_y2 . maximum ( b2_y2 ) - b1_y1 . minimum ( b2_y1 ) # convex height if CIoU or DIoU : # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1 c2 = cw ** 2 + ch ** 2 + eps # convex diagonal squared rho2 = (( b2_x1 + b2_x2 - b1_x1 - b1_x2 ) ** 2 + ( b2_y1 + b2_y2 - b1_y1 - b1_y2 ) ** 2 ) / 4 # center dist ** 2 if CIoU : # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47 v = ( 4 / math . pi ** 2 ) * ( torch . atan ( w2 / h2 ) - torch . atan ( w1 / h1 )) . pow ( 2 ) with torch . no_grad (): alpha = v / ( v - iou + ( 1 + eps )) return iou - ( rho2 / c2 + v * alpha ) # CIoU return iou - rho2 / c2 # DIoU c_area = cw * ch + eps # convex area return iou - ( c_area - union ) / c_area # GIoU https://arxiv.org/pdf/1902.09630.pdf return iou # IoU \u4ee5one-yolov5\u7684\u539f\u59cb\u6267\u884c\u5e8f\u5217\u56fe\u4e3a\u4f8b\uff0c\u6211\u4eec\u53d1\u73b0bbox_iou\u51fd\u6570\u8fd9\u90e8\u5206\u6bcf\u4e00\u6b21\u8fd0\u884c\u90fd\u9700\u8981\u82b12.6ms\u5de6\u53f3\u3002\u5e76\u4e14\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u8fd9\u91cc\u6709\u5927\u91cf\u7684\u5c0f\u7684Kernel\u88ab\u8c03\u5ea6\uff0c\u867d\u7136\u6bcf\u4e2a\u5c0fKernel\u8ba1\u7b97\u5f88\u5feb\uff0c\u4f46\u8bbf\u95eeGlobal Memory\u4ee5\u53ca\u591a\u6b21Kernel Launch\u7684\u5f00\u9500\u4e5f\u662f\u6bd4\u8f83\u5927\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u505a\u4e86\u51e0\u4e2afuse\u6765\u964d\u4f4eKernel Launch\u7684\u5f00\u9500\u4ee5\u53ca\u51cf\u5c11\u8bbf\u95eeGlobal Memrory\u6765\u63d0\u5347\u5e26\u5bbd\u3002 \u7136\u540e\u7ecf\u8fc7\u6211\u4eec\u7684Kernel Fuse\u4e4b\u540e\u7684\u8017\u65f6\u53ea\u9700\u8981600+us\u3002 \u5177\u4f53\u6765\u8bf4\u6211\u4eec\u8fd9\u91cc\u505a\u4e86\u5982\u4e0b\u7684\u51e0\u4e2afuse\uff1a fused_get_boundding_boxes_coord\uff1ahttps://github.com/Oneflow-Inc/oneflow/pull/9433 fused_get_intersection_area: https://github.com/Oneflow-Inc/oneflow/pull/9485 fused_get_iou: https://github.com/Oneflow-Inc/oneflow/pull/9475 fused_get_convex_diagonal_squared: https://github.com/Oneflow-Inc/oneflow/pull/9481 fused_get_center_dist: https://github.com/Oneflow-Inc/oneflow/pull/9446 fused_get_ciou_diagonal_angle: https://github.com/Oneflow-Inc/oneflow/pull/9465 fused_get_ciou_result: https://github.com/Oneflow-Inc/oneflow/pull/9462 \u7136\u540e\u6211\u4eec\u5728one-yolov5\u7684train.py\u4e2d\u6269\u5c55\u4e86\u4e00\u4e2a --bbox_iou_optim \u9009\u9879\uff0c\u53ea\u8981\u8bad\u7ec3\u7684\u65f6\u5019\u5e26\u4e0a\u8fd9\u4e2a\u9009\u9879\u5c31\u4f1a\u81ea\u52a8\u8c03\u7528\u4e0a\u9762\u7684fuse kernel\u6765\u5bf9bbox_iou\u51fd\u6570\u8fdb\u884c\u4f18\u5316\u4e86\uff0c\u5177\u4f53\u8bf7\u770b\uff1ahttps://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L224-L284 \u3002\u5bf9bbox_iou\u8fd9\u4e2a\u51fd\u6570\u7684\u4e00\u7cfb\u5217\u5782\u76f4Fuse\u4f18\u5316\u4f7f\u5f97YOLOv5\u6574\u4f53\u7684\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u4e868%\u5de6\u53f3\uff0c\u662f\u4e00\u4e2a\u5341\u5206\u6709\u6548\u7684\u4f18\u5316\u3002 0x2.3 \u5bf9\u6a21\u578b\u6ed1\u52a8\u5e73\u5747\u66f4\u65b0\u8fdb\u884c\u4f18\u5316\uff08\u6c34\u5e73Fuse\u4f18\u5316\uff09 \u5728 YOLOv5 \u4e2d\u4f1a\u4f7f\u7528EMA\uff08\u6307\u6570\u79fb\u52a8\u5e73\u5747\uff09\u5bf9\u6a21\u578b\u7684\u53c2\u6570\u505a\u5e73\u5747, \u4e00\u79cd\u7ed9\u4e88\u8fd1\u671f\u6570\u636e\u66f4\u9ad8\u6743\u91cd\u7684\u5e73\u5747\u65b9\u6cd5, \u4ee5\u6c42\u63d0\u9ad8\u6d4b\u8bd5\u6307\u6807\u5e76\u589e\u52a0\u6a21\u578b\u9c81\u68d2\u3002\u8fd9\u91cc\u7684\u6838\u5fc3\u64cd\u4f5c\u5982\u4e0b\u4ee3\u7801\u6240\u793a\uff1a def update ( self , model ): # Update EMA parameters self . updates += 1 d = self . decay ( self . updates ) msd = de_parallel ( model ) . state_dict () # model state_dict for k , v in self . ema . state_dict () . items (): if v . dtype . is_floating_point : # true for FP16 and FP32 v *= d v += ( 1 - d ) * msd [ k ] . detach () # assert v.dtype == msd[k].dtype == flow.float32, f'{k}: EMA {v.dtype} and model {msd[k].dtype} must be FP32' \u4ee5\u4e0b\u662f\u672a\u4f18\u5316\u524d\u7684\u8fd9\u4e2a\u51fd\u6570\u7684\u65f6\u5e8f\u56fe\uff1a \u8fd9\u90e8\u5206\u7684cuda kernel\u7684\u6267\u884c\u901f\u5ea6\u5927\u6982\u4e3a7.4ms\uff0c\u800c\u7ecf\u8fc7\u6211\u4eec\u6c34\u5e73Fuse\u4f18\u5316\uff08\u5373MultiTensor\uff09\uff0c\u8fd9\u90e8\u5206\u7684\u8017\u65f6\u60c5\u51b5\u964d\u4f4e\u4e3a\u4e86127us\u3002 \u5e76\u4e14\u6c34\u5e73\u65b9\u5411\u7684Kernel Fuse\u4e5f\u540c\u6837\u964d\u4f4e\u4e86Kernel Launch\u7684\u5f00\u9500\uff0c\u4f7f\u5f97\u524d\u540e2\u4e2aIter\u7684\u95f4\u9699\u4e5f\u8fdb\u4e00\u6b65\u7f29\u77ed\u4e86\u3002\u6700\u7ec8\u8fd9\u4e2a\u4f18\u5316\u4e3aYOLOv5\u7684\u6574\u4f53\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u4e8610%\u5de6\u53f3\u3002\u672c\u4f18\u5316\u5b9e\u73b0\u7684pr\u5982\u4e0b\uff1ahttps://github.com/Oneflow-Inc/oneflow/pull/9498 \u6b64\u5916\uff0c\u5bf9\u4e8eOptimizer\u90e8\u5206\u540c\u6837\u53ef\u4ee5\u6c34\u5e73\u5e76\u884c\uff0c\u6240\u4ee5\u6211\u4eec\u5728 one-yolov5 \u91cc\u9762\u8bbe\u7f6e\u4e86\u4e00\u4e2a multi_tensor_optimizer \u6807\u5fd7\uff0c\u6253\u5f00\u8fd9\u4e2a\u6807\u5fd7\u5c31\u53ef\u4ee5\u8ba9 optimizer \u4ee5\u53ca EMA \u7684 update\u4ee5\u6c34\u5e73\u5e76\u884c\u7684\u65b9\u5f0f\u8fd0\u884c\u4e86\u3002 \u5173\u4e8eMultiTensor\u8fd9\u4e2a\u77e5\u8bc6\u53ef\u4ee5\u770b zzk \u7684\u8fd9\u7bc7\u6587\u7ae0\uff1ahttps://zhuanlan.zhihu.com/p/566595789\u3002zzk \u5728 OneFlow \u4e2d\u4e5f\u5b9e\u73b0\u4e86\u4e00\u5957 MultiTensor \u65b9\u6848\uff0c\u4e0a\u9762\u7684 PR 9498 \u4e5f\u662f\u57fa\u4e8e\u8fd9\u5957 MultiTensor \u65b9\u6848\u5b9e\u73b0\u7684\u3002\u4ecb\u4e8e\u7bc7\u5e45\u539f\u56e0\u6211\u4eec\u5c31\u4e0d\u5c55\u5f00\u8fd9\u4e2a MultiTensor \u7684\u4ee3\u7801\u5b9e\u73b0\u4e86\uff0c\u611f\u5174\u8da3\u7684\u53ef\u4ee5\u7559\u8a00\u540e\u7eed\u5355\u72ec\u8bb2\u89e3\u3002 0x3. \u4f7f\u7528\u65b9\u6cd5 \u4e0a\u9762\u5df2\u7ecf\u63d0\u5230\u6240\u6709\u7684\u4f18\u5316\u90fd\u96c6\u4e2d\u4e8e bbox_iou_optim \u548c multi_tensor_optimizer \u8fd9\u4e24\u4e2a\u6269\u5c55\u7684Flag\uff0c\u53ea\u8981\u6211\u4eec\u8bad\u7ec3\u7684\u65f6\u5019\u6253\u5f00\u8fd9\u4e24\u4e2aFlag\u5c31\u53ef\u4ee5\u4eab\u53d7\u5230\u4e0a\u8ff0\u4f18\u5316\u4e86\u3002\u5176\u4ed6\u7684\u8fd0\u884c\u547d\u4ee4\u548cOne-YOLOv5\u6ca1\u6709\u53d8\u5316\uff0c\u4ee5One-YOLOv5\u5728GTX 3090\u4e0a\u8bad\u7ec3yolov5s\u4e3a\u4f8b\uff0c\u547d\u4ee4\u4e3a\uff1a python train.py --batch 16 --cfg models/yolov5s.yaml --weights '' --data coco.yaml --img 640 --device 0 --epoch 1 --bbox_iou_optim --multi_tensor_optimizer 0x4. \u603b\u7ed3 \u76ee\u524d\uff0cyolov5s\u7f51\u7edc\u5f53\u4ee5BatchSize=16\u7684\u914d\u7f6e\u5728GeForce RTX 3090\u4e0a\uff08\u8fd9\u91cc\u6307\u5b9aBatchSize\u4e3a16\u65f6\uff09\u8bad\u7ec3COCO\u6570\u636e\u96c6\u65f6\uff0cOneFlow\u76f8\u6bd4PyTorch\u53ef\u4ee5\u8282\u7701 11.35 \u4e2a\u5c0f\u65f6\u3002\u6211\u4eec\u76f8\u4fe1\u8fd9\u7bc7\u6587\u7ae0\u63d0\u5230\u7684\u4f18\u5316\u6280\u5de7\u4e5f\u53ef\u4ee5\u5bf9\u66f4\u591a\u7684\u4ece\u4e8b\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u751f\u6216\u8005\u5de5\u7a0b\u5e08\u5e26\u6765\u542f\u53d1\u3002\u6b22\u8fce\u5927\u5bb6star one-yolov5\u9879\u76ee\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 One-YOLOv5\u7684\u4f18\u5316\u5de5\u4f5c\u5b9e\u9645\u4e0a\u4e0d\u4ec5\u5305\u542b\u6027\u80fd\uff0c\u6211\u4eec\u76ee\u524d\u4e5f\u4ed8\u51fa\u4e86\u5f88\u591a\u5fc3\u8840\u5728\u6587\u6863\u548c\u6e90\u7801\u89e3\u8bfb\u4e0a\uff0c\u540e\u7eed\u4f1a\u7ee7\u7eed\u653e\u51fa\u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b\u7684\u5176\u4ed6\u6587\u7ae0\uff0c\u5e76\u5c06\u5c3d\u5feb Relase \u65b0\u7248\u672c\u3002\u8bf7\u671f\u5f85\u540e\u7eed\u53d1\u5c55... 0x5. \u81f4\u8c22 \u611f\u8c22\u67f3\u4fca\u4e1e\u540c\u4e8b\u5728\u8fd9\u6b21\u8c03\u4f18\u4e2d\u63d0\u4f9b\u7684 idea \u548c\u6280\u672f\u652f\u6301\uff0c\u611f\u8c22\u80e1\u4f3d\u9b41\u540c\u5b66\u5b9e\u73b0\u7684\u4e00\u4e9bfuse kernel\uff0c\u611f\u8c22\u90d1\u6cfd\u5eb7\u548c\u5b8b\u6613\u627f\u7684 MultiTensorUpdate \u5b9e\u73b0\uff0c\u611f\u8c22\u51af\u6587\u7684\u7cbe\u5ea6\u9a8c\u8bc1\u5de5\u4f5c\u4ee5\u53ca\u6587\u6863\u652f\u6301\uff0c\u4ee5\u53ca\u5c0f\u7cd6\u5bf9 One-YOLOv5 \u7684\u63a8\u5e7f\u5e2e\u52a9\u548c\u5e2e\u52a9\u672c\u9879\u76ee\u53d1\u5c55\u7684\u5de5\u7a0b\u5e08\u4eec\u5982\u8d75\u9732\u9633\uff0c\u6881\u5fb7\u6f8e\u7b49\u7b49\u3002\u672c\u9879\u76ee\u672a\u6765\u4f1a\u7ee7\u7eed\u53d1\u529b\u505a\u51fa\u66f4\u591a\u7684\u6210\u679c\u3002","title":"\u6d88\u8d39\u7ea7\u663e\u5361\u7684\u6625\u5929\uff0cGTX 3090 YOLOv5s\u5355\u5361\u5b8c\u6574\u8bad\u7ec3COCO\u6570\u636e\u96c6\u7f29\u77ed11.35\u4e2a\u5c0f\u65f6"},{"location":"tutorials/00_chapter/optim_speed_version1.html#0x0","text":"\u5927\u5bb6\u597d\uff0c\u5f88\u9ad8\u5174\u53c8\u53ef\u4ee5\u4e3a\u5927\u5bb6\u5e26\u6765One-YOLOv5\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5728 One-YOLOv5 \u53d1\u5e03\uff0c\u4e00\u4e2a\u8bad\u5f97\u66f4\u5feb\u7684YOLOv5 \u53d1\u5e03\u540e\u6536\u5230\u4e86\u5f88\u591a\u7b97\u6cd5\u884c\u4e1a\u670b\u53cb\u7684\u5173\u6ce8\uff0c\u5341\u5206\u611f\u8c22\u3002\u4f46\u53ef\u80fd\u5927\u5bb6\u90fd\u5728\u601d\u8003\u4e00\u4e2a\u95ee\u9898\uff0c\u867d\u7136OneFlow\u7684\u517c\u5bb9\u6027\u505a\u5f97\u5f88\u597d\uff0c\u53ef\u4ee5\u5f88\u65b9\u4fbf\u7684\u79fb\u690dYOLOv5\u5e76\u4f7f\u7528OneFlow\u540e\u7aef\u6765\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u6211\u4e3a\u4ec0\u4e48\u8981\u7528\u4f60\u5462\uff1f\u80fd\u5e2e\u6211\u7f29\u77ed\u6a21\u578b\u5f00\u53d1\u5468\u671f\u5417\uff1f\u5e2e\u6211\u89e3\u51b3\u4e86\u4efb\u4f55\u75db\u70b9\u5417\uff1f\u672c\u7bc7\u6587\u7ae0\u5c06\u5c1d\u8bd5\u56de\u7b54\u8fd9\u51e0\u4e2a\u95ee\u9898\u3002 \u4e5f\u8bb8\u719f\u6089\u6211\u7684\u670b\u53cb\u77e5\u9053\u6211\u5728\u5165\u804c\u4e00\u6d41\u79d1\u6280\u4e4b\u524d\u4e5f\u662f\u4e00\u540d\u7b97\u6cd5\u5de5\u7a0b\u5e08\uff0c\u6211\u4e4b\u524d\u7684\u5f00\u53d1\u673a\u5668\u4e5f\u53ea\u6709\u4e24\u5f20GTX 3090\u6d88\u8d39\u7ea7\u663e\u5361\u800c\u5df2\u3002\u4f46\u5b9e\u9645\u4e0a\u516c\u53f8\u5927\u591a\u6570\u7531\u6211\u4e0a\u7ebf\u7684\u68c0\u6d4b\u4ea7\u54c1\u57fa\u672c\u4e0a\u4e5f\u5c31\u662f\u9760\u8fd91\u5f20\u6216\u80052\u5f20GTX 3090\u5b8c\u6210\u7684\u3002\u7531\u4e8e\u6210\u672c\u95ee\u9898\uff0c\u5f88\u591a\u4e2d\u5c0f\u516c\u53f8\u6ca1\u6709\u7ec4\u4e00\u4e2aA100\u96c6\u7fa4\u6216\u8005\u76f4\u63a5\u4e0a\u6570\u5341\u5f20\u5361\u6765\u8bad\u7ec3\u68c0\u6d4b\u6a21\u578b\u7684\u5b9e\u529b\uff0c\u6240\u4ee5\u8fd9\u4e2a\u65f6\u5019\u5728\u5355\u5361\u6216\u80052\u5361\u4e0a\u5c06\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u505a\u5feb\u5c31\u5c24\u4e3a\u91cd\u8981\u4e86\u3002\u628a\u6a21\u578b\u8bad\u7ec3\u505a\u5feb\u4e4b\u540e\u662f\u771f\u7684\u53ef\u4ee5\u964d\u672c\u589e\u6548\uff0c\u63d0\u9ad8\u6a21\u578b\u751f\u4ea7\u7387\u7684\u3002 \u6240\u4ee5\uff0c\u8fd1\u671f\u6211\u548c\u5b9e\u4e60\u751f\u5c0f\u4f19\u4f34\u4e00\u8d77\u505a\u4e86\u8fd9\u4e48\u4e00\u4ef6\u4e8b\u60c5\uff0c\u6211\u4eec\u5728\u5355\u5361\u4e0a\u51ed\u501f\u5bf9YOLOv5\u7684\u6027\u80fd\u5206\u6790\u4ee5\u53ca\u51e0\u4e2a\u7b80\u5355\u7684\u4f18\u5316\u5c06GTX 3090 FP32 YOLOv5s\u7684\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u4e86\u8fd120%\u3002\u5bf9\u4e8e\u9700\u8981\u8fed\u4ee3300\u4e2aEpoch\u7684COCO\u6570\u636e\u96c6\u6765\u8bf4\u76f8\u6bd4 ultralytics/yolov5 \u6211\u4eec\u7f29\u77ed\u4e8611.35\u4e2a\u5c0f\u65f6\u7684\u8bad\u7ec3\u65f6\u95f4\u3002\u6211\u4eec\u51b3\u5b9a\u5728\u672c\u6587\u5206\u4eab\u6211\u4eec\u7684\u6240\u6709\u4f18\u5316\u6280\u672f\uff0c\u5982\u679c\u4f60\u662f\u4e00\u540dPyTorch\u548cOneFlow\u7684\u7231\u597d\u8005\uff0c\u7279\u522b\u7684\u5982\u679c\u4f60\u662f\u4e00\u540d\u65e5\u5e38\u548c\u68c0\u6d4b\u6a21\u578b\u6253\u4ea4\u9053\u4f46\u8d44\u6e90\u76f8\u5bf9\u53d7\u9650\uff0c\u90a3\u4e48\u672c\u6587\u7684\u4f18\u5316\u65b9\u6cd5\u5c06\u5bf9\u4f60\u4ea7\u751f\u4e00\u5b9a\u5f71\u54cd\u3002 \u6700\u540e\uff0c\u5982\u679c\u672c\u6587\u5e2e\u52a9\u5230\u4e86\u4f60\uff0c\u8bf7\u4e00\u5b9a\u7ed9\u6211\u4eec\u70b9\u4e2astar\uff0c\u6211\u548c OneFlow \u4e5f\u4f1a\u7528\u66f4\u591a\u7684\u9ad8\u8d28\u91cf\u6280\u672f\u5206\u4eab\u6765\u56de\u9988\u5927\u5bb6\u3002 one-yolov5\u94fe\u63a5\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 \u5bf9 One-YOLOv5 \u611f\u5174\u8da3\u7684\u4f19\u4f34\u53ef\u4ee5\u6dfb\u52a0 bbuf23333 \u8fdb\u5165 One-YOLOv5 \u5fae\u4fe1\u4ea4\u6d41\u7fa4\u3002","title":"0x0. \u524d\u8a00"},{"location":"tutorials/00_chapter/optim_speed_version1.html#0x1","text":"\u6211\u4eec\u5c55\u793a\u4e00\u4e0b\u5206\u522b\u4f7f\u7528One-YOLOv5\u4ee5\u53ca ultralytics/yolov5 \u5728GTX 3090\u5355\u5361\u4e0a\u4f7f\u7528YOLOv5s FP32\u6a21\u578b\u8bad\u7ec3COCO\u6570\u636e\u96c6\u4e00\u4e2aEpoch\u6240\u9700\u7684\u8017\u65f6\uff1a \u53ef\u4ee5\u770b\u5230\u5728\u5355\u5361\u6a21\u5f0f\u4e0b\uff0c\u7ecf\u8fc7\u6211\u4eec\u7684\u4f18\u5316\u76f8\u6bd4\u4e8e ultralytics/yolov5 \u7684\u8bad\u7ec3\u901f\u5ea6\uff0c\u6211\u4eec\u63d0\u5347\u4e86 20% \u5de6\u53f3\u3002 \u7136\u540e\u6211\u4eec\u518d\u5c55\u793a\u4e00\u4e0b2\u5361DDP\u6a21\u5f0fYOLOv5s FP32\u6a21\u578b\u8bad\u7ec3COCO\u6570\u636e\u96c6\u4e00\u4e2aEpoch\u6240\u9700\u7684\u8017\u65f6\uff1a \u5728DDP\u6a21\u5f0f\u4e0b\u7684\u6027\u80fd\u63d0\u5347\u5e45\u5ea6\u6ca1\u6709\u5355\u5361\u8fd9\u4e48\u591a\uff0c\u731c\u6d4b\u53ef\u80fd\u662f\u901a\u4fe1\u90e8\u5206\u7684\u5f00\u9500\u6bd4\u8f83\u5927\uff0c\u540e\u7eed\u6211\u4eec\u4f1a\u518d\u7814\u7a76\u4e00\u4e0b\u3002","title":"0x1. \u7ed3\u679c\u5c55\u793a"},{"location":"tutorials/00_chapter/optim_speed_version1.html#0x2","text":"\u6211\u4eec\u5728\u8fd9\u4e00\u8282\u5b8c\u6210\u6280\u672f\u63ed\u79d8\u3002\u6211\u4eec\u6df1\u5ea6\u5206\u6790\u4e86PyTorch\u7684YOLOv5\u7684\u6267\u884c\u5e8f\u5217\uff0c\u6211\u4eec\u53d1\u73b0\u5f53\u524dYOLOv5\u4e3b\u8981\u5b58\u57283\u4e2a\u4f18\u5316\u70b9\u3002\u7b2c\u4e00\u4e2a\u5c31\u662f\u5bf9\u4e8eUpsample\u7b97\u5b50\u7684\u6539\u8fdb\uff0c\u7531\u4e8eYOLOv5\u4f7f\u7528\u4e0a\u91c7\u6837\u662f\u89c4\u6574\u7684\u6700\u8fd1\u90bb2\u500d\u63d2\u503c\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u5b9e\u73b0\u4e00\u4e2a\u7279\u6b8aKernel\u964d\u4f4e\u8ba1\u7b97\u91cf\u5e76\u63d0\u5347\u5e26\u5bbd\u3002\u7b2c\u4e8c\u4e2a\u5c31\u662f\u5728YOLOv5\u4e2d\u5b58\u5728\u4e00\u4e2a\u6ed1\u52a8\u66f4\u65b0\u6a21\u578b\u53c2\u6570\u7684\u64cd\u4f5c\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u542f\u52a8\u4e86\u5f88\u591a\u788e\u7684CUDA Kernel\uff0c\u800c\u6bcf\u4e2aCUDA Kernel\u7684\u6267\u884c\u65f6\u95f4\u90fd\u975e\u5e38\u77ed\uff0c\u6240\u4ee5\u542f\u52a8\u5f00\u9500\u4e0d\u80fd\u5ffd\u7565\u3002\u6211\u4eec\u4f7f\u7528\u6c34\u5e73\u5e76\u884cCUDA Kernel\u7684\u65b9\u5f0f\uff08MultiTensor\uff09\u5bf9\u5176\u5b8c\u6210\u4e86\u4f18\u5316\uff0c\u57fa\u4e8e\u8fd9\u4e2a\u4f18\u5316One-YOLOv5\u83b7\u5f97\u4e869%\u7684\u52a0\u901f\u3002\u7b2c\u4e09\u4e2a\u4f18\u5316\u70b9\u6765\u6e90\u4e8e\u5bf9YOLOv5 nsys\u6267\u884c\u5e8f\u5217\u7684\u89c2\u5bdf\uff0c\u6211\u4eec\u53d1\u73b0\u5728ComputeLoss\u90e8\u5206\u51fa\u73b0\u7684bbox_iou\u662f\u6574\u4e2aLoss\u8ba1\u7b97\u90e8\u5206\u4e00\u4e2a\u6bd4\u8f83\u5927\u7684\u74f6\u9888\uff0c\u6211\u4eec\u5728bbox_iou\u51fd\u6570\u90e8\u5206\u5b8c\u6210\u4e86\u591a\u4e2a\u5782\u76f4\u7684Kernel Fuse\uff0c\u4f7f\u5f97\u5b83\u7684\u5f00\u9500\u4ece\u6700\u521d\u76843.xms\u964d\u4f4e\u5230\u4e86\u51e0\u767e\u4e2aus\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5206\u522b\u8be6\u7ec6\u9610\u8ff0\u8fd9\u51e0\u79cd\u4f18\u5316\uff1a","title":"0x2. \u4f18\u5316\u624b\u6bb5"},{"location":"tutorials/00_chapter/optim_speed_version1.html#0x21-upsamplenearest2d","text":"\u4e3a\u4e86\u4e0d\u5199\u5f97\u5570\u55e6\uff0c\u6211\u8fd9\u91cc\u76f4\u63a5\u5c55\u793a\u6211\u4eec\u5bf9UpsampleNearest2D\u8fdb\u884c\u8c03\u4f18\u7684\u6280\u672f\u603b\u7ed3\uff0c\u5927\u5bb6\u53ef\u4ee5\u7ed3\u5408\u4e0b\u9762\u7684 pr \u94fe\u63a5\u6765\u5bf9\u5e94\u4e0b\u9762\u7684\u77e5\u8bc6\u70b9\u603b\u7ed3\u3002\u6211\u4eec\u5728A100 40G\u4e0a\u6d4b\u8bd5 UpsampleNearest2D \u7b97\u5b50\u7684\u6027\u80fd\u8868\u73b0\u3002\u8fd9\u5757\u5361\u7684\u5cf0\u503c\u5e26\u5bbd\u57281555Gb/s , \u6211\u4eec\u4f7f\u7528\u7684CUDA\u7248\u672c\u4e3a11.8\u3002 \u8fdb\u884c Profile \u7684\u7a0b\u5e8f\u5982\u4e0b\uff1a import oneflow as flow x = flow . randn ( 16 , 32 , 80 , 80 , device = \"cuda\" , dtype = flow . float32 ) . requires_grad_ () m = flow . nn . Upsample ( scale_factor = 2.0 , mode = \"nearest\" ) y = m ( x ) print ( y . device ) y . sum () . backward () https://github.com/Oneflow-Inc/oneflow/pull/9415 & https://github.com/Oneflow-Inc/oneflow/pull/9424 \u8fd9\u4e24\u4e2a PR \u5206\u522b\u9488\u5bf9 UpsampleNearest2D \u8fd9\u4e2a\u7b97\u5b50\uff08\u8fd9\u4e2a\u7b97\u5b50\u662f YOLO \u7cfb\u5217\u7b97\u6cd5\u5927\u91cf\u4f7f\u7528\u7684\uff09\u7684\u524d\u540e\u5411\u8fdb\u884c\u4e86\u8c03\u4f18\uff0c\u4e0b\u9762\u5c55\u793a\u4e86\u5728 A100 \u4e0a\u8c03\u4f18\u524d\u540e\u7684\u5e26\u5bbd\u5360\u7528\u548c\u8ba1\u7b97\u65f6\u95f4\u6bd4\u8f83\uff1a \u6846\u67b6 \u6570\u636e\u7c7b\u578b Op\u7c7b\u578b \u5e26\u5bbd\u5229\u7528\u7387 \u8017\u65f6 PyTorch Float32 UpsampleNearest2D forward 28.30% 111.42us PyTorch Float32 UpsampleNearest2D backward 60.16% 65.12us OneFlow \u672a\u4f18\u5316 Float32 UpsampleNearest2D forward 12.54% 265.82us OneFlow \u672a\u4f18\u5316 Float32 UpsampleNearest2D backward 18.4% 260.22us OneFlow \u4f18\u5316\u540e Float32 UpsampleNearest2D forward 52.18% 61.44us OneFlow \u4f18\u5316\u540e Float32 UpsampleNearest2D backward 77.66% 50.56us PyTorch Float16 UpsampleNearest2D forward 16.99% 100.38us PyTorch Float16 UpsampleNearest2D backward 31.56% 57.38us OneFlow \u672a\u4f18\u5316 Float16 UpsampleNearest2D forward 7.07% 262.82us OneFlow \u672a\u4f18\u5316 Float16 UpsampleNearest2D backward 41.04% 558.88us OneFlow \u4f18\u5316\u540e Float16 UpsampleNearest2D forward 43.26% 35.36us OneFlow \u4f18\u5316\u540e Float16 UpsampleNearest2D backward 44.82% 40.26us \u4e0a\u8ff0\u7ed3\u679c\u4f7f\u7528 /usr/local/cuda/bin/ncu -o torch_upsample /home/python3 debug.py \u5f97\u5230profile\u6587\u4ef6\u540e\u4f7f\u7528Nsight Compute\u6253\u5f00\u8bb0\u5f55\u3002 \u57fa\u4e8e\u4e0a\u8ff0\u5bf9 UpsampleNearest2D \u7684\u4f18\u5316\uff0cOneFlow \u5728 FP32 \u548c FP16 \u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u548c\u5e26\u5bbd\u90fd\u5927\u5e45\u8d85\u8d8a\u4e4b\u524d\u672a\u7ecf\u4f18\u5316\u7684\u7248\u672c\uff0c\u5e76\u4e14\u76f8\u6bd4\u4e8e PyTorch \u4e5f\u6709\u8f83\u5927\u5e45\u5ea6\u7684\u9886\u5148\u3002 \u672c\u6b21\u4f18\u5316\u6d89\u53ca\u5230\u7684 \u77e5\u8bc6\u70b9\u603b\u7ed3 \u5982\u4e0b\uff08by OneFlow \u67f3\u4fca\u4e1e\uff09\uff1a \u4e3a\u5e38\u89c1\u7684\u60c5\u51b5\u5199\u7279\u4f8b\uff0c\u6bd4\u5982\u8fd9\u91cc\u5c31\u662f\u4e3a\u91c7\u6837\u500d\u6570\u4e3a2\u7684Nearest\u63d2\u503c\u5199\u7279\u4f8b\uff0c\u907f\u514d\u4f7f\u7528NdIndexHelper\u5e26\u6765\u7684\u989d\u5916\u8ba1\u7b97\u5f00\u9500\uff0c\u4e0d\u7528\u8ffd\u6c42\u518d\u4e00\u4e2akernel\u5b9e\u73b0\u4e2d\u540c\u65f6\u62e5\u6709\u901a\u7528\u578b\u548c\u9ad8\u6548\u6027\uff1b \u6574\u6570\u9664\u6cd5\u5f00\u9500\u5927\uff08\u4f46\u662f\u7f16\u8bd1\u5668\u6709\u7684\u65f6\u5019\u4f1a\u4f18\u5316\u6389\u4e00\u4e9b\u9664\u6cd5\uff09\uff0cnchw\u4e2d\u7684nc\u4e0d\u9700\u8981\u5206\u5f00\uff0c\u5408\u5e76\u5728\u4e00\u8d77\u8ba1\u7b97\u51cf\u5c11\u8ba1\u7b97\u91cf\uff1b int64_t \u9664\u6cd5\u7684\u5f00\u9500\u66f4\u5927\uff0c\u7528int32\u6ee1\u8db3\u5927\u90e8\u5206\u9700\u6c42\uff0c\u5176\u5b9e\u8fd9\u91cc\u8fd8\u6709\u4e00\u4e2a\u5feb\u901f\u6574\u6570\u9664\u6cd5\u7684\u95ee\u9898\uff1b \u53cd\u5411 Kernel \u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u5faa\u73af dx \u76f8\u6bd4 \u5faa\u73af dy \uff0c\u5b9e\u9645\u4e0a\u5c06\u5750\u6807\u6362\u7b97\u7684\u5f00\u9500\u51cf\u5c11\u5230\u539f\u6765\u7684 1/4\uff1b CUDA GMEM \u7684\u5f00\u9500\u7684\u4e5f\u6bd4\u8f83\u5927\uff0c\u867d\u7136\u7f16\u8bd1\u5668\u6709\u53ef\u80fd\u505a\u4f18\u5316\uff0c\u4f46\u662f\u663e\u5f0f\u7684\u4f7f\u7528\u5c40\u90e8\u53d8\u91cf\u66f4\u597d\uff1b \u4e00\u6b21 Memset \u7684\u5f00\u9500\u4e5f\u5f88\u5927\uff0c\u548c\u5199\u4e00\u6b21\u4e00\u6837\uff0c\u6240\u4ee5\u53cd\u5411 Kernel \u4e2d\u5bf9 dx \u4f7f\u7528Memset \u6e05\u96f6\u7684\u65f6\u673a\u9700\u8981\u6ce8\u610f\uff1b atomicAdd \u5f00\u9500\u5f88\u5927\uff0c\u5373\u4f7f\u629b\u5f00\u4e3a\u4e86\u5b9e\u73b0\u539f\u5b50\u6027\u53ef\u80fd\u9700\u8981\u7684\u9501\u603b\u7ebf\u7b49\uff0catomicAdd \u9700\u8981\u628a\u539f\u6765\u7684\u503c\u5148\u8bfb\u51fa\u6765\uff0c\u518d\u5199\u56de\u53bb\uff1b\u53e6\u5916\uff0chalf\u7684atomicAdd \u5de8\u6162\u65e0\u6bd4\uff0c\u6162\u5230\u5982\u679c\u4e00\u4e2a\u7b97\u6cd5\u9700\u8981\u7528\u5230 atomicAdd\uff0c\u90a3\u4e48\u76f8\u6bd4\u4e8e\u7528 half \uff0c\u8f6c\u6210 float \uff0c\u518datomicAdd\uff0c\u518d\u8f6c\u56de\u53bb\u8fd8\u8981\u6162\u5f88\u591a\uff1b \u5411\u91cf\u5316\u8bbf\u5b58\uff1b \u5bf9\u8fd9\u4e2a Kernel \u8fdb\u884c\u7279\u5316\u662f\u4f18\u5316\u7684\u7b2c\u4e00\u6b65\uff0c\u57fa\u4e8e\u8fd9\u4e2a\u4f18\u5316\u53ef\u4ee5\u7ed9 YOLOv5 \u7684\u5355\u5361 PipLine \u5e26\u67651%\u7684\u63d0\u5347\u3002","title":"0x2.1 \u5bf9UpsampleNearest2D\u7684\u7279\u5316\u6539\u8fdb"},{"location":"tutorials/00_chapter/optim_speed_version1.html#0x22-bbox_iou-fuse","text":"\u901a\u8fc7\u5bf9nsys\u7684\u5206\u6790\uff0c\u6211\u4eec\u53d1\u73b0\u65e0\u8bba\u662fone-yolov5\u8fd8\u662fultralytics/yolov5\uff0c\u5728\u8ba1\u7b97Loss\u7684\u9636\u6bb5\u90fd\u6709\u4e00\u4e2a\u8017\u65f6\u6bd4\u8f83\u4e25\u91cd\u7684bbox_iou\u51fd\u6570\uff0c\u6211\u4eec\u8fd9\u91cc\u5148\u8d34\u4e00\u4e0bbbox_iou\u90e8\u5206\u7684\u4ee3\u7801\uff1a def bbox_iou ( box1 , box2 , xywh = True , GIoU = False , DIoU = False , CIoU = False , eps = 1e-7 ): # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4) # Get the coordinates of bounding boxes if xywh : # transform from xywh to xyxy ( x1 , y1 , w1 , h1 ), ( x2 , y2 , w2 , h2 ) = box1 . chunk ( 4 , - 1 ), box2 . chunk ( 4 , - 1 ) w1_ , h1_ , w2_ , h2_ = w1 / 2 , h1 / 2 , w2 / 2 , h2 / 2 b1_x1 , b1_x2 , b1_y1 , b1_y2 = x1 - w1_ , x1 + w1_ , y1 - h1_ , y1 + h1_ b2_x1 , b2_x2 , b2_y1 , b2_y2 = x2 - w2_ , x2 + w2_ , y2 - h2_ , y2 + h2_ else : # x1, y1, x2, y2 = box1 b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 . chunk ( 4 , - 1 ) b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 . chunk ( 4 , - 1 ) w1 , h1 = b1_x2 - b1_x1 , ( b1_y2 - b1_y1 ) . clamp ( eps ) w2 , h2 = b2_x2 - b2_x1 , ( b2_y2 - b2_y1 ) . clamp ( eps ) # Intersection area inter = ( b1_x2 . minimum ( b2_x2 ) - b1_x1 . maximum ( b2_x1 )) . clamp ( 0 ) * \\ ( b1_y2 . minimum ( b2_y2 ) - b1_y1 . maximum ( b2_y1 )) . clamp ( 0 ) # Union Area union = w1 * h1 + w2 * h2 - inter + eps # IoU iou = inter / union if CIoU or DIoU or GIoU : cw = b1_x2 . maximum ( b2_x2 ) - b1_x1 . minimum ( b2_x1 ) # convex (smallest enclosing box) width ch = b1_y2 . maximum ( b2_y2 ) - b1_y1 . minimum ( b2_y1 ) # convex height if CIoU or DIoU : # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1 c2 = cw ** 2 + ch ** 2 + eps # convex diagonal squared rho2 = (( b2_x1 + b2_x2 - b1_x1 - b1_x2 ) ** 2 + ( b2_y1 + b2_y2 - b1_y1 - b1_y2 ) ** 2 ) / 4 # center dist ** 2 if CIoU : # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47 v = ( 4 / math . pi ** 2 ) * ( torch . atan ( w2 / h2 ) - torch . atan ( w1 / h1 )) . pow ( 2 ) with torch . no_grad (): alpha = v / ( v - iou + ( 1 + eps )) return iou - ( rho2 / c2 + v * alpha ) # CIoU return iou - rho2 / c2 # DIoU c_area = cw * ch + eps # convex area return iou - ( c_area - union ) / c_area # GIoU https://arxiv.org/pdf/1902.09630.pdf return iou # IoU \u4ee5one-yolov5\u7684\u539f\u59cb\u6267\u884c\u5e8f\u5217\u56fe\u4e3a\u4f8b\uff0c\u6211\u4eec\u53d1\u73b0bbox_iou\u51fd\u6570\u8fd9\u90e8\u5206\u6bcf\u4e00\u6b21\u8fd0\u884c\u90fd\u9700\u8981\u82b12.6ms\u5de6\u53f3\u3002\u5e76\u4e14\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u8fd9\u91cc\u6709\u5927\u91cf\u7684\u5c0f\u7684Kernel\u88ab\u8c03\u5ea6\uff0c\u867d\u7136\u6bcf\u4e2a\u5c0fKernel\u8ba1\u7b97\u5f88\u5feb\uff0c\u4f46\u8bbf\u95eeGlobal Memory\u4ee5\u53ca\u591a\u6b21Kernel Launch\u7684\u5f00\u9500\u4e5f\u662f\u6bd4\u8f83\u5927\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u505a\u4e86\u51e0\u4e2afuse\u6765\u964d\u4f4eKernel Launch\u7684\u5f00\u9500\u4ee5\u53ca\u51cf\u5c11\u8bbf\u95eeGlobal Memrory\u6765\u63d0\u5347\u5e26\u5bbd\u3002 \u7136\u540e\u7ecf\u8fc7\u6211\u4eec\u7684Kernel Fuse\u4e4b\u540e\u7684\u8017\u65f6\u53ea\u9700\u8981600+us\u3002 \u5177\u4f53\u6765\u8bf4\u6211\u4eec\u8fd9\u91cc\u505a\u4e86\u5982\u4e0b\u7684\u51e0\u4e2afuse\uff1a fused_get_boundding_boxes_coord\uff1ahttps://github.com/Oneflow-Inc/oneflow/pull/9433 fused_get_intersection_area: https://github.com/Oneflow-Inc/oneflow/pull/9485 fused_get_iou: https://github.com/Oneflow-Inc/oneflow/pull/9475 fused_get_convex_diagonal_squared: https://github.com/Oneflow-Inc/oneflow/pull/9481 fused_get_center_dist: https://github.com/Oneflow-Inc/oneflow/pull/9446 fused_get_ciou_diagonal_angle: https://github.com/Oneflow-Inc/oneflow/pull/9465 fused_get_ciou_result: https://github.com/Oneflow-Inc/oneflow/pull/9462 \u7136\u540e\u6211\u4eec\u5728one-yolov5\u7684train.py\u4e2d\u6269\u5c55\u4e86\u4e00\u4e2a --bbox_iou_optim \u9009\u9879\uff0c\u53ea\u8981\u8bad\u7ec3\u7684\u65f6\u5019\u5e26\u4e0a\u8fd9\u4e2a\u9009\u9879\u5c31\u4f1a\u81ea\u52a8\u8c03\u7528\u4e0a\u9762\u7684fuse kernel\u6765\u5bf9bbox_iou\u51fd\u6570\u8fdb\u884c\u4f18\u5316\u4e86\uff0c\u5177\u4f53\u8bf7\u770b\uff1ahttps://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L224-L284 \u3002\u5bf9bbox_iou\u8fd9\u4e2a\u51fd\u6570\u7684\u4e00\u7cfb\u5217\u5782\u76f4Fuse\u4f18\u5316\u4f7f\u5f97YOLOv5\u6574\u4f53\u7684\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u4e868%\u5de6\u53f3\uff0c\u662f\u4e00\u4e2a\u5341\u5206\u6709\u6548\u7684\u4f18\u5316\u3002","title":"0x2.2 \u5bf9bbox_iou\u51fd\u6570\u8fdb\u884c\u4f18\u5316 (\u5782\u76f4Fuse\u4f18\u5316)"},{"location":"tutorials/00_chapter/optim_speed_version1.html#0x23-fuse","text":"\u5728 YOLOv5 \u4e2d\u4f1a\u4f7f\u7528EMA\uff08\u6307\u6570\u79fb\u52a8\u5e73\u5747\uff09\u5bf9\u6a21\u578b\u7684\u53c2\u6570\u505a\u5e73\u5747, \u4e00\u79cd\u7ed9\u4e88\u8fd1\u671f\u6570\u636e\u66f4\u9ad8\u6743\u91cd\u7684\u5e73\u5747\u65b9\u6cd5, \u4ee5\u6c42\u63d0\u9ad8\u6d4b\u8bd5\u6307\u6807\u5e76\u589e\u52a0\u6a21\u578b\u9c81\u68d2\u3002\u8fd9\u91cc\u7684\u6838\u5fc3\u64cd\u4f5c\u5982\u4e0b\u4ee3\u7801\u6240\u793a\uff1a def update ( self , model ): # Update EMA parameters self . updates += 1 d = self . decay ( self . updates ) msd = de_parallel ( model ) . state_dict () # model state_dict for k , v in self . ema . state_dict () . items (): if v . dtype . is_floating_point : # true for FP16 and FP32 v *= d v += ( 1 - d ) * msd [ k ] . detach () # assert v.dtype == msd[k].dtype == flow.float32, f'{k}: EMA {v.dtype} and model {msd[k].dtype} must be FP32' \u4ee5\u4e0b\u662f\u672a\u4f18\u5316\u524d\u7684\u8fd9\u4e2a\u51fd\u6570\u7684\u65f6\u5e8f\u56fe\uff1a \u8fd9\u90e8\u5206\u7684cuda kernel\u7684\u6267\u884c\u901f\u5ea6\u5927\u6982\u4e3a7.4ms\uff0c\u800c\u7ecf\u8fc7\u6211\u4eec\u6c34\u5e73Fuse\u4f18\u5316\uff08\u5373MultiTensor\uff09\uff0c\u8fd9\u90e8\u5206\u7684\u8017\u65f6\u60c5\u51b5\u964d\u4f4e\u4e3a\u4e86127us\u3002 \u5e76\u4e14\u6c34\u5e73\u65b9\u5411\u7684Kernel Fuse\u4e5f\u540c\u6837\u964d\u4f4e\u4e86Kernel Launch\u7684\u5f00\u9500\uff0c\u4f7f\u5f97\u524d\u540e2\u4e2aIter\u7684\u95f4\u9699\u4e5f\u8fdb\u4e00\u6b65\u7f29\u77ed\u4e86\u3002\u6700\u7ec8\u8fd9\u4e2a\u4f18\u5316\u4e3aYOLOv5\u7684\u6574\u4f53\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u4e8610%\u5de6\u53f3\u3002\u672c\u4f18\u5316\u5b9e\u73b0\u7684pr\u5982\u4e0b\uff1ahttps://github.com/Oneflow-Inc/oneflow/pull/9498 \u6b64\u5916\uff0c\u5bf9\u4e8eOptimizer\u90e8\u5206\u540c\u6837\u53ef\u4ee5\u6c34\u5e73\u5e76\u884c\uff0c\u6240\u4ee5\u6211\u4eec\u5728 one-yolov5 \u91cc\u9762\u8bbe\u7f6e\u4e86\u4e00\u4e2a multi_tensor_optimizer \u6807\u5fd7\uff0c\u6253\u5f00\u8fd9\u4e2a\u6807\u5fd7\u5c31\u53ef\u4ee5\u8ba9 optimizer \u4ee5\u53ca EMA \u7684 update\u4ee5\u6c34\u5e73\u5e76\u884c\u7684\u65b9\u5f0f\u8fd0\u884c\u4e86\u3002 \u5173\u4e8eMultiTensor\u8fd9\u4e2a\u77e5\u8bc6\u53ef\u4ee5\u770b zzk \u7684\u8fd9\u7bc7\u6587\u7ae0\uff1ahttps://zhuanlan.zhihu.com/p/566595789\u3002zzk \u5728 OneFlow \u4e2d\u4e5f\u5b9e\u73b0\u4e86\u4e00\u5957 MultiTensor \u65b9\u6848\uff0c\u4e0a\u9762\u7684 PR 9498 \u4e5f\u662f\u57fa\u4e8e\u8fd9\u5957 MultiTensor \u65b9\u6848\u5b9e\u73b0\u7684\u3002\u4ecb\u4e8e\u7bc7\u5e45\u539f\u56e0\u6211\u4eec\u5c31\u4e0d\u5c55\u5f00\u8fd9\u4e2a MultiTensor \u7684\u4ee3\u7801\u5b9e\u73b0\u4e86\uff0c\u611f\u5174\u8da3\u7684\u53ef\u4ee5\u7559\u8a00\u540e\u7eed\u5355\u72ec\u8bb2\u89e3\u3002","title":"0x2.3 \u5bf9\u6a21\u578b\u6ed1\u52a8\u5e73\u5747\u66f4\u65b0\u8fdb\u884c\u4f18\u5316\uff08\u6c34\u5e73Fuse\u4f18\u5316\uff09"},{"location":"tutorials/00_chapter/optim_speed_version1.html#0x3","text":"\u4e0a\u9762\u5df2\u7ecf\u63d0\u5230\u6240\u6709\u7684\u4f18\u5316\u90fd\u96c6\u4e2d\u4e8e bbox_iou_optim \u548c multi_tensor_optimizer \u8fd9\u4e24\u4e2a\u6269\u5c55\u7684Flag\uff0c\u53ea\u8981\u6211\u4eec\u8bad\u7ec3\u7684\u65f6\u5019\u6253\u5f00\u8fd9\u4e24\u4e2aFlag\u5c31\u53ef\u4ee5\u4eab\u53d7\u5230\u4e0a\u8ff0\u4f18\u5316\u4e86\u3002\u5176\u4ed6\u7684\u8fd0\u884c\u547d\u4ee4\u548cOne-YOLOv5\u6ca1\u6709\u53d8\u5316\uff0c\u4ee5One-YOLOv5\u5728GTX 3090\u4e0a\u8bad\u7ec3yolov5s\u4e3a\u4f8b\uff0c\u547d\u4ee4\u4e3a\uff1a python train.py --batch 16 --cfg models/yolov5s.yaml --weights '' --data coco.yaml --img 640 --device 0 --epoch 1 --bbox_iou_optim --multi_tensor_optimizer","title":"0x3. \u4f7f\u7528\u65b9\u6cd5"},{"location":"tutorials/00_chapter/optim_speed_version1.html#0x4","text":"\u76ee\u524d\uff0cyolov5s\u7f51\u7edc\u5f53\u4ee5BatchSize=16\u7684\u914d\u7f6e\u5728GeForce RTX 3090\u4e0a\uff08\u8fd9\u91cc\u6307\u5b9aBatchSize\u4e3a16\u65f6\uff09\u8bad\u7ec3COCO\u6570\u636e\u96c6\u65f6\uff0cOneFlow\u76f8\u6bd4PyTorch\u53ef\u4ee5\u8282\u7701 11.35 \u4e2a\u5c0f\u65f6\u3002\u6211\u4eec\u76f8\u4fe1\u8fd9\u7bc7\u6587\u7ae0\u63d0\u5230\u7684\u4f18\u5316\u6280\u5de7\u4e5f\u53ef\u4ee5\u5bf9\u66f4\u591a\u7684\u4ece\u4e8b\u76ee\u6807\u68c0\u6d4b\u7684\u5b66\u751f\u6216\u8005\u5de5\u7a0b\u5e08\u5e26\u6765\u542f\u53d1\u3002\u6b22\u8fce\u5927\u5bb6star one-yolov5\u9879\u76ee\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 One-YOLOv5\u7684\u4f18\u5316\u5de5\u4f5c\u5b9e\u9645\u4e0a\u4e0d\u4ec5\u5305\u542b\u6027\u80fd\uff0c\u6211\u4eec\u76ee\u524d\u4e5f\u4ed8\u51fa\u4e86\u5f88\u591a\u5fc3\u8840\u5728\u6587\u6863\u548c\u6e90\u7801\u89e3\u8bfb\u4e0a\uff0c\u540e\u7eed\u4f1a\u7ee7\u7eed\u653e\u51fa\u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b\u7684\u5176\u4ed6\u6587\u7ae0\uff0c\u5e76\u5c06\u5c3d\u5feb Relase \u65b0\u7248\u672c\u3002\u8bf7\u671f\u5f85\u540e\u7eed\u53d1\u5c55...","title":"0x4. \u603b\u7ed3"},{"location":"tutorials/00_chapter/optim_speed_version1.html#0x5","text":"\u611f\u8c22\u67f3\u4fca\u4e1e\u540c\u4e8b\u5728\u8fd9\u6b21\u8c03\u4f18\u4e2d\u63d0\u4f9b\u7684 idea \u548c\u6280\u672f\u652f\u6301\uff0c\u611f\u8c22\u80e1\u4f3d\u9b41\u540c\u5b66\u5b9e\u73b0\u7684\u4e00\u4e9bfuse kernel\uff0c\u611f\u8c22\u90d1\u6cfd\u5eb7\u548c\u5b8b\u6613\u627f\u7684 MultiTensorUpdate \u5b9e\u73b0\uff0c\u611f\u8c22\u51af\u6587\u7684\u7cbe\u5ea6\u9a8c\u8bc1\u5de5\u4f5c\u4ee5\u53ca\u6587\u6863\u652f\u6301\uff0c\u4ee5\u53ca\u5c0f\u7cd6\u5bf9 One-YOLOv5 \u7684\u63a8\u5e7f\u5e2e\u52a9\u548c\u5e2e\u52a9\u672c\u9879\u76ee\u53d1\u5c55\u7684\u5de5\u7a0b\u5e08\u4eec\u5982\u8d75\u9732\u9633\uff0c\u6881\u5fb7\u6f8e\u7b49\u7b49\u3002\u672c\u9879\u76ee\u672a\u6765\u4f1a\u7ee7\u7eed\u53d1\u529b\u505a\u51fa\u66f4\u591a\u7684\u6210\u679c\u3002","title":"0x5. \u81f4\u8c22"},{"location":"tutorials/00_chapter/overview.html","text":"0x0 \u52a8\u673a \u4e3a\u4e86\u8bf4\u660e\u4f7f\u7528 OneFlow \u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u53ef\u884c\u6027\u4ee5\u53ca\u6027\u80fd\u7684\u4f18\u8d8a\u6027\uff0c\u6700\u8fd1\u6211\u4eec\u5c06 ultralytics \u7248 YOLOv5\uff08https://github.com/ultralytics/yolov5\uff09\u901a\u8fc7import oneflow as torch\u7684\u65b9\u5f0f\u8fc1\u79fb\u4e3a\u4e86OneFlow\u540e\u7aef\uff08\u5bf9\u5e94YOLOv5\u7684commit\u53f7\u4e3a\uff1a 48a85314bc80d8023c99bfb114cea98d71dd0591 \uff09\u3002\u5e76\u5bf9 YOLOv5 \u4e2d\u76f8\u5173\u7684\u6559\u7a0b\u8fdb\u884c\u4e86\u6c49\u5316\uff0c\u6dfb\u52a0\u4e86\u4e00\u7cfb\u5217\u8be6\u7ec6\u7684\u4ee3\u7801\u89e3\u8bfb\uff0c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u90e8\u7f72\u6559\u7a0b\uff0c\u5e0c\u671b\u4f7f\u5f97 YOLOv5 \u9879\u76ee\u5bf9\u7528\u6237\u66f4\u52a0\u900f\u660e\u5316\u3002\u53e6\u5916\u6211\u4eec\u4e5f\u5c06\u5728\u6027\u80fd\u8fd9\u4e2a\u89d2\u5ea6\u8fdb\u884c\u6df1\u5165\u63a2\u7d22\uff0c\u672c\u6b21\u6211\u4eec\u53d1\u5e03\u7684OneFlow\u540e\u7aef\u7684YOLOv5\u53ea\u662f\u4e00\u4e2a\u57fa\u7840\u7248\u672c\uff0c\u6ca1\u6709\u7528\u4e0a\u4efb\u4f55\u7684\u4f18\u5316\u6280\u5de7\u3002\u76ee\u524d\u6211\u4eec\u5728\u5c0f Batch \u8fdb\u884c\u8bad\u7ec3\u65f6\u76f8\u6bd4\u4e8e PyTorch \u67095%-10%\u5de6\u53f3\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u800c\u5bf9\u4e8e\u5927 Batch \u5219\u6027\u80fd\u548c PyTorch \u6301\u5e73\u3002\u76f8\u4fe1\u5728\u540e\u7eed\u7684\u4e00\u4e9b\u5b9a\u5236\u5316\u7684\u6027\u80fd\u4f18\u5316\u6280\u5de7\u4e0b\uff08\u6bd4\u5982nn.Graph\u52a0\u6301\uff0c\u7b97\u5b50\u7684\u4f18\u5316\uff09\uff0c\u6211\u4eec\u53ef\u4ee5\u7ee7\u7eed\u63d0\u5347YOLOv5\u5728COCO\u7b49\u6570\u636e\u96c6\u7684\u8bad\u7ec3\u901f\u5ea6\uff0c\u66f4\u6709\u6548\u7f29\u77ed\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\u3002 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 \ud83c\udf89\u6587\u6863\u7f51\u7ad9\u5730\u5740\uff1ahttps://start.oneflow.org/oneflow-yolo-doc/index.html OneFlow \u5b89\u88c5\u65b9\u6cd5\uff1ahttps://github.com/Oneflow-Inc/oneflow#install-oneflow \u4e0d\u8fc7\u5373\u4f7f\u4f60\u5bf9 OneFlow \u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u4e0d\u592a\u611f\u5174\u8da3\uff0c\u6211\u4eec\u76f8\u4fe1 \u6587\u6863\u7f51\u7ad9 \u4e2d\u5bf9 YOLOv5 \u6559\u7a0b\u7684\u6c49\u5316\u4ee5\u53ca\u6e90\u7801\u5256\u6790\u4e5f\u4f1a\u662f\u4ece\u96f6\u5f00\u59cb\u6df1\u5165\u5b66\u4e60 YOLOv5 \u4e00\u4efd\u4e0d\u9519\u7684\u8d44\u6599\u3002\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6\u6700\u65b0\u7684\u52a8\u6001\u3002 0x1. \u5dee\u5f02 \u6211\u4eec\u5c06 YOLOv5 \u7684\u540e\u7aef\u4ece PyTorch \u6362\u6210 OneFlow \u4e4b\u540e\u9664\u4e86\u6027\u80fd\u4f18\u52bf\u5916\u8fd8\u505a\u4e86\u4e00\u4e9b\u5dee\u5f02\u5316\u7684\u5185\u5bb9\uff0c\u5176\u4e2d\u4e00\u4e9b\u5185\u5bb9\u5df2\u7ecf\u5b8c\u6210\uff0c\u8fd8\u6709\u4e00\u4e9b\u6b63\u5728\u8fdb\u884c\u4e2d\uff0c\u4e0b\u9762\u7b80\u5355\u5c55\u793a\u4e00\u4e0b\uff1a 1. YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790 2. \u5982\u4f55\u51c6\u5907yolov5\u6a21\u578b\u8bad\u7ec3\u6570\u636e 3. \u5feb\u901f\u5f00\u59cb 4. \u6a21\u578b\u8bad\u7ec3 5. \u6d4b\u8bd5\u65f6\u589e\u5f3a (TTA) 6. \u6a21\u578b\u878d\u5408 (Model Ensembling) 7. \u4ece OneFlow Hub \u52a0\u8f7d YOLOv5 8. \u6570\u636e\u589e\u5f3a 9. \u77e9\u5f62\u63a8\u7406 10. IOU\u6df1\u5165\u89e3\u6790 11. \u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30 12. ONNX\u6a21\u578b\u5bfc\u51fa \u8fd9\u4e00\u7cfb\u5217\u7684\u6587\u7ae0\u6211\u4eec\u5c06\u9010\u6b65\u5f00\u53d1\uff0cReview \u4ee5\u53ca\u53d1\u5e03\u5e76\u4e14\u4f1a\u6709\u76f8\u5e94\u7684\u89c6\u9891\u8bb2\u89e3\uff0c\u6211\u4eec\u5c06\u8fd9\u4e2a\u7cfb\u5217\u7684\u6587\u7ae0\u53eb\u4f5c\uff1a \u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b \ud83c\udf89\ud83c\udf89\ud83c\udf89 0x2. \u5728COCO\u4e0a\u7684\u7cbe\u5ea6\u8868\u73b0 \u6211\u4eec\u4ee5 yolov5n \u7f51\u7edc\u4e3a\u4f8b\uff0c result.csv \u8fd9\u4e2a\u65e5\u5fd7\u5c55\u793a\u4e86\u6211\u4eec\u57fa\u4e8e one-yolov5 \u5728 COCO \u4e0a\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 YOLOv5n \u7f51\u7edc\u7684\u65e5\u5fd7\u3002\u4e0b\u56fe\u5c55\u793a\u4e86 box_loss , obj_loss , cls_loss \uff0c map_0.5 , map_0.5:0.95 \u7b49\u6307\u6807\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u60c5\u51b5\uff1a \u6700\u7ec8\u5728\u7b2c 300 \u4e2a epoch \u65f6\uff0c\u6211\u4eec\u7684 map_0.5 \u8fbe\u5230\u4e86 0.45174 \uff0c map_0.5:0.95 \u8fbe\u5230\u4e86 0.27726 \u3002 \u548c ultralytics/yolov5 \u7ed9\u51fa\u7684\u7cbe\u5ea6\u6570\u636e \u4e00\u81f4\uff08\u6ce8\u610f\u5b98\u7f51\u7ed9\u51fa\u7684\u7cbe\u5ea6\u6307\u5b9a iou \u4e3a 0.65 \u7684\u7cbe\u5ea6\uff0c\u800c\u4e0a\u8ff0 csv \u6587\u4ef6\u4e2d\u662f\u5728 iou \u4e3a 0.60 \u4e0b\u7684\u7cbe\u5ea6\uff0c\u4f7f\u7528\u6211\u4eec\u8bad\u7ec3\u7684\u6743\u91cd\u5e76\u628a iou \u6307\u5b9a\u4e3a 0.65 \u53ef\u4ee5\u5b8c\u5168\u5bf9\u9f50\u5b98\u65b9\u7ed9\u51fa\u7684\u7cbe\u5ea6\u6570\u636e\uff09\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 ultralytics/yolov5 \u6765\u9a8c\u8bc1\u4e00\u4e0b\uff1a python val . py -- weights yolov5n . pt -- data data / coco . yaml -- img 640 -- iou 0.60 \u8f93\u51fa\uff1a val: data = data/coco.yaml, weights =[ 'yolov5n.pt' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, max_det = 300 , task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = False, dnn = False YOLOv5 \ud83d\ude80 v6.1-384-g7fd9867 Python-3.8.13 torch-1.10.0+cu113 CUDA:0 ( NVIDIA GeForce RTX 3080 Ti, 12054MiB ) cuda:0 Fusing layers... YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4 .5 GFLOPs val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588 Class Images Instances P R mAP50 mAP50-95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 00 :40< 00 :00, 3 . all 5000 36335 0 .573 0 .432 0 .456 0 .277 \u4e0a\u9762\u7684\u8f93\u51fa\u53ef\u4ee5\u8bf4\u660e\u6211\u4eec\u548c ultralytics/yolov5 \u7684\u7cbe\u5ea6\u662f\u5b8c\u5168\u5bf9\u9f50\u7684\u3002 \u5728 one-yolov5 \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 yolov5n \u8fdb\u884c\u7cbe\u5ea6\u590d\u73b0\u7684\u547d\u4ee4\u4e3a (2\u5361DDP\u6a21\u5f0f) \uff1a python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- data data / coco . yaml -- weights ' ' -- cfg models / yolov5n . yaml -- batch 64 0x3. \u5728COCO\u4e0a\u7684\u6027\u80fd\u8868\u73b0 \u4ee5\u4e0b\u7684\u6027\u80fd\u7ed3\u679c\u90fd\u662f\u76f4\u63a5\u5c06 PyTorch \u5207\u6362\u4e3a OneFlow \u4e4b\u540e\u6d4b\u8bd5\u7684\uff0c \u5e76\u6ca1\u6709\u505a\u9488\u5bf9\u6027\u4f18\u5316 \uff0c\u540e\u7eed\u4f1a\u5728\u6b64\u57fa\u7840\u4e0a\u7ee7\u7eed\u63d0\u5347 OneFlow \u540e\u7aef YOLOv5 \u7684\u8bad\u7ec3\u901f\u5ea6\u3002 \u5728 3080Ti \u7684\u6027\u80fd\u6d4b\u8bd5\u7ed3\u679c \u5355\u5361\u6d4b\u8bd5\u7ed3\u679c \u4ee5\u4e0b\u4e3aGTX 3080ti(12GB) \u7684yolov5\u6d4b\u8bd5\u7ed3\u679c\uff08oneflow\u540e\u7aef vs PyTorch\u540e\u7aef\uff09 \u4ee5\u4e0b\u6d4b\u8bd5\u7ed3\u679c\u7684\u6570\u636e\u914d\u7f6e\u5747\u4e3acoco.yaml\uff0c\u6a21\u578b\u914d\u7f6e\u4e5f\u5b8c\u5168\u4e00\u6837\uff0c\u5e76\u8bb0\u5f55\u8bad\u7ec3\u5b8ccoco\u6570\u636e\u96c61\u4e2aepoch\u9700\u8981\u7684\u65f6\u95f4 \u7531\u4e8eoneflow eager\u76ee\u524damp\u7684\u652f\u6301\u8fd8\u4e0d\u5b8c\u5584\uff0c\u6240\u4ee5\u6211\u4eec\u63d0\u4f9b\u7684\u7ed3\u679c\u5747\u4e3afp32\u6a21\u5f0f\u4e0b\u8fdb\u884c\u8bad\u7ec3\u7684\u6027\u80fd\u7ed3\u679c PyTorch\u7248\u672c yolov5 code base\u94fe\u63a5\uff1ahttps://github.com/ultralytics/yolov5 OneFlow\u7248\u672c yolov5 code base\u94fe\u63a5\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 cuda \u7248\u672c 11.7, cudnn \u7248\u672c\u4e3a 8.5.0 \u6d4b\u8bd5\u7684\u547d\u4ee4\u4e3a\uff1a python train.py --batch 16 --cfg models/yolov5n.yaml --weights '' --data coco.yaml --img 640 --device 0 \uff0c\u5176\u4e2d batch \u53c2\u6570\u662f\u52a8\u6001\u53d8\u5316\u7684 \u53ef\u4ee5\u770b\u5230\uff0c\u5728 batch \u6bd4\u8f83\u5c0f\u7684\u65f6\u5019 OneFlow \u540e\u7aef\u7684 YOLOv5 \u76f8\u6bd4\u4e8e PyTorch \u6709 5%-10% \u5de6\u53f3\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u8fd9\u53ef\u80fd\u5f97\u76ca\u4e8e OneFlow \u7684 Eager \u8fd0\u884c\u65f6\u7cfb\u7edf\u53ef\u4ee5\u66f4\u5feb\u7684\u505a CUDA Kernel Launch\u3002\u800c batch \u6bd4\u8f83\u5927\u7684\u65f6\u5019 OneFlow \u540e\u7aef\u7684 YOLOv5 \u76f8\u6bd4\u4e8e PyTorch \u7684\u6027\u80fd\u5dee\u4e0d\u591a\u662f\u6301\u5e73\uff0c\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u5f53 Batch \u6bd4\u8f83\u5927\u7684\u65f6\u5019 CUDA Kernel Launch \u7684\u5f00\u9500\u76f8\u6bd4\u4e8e\u8ba1\u7b97\u7684\u5f00\u9500\u4f1a\u6bd4\u8f83\u5c0f\u3002 \u4e24\u5361DDP\u6d4b\u8bd5\u7ed3\u679c \u914d\u7f6e\u548c\u5355\u5361\u5747\u4e00\u81f4 \u6d4b\u8bd5\u7684\u547d\u4ee4\u4e3a\uff1a python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 16 --data coco.yaml --weights '' --device 0,1 \uff0c\u5176\u4e2d batch \u53c2\u6570\u662f\u52a8\u6001\u53d8\u5316\u7684 \u5f97\u76ca\u4e8e\u5355\u5361\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5728 2 \u5361DDP\u6a21\u5f0f\u4e0b\uff0cOneFlow \u540e\u7aef\u7684 YOLOv5 \u5728\u5c0f batch \u7684\u8bad\u7ec3\u65f6\u95f4\u4e5f\u662f\u7a0d\u5fae\u9886\u5148 PyTorch \u540e\u7aef\u7684 YoloV5 \uff0c\u800c\u5bf9\u4e8e\u5927 Batch \u6765\u8bf4\u6027\u80fd\u548c PyTorch \u76f8\u6bd4\u4e5f\u662f\u5dee\u4e0d\u591a\u6301\u5e73\u3002 0x4. \u603b\u7ed3 \u6211\u4eec\u57fa\u4e8e OneFlow \u79fb\u690d\u4e86 ultralytics \u7248\u7684 YOLOv5 \uff0c\u5728\u7cbe\u5ea6\u8bad\u7ec3\u8fbe\u6807\u7684\u60c5\u51b5\u4e0b\u8fd8\u53ef\u4ee5\u5728 Batch \u6bd4\u8f83\u5c0f\u65f6\u53d6\u5f97\u4e00\u4e9b\u6027\u80fd\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9 YOLOv5 \u4e2d\u76f8\u5173\u7684\u6559\u7a0b\u8fdb\u884c\u4e86\u6c49\u5316\uff0c\u6dfb\u52a0\u4e86\u4e00\u7cfb\u5217\u8be6\u7ec6\u7684\u4ee3\u7801\u89e3\u8bfb\uff0c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u90e8\u7f72\u6559\u7a0b\uff0c\u5e0c\u671b\u4f7f\u5f97 YOLOv5 \u9879\u76ee\u5bf9\u7528\u6237\u66f4\u52a0\u900f\u660e\u5316\u3002\u76f8\u4fe1\u5bf9\u60f3\u6df1\u5165\u4e86\u89e3 YOLOv5 \u7684\u8bfb\u8005\u6211\u4eec\u7684 \u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b \u4e5f\u662f\u4e00\u4efd\u4e0d\u9519\u7684\u5b66\u4e60\u8d44\u6599\u3002","title":"one-yolov5 \u7279\u70b9\u89e3\u6790"},{"location":"tutorials/00_chapter/overview.html#0x0","text":"\u4e3a\u4e86\u8bf4\u660e\u4f7f\u7528 OneFlow \u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u53ef\u884c\u6027\u4ee5\u53ca\u6027\u80fd\u7684\u4f18\u8d8a\u6027\uff0c\u6700\u8fd1\u6211\u4eec\u5c06 ultralytics \u7248 YOLOv5\uff08https://github.com/ultralytics/yolov5\uff09\u901a\u8fc7import oneflow as torch\u7684\u65b9\u5f0f\u8fc1\u79fb\u4e3a\u4e86OneFlow\u540e\u7aef\uff08\u5bf9\u5e94YOLOv5\u7684commit\u53f7\u4e3a\uff1a 48a85314bc80d8023c99bfb114cea98d71dd0591 \uff09\u3002\u5e76\u5bf9 YOLOv5 \u4e2d\u76f8\u5173\u7684\u6559\u7a0b\u8fdb\u884c\u4e86\u6c49\u5316\uff0c\u6dfb\u52a0\u4e86\u4e00\u7cfb\u5217\u8be6\u7ec6\u7684\u4ee3\u7801\u89e3\u8bfb\uff0c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u90e8\u7f72\u6559\u7a0b\uff0c\u5e0c\u671b\u4f7f\u5f97 YOLOv5 \u9879\u76ee\u5bf9\u7528\u6237\u66f4\u52a0\u900f\u660e\u5316\u3002\u53e6\u5916\u6211\u4eec\u4e5f\u5c06\u5728\u6027\u80fd\u8fd9\u4e2a\u89d2\u5ea6\u8fdb\u884c\u6df1\u5165\u63a2\u7d22\uff0c\u672c\u6b21\u6211\u4eec\u53d1\u5e03\u7684OneFlow\u540e\u7aef\u7684YOLOv5\u53ea\u662f\u4e00\u4e2a\u57fa\u7840\u7248\u672c\uff0c\u6ca1\u6709\u7528\u4e0a\u4efb\u4f55\u7684\u4f18\u5316\u6280\u5de7\u3002\u76ee\u524d\u6211\u4eec\u5728\u5c0f Batch \u8fdb\u884c\u8bad\u7ec3\u65f6\u76f8\u6bd4\u4e8e PyTorch \u67095%-10%\u5de6\u53f3\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u800c\u5bf9\u4e8e\u5927 Batch \u5219\u6027\u80fd\u548c PyTorch \u6301\u5e73\u3002\u76f8\u4fe1\u5728\u540e\u7eed\u7684\u4e00\u4e9b\u5b9a\u5236\u5316\u7684\u6027\u80fd\u4f18\u5316\u6280\u5de7\u4e0b\uff08\u6bd4\u5982nn.Graph\u52a0\u6301\uff0c\u7b97\u5b50\u7684\u4f18\u5316\uff09\uff0c\u6211\u4eec\u53ef\u4ee5\u7ee7\u7eed\u63d0\u5347YOLOv5\u5728COCO\u7b49\u6570\u636e\u96c6\u7684\u8bad\u7ec3\u901f\u5ea6\uff0c\u66f4\u6709\u6548\u7f29\u77ed\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\u3002 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 \ud83c\udf89\u6587\u6863\u7f51\u7ad9\u5730\u5740\uff1ahttps://start.oneflow.org/oneflow-yolo-doc/index.html OneFlow \u5b89\u88c5\u65b9\u6cd5\uff1ahttps://github.com/Oneflow-Inc/oneflow#install-oneflow \u4e0d\u8fc7\u5373\u4f7f\u4f60\u5bf9 OneFlow \u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u4e0d\u592a\u611f\u5174\u8da3\uff0c\u6211\u4eec\u76f8\u4fe1 \u6587\u6863\u7f51\u7ad9 \u4e2d\u5bf9 YOLOv5 \u6559\u7a0b\u7684\u6c49\u5316\u4ee5\u53ca\u6e90\u7801\u5256\u6790\u4e5f\u4f1a\u662f\u4ece\u96f6\u5f00\u59cb\u6df1\u5165\u5b66\u4e60 YOLOv5 \u4e00\u4efd\u4e0d\u9519\u7684\u8d44\u6599\u3002\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6\u6700\u65b0\u7684\u52a8\u6001\u3002","title":"0x0 \u52a8\u673a"},{"location":"tutorials/00_chapter/overview.html#0x1","text":"\u6211\u4eec\u5c06 YOLOv5 \u7684\u540e\u7aef\u4ece PyTorch \u6362\u6210 OneFlow \u4e4b\u540e\u9664\u4e86\u6027\u80fd\u4f18\u52bf\u5916\u8fd8\u505a\u4e86\u4e00\u4e9b\u5dee\u5f02\u5316\u7684\u5185\u5bb9\uff0c\u5176\u4e2d\u4e00\u4e9b\u5185\u5bb9\u5df2\u7ecf\u5b8c\u6210\uff0c\u8fd8\u6709\u4e00\u4e9b\u6b63\u5728\u8fdb\u884c\u4e2d\uff0c\u4e0b\u9762\u7b80\u5355\u5c55\u793a\u4e00\u4e0b\uff1a 1. YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790 2. \u5982\u4f55\u51c6\u5907yolov5\u6a21\u578b\u8bad\u7ec3\u6570\u636e 3. \u5feb\u901f\u5f00\u59cb 4. \u6a21\u578b\u8bad\u7ec3 5. \u6d4b\u8bd5\u65f6\u589e\u5f3a (TTA) 6. \u6a21\u578b\u878d\u5408 (Model Ensembling) 7. \u4ece OneFlow Hub \u52a0\u8f7d YOLOv5 8. \u6570\u636e\u589e\u5f3a 9. \u77e9\u5f62\u63a8\u7406 10. IOU\u6df1\u5165\u89e3\u6790 11. \u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30 12. ONNX\u6a21\u578b\u5bfc\u51fa \u8fd9\u4e00\u7cfb\u5217\u7684\u6587\u7ae0\u6211\u4eec\u5c06\u9010\u6b65\u5f00\u53d1\uff0cReview \u4ee5\u53ca\u53d1\u5e03\u5e76\u4e14\u4f1a\u6709\u76f8\u5e94\u7684\u89c6\u9891\u8bb2\u89e3\uff0c\u6211\u4eec\u5c06\u8fd9\u4e2a\u7cfb\u5217\u7684\u6587\u7ae0\u53eb\u4f5c\uff1a \u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b \ud83c\udf89\ud83c\udf89\ud83c\udf89","title":"0x1. \u5dee\u5f02"},{"location":"tutorials/00_chapter/overview.html#0x2-coco","text":"\u6211\u4eec\u4ee5 yolov5n \u7f51\u7edc\u4e3a\u4f8b\uff0c result.csv \u8fd9\u4e2a\u65e5\u5fd7\u5c55\u793a\u4e86\u6211\u4eec\u57fa\u4e8e one-yolov5 \u5728 COCO \u4e0a\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 YOLOv5n \u7f51\u7edc\u7684\u65e5\u5fd7\u3002\u4e0b\u56fe\u5c55\u793a\u4e86 box_loss , obj_loss , cls_loss \uff0c map_0.5 , map_0.5:0.95 \u7b49\u6307\u6807\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u60c5\u51b5\uff1a \u6700\u7ec8\u5728\u7b2c 300 \u4e2a epoch \u65f6\uff0c\u6211\u4eec\u7684 map_0.5 \u8fbe\u5230\u4e86 0.45174 \uff0c map_0.5:0.95 \u8fbe\u5230\u4e86 0.27726 \u3002 \u548c ultralytics/yolov5 \u7ed9\u51fa\u7684\u7cbe\u5ea6\u6570\u636e \u4e00\u81f4\uff08\u6ce8\u610f\u5b98\u7f51\u7ed9\u51fa\u7684\u7cbe\u5ea6\u6307\u5b9a iou \u4e3a 0.65 \u7684\u7cbe\u5ea6\uff0c\u800c\u4e0a\u8ff0 csv \u6587\u4ef6\u4e2d\u662f\u5728 iou \u4e3a 0.60 \u4e0b\u7684\u7cbe\u5ea6\uff0c\u4f7f\u7528\u6211\u4eec\u8bad\u7ec3\u7684\u6743\u91cd\u5e76\u628a iou \u6307\u5b9a\u4e3a 0.65 \u53ef\u4ee5\u5b8c\u5168\u5bf9\u9f50\u5b98\u65b9\u7ed9\u51fa\u7684\u7cbe\u5ea6\u6570\u636e\uff09\u3002 \u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 ultralytics/yolov5 \u6765\u9a8c\u8bc1\u4e00\u4e0b\uff1a python val . py -- weights yolov5n . pt -- data data / coco . yaml -- img 640 -- iou 0.60 \u8f93\u51fa\uff1a val: data = data/coco.yaml, weights =[ 'yolov5n.pt' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, max_det = 300 , task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = False, dnn = False YOLOv5 \ud83d\ude80 v6.1-384-g7fd9867 Python-3.8.13 torch-1.10.0+cu113 CUDA:0 ( NVIDIA GeForce RTX 3080 Ti, 12054MiB ) cuda:0 Fusing layers... YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4 .5 GFLOPs val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588 Class Images Instances P R mAP50 mAP50-95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 00 :40< 00 :00, 3 . all 5000 36335 0 .573 0 .432 0 .456 0 .277 \u4e0a\u9762\u7684\u8f93\u51fa\u53ef\u4ee5\u8bf4\u660e\u6211\u4eec\u548c ultralytics/yolov5 \u7684\u7cbe\u5ea6\u662f\u5b8c\u5168\u5bf9\u9f50\u7684\u3002 \u5728 one-yolov5 \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 yolov5n \u8fdb\u884c\u7cbe\u5ea6\u590d\u73b0\u7684\u547d\u4ee4\u4e3a (2\u5361DDP\u6a21\u5f0f) \uff1a python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- data data / coco . yaml -- weights ' ' -- cfg models / yolov5n . yaml -- batch 64","title":"0x2. \u5728COCO\u4e0a\u7684\u7cbe\u5ea6\u8868\u73b0"},{"location":"tutorials/00_chapter/overview.html#0x3-coco","text":"\u4ee5\u4e0b\u7684\u6027\u80fd\u7ed3\u679c\u90fd\u662f\u76f4\u63a5\u5c06 PyTorch \u5207\u6362\u4e3a OneFlow \u4e4b\u540e\u6d4b\u8bd5\u7684\uff0c \u5e76\u6ca1\u6709\u505a\u9488\u5bf9\u6027\u4f18\u5316 \uff0c\u540e\u7eed\u4f1a\u5728\u6b64\u57fa\u7840\u4e0a\u7ee7\u7eed\u63d0\u5347 OneFlow \u540e\u7aef YOLOv5 \u7684\u8bad\u7ec3\u901f\u5ea6\u3002","title":"0x3. \u5728COCO\u4e0a\u7684\u6027\u80fd\u8868\u73b0"},{"location":"tutorials/00_chapter/overview.html#3080ti","text":"","title":"\u5728 3080Ti \u7684\u6027\u80fd\u6d4b\u8bd5\u7ed3\u679c"},{"location":"tutorials/00_chapter/overview.html#_1","text":"\u4ee5\u4e0b\u4e3aGTX 3080ti(12GB) \u7684yolov5\u6d4b\u8bd5\u7ed3\u679c\uff08oneflow\u540e\u7aef vs PyTorch\u540e\u7aef\uff09 \u4ee5\u4e0b\u6d4b\u8bd5\u7ed3\u679c\u7684\u6570\u636e\u914d\u7f6e\u5747\u4e3acoco.yaml\uff0c\u6a21\u578b\u914d\u7f6e\u4e5f\u5b8c\u5168\u4e00\u6837\uff0c\u5e76\u8bb0\u5f55\u8bad\u7ec3\u5b8ccoco\u6570\u636e\u96c61\u4e2aepoch\u9700\u8981\u7684\u65f6\u95f4 \u7531\u4e8eoneflow eager\u76ee\u524damp\u7684\u652f\u6301\u8fd8\u4e0d\u5b8c\u5584\uff0c\u6240\u4ee5\u6211\u4eec\u63d0\u4f9b\u7684\u7ed3\u679c\u5747\u4e3afp32\u6a21\u5f0f\u4e0b\u8fdb\u884c\u8bad\u7ec3\u7684\u6027\u80fd\u7ed3\u679c PyTorch\u7248\u672c yolov5 code base\u94fe\u63a5\uff1ahttps://github.com/ultralytics/yolov5 OneFlow\u7248\u672c yolov5 code base\u94fe\u63a5\uff1ahttps://github.com/Oneflow-Inc/one-yolov5 cuda \u7248\u672c 11.7, cudnn \u7248\u672c\u4e3a 8.5.0 \u6d4b\u8bd5\u7684\u547d\u4ee4\u4e3a\uff1a python train.py --batch 16 --cfg models/yolov5n.yaml --weights '' --data coco.yaml --img 640 --device 0 \uff0c\u5176\u4e2d batch \u53c2\u6570\u662f\u52a8\u6001\u53d8\u5316\u7684 \u53ef\u4ee5\u770b\u5230\uff0c\u5728 batch \u6bd4\u8f83\u5c0f\u7684\u65f6\u5019 OneFlow \u540e\u7aef\u7684 YOLOv5 \u76f8\u6bd4\u4e8e PyTorch \u6709 5%-10% \u5de6\u53f3\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u8fd9\u53ef\u80fd\u5f97\u76ca\u4e8e OneFlow \u7684 Eager \u8fd0\u884c\u65f6\u7cfb\u7edf\u53ef\u4ee5\u66f4\u5feb\u7684\u505a CUDA Kernel Launch\u3002\u800c batch \u6bd4\u8f83\u5927\u7684\u65f6\u5019 OneFlow \u540e\u7aef\u7684 YOLOv5 \u76f8\u6bd4\u4e8e PyTorch \u7684\u6027\u80fd\u5dee\u4e0d\u591a\u662f\u6301\u5e73\uff0c\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u5f53 Batch \u6bd4\u8f83\u5927\u7684\u65f6\u5019 CUDA Kernel Launch \u7684\u5f00\u9500\u76f8\u6bd4\u4e8e\u8ba1\u7b97\u7684\u5f00\u9500\u4f1a\u6bd4\u8f83\u5c0f\u3002","title":"\u5355\u5361\u6d4b\u8bd5\u7ed3\u679c"},{"location":"tutorials/00_chapter/overview.html#ddp","text":"\u914d\u7f6e\u548c\u5355\u5361\u5747\u4e00\u81f4 \u6d4b\u8bd5\u7684\u547d\u4ee4\u4e3a\uff1a python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 16 --data coco.yaml --weights '' --device 0,1 \uff0c\u5176\u4e2d batch \u53c2\u6570\u662f\u52a8\u6001\u53d8\u5316\u7684 \u5f97\u76ca\u4e8e\u5355\u5361\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5728 2 \u5361DDP\u6a21\u5f0f\u4e0b\uff0cOneFlow \u540e\u7aef\u7684 YOLOv5 \u5728\u5c0f batch \u7684\u8bad\u7ec3\u65f6\u95f4\u4e5f\u662f\u7a0d\u5fae\u9886\u5148 PyTorch \u540e\u7aef\u7684 YoloV5 \uff0c\u800c\u5bf9\u4e8e\u5927 Batch \u6765\u8bf4\u6027\u80fd\u548c PyTorch \u76f8\u6bd4\u4e5f\u662f\u5dee\u4e0d\u591a\u6301\u5e73\u3002","title":"\u4e24\u5361DDP\u6d4b\u8bd5\u7ed3\u679c"},{"location":"tutorials/00_chapter/overview.html#0x4","text":"\u6211\u4eec\u57fa\u4e8e OneFlow \u79fb\u690d\u4e86 ultralytics \u7248\u7684 YOLOv5 \uff0c\u5728\u7cbe\u5ea6\u8bad\u7ec3\u8fbe\u6807\u7684\u60c5\u51b5\u4e0b\u8fd8\u53ef\u4ee5\u5728 Batch \u6bd4\u8f83\u5c0f\u65f6\u53d6\u5f97\u4e00\u4e9b\u6027\u80fd\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9 YOLOv5 \u4e2d\u76f8\u5173\u7684\u6559\u7a0b\u8fdb\u884c\u4e86\u6c49\u5316\uff0c\u6dfb\u52a0\u4e86\u4e00\u7cfb\u5217\u8be6\u7ec6\u7684\u4ee3\u7801\u89e3\u8bfb\uff0c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u90e8\u7f72\u6559\u7a0b\uff0c\u5e0c\u671b\u4f7f\u5f97 YOLOv5 \u9879\u76ee\u5bf9\u7528\u6237\u66f4\u52a0\u900f\u660e\u5316\u3002\u76f8\u4fe1\u5bf9\u60f3\u6df1\u5165\u4e86\u89e3 YOLOv5 \u7684\u8bfb\u8005\u6211\u4eec\u7684 \u300aYOLOv5\u5168\u9762\u89e3\u6790\u6559\u7a0b\u300b \u4e5f\u662f\u4e00\u4efd\u4e0d\u9519\u7684\u5b66\u4e60\u8d44\u6599\u3002","title":"0x4. \u603b\u7ed3"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790 \u5f15\u8a00 YOLOv5\u9488\u5bf9\u4e0d\u540c\u5927\u5c0f\uff08n, s, m, l, x\uff09\u7684\u7f51\u7edc\u6574\u4f53\u67b6\u6784\u90fd\u662f\u4e00\u6837\u7684\uff0c\u53ea\u4e0d\u8fc7\u4f1a\u5728\u6bcf\u4e2a\u5b50\u6a21\u5757\u4e2d\u91c7\u7528\u4e0d\u540c\u7684\u6df1\u5ea6\u548c\u5bbd\u5ea6\uff0c \u5206\u522b\u5e94\u5bf9yaml\u6587\u4ef6\u4e2d\u7684depth_multiple\u548cwidth_multiple\u53c2\u6570\u3002 \u8fd8\u9700\u8981\u6ce8\u610f\u4e00\u70b9\uff0c\u5b98\u65b9\u9664\u4e86n, s, m, l, x\u7248\u672c\u5916\u8fd8\u6709n6, s6, m6, l6, x6\uff0c\u533a\u522b\u5728\u4e8e\u540e\u8005\u662f\u9488\u5bf9\u66f4\u5927\u5206\u8fa8\u7387\u7684\u56fe\u7247\u6bd4\u59821280x1280, \u5f53\u7136\u7ed3\u6784\u4e0a\u4e5f\u6709\u4e9b\u5dee\u5f02\uff0c\u524d\u8005\u53ea\u4f1a\u4e0b\u91c7\u6837\u523032\u500d\u4e14\u91c7\u75283\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42 , \u800c\u540e\u8005\u4f1a\u4e0b\u91c7\u683764\u500d\uff0c\u91c7\u75284\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u3002 \u672c\u7ae0\u5c06\u4ee5 yolov5s\u4e3a\u4f8b \uff0c\u4ece\u914d\u7f6e\u6587\u4ef6 models/ yolov5s.yaml \u5230 models/ yolo.py \u6e90\u7801\u8fdb\u884c\u89e3\u8bfb\u3002 yolov5s.yaml \u6587\u4ef6\u5185\u5bb9: nc : 80 # number of classes \u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u6570 depth_multiple : 0.33 # model depth multiple \u6a21\u578b\u5c42\u6570\u56e0\u5b50(\u7528\u6765\u8c03\u6574\u7f51\u7edc\u7684\u6df1\u5ea6) width_multiple : 0.50 # layer channel multiple \u6a21\u578b\u901a\u9053\u6570\u56e0\u5b50(\u7528\u6765\u8c03\u6574\u7f51\u7edc\u7684\u5bbd\u5ea6) # \u5982\u4f55\u7406\u89e3\u8fd9\u4e2adepth_multiple\u548cwidth_multiple\u5462? # \u5b83\u51b3\u5b9a\u7684\u662f\u6574\u4e2a\u6a21\u578b\u4e2d\u7684\u6df1\u5ea6\uff08\u5c42\u6570\uff09\u548c\u5bbd\u5ea6\uff08\u901a\u9053\u6570\uff09,\u5177\u4f53\u600e\u4e48\u8c03\u6574\u7684\u7ed3\u5408\u540e\u9762\u7684backbone\u4ee3\u7801\u89e3\u91ca\u3002 anchors : # \u8868\u793a\u4f5c\u7528\u4e8e\u5f53\u524d\u7279\u5f81\u56fe\u7684Anchor\u5927\u5c0f\u4e3a xxx # 9\u4e2aanchor\uff0c\u5176\u4e2dP\u8868\u793a\u7279\u5f81\u56fe\u7684\u5c42\u7ea7\uff0cP3/8\u8be5\u5c42\u7279\u5f81\u56fe\u7f29\u653e\u4e3a1/8,\u662f\u7b2c3\u5c42\u7279\u5f81 - [ 10 , 13 , 16 , 30 , 33 , 23 ] # P3/8\uff0c \u8868\u793a[10,13],[16,30], [33,23]3\u4e2aanchor - [ 30 , 61 , 62 , 45 , 59 , 119 ] # P4/16 - [ 116 , 90 , 156 , 198 , 373 , 326 ] # P5/32 # YOLOv5s v6.0 backbone backbone : # [from, number, module, args] [[ -1 , 1 , Conv , [ 64 , 6 , 2 , 2 ]], # 0-P1/2 [ -1 , 1 , Conv , [ 128 , 3 , 2 ]], # 1-P2/4 [ -1 , 3 , C3 , [ 128 ]], [ -1 , 1 , Conv , [ 256 , 3 , 2 ]], # 3-P3/8 [ -1 , 6 , C3 , [ 256 ]], [ -1 , 1 , Conv , [ 512 , 3 , 2 ]], # 5-P4/16 [ -1 , 9 , C3 , [ 512 ]], [ -1 , 1 , Conv , [ 1024 , 3 , 2 ]], # 7-P5/32 [ -1 , 3 , C3 , [ 1024 ]], [ -1 , 1 , SPPF , [ 1024 , 5 ]], # 9 ] # YOLOv5s v6.0 head head : [[ -1 , 1 , Conv , [ 512 , 1 , 1 ]], [ -1 , 1 , nn.Upsample , [ None , 2 , 'nearest' ]], [[ -1 , 6 ], 1 , Concat , [ 1 ]], # cat backbone P4 [ -1 , 3 , C3 , [ 512 , False ]], # 13 [ -1 , 1 , Conv , [ 256 , 1 , 1 ]], [ -1 , 1 , nn.Upsample , [ None , 2 , 'nearest' ]], [[ -1 , 4 ], 1 , Concat , [ 1 ]], # cat backbone P3 [ -1 , 3 , C3 , [ 256 , False ]], # 17 (P3/8-small) [ -1 , 1 , Conv , [ 256 , 3 , 2 ]], [[ -1 , 14 ], 1 , Concat , [ 1 ]], # cat head P4 [ -1 , 3 , C3 , [ 512 , False ]], # 20 (P4/16-medium) [ -1 , 1 , Conv , [ 512 , 3 , 2 ]], [[ -1 , 10 ], 1 , Concat , [ 1 ]], # cat head P5 [ -1 , 3 , C3 , [ 1024 , False ]], # 23 (P5/32-large) [[ 17 , 20 , 23 ], 1 , Detect , [ nc , anchors ]], # Detect(P3, P4, P5) ] anchors \u89e3\u8bfb yolov5 \u521d\u59cb\u5316\u4e86 9 \u4e2a anchors\uff0c\u5206\u522b\u5728\u4e09\u4e2a\u7279\u5f81\u56fe \uff08feature map\uff09\u4e2d\u4f7f\u7528\uff0c\u6bcf\u4e2a feature map \u7684\u6bcf\u4e2a grid cell \u90fd\u6709\u4e09\u4e2a anchor \u8fdb\u884c\u9884\u6d4b\u3002 \u5206\u914d\u89c4\u5219\uff1a \u5c3a\u5ea6\u8d8a\u5927\u7684 feature map \u8d8a\u9760\u524d\uff0c\u76f8\u5bf9\u539f\u56fe\u7684\u4e0b\u91c7\u6837\u7387\u8d8a\u5c0f\uff0c\u611f\u53d7\u91ce\u8d8a\u5c0f\uff0c \u6240\u4ee5\u76f8\u5bf9\u53ef\u4ee5\u9884\u6d4b\u4e00\u4e9b\u5c3a\u5ea6\u6bd4\u8f83\u5c0f\u7684\u7269\u4f53(\u5c0f\u76ee\u6807)\uff0c\u5206\u914d\u5230\u7684 anchors \u8d8a\u5c0f\u3002 \u5c3a\u5ea6\u8d8a\u5c0f\u7684 feature map \u8d8a\u9760\u540e\uff0c\u76f8\u5bf9\u539f\u56fe\u7684\u4e0b\u91c7\u6837\u7387\u8d8a\u5927\uff0c\u611f\u53d7\u91ce\u8d8a\u5927\uff0c \u6240\u4ee5\u53ef\u4ee5\u9884\u6d4b\u4e00\u4e9b\u5c3a\u5ea6\u6bd4\u8f83\u5927\u7684\u7269\u4f53(\u5927\u76ee\u6807)\uff0c\u6240\u4ee5\u5206\u914d\u5230\u7684 anchors \u8d8a\u5927\u3002 \u5373\u5728\u5c0f\u7279\u5f81\u56fe\uff08feature map\uff09\u4e0a\u68c0\u6d4b\u5927\u76ee\u6807\uff0c\u4e2d\u7b49\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u4e0a\u68c0\u6d4b\u4e2d\u7b49\u76ee\u6807\uff0c \u5728\u5927\u7279\u5f81\u56fe\u4e0a\u68c0\u6d4b\u5c0f\u76ee\u6807\u3002 backbone & head\u89e3\u8bfb [from, number, module, args] \u53c2\u6570 \u56db\u4e2a\u53c2\u6570\u7684\u610f\u4e49\u5206\u522b\u662f\uff1a 1. \u7b2c\u4e00\u4e2a\u53c2\u6570 from \uff1a\u4ece\u54ea\u4e00\u5c42\u83b7\u5f97\u8f93\u5165\uff0c-1\u8868\u793a\u4ece\u4e0a\u4e00\u5c42\u83b7\u5f97\uff0c[-1, 6]\u8868\u793a\u4ece\u4e0a\u5c42\u548c\u7b2c6\u5c42\u4e24\u5c42\u83b7\u5f97\u3002 2. \u7b2c\u4e8c\u4e2a\u53c2\u6570 number\uff1a\u8868\u793a\u6709\u51e0\u4e2a\u76f8\u540c\u7684\u6a21\u5757\uff0c\u5982\u679c\u4e3a9\u5219\u8868\u793a\u67099\u4e2a\u76f8\u540c\u7684\u6a21\u5757\u3002 3. \u7b2c\u4e09\u4e2a\u53c2\u6570 module\uff1a\u6a21\u5757\u7684\u540d\u79f0\uff0c\u8fd9\u4e9b\u6a21\u5757\u5199\u5728common.py\u4e2d\u3002 4. \u7b2c\u56db\u4e2a\u53c2\u6570 args\uff1a\u7c7b\u7684\u521d\u59cb\u5316\u53c2\u6570\uff0c\u7528\u4e8e\u89e3\u6790\u4f5c\u4e3a moudle \u7684\u4f20\u5165\u53c2\u6570\u3002 \u4e0b\u9762\u4ee5\u7b2c\u4e00\u4e2a\u6a21\u5757Conv \u4e3a\u4f8b\u4ecb\u7ecd\u4e0bcommon.py\u4e2d\u7684\u6a21\u5757 Conv \u6a21\u5757\u5b9a\u4e49\u5982\u4e0b: class Conv ( nn . Module ): # Standard convolution def __init__ ( self , c1 , c2 , k = 1 , s = 1 , p = None , g = 1 , act = True ): # ch_in, ch_out, kernel, stride, padding, groups \"\"\" @Pargm c1: \u8f93\u5165\u901a\u9053\u6570 @Pargm c2: \u8f93\u51fa\u901a\u9053\u6570 @Pargm k : \u5377\u79ef\u6838\u5927\u5c0f(kernel_size) @Pargm s : \u5377\u79ef\u6b65\u957f (stride) @Pargm p : \u7279\u5f81\u56fe\u586b\u5145\u5bbd\u5ea6 (padding) @Pargm g : \u63a7\u5236\u5206\u7ec4\uff0c\u5fc5\u987b\u6574\u9664\u8f93\u5165\u7684\u901a\u9053\u6570(\u4fdd\u8bc1\u8f93\u5165\u7684\u901a\u9053\u80fd\u88ab\u6b63\u786e\u5206\u7ec4) \"\"\" super () . __init__ () # https://oneflow.readthedocs.io/en/master/generated/oneflow.nn.Conv2d.html?highlight=Conv self . conv = nn . Conv2d ( c1 , c2 , k , s , autopad ( k , p ), groups = g , bias = False ) self . bn = nn . BatchNorm2d ( c2 ) self . act = nn . SiLU () if act is True else ( act if isinstance ( act , nn . Module ) else nn . Identity ()) def forward ( self , x ): return self . act ( self . bn ( self . conv ( x ))) def forward_fuse ( self , x ): return self . act ( self . conv ( x )) \u6bd4\u5982\u4e0a\u9762\u628awidth_multiple\u8bbe\u7f6e\u4e3a\u4e860.5\uff0c\u90a3\u4e48\u7b2c\u4e00\u4e2a [64, 6, 2, 2] \u5c31\u4f1a\u88ab\u89e3\u6790\u4e3a [3,64*0.5=32,6,2,2]\uff0c\u5176\u4e2d\u7b2c\u4e00\u4e2a 3 \u4e3a\u8f93\u5165channel(\u56e0\u4e3a\u8f93\u5165)\uff0c32 \u4e3a\u8f93\u51fachannel\u3002 \u5173\u4e8e\u8c03\u6574\u7f51\u7edc\u5927\u5c0f\u7684\u8be6\u89e3\u8bf4\u660e \u5728 yolo.py \u7684 286 \u884c\u6709\u5bf9yaml \u6587\u4ef6\u7684nc,depth_multiple\u7b49\u53c2\u6570\u8bfb\u53d6\uff0c\u5177\u4f53\u4ee3\u7801\u5982\u4e0b: anchors , nc , gd , gw = d [ 'anchors' ], d [ 'nc' ], d [ 'depth_multiple' ], d [ 'width_multiple' ], d . get ( \"activation\" ) \"width_multiple\"\u53c2\u6570\u7684\u4f5c\u7528\u524d\u9762\u4ecb\u7ecdargs\u53c2\u6570\u4e2d\u5df2\u7ecf\u4ecb\u7ecd\u8fc7\u4e86\uff0c\u90a3\u4e48\"depth_multiple\"\u53c8\u662f\u4ec0\u4e48\u4f5c\u7528\u5462\uff1f \u5728 yolo.py \u7684 300 \u884c\u6709\u5bf9\u53c2\u6570\u7684\u5177\u4f53\u5b9a\u4e49\uff1a n = n_ = max ( round ( n * gd ), 1 ) if n > 1 else n # depth gain \u6682\u4e14\u5c06\u8fd9\u6bb5\u4ee3\u7801\u5f53\u4f5c\u516c\u5f0f(1) \u5176\u4e2d gd \u5c31\u662fdepth_multiple\u7684\u503c\uff0cn\u7684\u503c\u5c31\u662fbackbone\u4e2d\u5217\u8868\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\uff1a \u6839\u636e\u516c\u793a(1) \u5f88\u5bb9\u6613\u770b\u51fa gd \u5f71\u54cd n \u7684\u5927\u5c0f\uff0c\u4ece\u800c\u5f71\u54cd\u7f51\u7edc\u7684\u7ed3\u6784\u5927\u5c0f\u3002 \u540e\u9762\u5404\u5c42\u4e4b\u95f4\u7684\u6a21\u5757\u6570\u91cf\u3001\u5377\u79ef\u6838\u5927\u5c0f\u548c\u6570\u91cf\u7b49\u4e5f\u90fd\u4ea7\u751f\u4e86\u53d8\u5316\uff0cYOLOv5l \u4e0e YOLOv5s \u76f8\u6bd4\u8f83\u8d77\u6765\u8bad\u7ec3\u53c2\u6570\u7684\u5927\u5c0f\u6210\u500d\u6570\u589e\u957f\uff0c \u5176\u6a21\u578b\u7684\u6df1\u5ea6\u548c\u5bbd\u5ea6\u4e5f\u4f1a\u5927\u5f88\u591a\uff0c\u8fd9\u5c31\u4f7f\u5f97 YOLOv5l \u7684 \u7cbe\u5ea6\u503c\u8981\u6bd4 YOLOv5s \u597d\u5f88\u591a\uff0c\u56e0\u6b64\u5728\u6700\u7ec8\u63a8\u7406\u65f6\u7684\u68c0\u6d4b\u7cbe\u5ea6\u9ad8\uff0c\u4f46\u662f\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u66f4\u6162\u3002 \u6240\u4ee5 YOLOv5 \u63d0\u4f9b\u4e86\u4e0d\u540c\u7684\u9009\u62e9\uff0c\u5982\u679c\u60f3\u8981\u8ffd\u6c42\u63a8\u7406\u901f\u5ea6\u53ef\u9009\u7528\u8f83\u5c0f\u4e00\u4e9b\u7684\u6a21\u578b\u5982 YOLOv5s\u3001YOLOv5m\uff0c\u5982\u679c\u60f3\u8981\u8ffd\u6c42\u7cbe\u5ea6\u66f4\u9ad8\u5bf9\u63a8\u7406\u901f\u5ea6\u8981\u6c42\u4e0d\u9ad8\u7684\u53ef\u4ee5\u9009\u62e9\u5176\u4ed6\u4e24\u4e2a\u7a0d\u5927\u7684\u6a21\u578b\u3002 \u5982\u4e0b\u9762\u8fd9\u5f20\u56fe\uff1a \u56fe2.1 :yolov5 \u6a21\u578b\u6bd4\u8f83\u56fe \u6765\u6e90:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data Conv\u6a21\u5757\u89e3\u8bfb \u7f51\u7edc\u7ed3\u6784\u9884\u89c8 \u4e0b\u9762\u662f\u6839\u636e yolov5s.yaml \u7ed8\u5236\u7684\u7f51\u7edc\u6574\u4f53\u7ed3\u6784\u7b80\u5316\u7248\u3002 \u56fe2.2 :yolov5s \u7f51\u7edc\u6574\u4f53\u7ed3\u6784 \u8be6\u7ec6\u7684\u7f51\u7edc\u7ed3\u6784\u56fe\uff1ahttps://oneflow-static.oss-cn-beijing.aliyuncs.com/one-yolo/imgs/yolov5s.onnx.png \u901a\u8fc7export.py\u5bfc\u51fa\u7684onnx\u683c\u5f0f\uff0c\u5e76\u901a\u8fc7 https://netron.app/ \u7f51\u7ad9\u5bfc\u51fa\u7684\u56fe\u7247(\u6a21\u578b\u5bfc\u51fa\u5c06\u5728\u672c\u6559\u7a0b\u7684\u540e\u7eed\u6587\u7ae0\u5355\u72ec\u4ecb\u7ecd)\u3002 \u6a21\u5757\u7ec4\u4ef6\u53f3\u8fb9\u53c2\u6570 \u8868\u793a\u7279\u5f81\u56fe\u7684\u7684\u5f62\u72b6\uff0c\u6bd4\u5982 \u5728 \u7b2c \u4e00 \u5c42( Conv )\u8f93\u5165 \u56fe\u7247\u5f62\u72b6\u4e3a [ 3, 640, 640] ,\u5173\u4e8e\u8fd9\u4e9b\u53c2\u6570\uff0c\u53ef\u4ee5\u56fa\u5b9a\u4e00\u5f20\u56fe\u7247\u8f93\u5165\u5230\u7f51\u7edc\u5e76\u901a\u8fc7 yolov5s.yaml \u7684\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\u5f97\u5230\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u5de5\u7a0b models/ yolo.py \u901a\u8fc7\u4ee3\u7801\u8fdb\u884cprint\u67e5\u770b,\u8be6\u7ec6\u6570\u636e\u53ef\u4ee5\u53c2\u8003\u9644\u4ef6\u88682.1\u3002 [1, 128, 80, 80],[1, 256, 40, 40],[1, 512, 20, 20] \u4f5c\u4e3a\u8f93\u5165\u7ecf\u8fc7Detect\u7684forward, \u63a5\u7740flow.cat()\u51fd\u6570\u62fc\u63a5\u6210\u4e3aoutput: [1, 25200, 85]\u3002 yolo.py \u89e3\u8bfb \u6587\u4ef6\u5730\u5740 \u6587\u4ef6\u4e3b\u8981\u5305\u542b \u4e09\u5927\u90e8\u5206 Detect\u7c7b\uff0c Model\u7c7b\uff0c\u548c parse_model \u51fd\u6570 \u53ef\u4ee5\u901a\u8fc7 python models/ yolo.py --cfg yolov5s.yaml \u8fd0\u884c\u8be5\u811a\u672c\u8fdb\u884c\u89c2\u5bdf parse_model\u51fd\u6570\u89e3\u8bfb def parse_model ( d , ch ): # model_dict, input_channels(3) \"\"\"\u7528\u5728\u4e0b\u9762Model\u6a21\u5757\u4e2d \u89e3\u6790\u6a21\u578b\u6587\u4ef6(\u5b57\u5178\u5f62\u5f0f)\uff0c\u5e76\u642d\u5efa\u7f51\u7edc\u7ed3\u6784 \u8fd9\u4e2a\u51fd\u6570\u5176\u5b9e\u4e3b\u8981\u505a\u7684\u5c31\u662f: \u66f4\u65b0\u5f53\u524d\u5c42\u7684args\uff08\u53c2\u6570\uff09,\u8ba1\u7b97c2\uff08\u5f53\u524d\u5c42\u7684\u8f93\u51fachannel\uff09 => \u4f7f\u7528\u5f53\u524d\u5c42\u7684\u53c2\u6570\u642d\u5efa\u5f53\u524d\u5c42 => \u751f\u6210 layers + save @Params d: model_dict \u6a21\u578b\u6587\u4ef6 \u5b57\u5178\u5f62\u5f0f {dict:7} [yolov5s.yaml](https://github.com/Oneflow-Inc/one-yolov5/blob/main/models/yolov5s.yaml)\u4e2d\u76846\u4e2a\u5143\u7d20 + ch #Params ch: \u8bb0\u5f55\u6a21\u578b\u6bcf\u4e00\u5c42\u7684\u8f93\u51fachannel \u521d\u59cbch=[3] \u540e\u9762\u4f1a\u5220\u9664 @return nn.Sequential(*layers): \u7f51\u7edc\u7684\u6bcf\u4e00\u5c42\u7684\u5c42\u7ed3\u6784 @return sorted(save): \u628a\u6240\u6709\u5c42\u7ed3\u6784\u4e2dfrom\u4e0d\u662f-1\u7684\u503c\u8bb0\u4e0b \u5e76\u6392\u5e8f [4, 6, 10, 14, 17, 20, 23] \"\"\" LOGGER . info ( f \" \\n { '' : >3 }{ 'from' : >18 }{ 'n' : >3 }{ 'params' : >10 } { 'module' : <40 }{ 'arguments' : <30 } \" ) # \u8bfb\u53d6d\u5b57\u5178\u4e2d\u7684anchors\u548cparameters(nc\u3001depth_multiple\u3001width_multiple) anchors , nc , gd , gw = d [ 'anchors' ], d [ 'nc' ], d [ 'depth_multiple' ], d [ 'width_multiple' ] # na: number of anchors \u6bcf\u4e00\u4e2apredict head\u4e0a\u7684anchor\u6570 = 3 na = ( len ( anchors [ 0 ]) // 2 ) if isinstance ( anchors , list ) else anchors # number of anchors no = na * ( nc + 5 ) # number of outputs = anchors * (classes + 5) \u6bcf\u4e00\u4e2apredict head\u5c42\u7684\u8f93\u51fachannel # \u5f00\u59cb\u642d\u5efa\u7f51\u7edc # layers: \u4fdd\u5b58\u6bcf\u4e00\u5c42\u7684\u5c42\u7ed3\u6784 # save: \u8bb0\u5f55\u4e0b\u6240\u6709\u5c42\u7ed3\u6784\u4e2dfrom\u4e2d\u4e0d\u662f-1\u7684\u5c42\u7ed3\u6784\u5e8f\u53f7 # c2: \u4fdd\u5b58\u5f53\u524d\u5c42\u7684\u8f93\u51fachannel layers , save , c2 = [], [], ch [ - 1 ] # layers, savelist, ch out # enumerate() \u51fd\u6570\u7528\u4e8e\u5c06\u4e00\u4e2a\u53ef\u904d\u5386\u7684\u6570\u636e\u5bf9\u8c61(\u5982\u5217\u8868\u3001\u5143\u7ec4\u6216\u5b57\u7b26\u4e32)\u7ec4\u5408\u4e3a\u4e00\u4e2a\u7d22\u5f15\u5e8f\u5217\uff0c\u540c\u65f6\u5217\u51fa\u6570\u636e\u548c\u6570\u636e\u4e0b\u6807\uff0c\u4e00\u822c\u7528\u5728 for \u5faa\u73af\u5f53\u4e2d\u3002 for i , ( f , n , m , args ) in enumerate ( d [ 'backbone' ] + d [ 'head' ]): # from, number, module, args m = eval ( m ) if isinstance ( m , str ) else m # eval strings for j , a in enumerate ( args ): # args\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u8fd9\u4e00\u6b65\u628a\u5217\u8868\u4e2d\u7684\u5185\u5bb9\u53d6\u51fa\u6765 with contextlib . suppress ( NameError ): args [ j ] = eval ( a ) if isinstance ( a , str ) else a # eval strings # \u5c06\u6df1\u5ea6\u4e0e\u6df1\u5ea6\u56e0\u5b50\u76f8\u4e58\uff0c\u8ba1\u7b97\u5c42\u6df1\u5ea6\u3002\u6df1\u5ea6\u6700\u5c0f\u4e3a1. n = n_ = max ( round ( n * gd ), 1 ) if n > 1 else n # depth gain # \u5982\u679c\u5f53\u524d\u7684\u6a21\u5757m\u5728\u672c\u9879\u76ee\u5b9a\u4e49\u7684\u6a21\u5757\u7c7b\u578b\u4e2d\uff0c\u5c31\u53ef\u4ee5\u5904\u7406\u8fd9\u4e2a\u6a21\u5757 if m in ( Conv , GhostConv , Bottleneck , GhostBottleneck , SPP , SPPF , DWConv , MixConv2d , Focus , CrossConv , BottleneckCSP , C3 , C3TR , C3SPP , C3Ghost , nn . ConvTranspose2d , DWConvTranspose2d , C3x ): # c1: \u8f93\u5165\u901a\u9053\u6570 c2\uff1a\u8f93\u51fa\u901a\u9053\u6570 c1 , c2 = ch [ f ], args [ 0 ] # \u8be5\u5c42\u4e0d\u662f\u6700\u540e\u4e00\u5c42\uff0c\u5219\u5c06\u901a\u9053\u6570\u4e58\u4ee5\u5bbd\u5ea6\u56e0\u5b50 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5bbd\u5ea6\u56e0\u5b50\u4f5c\u7528\u4e8e\u9664\u4e86\u6700\u540e\u4e00\u5c42\u4e4b\u5916\u7684\u6240\u6709\u5c42 if c2 != no : # if not output # make_divisible\u7684\u4f5c\u7528\uff0c\u4f7f\u5f97\u539f\u59cb\u7684\u901a\u9053\u6570\u4e58\u4ee5\u5bbd\u5ea6\u56e0\u5b50\u4e4b\u540e\u53d6\u6574\u52308\u7684\u500d\u6570\uff0c\u8fd9\u6837\u5904\u7406\u4e00\u822c\u662f\u8ba9\u6a21\u578b\u7684\u5e76\u884c\u6027\u548c\u63a8\u7406\u6027\u80fd\u66f4\u597d\u3002 c2 = make_divisible ( c2 * gw , 8 ) # \u5c06\u524d\u9762\u7684\u8fd0\u7b97\u7ed3\u679c\u4fdd\u5b58\u5728args\u4e2d\uff0c\u5b83\u4e5f\u5c31\u662f\u8fd9\u4e2a\u6a21\u5757\u6700\u7ec8\u7684\u8f93\u5165\u53c2\u6570\u3002 args = [ c1 , c2 , * args [ 1 :]] # \u6839\u636e\u6bcf\u5c42\u7f51\u7edc\u53c2\u6570\u7684\u4e0d\u540c\uff0c\u5206\u522b\u5904\u7406\u53c2\u6570 \u5177\u4f53\u5404\u4e2a\u7c7b\u7684\u53c2\u6570\u662f\u4ec0\u4e48\u8bf7\u53c2\u8003\u5b83\u4eec\u7684__init__\u65b9\u6cd5\u8fd9\u91cc\u4e0d\u518d\u8be6\u7ec6\u89e3\u91ca\u4e86 if m in [ BottleneckCSP , C3 , C3TR , C3Ghost , C3x ]: # \u8fd9\u91cc\u7684\u610f\u601d\u5c31\u662f\u91cd\u590dn\u6b21\uff0c\u6bd4\u5982conv\u8fd9\u4e2a\u6a21\u5757\u91cd\u590dn\u6b21\uff0c\u8fd9\u4e2an \u662f\u4e0a\u9762\u7b97\u51fa\u6765\u7684 depth args . insert ( 2 , n ) # number of repeats n = 1 elif m is nn . BatchNorm2d : args = [ ch [ f ]] elif m is Concat : c2 = sum ( ch [ x ] for x in f ) elif m is Detect : args . append ([ ch [ x ] for x in f ]) if isinstance ( args [ 1 ], int ): # number of anchors args [ 1 ] = [ list ( range ( args [ 1 ] * 2 ))] * len ( f ) elif m is Contract : c2 = ch [ f ] * args [ 0 ] ** 2 elif m is Expand : c2 = ch [ f ] // args [ 0 ] ** 2 else : c2 = ch [ f ] # \u6784\u5efa\u6574\u4e2a\u7f51\u7edc\u6a21\u5757 \u8fd9\u91cc\u5c31\u662f\u6839\u636e\u6a21\u5757\u7684\u91cd\u590d\u6b21\u6570n\u4ee5\u53ca\u6a21\u5757\u672c\u8eab\u548c\u5b83\u7684\u53c2\u6570\u6765\u6784\u5efa\u8fd9\u4e2a\u6a21\u5757\u548c\u53c2\u6570\u5bf9\u5e94\u7684Module m_ = nn . Sequential ( * ( m ( * args ) for _ in range ( n ))) if n > 1 else m ( * args ) # module # \u83b7\u53d6\u6a21\u5757(module type)\u5177\u4f53\u540d\u4f8b\u5982 models.common.Conv , models.common.C3 , models.common.SPPF \u7b49\u3002 t = str ( m )[ 8 : - 2 ] . replace ( '__main__.' , '' ) # replace\u51fd\u6570\u4f5c\u7528\u662f\u5b57\u7b26\u4e32\"__main__\"\u66ff\u6362\u4e3a''\uff0c\u5728\u5f53\u524d\u9879\u76ee\u6ca1\u6709\u7528\u5230\u8fd9\u4e2a\u66ff\u6362\u3002 np = sum ( x . numel () for x in m_ . parameters ()) # number params m_ . i , m_ . f , m_ . type , m_ . np = i , f , t , np # attach index, 'from' index, type, number params LOGGER . info ( f ' { i : >3 }{ str ( f ) : >18 }{ n_ : >3 }{ np : 10.0f } { t : <40 }{ str ( args ) : <30 } ' ) # print \"\"\" \u5982\u679cx\u4e0d\u662f-1\uff0c\u5219\u5c06\u5176\u4fdd\u5b58\u5728save\u5217\u8868\u4e2d\uff0c\u8868\u793a\u8be5\u5c42\u9700\u8981\u4fdd\u5b58\u7279\u5f81\u56fe\u3002 \u8fd9\u91cc x % i \u4e0e x \u7b49\u4ef7\u4f8b\u5982\u5728\u6700\u540e\u4e00\u5c42 : f = [17,20,23] , i = 24 y = [ x % i for x in ([f] if isinstance(f, int) else f) if x != -1 ] print(y) # [17, 20, 23] # \u5199\u6210x % i \u53ef\u80fd\u56e0\u4e3a\uff1ai - 1 = -1 % i (\u6bd4\u5982 f = [-1]\uff0c\u5219 [x % i for x in f] \u4ee3\u8868 [11] ) \"\"\" save . extend ( x % i for x in ([ f ] if isinstance ( f , int ) else f ) if x != - 1 ) # append to savelist layers . append ( m_ ) if i == 0 : # \u5982\u679c\u662f\u521d\u6b21\u8fed\u4ee3\uff0c\u5219\u65b0\u521b\u5efa\u4e00\u4e2ach\uff08\u56e0\u4e3a\u5f62\u53c2ch\u5728\u521b\u5efa\u7b2c\u4e00\u4e2a\u7f51\u7edc\u6a21\u5757\u65f6\u9700\u8981\u7528\u5230\uff0c\u6240\u4ee5\u521b\u5efa\u7f51\u7edc\u6a21\u5757\u4e4b\u540e\u518d\u521d\u59cb\u5316ch\uff09 ch = [] ch . append ( c2 ) # \u5c06\u6240\u6709\u7684\u5c42\u5c01\u88c5\u4e3ann.Sequential , \u5bf9\u4fdd\u5b58\u7684\u7279\u5f81\u56fe\u6392\u5e8f return nn . Sequential ( * layers ), sorted ( save ) Model \u7c7b\u89e3\u8bfb class Model ( nn . Module ): # YOLOv5 model def __init__ ( self , cfg = '[yolov5s.yaml](https://github.com/Oneflow-Inc/one-yolov5/blob/main/models/yolov5s.yaml)' , ch = 3 , nc = None , anchors = None ): # model, input channels, number of classes super () . __init__ () # \u5982\u679ccfg\u5df2\u7ecf\u662f\u5b57\u5178\uff0c\u5219\u76f4\u63a5\u8d4b\u503c\uff0c\u5426\u5219\u5148\u52a0\u8f7dcfg\u8def\u5f84\u7684\u6587\u4ef6\u4e3a\u5b57\u5178\u5e76\u8d4b\u503c\u7ed9self.yaml\u3002 if isinstance ( cfg , dict ): self . yaml = cfg # model dict else : # is *.yaml \u52a0\u8f7dyaml\u6a21\u5757 import yaml # for flow hub self . yaml_file = Path ( cfg ) . name with open ( cfg , encoding = 'ascii' , errors = 'ignore' ) as f : self . yaml = yaml . safe_load ( f ) # model dict \u4eceyaml\u6587\u4ef6\u4e2d\u52a0\u8f7d\u51fa\u5b57\u5178 # Define model # ch: \u8f93\u5165\u901a\u9053\u6570\u3002 \u5047\u5982self.yaml\u6709\u952e\u2018ch\u2019\uff0c\u5219\u5c06\u8be5\u952e\u5bf9\u5e94\u7684\u503c\u8d4b\u7ed9\u5185\u90e8\u53d8\u91cfch\u3002\u5047\u5982\u6ca1\u6709\u2018ch\u2019\uff0c\u5219\u5c06\u5f62\u53c2ch\u8d4b\u7ed9\u5185\u90e8\u53d8\u91cfch ch = self . yaml [ 'ch' ] = self . yaml . get ( 'ch' , ch ) # input channels # \u5047\u5982yaml\u4e2d\u7684nc\u548c\u65b9\u6cd5\u5f62\u53c2\u4e2d\u7684nc\u4e0d\u4e00\u81f4\uff0c\u5219\u8986\u76d6yaml\u4e2d\u7684nc\u3002 if nc and nc != self . yaml [ 'nc' ]: LOGGER . info ( f \"Overriding model.yaml nc= { self . yaml [ 'nc' ] } with nc= { nc } \" ) self . yaml [ 'nc' ] = nc # override yaml value if anchors : # anchors \u5148\u9a8c\u6846\u7684\u914d\u7f6e LOGGER . info ( f 'Overriding model.yaml anchors with anchors= { anchors } ' ) self . yaml [ 'anchors' ] = round ( anchors ) # override yaml value # \u5f97\u5230\u6a21\u578b\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7684\u4fdd\u5b58\u7684\u7279\u5f81\u56fe\u5217\u8868\u3002 self . model , self . save = parse_model ( deepcopy ( self . yaml ), ch = [ ch ]) # model, savelist self . names = [ str ( i ) for i in range ( self . yaml [ 'nc' ])] # default names \u521d\u59cb\u5316\u7c7b\u540d\u5217\u8868\uff0c\u9ed8\u8ba4\u4e3a[0,1,2...] # self.inplace=True \u9ed8\u8ba4True \u8282\u7701\u5185\u5b58 self . inplace = self . yaml . get ( 'inplace' , True ) # Build strides, anchors \u786e\u5b9a\u6b65\u957f\u3001\u6b65\u957f\u5bf9\u5e94\u7684\u951a\u6846 m = self . model [ - 1 ] # Detect() if isinstance ( m , Detect ): # \u68c0\u9a8c\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42\u662fDetect\u6a21\u5757 s = 256 # 2x min stride m . inplace = self . inplace # \u8ba1\u7b97\u4e09\u4e2afeature map\u4e0b\u91c7\u6837\u7684\u500d\u7387 [8, 16, 32] m . stride = flow . tensor ([ s / x . shape [ - 2 ] for x in self . forward ( flow . zeros ( 1 , ch , s , s ))]) # forward # \u68c0\u67e5anchor\u987a\u5e8f\u4e0estride\u987a\u5e8f\u662f\u5426\u4e00\u81f4 anchor\u7684\u987a\u5e8f\u5e94\u8be5\u662f\u4ece\u5c0f\u5230\u5927\uff0c\u8fd9\u91cc\u6392\u4e00\u4e0b\u5e8f check_anchor_order ( m ) # must be in pixel-space (not grid-space) # \u5bf9\u5e94\u7684anchor\u8fdb\u884c\u7f29\u653e\u64cd\u4f5c\uff0c\u539f\u56e0\uff1a\u5f97\u5230anchor\u5728\u5b9e\u9645\u7684\u7279\u5f81\u56fe\u4e2d\u7684\u4f4d\u7f6e\uff0c\u56e0\u4e3a\u52a0\u8f7d\u7684\u539f\u59cbanchor\u5927\u5c0f\u662f\u76f8\u5bf9\u4e8e\u539f\u56fe\u7684\u50cf\u7d20\uff0c\u4f46\u662f\u7ecf\u8fc7\u5377\u79ef\u6c60\u5316\u4e4b\u540e\uff0c\u7279\u5f81\u56fe\u7684\u957f\u5bbd\u53d8\u5c0f\u4e86\u3002 m . anchors /= m . stride . view ( - 1 , 1 , 1 ) self . stride = m . stride self . _initialize_biases () # only run once \u521d\u59cb\u5316\u504f\u7f6e # Init weights, biases # \u8c03\u7528oneflow_utils.py\u4e0binitialize_weights\u521d\u59cb\u5316\u6a21\u578b\u6743\u91cd initialize_weights ( self ) self . info () # \u6253\u5370\u6a21\u578b\u4fe1\u606f LOGGER . info ( '' ) # \u7ba1\u7406\u524d\u5411\u4f20\u64ad\u51fd\u6570 def forward ( self , x , augment = False , profile = False , visualize = False ): if augment : # \u662f\u5426\u5728\u6d4b\u8bd5\u65f6\u4e5f\u4f7f\u7528\u6570\u636e\u589e\u5f3a Test Time Augmentation(TTA) return self . _forward_augment ( x ) # augmented inference, None return self . _forward_once ( x , profile , visualize ) # single-scale inference, train # \u5e26\u6570\u636e\u589e\u5f3a\u7684\u524d\u5411\u4f20\u64ad def _forward_augment ( self , x ): img_size = x . shape [ - 2 :] # height, width s = [ 1 , 0.83 , 0.67 ] # scales f = [ None , 3 , None ] # flips (2-ud, 3-lr) y = [] # outputs for si , fi in zip ( s , f ): xi = scale_img ( x . flip ( fi ) if fi else x , si , gs = int ( self . stride . max ())) yi = self . _forward_once ( xi )[ 0 ] # forward # cv2.imwrite(f'img_{si}.jpg', 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1]) # save yi = self . _descale_pred ( yi , fi , si , img_size ) y . append ( yi ) y = self . _clip_augmented ( y ) # clip augmented tails return flow . cat ( y , 1 ), None # augmented inference, train # \u524d\u5411\u4f20\u64ad\u5177\u4f53\u5b9e\u73b0 def _forward_once ( self , x , profile = False , visualize = False ): \"\"\" @params x: \u8f93\u5165\u56fe\u50cf @params profile: True \u53ef\u4ee5\u505a\u4e00\u4e9b\u6027\u80fd\u8bc4\u4f30 @params feature_vis: True \u53ef\u4ee5\u505a\u4e00\u4e9b\u7279\u5f81\u53ef\u89c6\u5316 \"\"\" # y: \u5b58\u653e\u7740self.save=True\u7684\u6bcf\u4e00\u5c42\u7684\u8f93\u51fa\uff0c\u56e0\u4e3a\u540e\u9762\u7684\u7279\u5f81\u878d\u5408\u64cd\u4f5c\u8981\u7528\u5230\u8fd9\u4e9b\u7279\u5f81\u56fe y , dt = [], [] # outputs # \u524d\u5411\u63a8\u7406\u6bcf\u4e00\u5c42\u7ed3\u6784 m.i=index m.f=from m.type=\u7c7b\u540d m.np=number of params for m in self . model : # if not from previous layer m.f=\u5f53\u524d\u5c42\u7684\u8f93\u5165\u6765\u81ea\u54ea\u4e00\u5c42\u7684\u8f93\u51fa s\u7684m.f\u90fd\u662f-1 if m . f != - 1 : # if not from previous layer x = y [ m . f ] if isinstance ( m . f , int ) else [ x if j == - 1 else y [ j ] for j in m . f ] # from earlier layers if profile : self . _profile_one_layer ( m , x , dt ) x = m ( x ) # run y . append ( x if m . i in self . save else None ) # save output if visualize : feature_visualization ( x , m . type , m . i , save_dir = visualize ) return x # \u5c06\u63a8\u7406\u7ed3\u679c\u6062\u590d\u5230\u539f\u56fe\u56fe\u7247\u5c3a\u5bf8(\u9006\u64cd\u4f5c) def _descale_pred ( self , p , flips , scale , img_size ): # de-scale predictions following augmented inference (inverse operation) \"\"\"\u7528\u5728\u4e0a\u9762\u7684__init__\u51fd\u6570\u4e0a \u5c06\u63a8\u7406\u7ed3\u679c\u6062\u590d\u5230\u539f\u56fe\u56fe\u7247\u5c3a\u5bf8 Test Time Augmentation(TTA)\u4e2d\u7528\u5230 de-scale predictions following augmented inference (inverse operation) @params p: \u63a8\u7406\u7ed3\u679c @params flips: @params scale: @params img_size: \"\"\" if self . inplace : p [ ... , : 4 ] /= scale # de-scale if flips == 2 : p [ ... , 1 ] = img_size [ 0 ] - p [ ... , 1 ] # de-flip ud elif flips == 3 : p [ ... , 0 ] = img_size [ 1 ] - p [ ... , 0 ] # de-flip lr else : x , y , wh = p [ ... , 0 : 1 ] / scale , p [ ... , 1 : 2 ] / scale , p [ ... , 2 : 4 ] / scale # de-scale if flips == 2 : y = img_size [ 0 ] - y # de-flip ud elif flips == 3 : x = img_size [ 1 ] - x # de-flip lr p = flow . cat (( x , y , wh , p [ ... , 4 :]), - 1 ) return p # \u8fd9\u4e2a\u662fTTA\u7684\u65f6\u5019\u5bf9\u539f\u56fe\u7247\u8fdb\u884c\u88c1\u526a\uff0c\u4e5f\u662f\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u5f0f\uff0c\u7528\u5728TTA\u6d4b\u8bd5\u7684\u65f6\u5019\u3002 def _clip_augmented ( self , y ): # Clip YOLOv5 augmented inference tails nl = self . model [ - 1 ] . nl # number of detection layers (P3-P5) g = sum ( 4 ** x for x in range ( nl )) # grid points e = 1 # exclude layer count i = ( y [ 0 ] . shape [ 1 ] // g ) * sum ( 4 ** x for x in range ( e )) # indices y [ 0 ] = y [ 0 ][:, : - i ] # large i = ( y [ - 1 ] . shape [ 1 ] // g ) * sum ( 4 ** ( nl - 1 - x ) for x in range ( e )) # indices y [ - 1 ] = y [ - 1 ][:, i :] # small return y # \u6253\u5370\u65e5\u5fd7\u4fe1\u606f \u524d\u5411\u63a8\u7406\u65f6\u95f4 def _profile_one_layer ( self , m , x , dt ): c = isinstance ( m , Detect ) # is final layer, copy input as inplace fix o = thop . profile ( m , inputs = ( x . copy () if c else x ,), verbose = False )[ 0 ] / 1E9 * 2 if thop else 0 # FLOPs t = time_sync () for _ in range ( 10 ): m ( x . copy () if c else x ) dt . append (( time_sync () - t ) * 100 ) if m == self . model [ 0 ]: LOGGER . info ( f \" { 'time (ms)' : >10s } { 'GFLOPs' : >10s } { 'params' : >10s } module\" ) LOGGER . info ( f ' { dt [ - 1 ] : 10.2f } { o : 10.2f } { m . np : 10.0f } { m . type } ' ) if c : LOGGER . info ( f \" { sum ( dt ) : 10.2f } { '-' : >10s } { '-' : >10s } Total\" ) # initialize biases into Detect(), cf is class frequency def _initialize_biases ( self , cf = None ): # https://arxiv.org/abs/1708.02002 section 3.3 # cf = flow.bincount(flow.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1. m = self . model [ - 1 ] # Detect() module for mi , s in zip ( m . m , m . stride ): # from b = mi . bias . view ( m . na , - 1 ) . detach () # conv.bias(255) to (3,85) b [:, 4 ] += math . log ( 8 / ( 640 / s ) ** 2 ) # obj (8 objects per 640 image) b [:, 5 :] += math . log ( 0.6 / ( m . nc - 0.999999 )) if cf is None else flow . log ( cf / cf . sum ()) # cls mi . bias = flow . nn . Parameter ( b . view ( - 1 ), requires_grad = True ) # \u6253\u5370\u6a21\u578b\u4e2d\u6700\u540eDetect\u5c42\u7684\u504f\u7f6ebiases\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42biases\u4fe1\u606f) def _print_biases ( self ): \"\"\" \u6253\u5370\u6a21\u578b\u4e2d\u6700\u540eDetect\u6a21\u5757\u91cc\u9762\u7684\u5377\u79ef\u5c42\u7684\u504f\u7f6ebiases\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42biases\u4fe1\u606f) \"\"\" m = self . model [ - 1 ] # Detect() module for mi in m . m : # from b = mi . bias . detach () . view ( m . na , - 1 ) . T # conv.bias(255) to (3,85) LOGGER . info ( ( ' %6g Conv2d.bias:' + ' %10.3g ' * 6 ) % ( mi . weight . shape [ 1 ], * b [: 5 ] . mean ( 1 ) . tolist (), b [ 5 :] . mean ())) def _print_weights ( self ): \"\"\" \u6253\u5370\u6a21\u578b\u4e2dBottleneck\u5c42\u7684\u6743\u91cd\u53c2\u6570weights\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42weights\u4fe1\u606f) \"\"\" for m in self . model . modules (): if type ( m ) is Bottleneck : LOGGER . info ( ' %10.3g ' % ( m . w . detach () . sigmoid () * 2 )) # shortcut weights # fuse()\u662f\u7528\u6765\u8fdb\u884cconv\u548cbn\u5c42\u5408\u5e76\uff0c\u4e3a\u4e86\u63d0\u901f\u6a21\u578b\u63a8\u7406\u901f\u5ea6\u3002 def fuse ( self ): # fuse model Conv2d() + BatchNorm2d() layers \"\"\"\u7528\u5728detect.py\u3001val.py fuse model Conv2d() + BatchNorm2d() layers \u8c03\u7528oneflow_utils.py\u4e2d\u7684fuse_conv_and_bn\u51fd\u6570\u548ccommon.py\u4e2dConv\u6a21\u5757\u7684fuseforward\u51fd\u6570 \"\"\" LOGGER . info ( 'Fusing layers... ' ) for m in self . model . modules (): # \u5982\u679c\u5f53\u524d\u5c42\u662f\u5377\u79ef\u5c42Conv\u4e14\u6709bn\u7ed3\u6784, \u90a3\u4e48\u5c31\u8c03\u7528fuse_conv_and_bn\u51fd\u6570\u8bb2conv\u548cbn\u8fdb\u884c\u878d\u5408, \u52a0\u901f\u63a8\u7406 if isinstance ( m , ( Conv , DWConv )) and hasattr ( m , 'bn' ): m . conv = fuse_conv_and_bn ( m . conv , m . bn ) # update conv delattr ( m , 'bn' ) # remove batchnorm \u79fb\u9664bn remove batchnorm m . forward = m . forward_fuse # update forward \u66f4\u65b0\u524d\u5411\u4f20\u64ad update forward (\u53cd\u5411\u4f20\u64ad\u4e0d\u7528\u7ba1, \u56e0\u4e3a\u8fd9\u79cd\u63a8\u7406\u53ea\u7528\u5728\u63a8\u7406\u9636\u6bb5) self . info () # \u6253\u5370conv+bn\u878d\u5408\u540e\u7684\u6a21\u578b\u4fe1\u606f return self # \u6253\u5370\u6a21\u578b\u7ed3\u6784\u4fe1\u606f \u5728\u5f53\u524d\u7c7b__init__\u51fd\u6570\u7ed3\u5c3e\u5904\u6709\u8c03\u7528 def info ( self , verbose = False , img_size = 640 ): # print model information model_info ( self , verbose , img_size ) def _apply ( self , fn ): # Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers self = super () . _apply ( fn ) m = self . model [ - 1 ] # Detect() if isinstance ( m , Detect ): m . stride = fn ( m . stride ) m . grid = list ( map ( fn , m . grid )) if isinstance ( m . anchor_grid , list ): m . anchor_grid = list ( map ( fn , m . anchor_grid )) return self Detect\u7c7b\u89e3\u8bfb class Detect ( nn . Module ): \"\"\" Detect\u6a21\u5757\u662f\u7528\u6765\u6784\u5efaDetect\u5c42\u7684\uff0c\u5c06\u8f93\u5165feature map \u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u64cd\u4f5c\u548c\u516c\u5f0f\u8ba1\u7b97\u5230\u6211\u4eec\u60f3\u8981\u7684shape, \u4e3a\u540e\u9762\u7684\u8ba1\u7b97\u635f\u5931\u6216\u8005NMS\u540e\u5904\u7406\u4f5c\u51c6\u5907 \"\"\" stride = None # strides computed during build onnx_dynamic = False # ONNX export parameter export = False # export mode def __init__ ( self , nc = 80 , anchors = (), ch = (), inplace = True ): # detection layer super () . __init__ () # nc:\u5206\u7c7b\u6570\u91cf self . nc = nc # number of classes COCO : 80 # no:\u6bcf\u4e2aanchor\u7684\u8f93\u51fa\u6570 COCO: 80 + 5 = 85 self . no = nc + 5 # number of outputs per anchor Detect\u7684\u4e2a\u6570 3 # nl:\u9884\u6d4b\u5c42\u6570\uff0c\u6b64\u6b21\u4e3a3 self . nl = len ( anchors ) # number of detection layers # na:anchors\u7684\u6570\u91cf\uff0c\u6b64\u6b21\u4e3a3 self . na = len ( anchors [ 0 ]) // 2 # number of anchors # grid:\u683c\u5b50\u5750\u6807\u7cfb\uff0c\u5de6\u4e0a\u89d2\u4e3a(1,1),\u53f3\u4e0b\u89d2\u4e3a(input.w/stride,input.h/stride) self . grid = [ flow . zeros ( 1 )] * self . nl # init grid self . anchor_grid = [ flow . zeros ( 1 )] * self . nl # init anchor grid # \u5199\u5165\u7f13\u5b58\u4e2d\uff0c\u5e76\u547d\u540d\u4e3aanchors # register_buffer # \u6a21\u578b\u4e2d\u9700\u8981\u4fdd\u5b58\u7684\u53c2\u6570\u4e00\u822c\u6709\u4e24\u79cd\uff1a\u4e00\u79cd\u662f\u53cd\u5411\u4f20\u64ad\u9700\u8981\u88aboptimizer\u66f4\u65b0\u7684\uff0c\u79f0\u4e3aparameter; \u53e6\u4e00\u79cd\u4e0d\u8981\u88ab\u66f4\u65b0\u79f0\u4e3abuffer # buffer\u7684\u53c2\u6570\u66f4\u65b0\u662f\u5728forward\u4e2d\uff0c\u800coptim.step\u53ea\u80fd\u66f4\u65b0nn.parameter\u7c7b\u578b\u7684\u53c2\u6570 self . register_buffer ( 'anchors' , flow . tensor ( anchors ) . float () . view ( self . nl , - 1 , 2 )) # shape(nl,na,2) # \u5c06\u8f93\u51fa\u901a\u8fc7\u5377\u79ef\u5230 self.no * self.na \u7684\u901a\u9053\uff0c\u8fbe\u5230\u5168\u8fde\u63a5\u7684\u4f5c\u7528 self . m = nn . ModuleList ( nn . Conv2d ( x , self . no * self . na , 1 ) for x in ch ) # output conv self . inplace = inplace # use inplace ops (e.g. slice assignment) def forward ( self , x ): z = [] # inference output for i in range ( self . nl ): x [ i ] = self . m [ i ]( x [ i ]) # conv bs , _ , ny , nx = x [ i ] . shape # x(bs,255,20,20) to x(bs,3,20,20,85) x [ i ] = x [ i ] . view ( bs , self . na , self . no , ny , nx ) . permute ( 0 , 1 , 3 , 4 , 2 ) . contiguous () if not self . training : # inference # \u6784\u9020\u7f51\u683c # \u56e0\u4e3a\u63a8\u7406\u8fd4\u56de\u7684\u4e0d\u662f\u5f52\u4e00\u5316\u540e\u7684\u7f51\u683c\u504f\u79fb\u91cf \u9700\u8981\u518d\u52a0\u4e0a\u7f51\u683c\u7684\u4f4d\u7f6e \u5f97\u5230\u6700\u7ec8\u7684\u63a8\u7406\u5750\u6807 \u518d\u9001\u5165nms # \u6240\u4ee5\u8fd9\u91cc\u6784\u5efa\u7f51\u683c\u5c31\u662f\u4e3a\u4e86\u8bb0\u5f55\u6bcf\u4e2agrid\u7684\u7f51\u683c\u5750\u6807 \u65b9\u9762\u540e\u9762\u4f7f\u7528 if self . onnx_dynamic or self . grid [ i ] . shape [ 2 : 4 ] != x [ i ] . shape [ 2 : 4 ]: # \u5411\u524d\u4f20\u64ad\u65f6\u9700\u8981\u5c06\u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u5230grid\u7edd\u5bf9\u5750\u6807\u7cfb\u4e2d self . grid [ i ], self . anchor_grid [ i ] = self . _make_grid ( nx , ny , i ) y = x [ i ] . sigmoid () if self . inplace : # \u9ed8\u8ba4\u6267\u884c \u4e0d\u4f7f\u7528AWS Inferentia # \u8fd9\u91cc\u7684\u516c\u5f0f\u548cyolov3\u3001v4\u4e2d\u4f7f\u7528\u7684\u4e0d\u4e00\u6837 \u662fyolov5\u4f5c\u8005\u81ea\u5df1\u7528\u7684 \u6548\u679c\u66f4\u597d y [ ... , 0 : 2 ] = ( y [ ... , 0 : 2 ] * 2 + self . grid [ i ]) * self . stride [ i ] # xy y [ ... , 2 : 4 ] = ( y [ ... , 2 : 4 ] * 2 ) ** 2 * self . anchor_grid [ i ] # wh else : # for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953 xy , wh , conf = y . split (( 2 , 2 , self . nc + 1 ), 4 ) # y.tensor_split((2, 4, 5), 4) xy = ( xy * 2 + self . grid [ i ]) * self . stride [ i ] # xy wh = ( wh * 2 ) ** 2 * self . anchor_grid [ i ] # wh y = flow . cat (( xy , wh , conf ), 4 ) # z [oneflow.Size([1, 19200, 85]) oneflow.Size([1, 4800, 85]) oneflow.Size([1, 1200, 85])] z . append ( y . view ( bs , - 1 , self . no )) return x if self . training else ( flow . cat ( z , 1 ),) if self . export else ( flow . cat ( z , 1 ), x ) # \u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u5230grid\u7edd\u5bf9\u5750\u6807\u7cfb def _make_grid ( self , nx = 20 , ny = 20 , i = 0 ): d = self . anchors [ i ] . device t = self . anchors [ i ] . dtype shape = 1 , self . na , ny , nx , 2 # grid shape y , x = flow . arange ( ny , device = d , dtype = t ), flow . arange ( nx , device = d , dtype = t ) yv , xv = flow . meshgrid ( y , x , indexing = \"ij\" ) grid = flow . stack (( xv , yv ), 2 ) . expand ( shape ) - 0.5 # add grid offset, i.e. y = 2.0 * x - 0.5 anchor_grid = ( self . anchors [ i ] * self . stride [ i ]) . view (( 1 , self . na , 1 , 1 , 2 )) . expand ( shape ) return grid , anchor_grid \u9644\u4ef6 \u88682.1 yolov5s.yaml \u89e3\u6790\u8868 \u5c42\u6570 form moudule arguments input output 0 -1 Conv [3, 32, 6, 2, 2] [3, 640, 640] [32, 320, 320] 1 -1 Conv [32, 64, 3, 2] [32, 320, 320] [64, 160, 160] 2 -1 C3 [64, 64, 1] [64, 160, 160] [64, 160, 160] 3 -1 Conv [64, 128, 3, 2] [64, 160, 160] [128, 80, 80] 4 -1 C3 [128, 128, 2] [128, 80, 80] [128, 80, 80] 5 -1 Conv [128, 256, 3, 2] [128, 80, 80] [256, 40, 40] 6 -1 C3 [256, 256, 3] [256, 40, 40] [256, 40, 40] 7 -1 Conv [256, 512, 3, 2] [256, 40, 40] [512, 20, 20] 8 -1 C3 [512, 512, 1] [512, 20, 20] [512, 20, 20] 9 -1 SPPF [512, 512, 5] [512, 20, 20] [512, 20, 20] 10 -1 Conv [512, 256, 1, 1] [512, 20, 20] [256, 20, 20] 11 -1 Upsample [None, 2, 'nearest'] [256, 20, 20] [256, 40, 40] 12 [-1, 6] Concat [1] [1, 256, 40, 40],[1, 256, 40, 40] [512, 40, 40] 13 -1 C3 [512, 256, 1, False] [512, 40, 40] [256, 40, 40] 14 -1 Conv [256, 128, 1, 1] [256, 40, 40] [128, 40, 40] 15 -1 Upsample [None, 2, 'nearest'] [128, 40, 40] [128, 80, 80] 16 [-1, 4] Concat [1] [1, 128, 80, 80],[1, 128, 80, 80] [256, 80, 80] 17 -1 C3 [256, 128, 1, False] [256, 80, 80] [128, 80, 80] 18 -1 Conv [128, 128, 3, 2] [128, 80, 80] [128, 40, 40] 19 [-1, 14] Concat [1] [1, 128, 40, 40],[1, 128, 40, 40] [256, 40, 40] 20 -1 C3 [256, 256, 1, False] [256, 40, 40] [256, 40, 40] 21 -1 Conv [256, 256, 3, 2] [256, 40, 40] [256, 20, 20] 22 [-1, 10] Concat [1] [1, 256, 20, 20],[1, 256, 20, 20] [512, 20, 20] 23 -1 C3 [512, 512, 1, False] [512, 20, 20] [512, 20, 20] 24 [17, 20, 23] Detect [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]] [1, 128, 80, 80],[1, 256, 40, 40],[1, 512, 20, 20] [1, 3, 80, 80, 85],[1, 3, 40, 40, 85],[1, 3, 20, 20, 85] \u53c2\u8003\u6587\u7ae0: https://zhuanlan.zhihu.com/p/436891962?ivk_sa=1025922q https://zhuanlan.zhihu.com/p/110204563 https://www.it610.com/article/1550621248474648576.htm","title":"1.1. YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"\u524d\u8a00"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#yolov5","text":"","title":"YOLOv5 \u7f51\u7edc\u7ed3\u6784\u89e3\u6790"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_2","text":"YOLOv5\u9488\u5bf9\u4e0d\u540c\u5927\u5c0f\uff08n, s, m, l, x\uff09\u7684\u7f51\u7edc\u6574\u4f53\u67b6\u6784\u90fd\u662f\u4e00\u6837\u7684\uff0c\u53ea\u4e0d\u8fc7\u4f1a\u5728\u6bcf\u4e2a\u5b50\u6a21\u5757\u4e2d\u91c7\u7528\u4e0d\u540c\u7684\u6df1\u5ea6\u548c\u5bbd\u5ea6\uff0c \u5206\u522b\u5e94\u5bf9yaml\u6587\u4ef6\u4e2d\u7684depth_multiple\u548cwidth_multiple\u53c2\u6570\u3002 \u8fd8\u9700\u8981\u6ce8\u610f\u4e00\u70b9\uff0c\u5b98\u65b9\u9664\u4e86n, s, m, l, x\u7248\u672c\u5916\u8fd8\u6709n6, s6, m6, l6, x6\uff0c\u533a\u522b\u5728\u4e8e\u540e\u8005\u662f\u9488\u5bf9\u66f4\u5927\u5206\u8fa8\u7387\u7684\u56fe\u7247\u6bd4\u59821280x1280, \u5f53\u7136\u7ed3\u6784\u4e0a\u4e5f\u6709\u4e9b\u5dee\u5f02\uff0c\u524d\u8005\u53ea\u4f1a\u4e0b\u91c7\u6837\u523032\u500d\u4e14\u91c7\u75283\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42 , \u800c\u540e\u8005\u4f1a\u4e0b\u91c7\u683764\u500d\uff0c\u91c7\u75284\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u3002 \u672c\u7ae0\u5c06\u4ee5 yolov5s\u4e3a\u4f8b \uff0c\u4ece\u914d\u7f6e\u6587\u4ef6 models/ yolov5s.yaml \u5230 models/ yolo.py \u6e90\u7801\u8fdb\u884c\u89e3\u8bfb\u3002","title":"\u5f15\u8a00"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#yolov5syaml","text":"nc : 80 # number of classes \u6570\u636e\u96c6\u4e2d\u7684\u7c7b\u522b\u6570 depth_multiple : 0.33 # model depth multiple \u6a21\u578b\u5c42\u6570\u56e0\u5b50(\u7528\u6765\u8c03\u6574\u7f51\u7edc\u7684\u6df1\u5ea6) width_multiple : 0.50 # layer channel multiple \u6a21\u578b\u901a\u9053\u6570\u56e0\u5b50(\u7528\u6765\u8c03\u6574\u7f51\u7edc\u7684\u5bbd\u5ea6) # \u5982\u4f55\u7406\u89e3\u8fd9\u4e2adepth_multiple\u548cwidth_multiple\u5462? # \u5b83\u51b3\u5b9a\u7684\u662f\u6574\u4e2a\u6a21\u578b\u4e2d\u7684\u6df1\u5ea6\uff08\u5c42\u6570\uff09\u548c\u5bbd\u5ea6\uff08\u901a\u9053\u6570\uff09,\u5177\u4f53\u600e\u4e48\u8c03\u6574\u7684\u7ed3\u5408\u540e\u9762\u7684backbone\u4ee3\u7801\u89e3\u91ca\u3002 anchors : # \u8868\u793a\u4f5c\u7528\u4e8e\u5f53\u524d\u7279\u5f81\u56fe\u7684Anchor\u5927\u5c0f\u4e3a xxx # 9\u4e2aanchor\uff0c\u5176\u4e2dP\u8868\u793a\u7279\u5f81\u56fe\u7684\u5c42\u7ea7\uff0cP3/8\u8be5\u5c42\u7279\u5f81\u56fe\u7f29\u653e\u4e3a1/8,\u662f\u7b2c3\u5c42\u7279\u5f81 - [ 10 , 13 , 16 , 30 , 33 , 23 ] # P3/8\uff0c \u8868\u793a[10,13],[16,30], [33,23]3\u4e2aanchor - [ 30 , 61 , 62 , 45 , 59 , 119 ] # P4/16 - [ 116 , 90 , 156 , 198 , 373 , 326 ] # P5/32 # YOLOv5s v6.0 backbone backbone : # [from, number, module, args] [[ -1 , 1 , Conv , [ 64 , 6 , 2 , 2 ]], # 0-P1/2 [ -1 , 1 , Conv , [ 128 , 3 , 2 ]], # 1-P2/4 [ -1 , 3 , C3 , [ 128 ]], [ -1 , 1 , Conv , [ 256 , 3 , 2 ]], # 3-P3/8 [ -1 , 6 , C3 , [ 256 ]], [ -1 , 1 , Conv , [ 512 , 3 , 2 ]], # 5-P4/16 [ -1 , 9 , C3 , [ 512 ]], [ -1 , 1 , Conv , [ 1024 , 3 , 2 ]], # 7-P5/32 [ -1 , 3 , C3 , [ 1024 ]], [ -1 , 1 , SPPF , [ 1024 , 5 ]], # 9 ] # YOLOv5s v6.0 head head : [[ -1 , 1 , Conv , [ 512 , 1 , 1 ]], [ -1 , 1 , nn.Upsample , [ None , 2 , 'nearest' ]], [[ -1 , 6 ], 1 , Concat , [ 1 ]], # cat backbone P4 [ -1 , 3 , C3 , [ 512 , False ]], # 13 [ -1 , 1 , Conv , [ 256 , 1 , 1 ]], [ -1 , 1 , nn.Upsample , [ None , 2 , 'nearest' ]], [[ -1 , 4 ], 1 , Concat , [ 1 ]], # cat backbone P3 [ -1 , 3 , C3 , [ 256 , False ]], # 17 (P3/8-small) [ -1 , 1 , Conv , [ 256 , 3 , 2 ]], [[ -1 , 14 ], 1 , Concat , [ 1 ]], # cat head P4 [ -1 , 3 , C3 , [ 512 , False ]], # 20 (P4/16-medium) [ -1 , 1 , Conv , [ 512 , 3 , 2 ]], [[ -1 , 10 ], 1 , Concat , [ 1 ]], # cat head P5 [ -1 , 3 , C3 , [ 1024 , False ]], # 23 (P5/32-large) [[ 17 , 20 , 23 ], 1 , Detect , [ nc , anchors ]], # Detect(P3, P4, P5) ]","title":"yolov5s.yaml\u6587\u4ef6\u5185\u5bb9:"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#anchors","text":"yolov5 \u521d\u59cb\u5316\u4e86 9 \u4e2a anchors\uff0c\u5206\u522b\u5728\u4e09\u4e2a\u7279\u5f81\u56fe \uff08feature map\uff09\u4e2d\u4f7f\u7528\uff0c\u6bcf\u4e2a feature map \u7684\u6bcf\u4e2a grid cell \u90fd\u6709\u4e09\u4e2a anchor \u8fdb\u884c\u9884\u6d4b\u3002 \u5206\u914d\u89c4\u5219\uff1a \u5c3a\u5ea6\u8d8a\u5927\u7684 feature map \u8d8a\u9760\u524d\uff0c\u76f8\u5bf9\u539f\u56fe\u7684\u4e0b\u91c7\u6837\u7387\u8d8a\u5c0f\uff0c\u611f\u53d7\u91ce\u8d8a\u5c0f\uff0c \u6240\u4ee5\u76f8\u5bf9\u53ef\u4ee5\u9884\u6d4b\u4e00\u4e9b\u5c3a\u5ea6\u6bd4\u8f83\u5c0f\u7684\u7269\u4f53(\u5c0f\u76ee\u6807)\uff0c\u5206\u914d\u5230\u7684 anchors \u8d8a\u5c0f\u3002 \u5c3a\u5ea6\u8d8a\u5c0f\u7684 feature map \u8d8a\u9760\u540e\uff0c\u76f8\u5bf9\u539f\u56fe\u7684\u4e0b\u91c7\u6837\u7387\u8d8a\u5927\uff0c\u611f\u53d7\u91ce\u8d8a\u5927\uff0c \u6240\u4ee5\u53ef\u4ee5\u9884\u6d4b\u4e00\u4e9b\u5c3a\u5ea6\u6bd4\u8f83\u5927\u7684\u7269\u4f53(\u5927\u76ee\u6807)\uff0c\u6240\u4ee5\u5206\u914d\u5230\u7684 anchors \u8d8a\u5927\u3002 \u5373\u5728\u5c0f\u7279\u5f81\u56fe\uff08feature map\uff09\u4e0a\u68c0\u6d4b\u5927\u76ee\u6807\uff0c\u4e2d\u7b49\u5927\u5c0f\u7684\u7279\u5f81\u56fe\u4e0a\u68c0\u6d4b\u4e2d\u7b49\u76ee\u6807\uff0c \u5728\u5927\u7279\u5f81\u56fe\u4e0a\u68c0\u6d4b\u5c0f\u76ee\u6807\u3002","title":"anchors \u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#backbone-head","text":"","title":"backbone &amp; head\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#from-number-module-args","text":"\u56db\u4e2a\u53c2\u6570\u7684\u610f\u4e49\u5206\u522b\u662f\uff1a 1. \u7b2c\u4e00\u4e2a\u53c2\u6570 from \uff1a\u4ece\u54ea\u4e00\u5c42\u83b7\u5f97\u8f93\u5165\uff0c-1\u8868\u793a\u4ece\u4e0a\u4e00\u5c42\u83b7\u5f97\uff0c[-1, 6]\u8868\u793a\u4ece\u4e0a\u5c42\u548c\u7b2c6\u5c42\u4e24\u5c42\u83b7\u5f97\u3002 2. \u7b2c\u4e8c\u4e2a\u53c2\u6570 number\uff1a\u8868\u793a\u6709\u51e0\u4e2a\u76f8\u540c\u7684\u6a21\u5757\uff0c\u5982\u679c\u4e3a9\u5219\u8868\u793a\u67099\u4e2a\u76f8\u540c\u7684\u6a21\u5757\u3002 3. \u7b2c\u4e09\u4e2a\u53c2\u6570 module\uff1a\u6a21\u5757\u7684\u540d\u79f0\uff0c\u8fd9\u4e9b\u6a21\u5757\u5199\u5728common.py\u4e2d\u3002 4. \u7b2c\u56db\u4e2a\u53c2\u6570 args\uff1a\u7c7b\u7684\u521d\u59cb\u5316\u53c2\u6570\uff0c\u7528\u4e8e\u89e3\u6790\u4f5c\u4e3a moudle \u7684\u4f20\u5165\u53c2\u6570\u3002 \u4e0b\u9762\u4ee5\u7b2c\u4e00\u4e2a\u6a21\u5757Conv \u4e3a\u4f8b\u4ecb\u7ecd\u4e0bcommon.py\u4e2d\u7684\u6a21\u5757 Conv \u6a21\u5757\u5b9a\u4e49\u5982\u4e0b: class Conv ( nn . Module ): # Standard convolution def __init__ ( self , c1 , c2 , k = 1 , s = 1 , p = None , g = 1 , act = True ): # ch_in, ch_out, kernel, stride, padding, groups \"\"\" @Pargm c1: \u8f93\u5165\u901a\u9053\u6570 @Pargm c2: \u8f93\u51fa\u901a\u9053\u6570 @Pargm k : \u5377\u79ef\u6838\u5927\u5c0f(kernel_size) @Pargm s : \u5377\u79ef\u6b65\u957f (stride) @Pargm p : \u7279\u5f81\u56fe\u586b\u5145\u5bbd\u5ea6 (padding) @Pargm g : \u63a7\u5236\u5206\u7ec4\uff0c\u5fc5\u987b\u6574\u9664\u8f93\u5165\u7684\u901a\u9053\u6570(\u4fdd\u8bc1\u8f93\u5165\u7684\u901a\u9053\u80fd\u88ab\u6b63\u786e\u5206\u7ec4) \"\"\" super () . __init__ () # https://oneflow.readthedocs.io/en/master/generated/oneflow.nn.Conv2d.html?highlight=Conv self . conv = nn . Conv2d ( c1 , c2 , k , s , autopad ( k , p ), groups = g , bias = False ) self . bn = nn . BatchNorm2d ( c2 ) self . act = nn . SiLU () if act is True else ( act if isinstance ( act , nn . Module ) else nn . Identity ()) def forward ( self , x ): return self . act ( self . bn ( self . conv ( x ))) def forward_fuse ( self , x ): return self . act ( self . conv ( x )) \u6bd4\u5982\u4e0a\u9762\u628awidth_multiple\u8bbe\u7f6e\u4e3a\u4e860.5\uff0c\u90a3\u4e48\u7b2c\u4e00\u4e2a [64, 6, 2, 2] \u5c31\u4f1a\u88ab\u89e3\u6790\u4e3a [3,64*0.5=32,6,2,2]\uff0c\u5176\u4e2d\u7b2c\u4e00\u4e2a 3 \u4e3a\u8f93\u5165channel(\u56e0\u4e3a\u8f93\u5165)\uff0c32 \u4e3a\u8f93\u51fachannel\u3002","title":"[from, number, module, args] \u53c2\u6570"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_3","text":"\u5728 yolo.py \u7684 286 \u884c\u6709\u5bf9yaml \u6587\u4ef6\u7684nc,depth_multiple\u7b49\u53c2\u6570\u8bfb\u53d6\uff0c\u5177\u4f53\u4ee3\u7801\u5982\u4e0b: anchors , nc , gd , gw = d [ 'anchors' ], d [ 'nc' ], d [ 'depth_multiple' ], d [ 'width_multiple' ], d . get ( \"activation\" ) \"width_multiple\"\u53c2\u6570\u7684\u4f5c\u7528\u524d\u9762\u4ecb\u7ecdargs\u53c2\u6570\u4e2d\u5df2\u7ecf\u4ecb\u7ecd\u8fc7\u4e86\uff0c\u90a3\u4e48\"depth_multiple\"\u53c8\u662f\u4ec0\u4e48\u4f5c\u7528\u5462\uff1f \u5728 yolo.py \u7684 300 \u884c\u6709\u5bf9\u53c2\u6570\u7684\u5177\u4f53\u5b9a\u4e49\uff1a n = n_ = max ( round ( n * gd ), 1 ) if n > 1 else n # depth gain \u6682\u4e14\u5c06\u8fd9\u6bb5\u4ee3\u7801\u5f53\u4f5c\u516c\u5f0f(1) \u5176\u4e2d gd \u5c31\u662fdepth_multiple\u7684\u503c\uff0cn\u7684\u503c\u5c31\u662fbackbone\u4e2d\u5217\u8868\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\uff1a \u6839\u636e\u516c\u793a(1) \u5f88\u5bb9\u6613\u770b\u51fa gd \u5f71\u54cd n \u7684\u5927\u5c0f\uff0c\u4ece\u800c\u5f71\u54cd\u7f51\u7edc\u7684\u7ed3\u6784\u5927\u5c0f\u3002 \u540e\u9762\u5404\u5c42\u4e4b\u95f4\u7684\u6a21\u5757\u6570\u91cf\u3001\u5377\u79ef\u6838\u5927\u5c0f\u548c\u6570\u91cf\u7b49\u4e5f\u90fd\u4ea7\u751f\u4e86\u53d8\u5316\uff0cYOLOv5l \u4e0e YOLOv5s \u76f8\u6bd4\u8f83\u8d77\u6765\u8bad\u7ec3\u53c2\u6570\u7684\u5927\u5c0f\u6210\u500d\u6570\u589e\u957f\uff0c \u5176\u6a21\u578b\u7684\u6df1\u5ea6\u548c\u5bbd\u5ea6\u4e5f\u4f1a\u5927\u5f88\u591a\uff0c\u8fd9\u5c31\u4f7f\u5f97 YOLOv5l \u7684 \u7cbe\u5ea6\u503c\u8981\u6bd4 YOLOv5s \u597d\u5f88\u591a\uff0c\u56e0\u6b64\u5728\u6700\u7ec8\u63a8\u7406\u65f6\u7684\u68c0\u6d4b\u7cbe\u5ea6\u9ad8\uff0c\u4f46\u662f\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u66f4\u6162\u3002 \u6240\u4ee5 YOLOv5 \u63d0\u4f9b\u4e86\u4e0d\u540c\u7684\u9009\u62e9\uff0c\u5982\u679c\u60f3\u8981\u8ffd\u6c42\u63a8\u7406\u901f\u5ea6\u53ef\u9009\u7528\u8f83\u5c0f\u4e00\u4e9b\u7684\u6a21\u578b\u5982 YOLOv5s\u3001YOLOv5m\uff0c\u5982\u679c\u60f3\u8981\u8ffd\u6c42\u7cbe\u5ea6\u66f4\u9ad8\u5bf9\u63a8\u7406\u901f\u5ea6\u8981\u6c42\u4e0d\u9ad8\u7684\u53ef\u4ee5\u9009\u62e9\u5176\u4ed6\u4e24\u4e2a\u7a0d\u5927\u7684\u6a21\u578b\u3002 \u5982\u4e0b\u9762\u8fd9\u5f20\u56fe\uff1a \u56fe2.1 :yolov5 \u6a21\u578b\u6bd4\u8f83\u56fe \u6765\u6e90:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data","title":"\u5173\u4e8e\u8c03\u6574\u7f51\u7edc\u5927\u5c0f\u7684\u8be6\u89e3\u8bf4\u660e"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#conv","text":"","title":"Conv\u6a21\u5757\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_4","text":"\u4e0b\u9762\u662f\u6839\u636e yolov5s.yaml \u7ed8\u5236\u7684\u7f51\u7edc\u6574\u4f53\u7ed3\u6784\u7b80\u5316\u7248\u3002 \u56fe2.2 :yolov5s \u7f51\u7edc\u6574\u4f53\u7ed3\u6784 \u8be6\u7ec6\u7684\u7f51\u7edc\u7ed3\u6784\u56fe\uff1ahttps://oneflow-static.oss-cn-beijing.aliyuncs.com/one-yolo/imgs/yolov5s.onnx.png \u901a\u8fc7export.py\u5bfc\u51fa\u7684onnx\u683c\u5f0f\uff0c\u5e76\u901a\u8fc7 https://netron.app/ \u7f51\u7ad9\u5bfc\u51fa\u7684\u56fe\u7247(\u6a21\u578b\u5bfc\u51fa\u5c06\u5728\u672c\u6559\u7a0b\u7684\u540e\u7eed\u6587\u7ae0\u5355\u72ec\u4ecb\u7ecd)\u3002 \u6a21\u5757\u7ec4\u4ef6\u53f3\u8fb9\u53c2\u6570 \u8868\u793a\u7279\u5f81\u56fe\u7684\u7684\u5f62\u72b6\uff0c\u6bd4\u5982 \u5728 \u7b2c \u4e00 \u5c42( Conv )\u8f93\u5165 \u56fe\u7247\u5f62\u72b6\u4e3a [ 3, 640, 640] ,\u5173\u4e8e\u8fd9\u4e9b\u53c2\u6570\uff0c\u53ef\u4ee5\u56fa\u5b9a\u4e00\u5f20\u56fe\u7247\u8f93\u5165\u5230\u7f51\u7edc\u5e76\u901a\u8fc7 yolov5s.yaml \u7684\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\u5f97\u5230\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u5de5\u7a0b models/ yolo.py \u901a\u8fc7\u4ee3\u7801\u8fdb\u884cprint\u67e5\u770b,\u8be6\u7ec6\u6570\u636e\u53ef\u4ee5\u53c2\u8003\u9644\u4ef6\u88682.1\u3002 [1, 128, 80, 80],[1, 256, 40, 40],[1, 512, 20, 20] \u4f5c\u4e3a\u8f93\u5165\u7ecf\u8fc7Detect\u7684forward, \u63a5\u7740flow.cat()\u51fd\u6570\u62fc\u63a5\u6210\u4e3aoutput: [1, 25200, 85]\u3002","title":"\u7f51\u7edc\u7ed3\u6784\u9884\u89c8"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#yolopy","text":"\u6587\u4ef6\u5730\u5740 \u6587\u4ef6\u4e3b\u8981\u5305\u542b \u4e09\u5927\u90e8\u5206 Detect\u7c7b\uff0c Model\u7c7b\uff0c\u548c parse_model \u51fd\u6570 \u53ef\u4ee5\u901a\u8fc7 python models/ yolo.py --cfg yolov5s.yaml \u8fd0\u884c\u8be5\u811a\u672c\u8fdb\u884c\u89c2\u5bdf","title":"yolo.py \u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#parse_model","text":"def parse_model ( d , ch ): # model_dict, input_channels(3) \"\"\"\u7528\u5728\u4e0b\u9762Model\u6a21\u5757\u4e2d \u89e3\u6790\u6a21\u578b\u6587\u4ef6(\u5b57\u5178\u5f62\u5f0f)\uff0c\u5e76\u642d\u5efa\u7f51\u7edc\u7ed3\u6784 \u8fd9\u4e2a\u51fd\u6570\u5176\u5b9e\u4e3b\u8981\u505a\u7684\u5c31\u662f: \u66f4\u65b0\u5f53\u524d\u5c42\u7684args\uff08\u53c2\u6570\uff09,\u8ba1\u7b97c2\uff08\u5f53\u524d\u5c42\u7684\u8f93\u51fachannel\uff09 => \u4f7f\u7528\u5f53\u524d\u5c42\u7684\u53c2\u6570\u642d\u5efa\u5f53\u524d\u5c42 => \u751f\u6210 layers + save @Params d: model_dict \u6a21\u578b\u6587\u4ef6 \u5b57\u5178\u5f62\u5f0f {dict:7} [yolov5s.yaml](https://github.com/Oneflow-Inc/one-yolov5/blob/main/models/yolov5s.yaml)\u4e2d\u76846\u4e2a\u5143\u7d20 + ch #Params ch: \u8bb0\u5f55\u6a21\u578b\u6bcf\u4e00\u5c42\u7684\u8f93\u51fachannel \u521d\u59cbch=[3] \u540e\u9762\u4f1a\u5220\u9664 @return nn.Sequential(*layers): \u7f51\u7edc\u7684\u6bcf\u4e00\u5c42\u7684\u5c42\u7ed3\u6784 @return sorted(save): \u628a\u6240\u6709\u5c42\u7ed3\u6784\u4e2dfrom\u4e0d\u662f-1\u7684\u503c\u8bb0\u4e0b \u5e76\u6392\u5e8f [4, 6, 10, 14, 17, 20, 23] \"\"\" LOGGER . info ( f \" \\n { '' : >3 }{ 'from' : >18 }{ 'n' : >3 }{ 'params' : >10 } { 'module' : <40 }{ 'arguments' : <30 } \" ) # \u8bfb\u53d6d\u5b57\u5178\u4e2d\u7684anchors\u548cparameters(nc\u3001depth_multiple\u3001width_multiple) anchors , nc , gd , gw = d [ 'anchors' ], d [ 'nc' ], d [ 'depth_multiple' ], d [ 'width_multiple' ] # na: number of anchors \u6bcf\u4e00\u4e2apredict head\u4e0a\u7684anchor\u6570 = 3 na = ( len ( anchors [ 0 ]) // 2 ) if isinstance ( anchors , list ) else anchors # number of anchors no = na * ( nc + 5 ) # number of outputs = anchors * (classes + 5) \u6bcf\u4e00\u4e2apredict head\u5c42\u7684\u8f93\u51fachannel # \u5f00\u59cb\u642d\u5efa\u7f51\u7edc # layers: \u4fdd\u5b58\u6bcf\u4e00\u5c42\u7684\u5c42\u7ed3\u6784 # save: \u8bb0\u5f55\u4e0b\u6240\u6709\u5c42\u7ed3\u6784\u4e2dfrom\u4e2d\u4e0d\u662f-1\u7684\u5c42\u7ed3\u6784\u5e8f\u53f7 # c2: \u4fdd\u5b58\u5f53\u524d\u5c42\u7684\u8f93\u51fachannel layers , save , c2 = [], [], ch [ - 1 ] # layers, savelist, ch out # enumerate() \u51fd\u6570\u7528\u4e8e\u5c06\u4e00\u4e2a\u53ef\u904d\u5386\u7684\u6570\u636e\u5bf9\u8c61(\u5982\u5217\u8868\u3001\u5143\u7ec4\u6216\u5b57\u7b26\u4e32)\u7ec4\u5408\u4e3a\u4e00\u4e2a\u7d22\u5f15\u5e8f\u5217\uff0c\u540c\u65f6\u5217\u51fa\u6570\u636e\u548c\u6570\u636e\u4e0b\u6807\uff0c\u4e00\u822c\u7528\u5728 for \u5faa\u73af\u5f53\u4e2d\u3002 for i , ( f , n , m , args ) in enumerate ( d [ 'backbone' ] + d [ 'head' ]): # from, number, module, args m = eval ( m ) if isinstance ( m , str ) else m # eval strings for j , a in enumerate ( args ): # args\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u8fd9\u4e00\u6b65\u628a\u5217\u8868\u4e2d\u7684\u5185\u5bb9\u53d6\u51fa\u6765 with contextlib . suppress ( NameError ): args [ j ] = eval ( a ) if isinstance ( a , str ) else a # eval strings # \u5c06\u6df1\u5ea6\u4e0e\u6df1\u5ea6\u56e0\u5b50\u76f8\u4e58\uff0c\u8ba1\u7b97\u5c42\u6df1\u5ea6\u3002\u6df1\u5ea6\u6700\u5c0f\u4e3a1. n = n_ = max ( round ( n * gd ), 1 ) if n > 1 else n # depth gain # \u5982\u679c\u5f53\u524d\u7684\u6a21\u5757m\u5728\u672c\u9879\u76ee\u5b9a\u4e49\u7684\u6a21\u5757\u7c7b\u578b\u4e2d\uff0c\u5c31\u53ef\u4ee5\u5904\u7406\u8fd9\u4e2a\u6a21\u5757 if m in ( Conv , GhostConv , Bottleneck , GhostBottleneck , SPP , SPPF , DWConv , MixConv2d , Focus , CrossConv , BottleneckCSP , C3 , C3TR , C3SPP , C3Ghost , nn . ConvTranspose2d , DWConvTranspose2d , C3x ): # c1: \u8f93\u5165\u901a\u9053\u6570 c2\uff1a\u8f93\u51fa\u901a\u9053\u6570 c1 , c2 = ch [ f ], args [ 0 ] # \u8be5\u5c42\u4e0d\u662f\u6700\u540e\u4e00\u5c42\uff0c\u5219\u5c06\u901a\u9053\u6570\u4e58\u4ee5\u5bbd\u5ea6\u56e0\u5b50 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5bbd\u5ea6\u56e0\u5b50\u4f5c\u7528\u4e8e\u9664\u4e86\u6700\u540e\u4e00\u5c42\u4e4b\u5916\u7684\u6240\u6709\u5c42 if c2 != no : # if not output # make_divisible\u7684\u4f5c\u7528\uff0c\u4f7f\u5f97\u539f\u59cb\u7684\u901a\u9053\u6570\u4e58\u4ee5\u5bbd\u5ea6\u56e0\u5b50\u4e4b\u540e\u53d6\u6574\u52308\u7684\u500d\u6570\uff0c\u8fd9\u6837\u5904\u7406\u4e00\u822c\u662f\u8ba9\u6a21\u578b\u7684\u5e76\u884c\u6027\u548c\u63a8\u7406\u6027\u80fd\u66f4\u597d\u3002 c2 = make_divisible ( c2 * gw , 8 ) # \u5c06\u524d\u9762\u7684\u8fd0\u7b97\u7ed3\u679c\u4fdd\u5b58\u5728args\u4e2d\uff0c\u5b83\u4e5f\u5c31\u662f\u8fd9\u4e2a\u6a21\u5757\u6700\u7ec8\u7684\u8f93\u5165\u53c2\u6570\u3002 args = [ c1 , c2 , * args [ 1 :]] # \u6839\u636e\u6bcf\u5c42\u7f51\u7edc\u53c2\u6570\u7684\u4e0d\u540c\uff0c\u5206\u522b\u5904\u7406\u53c2\u6570 \u5177\u4f53\u5404\u4e2a\u7c7b\u7684\u53c2\u6570\u662f\u4ec0\u4e48\u8bf7\u53c2\u8003\u5b83\u4eec\u7684__init__\u65b9\u6cd5\u8fd9\u91cc\u4e0d\u518d\u8be6\u7ec6\u89e3\u91ca\u4e86 if m in [ BottleneckCSP , C3 , C3TR , C3Ghost , C3x ]: # \u8fd9\u91cc\u7684\u610f\u601d\u5c31\u662f\u91cd\u590dn\u6b21\uff0c\u6bd4\u5982conv\u8fd9\u4e2a\u6a21\u5757\u91cd\u590dn\u6b21\uff0c\u8fd9\u4e2an \u662f\u4e0a\u9762\u7b97\u51fa\u6765\u7684 depth args . insert ( 2 , n ) # number of repeats n = 1 elif m is nn . BatchNorm2d : args = [ ch [ f ]] elif m is Concat : c2 = sum ( ch [ x ] for x in f ) elif m is Detect : args . append ([ ch [ x ] for x in f ]) if isinstance ( args [ 1 ], int ): # number of anchors args [ 1 ] = [ list ( range ( args [ 1 ] * 2 ))] * len ( f ) elif m is Contract : c2 = ch [ f ] * args [ 0 ] ** 2 elif m is Expand : c2 = ch [ f ] // args [ 0 ] ** 2 else : c2 = ch [ f ] # \u6784\u5efa\u6574\u4e2a\u7f51\u7edc\u6a21\u5757 \u8fd9\u91cc\u5c31\u662f\u6839\u636e\u6a21\u5757\u7684\u91cd\u590d\u6b21\u6570n\u4ee5\u53ca\u6a21\u5757\u672c\u8eab\u548c\u5b83\u7684\u53c2\u6570\u6765\u6784\u5efa\u8fd9\u4e2a\u6a21\u5757\u548c\u53c2\u6570\u5bf9\u5e94\u7684Module m_ = nn . Sequential ( * ( m ( * args ) for _ in range ( n ))) if n > 1 else m ( * args ) # module # \u83b7\u53d6\u6a21\u5757(module type)\u5177\u4f53\u540d\u4f8b\u5982 models.common.Conv , models.common.C3 , models.common.SPPF \u7b49\u3002 t = str ( m )[ 8 : - 2 ] . replace ( '__main__.' , '' ) # replace\u51fd\u6570\u4f5c\u7528\u662f\u5b57\u7b26\u4e32\"__main__\"\u66ff\u6362\u4e3a''\uff0c\u5728\u5f53\u524d\u9879\u76ee\u6ca1\u6709\u7528\u5230\u8fd9\u4e2a\u66ff\u6362\u3002 np = sum ( x . numel () for x in m_ . parameters ()) # number params m_ . i , m_ . f , m_ . type , m_ . np = i , f , t , np # attach index, 'from' index, type, number params LOGGER . info ( f ' { i : >3 }{ str ( f ) : >18 }{ n_ : >3 }{ np : 10.0f } { t : <40 }{ str ( args ) : <30 } ' ) # print \"\"\" \u5982\u679cx\u4e0d\u662f-1\uff0c\u5219\u5c06\u5176\u4fdd\u5b58\u5728save\u5217\u8868\u4e2d\uff0c\u8868\u793a\u8be5\u5c42\u9700\u8981\u4fdd\u5b58\u7279\u5f81\u56fe\u3002 \u8fd9\u91cc x % i \u4e0e x \u7b49\u4ef7\u4f8b\u5982\u5728\u6700\u540e\u4e00\u5c42 : f = [17,20,23] , i = 24 y = [ x % i for x in ([f] if isinstance(f, int) else f) if x != -1 ] print(y) # [17, 20, 23] # \u5199\u6210x % i \u53ef\u80fd\u56e0\u4e3a\uff1ai - 1 = -1 % i (\u6bd4\u5982 f = [-1]\uff0c\u5219 [x % i for x in f] \u4ee3\u8868 [11] ) \"\"\" save . extend ( x % i for x in ([ f ] if isinstance ( f , int ) else f ) if x != - 1 ) # append to savelist layers . append ( m_ ) if i == 0 : # \u5982\u679c\u662f\u521d\u6b21\u8fed\u4ee3\uff0c\u5219\u65b0\u521b\u5efa\u4e00\u4e2ach\uff08\u56e0\u4e3a\u5f62\u53c2ch\u5728\u521b\u5efa\u7b2c\u4e00\u4e2a\u7f51\u7edc\u6a21\u5757\u65f6\u9700\u8981\u7528\u5230\uff0c\u6240\u4ee5\u521b\u5efa\u7f51\u7edc\u6a21\u5757\u4e4b\u540e\u518d\u521d\u59cb\u5316ch\uff09 ch = [] ch . append ( c2 ) # \u5c06\u6240\u6709\u7684\u5c42\u5c01\u88c5\u4e3ann.Sequential , \u5bf9\u4fdd\u5b58\u7684\u7279\u5f81\u56fe\u6392\u5e8f return nn . Sequential ( * layers ), sorted ( save )","title":"parse_model\u51fd\u6570\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#model","text":"class Model ( nn . Module ): # YOLOv5 model def __init__ ( self , cfg = '[yolov5s.yaml](https://github.com/Oneflow-Inc/one-yolov5/blob/main/models/yolov5s.yaml)' , ch = 3 , nc = None , anchors = None ): # model, input channels, number of classes super () . __init__ () # \u5982\u679ccfg\u5df2\u7ecf\u662f\u5b57\u5178\uff0c\u5219\u76f4\u63a5\u8d4b\u503c\uff0c\u5426\u5219\u5148\u52a0\u8f7dcfg\u8def\u5f84\u7684\u6587\u4ef6\u4e3a\u5b57\u5178\u5e76\u8d4b\u503c\u7ed9self.yaml\u3002 if isinstance ( cfg , dict ): self . yaml = cfg # model dict else : # is *.yaml \u52a0\u8f7dyaml\u6a21\u5757 import yaml # for flow hub self . yaml_file = Path ( cfg ) . name with open ( cfg , encoding = 'ascii' , errors = 'ignore' ) as f : self . yaml = yaml . safe_load ( f ) # model dict \u4eceyaml\u6587\u4ef6\u4e2d\u52a0\u8f7d\u51fa\u5b57\u5178 # Define model # ch: \u8f93\u5165\u901a\u9053\u6570\u3002 \u5047\u5982self.yaml\u6709\u952e\u2018ch\u2019\uff0c\u5219\u5c06\u8be5\u952e\u5bf9\u5e94\u7684\u503c\u8d4b\u7ed9\u5185\u90e8\u53d8\u91cfch\u3002\u5047\u5982\u6ca1\u6709\u2018ch\u2019\uff0c\u5219\u5c06\u5f62\u53c2ch\u8d4b\u7ed9\u5185\u90e8\u53d8\u91cfch ch = self . yaml [ 'ch' ] = self . yaml . get ( 'ch' , ch ) # input channels # \u5047\u5982yaml\u4e2d\u7684nc\u548c\u65b9\u6cd5\u5f62\u53c2\u4e2d\u7684nc\u4e0d\u4e00\u81f4\uff0c\u5219\u8986\u76d6yaml\u4e2d\u7684nc\u3002 if nc and nc != self . yaml [ 'nc' ]: LOGGER . info ( f \"Overriding model.yaml nc= { self . yaml [ 'nc' ] } with nc= { nc } \" ) self . yaml [ 'nc' ] = nc # override yaml value if anchors : # anchors \u5148\u9a8c\u6846\u7684\u914d\u7f6e LOGGER . info ( f 'Overriding model.yaml anchors with anchors= { anchors } ' ) self . yaml [ 'anchors' ] = round ( anchors ) # override yaml value # \u5f97\u5230\u6a21\u578b\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7684\u4fdd\u5b58\u7684\u7279\u5f81\u56fe\u5217\u8868\u3002 self . model , self . save = parse_model ( deepcopy ( self . yaml ), ch = [ ch ]) # model, savelist self . names = [ str ( i ) for i in range ( self . yaml [ 'nc' ])] # default names \u521d\u59cb\u5316\u7c7b\u540d\u5217\u8868\uff0c\u9ed8\u8ba4\u4e3a[0,1,2...] # self.inplace=True \u9ed8\u8ba4True \u8282\u7701\u5185\u5b58 self . inplace = self . yaml . get ( 'inplace' , True ) # Build strides, anchors \u786e\u5b9a\u6b65\u957f\u3001\u6b65\u957f\u5bf9\u5e94\u7684\u951a\u6846 m = self . model [ - 1 ] # Detect() if isinstance ( m , Detect ): # \u68c0\u9a8c\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42\u662fDetect\u6a21\u5757 s = 256 # 2x min stride m . inplace = self . inplace # \u8ba1\u7b97\u4e09\u4e2afeature map\u4e0b\u91c7\u6837\u7684\u500d\u7387 [8, 16, 32] m . stride = flow . tensor ([ s / x . shape [ - 2 ] for x in self . forward ( flow . zeros ( 1 , ch , s , s ))]) # forward # \u68c0\u67e5anchor\u987a\u5e8f\u4e0estride\u987a\u5e8f\u662f\u5426\u4e00\u81f4 anchor\u7684\u987a\u5e8f\u5e94\u8be5\u662f\u4ece\u5c0f\u5230\u5927\uff0c\u8fd9\u91cc\u6392\u4e00\u4e0b\u5e8f check_anchor_order ( m ) # must be in pixel-space (not grid-space) # \u5bf9\u5e94\u7684anchor\u8fdb\u884c\u7f29\u653e\u64cd\u4f5c\uff0c\u539f\u56e0\uff1a\u5f97\u5230anchor\u5728\u5b9e\u9645\u7684\u7279\u5f81\u56fe\u4e2d\u7684\u4f4d\u7f6e\uff0c\u56e0\u4e3a\u52a0\u8f7d\u7684\u539f\u59cbanchor\u5927\u5c0f\u662f\u76f8\u5bf9\u4e8e\u539f\u56fe\u7684\u50cf\u7d20\uff0c\u4f46\u662f\u7ecf\u8fc7\u5377\u79ef\u6c60\u5316\u4e4b\u540e\uff0c\u7279\u5f81\u56fe\u7684\u957f\u5bbd\u53d8\u5c0f\u4e86\u3002 m . anchors /= m . stride . view ( - 1 , 1 , 1 ) self . stride = m . stride self . _initialize_biases () # only run once \u521d\u59cb\u5316\u504f\u7f6e # Init weights, biases # \u8c03\u7528oneflow_utils.py\u4e0binitialize_weights\u521d\u59cb\u5316\u6a21\u578b\u6743\u91cd initialize_weights ( self ) self . info () # \u6253\u5370\u6a21\u578b\u4fe1\u606f LOGGER . info ( '' ) # \u7ba1\u7406\u524d\u5411\u4f20\u64ad\u51fd\u6570 def forward ( self , x , augment = False , profile = False , visualize = False ): if augment : # \u662f\u5426\u5728\u6d4b\u8bd5\u65f6\u4e5f\u4f7f\u7528\u6570\u636e\u589e\u5f3a Test Time Augmentation(TTA) return self . _forward_augment ( x ) # augmented inference, None return self . _forward_once ( x , profile , visualize ) # single-scale inference, train # \u5e26\u6570\u636e\u589e\u5f3a\u7684\u524d\u5411\u4f20\u64ad def _forward_augment ( self , x ): img_size = x . shape [ - 2 :] # height, width s = [ 1 , 0.83 , 0.67 ] # scales f = [ None , 3 , None ] # flips (2-ud, 3-lr) y = [] # outputs for si , fi in zip ( s , f ): xi = scale_img ( x . flip ( fi ) if fi else x , si , gs = int ( self . stride . max ())) yi = self . _forward_once ( xi )[ 0 ] # forward # cv2.imwrite(f'img_{si}.jpg', 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1]) # save yi = self . _descale_pred ( yi , fi , si , img_size ) y . append ( yi ) y = self . _clip_augmented ( y ) # clip augmented tails return flow . cat ( y , 1 ), None # augmented inference, train # \u524d\u5411\u4f20\u64ad\u5177\u4f53\u5b9e\u73b0 def _forward_once ( self , x , profile = False , visualize = False ): \"\"\" @params x: \u8f93\u5165\u56fe\u50cf @params profile: True \u53ef\u4ee5\u505a\u4e00\u4e9b\u6027\u80fd\u8bc4\u4f30 @params feature_vis: True \u53ef\u4ee5\u505a\u4e00\u4e9b\u7279\u5f81\u53ef\u89c6\u5316 \"\"\" # y: \u5b58\u653e\u7740self.save=True\u7684\u6bcf\u4e00\u5c42\u7684\u8f93\u51fa\uff0c\u56e0\u4e3a\u540e\u9762\u7684\u7279\u5f81\u878d\u5408\u64cd\u4f5c\u8981\u7528\u5230\u8fd9\u4e9b\u7279\u5f81\u56fe y , dt = [], [] # outputs # \u524d\u5411\u63a8\u7406\u6bcf\u4e00\u5c42\u7ed3\u6784 m.i=index m.f=from m.type=\u7c7b\u540d m.np=number of params for m in self . model : # if not from previous layer m.f=\u5f53\u524d\u5c42\u7684\u8f93\u5165\u6765\u81ea\u54ea\u4e00\u5c42\u7684\u8f93\u51fa s\u7684m.f\u90fd\u662f-1 if m . f != - 1 : # if not from previous layer x = y [ m . f ] if isinstance ( m . f , int ) else [ x if j == - 1 else y [ j ] for j in m . f ] # from earlier layers if profile : self . _profile_one_layer ( m , x , dt ) x = m ( x ) # run y . append ( x if m . i in self . save else None ) # save output if visualize : feature_visualization ( x , m . type , m . i , save_dir = visualize ) return x # \u5c06\u63a8\u7406\u7ed3\u679c\u6062\u590d\u5230\u539f\u56fe\u56fe\u7247\u5c3a\u5bf8(\u9006\u64cd\u4f5c) def _descale_pred ( self , p , flips , scale , img_size ): # de-scale predictions following augmented inference (inverse operation) \"\"\"\u7528\u5728\u4e0a\u9762\u7684__init__\u51fd\u6570\u4e0a \u5c06\u63a8\u7406\u7ed3\u679c\u6062\u590d\u5230\u539f\u56fe\u56fe\u7247\u5c3a\u5bf8 Test Time Augmentation(TTA)\u4e2d\u7528\u5230 de-scale predictions following augmented inference (inverse operation) @params p: \u63a8\u7406\u7ed3\u679c @params flips: @params scale: @params img_size: \"\"\" if self . inplace : p [ ... , : 4 ] /= scale # de-scale if flips == 2 : p [ ... , 1 ] = img_size [ 0 ] - p [ ... , 1 ] # de-flip ud elif flips == 3 : p [ ... , 0 ] = img_size [ 1 ] - p [ ... , 0 ] # de-flip lr else : x , y , wh = p [ ... , 0 : 1 ] / scale , p [ ... , 1 : 2 ] / scale , p [ ... , 2 : 4 ] / scale # de-scale if flips == 2 : y = img_size [ 0 ] - y # de-flip ud elif flips == 3 : x = img_size [ 1 ] - x # de-flip lr p = flow . cat (( x , y , wh , p [ ... , 4 :]), - 1 ) return p # \u8fd9\u4e2a\u662fTTA\u7684\u65f6\u5019\u5bf9\u539f\u56fe\u7247\u8fdb\u884c\u88c1\u526a\uff0c\u4e5f\u662f\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u5f0f\uff0c\u7528\u5728TTA\u6d4b\u8bd5\u7684\u65f6\u5019\u3002 def _clip_augmented ( self , y ): # Clip YOLOv5 augmented inference tails nl = self . model [ - 1 ] . nl # number of detection layers (P3-P5) g = sum ( 4 ** x for x in range ( nl )) # grid points e = 1 # exclude layer count i = ( y [ 0 ] . shape [ 1 ] // g ) * sum ( 4 ** x for x in range ( e )) # indices y [ 0 ] = y [ 0 ][:, : - i ] # large i = ( y [ - 1 ] . shape [ 1 ] // g ) * sum ( 4 ** ( nl - 1 - x ) for x in range ( e )) # indices y [ - 1 ] = y [ - 1 ][:, i :] # small return y # \u6253\u5370\u65e5\u5fd7\u4fe1\u606f \u524d\u5411\u63a8\u7406\u65f6\u95f4 def _profile_one_layer ( self , m , x , dt ): c = isinstance ( m , Detect ) # is final layer, copy input as inplace fix o = thop . profile ( m , inputs = ( x . copy () if c else x ,), verbose = False )[ 0 ] / 1E9 * 2 if thop else 0 # FLOPs t = time_sync () for _ in range ( 10 ): m ( x . copy () if c else x ) dt . append (( time_sync () - t ) * 100 ) if m == self . model [ 0 ]: LOGGER . info ( f \" { 'time (ms)' : >10s } { 'GFLOPs' : >10s } { 'params' : >10s } module\" ) LOGGER . info ( f ' { dt [ - 1 ] : 10.2f } { o : 10.2f } { m . np : 10.0f } { m . type } ' ) if c : LOGGER . info ( f \" { sum ( dt ) : 10.2f } { '-' : >10s } { '-' : >10s } Total\" ) # initialize biases into Detect(), cf is class frequency def _initialize_biases ( self , cf = None ): # https://arxiv.org/abs/1708.02002 section 3.3 # cf = flow.bincount(flow.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1. m = self . model [ - 1 ] # Detect() module for mi , s in zip ( m . m , m . stride ): # from b = mi . bias . view ( m . na , - 1 ) . detach () # conv.bias(255) to (3,85) b [:, 4 ] += math . log ( 8 / ( 640 / s ) ** 2 ) # obj (8 objects per 640 image) b [:, 5 :] += math . log ( 0.6 / ( m . nc - 0.999999 )) if cf is None else flow . log ( cf / cf . sum ()) # cls mi . bias = flow . nn . Parameter ( b . view ( - 1 ), requires_grad = True ) # \u6253\u5370\u6a21\u578b\u4e2d\u6700\u540eDetect\u5c42\u7684\u504f\u7f6ebiases\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42biases\u4fe1\u606f) def _print_biases ( self ): \"\"\" \u6253\u5370\u6a21\u578b\u4e2d\u6700\u540eDetect\u6a21\u5757\u91cc\u9762\u7684\u5377\u79ef\u5c42\u7684\u504f\u7f6ebiases\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42biases\u4fe1\u606f) \"\"\" m = self . model [ - 1 ] # Detect() module for mi in m . m : # from b = mi . bias . detach () . view ( m . na , - 1 ) . T # conv.bias(255) to (3,85) LOGGER . info ( ( ' %6g Conv2d.bias:' + ' %10.3g ' * 6 ) % ( mi . weight . shape [ 1 ], * b [: 5 ] . mean ( 1 ) . tolist (), b [ 5 :] . mean ())) def _print_weights ( self ): \"\"\" \u6253\u5370\u6a21\u578b\u4e2dBottleneck\u5c42\u7684\u6743\u91cd\u53c2\u6570weights\u4fe1\u606f(\u4e5f\u53ef\u4ee5\u4efb\u9009\u54ea\u4e9b\u5c42weights\u4fe1\u606f) \"\"\" for m in self . model . modules (): if type ( m ) is Bottleneck : LOGGER . info ( ' %10.3g ' % ( m . w . detach () . sigmoid () * 2 )) # shortcut weights # fuse()\u662f\u7528\u6765\u8fdb\u884cconv\u548cbn\u5c42\u5408\u5e76\uff0c\u4e3a\u4e86\u63d0\u901f\u6a21\u578b\u63a8\u7406\u901f\u5ea6\u3002 def fuse ( self ): # fuse model Conv2d() + BatchNorm2d() layers \"\"\"\u7528\u5728detect.py\u3001val.py fuse model Conv2d() + BatchNorm2d() layers \u8c03\u7528oneflow_utils.py\u4e2d\u7684fuse_conv_and_bn\u51fd\u6570\u548ccommon.py\u4e2dConv\u6a21\u5757\u7684fuseforward\u51fd\u6570 \"\"\" LOGGER . info ( 'Fusing layers... ' ) for m in self . model . modules (): # \u5982\u679c\u5f53\u524d\u5c42\u662f\u5377\u79ef\u5c42Conv\u4e14\u6709bn\u7ed3\u6784, \u90a3\u4e48\u5c31\u8c03\u7528fuse_conv_and_bn\u51fd\u6570\u8bb2conv\u548cbn\u8fdb\u884c\u878d\u5408, \u52a0\u901f\u63a8\u7406 if isinstance ( m , ( Conv , DWConv )) and hasattr ( m , 'bn' ): m . conv = fuse_conv_and_bn ( m . conv , m . bn ) # update conv delattr ( m , 'bn' ) # remove batchnorm \u79fb\u9664bn remove batchnorm m . forward = m . forward_fuse # update forward \u66f4\u65b0\u524d\u5411\u4f20\u64ad update forward (\u53cd\u5411\u4f20\u64ad\u4e0d\u7528\u7ba1, \u56e0\u4e3a\u8fd9\u79cd\u63a8\u7406\u53ea\u7528\u5728\u63a8\u7406\u9636\u6bb5) self . info () # \u6253\u5370conv+bn\u878d\u5408\u540e\u7684\u6a21\u578b\u4fe1\u606f return self # \u6253\u5370\u6a21\u578b\u7ed3\u6784\u4fe1\u606f \u5728\u5f53\u524d\u7c7b__init__\u51fd\u6570\u7ed3\u5c3e\u5904\u6709\u8c03\u7528 def info ( self , verbose = False , img_size = 640 ): # print model information model_info ( self , verbose , img_size ) def _apply ( self , fn ): # Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers self = super () . _apply ( fn ) m = self . model [ - 1 ] # Detect() if isinstance ( m , Detect ): m . stride = fn ( m . stride ) m . grid = list ( map ( fn , m . grid )) if isinstance ( m . anchor_grid , list ): m . anchor_grid = list ( map ( fn , m . anchor_grid )) return self","title":"Model \u7c7b\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#detect","text":"class Detect ( nn . Module ): \"\"\" Detect\u6a21\u5757\u662f\u7528\u6765\u6784\u5efaDetect\u5c42\u7684\uff0c\u5c06\u8f93\u5165feature map \u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u64cd\u4f5c\u548c\u516c\u5f0f\u8ba1\u7b97\u5230\u6211\u4eec\u60f3\u8981\u7684shape, \u4e3a\u540e\u9762\u7684\u8ba1\u7b97\u635f\u5931\u6216\u8005NMS\u540e\u5904\u7406\u4f5c\u51c6\u5907 \"\"\" stride = None # strides computed during build onnx_dynamic = False # ONNX export parameter export = False # export mode def __init__ ( self , nc = 80 , anchors = (), ch = (), inplace = True ): # detection layer super () . __init__ () # nc:\u5206\u7c7b\u6570\u91cf self . nc = nc # number of classes COCO : 80 # no:\u6bcf\u4e2aanchor\u7684\u8f93\u51fa\u6570 COCO: 80 + 5 = 85 self . no = nc + 5 # number of outputs per anchor Detect\u7684\u4e2a\u6570 3 # nl:\u9884\u6d4b\u5c42\u6570\uff0c\u6b64\u6b21\u4e3a3 self . nl = len ( anchors ) # number of detection layers # na:anchors\u7684\u6570\u91cf\uff0c\u6b64\u6b21\u4e3a3 self . na = len ( anchors [ 0 ]) // 2 # number of anchors # grid:\u683c\u5b50\u5750\u6807\u7cfb\uff0c\u5de6\u4e0a\u89d2\u4e3a(1,1),\u53f3\u4e0b\u89d2\u4e3a(input.w/stride,input.h/stride) self . grid = [ flow . zeros ( 1 )] * self . nl # init grid self . anchor_grid = [ flow . zeros ( 1 )] * self . nl # init anchor grid # \u5199\u5165\u7f13\u5b58\u4e2d\uff0c\u5e76\u547d\u540d\u4e3aanchors # register_buffer # \u6a21\u578b\u4e2d\u9700\u8981\u4fdd\u5b58\u7684\u53c2\u6570\u4e00\u822c\u6709\u4e24\u79cd\uff1a\u4e00\u79cd\u662f\u53cd\u5411\u4f20\u64ad\u9700\u8981\u88aboptimizer\u66f4\u65b0\u7684\uff0c\u79f0\u4e3aparameter; \u53e6\u4e00\u79cd\u4e0d\u8981\u88ab\u66f4\u65b0\u79f0\u4e3abuffer # buffer\u7684\u53c2\u6570\u66f4\u65b0\u662f\u5728forward\u4e2d\uff0c\u800coptim.step\u53ea\u80fd\u66f4\u65b0nn.parameter\u7c7b\u578b\u7684\u53c2\u6570 self . register_buffer ( 'anchors' , flow . tensor ( anchors ) . float () . view ( self . nl , - 1 , 2 )) # shape(nl,na,2) # \u5c06\u8f93\u51fa\u901a\u8fc7\u5377\u79ef\u5230 self.no * self.na \u7684\u901a\u9053\uff0c\u8fbe\u5230\u5168\u8fde\u63a5\u7684\u4f5c\u7528 self . m = nn . ModuleList ( nn . Conv2d ( x , self . no * self . na , 1 ) for x in ch ) # output conv self . inplace = inplace # use inplace ops (e.g. slice assignment) def forward ( self , x ): z = [] # inference output for i in range ( self . nl ): x [ i ] = self . m [ i ]( x [ i ]) # conv bs , _ , ny , nx = x [ i ] . shape # x(bs,255,20,20) to x(bs,3,20,20,85) x [ i ] = x [ i ] . view ( bs , self . na , self . no , ny , nx ) . permute ( 0 , 1 , 3 , 4 , 2 ) . contiguous () if not self . training : # inference # \u6784\u9020\u7f51\u683c # \u56e0\u4e3a\u63a8\u7406\u8fd4\u56de\u7684\u4e0d\u662f\u5f52\u4e00\u5316\u540e\u7684\u7f51\u683c\u504f\u79fb\u91cf \u9700\u8981\u518d\u52a0\u4e0a\u7f51\u683c\u7684\u4f4d\u7f6e \u5f97\u5230\u6700\u7ec8\u7684\u63a8\u7406\u5750\u6807 \u518d\u9001\u5165nms # \u6240\u4ee5\u8fd9\u91cc\u6784\u5efa\u7f51\u683c\u5c31\u662f\u4e3a\u4e86\u8bb0\u5f55\u6bcf\u4e2agrid\u7684\u7f51\u683c\u5750\u6807 \u65b9\u9762\u540e\u9762\u4f7f\u7528 if self . onnx_dynamic or self . grid [ i ] . shape [ 2 : 4 ] != x [ i ] . shape [ 2 : 4 ]: # \u5411\u524d\u4f20\u64ad\u65f6\u9700\u8981\u5c06\u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u5230grid\u7edd\u5bf9\u5750\u6807\u7cfb\u4e2d self . grid [ i ], self . anchor_grid [ i ] = self . _make_grid ( nx , ny , i ) y = x [ i ] . sigmoid () if self . inplace : # \u9ed8\u8ba4\u6267\u884c \u4e0d\u4f7f\u7528AWS Inferentia # \u8fd9\u91cc\u7684\u516c\u5f0f\u548cyolov3\u3001v4\u4e2d\u4f7f\u7528\u7684\u4e0d\u4e00\u6837 \u662fyolov5\u4f5c\u8005\u81ea\u5df1\u7528\u7684 \u6548\u679c\u66f4\u597d y [ ... , 0 : 2 ] = ( y [ ... , 0 : 2 ] * 2 + self . grid [ i ]) * self . stride [ i ] # xy y [ ... , 2 : 4 ] = ( y [ ... , 2 : 4 ] * 2 ) ** 2 * self . anchor_grid [ i ] # wh else : # for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953 xy , wh , conf = y . split (( 2 , 2 , self . nc + 1 ), 4 ) # y.tensor_split((2, 4, 5), 4) xy = ( xy * 2 + self . grid [ i ]) * self . stride [ i ] # xy wh = ( wh * 2 ) ** 2 * self . anchor_grid [ i ] # wh y = flow . cat (( xy , wh , conf ), 4 ) # z [oneflow.Size([1, 19200, 85]) oneflow.Size([1, 4800, 85]) oneflow.Size([1, 1200, 85])] z . append ( y . view ( bs , - 1 , self . no )) return x if self . training else ( flow . cat ( z , 1 ),) if self . export else ( flow . cat ( z , 1 ), x ) # \u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u5230grid\u7edd\u5bf9\u5750\u6807\u7cfb def _make_grid ( self , nx = 20 , ny = 20 , i = 0 ): d = self . anchors [ i ] . device t = self . anchors [ i ] . dtype shape = 1 , self . na , ny , nx , 2 # grid shape y , x = flow . arange ( ny , device = d , dtype = t ), flow . arange ( nx , device = d , dtype = t ) yv , xv = flow . meshgrid ( y , x , indexing = \"ij\" ) grid = flow . stack (( xv , yv ), 2 ) . expand ( shape ) - 0.5 # add grid offset, i.e. y = 2.0 * x - 0.5 anchor_grid = ( self . anchors [ i ] * self . stride [ i ]) . view (( 1 , self . na , 1 , 1 , 2 )) . expand ( shape ) return grid , anchor_grid","title":"Detect\u7c7b\u89e3\u8bfb"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_5","text":"\u88682.1 yolov5s.yaml \u89e3\u6790\u8868 \u5c42\u6570 form moudule arguments input output 0 -1 Conv [3, 32, 6, 2, 2] [3, 640, 640] [32, 320, 320] 1 -1 Conv [32, 64, 3, 2] [32, 320, 320] [64, 160, 160] 2 -1 C3 [64, 64, 1] [64, 160, 160] [64, 160, 160] 3 -1 Conv [64, 128, 3, 2] [64, 160, 160] [128, 80, 80] 4 -1 C3 [128, 128, 2] [128, 80, 80] [128, 80, 80] 5 -1 Conv [128, 256, 3, 2] [128, 80, 80] [256, 40, 40] 6 -1 C3 [256, 256, 3] [256, 40, 40] [256, 40, 40] 7 -1 Conv [256, 512, 3, 2] [256, 40, 40] [512, 20, 20] 8 -1 C3 [512, 512, 1] [512, 20, 20] [512, 20, 20] 9 -1 SPPF [512, 512, 5] [512, 20, 20] [512, 20, 20] 10 -1 Conv [512, 256, 1, 1] [512, 20, 20] [256, 20, 20] 11 -1 Upsample [None, 2, 'nearest'] [256, 20, 20] [256, 40, 40] 12 [-1, 6] Concat [1] [1, 256, 40, 40],[1, 256, 40, 40] [512, 40, 40] 13 -1 C3 [512, 256, 1, False] [512, 40, 40] [256, 40, 40] 14 -1 Conv [256, 128, 1, 1] [256, 40, 40] [128, 40, 40] 15 -1 Upsample [None, 2, 'nearest'] [128, 40, 40] [128, 80, 80] 16 [-1, 4] Concat [1] [1, 128, 80, 80],[1, 128, 80, 80] [256, 80, 80] 17 -1 C3 [256, 128, 1, False] [256, 80, 80] [128, 80, 80] 18 -1 Conv [128, 128, 3, 2] [128, 80, 80] [128, 40, 40] 19 [-1, 14] Concat [1] [1, 128, 40, 40],[1, 128, 40, 40] [256, 40, 40] 20 -1 C3 [256, 256, 1, False] [256, 40, 40] [256, 40, 40] 21 -1 Conv [256, 256, 3, 2] [256, 40, 40] [256, 20, 20] 22 [-1, 10] Concat [1] [1, 256, 20, 20],[1, 256, 20, 20] [512, 20, 20] 23 -1 C3 [512, 512, 1, False] [512, 20, 20] [512, 20, 20] 24 [17, 20, 23] Detect [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]] [1, 128, 80, 80],[1, 256, 40, 40],[1, 512, 20, 20] [1, 3, 80, 80, 85],[1, 3, 40, 40, 85],[1, 3, 20, 20, 85]","title":"\u9644\u4ef6"},{"location":"tutorials/01_chapter/yolov5_network_structure_analysis.html#_6","text":"https://zhuanlan.zhihu.com/p/436891962?ivk_sa=1025922q https://zhuanlan.zhihu.com/p/110204563 https://www.it610.com/article/1550621248474648576.htm","title":"\u53c2\u8003\u6587\u7ae0:"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u672c\u6587\u4e3b\u8981\u4ecb\u7ecd one-yolov5 \u4f7f\u7528\u7684\u6570\u636e\u96c6\u7684\u683c\u5f0f\u4ee5\u53ca\u5982\u4f55\u5236\u4f5c\u4e00\u4e2a\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u8bad\u7ec3\u6548\u679c\u7684\u6570\u636e\u96c6\u3002\u672c\u8282\u6559\u7a0b\u597d\u7684\u6570\u636e\u96c6\u6807\u51c6\u90e8\u5206\u7ffb\u8bd1\u4e86 ultralytics/yolov5 wiki \u4e2d \u5bf9\u6570\u636e\u96c6\u76f8\u5173\u7684\u63cf\u8ff0 \u3002 \u6570\u636e\u96c6\u7ed3\u6784\u89e3\u8bfb 1.\u521b\u5efadataset.yaml COCO128\u662f\u5b98\u65b9\u7ed9\u7684\u4e00\u4e2a\u5c0f\u7684\u6570\u636e\u96c6 \u7531 COCO \u6570\u636e\u96c6\u524d 128 \u5f20\u56fe\u7247\u7ec4\u6210\u3002 \u8fd9128\u5e45\u56fe\u50cf\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\uff0c\u5224\u65ad yolov5 \u811a\u672c\u662f\u5426\u80fd\u591f\u8fc7\u6b63\u5e38\u8fdb\u884c\u3002 \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6 coco128.yaml \u5b9a\u4e49\u4e86\u5982\u4e0b\u7684\u914d\u7f6e\u9009\u9879\uff1a # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license # COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics # Example usage: python train.py --data coco128.yaml # parent # \u251c\u2500\u2500 one-yolov5 # \u2514\u2500\u2500 datasets # \u2514\u2500\u2500 coco128 \u2190 downloads here (7 MB) # train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/] # \u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u76f8\u540c train: ../coco128/images/train2017/ val: ../coco128/images/train2017/ # number of classes nc: 80 # \u7c7b\u522b\u6570 # class names \u7c7b\u540d\u5217\u8868 names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'] # Download script/URL (optional) \u7528\u4e8e\u81ea\u52a8\u4e0b\u8f7d\u7684\u53ef\u9009\u4e0b\u8f7d\u547d\u4ee4/URL \u3002 download: https://ultralytics.com/assets/coco128.zip \u6ce8\u610f\uff1a\u5982\u679c\u662f\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u7684\u8bdd\u6309\u81ea\u5df1\u9700\u6c42\u4fee\u6539\u8fd9\u4e2ayaml\u6587\u4ef6\u3002\u4e3b\u8981\u4fee\u6539\u4ee5\u4e0b\u4e24\u70b9\u3002 1. \u4fee\u6539\u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u4e3a\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u8def\u5f84 2. \u4fee\u6539\u7c7b\u522b\u6570\u548c\u7c7b\u540d\u5217\u8868 \u518d\u5c55\u793a\u4e00\u4e0b coco.yaml \u7684\u6570\u636e\u96c6\u8def\u5f84\u914d\u7f6e\uff0c\u8fd9\u91cc\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u5c31\u662f\u76f4\u63a5\u7528txt\u8868\u793a\uff1a 2.\u521b\u5efa Labels \u4f7f\u7528\u5de5\u5177\u4f8b\u5982 CVAT , makesense.ai , Labelbox \uff0cLabelImg(\u5728\u672c\u7ae0\u5982\u4f55\u5236\u4f5c\u6570\u636e\u96c6\u4e2d\u4ecb\u7ecdLabelImg\u5de5\u5177\u4f7f\u7528) \u7b49\uff0c\u5728\u4f60\u81ea\u5df1\u7684\u6570\u636e\u96c6\u63d0\u4f9b\u7684\u56fe\u7247\u4e0a\u505a\u76ee\u6807\u6846\u7684\u6807\u6ce8\uff0c\u5c06\u6807\u6ce8\u4fe1\u606f\u5bfc\u51fa\u4e3a\u4e00\u4e2atxt\u540e\u7f00\u7ed3\u5c3e\u7684\u6587\u4ef6\u3002\uff08\u5982\u679c\u56fe\u50cf\u4e2d\u6ca1\u6709\u76ee\u6807\uff0c\u5219\u4e0d\u9700\u8981*.txt\u6587\u4ef6\uff09\u3002 *.txt\u6587\u4ef6\u89c4\u8303\u5982\u4e0b\u6240\u793a: - \u6bcf\u4e00\u884c \u4e00\u4e2a\u76ee\u6807\u3002 - \u6bcf\u4e00\u884c\u662f class x_center y_center width height \u683c\u5f0f\u3002 - \u6846\u5750\u6807\u5fc5\u987b\u91c7\u7528\u6807\u51c6\u5316xywh\u683c\u5f0f\uff08\u4ece0\u52301\uff09\u3002\u5982\u679c\u6846\u4ee5\u50cf\u7d20\u4e3a\u5355\u4f4d\uff0c\u5219\u5c06x_center\u548cwidth\u9664\u4ee5\u56fe\u50cf\u5bbd\u5ea6\uff0c\u5c06y_centre\u548cheight\u9664\u4ee5\u56fe\u50cf\u9ad8\u5ea6\u3002 - \u7c7b\u53f7\u4e3a\u96f6\u7d22\u5f15\u7684\u7f16\u53f7\uff08\u4ece0\u5f00\u59cb\u8ba1\u6570\uff09\u3002 **\u8fd9\u91cc\u5047\u8bbe\u4ee5 COCO \u6570\u636e\u96c6\u7684\u76ee\u6807\u7c7b\u522b\u7ea6\u5b9a\u6765\u6807\u6ce8** \u4e0e\u4e0a\u8ff0\u56fe\u50cf\u76f8\u5bf9\u5e94\u7684\u6807\u7b7e\u6587\u4ef6\u5305\u542b2\u4e2a\u4eba\uff08class 0\uff09\u548c \u4e00\u4e2a\u9886\u5e26\uff08class 27\uff09\uff1a 3.COCO128 \u6570\u636e\u96c6\u76ee\u5f55\u7ed3\u6784\u7ec4\u7ec7 \u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u4eec\u7684 coco128 \u662f\u4f4d\u4e8e yolov5 \u76ee\u5f55\u9644\u8fd1\u3002yolov5 \u901a\u8fc7\u5c06\u6bcf\u4e2a\u56fe\u50cf\u8def\u5f84 xx/images/xx.jpg \u66ff\u6362\u4e3a xx/labels/xx.txt \u6765\u81ea\u52a8\u5b9a\u4f4d\u6bcf\u4e2a\u56fe\u50cf\u7684\u6807\u7b7e\u3002\u4f8b\u5982\uff1a dataset / images / im0 . jpg # image dataset / labels / im0 . txt # label \u5236\u4f5c\u6570\u636e\u96c6 \u6570\u636e\u96c6\u6807\u6ce8\u5de5\u5177 \u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd LabelImg: \u662f\u4e00\u79cd\u77e9\u5f62\u6807\u6ce8\u5de5\u5177\uff0c\u5e38\u7528\u4e8e\u76ee\u6807\u8bc6\u522b\u548c\u76ee\u6807\u68c0\u6d4b,\u53ef\u76f4\u63a5\u751f\u6210 yolov5 \u8bfb\u53d6\u7684txt\u6807\u7b7e\u683c\u5f0f\uff0c\u4f46\u5176\u53ea\u80fd\u8fdb\u884c\u77e9\u5f62\u6846\u6807\u6ce8\u3002(\u5f53\u7136\u4e5f\u53ef\u4ee5\u9009\u7528\u5176\u5b83\u7684\u5de5\u5177\u8fdb\u884c\u6807\u6ce8\u5e76\u4e14\u7f51\u4e0a\u90fd\u6709\u5927\u91cf\u5173\u4e8e\u6807\u6ce8\u5de5\u5177\u7684\u6559\u7a0b\u3002) \u9996\u5148labelimg\u7684\u5b89\u88c5\u5341\u5206\u7b80\u5355\uff0c\u76f4\u63a5\u4f7f\u7528cmd\u4e2d\u7684pip\u8fdb\u884c\u5b89\u88c5\uff0c\u5728cmd\u4e2d\u8f93\u5165\u547d\u4ee4\u884c\uff1a pip install labelimg \u5b89\u88c5\u540e\u76f4\u63a5\u8f93\u5165\u547d\u4ee4\uff1a labelimg \u5373\u53ef\u6253\u5f00\u8fd0\u884c\u3002 \u70b9\u51fbOpen Dir\u9009\u62e9\u6570\u636e\u96c6\u6587\u4ef6\u5939\uff0c\u518d\u70b9\u51fbCreate RectBox\u8fdb\u884c\u6807\u6ce8\u3002 \u5f53\u4f60\u7ed8\u5236\u6846\u7ed3\u675f\u5c31\u4f1a\u5f39\u51fa\u6807\u7b7e\u9009\u62e9\u6846\uff0c\u7136\u540e\u6807\u6ce8\u7c7b\u522b\u3002\u8fd9\u4e2a\u7c7b\u522b\u7f16\u8f91\u66f4\u6539\u5728Labelimg\u6587\u4ef6\u91cc\uff0c\u91cc\u9762\u6709classes.txt\u6587\u6863\uff0c\u6253\u5f00\u624b\u52a8\u66f4\u6539\u7c7b\u522b\u5373\u53ef\u3002\uff08\u5f53\u51fa\u73b0\u65b0\u7c7b\u522b\u65f6\u4e5f\u53ef\u5728\u6807\u7b7e\u9009\u62e9\u6846\u91cc\u8f93\u5165\u70b9OK\u5c31\u81ea\u52a8\u6dfb\u52a0\u7c7b\u522b\u4e86\uff09 \u6807\u6ce8\u597d\u540e\u9009\u62e9 yolo \u683c\u5f0f\uff0c\u70b9\u51fb Save \u4fdd\u5b58\u3002\u6807\u6ce8\u7ed3\u679c\u4fdd\u5b58\u5728 \u56fe\u7247\u540d.txt \u6587\u4ef6\u4e2d\uff0ctxt\u6587\u4ef6\u548c\u56fe\u7247\u540d\u79f0\u4e00\u81f4\uff0c\u5185\u5bb9\u5982\u4e0b\uff1a \u4e00\u4e2a\u597d\u7684\u6570\u636e\u96c6\u6807\u51c6\uff1f \u6bcf\u4e2a\u7c7b\u7684\u56fe\u50cf\u3002 >= 1500 \u5f20\u56fe\u7247\u3002 \u6bcf\u4e2a\u7c7b\u7684\u5b9e\u4f8b\u3002\u2265 \u5efa\u8bae\u6bcf\u4e2a\u7c7b10000\u4e2a\u5b9e\u4f8b\uff08\u6807\u8bb0\u5bf9\u8c61\uff09 \u56fe\u7247\u5f62\u8c61\u591a\u6837\u3002\u5fc5\u987b\u4ee3\u8868\u5df2\u90e8\u7f72\u7684\u73af\u5883\u3002\u5bf9\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u4f7f\u7528\u6848\u4f8b\uff0c\u6211\u4eec\u63a8\u8350\u6765\u81ea\u4e00\u5929\u4e2d\u4e0d\u540c\u65f6\u95f4\u3001\u4e0d\u540c\u5b63\u8282\u3001\u4e0d\u540c\u5929\u6c14\u3001\u4e0d\u540c\u7167\u660e\u3001\u4e0d\u540c\u89d2\u5ea6\u3001\u4e0d\u540c\u6765\u6e90\uff08\u5728\u7ebf\u91c7\u96c6\u3001\u672c\u5730\u91c7\u96c6\u3001\u4e0d\u540c\u6444\u50cf\u673a\uff09\u7b49\u7684\u56fe\u50cf\u3002 \u6807\u7b7e\u4e00\u81f4\u6027\u3002\u5fc5\u987b\u6807\u8bb0\u6240\u6709\u56fe\u50cf\u4e2d\u6240\u6709\u7c7b\u7684\u6240\u6709\u5b9e\u4f8b\u3002\u90e8\u5206\u6807\u8bb0\u5c06\u4e0d\u8d77\u4f5c\u7528\u3002 \u6807\u7b7e\u51c6\u786e\u6027\u3002 \u6807\u7b7e\u5fc5\u987b\u7d27\u5bc6\u5730\u5305\u56f4\u6bcf\u4e2a\u5bf9\u8c61\u3002\u5bf9\u8c61\u4e0e\u5176\u8fb9\u754c\u6846\u4e4b\u95f4\u4e0d\u5e94\u5b58\u5728\u4efb\u4f55\u7a7a\u95f4\u3002\u4efb\u4f55\u5bf9\u8c61\u90fd\u4e0d\u5e94\u7f3a\u5c11\u6807\u7b7e\u3002 \u6807\u7b7e\u9a8c\u8bc1\u3002\u67e5\u770btrain_batch .jpg \u5728 \u8bad\u7ec3\u5f00\u59cb\u9a8c\u8bc1\u6807\u7b7e\u662f\u5426\u6b63\u786e\uff0c\u5373\u53c2\u89c1 mosaic \uff08\u5728 yolov5 \u7684\u8bad\u7ec3\u65e5\u5fd7 runs/train/exp \u6587\u4ef6\u5939\u91cc\u9762\u53ef\u4ee5\u770b\u5230\uff09\u3002 \u80cc\u666f\u56fe\u50cf\u3002\u80cc\u666f\u56fe\u50cf\u662f\u6ca1\u6709\u6dfb\u52a0\u5230\u6570\u636e\u96c6\u4ee5\u51cf\u5c11 False Positives\uff08FP\uff09\u7684\u5bf9\u8c61\u7684\u56fe\u50cf\u3002\u6211\u4eec\u5efa\u8bae\u4f7f\u7528\u5927\u7ea60-10%\u7684\u80cc\u666f\u56fe\u50cf\u6765\u5e2e\u52a9\u51cf\u5c11FPs\uff08COCO\u67091000\u4e2a\u80cc\u666f\u56fe\u50cf\u4f9b\u53c2\u8003\uff0c\u5360\u603b\u6570\u76841%\uff09\u3002\u80cc\u666f\u56fe\u50cf\u4e0d\u9700\u8981\u6807\u7b7e\u3002 \u4e0b\u56fe\u5c55\u793a\u4e86\u591a\u79cd\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7279\u70b9\uff1a \u5176\u4e2d\uff1a Instances per category \u8868\u793a\u6bcf\u4e2a\u7c7b\u522b\u7684\u5b9e\u4f8b\u6570 Categories per image \u8868\u793a\u6bcf\u5e45\u56fe\u50cf\u7684\u7c7b\u522b (a) Instances per image \u8868\u793a\u6bcf\u5e45\u56fe\u50cf\u7684\u5b9e\u4f8b\u6570 (b) Number of categories vs. number of instances \u8868\u793a\u7c7b\u522b\u6570\u76ee vs \u5b9e\u4f8b\u6570\u76ee \uff08\u6211\u4eec\u53ef\u4ee5\u770b\u5230 COCO \u6570\u636e\u96c6\u7684\u7c7b\u522b\u548c\u5b9e\u4f8b\u7684\u6570\u76ee\u8fbe\u5230\u4e86\u4e00\u4e2a\u8f83\u597d\u7684\u5e73\u8861\uff09 (c) Instance size \u8868\u793a\u5b9e\u4f8b\u4e2a\u6570 (d) Number of categories \u8868\u793a\u7c7b\u522b\u6570 (e) Percent of image size \u8868\u793a\u56fe\u50cf\u5927\u5c0f\u767e\u5206\u6bd4 \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results https://docs.ultralytics.com/tutorials/train-custom-datasets/#weights-biases-logging-new","title":"2.1. \u5982\u4f55\u51c6\u5907YOLOv5\u6a21\u578b\u8bad\u7ec3\u6570\u636e"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u672c\u6587\u4e3b\u8981\u4ecb\u7ecd one-yolov5 \u4f7f\u7528\u7684\u6570\u636e\u96c6\u7684\u683c\u5f0f\u4ee5\u53ca\u5982\u4f55\u5236\u4f5c\u4e00\u4e2a\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u8bad\u7ec3\u6548\u679c\u7684\u6570\u636e\u96c6\u3002\u672c\u8282\u6559\u7a0b\u597d\u7684\u6570\u636e\u96c6\u6807\u51c6\u90e8\u5206\u7ffb\u8bd1\u4e86 ultralytics/yolov5 wiki \u4e2d \u5bf9\u6570\u636e\u96c6\u76f8\u5173\u7684\u63cf\u8ff0 \u3002","title":"\u524d\u8a00"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_2","text":"","title":"\u6570\u636e\u96c6\u7ed3\u6784\u89e3\u8bfb"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#1datasetyaml","text":"COCO128\u662f\u5b98\u65b9\u7ed9\u7684\u4e00\u4e2a\u5c0f\u7684\u6570\u636e\u96c6 \u7531 COCO \u6570\u636e\u96c6\u524d 128 \u5f20\u56fe\u7247\u7ec4\u6210\u3002 \u8fd9128\u5e45\u56fe\u50cf\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\uff0c\u5224\u65ad yolov5 \u811a\u672c\u662f\u5426\u80fd\u591f\u8fc7\u6b63\u5e38\u8fdb\u884c\u3002 \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6 coco128.yaml \u5b9a\u4e49\u4e86\u5982\u4e0b\u7684\u914d\u7f6e\u9009\u9879\uff1a # YOLOv5 \ud83d\ude80 by Ultralytics, GPL-3.0 license # COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics # Example usage: python train.py --data coco128.yaml # parent # \u251c\u2500\u2500 one-yolov5 # \u2514\u2500\u2500 datasets # \u2514\u2500\u2500 coco128 \u2190 downloads here (7 MB) # train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/] # \u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u76f8\u540c train: ../coco128/images/train2017/ val: ../coco128/images/train2017/ # number of classes nc: 80 # \u7c7b\u522b\u6570 # class names \u7c7b\u540d\u5217\u8868 names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'] # Download script/URL (optional) \u7528\u4e8e\u81ea\u52a8\u4e0b\u8f7d\u7684\u53ef\u9009\u4e0b\u8f7d\u547d\u4ee4/URL \u3002 download: https://ultralytics.com/assets/coco128.zip \u6ce8\u610f\uff1a\u5982\u679c\u662f\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u7684\u8bdd\u6309\u81ea\u5df1\u9700\u6c42\u4fee\u6539\u8fd9\u4e2ayaml\u6587\u4ef6\u3002\u4e3b\u8981\u4fee\u6539\u4ee5\u4e0b\u4e24\u70b9\u3002 1. \u4fee\u6539\u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u4e3a\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u8def\u5f84 2. \u4fee\u6539\u7c7b\u522b\u6570\u548c\u7c7b\u540d\u5217\u8868 \u518d\u5c55\u793a\u4e00\u4e0b coco.yaml \u7684\u6570\u636e\u96c6\u8def\u5f84\u914d\u7f6e\uff0c\u8fd9\u91cc\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u56fe\u50cf\u7684\u8def\u5f84\u5c31\u662f\u76f4\u63a5\u7528txt\u8868\u793a\uff1a","title":"1.\u521b\u5efadataset.yaml"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#2-labels","text":"\u4f7f\u7528\u5de5\u5177\u4f8b\u5982 CVAT , makesense.ai , Labelbox \uff0cLabelImg(\u5728\u672c\u7ae0\u5982\u4f55\u5236\u4f5c\u6570\u636e\u96c6\u4e2d\u4ecb\u7ecdLabelImg\u5de5\u5177\u4f7f\u7528) \u7b49\uff0c\u5728\u4f60\u81ea\u5df1\u7684\u6570\u636e\u96c6\u63d0\u4f9b\u7684\u56fe\u7247\u4e0a\u505a\u76ee\u6807\u6846\u7684\u6807\u6ce8\uff0c\u5c06\u6807\u6ce8\u4fe1\u606f\u5bfc\u51fa\u4e3a\u4e00\u4e2atxt\u540e\u7f00\u7ed3\u5c3e\u7684\u6587\u4ef6\u3002\uff08\u5982\u679c\u56fe\u50cf\u4e2d\u6ca1\u6709\u76ee\u6807\uff0c\u5219\u4e0d\u9700\u8981*.txt\u6587\u4ef6\uff09\u3002 *.txt\u6587\u4ef6\u89c4\u8303\u5982\u4e0b\u6240\u793a: - \u6bcf\u4e00\u884c \u4e00\u4e2a\u76ee\u6807\u3002 - \u6bcf\u4e00\u884c\u662f class x_center y_center width height \u683c\u5f0f\u3002 - \u6846\u5750\u6807\u5fc5\u987b\u91c7\u7528\u6807\u51c6\u5316xywh\u683c\u5f0f\uff08\u4ece0\u52301\uff09\u3002\u5982\u679c\u6846\u4ee5\u50cf\u7d20\u4e3a\u5355\u4f4d\uff0c\u5219\u5c06x_center\u548cwidth\u9664\u4ee5\u56fe\u50cf\u5bbd\u5ea6\uff0c\u5c06y_centre\u548cheight\u9664\u4ee5\u56fe\u50cf\u9ad8\u5ea6\u3002 - \u7c7b\u53f7\u4e3a\u96f6\u7d22\u5f15\u7684\u7f16\u53f7\uff08\u4ece0\u5f00\u59cb\u8ba1\u6570\uff09\u3002 **\u8fd9\u91cc\u5047\u8bbe\u4ee5 COCO \u6570\u636e\u96c6\u7684\u76ee\u6807\u7c7b\u522b\u7ea6\u5b9a\u6765\u6807\u6ce8** \u4e0e\u4e0a\u8ff0\u56fe\u50cf\u76f8\u5bf9\u5e94\u7684\u6807\u7b7e\u6587\u4ef6\u5305\u542b2\u4e2a\u4eba\uff08class 0\uff09\u548c \u4e00\u4e2a\u9886\u5e26\uff08class 27\uff09\uff1a","title":"2.\u521b\u5efa Labels"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#3coco128","text":"\u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u4eec\u7684 coco128 \u662f\u4f4d\u4e8e yolov5 \u76ee\u5f55\u9644\u8fd1\u3002yolov5 \u901a\u8fc7\u5c06\u6bcf\u4e2a\u56fe\u50cf\u8def\u5f84 xx/images/xx.jpg \u66ff\u6362\u4e3a xx/labels/xx.txt \u6765\u81ea\u52a8\u5b9a\u4f4d\u6bcf\u4e2a\u56fe\u50cf\u7684\u6807\u7b7e\u3002\u4f8b\u5982\uff1a dataset / images / im0 . jpg # image dataset / labels / im0 . txt # label","title":"3.COCO128 \u6570\u636e\u96c6\u76ee\u5f55\u7ed3\u6784\u7ec4\u7ec7"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_3","text":"","title":"\u5236\u4f5c\u6570\u636e\u96c6"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_4","text":"\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd LabelImg: \u662f\u4e00\u79cd\u77e9\u5f62\u6807\u6ce8\u5de5\u5177\uff0c\u5e38\u7528\u4e8e\u76ee\u6807\u8bc6\u522b\u548c\u76ee\u6807\u68c0\u6d4b,\u53ef\u76f4\u63a5\u751f\u6210 yolov5 \u8bfb\u53d6\u7684txt\u6807\u7b7e\u683c\u5f0f\uff0c\u4f46\u5176\u53ea\u80fd\u8fdb\u884c\u77e9\u5f62\u6846\u6807\u6ce8\u3002(\u5f53\u7136\u4e5f\u53ef\u4ee5\u9009\u7528\u5176\u5b83\u7684\u5de5\u5177\u8fdb\u884c\u6807\u6ce8\u5e76\u4e14\u7f51\u4e0a\u90fd\u6709\u5927\u91cf\u5173\u4e8e\u6807\u6ce8\u5de5\u5177\u7684\u6559\u7a0b\u3002) \u9996\u5148labelimg\u7684\u5b89\u88c5\u5341\u5206\u7b80\u5355\uff0c\u76f4\u63a5\u4f7f\u7528cmd\u4e2d\u7684pip\u8fdb\u884c\u5b89\u88c5\uff0c\u5728cmd\u4e2d\u8f93\u5165\u547d\u4ee4\u884c\uff1a pip install labelimg \u5b89\u88c5\u540e\u76f4\u63a5\u8f93\u5165\u547d\u4ee4\uff1a labelimg \u5373\u53ef\u6253\u5f00\u8fd0\u884c\u3002 \u70b9\u51fbOpen Dir\u9009\u62e9\u6570\u636e\u96c6\u6587\u4ef6\u5939\uff0c\u518d\u70b9\u51fbCreate RectBox\u8fdb\u884c\u6807\u6ce8\u3002 \u5f53\u4f60\u7ed8\u5236\u6846\u7ed3\u675f\u5c31\u4f1a\u5f39\u51fa\u6807\u7b7e\u9009\u62e9\u6846\uff0c\u7136\u540e\u6807\u6ce8\u7c7b\u522b\u3002\u8fd9\u4e2a\u7c7b\u522b\u7f16\u8f91\u66f4\u6539\u5728Labelimg\u6587\u4ef6\u91cc\uff0c\u91cc\u9762\u6709classes.txt\u6587\u6863\uff0c\u6253\u5f00\u624b\u52a8\u66f4\u6539\u7c7b\u522b\u5373\u53ef\u3002\uff08\u5f53\u51fa\u73b0\u65b0\u7c7b\u522b\u65f6\u4e5f\u53ef\u5728\u6807\u7b7e\u9009\u62e9\u6846\u91cc\u8f93\u5165\u70b9OK\u5c31\u81ea\u52a8\u6dfb\u52a0\u7c7b\u522b\u4e86\uff09 \u6807\u6ce8\u597d\u540e\u9009\u62e9 yolo \u683c\u5f0f\uff0c\u70b9\u51fb Save \u4fdd\u5b58\u3002\u6807\u6ce8\u7ed3\u679c\u4fdd\u5b58\u5728 \u56fe\u7247\u540d.txt \u6587\u4ef6\u4e2d\uff0ctxt\u6587\u4ef6\u548c\u56fe\u7247\u540d\u79f0\u4e00\u81f4\uff0c\u5185\u5bb9\u5982\u4e0b\uff1a","title":"\u6570\u636e\u96c6\u6807\u6ce8\u5de5\u5177"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_5","text":"\u6bcf\u4e2a\u7c7b\u7684\u56fe\u50cf\u3002 >= 1500 \u5f20\u56fe\u7247\u3002 \u6bcf\u4e2a\u7c7b\u7684\u5b9e\u4f8b\u3002\u2265 \u5efa\u8bae\u6bcf\u4e2a\u7c7b10000\u4e2a\u5b9e\u4f8b\uff08\u6807\u8bb0\u5bf9\u8c61\uff09 \u56fe\u7247\u5f62\u8c61\u591a\u6837\u3002\u5fc5\u987b\u4ee3\u8868\u5df2\u90e8\u7f72\u7684\u73af\u5883\u3002\u5bf9\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u4f7f\u7528\u6848\u4f8b\uff0c\u6211\u4eec\u63a8\u8350\u6765\u81ea\u4e00\u5929\u4e2d\u4e0d\u540c\u65f6\u95f4\u3001\u4e0d\u540c\u5b63\u8282\u3001\u4e0d\u540c\u5929\u6c14\u3001\u4e0d\u540c\u7167\u660e\u3001\u4e0d\u540c\u89d2\u5ea6\u3001\u4e0d\u540c\u6765\u6e90\uff08\u5728\u7ebf\u91c7\u96c6\u3001\u672c\u5730\u91c7\u96c6\u3001\u4e0d\u540c\u6444\u50cf\u673a\uff09\u7b49\u7684\u56fe\u50cf\u3002 \u6807\u7b7e\u4e00\u81f4\u6027\u3002\u5fc5\u987b\u6807\u8bb0\u6240\u6709\u56fe\u50cf\u4e2d\u6240\u6709\u7c7b\u7684\u6240\u6709\u5b9e\u4f8b\u3002\u90e8\u5206\u6807\u8bb0\u5c06\u4e0d\u8d77\u4f5c\u7528\u3002 \u6807\u7b7e\u51c6\u786e\u6027\u3002 \u6807\u7b7e\u5fc5\u987b\u7d27\u5bc6\u5730\u5305\u56f4\u6bcf\u4e2a\u5bf9\u8c61\u3002\u5bf9\u8c61\u4e0e\u5176\u8fb9\u754c\u6846\u4e4b\u95f4\u4e0d\u5e94\u5b58\u5728\u4efb\u4f55\u7a7a\u95f4\u3002\u4efb\u4f55\u5bf9\u8c61\u90fd\u4e0d\u5e94\u7f3a\u5c11\u6807\u7b7e\u3002 \u6807\u7b7e\u9a8c\u8bc1\u3002\u67e5\u770btrain_batch .jpg \u5728 \u8bad\u7ec3\u5f00\u59cb\u9a8c\u8bc1\u6807\u7b7e\u662f\u5426\u6b63\u786e\uff0c\u5373\u53c2\u89c1 mosaic \uff08\u5728 yolov5 \u7684\u8bad\u7ec3\u65e5\u5fd7 runs/train/exp \u6587\u4ef6\u5939\u91cc\u9762\u53ef\u4ee5\u770b\u5230\uff09\u3002 \u80cc\u666f\u56fe\u50cf\u3002\u80cc\u666f\u56fe\u50cf\u662f\u6ca1\u6709\u6dfb\u52a0\u5230\u6570\u636e\u96c6\u4ee5\u51cf\u5c11 False Positives\uff08FP\uff09\u7684\u5bf9\u8c61\u7684\u56fe\u50cf\u3002\u6211\u4eec\u5efa\u8bae\u4f7f\u7528\u5927\u7ea60-10%\u7684\u80cc\u666f\u56fe\u50cf\u6765\u5e2e\u52a9\u51cf\u5c11FPs\uff08COCO\u67091000\u4e2a\u80cc\u666f\u56fe\u50cf\u4f9b\u53c2\u8003\uff0c\u5360\u603b\u6570\u76841%\uff09\u3002\u80cc\u666f\u56fe\u50cf\u4e0d\u9700\u8981\u6807\u7b7e\u3002 \u4e0b\u56fe\u5c55\u793a\u4e86\u591a\u79cd\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7279\u70b9\uff1a \u5176\u4e2d\uff1a Instances per category \u8868\u793a\u6bcf\u4e2a\u7c7b\u522b\u7684\u5b9e\u4f8b\u6570 Categories per image \u8868\u793a\u6bcf\u5e45\u56fe\u50cf\u7684\u7c7b\u522b (a) Instances per image \u8868\u793a\u6bcf\u5e45\u56fe\u50cf\u7684\u5b9e\u4f8b\u6570 (b) Number of categories vs. number of instances \u8868\u793a\u7c7b\u522b\u6570\u76ee vs \u5b9e\u4f8b\u6570\u76ee \uff08\u6211\u4eec\u53ef\u4ee5\u770b\u5230 COCO \u6570\u636e\u96c6\u7684\u7c7b\u522b\u548c\u5b9e\u4f8b\u7684\u6570\u76ee\u8fbe\u5230\u4e86\u4e00\u4e2a\u8f83\u597d\u7684\u5e73\u8861\uff09 (c) Instance size \u8868\u793a\u5b9e\u4f8b\u4e2a\u6570 (d) Number of categories \u8868\u793a\u7c7b\u522b\u6570 (e) Percent of image size \u8868\u793a\u56fe\u50cf\u5927\u5c0f\u767e\u5206\u6bd4","title":"\u4e00\u4e2a\u597d\u7684\u6570\u636e\u96c6\u6807\u51c6\uff1f"},{"location":"tutorials/02_chapter/how_to_prepare_yolov5_training_data.html#_6","text":"https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results https://docs.ultralytics.com/tutorials/train-custom-datasets/#weights-biases-logging-new","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/03_chapter/TTA.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u4f60\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6d4b\u8bd5\u65f6\u6570\u636e\u589e\u5f3a \ud83d\ude80 \ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5728YOLOv5\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u63a8\u7406\u4e2d\u5982\u4f55\u4f7f\u7528 Test Time Augmentation (TTA) \u63d0\u9ad8mAP\u548cRecall \ud83d\ude80\u3002 \ud83d\udccc\u5f00\u59cb\u4e4b\u524d \u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install \ud83d\udccc\u666e\u901a\u6d4b\u8bd5 \u5728\u5c1d\u8bd5 TTA \u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u80fd\u591f\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u547d\u4ee4\u5728COCO val2017\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5YOLOv5x\u3002 yolov5x \u662f\u53ef\u7528\u7684\u6700\u5927\u5e76\u4e14\u6700\u7cbe\u786e\u7684\u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u7684\u662f yolov5s , yolov5m \u548c yolov5l \u6216\u8005 \u81ea\u5df1\u4ece\u6570\u636e\u96c6\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u3002 ./weights/best \u3002\u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 READEME table $ python val . py -- weights yolov5x -- data coco . yaml -- img 640 -- half \ud83d\udce2 \u8f93\u51fa: val: data = data/coco.yaml, weights =[ 'yolov5x' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = True, dnn = False YOLOv5 \ud83d\ude80 v1.0-8-g94ec5c4 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 01 :55< 00 :00, 1 .36it/ all 5000 36335 0 .743 0 .627 0 .685 0 .503 Speed: 0 .1ms pre-process, 7 .5ms inference, 2 .1ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json... ... Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0 .50 | area = all | maxDets = 100 ] = 0 .689 Average Precision ( AP ) @ [ IoU = 0 .75 | area = all | maxDets = 100 ] = 0 .545 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .339 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .557 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .650 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 1 ] = 0 .382 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 10 ] = 0 .628 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .523 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .730 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .826 \ud83d\udcccTTA\u6d4b\u8bd5 \u5728val.py \u540e\u9644\u52a0 --augment \u9009\u9879\u542f\u7528TTA\u3002( \u5c06\u56fe\u50cf\u5927\u5c0f\u589e\u52a0\u7ea630%\u5de6\u53f3\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7ed3\u679c\u54e6 \ud83d\ude80)\u3002 \u2757\u8bf7\u6ce8\u610f: \u542f\u7528TTA\u7684\u63a8\u65ad\u901a\u5e38\u9700\u8981\u6b63\u5e38\u63a8\u65ad\u65f6\u95f4\u76842-3\u500d\uff0c\u56e0\u4e3a\u56fe\u50cf\u5de6\u53f3\u7ffb\u8f6c\u5e76\u4ee53\u79cd\u4e0d\u540c\u5206\u8fa8\u7387\u5904\u7406\uff0c\u8f93\u51fa\u5728NMS\u4e4b\u524d\u5408\u5e76\u3002 \u901f\u5ea6\u4e0b\u964d\u7684\u90e8\u5206\u539f\u56e0\u662f\u56fe\u50cf\u5c3a\u5bf8\u8f83\u5927\uff08832 vs 640\uff09\uff0c\u5f53\u7136\u4e5f\u6709\u90e8\u5206\u539f\u56e0\u662f TTA \u64cd\u4f5c\u9020\u6210\u7684\u3002 $ python val . py -- weights yolov5x -- data coco . yaml -- img 832 -- augment -- half \u8f93\u51fa: ( python3 .8 ) fengwen @oneflow - 25 : ~/ one - yolov5 $ python val . py -- weights yolov5x -- data data / coco . yaml -- img 832 -- augment -- half loaded library : / lib / x86_64 - linux - gnu / libibverbs . so .1 val : data = data / coco . yaml , weights = [ 'yolov5x' ], batch_size = 32 , imgsz = 832 , conf_thres = 0.001 , iou_thres = 0.6 , task = val , device = , workers = 8 , single_cls = False , augment = True , verbose = False , save_txt = False , save_hybrid = False , save_conf = False , save_json = True , project = runs / val , name = exp , exist_ok = False , half = True , dnn = False YOLOv5 \ud83d\ude80 v1 .0 - 31 - g6b1387c Python - 3.8.13 oneflow - 0.8.1 . dev20221021 + cu112 Fusing layers ... Model summary : 322 layers , 86705005 parameters , 571965 gradients val : Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels ... 4952 found , 48 missing , 0 empty , 0 corrupt : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | Class Images Labels P R mAP @ .5 mAP @ .5 : .95 : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 / 157 [ 04 : 39 < 00 : 00 , 1.78 s / it ] all 5000 36335 0.743 0.645 0.7 0.518 Speed : 0.1 ms pre - process , 40.6 ms inference , 2.2 ms NMS per image at shape ( 32 , 3 , 832 , 832 ) Evaluating pycocotools mAP ... saving runs / val / exp / yolov5x_predictions . json ... ... Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.519 # <--- TTA mAP Average Precision ( AP ) @ [ IoU = 0.50 | area = all | maxDets = 100 ] = 0.704 Average Precision ( AP ) @ [ IoU = 0.75 | area = all | maxDets = 100 ] = 0.564 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.358 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.565 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.662 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 1 ] = 0.389 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 10 ] = 0.645 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.698 # <--- TTA mAR Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.556 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.745 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.837 \ud83d\udce2 \u58f0\u660e:\u4e0a\u8ff0\u4e24\u6b21\u6d4b\u8bd5\u7684mAP\uff0cmAR\u7ed3\u679c\u5982\u4e0b\uff1a | | mAP | mAR | |----------|-------|-------| | baseline | 0.505 | 0.677 | | TTA | 0.519 | 0.698 | \ud83d\udcccTTA\u63a8\u7406 \u5728 detect.py \u4e2d\u4f7f\u7528 TTA \u7684\u64cd\u4f5c\u4e0e val.py \u4e2d\u4f7f\u7528TTA\u76f8\u540c\uff1a\u53ea\u9700\u5c06\u5176\u9644\u52a0 --augment \u5230\u4efb\u4f55\u73b0\u6709\u68c0\u6d4b\u4efb\u52a1\u4e2d\u3002 detect.py \u6307\u4ee4\u300c\u6848\u4f8b\ud83c\udf30\u300d: $ python detect . py -- weights yolov5s -- img 832 -- source data / images -- augment \u8f93\u51fa: loaded library: /lib/x86_64-linux-gnu/libibverbs.so.1 detect: weights=['yolov5x'], source=data/images/, data=data/coco128.yaml, imgsz=[832, 832], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=True, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 v1.0-31-g6b1387c Python-3.8.13 oneflow-0.8.1.dev20221021+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/fengwen/one-yolov5/data/images/bus.jpg: 832x640 4 persons, 1 bicycle, 1 bus, Done. (0.057s) detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 2/2 /home/fengwen/one-yolov5/data/images/zidane.jpg: 480x832 3 persons, 2 ties, Done. (0.041s) 0.5ms pre-process, 48.6ms inference, 2.1ms NMS per image at shape (1, 3, 832, 832) OneFlow Hub TTA TTA\u81ea\u52a8\u96c6\u6210\u5230\u6240\u6709YOLOv5 OneFlow Hub\u6a21\u578b\u4e2d\uff0c\u5e76\u53ef\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u4f20\u9012 augment=True \u53c2\u6570\u8fdb\u884c\u5f00\u542f\u3002 import oneflow as flow # \u6a21\u578b model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # or yolov5n - yolov5x6, custom # \u56fe\u50cf img = 'https://raw.githubusercontent.com/Oneflow-Inc/one-yolov5/main/data/images/zidane.jpg' # or file, Path, PIL, OpenCV, numpy, list # \u63a8\u7406 results = model ( img ) # \u7ed3\u679c results . print () # or .show(), .save(), .crop(), .pandas(), etc. \u81ea\u5b9a\u4e49 \u6211\u4eec\u53ef\u4ee5\u81ea\u5b9a\u4e49TTA\u64cd\u4f5c\u5728 YOLOv5 forward_augment() \u65b9\u6cd5\u4e2d, \u5e94\u7528\u7684TTA\u64cd\u4f5c\u7ec6\u8282\u5177\u4f53\u53ef\u89c1\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/bbdf286ad1b1d3fd2c82cecdfa4487db423d9cfe/models/yolo.py#L141-L153 \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/issues/303","title":"3.3 \u6d4b\u8bd5\u65f6\u589e\u5f3a (TTA)"},{"location":"tutorials/03_chapter/TTA.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u4f60\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"\u524d\u8a00"},{"location":"tutorials/03_chapter/TTA.html#_2","text":"\ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5728YOLOv5\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u63a8\u7406\u4e2d\u5982\u4f55\u4f7f\u7528 Test Time Augmentation (TTA) \u63d0\u9ad8mAP\u548cRecall \ud83d\ude80\u3002","title":"\u6d4b\u8bd5\u65f6\u6570\u636e\u589e\u5f3a \ud83d\ude80"},{"location":"tutorials/03_chapter/TTA.html#_3","text":"\u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install","title":"\ud83d\udccc\u5f00\u59cb\u4e4b\u524d"},{"location":"tutorials/03_chapter/TTA.html#_4","text":"\u5728\u5c1d\u8bd5 TTA \u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u80fd\u591f\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u547d\u4ee4\u5728COCO val2017\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5YOLOv5x\u3002 yolov5x \u662f\u53ef\u7528\u7684\u6700\u5927\u5e76\u4e14\u6700\u7cbe\u786e\u7684\u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u7684\u662f yolov5s , yolov5m \u548c yolov5l \u6216\u8005 \u81ea\u5df1\u4ece\u6570\u636e\u96c6\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u3002 ./weights/best \u3002\u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 READEME table $ python val . py -- weights yolov5x -- data coco . yaml -- img 640 -- half \ud83d\udce2 \u8f93\u51fa: val: data = data/coco.yaml, weights =[ 'yolov5x' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = True, dnn = False YOLOv5 \ud83d\ude80 v1.0-8-g94ec5c4 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 01 :55< 00 :00, 1 .36it/ all 5000 36335 0 .743 0 .627 0 .685 0 .503 Speed: 0 .1ms pre-process, 7 .5ms inference, 2 .1ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json... ... Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0 .50 | area = all | maxDets = 100 ] = 0 .689 Average Precision ( AP ) @ [ IoU = 0 .75 | area = all | maxDets = 100 ] = 0 .545 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .339 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .557 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .650 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 1 ] = 0 .382 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 10 ] = 0 .628 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .523 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .730 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .826","title":"\ud83d\udccc\u666e\u901a\u6d4b\u8bd5"},{"location":"tutorials/03_chapter/TTA.html#tta","text":"\u5728val.py \u540e\u9644\u52a0 --augment \u9009\u9879\u542f\u7528TTA\u3002( \u5c06\u56fe\u50cf\u5927\u5c0f\u589e\u52a0\u7ea630%\u5de6\u53f3\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7ed3\u679c\u54e6 \ud83d\ude80)\u3002 \u2757\u8bf7\u6ce8\u610f: \u542f\u7528TTA\u7684\u63a8\u65ad\u901a\u5e38\u9700\u8981\u6b63\u5e38\u63a8\u65ad\u65f6\u95f4\u76842-3\u500d\uff0c\u56e0\u4e3a\u56fe\u50cf\u5de6\u53f3\u7ffb\u8f6c\u5e76\u4ee53\u79cd\u4e0d\u540c\u5206\u8fa8\u7387\u5904\u7406\uff0c\u8f93\u51fa\u5728NMS\u4e4b\u524d\u5408\u5e76\u3002 \u901f\u5ea6\u4e0b\u964d\u7684\u90e8\u5206\u539f\u56e0\u662f\u56fe\u50cf\u5c3a\u5bf8\u8f83\u5927\uff08832 vs 640\uff09\uff0c\u5f53\u7136\u4e5f\u6709\u90e8\u5206\u539f\u56e0\u662f TTA \u64cd\u4f5c\u9020\u6210\u7684\u3002 $ python val . py -- weights yolov5x -- data coco . yaml -- img 832 -- augment -- half \u8f93\u51fa: ( python3 .8 ) fengwen @oneflow - 25 : ~/ one - yolov5 $ python val . py -- weights yolov5x -- data data / coco . yaml -- img 832 -- augment -- half loaded library : / lib / x86_64 - linux - gnu / libibverbs . so .1 val : data = data / coco . yaml , weights = [ 'yolov5x' ], batch_size = 32 , imgsz = 832 , conf_thres = 0.001 , iou_thres = 0.6 , task = val , device = , workers = 8 , single_cls = False , augment = True , verbose = False , save_txt = False , save_hybrid = False , save_conf = False , save_json = True , project = runs / val , name = exp , exist_ok = False , half = True , dnn = False YOLOv5 \ud83d\ude80 v1 .0 - 31 - g6b1387c Python - 3.8.13 oneflow - 0.8.1 . dev20221021 + cu112 Fusing layers ... Model summary : 322 layers , 86705005 parameters , 571965 gradients val : Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels ... 4952 found , 48 missing , 0 empty , 0 corrupt : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | Class Images Labels P R mAP @ .5 mAP @ .5 : .95 : 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 / 157 [ 04 : 39 < 00 : 00 , 1.78 s / it ] all 5000 36335 0.743 0.645 0.7 0.518 Speed : 0.1 ms pre - process , 40.6 ms inference , 2.2 ms NMS per image at shape ( 32 , 3 , 832 , 832 ) Evaluating pycocotools mAP ... saving runs / val / exp / yolov5x_predictions . json ... ... Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.519 # <--- TTA mAP Average Precision ( AP ) @ [ IoU = 0.50 | area = all | maxDets = 100 ] = 0.704 Average Precision ( AP ) @ [ IoU = 0.75 | area = all | maxDets = 100 ] = 0.564 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.358 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.565 Average Precision ( AP ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.662 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 1 ] = 0.389 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 10 ] = 0.645 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = all | maxDets = 100 ] = 0.698 # <--- TTA mAR Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = small | maxDets = 100 ] = 0.556 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = medium | maxDets = 100 ] = 0.745 Average Recall ( AR ) @ [ IoU = 0.50 : 0.95 | area = large | maxDets = 100 ] = 0.837 \ud83d\udce2 \u58f0\u660e:\u4e0a\u8ff0\u4e24\u6b21\u6d4b\u8bd5\u7684mAP\uff0cmAR\u7ed3\u679c\u5982\u4e0b\uff1a | | mAP | mAR | |----------|-------|-------| | baseline | 0.505 | 0.677 | | TTA | 0.519 | 0.698 |","title":"\ud83d\udcccTTA\u6d4b\u8bd5"},{"location":"tutorials/03_chapter/TTA.html#tta_1","text":"\u5728 detect.py \u4e2d\u4f7f\u7528 TTA \u7684\u64cd\u4f5c\u4e0e val.py \u4e2d\u4f7f\u7528TTA\u76f8\u540c\uff1a\u53ea\u9700\u5c06\u5176\u9644\u52a0 --augment \u5230\u4efb\u4f55\u73b0\u6709\u68c0\u6d4b\u4efb\u52a1\u4e2d\u3002 detect.py \u6307\u4ee4\u300c\u6848\u4f8b\ud83c\udf30\u300d: $ python detect . py -- weights yolov5s -- img 832 -- source data / images -- augment \u8f93\u51fa: loaded library: /lib/x86_64-linux-gnu/libibverbs.so.1 detect: weights=['yolov5x'], source=data/images/, data=data/coco128.yaml, imgsz=[832, 832], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=True, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 v1.0-31-g6b1387c Python-3.8.13 oneflow-0.8.1.dev20221021+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/fengwen/one-yolov5/data/images/bus.jpg: 832x640 4 persons, 1 bicycle, 1 bus, Done. (0.057s) detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 2/2 /home/fengwen/one-yolov5/data/images/zidane.jpg: 480x832 3 persons, 2 ties, Done. (0.041s) 0.5ms pre-process, 48.6ms inference, 2.1ms NMS per image at shape (1, 3, 832, 832)","title":"\ud83d\udcccTTA\u63a8\u7406"},{"location":"tutorials/03_chapter/TTA.html#oneflow-hub-tta","text":"TTA\u81ea\u52a8\u96c6\u6210\u5230\u6240\u6709YOLOv5 OneFlow Hub\u6a21\u578b\u4e2d\uff0c\u5e76\u53ef\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u4f20\u9012 augment=True \u53c2\u6570\u8fdb\u884c\u5f00\u542f\u3002 import oneflow as flow # \u6a21\u578b model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # or yolov5n - yolov5x6, custom # \u56fe\u50cf img = 'https://raw.githubusercontent.com/Oneflow-Inc/one-yolov5/main/data/images/zidane.jpg' # or file, Path, PIL, OpenCV, numpy, list # \u63a8\u7406 results = model ( img ) # \u7ed3\u679c results . print () # or .show(), .save(), .crop(), .pandas(), etc.","title":"OneFlow Hub TTA"},{"location":"tutorials/03_chapter/TTA.html#_5","text":"\u6211\u4eec\u53ef\u4ee5\u81ea\u5b9a\u4e49TTA\u64cd\u4f5c\u5728 YOLOv5 forward_augment() \u65b9\u6cd5\u4e2d, \u5e94\u7528\u7684TTA\u64cd\u4f5c\u7ec6\u8282\u5177\u4f53\u53ef\u89c1\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/bbdf286ad1b1d3fd2c82cecdfa4487db423d9cfe/models/yolo.py#L141-L153","title":"\u81ea\u5b9a\u4e49"},{"location":"tutorials/03_chapter/TTA.html#_6","text":"https://github.com/ultralytics/yolov5/issues/303","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/03_chapter/intro_to_wandb.html","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u4f60\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u5f15\u8a00 \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 Weights & Biases(W&B) \u6765\u8fdb\u884c\u673a\u5668\u5b66\u4e60\u7684\u5b9e\u9a8c\u8ddf\u8e2a\u3001\u6570\u636e\u96c6\u7248\u672c\u63a7\u5236\u548c\u534f\u4f5c\u3002 \u4eea\u8868\u76d8\u793a\u4f8b \u4e0b\u9762\u662f W&B \u4e2d\u4ea4\u4e92\u5f0f\u4eea\u8868\u76d8\u7684\u4e00\u4e2a\u793a\u4f8b \u6570\u636e & \u9690\u79c1 W&B \u5bf9\u5176\u4e91\u63a7\u5236\u4eea\u8868\u76d8\u8fdb\u884c\u4e86\u5de5\u4e1a\u7ea7\u522b\u7684\u52a0\u5bc6\u3002\u5982\u679c\u60a8\u7684\u6570\u636e\u96c6\u4f4d\u4e8e\u8f83\u654f\u611f\u7684\u73af\u5883\uff08\u5982\u60a8\u7684\u4f01\u4e1a\u5185\u90e8\u96c6\u7fa4\uff09\uff0c\u6211\u4eec\u63a8\u8350\u4f7f\u7528 on-prem \u3002 \u4e0b\u8f7d\u6240\u6709\u6570\u636e\u5e76\u5bfc\u51fa\u5230\u5176\u4ed6\u5de5\u5177\u4e5f\u5f88\u5bb9\u6613\uff0c\u4f8b\u5982\uff0c\u4f7f\u7528Jupyter\u7b14\u8bb0\u672c\u8fdb\u884c\u81ea\u5b9a\u4e49\u5206\u6790\u3002\u7ec6\u8282\u8bf7\u67e5\u9605 W&B \u7684 API \u3002 Weights & Biases (W&B) with One-YOLOv5 \u7b80\u5355\u4e24\u6b65\u5373\u53ef\u5f00\u59cb\u8bb0\u5f55\u673a\u5668\u5b66\u4e60\u5b9e\u9a8c\u3002 1. \u5b89\u88c5\u5e93 pip install wandb 2. \u521b\u5efa\u8d26\u53f7 \u6ce8\u518c\u9875\u6ce8\u518c\u4e00\u4e2a \u514d\u8d39\u8d26\u53f7 \u3002 \u7ec8\u7aef\u8f93\u5165 wandb login \u7ec8\u7aef\u8f93\u5165\u540e\u7c98\u8d34copy\u7684key \u8f93\u5165\u56de\u8f66\u786e\u8ba4 \uff0c\u5927\u529f\u544a\u6210\u3002 \u9a8c\u8bc1 \u4f7f\u7528coco128\u6570\u636e\u96c6 \u5bf9 wandb \u96c6\u6210\u53ef\u89c6\u5316\u6d4b\u8bd5\u7ed3\u679c\u793a\u4f8b \u5728one-yolov5\u4ed3\u5e93\u7684\u6839\u76ee\u5f55\u4e0b \u4f7f\u7528\u6307\u4ee4 python train.py --weights ' ' --data data/coco128.yaml --cfg models/yolov5s.yaml \u6210\u529f\u8fd0\u884c\u793a\u4f8b\u5982\u4e0b: \u901a\u8fc7W&B: \ud83d\ude80 View run at\uff1axxx\u94fe\u63a5\u5373\u53ef\u67e5\u770b W&B\u53ef\u89c6\u5316\u7684\u7ed3\u679c\u3002 \u7ed3\u679c\u62a5\u544a\u793a\u4f8b: \u4f7f\u7528coco128\u6570\u636e\u96c6 \u5bf9 wandb \u96c6\u6210\u53ef\u89c6\u5316\u6d4b\u8bd5\u7ed3\u679c \u5176\u4ed6\u793a\u4f8b \u4f7f\u7528jupyter-notebook \u521b\u5efa\u8d26\u6237 , \u63a5\u7740\u8fd0\u884c\u4ee5\u4e0b\u4ee3\u7801\u5b89\u88c5\"wandb\" \u5305\u5e76\u767b\u5f55\u3002 ! pip install wandb # \u5b89\u88c5 import wandb wandb . login () # \u767b\u9646 \u53ef\u89c6\u5316\u5b9e\u9a8c \u5f00\u59cb\u4f60\u7684\u7b2c\u4e00\u6b21\u53ef\u89c6\u5316\u8bad\u7ec3 \u5f00\u59cb\u4e00\u4e2a\u65b0\u7684\u8bad\u7ec3\uff0c\u5e76\u4f20\u5165\u8d85\u53c2\u6570\u4ee5\u8ddf\u8e2a \u8bb0\u5f55\u6765\u81ea\u8bad\u7ec3\u6216\u8bc4\u4f30\u7684\u6307\u6807 \u5728\u4eea\u8868\u677f\u4e2d\u53ef\u89c6\u5316\u7ed3\u679c import wandb import math import random # Start a new run, tracking hyperparameters in config wandb . init ( project = \"test-drive\" , config = { \"learning_rate\" : 0.01 , \"dropout\" : 0.2 , \"architecture\" : \"CNN\" , \"dataset\" : \"CIFAR-100\" , }) config = wandb . config # Simulating a training or evaluation loop for x in range ( 50 ): acc = math . log ( 1 + x + random . random () * config . learning_rate ) + random . random () + config . dropout loss = 10 - math . log ( 1 + x + random . random () + config . learning_rate * x ) + random . random () + config . dropout # Log metrics from your script to W&B wandb . log ({ \"acc\" : acc , \"loss\" : loss }) wandb . finish ()","title":"3.5 Weights & Biases"},{"location":"tutorials/03_chapter/intro_to_wandb.html#_1","text":"\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 Weights & Biases(W&B) \u6765\u8fdb\u884c\u673a\u5668\u5b66\u4e60\u7684\u5b9e\u9a8c\u8ddf\u8e2a\u3001\u6570\u636e\u96c6\u7248\u672c\u63a7\u5236\u548c\u534f\u4f5c\u3002","title":"\u5f15\u8a00"},{"location":"tutorials/03_chapter/intro_to_wandb.html#_2","text":"\u4e0b\u9762\u662f W&B \u4e2d\u4ea4\u4e92\u5f0f\u4eea\u8868\u76d8\u7684\u4e00\u4e2a\u793a\u4f8b","title":"\u4eea\u8868\u76d8\u793a\u4f8b"},{"location":"tutorials/03_chapter/intro_to_wandb.html#_3","text":"W&B \u5bf9\u5176\u4e91\u63a7\u5236\u4eea\u8868\u76d8\u8fdb\u884c\u4e86\u5de5\u4e1a\u7ea7\u522b\u7684\u52a0\u5bc6\u3002\u5982\u679c\u60a8\u7684\u6570\u636e\u96c6\u4f4d\u4e8e\u8f83\u654f\u611f\u7684\u73af\u5883\uff08\u5982\u60a8\u7684\u4f01\u4e1a\u5185\u90e8\u96c6\u7fa4\uff09\uff0c\u6211\u4eec\u63a8\u8350\u4f7f\u7528 on-prem \u3002 \u4e0b\u8f7d\u6240\u6709\u6570\u636e\u5e76\u5bfc\u51fa\u5230\u5176\u4ed6\u5de5\u5177\u4e5f\u5f88\u5bb9\u6613\uff0c\u4f8b\u5982\uff0c\u4f7f\u7528Jupyter\u7b14\u8bb0\u672c\u8fdb\u884c\u81ea\u5b9a\u4e49\u5206\u6790\u3002\u7ec6\u8282\u8bf7\u67e5\u9605 W&B \u7684 API \u3002","title":"\u6570\u636e &amp; \u9690\u79c1"},{"location":"tutorials/03_chapter/intro_to_wandb.html#weights-biases-wb-with-one-yolov5","text":"\u7b80\u5355\u4e24\u6b65\u5373\u53ef\u5f00\u59cb\u8bb0\u5f55\u673a\u5668\u5b66\u4e60\u5b9e\u9a8c\u3002","title":"Weights &amp; Biases (W&amp;B) with One-YOLOv5"},{"location":"tutorials/03_chapter/intro_to_wandb.html#1","text":"pip install wandb","title":"1. \u5b89\u88c5\u5e93"},{"location":"tutorials/03_chapter/intro_to_wandb.html#2","text":"\u6ce8\u518c\u9875\u6ce8\u518c\u4e00\u4e2a \u514d\u8d39\u8d26\u53f7 \u3002 \u7ec8\u7aef\u8f93\u5165 wandb login \u7ec8\u7aef\u8f93\u5165\u540e\u7c98\u8d34copy\u7684key \u8f93\u5165\u56de\u8f66\u786e\u8ba4 \uff0c\u5927\u529f\u544a\u6210\u3002","title":"2. \u521b\u5efa\u8d26\u53f7"},{"location":"tutorials/03_chapter/intro_to_wandb.html#_4","text":"\u4f7f\u7528coco128\u6570\u636e\u96c6 \u5bf9 wandb \u96c6\u6210\u53ef\u89c6\u5316\u6d4b\u8bd5\u7ed3\u679c\u793a\u4f8b \u5728one-yolov5\u4ed3\u5e93\u7684\u6839\u76ee\u5f55\u4e0b \u4f7f\u7528\u6307\u4ee4 python train.py --weights ' ' --data data/coco128.yaml --cfg models/yolov5s.yaml \u6210\u529f\u8fd0\u884c\u793a\u4f8b\u5982\u4e0b: \u901a\u8fc7W&B: \ud83d\ude80 View run at\uff1axxx\u94fe\u63a5\u5373\u53ef\u67e5\u770b W&B\u53ef\u89c6\u5316\u7684\u7ed3\u679c\u3002 \u7ed3\u679c\u62a5\u544a\u793a\u4f8b: \u4f7f\u7528coco128\u6570\u636e\u96c6 \u5bf9 wandb \u96c6\u6210\u53ef\u89c6\u5316\u6d4b\u8bd5\u7ed3\u679c","title":"\u9a8c\u8bc1"},{"location":"tutorials/03_chapter/intro_to_wandb.html#_5","text":"\u4f7f\u7528jupyter-notebook \u521b\u5efa\u8d26\u6237 , \u63a5\u7740\u8fd0\u884c\u4ee5\u4e0b\u4ee3\u7801\u5b89\u88c5\"wandb\" \u5305\u5e76\u767b\u5f55\u3002 ! pip install wandb # \u5b89\u88c5 import wandb wandb . login () # \u767b\u9646","title":"\u5176\u4ed6\u793a\u4f8b"},{"location":"tutorials/03_chapter/intro_to_wandb.html#_6","text":"\u5f00\u59cb\u4f60\u7684\u7b2c\u4e00\u6b21\u53ef\u89c6\u5316\u8bad\u7ec3 \u5f00\u59cb\u4e00\u4e2a\u65b0\u7684\u8bad\u7ec3\uff0c\u5e76\u4f20\u5165\u8d85\u53c2\u6570\u4ee5\u8ddf\u8e2a \u8bb0\u5f55\u6765\u81ea\u8bad\u7ec3\u6216\u8bc4\u4f30\u7684\u6307\u6807 \u5728\u4eea\u8868\u677f\u4e2d\u53ef\u89c6\u5316\u7ed3\u679c import wandb import math import random # Start a new run, tracking hyperparameters in config wandb . init ( project = \"test-drive\" , config = { \"learning_rate\" : 0.01 , \"dropout\" : 0.2 , \"architecture\" : \"CNN\" , \"dataset\" : \"CIFAR-100\" , }) config = wandb . config # Simulating a training or evaluation loop for x in range ( 50 ): acc = math . log ( 1 + x + random . random () * config . learning_rate ) + random . random () + config . dropout loss = 10 - math . log ( 1 + x + random . random () + config . learning_rate * x ) + random . random () + config . dropout # Log metrics from your script to W&B wandb . log ({ \"acc\" : acc , \"loss\" : loss }) wandb . finish ()","title":"\u53ef\u89c6\u5316\u5b9e\u9a8c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html","text":"\ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5982\u4f55\u4ece OneFlow Hub \u52a0\u8f7d one-yolov5 \u3002\ud83d\ude80 \u5f00\u59cb\u4e4b\u524d \u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 \u6240\u9700\u7684\u4f9d\u8d56\u5e93 , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u4e0d\u9700\u8981\u514b\u9686 https://github.com/Oneflow-Inc/one-yolov5 \u4f7f\u7528 OneFlow Hub \u52a0\u8f7d one-yolov5 \u7b80\u5355\u7684\u4f8b\u5b50 \u6b64\u793a\u4f8b\u4ece OneFlow Hub \u52a0\u8f7d\u9884\u8bad\u7ec3\u7684 YOLOv5s \u6a21\u578b\u4f5c\u4e3a model \uff0c\u5e76\u4f20\u4e00\u5f20\u56fe\u50cf\u8fdb\u884c\u63a8\u7406\u3002 yolov5s \u662f\u6700\u8f7b\u3001\u6700\u5feb\u7684 YOLOv5 \u6a21\u578b\u3002 \u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 README \u3002 import oneflow as flow # \u6a21\u578b model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # or yolov5n - yolov5x6, custom # \u56fe\u50cf img = 'https://raw.githubusercontent.com/Oneflow-Inc/one-yolov5/main/data/images/zidane.jpg' # or file, Path, PIL, OpenCV, numpy, list # \u63a8\u7406 results = model ( img ) # \u7ed3\u679c results . print () # or .show(), .save(), .crop(), .pandas(), etc. print ( results . pandas () . xyxy [ 0 ]) xmin ymin xmax ymax confidence class name 0 743.290649 48.343842 1141.756348 720.000000 0.879861 0 person 1 441.989624 437.336670 496.585083 710.036255 0.675118 27 tie 2 123.051117 193.237976 714.690674 719.771362 0.666694 0 person 3 978.989807 313.579468 1025.302856 415.526184 0.261517 27 tie \u66f4\u7ec6\u8282\u7684\u4f8b\u5b50 \u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4e86\u4f7f\u7528 PIL \u548c OpenCV \u5206\u522b\u4f5c\u4e3a\u56fe\u50cf\u6e90\u7684\u6279\u91cf\u63a8\u7406\u3002 result \u53ef\u4ee5\u6253\u5370\u5230\u63a7\u5236\u53f0\uff0c\u4fdd\u5b58\u5230 runs/hub , \u5728\u652f\u6301\u7684\u73af\u5883\u4e2d\u663e\u793a\u5230\u5c4f\u5e55\u4e0a\uff0c\u5e76\u4f5c\u4e3a\u5f20\u91cf\u6216 pandas \u6570\u636e\u8fd4\u56de\u3002 import cv2 import oneflow as flow from PIL import Image # Model model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # Images for f in 'zidane.jpg' , 'bus.jpg' : flow . hub . download_url_to_file ( 'https://ultralytics.com/images/' + f , f ) # download 2 images im1 = Image . open ( 'zidane.jpg' ) # PIL image im2 = cv2 . imread ( 'bus.jpg' )[ ... , :: - 1 ] # OpenCV image (BGR to RGB) # Inference results = model ([ im1 , im2 ], size = 640 ) # batch of images # Results results . print () results . save () # or .show() results . xyxy [ 0 ] # im1 predictions (tensor) print ( results . pandas () . xyxy [ 0 ]) # im1 predictions (pandas) \u5bf9\u4e8e\u6240\u6709\u63a8\u7406\u9009\u9879\uff0c\u8bf7\u53c2\u9605 YOLOv5 AutoShape() forward\u65b9\u6cd5 \u3002 \u63a8\u7406\u8bbe\u7f6e YOLOv5 \u6a21\u578b\u5305\u542b\u5404\u79cd\u63a8\u7406\u5c5e\u6027\uff0c\u4f8b\u5982\u7f6e\u4fe1\u5ea6\u9608\u503c\u3001IoU \u9608\u503c\u7b49\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u8bbe\u7f6e\uff1a model . conf = 0.25 # NMS confidence threshold iou = 0.45 # NMS IoU threshold agnostic = False # NMS class-agnostic multi_label = False # NMS multiple labels per box classes = None # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs max_det = 1000 # maximum number of detections per image amp = False # Automatic Mixed Precision (AMP) inference results = model ( im , size = 320 ) # custom inference size \u8bbe\u5907 \u6a21\u578b\u521b\u5efa\u540e\u53ef\u4ee5\u8fc1\u79fb\u5230\u4efb\u610f\u8bbe\u5907\u4e0a model . cpu () # CPU model . cuda () # GPU model . to ( device ) # i.e. device=flow.device(0) \u6a21\u578b\u4e5f\u53ef\u4ee5\u5728\u4efb\u610f device \u4e0a\u76f4\u63a5\u521b\u5efa\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 'cpu' ) # load on CPU \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a \u5728\u63a8\u7406\u4e4b\u524d\uff0c\u8f93\u5165\u56fe\u50cf\u4e5f\u4f1a\u81ea\u52a8\u4f20\u8f93\u5230\u6a21\u578b\u6240\u5728\u7684\u8bbe\u5907\u4e0a\u3002 \u9759\u97f3\u8f93\u51fa \u4f7f\u7528 _verbose=False ,\u6a21\u578b\u53ef\u4ee5\u88ab\u9759\u97f3\u7684\u52a0\u8f7d\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , _verbose = False ) # load silently \u8f93\u5165\u901a\u9053 model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , channels = 4 ) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9664\u4e86\u7b2c\u4e00\u4e2a\u8f93\u5165\u5c42\u5916\u5c06\u7531\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u7ec4\u6210\uff0c\u5b83\u4e0d\u518d\u4e0e\u9884\u8bad\u7ec3\u7684\u8f93\u5165\u5c42\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u3002 \u8f93\u5165\u5c42\u5c06\u4fdd\u6301\u7531\u968f\u673a\u6743\u91cd\u521d\u59cb\u5316\u3002 \u7c7b\u522b\u6570 \u8981\u52a0\u8f7d\u5177\u6709 10 \u4e2a\u8f93\u51fa\u7c7b\u800c\u4e0d\u662f\u9ed8\u8ba4\u7684 80 \u4e2a\u8f93\u51fa\u7c7b\u7684\u9884\u8bad\u7ec3 YOLOv5s \u6a21\u578b\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , classes = 10 ) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9664\u4e86\u8f93\u51fa\u5c42\u5c06\u7531\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u7ec4\u6210\uff0c\u5b83\u4eec\u4e0d\u518d\u4e0e\u9884\u8bad\u7ec3\u7684\u8f93\u51fa\u5c42\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u3002 \u8f93\u51fa\u5c42\u5c06\u4fdd\u6301\u7531\u968f\u673a\u6743\u91cd\u521d\u59cb\u5316\u3002 \u5f3a\u5236\u91cd\u65b0\u52a0\u8f7d \u5982\u679c\u60a8\u5728\u4e0a\u8ff0\u6b65\u9aa4\u4e2d\u9047\u5230\u95ee\u9898\uff0c\u8bbe\u7f6e force_reload=True \u53ef\u80fd\u6709\u52a9\u4e8e\u4e22\u5f03\u73b0\u6709\u7f13\u5b58\u5e76\u5f3a\u5236\u4ece OneFlow Hub \u91cd\u65b0\u4e0b\u8f7d\u6700\u65b0\u7684 YOLOv5 \u7248\u672c\u3002 \u622a\u56fe\u63a8\u7406 \u8981\u5728\u684c\u9762\u5c4f\u5e55\u4e0a\u8fd0\u884c\u63a8\u7406\uff1a import oneflow as flow from PIL import ImageGrab # Model model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , _verbose = False ) # Image im = ImageGrab . grab () # take a screenshot # Inference results = model ( im ) \u591a GPU \u63a8\u7406 YOLOv5 \u6a21\u578b\u53ef\u4ee5\u52a0\u8f7d\u5230\u591a\u4e2a GPU \u5b9e\u73b0\u591a\u7ebf\u7a0b\u63a8\u7406\uff1a import oneflow as flow import threading def run ( model , im ): results = model ( im ) results . save () # Models model0 = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 0 ) model1 = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 1 ) # Inference threading . Thread ( target = run , args = [ model0 , 'https://ultralytics.com/images/zidane.jpg' ], daemon = True ) . start () threading . Thread ( target = run , args = [ model1 , 'https://ultralytics.com/images/bus.jpg' ], daemon = True ) . start () \u8bad\u7ec3 \u8981\u52a0\u8f7d YOLOv5 \u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u800c\u4e0d\u662f\u63a8\u7406\uff0c\u8bf7\u8bbe\u7f6e autoshape=False\u3002 \u8981\u52a0\u8f7d\u5177\u6709\u968f\u673a\u521d\u59cb\u5316\u6743\u91cd\u7684\u6a21\u578b\uff08\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\uff09\uff0c\u8bf7\u4f7f\u7528 pretrained=False\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u60a8\u5fc5\u987b\u63d0\u4f9b\u81ea\u5df1\u7684\u8bad\u7ec3\u811a\u672c\u3002 \u6216\u8005\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 YOLOv5 \u8bad\u7ec3\u81ea\u5b9a\u4e49\u6570\u636e\u6559\u7a0b \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , autoshape = False ) # load pretrained model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , autoshape = False , pretrained = False ) # load scratch Base64 \u7ed3\u679c \u7528\u4e8e API \u670d\u52a1\u3002 \u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 #2291 \u548c Flask REST API \u793a\u4f8b\u3002 results = model ( im ) # inference results . ims # array of original images (as np array) passed to model for inference results . render () # updates results.ims with boxes and labels for im in results . ims : buffered = BytesIO () im_base64 = Image . fromarray ( im ) im_base64 . save ( buffered , format = \"JPEG\" ) print ( base64 . b64encode ( buffered . getvalue ()) . decode ( 'utf-8' )) # base64 encoded image with results \u88c1\u526a\u7ed3\u679c \u8fd4\u56de\u7684\u68c0\u6d4b\u7ed3\u679c\u53ef\u4ee5\u88ab\u88c1\u526a\uff1a results = model ( im ) # inference crops = results . crop ( save = True ) # cropped detections dictionary Pandas \u7ed3\u679c \u7ed3\u679c\u53ef\u4ee5\u4f5c\u4e3a Pandas DataFrames \u8fd4\u56de\uff1a results = model ( im ) # inference results . pandas () . xyxy [ 0 ] # Pandas DataFrame Pandas\u8f93\u51fa\uff08\u70b9\u51fb\u5c55\u5f00\uff09 print(results.pandas().xyxy[0]) xmin ymin xmax ymax confidence class name 0 743.290649 48.343842 1141.756348 720.000000 0.879861 0 person 1 441.989624 437.336670 496.585083 710.036255 0.675118 27 tie 2 123.051117 193.237976 714.690674 719.771362 0.666694 0 person 3 978.989807 313.579468 1025.302856 415.526184 0.261517 27 tie \u6392\u5e8f\u540e\u7684\u7ed3\u679c \u7ed3\u679c\u53ef\u4ee5\u6309\u5217\u6392\u5e8f\uff0c\u4f8b\u5982\u4ece\u5de6\u5230\u53f3\uff08x\u8f74\uff09\u5bf9\u8f66\u724c\u6570\u5b57\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u6392\u5e8f\uff1a results = model ( im ) # inference results . pandas () . xyxy [ 0 ] . sort_values ( 'xmin' ) # sorted left-right Box-Cropped \u7ed3\u679c \u7ed3\u679c\u53ef\u4ee5\u8fd4\u56de\u5e76\u4fdd\u5b58\u4e3a detection crops\uff1a results = model ( im ) # inference crops = results . crop ( save = True ) # cropped detections dictionary JSON \u7ed3\u679c \u7ed3\u679c\u4e00\u65e6\u4f7f\u7528 .pandas \u88ab\u4fdd\u5b58\u4e3a pandas \u6570\u636e\u683c\u5f0f\uff0c\u5c31\u53ef\u4ee5\u518d\u4f7f\u7528 .to_json() \u65b9\u6cd5\u4fdd\u5b58\u4e3a JSON \u683c\u5f0f\u3002\u53ef\u4ee5\u4f7f\u7528 orient \u53c2\u6570\u4fee\u6539 JSON \u683c\u5f0f\u3002\u8bf7\u67e5\u770b pandas \u7684 .to_json() \u65b9\u6cd5\u7684 \u6587\u6863 \u4e86\u89e3\u7ec6\u8282\u3002 results = model ( ims ) # inference results . pandas () . xyxy [ 0 ] . to_json ( orient = \"records\" ) # JSON img1 predictions Json\u8f93\u51fa\uff08\u70b9\u51fb\u5c55\u5f00\uff09 [{\"xmin\":743.2906494141,\"ymin\":48.3438415527,\"xmax\":1141.7563476562,\"ymax\":720.0,\"confidence\":0.87986058,\"class\":0,\"name\":\"person\"},{\"xmin\":441.9896240234,\"ymin\":437.3366699219,\"xmax\":496.5850830078,\"ymax\":710.0362548828,\"confidence\":0.6751183867,\"class\":27,\"name\":\"tie\"},{\"xmin\":123.0511169434,\"ymin\":193.2379760742,\"xmax\":714.6906738281,\"ymax\":719.7713623047,\"confidence\":0.6666944027,\"class\":0,\"name\":\"person\"},{\"xmin\":978.9898071289,\"ymin\":313.5794677734,\"xmax\":1025.3028564453,\"ymax\":415.526184082,\"confidence\":0.2615173161,\"class\":27,\"name\":\"tie\"}] \u81ea\u5b9a\u4e49\u6a21\u578b \u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4f7f\u7528 OneFlow Hub \u52a0\u8f7d\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684\u5728VOC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u768420\u4e2a\u7c7b\u522b\u7684 YOLOV5s \u6a21\u578b best \u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'custom' , path = 'path/to/best' ) # local model model = oneflow . hub . load ( '/path/to/one-yolov5' , 'custom' , path = 'path/to/best' ) # local repo TensorRT, ONNX \u548c OpenVINO \u6a21\u578b OneFlow Hub \u652f\u6301\u5bf9\u5927\u591a\u6570 YOLOv5 \u5bfc\u51fa\u683c\u5f0f\u8fdb\u884c\u63a8\u7406\uff0c\u5305\u62ec\u81ea\u5b9a\u4e49\u8bad\u7ec3\u6a21\u578b\u3002\u67e5\u770b TFLite, ONNX, CoreML, TensorRT \u6a21\u578b\u5bfc\u51fa\u6559\u7a0b \u67e5\u770b\u7ec6\u8282\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u5728 GPU benchmarks \u4e0a TensorRT \u53ef\u80fd\u6bd4PyTorch\u5feb3-5\u500d\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u5728 CPU benchmarks \u4e0a ONNX \u548c OpenVINO \u53ef\u80fd\u6bd4 PyTorch \u5feb2-3\u500d\u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'custom' , path = 'yolov5s/' ) # OneFlow 'yolov5s.onnx' ) # ONNX 'yolov5s_openvino_model/' ) # OpenVINO 'yolov5s.engine' ) # TensorRT 'yolov5s.mlmodel' ) # CoreML (macOS-only) 'yolov5s.tflite' ) # TFLite \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/issues/36","title":"3.2 \u4eceOneFlow Hub \u52a0\u8f7dYOLOv5"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_1","text":"\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 \u6240\u9700\u7684\u4f9d\u8d56\u5e93 , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u4e0d\u9700\u8981\u514b\u9686 https://github.com/Oneflow-Inc/one-yolov5","title":"\u5f00\u59cb\u4e4b\u524d"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#oneflow-hub-one-yolov5","text":"","title":"\u4f7f\u7528 OneFlow Hub \u52a0\u8f7d one-yolov5"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_2","text":"\u6b64\u793a\u4f8b\u4ece OneFlow Hub \u52a0\u8f7d\u9884\u8bad\u7ec3\u7684 YOLOv5s \u6a21\u578b\u4f5c\u4e3a model \uff0c\u5e76\u4f20\u4e00\u5f20\u56fe\u50cf\u8fdb\u884c\u63a8\u7406\u3002 yolov5s \u662f\u6700\u8f7b\u3001\u6700\u5feb\u7684 YOLOv5 \u6a21\u578b\u3002 \u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 README \u3002 import oneflow as flow # \u6a21\u578b model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # or yolov5n - yolov5x6, custom # \u56fe\u50cf img = 'https://raw.githubusercontent.com/Oneflow-Inc/one-yolov5/main/data/images/zidane.jpg' # or file, Path, PIL, OpenCV, numpy, list # \u63a8\u7406 results = model ( img ) # \u7ed3\u679c results . print () # or .show(), .save(), .crop(), .pandas(), etc. print ( results . pandas () . xyxy [ 0 ]) xmin ymin xmax ymax confidence class name 0 743.290649 48.343842 1141.756348 720.000000 0.879861 0 person 1 441.989624 437.336670 496.585083 710.036255 0.675118 27 tie 2 123.051117 193.237976 714.690674 719.771362 0.666694 0 person 3 978.989807 313.579468 1025.302856 415.526184 0.261517 27 tie","title":"\u7b80\u5355\u7684\u4f8b\u5b50"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_3","text":"\u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4e86\u4f7f\u7528 PIL \u548c OpenCV \u5206\u522b\u4f5c\u4e3a\u56fe\u50cf\u6e90\u7684\u6279\u91cf\u63a8\u7406\u3002 result \u53ef\u4ee5\u6253\u5370\u5230\u63a7\u5236\u53f0\uff0c\u4fdd\u5b58\u5230 runs/hub , \u5728\u652f\u6301\u7684\u73af\u5883\u4e2d\u663e\u793a\u5230\u5c4f\u5e55\u4e0a\uff0c\u5e76\u4f5c\u4e3a\u5f20\u91cf\u6216 pandas \u6570\u636e\u8fd4\u56de\u3002 import cv2 import oneflow as flow from PIL import Image # Model model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' ) # Images for f in 'zidane.jpg' , 'bus.jpg' : flow . hub . download_url_to_file ( 'https://ultralytics.com/images/' + f , f ) # download 2 images im1 = Image . open ( 'zidane.jpg' ) # PIL image im2 = cv2 . imread ( 'bus.jpg' )[ ... , :: - 1 ] # OpenCV image (BGR to RGB) # Inference results = model ([ im1 , im2 ], size = 640 ) # batch of images # Results results . print () results . save () # or .show() results . xyxy [ 0 ] # im1 predictions (tensor) print ( results . pandas () . xyxy [ 0 ]) # im1 predictions (pandas) \u5bf9\u4e8e\u6240\u6709\u63a8\u7406\u9009\u9879\uff0c\u8bf7\u53c2\u9605 YOLOv5 AutoShape() forward\u65b9\u6cd5 \u3002","title":"\u66f4\u7ec6\u8282\u7684\u4f8b\u5b50"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_4","text":"YOLOv5 \u6a21\u578b\u5305\u542b\u5404\u79cd\u63a8\u7406\u5c5e\u6027\uff0c\u4f8b\u5982\u7f6e\u4fe1\u5ea6\u9608\u503c\u3001IoU \u9608\u503c\u7b49\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u8bbe\u7f6e\uff1a model . conf = 0.25 # NMS confidence threshold iou = 0.45 # NMS IoU threshold agnostic = False # NMS class-agnostic multi_label = False # NMS multiple labels per box classes = None # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs max_det = 1000 # maximum number of detections per image amp = False # Automatic Mixed Precision (AMP) inference results = model ( im , size = 320 ) # custom inference size","title":"\u63a8\u7406\u8bbe\u7f6e"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_5","text":"\u6a21\u578b\u521b\u5efa\u540e\u53ef\u4ee5\u8fc1\u79fb\u5230\u4efb\u610f\u8bbe\u5907\u4e0a model . cpu () # CPU model . cuda () # GPU model . to ( device ) # i.e. device=flow.device(0) \u6a21\u578b\u4e5f\u53ef\u4ee5\u5728\u4efb\u610f device \u4e0a\u76f4\u63a5\u521b\u5efa\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 'cpu' ) # load on CPU \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a \u5728\u63a8\u7406\u4e4b\u524d\uff0c\u8f93\u5165\u56fe\u50cf\u4e5f\u4f1a\u81ea\u52a8\u4f20\u8f93\u5230\u6a21\u578b\u6240\u5728\u7684\u8bbe\u5907\u4e0a\u3002","title":"\u8bbe\u5907"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_6","text":"\u4f7f\u7528 _verbose=False ,\u6a21\u578b\u53ef\u4ee5\u88ab\u9759\u97f3\u7684\u52a0\u8f7d\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , _verbose = False ) # load silently","title":"\u9759\u97f3\u8f93\u51fa"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_7","text":"model = flow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , channels = 4 ) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9664\u4e86\u7b2c\u4e00\u4e2a\u8f93\u5165\u5c42\u5916\u5c06\u7531\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u7ec4\u6210\uff0c\u5b83\u4e0d\u518d\u4e0e\u9884\u8bad\u7ec3\u7684\u8f93\u5165\u5c42\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u3002 \u8f93\u5165\u5c42\u5c06\u4fdd\u6301\u7531\u968f\u673a\u6743\u91cd\u521d\u59cb\u5316\u3002","title":"\u8f93\u5165\u901a\u9053"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_8","text":"\u8981\u52a0\u8f7d\u5177\u6709 10 \u4e2a\u8f93\u51fa\u7c7b\u800c\u4e0d\u662f\u9ed8\u8ba4\u7684 80 \u4e2a\u8f93\u51fa\u7c7b\u7684\u9884\u8bad\u7ec3 YOLOv5s \u6a21\u578b\uff1a model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , classes = 10 ) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u9664\u4e86\u8f93\u51fa\u5c42\u5c06\u7531\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u7ec4\u6210\uff0c\u5b83\u4eec\u4e0d\u518d\u4e0e\u9884\u8bad\u7ec3\u7684\u8f93\u51fa\u5c42\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u3002 \u8f93\u51fa\u5c42\u5c06\u4fdd\u6301\u7531\u968f\u673a\u6743\u91cd\u521d\u59cb\u5316\u3002","title":"\u7c7b\u522b\u6570"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_9","text":"\u5982\u679c\u60a8\u5728\u4e0a\u8ff0\u6b65\u9aa4\u4e2d\u9047\u5230\u95ee\u9898\uff0c\u8bbe\u7f6e force_reload=True \u53ef\u80fd\u6709\u52a9\u4e8e\u4e22\u5f03\u73b0\u6709\u7f13\u5b58\u5e76\u5f3a\u5236\u4ece OneFlow Hub \u91cd\u65b0\u4e0b\u8f7d\u6700\u65b0\u7684 YOLOv5 \u7248\u672c\u3002","title":"\u5f3a\u5236\u91cd\u65b0\u52a0\u8f7d"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_10","text":"\u8981\u5728\u684c\u9762\u5c4f\u5e55\u4e0a\u8fd0\u884c\u63a8\u7406\uff1a import oneflow as flow from PIL import ImageGrab # Model model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , _verbose = False ) # Image im = ImageGrab . grab () # take a screenshot # Inference results = model ( im )","title":"\u622a\u56fe\u63a8\u7406"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#gpu","text":"YOLOv5 \u6a21\u578b\u53ef\u4ee5\u52a0\u8f7d\u5230\u591a\u4e2a GPU \u5b9e\u73b0\u591a\u7ebf\u7a0b\u63a8\u7406\uff1a import oneflow as flow import threading def run ( model , im ): results = model ( im ) results . save () # Models model0 = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 0 ) model1 = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , device = 1 ) # Inference threading . Thread ( target = run , args = [ model0 , 'https://ultralytics.com/images/zidane.jpg' ], daemon = True ) . start () threading . Thread ( target = run , args = [ model1 , 'https://ultralytics.com/images/bus.jpg' ], daemon = True ) . start ()","title":"\u591a GPU \u63a8\u7406"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_11","text":"\u8981\u52a0\u8f7d YOLOv5 \u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u800c\u4e0d\u662f\u63a8\u7406\uff0c\u8bf7\u8bbe\u7f6e autoshape=False\u3002 \u8981\u52a0\u8f7d\u5177\u6709\u968f\u673a\u521d\u59cb\u5316\u6743\u91cd\u7684\u6a21\u578b\uff08\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\uff09\uff0c\u8bf7\u4f7f\u7528 pretrained=False\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u60a8\u5fc5\u987b\u63d0\u4f9b\u81ea\u5df1\u7684\u8bad\u7ec3\u811a\u672c\u3002 \u6216\u8005\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 YOLOv5 \u8bad\u7ec3\u81ea\u5b9a\u4e49\u6570\u636e\u6559\u7a0b \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , autoshape = False ) # load pretrained model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'yolov5s' , autoshape = False , pretrained = False ) # load scratch","title":"\u8bad\u7ec3"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#base64","text":"\u7528\u4e8e API \u670d\u52a1\u3002 \u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 #2291 \u548c Flask REST API \u793a\u4f8b\u3002 results = model ( im ) # inference results . ims # array of original images (as np array) passed to model for inference results . render () # updates results.ims with boxes and labels for im in results . ims : buffered = BytesIO () im_base64 = Image . fromarray ( im ) im_base64 . save ( buffered , format = \"JPEG\" ) print ( base64 . b64encode ( buffered . getvalue ()) . decode ( 'utf-8' )) # base64 encoded image with results","title":"Base64 \u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_12","text":"\u8fd4\u56de\u7684\u68c0\u6d4b\u7ed3\u679c\u53ef\u4ee5\u88ab\u88c1\u526a\uff1a results = model ( im ) # inference crops = results . crop ( save = True ) # cropped detections dictionary","title":"\u88c1\u526a\u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#pandas","text":"\u7ed3\u679c\u53ef\u4ee5\u4f5c\u4e3a Pandas DataFrames \u8fd4\u56de\uff1a results = model ( im ) # inference results . pandas () . xyxy [ 0 ] # Pandas DataFrame Pandas\u8f93\u51fa\uff08\u70b9\u51fb\u5c55\u5f00\uff09 print(results.pandas().xyxy[0]) xmin ymin xmax ymax confidence class name 0 743.290649 48.343842 1141.756348 720.000000 0.879861 0 person 1 441.989624 437.336670 496.585083 710.036255 0.675118 27 tie 2 123.051117 193.237976 714.690674 719.771362 0.666694 0 person 3 978.989807 313.579468 1025.302856 415.526184 0.261517 27 tie","title":"Pandas \u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_13","text":"\u7ed3\u679c\u53ef\u4ee5\u6309\u5217\u6392\u5e8f\uff0c\u4f8b\u5982\u4ece\u5de6\u5230\u53f3\uff08x\u8f74\uff09\u5bf9\u8f66\u724c\u6570\u5b57\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u6392\u5e8f\uff1a results = model ( im ) # inference results . pandas () . xyxy [ 0 ] . sort_values ( 'xmin' ) # sorted left-right","title":"\u6392\u5e8f\u540e\u7684\u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#box-cropped","text":"\u7ed3\u679c\u53ef\u4ee5\u8fd4\u56de\u5e76\u4fdd\u5b58\u4e3a detection crops\uff1a results = model ( im ) # inference crops = results . crop ( save = True ) # cropped detections dictionary","title":"Box-Cropped \u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#json","text":"\u7ed3\u679c\u4e00\u65e6\u4f7f\u7528 .pandas \u88ab\u4fdd\u5b58\u4e3a pandas \u6570\u636e\u683c\u5f0f\uff0c\u5c31\u53ef\u4ee5\u518d\u4f7f\u7528 .to_json() \u65b9\u6cd5\u4fdd\u5b58\u4e3a JSON \u683c\u5f0f\u3002\u53ef\u4ee5\u4f7f\u7528 orient \u53c2\u6570\u4fee\u6539 JSON \u683c\u5f0f\u3002\u8bf7\u67e5\u770b pandas \u7684 .to_json() \u65b9\u6cd5\u7684 \u6587\u6863 \u4e86\u89e3\u7ec6\u8282\u3002 results = model ( ims ) # inference results . pandas () . xyxy [ 0 ] . to_json ( orient = \"records\" ) # JSON img1 predictions Json\u8f93\u51fa\uff08\u70b9\u51fb\u5c55\u5f00\uff09 [{\"xmin\":743.2906494141,\"ymin\":48.3438415527,\"xmax\":1141.7563476562,\"ymax\":720.0,\"confidence\":0.87986058,\"class\":0,\"name\":\"person\"},{\"xmin\":441.9896240234,\"ymin\":437.3366699219,\"xmax\":496.5850830078,\"ymax\":710.0362548828,\"confidence\":0.6751183867,\"class\":27,\"name\":\"tie\"},{\"xmin\":123.0511169434,\"ymin\":193.2379760742,\"xmax\":714.6906738281,\"ymax\":719.7713623047,\"confidence\":0.6666944027,\"class\":0,\"name\":\"person\"},{\"xmin\":978.9898071289,\"ymin\":313.5794677734,\"xmax\":1025.3028564453,\"ymax\":415.526184082,\"confidence\":0.2615173161,\"class\":27,\"name\":\"tie\"}]","title":"JSON \u7ed3\u679c"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_14","text":"\u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4f7f\u7528 OneFlow Hub \u52a0\u8f7d\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684\u5728VOC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u768420\u4e2a\u7c7b\u522b\u7684 YOLOV5s \u6a21\u578b best \u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'custom' , path = 'path/to/best' ) # local model model = oneflow . hub . load ( '/path/to/one-yolov5' , 'custom' , path = 'path/to/best' ) # local repo","title":"\u81ea\u5b9a\u4e49\u6a21\u578b"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#tensorrt-onnx-openvino","text":"OneFlow Hub \u652f\u6301\u5bf9\u5927\u591a\u6570 YOLOv5 \u5bfc\u51fa\u683c\u5f0f\u8fdb\u884c\u63a8\u7406\uff0c\u5305\u62ec\u81ea\u5b9a\u4e49\u8bad\u7ec3\u6a21\u578b\u3002\u67e5\u770b TFLite, ONNX, CoreML, TensorRT \u6a21\u578b\u5bfc\u51fa\u6559\u7a0b \u67e5\u770b\u7ec6\u8282\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u5728 GPU benchmarks \u4e0a TensorRT \u53ef\u80fd\u6bd4PyTorch\u5feb3-5\u500d\u3002 \ud83d\udca1 \u4e13\u5bb6\u63d0\u793a\uff1a\u5728 CPU benchmarks \u4e0a ONNX \u548c OpenVINO \u53ef\u80fd\u6bd4 PyTorch \u5feb2-3\u500d\u3002 model = oneflow . hub . load ( 'Oneflow-Inc/one-yolov5' , 'custom' , path = 'yolov5s/' ) # OneFlow 'yolov5s.onnx' ) # ONNX 'yolov5s_openvino_model/' ) # OpenVINO 'yolov5s.engine' ) # TensorRT 'yolov5s.mlmodel' ) # CoreML (macOS-only) 'yolov5s.tflite' ) # TFLite","title":"TensorRT, ONNX \u548c OpenVINO \u6a21\u578b"},{"location":"tutorials/03_chapter/loading_model_from_oneflowhub.html#_15","text":"https://github.com/ultralytics/yolov5/issues/36","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/03_chapter/model_ensembling.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u4f60\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6a21\u578b\u878d\u5408 (Model Ensembling) From https://www.sciencedirect.com/topics/computer-science/ensemble-modeling: Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data. The motivation for using ensemble models is to reduce the generalization error of the prediction. As long as the base models are diverse and independent, the prediction error of the model decreases when the ensemble approach is used. The approach seeks the wisdom of crowds in making a prediction. Even though the ensemble model has multiple base models within the model, it acts and performs as a single model. \ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5728YOLOv5\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u63a8\u7406\u4e2d\u5982\u4f55\u4f7f\u7528\u6a21\u578b\u878d\u5408 (Model Ensembling)\u63d0\u9ad8mAP\u548cRecall \ud83d\ude80 \ud83d\udccc\u5f00\u59cb\u4e4b\u524d \u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install \ud83d\udccc\u666e\u901a\u6d4b\u8bd5 \u5728\u5c1d\u8bd5 TTA \u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u80fd\u591f\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u547d\u4ee4\u5728COCO val2017\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5YOLOv5x\u3002 yolov5x \u662f\u53ef\u7528\u7684\u6700\u5927\u5e76\u4e14\u6700\u7cbe\u786e\u7684\u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u7684\u6a21\u578b\u662f yolov5s , yolov5m \u548c yolov5l \u7b49 \u6216\u8005 \u81ea\u5df1\u4ece\u6570\u636e\u96c6\u8bad\u7ec3\u51fa\u7684\u6a21\u578b ./weights/best \u3002\u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 READEME table $ python val . py -- weights ./ yolov5x -- data coco . yaml -- img 640 -- half \ud83d\udce2 \u8f93\u51fa: val: data = data/coco.yaml, weights =[ './yolov5x' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = True, dnn = False YOLOv5 \ud83d\ude80 v1.0-8-g94ec5c4 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 01 :55< 00 :00, 1 .36it/ all 5000 36335 0 .743 0 .627 0 .685 0 .503 Speed: 0 .1ms pre-process, 7 .5ms inference, 2 .1ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json... ... Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0 .50 | area = all | maxDets = 100 ] = 0 .689 Average Precision ( AP ) @ [ IoU = 0 .75 | area = all | maxDets = 100 ] = 0 .545 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .339 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .557 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .650 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 1 ] = 0 .382 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 10 ] = 0 .628 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .523 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .730 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .826 \ud83d\udccc \u878d\u5408\u6d4b\u8bd5 \u901a\u8fc7\u5728\u4efb\u4f55\u73b0\u6709\u7684 val.py\u6216detect.py\u547d\u4ee4\u4e2d\u7684 --weights \u53c2\u6570\u540e\u6dfb\u52a0\u989d\u5916\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u6d4b\u8bd5\u548c\u63a8\u7406\u65f6\u5c06\u591a\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u878d\u5408\u5728\u4e00\u8d77\u3002 \ud83d\udce2 \u5c06 yolov5x , yolov5l6 \u4e24\u4e2a\u6a21\u578b\u7684\u878d\u5408\u6d4b\u8bd5\u7684\u6307\u4ee4\u5982\u4e0b\uff1a python val.py --weights ./yolov5x ./yolov5l6 --data data/coco.yaml --img 640 --half val: data=data/coco.yaml, weights=['./yolov5x', './yolov5l6'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False YOLOv5 \ud83d\ude80 v1.0-29-g8ed33f3 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients Fusing layers... Model summary: 346 layers, 76726332 parameters, 653820 gradients Ensemble created with ['./yolov5x', './yolov5l6'] val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157/157 [03:14<00:00, 1.24s/i all 5000 36335 0.73 0.644 0.693 0.513 Speed: 0.1ms pre-process, 23.7ms inference, 2.3ms NMS per image at shape (32, 3, 640, 640) # <--- ensemble speed Evaluating pycocotools mAP... saving runs/val/exp21/yolov5x_predictions.json... ... Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.515 # <--- ensemble mAP Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.697 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.556 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.389 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.637 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.690 # <--- ensemble mAR Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.517 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.842 \ud83d\udce2 \u58f0\u660e:\u4e0a\u8ff0\u4e24\u6b21\u6d4b\u8bd5\u7684mAP\uff0cmAR\u7ed3\u679c\u5982\u4e0b\uff1a mAP mAR baseline 0.505 0.677 ensemble 0.515 0.690 \ud83d\udccc\u878d\u5408\u63a8\u7406 \u9644\u52a0\u989d\u5916\u7684\u6a21\u578b\u5728 --weights \u9009\u9879\u540e\u81ea\u52a8\u542f\u7528\u878d\u5408\u63a8\u7406\uff1a python detect.py --weights ./yolov5x ./yolov5l6 --img 640 --source data/images Output: detect: weights=['./yolov5x', './yolov5l6'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 v1.0-31-g6b1387c Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients Fusing layers... Model summary: 346 layers, 76726332 parameters, 653820 gradients Ensemble created with ['./yolov5x', './yolov5l6'] detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/fengwen/one-yolov5/data/images/bus.jpg: 640x512 4 persons, 1 bus, 1 handbag, 1 tie, Done. (0.028s) detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 2/2 /home/fengwen/one-yolov5/data/images/zidane.jpg: 384x640 3 persons, 2 ties, Done. (0.023s) 0.6ms pre-process, 25.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 640) \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/issues/318","title":"3.4 \u6a21\u578b\u878d\u5408 (Model Ensembling)"},{"location":"tutorials/03_chapter/model_ensembling.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u4f60\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~","title":"\u524d\u8a00"},{"location":"tutorials/03_chapter/model_ensembling.html#model-ensembling","text":"From https://www.sciencedirect.com/topics/computer-science/ensemble-modeling: Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data. The motivation for using ensemble models is to reduce the generalization error of the prediction. As long as the base models are diverse and independent, the prediction error of the model decreases when the ensemble approach is used. The approach seeks the wisdom of crowds in making a prediction. Even though the ensemble model has multiple base models within the model, it acts and performs as a single model. \ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5728YOLOv5\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u63a8\u7406\u4e2d\u5982\u4f55\u4f7f\u7528\u6a21\u578b\u878d\u5408 (Model Ensembling)\u63d0\u9ad8mAP\u548cRecall \ud83d\ude80","title":"\u6a21\u578b\u878d\u5408 (Model Ensembling)"},{"location":"tutorials/03_chapter/model_ensembling.html#_2","text":"\u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install","title":"\ud83d\udccc\u5f00\u59cb\u4e4b\u524d"},{"location":"tutorials/03_chapter/model_ensembling.html#_3","text":"\u5728\u5c1d\u8bd5 TTA \u4e4b\u524d\uff0c\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u80fd\u591f\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u547d\u4ee4\u5728COCO val2017\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5YOLOv5x\u3002 yolov5x \u662f\u53ef\u7528\u7684\u6700\u5927\u5e76\u4e14\u6700\u7cbe\u786e\u7684\u6a21\u578b\u3002\u5176\u5b83\u53ef\u7528\u7684\u6a21\u578b\u662f yolov5s , yolov5m \u548c yolov5l \u7b49 \u6216\u8005 \u81ea\u5df1\u4ece\u6570\u636e\u96c6\u8bad\u7ec3\u51fa\u7684\u6a21\u578b ./weights/best \u3002\u6709\u5173\u6240\u6709\u53ef\u7528\u6a21\u578b\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 READEME table $ python val . py -- weights ./ yolov5x -- data coco . yaml -- img 640 -- half \ud83d\udce2 \u8f93\u51fa: val: data = data/coco.yaml, weights =[ './yolov5x' ] , batch_size = 32 , imgsz = 640 , conf_thres = 0 .001, iou_thres = 0 .6, task = val, device = , workers = 8 , single_cls = False, augment = False, verbose = False, save_txt = False, save_hybrid = False, save_conf = False, save_json = True, project = runs/val, name = exp, exist_ok = False, half = True, dnn = False YOLOv5 \ud83d\ude80 v1.0-8-g94ec5c4 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100 % | \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 157 /157 [ 01 :55< 00 :00, 1 .36it/ all 5000 36335 0 .743 0 .627 0 .685 0 .503 Speed: 0 .1ms pre-process, 7 .5ms inference, 2 .1ms NMS per image at shape ( 32 , 3 , 640 , 640 ) # <--- baseline speed Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json... ... Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .505 # <--- baseline mAP Average Precision ( AP ) @ [ IoU = 0 .50 | area = all | maxDets = 100 ] = 0 .689 Average Precision ( AP ) @ [ IoU = 0 .75 | area = all | maxDets = 100 ] = 0 .545 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .339 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .557 Average Precision ( AP ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .650 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 1 ] = 0 .382 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 10 ] = 0 .628 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = all | maxDets = 100 ] = 0 .677 # <--- baseline mAR Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = small | maxDets = 100 ] = 0 .523 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = medium | maxDets = 100 ] = 0 .730 Average Recall ( AR ) @ [ IoU = 0 .50:0.95 | area = large | maxDets = 100 ] = 0 .826","title":"\ud83d\udccc\u666e\u901a\u6d4b\u8bd5"},{"location":"tutorials/03_chapter/model_ensembling.html#_4","text":"\u901a\u8fc7\u5728\u4efb\u4f55\u73b0\u6709\u7684 val.py\u6216detect.py\u547d\u4ee4\u4e2d\u7684 --weights \u53c2\u6570\u540e\u6dfb\u52a0\u989d\u5916\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u6d4b\u8bd5\u548c\u63a8\u7406\u65f6\u5c06\u591a\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u878d\u5408\u5728\u4e00\u8d77\u3002 \ud83d\udce2 \u5c06 yolov5x , yolov5l6 \u4e24\u4e2a\u6a21\u578b\u7684\u878d\u5408\u6d4b\u8bd5\u7684\u6307\u4ee4\u5982\u4e0b\uff1a python val.py --weights ./yolov5x ./yolov5l6 --data data/coco.yaml --img 640 --half val: data=data/coco.yaml, weights=['./yolov5x', './yolov5l6'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False YOLOv5 \ud83d\ude80 v1.0-29-g8ed33f3 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients Fusing layers... Model summary: 346 layers, 76726332 parameters, 653820 gradients Ensemble created with ['./yolov5x', './yolov5l6'] val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Class Images Labels P R mAP@.5 mAP@.5:.95: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157/157 [03:14<00:00, 1.24s/i all 5000 36335 0.73 0.644 0.693 0.513 Speed: 0.1ms pre-process, 23.7ms inference, 2.3ms NMS per image at shape (32, 3, 640, 640) # <--- ensemble speed Evaluating pycocotools mAP... saving runs/val/exp21/yolov5x_predictions.json... ... Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.515 # <--- ensemble mAP Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.697 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.556 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.389 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.637 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.690 # <--- ensemble mAR Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.517 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.842 \ud83d\udce2 \u58f0\u660e:\u4e0a\u8ff0\u4e24\u6b21\u6d4b\u8bd5\u7684mAP\uff0cmAR\u7ed3\u679c\u5982\u4e0b\uff1a mAP mAR baseline 0.505 0.677 ensemble 0.515 0.690","title":"\ud83d\udccc \u878d\u5408\u6d4b\u8bd5"},{"location":"tutorials/03_chapter/model_ensembling.html#_5","text":"\u9644\u52a0\u989d\u5916\u7684\u6a21\u578b\u5728 --weights \u9009\u9879\u540e\u81ea\u52a8\u542f\u7528\u878d\u5408\u63a8\u7406\uff1a python detect.py --weights ./yolov5x ./yolov5l6 --img 640 --source data/images Output: detect: weights=['./yolov5x', './yolov5l6'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 v1.0-31-g6b1387c Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 Fusing layers... Model summary: 322 layers, 86705005 parameters, 571965 gradients Fusing layers... Model summary: 346 layers, 76726332 parameters, 653820 gradients Ensemble created with ['./yolov5x', './yolov5l6'] detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/fengwen/one-yolov5/data/images/bus.jpg: 640x512 4 persons, 1 bus, 1 handbag, 1 tie, Done. (0.028s) detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 2/2 /home/fengwen/one-yolov5/data/images/zidane.jpg: 384x640 3 persons, 2 ties, Done. (0.023s) 0.6ms pre-process, 25.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 640)","title":"\ud83d\udccc\u878d\u5408\u63a8\u7406"},{"location":"tutorials/03_chapter/model_ensembling.html#_6","text":"https://github.com/ultralytics/yolov5/issues/318","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/03_chapter/quick_start.html","text":"\u524d\u8a00 \ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u4f60\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \ud83d\udce2 \u58f0\u660e:Model Train(\u4ee5coco\u6570\u636e\u96c6\u4e3a\u4f8b) \u9879\u76ee\u7ed3\u6784\u9884\u89c8 \ud83c\udfe0 \u5b89\u88c5 \ud83d\udcda git clone https://github.com/Oneflow-Inc/one-yolov5 # clone cd one-yolov5 pip install -r requirements.txt # install \u8bad\u7ec3 \ud83d\ude80 \u6ce8\u610f\u26a0\ufe0f: oneflow\u76ee\u524d\u4e0d\u652f\u6301windows\u5e73\u53f0 --batch \u5fc5\u987b\u662fGPU\u6570\u91cf\u7684\u500d\u6570\u3002 GPU 0 \u5c06\u6bd4\u5176\u4ed6GPU\u5360\u7528\u7565\u591a\u7684\u5185\u5b58\uff0c\u56e0\u4e3a\u5b83\u7ef4\u62a4EMA\u5e76\u8d1f\u8d23\u68c0\u67e5\u70b9\u7b49\u3002 \ud83d\udccc\u4e24\u79cd\u8bad\u7ec3\u65b9\u5f0f \u5e26\u6743\u91cd\u8bad\u7ec3 \ud83d\ude80 $ python path/to/train.py --data coco.yaml --weights yolov5s --img 640 \u4e0d\u5e26\u6743\u91cd\u8bad\u7ec3 \ud83d\ude80 $ python path/to/train.py --data coco.yaml --weights '' --cfg yolov5s.yaml --img 640 \ud83d\udccc\u5355GPU\u8bad\u7ec3 $ python train.py --data coco.yaml --weights yolov5s --device 0 \ud83d\udccc\u591aGPU\u8bad\u7ec3 $ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --weights yolov5s --device 0,1 \u6ce8\u610f\u26a0\ufe0f\uff1a --nproc_per_node \u6307\u5b9a\u8981\u4f7f\u7528\u591a\u5c11GPU\u3002\u4e3e\u4e2a\u4f8b\u5b50\ud83c\udf30:\u5728\u4e0a\u9762\ud83d\udc46 \u591aGPU\u8bad\u7ec3\u6307\u4ee4\u4e2d\u5b83\u662f2\u3002 --batch \u662f\u603b\u6279\u91cf\u5927\u5c0f\u3002\u5b83\u5c06\u5e73\u5747\u5206\u914d\u7ed9\u6bcf\u4e2aGPU\u3002\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u6bcfGPU\u662f64/2\uff1d32\u3002 --cfg : \u6307\u5b9a\u4e00\u4e2a\u5305\u542b\u6240\u6709\u8bc4\u4f30\u53c2\u6570\u7684\u914d\u7f6e\u6587\u4ef6\u3002 \u4e0a\u9762\u7684\u4ee3\u7801\u9ed8\u8ba4\u4f7f\u7528GPU 0\u2026\uff08N-1\uff09\u3002\u4f7f\u7528\u7279\u5b9a\u7684GPU\ud83e\udd14\ufe0f\uff1f \u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5728 --device \u540e\u8ddf\u6307\u5b9aGPU\u6765\u5b9e\u73b0\u3002\u300c\u6848\u4f8b\ud83c\udf30\u300d\uff0c\u5728\u4e0b\u9762\u7684\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528GPU 2,3\u3002 $ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights '' --device 2,3 \ud83d\udccc\u6062\u590d\u8bad\u7ec3 \u5982\u679c\u4f60\u7684\u8bad\u7ec3\u8fdb\u7a0b\u4e2d\u65ad\u4e86\uff0c\u4f60\u53ef\u4ee5\u8fd9\u6837\u6062\u590d\u5148\u524d\u7684\u8bad\u7ec3\u8fdb\u7a0b\u3002 # \u591a\u5361\u8bad\u7ec3. python -m oneflow.distributed.launch --nproc_per_node 2 train.py --resume \u4f60\u4e5f\u53ef\u4ee5\u901a\u8fc7 --resume \u53c2\u6570\u6307\u5b9a\u8981\u6062\u590d\u7684\u6a21\u578b\u8def\u5f84 # \u8bb0\u5f97\u628a /path/to/your/checkpoint/path \u66ff\u6362\u4e3a\u4f60\u8981\u6062\u590d\u8bad\u7ec3\u7684\u6a21\u578b\u6743\u91cd\u8def\u5f84 --resume /path/to/your/checkpoint/path \ud83d\udccc\u4f7f\u7528SyncBatchNorm SyncBatchNorm \u53ef\u4ee5\u63d0\u9ad8\u591agpu\u8bad\u7ec3\u7684\u51c6\u786e\u6027\uff0c\u4f46\u4f1a\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u901f\u5ea6\u3002\u5b83\u4ec5\u9002\u7528\u4e8e\u591aGPU DistributedDataParallel \u8bad\u7ec3\u3002 \u5efa\u8bae\u6700\u597d\u5728\u6bcf\u4e2aGPU\u4e0a\u7684\u6837\u672c\u6570\u91cf\u8f83\u5c0f\uff08 \u6837\u672c\u6570\u91cf<=8 \uff09\u65f6\u4f7f\u7528\u3002 \u8981\u4f7f\u7528SyncBatchNorm\uff0c\u53ea\u9700\u5c06\u6dfb\u52a0 --sync-bn \u53c2\u6570\u9009\u9879\uff0c\u5177\u4f53\u300c\u6848\u4f8b\ud83c\udf30\u300d\u5982\u4e0b: $ python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' -- sync - bn \u8bc4\u4f30 \ud83d\udc63 \u4e0b\u9762\u7684\u547d\u4ee4\u662f\u5728COCO val2017\u6570\u636e\u96c6\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5 yolov5x \u6a21\u578b\u3002 yolov5x \u662f\u53ef\u7528\u5c0f\u6a21\u578b\u4e2d\u6700\u5927\u4e14\u6700\u7cbe\u786e\u7684\uff0c\u5176\u5b83\u53ef\u7528\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5s \uff0c yolov5l \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 README-TABLE $ python val . py -- weights yolov5x -- data coco . yaml -- img 640 \u63a8\u7406 \ud83d\udc4d \u9996\u5148\uff0c\u4e0b\u8f7d\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u6743\u91cd\u6587\u4ef6\uff0c\u6216\u9009\u62e9\u4f60\u81ea\u5df1\u8bad\u7ec3\u7684\u6a21\u578b\uff1b \u7136\u540e\uff0c \u901a\u8fc7 detect.py\u6587\u4ef6\u8fdb\u884c\u63a8\u7406\u26a1\u3002 python path / to / detect . py -- weights yolov5s -- source 0 # webcam img . jpg # image vid . mp4 # video path / # directory path /*. jpg # glob 'https://youtu.be/Zgi9g1ksQHc' # YouTube 'rtsp://example.com/media.mp4' # RTSP, RTMP, HTTP stream \u6ce8\u610f\u26a0\ufe0f: - \u68c0\u6d4b\u5355\u4e2a\u56fe\u7247 \u4f7f\u7528\u793a\u4f8b python path/to/detect.py --weights yolov5s --source path/to/imgs/hello.jpg - \u60f3\u6279\u91cf\u68c0\u6d4b path/to/imgs/ \u8def\u5f84\u4e0b\u7684\u56fe\u7247, \u4f7f\u7528\u793a\u4f8b python path/to/detect.py --weights yolov5s --source path/to/imgs/ \uff0c\u6ce8\u610f\u4e0d\u8981\u7528 python path/to/detect.py --weights yolov5s --source path/to/imgs/*.jpg \u3002 \u8bad\u7ec3\u7ed3\u679c\ud83c\udf1f \ud83d\udccc\u672c\u5730\u65e5\u5fd7 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u7ed3\u679c\u90fd\u8bb0\u5f55\u4e3aruns/train\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u65b0\u8bad\u7ec3\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u8bad\u7ec3\u7ed3\u679c\u76ee\u5f55\uff0c\u5982runs/train/exp2\u3001runs/train/exp3\u7b49\u3002\u67e5\u770b\u8bad\u7ec3\u548c\u6d4b\u8bd5JPG\u4ee5\u67e5\u770b mosaics, labels, predictions and augmentation \u6548\u679c\u3002 \u6ce8\u610f\uff1aMosaic Dataloader \u7528\u4e8e\u8bad\u7ec3\uff08\u5982\u4e0b\u6240\u793a\uff09\uff0c\u8fd9\u662fUltralytics\u53d1\u8868\u7684\u65b0\u6982\u5ff5\uff0c\u9996\u6b21\u51fa\u73b0\u5728 YOLOv4 \u4e2d\u3002 train_batch0.jpg \u663e\u793a batch \u4e3a 0 \u7684 (mosaics and labels): val_batch0_labels.jpg \u5c55\u793a\u6d4b\u8bd5 batch \u4e3a 0 \u7684labels: val_batch0_pred.jpg \u5c55\u793a\u6d4b\u8bd5 batch \u4e3a 0 predictions(\u9884\u6d4b): \u8bad\u7ec3\u8bad\u635f\u5931\u548c\u6027\u80fd\u7684\u6307\u6807\u6709\u8bb0\u5f55\u5230Tensorboard\u548c\u81ea\u5b9a\u4e49\u7ed3\u679c\u4e2d results.csv\u65e5\u5fd7\u6587\u4ef6 \uff0c\u8bad\u7ec3\u8bad\u5b8c\u6210\u540e\u4f5c\u4e3a\u7ed3\u679c\u7ed8\u5236 results.png\u5982\u4e0b\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5728COCO128\u4e0a\u8bad\u7ec3\u7684YOLOV5\u7ed3\u679c - \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 (\u84dd\u8272)\u3002 - \u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd --weights yolov5s (\u6a59\u8272)\u3002 \u5177\u4f53\u7684\u6307\u6807\u5206\u6790\u8be6\u89c1\u6587\u7ae0 \u300a\u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30\u300b \u8bad\u7ec3\u6280\u5de7\ud83d\udd25 \ud83d\udce2 \u58f0\u660e\uff1a\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c \u53ea\u8981\u6570\u636e\u96c6\u8db3\u591f\u5927\u4e14\u6807\u8bb0\u826f\u597d \uff0c\u5c31\u53ef\u4ee5\u5728\u4e0d\u6539\u53d8\u6a21\u578b\u6216\u8bad\u7ec3\u8bbe\u7f6e\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u826f\u597d\u7684\u7ed3\u679c\u3002 \u5982\u679c\u4e00\u5f00\u59cb\u4f60\u6ca1\u6709\u5f97\u5230\u597d\u7684\u7ed3\u679c\uff0c\u4f60\u53ef\u4ee5\u91c7\u53d6\u4e00\u4e9b\u6b65\u9aa4\u6765\u6539\u8fdb\uff0c\u4f46\u6211\u4eec\u59cb\u7ec8\u5efa\u8bae\u7528\u6237\u5728\u8003\u8651\u4efb\u4f55\u66f4\u6539\u4e4b\u524d\u5148\u4f7f\u7528\u6240\u6709\u9ed8\u8ba4\u8bbe\u7f6e\u8fdb\u884c\u4e00\u6b21\u8bad\u7ec3\u3002\u8fd9\u6709\u52a9\u4e8e\u5efa\u7acb\u8bc4\u4f30\u57fa\u51c6\u548c\u53d1\u73b0\u9700\u8981\u6539\u8fdb\u7684\u5730\u65b9 \ud83d\ude80\u3002 \ud83d\udccc\u6a21\u578b\u9009\u62e9 \u7c7b\u4f3c\u4e8eYOLOv5x\u548cYOLOv5x6\u7684\u5927\u578b\u6a21\u578b\u5728\u51e0\u4e4e\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u4f1a\u4ea7\u751f\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u4f46\u53c2\u6570\u66f4\u591a\uff0c\u9700\u8981\u66f4\u591a\u7684CUDA\u5185\u5b58\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd0\u884c\u901f\u5ea6\u8f83\u6162\u3002 \u5bf9\u4e8e\u79fb\u52a8\u90e8\u7f72\uff0c\u6211\u4eec\u63a8\u8350YOLOv5s/m\uff0c\u5bf9\u4e8e\u4e91\u90e8\u7f72\uff0c\u6211\u4eec\u5efa\u8baeYOLOV5l/x\u3002 \u6709\u5173\u6240\u6709\u6a21\u578b\u7684\u5b8c\u6574\u6bd4\u8f83\uff0c\u8bf7\u53c2\u9605 \u8be6\u7ec6\u8868 \u4ece\u9884\u5148\u8bad\u7ec3\u7684\u6743\u91cd\u5f00\u59cb\u8bad\u7ec3\u3002\u5efa\u8bae\u7528\u4e8e\u4e2d\u5c0f\u578b\u6570\u636e\u96c6\uff08\u5373 VOC \u3001 VisDrone \u3001 GlobalWheat \uff09\u3002\u5c06\u6a21\u578b\u7684\u540d\u79f0\u4f20\u9012\u7ed9--weights\u53c2\u6570\u3002\u6a21\u578b\u81ea\u52a8\u4ece latest YOLOv5 releasse \u4e0b\u8f7d \u3002 python train . py -- data custom . yaml -- weights yolov5s yolov5m yolov5l yolov5x custom_pretrained # \u81ea\u5b9a\u4e49\u7684\u7f51\u7edc\u7ed3\u6784\u6587\u4ef6 \u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7684\u8bdd\uff0c\u63a8\u8350\u7528\u5927\u7684\u6570\u636e\u96c6(\u5373 COCO\u3001Objects365\u3001OIv6 )\u5728 --cfg \u9009\u9879\u540e\u4f20\u9012\u4f60\u611f\u5174\u8da3\u7684\u7f51\u7edc\u7ed3\u6784\u6587\u4ef6\u53c2\u6570 \u4ee5\u53ca\u7a7a\u7684 --weights '' \u53c2\u6570\uff1a python train . py -- data custom . yaml -- weights '' -- cfg yolov5s . yaml yolov5m . yaml yolov5l . yaml yolov5x . yaml \ud83d\udccc\u8bad\u7ec3\u914d\u7f6e \u5728\u4fee\u6539\u4efb\u4f55\u5185\u5bb9\u4e4b\u524d\uff0c\u9996\u5148\u4f7f\u7528\u9ed8\u8ba4\u8bbe\u7f6e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u5efa\u7acb\u6027\u80fd\u57fa\u7ebf\u3002\u8bad\u7ec3\u53c2\u6570\u7684\u5b8c\u6574\u5217\u8868,\u80fd\u591f\u5728train.py\u6587\u4ef6\u4e2d\u53d1\u73b0\u3002 Epochs : \u9ed8\u8ba4\u8bad\u7ec3300\u4e2aepochs\u3002\u5982\u679c\u65e9\u671f\u8fc7\u62df\u5408\uff0c\u5219\u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u3002\u5982\u679c\u5728300\u4e2a\u5468\u671f\u540e\u672a\u53d1\u751f\u8fc7\u62df\u5408\uff0c\u5219\u53ef\u4ee5\u8bad\u7ec3\u66f4\u957f\uff0c\u6bd4\u5982600\u30011200\u4e2aepochs\u3002 Image size: COCO\u4ee5 --img 640,\u7684\u5206\u8fa8\u7387\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u96c6\u4e2d\u6709\u5927\u91cf\u7684\u5c0f\u5bf9\u8c61\uff0c\u5b83\u53ef\u4ee5\u4ece\u66f4\u9ad8\u5206\u8fa8\u7387\uff08\u5982--img 1280\uff09\u7684\u8bad\u7ec3\u4e2d\u8bad\u7ec3\u3002 \u5982\u679c\u6709\u8bb8\u591a\u5c0f\u5bf9\u8c61\uff0c\u5219\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u5c06\u4ece\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8bad\u7ec3\u4e2d\u83b7\u76ca\u3002\u6700\u597d\u7684\u63a8\u65ad\u7ed3\u679c\u662f\u5728\u76f8\u540c\u7684--img \u5904\u83b7\u5f97\u7684 \uff0c\u5373\u5982\u679c\u5728-img 1280\u5904\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e5f\u5e94\u8be5\u5728--img 1280\u5904\u8fdb\u884c\u6d4b\u8bd5\u548c\u68c0\u6d4b\u3002 Batch Size: \u4f7f\u7528\u66f4\u5927\u7684 --batch-size \u3002\u80fd\u591f\u6709\u6548\u7f13\u89e3\u5c0f\u6837\u672c\u6570\u4ea7\u751f\u7684batchnorm\u7edf\u8ba1\u7684\u9519\u8bef\u3002 Hyperparameters\uff1a \u9ed8\u8ba4\u8d85\u53c2\u6570\u5728hyp.scratch-low.yaml\u6587\u4ef6\u4e2d\u3002\u6211\u4eec\u5efa\u8bae\u4f60\u5728\u8003\u8651\u4fee\u6539\u4efb\u4f55\u8d85\u53c2\u6570\u4e4b\u524d\uff0c\u5148\u4f7f\u7528\u9ed8\u8ba4\u8d85\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u589e\u52a0\u589e\u5f3a\u8d85\u53c2\u6570\u5c06\u51cf\u5c11\u548c\u5ef6\u8fdf\u8fc7\u5ea6\u62df\u5408\uff0c\u5141\u8bb8\u66f4\u957f\u7684\u8bad\u7ec3\u548c\u5f97\u5230\u66f4\u9ad8mAP\u503c\u3002\u51cf\u5c11\u635f\u8017\u5206\u91cf\u589e\u76ca\u8d85\u53c2\u6570\uff0c\u5982hyp['obj']\uff0c\u5c06\u6709\u52a9\u4e8e\u51cf\u5c11\u8fd9\u4e9b\u7279\u5b9a\u635f\u8017\u5206\u91cf\u4e2d\u7684\u8fc7\u5ea6\u62df\u5408\u3002\u6709\u5173\u4f18\u5316\u8fd9\u4e9b\u8d85\u53c2\u6570\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 \u300a\u8d85\u53c2\u6570\u6f14\u5316\u6559\u7a0b\u300b \u3002 ...\u66f4\u591a\u8bad\u7ec3\u7684\u8d85\u53c2\u6570\u914d\u7f6e\u8bf7\u67e5\u770b\u672c\u6587\u7684\u9644\u5f55\u3002 \u62d3\u5c55 \ud83d\udcd8 \ud83d\udccc\u4f7f\u7528\u591a\u673a\u8bad\u7ec3 \u8fd9\u4ec5\u9002\u7528\u4e8e\u591aGPU\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u3002 \u5728\u8bad\u7ec3\u4e4b\u524d\uff0c\u786e\u4fdd\u6240\u6709\u673a\u5668\u4e0a\u7684\u6587\u4ef6\u90fd\u76f8\u540c\uff0c\u6570\u636e\u96c6\u3001\u4ee3\u7801\u5e93\u7b49\u3002\u4e4b\u540e\uff0c\u786e\u4fdd\u673a\u5668\u53ef\u4ee5\u76f8\u4e92\u901a\u4fe1\u3002 \u4f60\u5fc5\u987b\u9009\u62e9\u4e00\u53f0\u4e3b\u673a\u5668\uff08\u5176\u4ed6\u673a\u5668\u5c06\u4e0e\u4e4b\u5bf9\u8bdd\uff09\u3002\u8bb0\u4e0b\u5b83\u7684\u5730\u5740\uff08master_addr\uff09\u5e76\u9009\u62e9\u4e00\u4e2a\u7aef\u53e3\uff08master-port\uff09\u3002\u5bf9\u4e8e\u4e0b\u9762\u7684\u793a\u4f8b\uff0c\u5c06\u4f7f\u7528master_addr=192.168.1.1\u548cmaster_ port=1234\u3002 \u8981\u4f7f\u7528\u5b83\uff0c\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u6307\u4ee4\uff1a # On master machine 0 $ python - m oneflow . distributed . launch -- nproc_per_node G -- nnodes N -- node_rank 0 -- master_addr \"192.168.1.1\" -- master_port 1234 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' # On machine R $ python - m oneflow . distributed . launch -- nproc_per_node G -- nnodes N -- node_rank R -- master_addr \"192.168.1.1\" -- master_port 1234 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' \u5176\u4e2dG\u662f\u6bcf\u53f0\u673a\u5668\u7684GPU\u6570\u91cf\uff0cN\u662f\u673a\u5668\u6570\u91cf\uff0cR\u662f\u4ece0\u5230\uff08N-1\uff09\u7684\u673a\u5668\u6570\u91cf\u3002 \u5047\u8bbe\u6211\u6709\u4e24\u53f0\u673a\u5668\uff0c\u6bcf\u53f0\u673a\u5668\u6709\u4e24\u4e2aGPU\uff0c\u5bf9\u4e8e\u4e0a\u9762\u7684\u60c5\u51b5\uff0cG=2\uff0cN=2\uff0cR=1\u3002 \u5728\u8fde\u63a5\u6240\u6709N\u53f0\u673a\u5668\u4e4b\u524d\uff0c\u8bad\u7ec3\u4e0d\u4f1a\u5f00\u59cb\u3002\u8f93\u51fa\u5c06\u4ec5\u663e\u793a\u5728\u4e3b\u673a\u4e0a\uff01 \u6ce8\u610f\u26a0\ufe0f oneflow\u76ee\u524d\u4e0d\u652f\u6301windows\u5e73\u53f0 --batch \u5fc5\u987b\u662fGPU\u6570\u91cf\u7684\u500d\u6570\u3002 GPU 0 \u5c06\u6bd4\u5176\u4ed6GPU\u5360\u7528\u7565\u591a\u7684\u5185\u5b58\uff0c\u56e0\u4e3a\u5b83\u7ef4\u62a4EMA\u5e76\u8d1f\u8d23\u68c0\u67e5\u70b9\u7b49\u3002 \u5982\u679c\u4f60\u5f97\u5230 RuntimeError: Address already in use \uff0c\u53ef\u80fd\u662f\u56e0\u4e3a\u4f60\u4e00\u6b21\u6b63\u5728\u8fd0\u884c\u591a\u4e2a\u8bad\u7ec3\u7a0b\u5e8f\u3002\u8981\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u53ea\u9700\u901a\u8fc7\u6dfb\u52a0--master_port\u6765\u4f7f\u7528\u4e0d\u540c\u7684\u7aef\u53e3\u53f7\uff0c\u5982\u4e0b\u6240\u793a $ python - m oneflow . distributed . launch -- master_port 1234 -- nproc_per_node 2 ... \u914d\u7f6e\u4ee3\u7801\u26a1 # prepare t = https : // github . com / Oneflow - Inc / one - yolov5 : latest && sudo docker pull $ t && sudo docker run - it -- ipc = host -- gpus all - v \"$(pwd)\" / coco : / usr / src / coco $ t pip install -- pre oneflow - f https : // staging . oneflow . info / branch / master / cu112 cd .. && rm - rf app && git clone https : // github . com / Oneflow - Inc / one - yolov5 - b master app && cd app cp data / coco . yaml data / coco_profile . yaml # profile python train . py -- batch - size 16 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- batch - size 32 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 python - m oneflow . distributed . launch -- nproc_per_node 4 train . py -- batch - size 64 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 , 2 , 3 python - m oneflow . distributed . launch -- nproc_per_node 8 train . py -- batch - size 128 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 \u9644\u4ef6 \u88683.1 \u88683.1 : train.py\u53c2\u6570\u89e3\u6790\u8868 \u53c2\u6570 help \u5e2e\u52a9 --weight initial weights path \u52a0\u8f7d\u7684\u6743\u91cd\u6587\u4ef6\u8def\u5f84 --cfg model.yaml path \u6a21\u578b\u914d\u7f6e\u6587\u4ef6\uff0c\u7f51\u7edc\u7ed3\u6784 \u8def\u5f84 --data dataset.yaml path \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6\uff0c\u6570\u636e\u96c6\u8def\u5f84 --hyp hyperparameters path \u8d85\u53c2\u6570\u6587\u4ef6 \u8def\u5f84 --epochs Total training rounds \u8bad\u7ec3\u603b\u8f6e\u6b21 --batch-size total batch size for all GPUs, -1 for autobatch \u4e00\u6b21\u8bad\u7ec3\u6240\u9009\u53d6\u7684\u6837\u672c\u6570 --imgsz train, val image size (pixels) \u8f93\u5165\u56fe\u7247\u5206\u8fa8\u7387\u5927\u5c0f --rect rectangular training \u662f\u5426\u91c7\u7528\u77e9\u5f62\u8bad\u7ec3\uff0c\u9ed8\u8ba4False --resume resume most recent training \u63a5\u7740\u6253\u65ad\u8bad\u7ec3\u4e0a\u6b21\u7684\u7ed3\u679c\u63a5\u7740\u8bad\u7ec3 --nosave only save final checkpoint \u53ea\u4fdd\u5b58\u6700\u7ec8\u7684\u6a21\u578b\uff0c\u9ed8\u8ba4False --noautoanchor disable AutoAnchor \u4e0d\u81ea\u52a8\u8c03\u6574anchor\uff0c\u9ed8\u8ba4False --noplots save no plot files \u4e0d\u4fdd\u5b58\u6253\u5370\u6587\u4ef6\uff0c\u9ed8\u8ba4False --evolve evolve hyperparameters for x generations \u662f\u5426\u8fdb\u884c\u8d85\u53c2\u6570\u8fdb\u5316\uff0c\u9ed8\u8ba4False --bucket gsutil bucket \u8c37\u6b4c\u4e91\u76d8bucket\uff0c\u4e00\u822c\u4e0d\u4f1a\u7528\u5230 --cache --cache images in \"ram\" (default) or \"disk\" \u662f\u5426\u63d0\u524d\u7f13\u5b58\u56fe\u7247\u5230\u5185\u5b58\uff0c\u4ee5\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\uff0c\u9ed8\u8ba4False --device cuda device, i.e. 0 or 0,1,2,3 or cpu \u8bad\u7ec3\u7684\u8bbe\u5907\uff0ccpu\uff1b0(\u8868\u793a\u4e00\u4e2agpu\u8bbe\u5907cuda:0)\uff1b0,1,2,3(\u591a\u4e2agpu\u8bbe\u5907) --multi-scale vary img-size +/- 50%% \u662f\u5426\u8fdb\u884c\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u9ed8\u8ba4False --single-cls train multi-class data as single-class \u6570\u636e\u96c6\u662f\u5426\u53ea\u6709\u4e00\u4e2a\u7c7b\u522b\uff0c\u9ed8\u8ba4False --optimizer optimizer \u4f18\u5316\u5668 --sync-bn use SyncBatchNorm, only available in DDP mode \u662f\u5426\u4f7f\u7528\u8de8\u5361\u540c\u6b65BN,\u5728DDP\u6a21\u5f0f\u4f7f\u7528 --workers max dataloader workers (per RANK in DDP mode) dataloader\u7684\u6700\u5927worker\u6570\u91cf --project save to project path \u4fdd\u5b58\u5230\u9879\u76ee\u7ed3\u679c\u5730\u5740 --name save to project/name/ \u4fdd\u5b58\u5230\u9879\u76ee\u7ed3\u679c/\u540d\u79f0 --exist-ok existing project/name ok, do not increment \u73b0\u6709\u9879\u76ee/\u540d\u79f0\u786e\u5b9a\uff0c\u4e0d\u9012\u589e\uff0c\u9ed8\u8ba4False --quad quad dataloader \u56db\u5143\u6570\u636e\u52a0\u8f7d\u5668 \u5f00\u542f\u4e4b\u540e\u5728\u5c3a\u5bf8\u5927\u4e8e640\u7684\u56fe\u50cf\u4e0a\u8bc6\u522b\u6548\u679c\u66f4\u597d\uff0c\u4f46\u662f\u6709\u53ef\u80fd\u4f1a\u4f7f\u5728640\u5c3a\u5bf8\u7684\u56fe\u7247\u4e0a\u6548\u679c\u66f4\u5dee --cos-lr cosine LR scheduler \u662f\u5426\u91c7\u7528\u9000\u706b\u4f59\u5f26\u5b66\u4e60\u7387\uff0c\u9ed8\u8ba4False --label-smoothing Label smoothing epsilon \u6807\u7b7e\u5e73\u6ed1 --patience EarlyStopping patience (epochs without improvement) \u65e9\u505c\u673a\u5236\uff0c\u9ed8\u8ba4False --freez Freeze layers: backbone=10, first3=0 1 2 \u51bb\u7ed3\u5c42\u6570\uff0c\u9ed8\u8ba4\u4e0d\u51bb\u7ed3 --save-period Save checkpoint every x epochs (disabled if < 1) \u7528\u4e8e\u8bb0\u5f55\u8bad\u7ec3\u65e5\u5fd7\u4fe1\u606f\uff0cint \u578b\uff0c\u9ed8\u8ba4 -1 --seed Global training seed \u968f\u673a\u6570\u79cd\u5b50\u8bbe\u7f6e --local_rank Automatic DDP Multi-GPU argument, do not modify \u81ea\u52a8\u5355\u673a\u591a\u5361\u8bad\u7ec3 \u4e00\u822c\u4e0d\u6539\u52a8 Reference https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data https://docs.ultralytics.com/quick-start/","title":"3.1 \u5feb\u901f\u5f00\u59cb"},{"location":"tutorials/03_chapter/quick_start.html#_1","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u4f60\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \ud83d\udce2 \u58f0\u660e:Model Train(\u4ee5coco\u6570\u636e\u96c6\u4e3a\u4f8b)","title":"\u524d\u8a00"},{"location":"tutorials/03_chapter/quick_start.html#_2","text":"","title":"\u9879\u76ee\u7ed3\u6784\u9884\u89c8 \ud83c\udfe0"},{"location":"tutorials/03_chapter/quick_start.html#_3","text":"git clone https://github.com/Oneflow-Inc/one-yolov5 # clone cd one-yolov5 pip install -r requirements.txt # install","title":"\u5b89\u88c5 \ud83d\udcda"},{"location":"tutorials/03_chapter/quick_start.html#_4","text":"\u6ce8\u610f\u26a0\ufe0f: oneflow\u76ee\u524d\u4e0d\u652f\u6301windows\u5e73\u53f0 --batch \u5fc5\u987b\u662fGPU\u6570\u91cf\u7684\u500d\u6570\u3002 GPU 0 \u5c06\u6bd4\u5176\u4ed6GPU\u5360\u7528\u7565\u591a\u7684\u5185\u5b58\uff0c\u56e0\u4e3a\u5b83\u7ef4\u62a4EMA\u5e76\u8d1f\u8d23\u68c0\u67e5\u70b9\u7b49\u3002","title":"\u8bad\u7ec3 \ud83d\ude80"},{"location":"tutorials/03_chapter/quick_start.html#_5","text":"\u5e26\u6743\u91cd\u8bad\u7ec3 \ud83d\ude80 $ python path/to/train.py --data coco.yaml --weights yolov5s --img 640 \u4e0d\u5e26\u6743\u91cd\u8bad\u7ec3 \ud83d\ude80 $ python path/to/train.py --data coco.yaml --weights '' --cfg yolov5s.yaml --img 640","title":"\ud83d\udccc\u4e24\u79cd\u8bad\u7ec3\u65b9\u5f0f"},{"location":"tutorials/03_chapter/quick_start.html#gpu","text":"$ python train.py --data coco.yaml --weights yolov5s --device 0","title":"\ud83d\udccc\u5355GPU\u8bad\u7ec3"},{"location":"tutorials/03_chapter/quick_start.html#gpu_1","text":"$ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --weights yolov5s --device 0,1 \u6ce8\u610f\u26a0\ufe0f\uff1a --nproc_per_node \u6307\u5b9a\u8981\u4f7f\u7528\u591a\u5c11GPU\u3002\u4e3e\u4e2a\u4f8b\u5b50\ud83c\udf30:\u5728\u4e0a\u9762\ud83d\udc46 \u591aGPU\u8bad\u7ec3\u6307\u4ee4\u4e2d\u5b83\u662f2\u3002 --batch \u662f\u603b\u6279\u91cf\u5927\u5c0f\u3002\u5b83\u5c06\u5e73\u5747\u5206\u914d\u7ed9\u6bcf\u4e2aGPU\u3002\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u6bcfGPU\u662f64/2\uff1d32\u3002 --cfg : \u6307\u5b9a\u4e00\u4e2a\u5305\u542b\u6240\u6709\u8bc4\u4f30\u53c2\u6570\u7684\u914d\u7f6e\u6587\u4ef6\u3002 \u4e0a\u9762\u7684\u4ee3\u7801\u9ed8\u8ba4\u4f7f\u7528GPU 0\u2026\uff08N-1\uff09\u3002\u4f7f\u7528\u7279\u5b9a\u7684GPU\ud83e\udd14\ufe0f\uff1f \u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5728 --device \u540e\u8ddf\u6307\u5b9aGPU\u6765\u5b9e\u73b0\u3002\u300c\u6848\u4f8b\ud83c\udf30\u300d\uff0c\u5728\u4e0b\u9762\u7684\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5c06\u4f7f\u7528GPU 2,3\u3002 $ python -m oneflow.distributed.launch --nproc_per_node 2 train.py --batch 64 --data coco.yaml --cfg yolov5s.yaml --weights '' --device 2,3","title":"\ud83d\udccc\u591aGPU\u8bad\u7ec3"},{"location":"tutorials/03_chapter/quick_start.html#_6","text":"\u5982\u679c\u4f60\u7684\u8bad\u7ec3\u8fdb\u7a0b\u4e2d\u65ad\u4e86\uff0c\u4f60\u53ef\u4ee5\u8fd9\u6837\u6062\u590d\u5148\u524d\u7684\u8bad\u7ec3\u8fdb\u7a0b\u3002 # \u591a\u5361\u8bad\u7ec3. python -m oneflow.distributed.launch --nproc_per_node 2 train.py --resume \u4f60\u4e5f\u53ef\u4ee5\u901a\u8fc7 --resume \u53c2\u6570\u6307\u5b9a\u8981\u6062\u590d\u7684\u6a21\u578b\u8def\u5f84 # \u8bb0\u5f97\u628a /path/to/your/checkpoint/path \u66ff\u6362\u4e3a\u4f60\u8981\u6062\u590d\u8bad\u7ec3\u7684\u6a21\u578b\u6743\u91cd\u8def\u5f84 --resume /path/to/your/checkpoint/path","title":"\ud83d\udccc\u6062\u590d\u8bad\u7ec3"},{"location":"tutorials/03_chapter/quick_start.html#syncbatchnorm","text":"SyncBatchNorm \u53ef\u4ee5\u63d0\u9ad8\u591agpu\u8bad\u7ec3\u7684\u51c6\u786e\u6027\uff0c\u4f46\u4f1a\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u901f\u5ea6\u3002\u5b83\u4ec5\u9002\u7528\u4e8e\u591aGPU DistributedDataParallel \u8bad\u7ec3\u3002 \u5efa\u8bae\u6700\u597d\u5728\u6bcf\u4e2aGPU\u4e0a\u7684\u6837\u672c\u6570\u91cf\u8f83\u5c0f\uff08 \u6837\u672c\u6570\u91cf<=8 \uff09\u65f6\u4f7f\u7528\u3002 \u8981\u4f7f\u7528SyncBatchNorm\uff0c\u53ea\u9700\u5c06\u6dfb\u52a0 --sync-bn \u53c2\u6570\u9009\u9879\uff0c\u5177\u4f53\u300c\u6848\u4f8b\ud83c\udf30\u300d\u5982\u4e0b: $ python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' -- sync - bn","title":"\ud83d\udccc\u4f7f\u7528SyncBatchNorm"},{"location":"tutorials/03_chapter/quick_start.html#_7","text":"\u4e0b\u9762\u7684\u547d\u4ee4\u662f\u5728COCO val2017\u6570\u636e\u96c6\u4e0a\u4ee5640\u50cf\u7d20\u7684\u56fe\u50cf\u5927\u5c0f\u6d4b\u8bd5 yolov5x \u6a21\u578b\u3002 yolov5x \u662f\u53ef\u7528\u5c0f\u6a21\u578b\u4e2d\u6700\u5927\u4e14\u6700\u7cbe\u786e\u7684\uff0c\u5176\u5b83\u53ef\u7528\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5s \uff0c yolov5l \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 README-TABLE $ python val . py -- weights yolov5x -- data coco . yaml -- img 640","title":"\u8bc4\u4f30 \ud83d\udc63"},{"location":"tutorials/03_chapter/quick_start.html#_8","text":"\u9996\u5148\uff0c\u4e0b\u8f7d\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u6743\u91cd\u6587\u4ef6\uff0c\u6216\u9009\u62e9\u4f60\u81ea\u5df1\u8bad\u7ec3\u7684\u6a21\u578b\uff1b \u7136\u540e\uff0c \u901a\u8fc7 detect.py\u6587\u4ef6\u8fdb\u884c\u63a8\u7406\u26a1\u3002 python path / to / detect . py -- weights yolov5s -- source 0 # webcam img . jpg # image vid . mp4 # video path / # directory path /*. jpg # glob 'https://youtu.be/Zgi9g1ksQHc' # YouTube 'rtsp://example.com/media.mp4' # RTSP, RTMP, HTTP stream \u6ce8\u610f\u26a0\ufe0f: - \u68c0\u6d4b\u5355\u4e2a\u56fe\u7247 \u4f7f\u7528\u793a\u4f8b python path/to/detect.py --weights yolov5s --source path/to/imgs/hello.jpg - \u60f3\u6279\u91cf\u68c0\u6d4b path/to/imgs/ \u8def\u5f84\u4e0b\u7684\u56fe\u7247, \u4f7f\u7528\u793a\u4f8b python path/to/detect.py --weights yolov5s --source path/to/imgs/ \uff0c\u6ce8\u610f\u4e0d\u8981\u7528 python path/to/detect.py --weights yolov5s --source path/to/imgs/*.jpg \u3002","title":"\u63a8\u7406 \ud83d\udc4d"},{"location":"tutorials/03_chapter/quick_start.html#_9","text":"","title":"\u8bad\u7ec3\u7ed3\u679c\ud83c\udf1f"},{"location":"tutorials/03_chapter/quick_start.html#_10","text":"\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u7ed3\u679c\u90fd\u8bb0\u5f55\u4e3aruns/train\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u65b0\u8bad\u7ec3\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u8bad\u7ec3\u7ed3\u679c\u76ee\u5f55\uff0c\u5982runs/train/exp2\u3001runs/train/exp3\u7b49\u3002\u67e5\u770b\u8bad\u7ec3\u548c\u6d4b\u8bd5JPG\u4ee5\u67e5\u770b mosaics, labels, predictions and augmentation \u6548\u679c\u3002 \u6ce8\u610f\uff1aMosaic Dataloader \u7528\u4e8e\u8bad\u7ec3\uff08\u5982\u4e0b\u6240\u793a\uff09\uff0c\u8fd9\u662fUltralytics\u53d1\u8868\u7684\u65b0\u6982\u5ff5\uff0c\u9996\u6b21\u51fa\u73b0\u5728 YOLOv4 \u4e2d\u3002 train_batch0.jpg \u663e\u793a batch \u4e3a 0 \u7684 (mosaics and labels): val_batch0_labels.jpg \u5c55\u793a\u6d4b\u8bd5 batch \u4e3a 0 \u7684labels: val_batch0_pred.jpg \u5c55\u793a\u6d4b\u8bd5 batch \u4e3a 0 predictions(\u9884\u6d4b): \u8bad\u7ec3\u8bad\u635f\u5931\u548c\u6027\u80fd\u7684\u6307\u6807\u6709\u8bb0\u5f55\u5230Tensorboard\u548c\u81ea\u5b9a\u4e49\u7ed3\u679c\u4e2d results.csv\u65e5\u5fd7\u6587\u4ef6 \uff0c\u8bad\u7ec3\u8bad\u5b8c\u6210\u540e\u4f5c\u4e3a\u7ed3\u679c\u7ed8\u5236 results.png\u5982\u4e0b\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5728COCO128\u4e0a\u8bad\u7ec3\u7684YOLOV5\u7ed3\u679c - \u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3 (\u84dd\u8272)\u3002 - \u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd --weights yolov5s (\u6a59\u8272)\u3002 \u5177\u4f53\u7684\u6307\u6807\u5206\u6790\u8be6\u89c1\u6587\u7ae0 \u300a\u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30\u300b","title":"\ud83d\udccc\u672c\u5730\u65e5\u5fd7"},{"location":"tutorials/03_chapter/quick_start.html#_11","text":"\ud83d\udce2 \u58f0\u660e\uff1a\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c \u53ea\u8981\u6570\u636e\u96c6\u8db3\u591f\u5927\u4e14\u6807\u8bb0\u826f\u597d \uff0c\u5c31\u53ef\u4ee5\u5728\u4e0d\u6539\u53d8\u6a21\u578b\u6216\u8bad\u7ec3\u8bbe\u7f6e\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u826f\u597d\u7684\u7ed3\u679c\u3002 \u5982\u679c\u4e00\u5f00\u59cb\u4f60\u6ca1\u6709\u5f97\u5230\u597d\u7684\u7ed3\u679c\uff0c\u4f60\u53ef\u4ee5\u91c7\u53d6\u4e00\u4e9b\u6b65\u9aa4\u6765\u6539\u8fdb\uff0c\u4f46\u6211\u4eec\u59cb\u7ec8\u5efa\u8bae\u7528\u6237\u5728\u8003\u8651\u4efb\u4f55\u66f4\u6539\u4e4b\u524d\u5148\u4f7f\u7528\u6240\u6709\u9ed8\u8ba4\u8bbe\u7f6e\u8fdb\u884c\u4e00\u6b21\u8bad\u7ec3\u3002\u8fd9\u6709\u52a9\u4e8e\u5efa\u7acb\u8bc4\u4f30\u57fa\u51c6\u548c\u53d1\u73b0\u9700\u8981\u6539\u8fdb\u7684\u5730\u65b9 \ud83d\ude80\u3002","title":"\u8bad\u7ec3\u6280\u5de7\ud83d\udd25"},{"location":"tutorials/03_chapter/quick_start.html#_12","text":"\u7c7b\u4f3c\u4e8eYOLOv5x\u548cYOLOv5x6\u7684\u5927\u578b\u6a21\u578b\u5728\u51e0\u4e4e\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u4f1a\u4ea7\u751f\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u4f46\u53c2\u6570\u66f4\u591a\uff0c\u9700\u8981\u66f4\u591a\u7684CUDA\u5185\u5b58\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd0\u884c\u901f\u5ea6\u8f83\u6162\u3002 \u5bf9\u4e8e\u79fb\u52a8\u90e8\u7f72\uff0c\u6211\u4eec\u63a8\u8350YOLOv5s/m\uff0c\u5bf9\u4e8e\u4e91\u90e8\u7f72\uff0c\u6211\u4eec\u5efa\u8baeYOLOV5l/x\u3002 \u6709\u5173\u6240\u6709\u6a21\u578b\u7684\u5b8c\u6574\u6bd4\u8f83\uff0c\u8bf7\u53c2\u9605 \u8be6\u7ec6\u8868 \u4ece\u9884\u5148\u8bad\u7ec3\u7684\u6743\u91cd\u5f00\u59cb\u8bad\u7ec3\u3002\u5efa\u8bae\u7528\u4e8e\u4e2d\u5c0f\u578b\u6570\u636e\u96c6\uff08\u5373 VOC \u3001 VisDrone \u3001 GlobalWheat \uff09\u3002\u5c06\u6a21\u578b\u7684\u540d\u79f0\u4f20\u9012\u7ed9--weights\u53c2\u6570\u3002\u6a21\u578b\u81ea\u52a8\u4ece latest YOLOv5 releasse \u4e0b\u8f7d \u3002 python train . py -- data custom . yaml -- weights yolov5s yolov5m yolov5l yolov5x custom_pretrained # \u81ea\u5b9a\u4e49\u7684\u7f51\u7edc\u7ed3\u6784\u6587\u4ef6 \u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7684\u8bdd\uff0c\u63a8\u8350\u7528\u5927\u7684\u6570\u636e\u96c6(\u5373 COCO\u3001Objects365\u3001OIv6 )\u5728 --cfg \u9009\u9879\u540e\u4f20\u9012\u4f60\u611f\u5174\u8da3\u7684\u7f51\u7edc\u7ed3\u6784\u6587\u4ef6\u53c2\u6570 \u4ee5\u53ca\u7a7a\u7684 --weights '' \u53c2\u6570\uff1a python train . py -- data custom . yaml -- weights '' -- cfg yolov5s . yaml yolov5m . yaml yolov5l . yaml yolov5x . yaml","title":"\ud83d\udccc\u6a21\u578b\u9009\u62e9"},{"location":"tutorials/03_chapter/quick_start.html#_13","text":"\u5728\u4fee\u6539\u4efb\u4f55\u5185\u5bb9\u4e4b\u524d\uff0c\u9996\u5148\u4f7f\u7528\u9ed8\u8ba4\u8bbe\u7f6e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u5efa\u7acb\u6027\u80fd\u57fa\u7ebf\u3002\u8bad\u7ec3\u53c2\u6570\u7684\u5b8c\u6574\u5217\u8868,\u80fd\u591f\u5728train.py\u6587\u4ef6\u4e2d\u53d1\u73b0\u3002 Epochs : \u9ed8\u8ba4\u8bad\u7ec3300\u4e2aepochs\u3002\u5982\u679c\u65e9\u671f\u8fc7\u62df\u5408\uff0c\u5219\u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u3002\u5982\u679c\u5728300\u4e2a\u5468\u671f\u540e\u672a\u53d1\u751f\u8fc7\u62df\u5408\uff0c\u5219\u53ef\u4ee5\u8bad\u7ec3\u66f4\u957f\uff0c\u6bd4\u5982600\u30011200\u4e2aepochs\u3002 Image size: COCO\u4ee5 --img 640,\u7684\u5206\u8fa8\u7387\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u96c6\u4e2d\u6709\u5927\u91cf\u7684\u5c0f\u5bf9\u8c61\uff0c\u5b83\u53ef\u4ee5\u4ece\u66f4\u9ad8\u5206\u8fa8\u7387\uff08\u5982--img 1280\uff09\u7684\u8bad\u7ec3\u4e2d\u8bad\u7ec3\u3002 \u5982\u679c\u6709\u8bb8\u591a\u5c0f\u5bf9\u8c61\uff0c\u5219\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u5c06\u4ece\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u8bad\u7ec3\u4e2d\u83b7\u76ca\u3002\u6700\u597d\u7684\u63a8\u65ad\u7ed3\u679c\u662f\u5728\u76f8\u540c\u7684--img \u5904\u83b7\u5f97\u7684 \uff0c\u5373\u5982\u679c\u5728-img 1280\u5904\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e5f\u5e94\u8be5\u5728--img 1280\u5904\u8fdb\u884c\u6d4b\u8bd5\u548c\u68c0\u6d4b\u3002 Batch Size: \u4f7f\u7528\u66f4\u5927\u7684 --batch-size \u3002\u80fd\u591f\u6709\u6548\u7f13\u89e3\u5c0f\u6837\u672c\u6570\u4ea7\u751f\u7684batchnorm\u7edf\u8ba1\u7684\u9519\u8bef\u3002 Hyperparameters\uff1a \u9ed8\u8ba4\u8d85\u53c2\u6570\u5728hyp.scratch-low.yaml\u6587\u4ef6\u4e2d\u3002\u6211\u4eec\u5efa\u8bae\u4f60\u5728\u8003\u8651\u4fee\u6539\u4efb\u4f55\u8d85\u53c2\u6570\u4e4b\u524d\uff0c\u5148\u4f7f\u7528\u9ed8\u8ba4\u8d85\u53c2\u6570\u8fdb\u884c\u8bad\u7ec3\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u589e\u52a0\u589e\u5f3a\u8d85\u53c2\u6570\u5c06\u51cf\u5c11\u548c\u5ef6\u8fdf\u8fc7\u5ea6\u62df\u5408\uff0c\u5141\u8bb8\u66f4\u957f\u7684\u8bad\u7ec3\u548c\u5f97\u5230\u66f4\u9ad8mAP\u503c\u3002\u51cf\u5c11\u635f\u8017\u5206\u91cf\u589e\u76ca\u8d85\u53c2\u6570\uff0c\u5982hyp['obj']\uff0c\u5c06\u6709\u52a9\u4e8e\u51cf\u5c11\u8fd9\u4e9b\u7279\u5b9a\u635f\u8017\u5206\u91cf\u4e2d\u7684\u8fc7\u5ea6\u62df\u5408\u3002\u6709\u5173\u4f18\u5316\u8fd9\u4e9b\u8d85\u53c2\u6570\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684 \u300a\u8d85\u53c2\u6570\u6f14\u5316\u6559\u7a0b\u300b \u3002 ...\u66f4\u591a\u8bad\u7ec3\u7684\u8d85\u53c2\u6570\u914d\u7f6e\u8bf7\u67e5\u770b\u672c\u6587\u7684\u9644\u5f55\u3002","title":"\ud83d\udccc\u8bad\u7ec3\u914d\u7f6e"},{"location":"tutorials/03_chapter/quick_start.html#_14","text":"","title":"\u62d3\u5c55 \ud83d\udcd8"},{"location":"tutorials/03_chapter/quick_start.html#_15","text":"\u8fd9\u4ec5\u9002\u7528\u4e8e\u591aGPU\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u3002 \u5728\u8bad\u7ec3\u4e4b\u524d\uff0c\u786e\u4fdd\u6240\u6709\u673a\u5668\u4e0a\u7684\u6587\u4ef6\u90fd\u76f8\u540c\uff0c\u6570\u636e\u96c6\u3001\u4ee3\u7801\u5e93\u7b49\u3002\u4e4b\u540e\uff0c\u786e\u4fdd\u673a\u5668\u53ef\u4ee5\u76f8\u4e92\u901a\u4fe1\u3002 \u4f60\u5fc5\u987b\u9009\u62e9\u4e00\u53f0\u4e3b\u673a\u5668\uff08\u5176\u4ed6\u673a\u5668\u5c06\u4e0e\u4e4b\u5bf9\u8bdd\uff09\u3002\u8bb0\u4e0b\u5b83\u7684\u5730\u5740\uff08master_addr\uff09\u5e76\u9009\u62e9\u4e00\u4e2a\u7aef\u53e3\uff08master-port\uff09\u3002\u5bf9\u4e8e\u4e0b\u9762\u7684\u793a\u4f8b\uff0c\u5c06\u4f7f\u7528master_addr=192.168.1.1\u548cmaster_ port=1234\u3002 \u8981\u4f7f\u7528\u5b83\uff0c\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u6307\u4ee4\uff1a # On master machine 0 $ python - m oneflow . distributed . launch -- nproc_per_node G -- nnodes N -- node_rank 0 -- master_addr \"192.168.1.1\" -- master_port 1234 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' # On machine R $ python - m oneflow . distributed . launch -- nproc_per_node G -- nnodes N -- node_rank R -- master_addr \"192.168.1.1\" -- master_port 1234 train . py -- batch 64 -- data coco . yaml -- cfg yolov5s . yaml -- weights '' \u5176\u4e2dG\u662f\u6bcf\u53f0\u673a\u5668\u7684GPU\u6570\u91cf\uff0cN\u662f\u673a\u5668\u6570\u91cf\uff0cR\u662f\u4ece0\u5230\uff08N-1\uff09\u7684\u673a\u5668\u6570\u91cf\u3002 \u5047\u8bbe\u6211\u6709\u4e24\u53f0\u673a\u5668\uff0c\u6bcf\u53f0\u673a\u5668\u6709\u4e24\u4e2aGPU\uff0c\u5bf9\u4e8e\u4e0a\u9762\u7684\u60c5\u51b5\uff0cG=2\uff0cN=2\uff0cR=1\u3002 \u5728\u8fde\u63a5\u6240\u6709N\u53f0\u673a\u5668\u4e4b\u524d\uff0c\u8bad\u7ec3\u4e0d\u4f1a\u5f00\u59cb\u3002\u8f93\u51fa\u5c06\u4ec5\u663e\u793a\u5728\u4e3b\u673a\u4e0a\uff01","title":"\ud83d\udccc\u4f7f\u7528\u591a\u673a\u8bad\u7ec3"},{"location":"tutorials/03_chapter/quick_start.html#_16","text":"oneflow\u76ee\u524d\u4e0d\u652f\u6301windows\u5e73\u53f0 --batch \u5fc5\u987b\u662fGPU\u6570\u91cf\u7684\u500d\u6570\u3002 GPU 0 \u5c06\u6bd4\u5176\u4ed6GPU\u5360\u7528\u7565\u591a\u7684\u5185\u5b58\uff0c\u56e0\u4e3a\u5b83\u7ef4\u62a4EMA\u5e76\u8d1f\u8d23\u68c0\u67e5\u70b9\u7b49\u3002 \u5982\u679c\u4f60\u5f97\u5230 RuntimeError: Address already in use \uff0c\u53ef\u80fd\u662f\u56e0\u4e3a\u4f60\u4e00\u6b21\u6b63\u5728\u8fd0\u884c\u591a\u4e2a\u8bad\u7ec3\u7a0b\u5e8f\u3002\u8981\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u53ea\u9700\u901a\u8fc7\u6dfb\u52a0--master_port\u6765\u4f7f\u7528\u4e0d\u540c\u7684\u7aef\u53e3\u53f7\uff0c\u5982\u4e0b\u6240\u793a $ python - m oneflow . distributed . launch -- master_port 1234 -- nproc_per_node 2 ...","title":"\u6ce8\u610f\u26a0\ufe0f"},{"location":"tutorials/03_chapter/quick_start.html#_17","text":"# prepare t = https : // github . com / Oneflow - Inc / one - yolov5 : latest && sudo docker pull $ t && sudo docker run - it -- ipc = host -- gpus all - v \"$(pwd)\" / coco : / usr / src / coco $ t pip install -- pre oneflow - f https : // staging . oneflow . info / branch / master / cu112 cd .. && rm - rf app && git clone https : // github . com / Oneflow - Inc / one - yolov5 - b master app && cd app cp data / coco . yaml data / coco_profile . yaml # profile python train . py -- batch - size 16 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 python - m oneflow . distributed . launch -- nproc_per_node 2 train . py -- batch - size 32 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 python - m oneflow . distributed . launch -- nproc_per_node 4 train . py -- batch - size 64 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 , 2 , 3 python - m oneflow . distributed . launch -- nproc_per_node 8 train . py -- batch - size 128 -- data coco_profile . yaml -- weights yolov5l -- epochs 1 -- device 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7","title":"\u914d\u7f6e\u4ee3\u7801\u26a1"},{"location":"tutorials/03_chapter/quick_start.html#_18","text":"\u88683.1 \u88683.1 : train.py\u53c2\u6570\u89e3\u6790\u8868 \u53c2\u6570 help \u5e2e\u52a9 --weight initial weights path \u52a0\u8f7d\u7684\u6743\u91cd\u6587\u4ef6\u8def\u5f84 --cfg model.yaml path \u6a21\u578b\u914d\u7f6e\u6587\u4ef6\uff0c\u7f51\u7edc\u7ed3\u6784 \u8def\u5f84 --data dataset.yaml path \u6570\u636e\u96c6\u914d\u7f6e\u6587\u4ef6\uff0c\u6570\u636e\u96c6\u8def\u5f84 --hyp hyperparameters path \u8d85\u53c2\u6570\u6587\u4ef6 \u8def\u5f84 --epochs Total training rounds \u8bad\u7ec3\u603b\u8f6e\u6b21 --batch-size total batch size for all GPUs, -1 for autobatch \u4e00\u6b21\u8bad\u7ec3\u6240\u9009\u53d6\u7684\u6837\u672c\u6570 --imgsz train, val image size (pixels) \u8f93\u5165\u56fe\u7247\u5206\u8fa8\u7387\u5927\u5c0f --rect rectangular training \u662f\u5426\u91c7\u7528\u77e9\u5f62\u8bad\u7ec3\uff0c\u9ed8\u8ba4False --resume resume most recent training \u63a5\u7740\u6253\u65ad\u8bad\u7ec3\u4e0a\u6b21\u7684\u7ed3\u679c\u63a5\u7740\u8bad\u7ec3 --nosave only save final checkpoint \u53ea\u4fdd\u5b58\u6700\u7ec8\u7684\u6a21\u578b\uff0c\u9ed8\u8ba4False --noautoanchor disable AutoAnchor \u4e0d\u81ea\u52a8\u8c03\u6574anchor\uff0c\u9ed8\u8ba4False --noplots save no plot files \u4e0d\u4fdd\u5b58\u6253\u5370\u6587\u4ef6\uff0c\u9ed8\u8ba4False --evolve evolve hyperparameters for x generations \u662f\u5426\u8fdb\u884c\u8d85\u53c2\u6570\u8fdb\u5316\uff0c\u9ed8\u8ba4False --bucket gsutil bucket \u8c37\u6b4c\u4e91\u76d8bucket\uff0c\u4e00\u822c\u4e0d\u4f1a\u7528\u5230 --cache --cache images in \"ram\" (default) or \"disk\" \u662f\u5426\u63d0\u524d\u7f13\u5b58\u56fe\u7247\u5230\u5185\u5b58\uff0c\u4ee5\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\uff0c\u9ed8\u8ba4False --device cuda device, i.e. 0 or 0,1,2,3 or cpu \u8bad\u7ec3\u7684\u8bbe\u5907\uff0ccpu\uff1b0(\u8868\u793a\u4e00\u4e2agpu\u8bbe\u5907cuda:0)\uff1b0,1,2,3(\u591a\u4e2agpu\u8bbe\u5907) --multi-scale vary img-size +/- 50%% \u662f\u5426\u8fdb\u884c\u591a\u5c3a\u5ea6\u8bad\u7ec3\uff0c\u9ed8\u8ba4False --single-cls train multi-class data as single-class \u6570\u636e\u96c6\u662f\u5426\u53ea\u6709\u4e00\u4e2a\u7c7b\u522b\uff0c\u9ed8\u8ba4False --optimizer optimizer \u4f18\u5316\u5668 --sync-bn use SyncBatchNorm, only available in DDP mode \u662f\u5426\u4f7f\u7528\u8de8\u5361\u540c\u6b65BN,\u5728DDP\u6a21\u5f0f\u4f7f\u7528 --workers max dataloader workers (per RANK in DDP mode) dataloader\u7684\u6700\u5927worker\u6570\u91cf --project save to project path \u4fdd\u5b58\u5230\u9879\u76ee\u7ed3\u679c\u5730\u5740 --name save to project/name/ \u4fdd\u5b58\u5230\u9879\u76ee\u7ed3\u679c/\u540d\u79f0 --exist-ok existing project/name ok, do not increment \u73b0\u6709\u9879\u76ee/\u540d\u79f0\u786e\u5b9a\uff0c\u4e0d\u9012\u589e\uff0c\u9ed8\u8ba4False --quad quad dataloader \u56db\u5143\u6570\u636e\u52a0\u8f7d\u5668 \u5f00\u542f\u4e4b\u540e\u5728\u5c3a\u5bf8\u5927\u4e8e640\u7684\u56fe\u50cf\u4e0a\u8bc6\u522b\u6548\u679c\u66f4\u597d\uff0c\u4f46\u662f\u6709\u53ef\u80fd\u4f1a\u4f7f\u5728640\u5c3a\u5bf8\u7684\u56fe\u7247\u4e0a\u6548\u679c\u66f4\u5dee --cos-lr cosine LR scheduler \u662f\u5426\u91c7\u7528\u9000\u706b\u4f59\u5f26\u5b66\u4e60\u7387\uff0c\u9ed8\u8ba4False --label-smoothing Label smoothing epsilon \u6807\u7b7e\u5e73\u6ed1 --patience EarlyStopping patience (epochs without improvement) \u65e9\u505c\u673a\u5236\uff0c\u9ed8\u8ba4False --freez Freeze layers: backbone=10, first3=0 1 2 \u51bb\u7ed3\u5c42\u6570\uff0c\u9ed8\u8ba4\u4e0d\u51bb\u7ed3 --save-period Save checkpoint every x epochs (disabled if < 1) \u7528\u4e8e\u8bb0\u5f55\u8bad\u7ec3\u65e5\u5fd7\u4fe1\u606f\uff0cint \u578b\uff0c\u9ed8\u8ba4 -1 --seed Global training seed \u968f\u673a\u6570\u79cd\u5b50\u8bbe\u7f6e --local_rank Automatic DDP Multi-GPU argument, do not modify \u81ea\u52a8\u5355\u673a\u591a\u5361\u8bad\u7ec3 \u4e00\u822c\u4e0d\u6539\u52a8","title":"\u9644\u4ef6"},{"location":"tutorials/03_chapter/quick_start.html#reference","text":"https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data https://docs.ultralytics.com/quick-start/","title":"Reference"},{"location":"tutorials/04_chapter/mosaic.html","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u5f15\u8a00 \\(YOLOv5\\) \u5728\u8bad\u7ec3\u6a21\u578b\u7684\u65f6\u5019\u4f7f\u7528\ud83d\ude80\u56fe\u50cf\u7a7a\u95f4\u548c\u8272\u5f69\u7a7a\u95f4\u7684\u6570\u636e\u589e\u5f3a( \u5728\u9a8c\u8bc1\u6a21\u578b\u7684\u65f6\u5019\u6ca1\u6709\u4f7f\u7528 )\uff0c\u901a\u8fc7\u8bad\u7ec3\u65f6\u91c7\u7528\u6570\u636e\u589e\u5f3a \u4ece\u800c\u4f7f\u5f97\u6bcf\u6b21\u52a0\u8f7d\u90fd\u662f\u65b0\u7684\u548c\u552f\u4e00\u7684\u56fe\u50cf\uff08 \u5373\u539f\u59cb\u56fe\u50cf+3\u4e2a\u968f\u673a\u56fe\u50cf \uff09\u5982\u4e0b\u56fe\u6240\u793a\u3002 \u56fe4.1 \u6570\u636e\u589e\u5f3a\u3002\u7ecf\u8fc7\u6570\u636e\u589e\u5f3a\u540e\u56fe\u50cf\u4e0d\u4f1a\u4ee5\u76f8\u540c\u7684\u65b9\u5f0f\u5448\u73b0\u4e24\u6b21\u3002 \u56fe\u7247\u6765\u6e90\uff1ahttps://docs.ultralytics.com/FAQ/augmentation/ \u8d85\u53c2\u6570\u6587\u4ef6 \u6570\u636e\u589e\u5f3a\u9ed8\u8ba4\u4f7f\u7528\u914d\u7f6e\u8d85\u53c2\u6570\u6587\u4ef6hyp.scratch.yaml\uff0c \u4e0b\u9762\u4ee5 hyp.scratch-low.yaml \u6587\u4ef6\u90e8\u5206\u53c2\u6570\u4e3a\u4f8b\uff0c\u5177\u4f53\u53c2\u6570\u89e3\u6790\u53ef\u89c1\u9644\u4ef6 \u88682.1 $ python train.py --hyp hyp.scratch-low.yaml Mosaic \u56fe4.2 Mosaic\u6570\u636e\u589e\u5f3a\u3002\u628a4\u5f20\u56fe\u7247\uff0c\u901a\u8fc7\u968f\u673a\u7f29\u653e\u3001\u968f\u673a\u88c1\u51cf\u3001\u968f\u673a\u6392\u5e03\u7684\u65b9\u5f0f\u8fdb\u884c\u62fc\u63a5\u3002 Copy paste \u56fe4.3 \u5206\u5272\u586b\u8865 Random affine (Rotation, Scale, Translation and Shear)\uff08\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u548c\u526a\u5207\uff09 \u56fe4.4 \u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u548c\u526a\u5207 \u56fe\u50cf MixUp \u56fe4.5 \u56fe\u50cf\u878d\u5408 Albumentations YOLOv5 \ud83d\ude80 \u96c6\u6210\u4e86Albumentations(\u4e00\u4e2a\u6d41\u884c\u7684\u5f00\u6e90\u56fe\u50cf\u589e\u5f3a\u5305)\u3002 \u53ef\u4ee5\u901a\u8fc7\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u66f4\u597d\u5730\u8bad\u7ec3\uff0c\u4e16\u754c\u4e0a\u6700\u68d2\u7684\u89c6\u89c9AI\u6a21\u578b\ud83d\ude03! \u56fe4.6 Albumentations Augment HSV (Hue, Saturation, Value) \u8272\u8c03\u3001\u9971\u548c\u5ea6\u3001\u66dd\u5149\u5ea6 \u56fe4.5 \u8272\u8c03\u3001\u9971\u548c\u5ea6\u3001\u66dd\u5149\u5ea6 Random horizontal flip (\u968f\u673a\u6c34\u5e73\u6216\u7ffb\u8f6c) \u56fe4.6 \u968f\u673a\u6c34\u5e73\u6216\u7ffb\u8f6c Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5 Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u5c06\u591a\u5f20\u56fe\u7247\u6309\u7167\u4e00\u5b9a\u6bd4\u4f8b\u7ec4\u5408\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u4f7f\u6a21\u578b\u5728\u66f4\u5c0f\u7684\u8303\u56f4\u5185\u8bc6\u522b\u76ee\u6807\u3002Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u53c2\u8003 CutMix\u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u3002CutMix\u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u4f7f\u7528\u4e24\u5f20\u56fe\u7247\u8fdb\u884c\u62fc\u63a5\uff0c\u800c Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u4e00\u822c\u4f7f\u7528\u56db\u5f20\u8fdb\u884c\u62fc\u63a5\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002 Mosaic\u65b9\u6cd5\u6b65\u9aa4 \u968f\u673a\u9009\u53d6\u56fe\u7247\u62fc\u63a5\u57fa\u51c6\u70b9\u5750\u6807 \\((x_c\uff0cy_c)\\) \uff0c\u53e6\u968f\u673a\u9009\u53d6\u56db\u5f20\u56fe\u7247\u3002 \u56db\u5f20\u56fe\u7247\u6839\u636e\u57fa\u51c6\u70b9\uff0c\u5206\u522b\u7ecf\u8fc7 \u5c3a\u5bf8\u8c03\u6574 \u548c \u6bd4\u4f8b\u7f29\u653e \u540e\uff0c\u653e\u7f6e\u5728\u6307\u5b9a\u5c3a\u5bf8\u7684\u5927\u56fe\u7684\u5de6\u4e0a\uff0c\u53f3\u4e0a\uff0c\u5de6\u4e0b\uff0c\u53f3\u4e0b\u4f4d\u7f6e\u3002 \u6839\u636e\u6bcf\u5f20\u56fe\u7247\u7684\u5c3a\u5bf8\u53d8\u6362\u65b9\u5f0f\uff0c\u5c06\u6620\u5c04\u5173\u7cfb\u5bf9\u5e94\u5230\u56fe\u7247\u6807\u7b7e\u4e0a\u3002 \u4f9d\u636e\u6307\u5b9a\u7684\u6a2a\u7eb5\u5750\u6807\uff0c\u5bf9\u5927\u56fe\u8fdb\u884c\u62fc\u63a5\u3002\u5904\u7406\u8d85\u8fc7\u8fb9\u754c\u7684\u68c0\u6d4b\u6846\u5750\u6807\u3002 Mosaic\u65b9\u6cd5\u4f18\u70b9 \u589e\u52a0\u6570\u636e\u591a\u6837\u6027\uff0c\u968f\u673a\u9009\u53d6\u56db\u5f20\u56fe\u50cf\u8fdb\u884c\u7ec4\u5408\uff0c\u7ec4\u5408\u5f97\u5230\u56fe\u50cf\u4e2a\u6570\u6bd4\u539f\u56fe\u4e2a\u6570\u8981\u591a\u3002 \u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u6df7\u5408\u56db\u5f20\u5177\u6709\u4e0d\u540c\u8bed\u4e49\u4fe1\u606f\u7684\u56fe\u7247\uff0c\u53ef\u4ee5\u8ba9\u6a21\u578b\u68c0\u6d4b\u8d85\u51fa\u5e38\u89c4\u8bed\u5883\u7684\u76ee\u6807\u3002 \u52a0\u5f3a\u6279\u5f52\u4e00\u5316\u5c42\uff08 \\(Batch \\ Normalization\\) \uff09\u7684\u6548\u679c\u3002\u5f53\u6a21\u578b\u8bbe\u7f6e \\(BN\\) \u64cd\u4f5c\u540e\uff0c\u8bad\u7ec3\u65f6\u4f1a\u5c3d\u53ef\u80fd\u589e\u5927\u6279\u6837\u672c\u603b\u91cf\uff08 \\(BatchSize\\) \uff09\uff0c\u56e0\u4e3a \\(BN\\) \u539f\u7406\u4e3a\u8ba1\u7b97\u6bcf\u4e00\u4e2a\u7279\u5f81\u5c42\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5982\u679c\u6279\u6837\u672c\u603b\u91cf\u8d8a\u5927\uff0c\u90a3\u4e48 \\(BN\\) \u8ba1\u7b97\u7684\u5747\u503c\u548c\u65b9\u5dee\u5c31\u8d8a\u63a5\u8fd1\u4e8e\u6574\u4e2a\u6570\u636e\u96c6\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u6548\u679c\u8d8a\u597d\u3002 Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u6709\u5229\u4e8e\u63d0\u5347\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u3002Mosaic \u6570\u636e\u589e\u5f3a\u56fe\u50cf\u7531\u56db\u5f20\u539f\u59cb\u56fe\u50cf\u62fc\u63a5\u800c\u6210\uff0c\u8fd9\u6837\u6bcf\u5f20\u56fe\u50cf\u4f1a\u6709\u66f4\u5927\u6982\u7387\u5305\u542b\u5c0f\u76ee\u6807\u3002 Mosaic\u6e90\u7801\u89e3\u8bfb \u601d\u8def\u6982\u62ec\uff1a\u5c06\u4e00\u5f20\u9009\u5b9a\u7684\u56fe\u7247\u548c\u968f\u673a\u76843\u5f20\u56fe\u7247\u8fdb\u884c\u968f\u673a\u88c1\u526a\uff0c\u518d\u62fc\u63a5\u5230\u4e00\u5f20\u56fe\u4e0a\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e ,\u53ef\u89c1\u672c\u6587 \u56fe4.2 \u3002 \u8fd9\u6837\u53ef\u4ee5\u4e30\u5bcc\u56fe\u7247\u7684\u80cc\u666f\uff0c\u800c\u4e14\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u8d77\u53d8\u76f8\u7684\u63d0\u9ad8\u4e86 \\(batch-size\\) \u5927\u5c0f\uff0c\u540c\u65f6\u5728\u8fdb\u884c \\(batch \\ normalization\\) \uff08\u6279\u91cf\u5f52\u4e00\u5316\uff09\u7684\u65f6\u5019\u4e5f\u4f1a\u8ba1\u7b97\u56db\u5f20\u56fe\u7247\u3002 \u8fd9\u4e2d\u65b9\u5f0f\u80fd\u4f7f\u5f97 \\(YOLOv5\\) \u5bf9\u4e8e \\(batch-size\\) \u5927\u5c0f\u5bf9\u6a21\u578b\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002 \u4e0b\u9762\u5bf9 utils/dataloaders.py\u4e2dMosaic \u7684\u5b9e\u73b0\u8fdb\u884c\u89e3\u8bfb\u3002 def load_mosaic ( self , index ): # YOLOv5 4-mosaic loader. Loads 1 image + 3 random images into a 4-image mosaic \"\"\" @param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 @return: img4: mosaic\u548c\u4eff\u5c04\u589e\u5f3a\u540e\u7684\u4e00\u5f20\u56fe\u7247 labels4: img4\u5bf9\u5e94\u7684target \"\"\" labels4 , segments4 = [], [] # \u83b7\u53d6\u56fe\u50cf\u5c3a\u5bf8 s = self . img_size # \u8fd9\u91cc\u662f\u968f\u673a\u751f\u6210mosaic\u4e2d\u5fc3\u70b9 yc , xc = ( int ( random . uniform ( - x , 2 * s + x )) for x in self . mosaic_border ) # mosaic center x, y # \u968f\u673a\u751f\u6210\u53e6\u59163\u5f20\u56fe\u7247\u7684\u7d22\u5f15 indices = [ index ] + random . choices ( self . indices , k = 3 ) # 3 additional image indices # \u5bf9\u8fd9\u4e9b\u7d22\u5f15\u503c\u968f\u673a\u6392\u5e8f random . shuffle ( indices ) # \u904d\u5386\u8fd94\u5f20\u56fe\u7247 for i , index in enumerate ( indices ): # Load image # \u52a0\u8f7d\u56fe\u7247\u5e76\u8fd4\u56de\u9ad8\u5bbd img , _ , ( h , w ) = self . load_image ( index ) # place img in img4 \u653e\u7f6e\u56fe\u7247 if i == 0 : # top left(\u5de6\u4e0a\u89d2) # \u751f\u6210\u80cc\u666f\u56fe np.full()\u51fd\u6570\u586b\u5145\u521d\u59cb\u5316\u5927\u56fe\uff0c\u5c3a\u5bf8\u662f4\u5f20\u56fe\u90a3\u4e48\u5927 img4 = np . full (( s * 2 , s * 2 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles # \u8bbe\u7f6e\u5927\u56fe\u4e0a\u7684\u4f4d\u7f6e\uff08\u8981\u4e48\u539f\u56fe\u5927\u5c0f\uff0c\u8981\u4e48\u653e\u5927\uff09\uff08w\uff0ch\uff09\u6216\uff08xc\uff0cyc\uff09\uff08\u65b0\u751f\u6210\u7684\u90a3\u5f20\u5927\u56fe\uff09 x1a , y1a , x2a , y2a = max ( xc - w , 0 ), max ( yc - h , 0 ), xc , yc # xmin, ymin, xmax, ymax (large image) # \u9009\u53d6\u5c0f\u56fe\u4e0a\u7684\u4f4d\u7f6e\uff08\u539f\u56fe\uff09 x1b , y1b , x2b , y2b = w - ( x2a - x1a ), h - ( y2a - y1a ), w , h # xmin, ymin, xmax, ymax (small image) elif i == 1 : # top right(\u53f3\u4e0a\u89d2) x1a , y1a , x2a , y2a = xc , max ( yc - h , 0 ), min ( xc + w , s * 2 ), yc x1b , y1b , x2b , y2b = 0 , h - ( y2a - y1a ), min ( w , x2a - x1a ), h elif i == 2 : # bottom left(\u5de6\u4e0b\u89d2) x1a , y1a , x2a , y2a = max ( xc - w , 0 ), yc , xc , min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = w - ( x2a - x1a ), 0 , w , min ( y2a - y1a , h ) elif i == 3 : # bottom right(\u53f3\u4e0b\u89d2) x1a , y1a , x2a , y2a = xc , yc , min ( xc + w , s * 2 ), min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = 0 , 0 , min ( w , x2a - x1a ), min ( y2a - y1a , h ) # \u5927\u56fe\u4e0a\u8d34\u4e0a\u5bf9\u5e94\u7684\u5c0f\u56fe img4 [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] padw = x1a - x1b padh = y1a - y1b # \u8ba1\u7b97\u5c0f\u56fe\u5230\u5927\u56fe\u4e0a\u65f6\u6240\u4ea7\u751f\u7684\u504f\u79fb\uff0c\u7528\u6765\u8ba1\u7b97mosaic\u589e\u5f3a\u540e\u7684\u6807\u7b7e\u7684\u4f4d\u7f6e # Labels \u83b7\u53d6\u6807\u7b7e \"\"\" \u5bf9label\u6807\u6ce8\u8fdb\u884c\u521d\u59cb\u5316\u64cd\u4f5c\uff1a \u5148\u8bfb\u53d6\u5bf9\u5e94\u56fe\u7247\u7684label\uff0c\u7136\u540e\u5c06xywh\u683c\u5f0f\u7684label\u6807\u51c6\u5316\u4e3a\u50cf\u7d20xy\u683c\u5f0f\u7684\u3002 segments4\u8f6c\u4e3a\u50cf\u7d20\u6bb5\u683c\u5f0f \u7136\u540e\u7edf\u7edf\u586b\u8fdb\u4e4b\u524d\u51c6\u5907\u7684\u6807\u6ce8\u5217\u8868 \"\"\" labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : # \u5c06xywh\uff08\u767e\u5206\u6bd4\u90a3\u4e9b\u503c\uff09\u6807\u51c6\u5316\u4e3a\u50cf\u7d20xy\u683c\u5f0f labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padw , padh ) # normalized xywh to pixel xyxy format # \u8f6c\u4e3a\u50cf\u7d20\u6bb5 segments = [ xyn2xy ( x , w , h , padw , padh ) for x in segments ] labels4 . append ( labels ) segments4 . extend ( segments ) # Concat/clip labels \u62fc\u63a5 labels4 = np . concatenate ( labels4 , 0 ) for x in ( labels4 [:, 1 :], * segments4 ): # np.clip\u622a\u53d6\u51fd\u6570\uff0c\u56fa\u5b9a\u503c\u57280\u52302s\u5185 np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img4, labels4 = replicate(img4, labels4) # replicate # Augment # \u8fdb\u884cmosaic\u7684\u65f6\u5019\u5c06\u56db\u5f20\u56fe\u7247\u6574\u5408\u5230\u4e00\u8d77\u4e4b\u540eshape\u4e3a[2*img_size,2*img_size] # \u5bf9mosaic\u6574\u5408\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u88c1\u526a\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size img4 , labels4 , segments4 = copy_paste ( img4 , labels4 , segments4 , p = self . hyp [ 'copy_paste' ]) img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove \u9644\u4ef6 \u88684.1 :\u6570\u636e\u589e\u5f3a\u53c2\u6570\u8868 \u53c2\u6570\u540d \u914d\u7f6e \u89e3\u6790 hsv_h: 0.015 # image HSV-Hue augmentation (fraction) \u8272\u8c03 hsv_s: 0.7 # image HSV-Saturation augmentation (fraction) \u9971\u548c\u5ea6 hsv_v: 0.4 # image HSV-Value augmentation (fraction) \u66dd\u5149\u5ea6 degrees: 0.0 # image rotation (+/- deg) \u65cb\u8f6c translate: 0.1 # image translation (+/- fraction) \u5e73\u79fb scale: 0.9 # image scale (+/- gain) \u7f29\u653e shear: 0.0 # image shear (+/- deg) \u9519\u5207(\u975e\u5782\u76f4\u6295\u5f71) perspective: 0.0 # image perspective (+/- fraction), range 0-0.001 \u900f\u89c6\u53d8\u6362 flipud: 0.0 # image flip up-down (probability) \u4e0a\u4e0b\u7ffb\u8f6c fliplr: 0.5 # image flip left-right (probability)\u5de6\u53f3\u7ffb\u8f6c mosaic: 1.0 # image mosaic (probability) \u56fe\u62fc\u63a5 mixup: 0.1 # image mixup (probability) \u56fe\u50cf\u878d\u5408 copy_paste: 0.0 # segment copy-paste (probability) \u5206\u5272\u586b\u8865 \u53c2\u8003\u6587\u7ae0 https://docs.ultralytics.com/FAQ/augmentation/","title":"4.1 mosaic \u89e3\u8bfb"},{"location":"tutorials/04_chapter/mosaic.html#_1","text":"\\(YOLOv5\\) \u5728\u8bad\u7ec3\u6a21\u578b\u7684\u65f6\u5019\u4f7f\u7528\ud83d\ude80\u56fe\u50cf\u7a7a\u95f4\u548c\u8272\u5f69\u7a7a\u95f4\u7684\u6570\u636e\u589e\u5f3a( \u5728\u9a8c\u8bc1\u6a21\u578b\u7684\u65f6\u5019\u6ca1\u6709\u4f7f\u7528 )\uff0c\u901a\u8fc7\u8bad\u7ec3\u65f6\u91c7\u7528\u6570\u636e\u589e\u5f3a \u4ece\u800c\u4f7f\u5f97\u6bcf\u6b21\u52a0\u8f7d\u90fd\u662f\u65b0\u7684\u548c\u552f\u4e00\u7684\u56fe\u50cf\uff08 \u5373\u539f\u59cb\u56fe\u50cf+3\u4e2a\u968f\u673a\u56fe\u50cf \uff09\u5982\u4e0b\u56fe\u6240\u793a\u3002 \u56fe4.1 \u6570\u636e\u589e\u5f3a\u3002\u7ecf\u8fc7\u6570\u636e\u589e\u5f3a\u540e\u56fe\u50cf\u4e0d\u4f1a\u4ee5\u76f8\u540c\u7684\u65b9\u5f0f\u5448\u73b0\u4e24\u6b21\u3002 \u56fe\u7247\u6765\u6e90\uff1ahttps://docs.ultralytics.com/FAQ/augmentation/","title":"\u5f15\u8a00"},{"location":"tutorials/04_chapter/mosaic.html#_2","text":"\u6570\u636e\u589e\u5f3a\u9ed8\u8ba4\u4f7f\u7528\u914d\u7f6e\u8d85\u53c2\u6570\u6587\u4ef6hyp.scratch.yaml\uff0c \u4e0b\u9762\u4ee5 hyp.scratch-low.yaml \u6587\u4ef6\u90e8\u5206\u53c2\u6570\u4e3a\u4f8b\uff0c\u5177\u4f53\u53c2\u6570\u89e3\u6790\u53ef\u89c1\u9644\u4ef6 \u88682.1 $ python train.py --hyp hyp.scratch-low.yaml","title":"\u8d85\u53c2\u6570\u6587\u4ef6"},{"location":"tutorials/04_chapter/mosaic.html#mosaic","text":"\u56fe4.2 Mosaic\u6570\u636e\u589e\u5f3a\u3002\u628a4\u5f20\u56fe\u7247\uff0c\u901a\u8fc7\u968f\u673a\u7f29\u653e\u3001\u968f\u673a\u88c1\u51cf\u3001\u968f\u673a\u6392\u5e03\u7684\u65b9\u5f0f\u8fdb\u884c\u62fc\u63a5\u3002","title":"Mosaic"},{"location":"tutorials/04_chapter/mosaic.html#copy-paste","text":"\u56fe4.3 \u5206\u5272\u586b\u8865","title":"Copy paste"},{"location":"tutorials/04_chapter/mosaic.html#random-affine","text":"(Rotation, Scale, Translation and Shear)\uff08\u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u548c\u526a\u5207\uff09 \u56fe4.4 \u65cb\u8f6c\u3001\u7f29\u653e\u3001\u5e73\u79fb\u548c\u526a\u5207 \u56fe\u50cf","title":"Random affine"},{"location":"tutorials/04_chapter/mosaic.html#mixup","text":"\u56fe4.5 \u56fe\u50cf\u878d\u5408","title":"MixUp"},{"location":"tutorials/04_chapter/mosaic.html#albumentations","text":"YOLOv5 \ud83d\ude80 \u96c6\u6210\u4e86Albumentations(\u4e00\u4e2a\u6d41\u884c\u7684\u5f00\u6e90\u56fe\u50cf\u589e\u5f3a\u5305)\u3002 \u53ef\u4ee5\u901a\u8fc7\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u66f4\u597d\u5730\u8bad\u7ec3\uff0c\u4e16\u754c\u4e0a\u6700\u68d2\u7684\u89c6\u89c9AI\u6a21\u578b\ud83d\ude03! \u56fe4.6 Albumentations","title":"Albumentations"},{"location":"tutorials/04_chapter/mosaic.html#augment-hsv","text":"(Hue, Saturation, Value) \u8272\u8c03\u3001\u9971\u548c\u5ea6\u3001\u66dd\u5149\u5ea6 \u56fe4.5 \u8272\u8c03\u3001\u9971\u548c\u5ea6\u3001\u66dd\u5149\u5ea6","title":"Augment HSV"},{"location":"tutorials/04_chapter/mosaic.html#random-horizontal-flip","text":"(\u968f\u673a\u6c34\u5e73\u6216\u7ffb\u8f6c) \u56fe4.6 \u968f\u673a\u6c34\u5e73\u6216\u7ffb\u8f6c","title":"Random horizontal flip"},{"location":"tutorials/04_chapter/mosaic.html#mosaic_1","text":"Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u5c06\u591a\u5f20\u56fe\u7247\u6309\u7167\u4e00\u5b9a\u6bd4\u4f8b\u7ec4\u5408\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u4f7f\u6a21\u578b\u5728\u66f4\u5c0f\u7684\u8303\u56f4\u5185\u8bc6\u522b\u76ee\u6807\u3002Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u53c2\u8003 CutMix\u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u3002CutMix\u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u4f7f\u7528\u4e24\u5f20\u56fe\u7247\u8fdb\u884c\u62fc\u63a5\uff0c\u800c Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u4e00\u822c\u4f7f\u7528\u56db\u5f20\u8fdb\u884c\u62fc\u63a5\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002","title":"Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5"},{"location":"tutorials/04_chapter/mosaic.html#mosaic_2","text":"\u968f\u673a\u9009\u53d6\u56fe\u7247\u62fc\u63a5\u57fa\u51c6\u70b9\u5750\u6807 \\((x_c\uff0cy_c)\\) \uff0c\u53e6\u968f\u673a\u9009\u53d6\u56db\u5f20\u56fe\u7247\u3002 \u56db\u5f20\u56fe\u7247\u6839\u636e\u57fa\u51c6\u70b9\uff0c\u5206\u522b\u7ecf\u8fc7 \u5c3a\u5bf8\u8c03\u6574 \u548c \u6bd4\u4f8b\u7f29\u653e \u540e\uff0c\u653e\u7f6e\u5728\u6307\u5b9a\u5c3a\u5bf8\u7684\u5927\u56fe\u7684\u5de6\u4e0a\uff0c\u53f3\u4e0a\uff0c\u5de6\u4e0b\uff0c\u53f3\u4e0b\u4f4d\u7f6e\u3002 \u6839\u636e\u6bcf\u5f20\u56fe\u7247\u7684\u5c3a\u5bf8\u53d8\u6362\u65b9\u5f0f\uff0c\u5c06\u6620\u5c04\u5173\u7cfb\u5bf9\u5e94\u5230\u56fe\u7247\u6807\u7b7e\u4e0a\u3002 \u4f9d\u636e\u6307\u5b9a\u7684\u6a2a\u7eb5\u5750\u6807\uff0c\u5bf9\u5927\u56fe\u8fdb\u884c\u62fc\u63a5\u3002\u5904\u7406\u8d85\u8fc7\u8fb9\u754c\u7684\u68c0\u6d4b\u6846\u5750\u6807\u3002","title":"Mosaic\u65b9\u6cd5\u6b65\u9aa4"},{"location":"tutorials/04_chapter/mosaic.html#mosaic_3","text":"\u589e\u52a0\u6570\u636e\u591a\u6837\u6027\uff0c\u968f\u673a\u9009\u53d6\u56db\u5f20\u56fe\u50cf\u8fdb\u884c\u7ec4\u5408\uff0c\u7ec4\u5408\u5f97\u5230\u56fe\u50cf\u4e2a\u6570\u6bd4\u539f\u56fe\u4e2a\u6570\u8981\u591a\u3002 \u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u6df7\u5408\u56db\u5f20\u5177\u6709\u4e0d\u540c\u8bed\u4e49\u4fe1\u606f\u7684\u56fe\u7247\uff0c\u53ef\u4ee5\u8ba9\u6a21\u578b\u68c0\u6d4b\u8d85\u51fa\u5e38\u89c4\u8bed\u5883\u7684\u76ee\u6807\u3002 \u52a0\u5f3a\u6279\u5f52\u4e00\u5316\u5c42\uff08 \\(Batch \\ Normalization\\) \uff09\u7684\u6548\u679c\u3002\u5f53\u6a21\u578b\u8bbe\u7f6e \\(BN\\) \u64cd\u4f5c\u540e\uff0c\u8bad\u7ec3\u65f6\u4f1a\u5c3d\u53ef\u80fd\u589e\u5927\u6279\u6837\u672c\u603b\u91cf\uff08 \\(BatchSize\\) \uff09\uff0c\u56e0\u4e3a \\(BN\\) \u539f\u7406\u4e3a\u8ba1\u7b97\u6bcf\u4e00\u4e2a\u7279\u5f81\u5c42\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5982\u679c\u6279\u6837\u672c\u603b\u91cf\u8d8a\u5927\uff0c\u90a3\u4e48 \\(BN\\) \u8ba1\u7b97\u7684\u5747\u503c\u548c\u65b9\u5dee\u5c31\u8d8a\u63a5\u8fd1\u4e8e\u6574\u4e2a\u6570\u636e\u96c6\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u6548\u679c\u8d8a\u597d\u3002 Mosaic \u6570\u636e\u589e\u5f3a\u7b97\u6cd5\u6709\u5229\u4e8e\u63d0\u5347\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u3002Mosaic \u6570\u636e\u589e\u5f3a\u56fe\u50cf\u7531\u56db\u5f20\u539f\u59cb\u56fe\u50cf\u62fc\u63a5\u800c\u6210\uff0c\u8fd9\u6837\u6bcf\u5f20\u56fe\u50cf\u4f1a\u6709\u66f4\u5927\u6982\u7387\u5305\u542b\u5c0f\u76ee\u6807\u3002","title":"Mosaic\u65b9\u6cd5\u4f18\u70b9"},{"location":"tutorials/04_chapter/mosaic.html#mosaic_4","text":"\u601d\u8def\u6982\u62ec\uff1a\u5c06\u4e00\u5f20\u9009\u5b9a\u7684\u56fe\u7247\u548c\u968f\u673a\u76843\u5f20\u56fe\u7247\u8fdb\u884c\u968f\u673a\u88c1\u526a\uff0c\u518d\u62fc\u63a5\u5230\u4e00\u5f20\u56fe\u4e0a\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e ,\u53ef\u89c1\u672c\u6587 \u56fe4.2 \u3002 \u8fd9\u6837\u53ef\u4ee5\u4e30\u5bcc\u56fe\u7247\u7684\u80cc\u666f\uff0c\u800c\u4e14\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u8d77\u53d8\u76f8\u7684\u63d0\u9ad8\u4e86 \\(batch-size\\) \u5927\u5c0f\uff0c\u540c\u65f6\u5728\u8fdb\u884c \\(batch \\ normalization\\) \uff08\u6279\u91cf\u5f52\u4e00\u5316\uff09\u7684\u65f6\u5019\u4e5f\u4f1a\u8ba1\u7b97\u56db\u5f20\u56fe\u7247\u3002 \u8fd9\u4e2d\u65b9\u5f0f\u80fd\u4f7f\u5f97 \\(YOLOv5\\) \u5bf9\u4e8e \\(batch-size\\) \u5927\u5c0f\u5bf9\u6a21\u578b\u8bad\u7ec3\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002 \u4e0b\u9762\u5bf9 utils/dataloaders.py\u4e2dMosaic \u7684\u5b9e\u73b0\u8fdb\u884c\u89e3\u8bfb\u3002 def load_mosaic ( self , index ): # YOLOv5 4-mosaic loader. Loads 1 image + 3 random images into a 4-image mosaic \"\"\" @param index: \u9700\u8981\u83b7\u53d6\u7684\u56fe\u50cf\u7d22\u5f15 @return: img4: mosaic\u548c\u4eff\u5c04\u589e\u5f3a\u540e\u7684\u4e00\u5f20\u56fe\u7247 labels4: img4\u5bf9\u5e94\u7684target \"\"\" labels4 , segments4 = [], [] # \u83b7\u53d6\u56fe\u50cf\u5c3a\u5bf8 s = self . img_size # \u8fd9\u91cc\u662f\u968f\u673a\u751f\u6210mosaic\u4e2d\u5fc3\u70b9 yc , xc = ( int ( random . uniform ( - x , 2 * s + x )) for x in self . mosaic_border ) # mosaic center x, y # \u968f\u673a\u751f\u6210\u53e6\u59163\u5f20\u56fe\u7247\u7684\u7d22\u5f15 indices = [ index ] + random . choices ( self . indices , k = 3 ) # 3 additional image indices # \u5bf9\u8fd9\u4e9b\u7d22\u5f15\u503c\u968f\u673a\u6392\u5e8f random . shuffle ( indices ) # \u904d\u5386\u8fd94\u5f20\u56fe\u7247 for i , index in enumerate ( indices ): # Load image # \u52a0\u8f7d\u56fe\u7247\u5e76\u8fd4\u56de\u9ad8\u5bbd img , _ , ( h , w ) = self . load_image ( index ) # place img in img4 \u653e\u7f6e\u56fe\u7247 if i == 0 : # top left(\u5de6\u4e0a\u89d2) # \u751f\u6210\u80cc\u666f\u56fe np.full()\u51fd\u6570\u586b\u5145\u521d\u59cb\u5316\u5927\u56fe\uff0c\u5c3a\u5bf8\u662f4\u5f20\u56fe\u90a3\u4e48\u5927 img4 = np . full (( s * 2 , s * 2 , img . shape [ 2 ]), 114 , dtype = np . uint8 ) # base image with 4 tiles # \u8bbe\u7f6e\u5927\u56fe\u4e0a\u7684\u4f4d\u7f6e\uff08\u8981\u4e48\u539f\u56fe\u5927\u5c0f\uff0c\u8981\u4e48\u653e\u5927\uff09\uff08w\uff0ch\uff09\u6216\uff08xc\uff0cyc\uff09\uff08\u65b0\u751f\u6210\u7684\u90a3\u5f20\u5927\u56fe\uff09 x1a , y1a , x2a , y2a = max ( xc - w , 0 ), max ( yc - h , 0 ), xc , yc # xmin, ymin, xmax, ymax (large image) # \u9009\u53d6\u5c0f\u56fe\u4e0a\u7684\u4f4d\u7f6e\uff08\u539f\u56fe\uff09 x1b , y1b , x2b , y2b = w - ( x2a - x1a ), h - ( y2a - y1a ), w , h # xmin, ymin, xmax, ymax (small image) elif i == 1 : # top right(\u53f3\u4e0a\u89d2) x1a , y1a , x2a , y2a = xc , max ( yc - h , 0 ), min ( xc + w , s * 2 ), yc x1b , y1b , x2b , y2b = 0 , h - ( y2a - y1a ), min ( w , x2a - x1a ), h elif i == 2 : # bottom left(\u5de6\u4e0b\u89d2) x1a , y1a , x2a , y2a = max ( xc - w , 0 ), yc , xc , min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = w - ( x2a - x1a ), 0 , w , min ( y2a - y1a , h ) elif i == 3 : # bottom right(\u53f3\u4e0b\u89d2) x1a , y1a , x2a , y2a = xc , yc , min ( xc + w , s * 2 ), min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = 0 , 0 , min ( w , x2a - x1a ), min ( y2a - y1a , h ) # \u5927\u56fe\u4e0a\u8d34\u4e0a\u5bf9\u5e94\u7684\u5c0f\u56fe img4 [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] padw = x1a - x1b padh = y1a - y1b # \u8ba1\u7b97\u5c0f\u56fe\u5230\u5927\u56fe\u4e0a\u65f6\u6240\u4ea7\u751f\u7684\u504f\u79fb\uff0c\u7528\u6765\u8ba1\u7b97mosaic\u589e\u5f3a\u540e\u7684\u6807\u7b7e\u7684\u4f4d\u7f6e # Labels \u83b7\u53d6\u6807\u7b7e \"\"\" \u5bf9label\u6807\u6ce8\u8fdb\u884c\u521d\u59cb\u5316\u64cd\u4f5c\uff1a \u5148\u8bfb\u53d6\u5bf9\u5e94\u56fe\u7247\u7684label\uff0c\u7136\u540e\u5c06xywh\u683c\u5f0f\u7684label\u6807\u51c6\u5316\u4e3a\u50cf\u7d20xy\u683c\u5f0f\u7684\u3002 segments4\u8f6c\u4e3a\u50cf\u7d20\u6bb5\u683c\u5f0f \u7136\u540e\u7edf\u7edf\u586b\u8fdb\u4e4b\u524d\u51c6\u5907\u7684\u6807\u6ce8\u5217\u8868 \"\"\" labels , segments = self . labels [ index ] . copy (), self . segments [ index ] . copy () if labels . size : # \u5c06xywh\uff08\u767e\u5206\u6bd4\u90a3\u4e9b\u503c\uff09\u6807\u51c6\u5316\u4e3a\u50cf\u7d20xy\u683c\u5f0f labels [:, 1 :] = xywhn2xyxy ( labels [:, 1 :], w , h , padw , padh ) # normalized xywh to pixel xyxy format # \u8f6c\u4e3a\u50cf\u7d20\u6bb5 segments = [ xyn2xy ( x , w , h , padw , padh ) for x in segments ] labels4 . append ( labels ) segments4 . extend ( segments ) # Concat/clip labels \u62fc\u63a5 labels4 = np . concatenate ( labels4 , 0 ) for x in ( labels4 [:, 1 :], * segments4 ): # np.clip\u622a\u53d6\u51fd\u6570\uff0c\u56fa\u5b9a\u503c\u57280\u52302s\u5185 np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img4, labels4 = replicate(img4, labels4) # replicate # Augment # \u8fdb\u884cmosaic\u7684\u65f6\u5019\u5c06\u56db\u5f20\u56fe\u7247\u6574\u5408\u5230\u4e00\u8d77\u4e4b\u540eshape\u4e3a[2*img_size,2*img_size] # \u5bf9mosaic\u6574\u5408\u7684\u56fe\u7247\u8fdb\u884c\u968f\u673a\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u88c1\u526a\uff0c\u5e76resize\u4e3a\u8f93\u5165\u5927\u5c0fimg_size img4 , labels4 , segments4 = copy_paste ( img4 , labels4 , segments4 , p = self . hyp [ 'copy_paste' ]) img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ], translate = self . hyp [ 'translate' ], scale = self . hyp [ 'scale' ], shear = self . hyp [ 'shear' ], perspective = self . hyp [ 'perspective' ], border = self . mosaic_border ) # border to remove","title":"Mosaic\u6e90\u7801\u89e3\u8bfb"},{"location":"tutorials/04_chapter/mosaic.html#_3","text":"\u88684.1 :\u6570\u636e\u589e\u5f3a\u53c2\u6570\u8868 \u53c2\u6570\u540d \u914d\u7f6e \u89e3\u6790 hsv_h: 0.015 # image HSV-Hue augmentation (fraction) \u8272\u8c03 hsv_s: 0.7 # image HSV-Saturation augmentation (fraction) \u9971\u548c\u5ea6 hsv_v: 0.4 # image HSV-Value augmentation (fraction) \u66dd\u5149\u5ea6 degrees: 0.0 # image rotation (+/- deg) \u65cb\u8f6c translate: 0.1 # image translation (+/- fraction) \u5e73\u79fb scale: 0.9 # image scale (+/- gain) \u7f29\u653e shear: 0.0 # image shear (+/- deg) \u9519\u5207(\u975e\u5782\u76f4\u6295\u5f71) perspective: 0.0 # image perspective (+/- fraction), range 0-0.001 \u900f\u89c6\u53d8\u6362 flipud: 0.0 # image flip up-down (probability) \u4e0a\u4e0b\u7ffb\u8f6c fliplr: 0.5 # image flip left-right (probability)\u5de6\u53f3\u7ffb\u8f6c mosaic: 1.0 # image mosaic (probability) \u56fe\u62fc\u63a5 mixup: 0.1 # image mixup (probability) \u56fe\u50cf\u878d\u5408 copy_paste: 0.0 # segment copy-paste (probability) \u5206\u5272\u586b\u8865","title":"\u9644\u4ef6"},{"location":"tutorials/04_chapter/mosaic.html#_4","text":"https://docs.ultralytics.com/FAQ/augmentation/","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u5f15\u8a00 \u672c\u6587\u4e3b\u8981\u4ecb\u7ecd\u5728 one-yolov5 \u9879\u76ee\u4e2d \u8ba1\u7b97mAP\u7528\u5230\u7684\u4e00\u4e9bnumpy\u64cd\u4f5c\uff0c\u51fd\u6570\u4f7f\u7528\u5728 utils/metrics.py \u4e2d\u3002 \u7528\u5230\u7684python/numpy\u7684\u64cd\u4f5c\u6bd4\u5982\uff1a np.cumsum()\u3001np.interp()\u3001np.maximum.accumulate()\u3001np.trapz()\u7b49\u3002\u63a5\u4e0b\u6765\u5c06\u5728\u4e0b\u9762\u9010\u4e00\u4ecb\u7ecd\u3002 import numpy as np np.cumsum() \u8fd4\u56de\u5143\u7d20\u6cbf\u7ed9\u5b9a\u8f74\u7684\u7d2f\u79ef\u548c\u3002 numpy.cumsum(a, axis=None, dtype=None, out=None) source \u53c2\u6570 a :\u6570\u7ec4 axis: \u8f74\u7d22\u5f15,\u6574\u578b\uff0c\u82e5a\u4e3an\u7ef4\u6570\u7ec4\uff0c\u5219axis\u7684\u53d6\u503c\u8303\u56f4\u4e3a[0,n-1] dtype: \u8fd4\u56de\u7ed3\u679c\u7684\u6570\u636e\u7c7b\u578b\uff0c\u82e5\u4e0d\u6307\u5b9a\uff0c\u5219\u9ed8\u8ba4\u4e0ea\u4e00\u81f4n out: \u6570\u636e\u7c7b\u578b\u4e3a\u6570\u7ec4\u3002\u7528\u6765\u653e\u7f6e\u7ed3\u679c\u7684\u66ff\u4ee3\u8f93\u51fa\u6570\u7ec4\uff0c\u5b83\u5fc5\u987b\u5177\u6709\u4e0e\u8f93\u51fa\u7ed3\u679c\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u548c\u6570\u636e\u7f13\u51b2\u533a\u957f\u5ea6 \u8fd4\u56de \u6cbf\u7740\u6307\u5b9a\u8f74\u7684\u5143\u7d20\u7d2f\u52a0\u548c\u6240\u7ec4\u6210\u7684\u6570\u7ec4\uff0c\u5176\u5f62\u72b6\u5e94\u4e0e\u8f93\u5165\u6570\u7ec4a\u4e00\u81f4 \u66f4\u591a\u4fe1\u606f\u8bf7\u53c2\u9605\u8bfb: API_CN API_EN np . cumsum ( a ) # \u8ba1\u7b97\u7d2f\u79ef\u548c\u7684\u8f74\u3002\u9ed8\u8ba4\uff08\u65e0\uff09\u662f\u5728\u5c55\u5e73\u7684\u6570\u7ec4\u4e0a\u8ba1\u7b97cumsum\u3002 array([ 1, 3, 6, 10, 15, 21]) a = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) np . cumsum ( a , dtype = float ) # \u6307\u5b9a\u8f93\u51fa\u7684\u7279\u5b9a\u7684\u7c7b\u578b array([ 1., 3., 6., 10., 15., 21.]) np . cumsum ( a , axis = 0 ) # 3\u5217\u4e2d\u6bcf\u4e00\u5217\u7684\u884c\u603b\u548c array([[1, 2, 3], [5, 7, 9]]) x = np . ones (( 3 , 4 ), dtype = int ) np . cumsum ( x , axis = 0 ) array([[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3]]) np . cumsum ( a , axis = 1 ) # 2\u884c\u4e2d\u6bcf\u884c\u7684\u5217\u603b\u548c array([[ 1, 3, 6], [ 4, 9, 15]]) np.interp() \u53c2\u6570 x: \u6570\u7ec4 \u5f85\u63d2\u5165\u6570\u636e\u7684\u6a2a\u5750\u6807 xp: \u4e00\u7ef4\u6d6e\u70b9\u6570\u5e8f\u5217 \u539f\u59cb\u6570\u636e\u70b9\u7684\u6a2a\u5750\u6807\uff0c\u5982\u679cperiod\u53c2\u6570\u6ca1\u6709\u6307\u5b9a\u90a3\u4e48\u5c31\u5fc5\u987b\u662f\u9012\u589e\u7684 \u5426\u5219\uff0c\u5728\u4f7f\u7528xp = xp % period\u6b63\u5219 \u5316\u4e4b\u540e\uff0cxp\u5728\u5185\u90e8\u8fdb\u884c\u6392\u5e8f fp: \u4e00\u7ef4\u6d6e\u70b9\u6570\u6216\u590d\u6570\u5e8f\u5217 \u539f\u59cb\u6570\u636e\u70b9\u7684\u7eb5\u5750\u6807\uff0c\u548cxp\u5e8f\u5217\u7b49\u957f. left: \u53ef\u9009\u53c2\u6570\uff0c\u7c7b\u578b\u4e3a\u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09 \u5f53x < xp[0]\u65f6\u7684\u63d2\u503c\u8fd4\u56de\u503c\uff0c\u9ed8\u8ba4\u4e3afp[0]. right: \u53ef\u9009\u53c2\u6570\uff0c\u7c7b\u578b\u4e3a\u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09\uff0c\u5f53x > xp[-1]\u65f6\u7684\u63d2\u503c\u8fd4\u56de\u503c\uff0c\u9ed8\u8ba4\u4e3afp[-1]. period: None\u6216\u8005\u6d6e\u70b9\u6570\uff0c\u53ef\u9009\u53c2\u6570 \u6a2a\u5750\u6807\u7684\u5468\u671f \u6b64\u53c2\u6570\u4f7f\u5f97\u53ef\u4ee5\u6b63\u786e\u63d2\u5165angular x-coordinates. \u5982\u679c\u8be5\u53c2\u6570\u88ab\u8bbe\u5b9a\uff0c\u90a3\u4e48\u5ffd\u7565left\u53c2\u6570\u548cright\u53c2\u6570 \u8fd4\u56de \u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09\u6216ndarray. \u63d2\u5165\u6570\u636e\u7684\u7eb5\u5750\u6807\uff0c\u548cx\u5f62\u72b6\u76f8\u540c \u6ce8\u610f\uff01 \u5728\u6ca1\u6709\u8bbe\u7f6eperiod\u53c2\u6570\u65f6\uff0c\u9ed8\u8ba4\u8981\u6c42xp\u53c2\u6570\u662f\u9012\u589e\u5e8f\u5217 # \u63d2\u5165\u4e00\u4e2a\u503c import numpy as np import matplotlib.pyplot as plt x = 2.5 xp = [ 1 , 2 , 3 ] fp = [ 3 , 2 , 0 ] y = np . interp ( x , xp , fp ) # 1.0 plt . plot ( xp , fp , '-o' ) plt . plot ( x , y , 'x' ) # \u753b\u63d2\u503c plt . show () # \u63d2\u5165\u4e00\u4e2a\u5e8f\u5217 import numpy as np import matplotlib.pyplot as plt x = [ 0 , 1 , 1.5 , 2.72 , 3.14 ] xp = [ 1 , 2 , 3 ] fp = [ 3 , 2 , 0 ] y = np . interp ( x , xp , fp ) # array([ 3. , 3. , 2.5 , 0.56, 0. ]) plt . plot ( xp , fp , '-o' ) plt . plot ( x , y , 'x' ) plt . show () np.maximum.accumulate \u8ba1\u7b97\u6570\u7ec4\uff08\u6216\u6570\u7ec4\u7684\u7279\u5b9a\u8f74\uff09\u7684\u7d2f\u79ef\u6700\u5927\u503c import numpy as np d = np . random . randint ( low = 1 , high = 10 , size = ( 2 , 3 )) print ( \"d: \\n \" , d ) c = np . maximum . accumulate ( d , axis = 1 ) print ( \"c: \\n \" , c ) d: [[1 9 5] [2 6 1]] c: [[1 9 9] [2 6 6]] np.trapz() numpy.trapz(y, x=None, dx=1.0, axis=- 1) \u4f7f\u7528\u590d\u5408\u68af\u5f62\u89c4\u5219\u6cbf\u7ed9\u5b9a\u8f74\u79ef\u5206\u3002 import matplotlib.pyplot as plt import numpy as np y = [ 1 , 2 , 3 ] ; x = [ i + 1 for i in range ( len ( y ))] print ( np . trapz ( x )) plt . fill_between ( x , y ) plt . show () # (1 + 3)*(3 - 1)/2 = 4 4.0 import matplotlib.pyplot as plt import numpy as np y = [ 1 , 2 , 3 ] x = [ 4 , 6 , 8 ] print ( np . trapz ( y , x )) plt . fill_between ( x , y ) plt . show () # (3 + 1)*(8 - 4) / 2 = 8 8.0 \u53c2\u8003\u6587\u7ae0 numpy API\u6587\u6863 CN\uff1a https://www.osgeo.cn/numpy/dev/index.html numpy API\u6587\u6863 EN\uff1a https://numpy.org/doc/stable/reference/index.html axis\u7684\u57fa\u672c\u4f7f\u7528\uff1a https://www.jb51.net/article/242067.htm","title":"5.4 \u8ba1\u7b97mAP\u7528\u5230\u7684numpy\u51fd\u6570"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#_1","text":"\u672c\u6587\u4e3b\u8981\u4ecb\u7ecd\u5728 one-yolov5 \u9879\u76ee\u4e2d \u8ba1\u7b97mAP\u7528\u5230\u7684\u4e00\u4e9bnumpy\u64cd\u4f5c\uff0c\u51fd\u6570\u4f7f\u7528\u5728 utils/metrics.py \u4e2d\u3002 \u7528\u5230\u7684python/numpy\u7684\u64cd\u4f5c\u6bd4\u5982\uff1a np.cumsum()\u3001np.interp()\u3001np.maximum.accumulate()\u3001np.trapz()\u7b49\u3002\u63a5\u4e0b\u6765\u5c06\u5728\u4e0b\u9762\u9010\u4e00\u4ecb\u7ecd\u3002 import numpy as np","title":"\u5f15\u8a00"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#npcumsum","text":"\u8fd4\u56de\u5143\u7d20\u6cbf\u7ed9\u5b9a\u8f74\u7684\u7d2f\u79ef\u548c\u3002 numpy.cumsum(a, axis=None, dtype=None, out=None) source \u53c2\u6570 a :\u6570\u7ec4 axis: \u8f74\u7d22\u5f15,\u6574\u578b\uff0c\u82e5a\u4e3an\u7ef4\u6570\u7ec4\uff0c\u5219axis\u7684\u53d6\u503c\u8303\u56f4\u4e3a[0,n-1] dtype: \u8fd4\u56de\u7ed3\u679c\u7684\u6570\u636e\u7c7b\u578b\uff0c\u82e5\u4e0d\u6307\u5b9a\uff0c\u5219\u9ed8\u8ba4\u4e0ea\u4e00\u81f4n out: \u6570\u636e\u7c7b\u578b\u4e3a\u6570\u7ec4\u3002\u7528\u6765\u653e\u7f6e\u7ed3\u679c\u7684\u66ff\u4ee3\u8f93\u51fa\u6570\u7ec4\uff0c\u5b83\u5fc5\u987b\u5177\u6709\u4e0e\u8f93\u51fa\u7ed3\u679c\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\u548c\u6570\u636e\u7f13\u51b2\u533a\u957f\u5ea6 \u8fd4\u56de \u6cbf\u7740\u6307\u5b9a\u8f74\u7684\u5143\u7d20\u7d2f\u52a0\u548c\u6240\u7ec4\u6210\u7684\u6570\u7ec4\uff0c\u5176\u5f62\u72b6\u5e94\u4e0e\u8f93\u5165\u6570\u7ec4a\u4e00\u81f4 \u66f4\u591a\u4fe1\u606f\u8bf7\u53c2\u9605\u8bfb: API_CN API_EN np . cumsum ( a ) # \u8ba1\u7b97\u7d2f\u79ef\u548c\u7684\u8f74\u3002\u9ed8\u8ba4\uff08\u65e0\uff09\u662f\u5728\u5c55\u5e73\u7684\u6570\u7ec4\u4e0a\u8ba1\u7b97cumsum\u3002 array([ 1, 3, 6, 10, 15, 21]) a = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) np . cumsum ( a , dtype = float ) # \u6307\u5b9a\u8f93\u51fa\u7684\u7279\u5b9a\u7684\u7c7b\u578b array([ 1., 3., 6., 10., 15., 21.]) np . cumsum ( a , axis = 0 ) # 3\u5217\u4e2d\u6bcf\u4e00\u5217\u7684\u884c\u603b\u548c array([[1, 2, 3], [5, 7, 9]]) x = np . ones (( 3 , 4 ), dtype = int ) np . cumsum ( x , axis = 0 ) array([[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3]]) np . cumsum ( a , axis = 1 ) # 2\u884c\u4e2d\u6bcf\u884c\u7684\u5217\u603b\u548c array([[ 1, 3, 6], [ 4, 9, 15]])","title":"np.cumsum()"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#npinterp","text":"\u53c2\u6570 x: \u6570\u7ec4 \u5f85\u63d2\u5165\u6570\u636e\u7684\u6a2a\u5750\u6807 xp: \u4e00\u7ef4\u6d6e\u70b9\u6570\u5e8f\u5217 \u539f\u59cb\u6570\u636e\u70b9\u7684\u6a2a\u5750\u6807\uff0c\u5982\u679cperiod\u53c2\u6570\u6ca1\u6709\u6307\u5b9a\u90a3\u4e48\u5c31\u5fc5\u987b\u662f\u9012\u589e\u7684 \u5426\u5219\uff0c\u5728\u4f7f\u7528xp = xp % period\u6b63\u5219 \u5316\u4e4b\u540e\uff0cxp\u5728\u5185\u90e8\u8fdb\u884c\u6392\u5e8f fp: \u4e00\u7ef4\u6d6e\u70b9\u6570\u6216\u590d\u6570\u5e8f\u5217 \u539f\u59cb\u6570\u636e\u70b9\u7684\u7eb5\u5750\u6807\uff0c\u548cxp\u5e8f\u5217\u7b49\u957f. left: \u53ef\u9009\u53c2\u6570\uff0c\u7c7b\u578b\u4e3a\u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09 \u5f53x < xp[0]\u65f6\u7684\u63d2\u503c\u8fd4\u56de\u503c\uff0c\u9ed8\u8ba4\u4e3afp[0]. right: \u53ef\u9009\u53c2\u6570\uff0c\u7c7b\u578b\u4e3a\u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09\uff0c\u5f53x > xp[-1]\u65f6\u7684\u63d2\u503c\u8fd4\u56de\u503c\uff0c\u9ed8\u8ba4\u4e3afp[-1]. period: None\u6216\u8005\u6d6e\u70b9\u6570\uff0c\u53ef\u9009\u53c2\u6570 \u6a2a\u5750\u6807\u7684\u5468\u671f \u6b64\u53c2\u6570\u4f7f\u5f97\u53ef\u4ee5\u6b63\u786e\u63d2\u5165angular x-coordinates. \u5982\u679c\u8be5\u53c2\u6570\u88ab\u8bbe\u5b9a\uff0c\u90a3\u4e48\u5ffd\u7565left\u53c2\u6570\u548cright\u53c2\u6570 \u8fd4\u56de \u6d6e\u70b9\u6570\u6216\u590d\u6570\uff08\u5bf9\u5e94\u4e8efp\u503c\uff09\u6216ndarray. \u63d2\u5165\u6570\u636e\u7684\u7eb5\u5750\u6807\uff0c\u548cx\u5f62\u72b6\u76f8\u540c \u6ce8\u610f\uff01 \u5728\u6ca1\u6709\u8bbe\u7f6eperiod\u53c2\u6570\u65f6\uff0c\u9ed8\u8ba4\u8981\u6c42xp\u53c2\u6570\u662f\u9012\u589e\u5e8f\u5217 # \u63d2\u5165\u4e00\u4e2a\u503c import numpy as np import matplotlib.pyplot as plt x = 2.5 xp = [ 1 , 2 , 3 ] fp = [ 3 , 2 , 0 ] y = np . interp ( x , xp , fp ) # 1.0 plt . plot ( xp , fp , '-o' ) plt . plot ( x , y , 'x' ) # \u753b\u63d2\u503c plt . show () # \u63d2\u5165\u4e00\u4e2a\u5e8f\u5217 import numpy as np import matplotlib.pyplot as plt x = [ 0 , 1 , 1.5 , 2.72 , 3.14 ] xp = [ 1 , 2 , 3 ] fp = [ 3 , 2 , 0 ] y = np . interp ( x , xp , fp ) # array([ 3. , 3. , 2.5 , 0.56, 0. ]) plt . plot ( xp , fp , '-o' ) plt . plot ( x , y , 'x' ) plt . show ()","title":"np.interp()"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#npmaximumaccumulate","text":"\u8ba1\u7b97\u6570\u7ec4\uff08\u6216\u6570\u7ec4\u7684\u7279\u5b9a\u8f74\uff09\u7684\u7d2f\u79ef\u6700\u5927\u503c import numpy as np d = np . random . randint ( low = 1 , high = 10 , size = ( 2 , 3 )) print ( \"d: \\n \" , d ) c = np . maximum . accumulate ( d , axis = 1 ) print ( \"c: \\n \" , c ) d: [[1 9 5] [2 6 1]] c: [[1 9 9] [2 6 6]]","title":"np.maximum.accumulate"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#nptrapz","text":"numpy.trapz(y, x=None, dx=1.0, axis=- 1) \u4f7f\u7528\u590d\u5408\u68af\u5f62\u89c4\u5219\u6cbf\u7ed9\u5b9a\u8f74\u79ef\u5206\u3002 import matplotlib.pyplot as plt import numpy as np y = [ 1 , 2 , 3 ] ; x = [ i + 1 for i in range ( len ( y ))] print ( np . trapz ( x )) plt . fill_between ( x , y ) plt . show () # (1 + 3)*(3 - 1)/2 = 4 4.0 import matplotlib.pyplot as plt import numpy as np y = [ 1 , 2 , 3 ] x = [ 4 , 6 , 8 ] print ( np . trapz ( y , x )) plt . fill_between ( x , y ) plt . show () # (3 + 1)*(8 - 4) / 2 = 8 8.0","title":"np.trapz()"},{"location":"tutorials/05_chapter/Introduction_to_functions_used_in_metrics.html#_2","text":"numpy API\u6587\u6863 CN\uff1a https://www.osgeo.cn/numpy/dev/index.html numpy API\u6587\u6863 EN\uff1a https://numpy.org/doc/stable/reference/index.html axis\u7684\u57fa\u672c\u4f7f\u7528\uff1a https://www.jb51.net/article/242067.htm","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \ud83d\udcd8\u6458\u8981 \u8fb9\u754c\u6846\u56de\u5f52\u662f\u76ee\u6807\u68c0\u6d4b\u7684\u5173\u952e\u6b65\u9aa4 \uff0c\u5728\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u867d\u7136 \\(\\ell_n\\) -norm loss \u88ab\u5e7f\u6cdb\u7528\u4e8e\u8fb9\u754c\u6846\u56de\u5f52\uff0c\u4f46\u5b83\u4e0d\u662f\u9488\u5bf9\u8bc4\u4f30\u6307\u6807\u91cf\u8eab\u5b9a\u5236\u7684\uff0c\u5373 Intersection over Union (IoU)\u3002\u6700\u8fd1\uff0c\u5df2\u7ecf\u63d0\u51fa\u4e86 IoU \u635f\u5931\u548cgeneralized IoU (GIoU) Loss\u4f5c\u4e3a\u8bc4\u4f30IoU\u7684\u6307\u6807 \uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u6536\u655b\u901f\u5ea6\u6162\u548c\u56de\u5f52\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u7ed3\u5408\u9884\u6d4b\u6846\u548c\u76ee\u6807\u6846\u4e4b\u95f4\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\u6765\u63d0\u51fa\u8ddd\u79bb-IoU (DIoU) Loss\uff0c\u5b83\u5728\u8bad\u7ec3\u4e2d\u7684\u6536\u655b\u901f\u5ea6\u6bd4 IoU \u548c GIoU Loss\u5feb\u5f97\u591a\u3002 \u6b64\u5916\uff0c\u672c\u6587\u603b\u7ed3\u4e86\u8fb9\u754c\u6846\u56de\u5f52\u4e2d\u7684\u4e09\u4e2a\u51e0\u4f55\u56e0\u7d20\uff0c\u5373 \u91cd\u53e0\u9762\u79ef\uff08overlap area\uff09\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb\uff08central point distance\uff09\u548c\u9ad8\u5bbd\u6bd4\uff08aspect ratio\uff09 \uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e86\u5b8c\u5168 \\(IoU (CIoU)\\) \u635f\u5931\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u4f18\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5c06 \\(DIoU \u548c CIoU \u635f\u5931\\) \u7ed3\u5408\u5230\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0c\u4f8b\u5982 YOLO v3\u3001SSD \u548c Faster RCNN\uff0c\u6211\u4eec\u4e0d\u4ec5\u5728 IoU \u6307\u6807\u65b9\u9762\u800c\u4e14\u5728 GIoU \u6307\u6807\u65b9\u9762\u90fd\u83b7\u5f97\u4e86\u663e\u7740\u7684\u6027\u80fd\u63d0\u5347\u3002\u6b64\u5916\uff0cDIoU \u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u7528\u4e8e\u975e\u6700\u5927\u6291\u5236\uff08NMS\uff09\u4f5c\u4e3a\u6807\u51c6\uff0c\u8fdb\u4e00\u6b65\u4fc3\u8fdb\u6027\u80fd\u63d0\u5347\u3002 \u6ce8\u91ca:\u8fd9\u91ccIoU\u6307\u6807\u65b9\u9762\u548cGIoU\u6307\u6807\u65b9\u9762\u6307\u7684\u662f\u5728\uff1a\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u6d4b\u91cf(mAP\u503c ),IoU\u635f\u5931\u8ba1\u7b97\u7a33\u5b9a\u6027\u7b49\u4e00\u4e9b\u65b9\u9762\u3002 \u76ee\u6807\u68c0\u6d4b\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u95ee\u9898\u4e4b\u4e00 \uff0c\u51e0\u5341 \u5e74\u6765\u4e00\u76f4\u53d7\u5230\u4e86\u5e7f\u6cdb\u7684\u7814\u7a76\u5173\u6ce8 (Redmon et al. 2016; Redmon and Farhadi 2018; Ren et al. 2015; He et al. 2017; Yang et al. 2018; Wang et al. 2019; 2018). \u901a\u5e38\uff0c\u73b0\u6709\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u53ef\u4ee5\u5206\u4e3a\uff1a - \u5355\u9636\u6bb5-\u68c0\u6d4b\uff0c\u5982YOLO\u7cfb\u5217 (Redmon et al. 2016; Red- mon and Farhadi 2017; 2018) \u548cSSD (Liu et al. 2016; Fu et al. 2017), - \u4e24\u9636\u6bb5\u68c0\u6d4b\uff0c\u5982 R-CNN\u7cfb\u5217\u68c0\u6d4b (Girshick et al. 2014; Girshick 2015; Ren et al. 2015; He et al. 2017), - \u751a\u81f3\u662f\u591a\u9636\u6bb5\u7684\u68c0\u6d4b, \u50cfCascade R-CNN (Cai and Vasconcelos 2018). \u5c3d\u7ba1\u5b58\u5728\u8fd9\u4e9b\u4e0d \u540c\u7684\u68c0\u6d4b\u6846\u67b6\uff0c\u4f46\u8fb9\u754c\u6846\u56de\u5f52\u9884\u6d4b\u4e00\u4e2a\u77e9\u5f62\u6846\u6765\u5b9a\u4f4d\u76ee\u6807\u5bf9\u8c61\u4ecd\u7136\u662f\u5176\u4e2d\u5173\u952e\u6b65\u9aa4\u3002 \u524d\u8a00 \u672c\u6587\u4e3b\u8981\u662f\u7ed3\u5408\u8bba\u6587Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression( https://arxiv.org/pdf/1911.08287.pdf ) \u5bf9 IoU \u7684\u89e3\u6790\u5b66\u4e60\u3002 IoU IoU\u4ecb\u7ecd Intersection over Union (IoU) \u5728\u6307\u6807\u8bc4\u4f30\u6982\u8ff0\u7684\u5c0f\u8282\u6709\u4ecb\u7ecd\u8fc7IoU,\u5df2\u7ecf\u5bf9IoU\u6709\u4e86\u521d\u6b65\u7684\u8ba4\u8bc6(\u5176\u5b9e\u5728yolov5\u9879\u76ee\u4e2d\u5e76\u4e0d\u662f\u7b80\u5355\u7684\u4f7f\u7528\uff0c\u800c\u662f\u7528\u7684\u540e\u9762\u4ecb\u7ecd\u7684CIoU ) \u8ba1\u7b97\u516c\u5f0f\uff1a \\(\\Large{I o U=\\frac{\\left|B \\cap B^{g t}\\right|}{\\left|B \\cup B^{g t}\\right|} }\\) (1) \\(B^{g t}=\\left(x^{g t}, y^{g t}, w^{g t}, h^{g t}\\right)\\) \u662f\u771f\u5b9e\u56de\u5f52\u6846(gt:ground-truth), \\(B=(x, y, w, h)\\) \u662f\u9884\u6d4b\u56de\u5f52\u6846\u3002 IoU loss \u8ba1\u7b97\u516c\u5f0f: \\(\\Large\\mathcal{L}_{I o U}=1-\\frac{\\left|B \\cap B^{g t}\\right|}{\\left|B \\cup B^{g t}\\right|}\\) (2) IoU Loss \u4f18\u7f3a\u70b9\u5206\u6790 \u6709\u660e\u663e\u7684\u7f3a\u9677 IoU loss\u53ea\u5728\u8fb9\u754c\u6846\u6709\u91cd\u53e0\u65f6\u624d\u80fd\u5de5\u4f5c, \u5bf9\u4e8e\u4e0d\u91cd\u53e0\u7684\u60c5\u51b5\u4e0d\u4f1a\u63d0\u4f9b\u4efb\u4f55\u79fb\u52a8\u68af\u5ea6 (\u79fb\u52a8\u4ee3\u8868\u9884\u6d4b\u6846\u671d\u7740\u76ee\u6807\u6846\u91cd\u53e0\u7684\u65b9\u5411\u79fb\u52a8) \u3002\u79fb\u52a8\u68af\u5ea6\u8868\u793a\u65e0\u6cd5\u8861\u91cf\u5b8c\u5168\u4e0d\u76f8\u4ea4\u7684\u4e24\u4e2a\u6846\u6240\u4ea7\u751f\u7684\u7684\u635f\u5931\uff08iou\u56fa\u5b9a\u4e3a0\uff09\uff0c\u548c\u4e24\u4e2a\u4e0d\u540c\u5f62\u72b6\u7684\u9884\u6d4b\u6846\u53ef\u80fd\u4ea7\u751f\u76f8\u540c\u7684loss\uff08\u76f8\u540c\u7684iou\uff09\u5206\u522b\u5982\u4e0b\u56fe\u7684\u5de6\u8fb9\u548c\u53f3\u8fb9\u6240\u793a\u3002 GIoU GIoU\u4ecb\u7ecd GIoU\u7684\u8bbe\u8ba1\u521d\u8877\u5c31\u662f\u60f3\u89e3\u51b3IoU Loss\u5b58\u5728\u7684\u95ee\u9898\uff08\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u4e0d\u76f8\u4ea4\u65f6iou\u6052\u5b9a\u4e3a0\uff09\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957Generalized Intersection over Union Loss\u3002\u5728IoU\u7684\u57fa\u7840\u4e0a\uff0cGIoU\u8fd8\u9700\u8981\u627e\u5230\u9884\u6d4b\u6846\u548c\u771f\u5b9e\u6846\u7684\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\uff0c\u7136\u540e\u6c42\u51fa\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u51cf\u53bb\u4e24\u4e2a\u9884\u6d4b\u6846union\u7684\u9762\u79ef\uff0c\u5177\u4f53\u7b97\u6cd5\u6d41\u7a0b\u5982\u4e0b\uff1a GIoU loss \u8ba1\u7b97\u516c\u5f0f : \\(\\large\\mathcal{L}_{G I o U}=1-I o U+\\frac{\\left|C-B \\cup B^{g t}\\right|}{|C|}\\) (3) \u5176\u4e2d \\(C\\) \u662f\u8986\u76d6 \\(B\\) \u548c \\(B^{g t}\\) \u7684\u6700\u5c0f\u65b9\u6846 ,\u7531\u4e8e\u5f15\u5165\u4e86 \\(C\\) \uff0c\u5728\u4e0d\u91cd\u53e0\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u6846\u4e5f\u4f1a\u5411\u76ee\u6807\u6846\u79fb\u52a8\u3002 GIoU \u4f18\u7f3a\u70b9\u5206\u6790 GIoU Loss\u89e3\u51b3\u4e86IoU Loss\u5728\u4e0d\u76f8\u4ea4\u60c5\u51b5\u7684\u95ee\u9898\uff0c\u5728\u6240\u6709\u6027\u80fd\u6307\u6807\u4e2d\u90fd\u53ef\u4ee5\u4f5c\u4e3aIoU\u7684\u9002\u5f53\u66ff\u4ee3\u54c1\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\u80fd\u591f\u5f97\u5230\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002 \u7f3a\u70b9\uff1a\u867d\u7136GIoU\u53ef\u4ee5\u7f13\u89e3\u91cd\u53e0\u60c5\u51b5\u4e0b\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898,\u4f46\u5b83\u4ecd\u6709\u4e00\u4e9b\u5c40\u9650\u6027\u3002\u5373\u65e0\u6cd5\u8861\u91cf\u6709\u5305\u542b\u5173\u7cfb\u65f6\u7684\u6846\u56de\u5f52\u635f\u5931\uff0c\u5982\u4e0b\u56fe\uff0c\u4e09\u4e2a\u56de\u5f52\u6846\u5177\u6709\u76f8\u540c\u7684GIoU Loss\uff0c\u4f46\u662f\u663e\u7136\u7b2c\u4e09\u4e2a\u6846\u7684\u56de\u5f52\u6548\u679c\u66f4\u597d\u3002 IoU & GIoU \u5206\u6790 \u9996\u5148\uff0c\u5728\u672c\u6587\u4e0a\u90e8\u5206\u6211\u4eec\u5206\u6790\u4e86\u5173\u4e8e\u539f\u59cb\u7684IoU\u635f\u5931\u548cGIoU \u635f\u5931\u7684\u5c40\u9650\u6027\u3002\u4e0b\u9762\u5c06\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u7ed3\u679c\u5bf9\u8fb9\u754c\u6846\u56de\u5f52\u7684\u8fc7\u7a0b\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684\u89e3\u6790\u3002(\u8865\u5145\u8bf4\u660e: \u4e3a\u4ec0\u4e48\u8981\u8fdb\u884c\u6a21\u578b\u5b9e\u9a8c? \u56e0\u4e3a\u4ec5\u4ec5\u4ece\u68c0\u6d4b\u7ed3\u679c\u6765\u5206\u6790\u8fb9\u754c\u6846\u56de\u5f52\u7684\u8fc7\u7a0b\u5f88\u96be\uff0c\u56e0\u4e3a\u5728\u4e0d\u53d7\u63a7\u5236\u7684\u57fa\u51c6\u4e2d\u7684\u56de\u5f52\u60c5\u51b5\u5f80\u5f80\u4e0d\u5168\u9762\u6bd4\u5982\uff1a\u4e0d\u540c\u7684\u8ddd\u79bb(distances),\u4e0d\u540c\u7684\u5c3a\u5ea6(scales)\u548c\u4e0d\u540c\u7684\u957f\u5bbd\u6bd4(aspect ratios)\u3002 \u76f8\u53cd\uff0c\u8fdb\u884c\u6a21\u62df\u5b9e\u9a8c\uff0c\u5728\u5b9e\u9a8c\u4e2d\u7efc\u5408\u8003\u8651\u56de\u5f52\u60c5\u51b5\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5206\u6790\u7ed9\u5b9a\u635f\u5931\u51fd\u6570\u7684\u95ee\u9898\u3002) \u6a21\u62df\u5b9e\u9a8c \u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u8bd5\u56fe\u901a\u8fc7\u8ddd\u79bb(distances), \u5c3a\u5ea6 (scales)\u548c\u957f\u5bbd\u6bd4(aspect ratios)\u6765\u8986\u76d6\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5927\u90e8\u5206\u5173\u7cfb\uff0c\u5982\u56fe3(a).\u6240\u793a\u3002\u7279\u522b\u662f, \u6211\u4eec\u9009\u62e97\u4e2a\u5355\u4f4d\u6846 (\u5373\u6bcf\u4e2a\u6846\u7684\u9762\u79ef\u4e3a 1) \uff0c\u5177\u6709\u4e0d\u540c\u7684\u957f\u5bbd\u6bd4 (\u5373 \\(1: 4\u30011: 3\u30011: 2\u30011:1\u30012: 1\u30013:1 \u548c 4: 1\\) ) \u4f5c\u4e3a\u76ee\u6807\u6846\u3002\u5728\u4e0d\u5931\u4e00\u822c\u6027\u7684\u60c5\u51b5\u4e0b\uff0c7\u4e2a\u76ee\u6807\u6846\u7684\u4e2d\u5fc3\u70b9\u88ab\u56fa\u5b9a\u5728 \\((10,10)\\) \u3002\u951a\u6846\u5747\u5300\u5730\u5206\u6563\u57285000\u4e2a\u70b9\u4e0a\u3002 \\(({i})\\) \u8ddd\u79bb: \u5728\u4ee5\u534a\u5f84\u4e3a 3 \u7684 \\((10\u300110)\\) \u4e3a\u4e2d\u5fc3\u7684\u5706\u5f62\u533a\u57df\u5185, \u5747\u5300\u9009\u62e95000\u4e2a\u70b9, \u653e\u7f6e7\u4e2a\u5c3a\u5ea6\u30017\u4e2a\u957f\u5bbd\u6bd4\u7684\u951a \u6846\u3002\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\uff0c\u91cd\u53e0\u548c\u4e0d\u91cd\u53e0\u7684\u65b9\u6846\u90fd\u88ab\u5305\u62ec\u3002 \\(({ii})\\) \u5c3a\u5ea6:\u5bf9\u4e8e\u6bcf\u4e2a\u70b9, \u951a\u6846\u7684\u9762\u79ef\u5206\u522b\u8bbe\u7f6e\u4e3a \\(0.5 \u3001 0.67 \u3001 0.75 \u3001 1 \u3001 1.33 \u3001 1.5 \u548c 2\\) \u3002 \\(({iii})\\) \u957f\u5bbd\u6bd4: \u5bf9\u4e8e\u7ed9\u5b9a\u7684\u70b9\u548c\u5c3a\u5ea6, \u91c7\u7528 7 \u4e2a\u957f\u5bbd\u6bd4, \u5373\u4e0e\u76ee\u6807\u6846\u9075\u5faa\u76f8\u540c\u7684\u8bbe\u7f6e (\u5373 \\(1: 4 \u3001 1: 3 \u3001 1: 2 \u3001 1: 1 \u3001 2: 1 \u3001 3: 1 \u548c 4: 1\\) ) \u3002\u6240\u6709 \\(5000 \\times 7 \\times 7\\) \u951a\u7bb1\u90fd\u5bf9\u5e94\u5728\u6bcf\u4e2a\u76ee\u6807\u6846\u3002\u7efc \u4e0a\u6240\u8ff0\uff0c\u603b\u5171\u6709 \\(1,715,000 =7 \\times 7 \\times 7 \\times 5,000\\) \u4e2a\u56de\u5f52\u6848\u4f8b\u3002 \u56fe3: \u4eff\u771f\u5b9e\u9a8c: (a) \u901a\u8fc7\u8003\u8651\u4e0d\u540c\u7684\u8ddd\u79bb\u3001\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4, \u91c7\u7528\u4e86171.5\u4e07\u4e2a\u56de\u5f52\u6848\u4f8b\u3002(b)\u56de\u5f52\u8bef\u5dee\u548c\uff08\u5373: \\(\\sum_{n} \\mathbf{E}(t, n)\\) ) \u8fed\u4ee3\u6b21\u6570\u4e3a \\(\\mathrm{t}\\) \u65f6\u4e0d\u540c\u635f\u5931\u51fd\u6570\u7684\u66f2\u7ebf\u3002 \u7136\u540e\u901a\u8fc7\u7ed9\u5b9a\u635f\u5931\u51fd\u6570 \\(\\mathcal{L}\\) , \u6211\u4eec\u53ef\u4ee5\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u6765\u6a21\u62df\u6bcf\u79cd\u60c5\u51b5\u4e0b\u7684\u8fb9\u754c\u6846\u56de\u5f52\u8fc7\u7a0b\u3002\u5bf9\u4e8e\u9884\u6d4b\u6846 \\(B_{i}\\) , \u5f53\u524d\u7684\u9884\u6d4b\u53ef\u4ee5\u901a\u8fc7: \\(B_{i}^{t}=B_{i}^{t-1}+\\eta\\left(2-I o U_{i}^{t-1}\\right) \\nabla B_{i}^{t-1},\\) (4) \u5176\u4e2d \\(B_{i}^{t}\\) \u662f\u8fed\u4ee3 \\(t\\) \u65f6\u7684\u9884\u6d4b\u6846, \\(\\nabla B_{i}^{t-1}\\) \u8868\u793a\u635f\u5931\u7684\u68af\u5ea6\u3002 \\(\\eta\\) \u611f\u89c9\u53ef\u4ee5\u7406\u89e3\u4e3a\u5b66\u4e60\u7387\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6211\u4eec\u7684\u5b9e\u73b0\u4e2d\uff0c\u68af\u5ea6\u4e58\u4ee5 \\(2-I o U_{1}^{t-1}\\) \u53bb\u52a0\u901f\u6536\u655b\u3002 \u8fb9\u754c\u6846\u56de\u5f52\u7684\u6027\u80fd\u8bc4\u4f30\u901a\u8fc7\u4f7f\u7528 \\(\\ell_{1} -norm.\\) \u5bf9\u4e8e\u6bcf\u4e2a\u635f\u5931 \u51fd\u6570, \u4eff\u771f\u6a21\u62df\u5b9e\u9a8c\u5f53\u8fbe\u5230\u8fed\u4ee3 \\(T=200\\) \u65f6, \u8bef\u5dee\u66f2\u7ebf\u5982 \\(\u56fe3(b).\\) \u6240\u793a\u3002 IoU \u548c GIoU \u635f\u5931\u7684\u9650\u5236 \u5728\u56fe4\u4e2d\uff0c\u6211\u4eec\u53ef\u89c6\u5316\u8fed\u4ee3T\u65f6\u5bf95000\u4e2a\u5206\u6563\u70b9\u7684\u6700\u7ec8\u56de\u5f52\u8bef\u5dee\u3002 \u4ece\u56fe4(a)\u4e2d\u5f88\u5bb9\u6613\u770b\u51fa\uff0cIoU\u635f\u5931\u53ea\u9002\u7528\u4e8e\u4e0e\u76ee\u6807\u6846\u91cd\u53e0\u7684\u60c5\u51b5\u3002\u7531\u4e8e\u2207B\u603b\u662f0\uff0c\u6ca1\u6709\u91cd\u53e0\u7684\u951a\u6846\u5c06\u4e0d\u4f1a\u79fb\u52a8\u3002\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2a\u60e9\u7f5a\u9879\u89c1\u516c\u5f0f(3), GIoU \u635f\u5931\u80fd\u591f\u66f4\u597d\u7684\u7f13\u89e3\u975e\u91cd\u53e0 \u6848\u4f8b\u7684\u95ee\u9898\uff0c\u5982\u56fe\u6240\u793a4(b), \u4f46GIoU\u7684\u635f\u5931\u663e\u8457\u6269\u5927\u4e86\u76c6\u5730\uff0c\u5373GIoU\u7684\u5de5\u4f5c\u9762\u79ef\u3002\u4f46\u662f\uff0c\u5728\u6c34\u5e73\u65b9\u5411\u548c\u5782\u76f4\u65b9\u5411\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u7136\u5f88\u53ef\u80fd\u6709\u5f88\u5927\u7684\u8bef\u5dee\u3002\u8fd9\u662f\u56e0\u4e3aGIoU\u635f\u5931\u4e2d\u7684\u60e9\u7f5a\u9879\u662f\u7528\u6765\u6700\u5c0f\u5316|C\u2212A\u222aB|\uff0c\u4f46\u662fC\u2212A\u222aB\u7684\u9762\u79ef\u901a\u5e38\u5f88\u5c0f\u6216\u4e3a0\uff08\u5f53\u4e24\u4e2a\u76d2\u5b50\u6709\u5305\u542b\u5173\u7cfb\u65f6\uff09\uff0c\u7136\u540eGIoU\u51e0\u4e4e\u9000\u5316\u4e3aIoU\u635f\u5931\u3002\u53ea\u8981\u4ee5\u9002\u5f53\u7684\u5b66\u4e60\u901f\u7387\u8fd0\u884c\u8db3\u591f\u7684\u8fed\u4ee3GIoU \u635f\u5931\u80fd\u6536\u655b\u5230\u5f88\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u6536\u655b\u901f\u5ea6\u5374\u662f\u975e\u5e38\u6162\u3002\u4ece\u51e0\u4f55\u4e0a\u6765\u8bf4\uff0c\u4ece\u5982\u56fe1\u6240\u793a\u7684\u56de\u5f52\u6b65\u9aa4\u6765\u770b\uff0cGIoU\u5b9e\u9645\u4e0a\u589e\u5927\u4e86\u9884\u6d4b\u7684\u6846\u5927\u5c0f\uff0c\u7528\u6765\u548c\u76ee\u6807\u6846\u91cd\u53e0\uff0c\u7136\u540eIoU\u9879\u7528\u4e8e\u9884\u6d4b\u6846\u4e0e\u76ee\u6807\u6846\u5339\u914d\uff0c\u4ea7\u751f\u975e\u5e38\u7f13\u6162\u7684\u6536\u655b\u3002 \u7efc\u4e0a\u6240\u8ff0\uff0c\u5728\u975e\u91cd\u53e0\u60c5\u51b5\u4e0b\uff0cIoU\u635f\u5931\u6536\u655b\u662f\u7cdf\u7cd5\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u800cGIoU\u635f\u5931\u6536\u655b\u901f\u5ea6\u8f83\u6162\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u6846\u3002\u5728\u76ee\u6807\u68c0\u6d4b\u6d41\u7a0b\u4e2d\uff0cIoU\u548cGIoU\u7684\u635f\u5931\u90fd\u4e0d\u80fd\u4fdd\u8bc1\u56de\u5f52\u7684\u51c6\u786e\u6027\u3002 DIoU & CIoU \u901a\u8fc7\u524d\u9762\u7684IoU\u548cGIoU\u7684\u5206\u6790\u6211\u4eec\u5f88\u81ea\u7136\u4f1a\u95ee\u4ee5\u4e0b\u95ee\u9898\uff1a \u7b2c\u4e00\uff0c\u662f\u5426\u53ef\u4ee5\u76f4\u63a5\u6700\u5c0f\u5316\u9884\u6d4b\u6846\u548c\u76ee\u6807\u6846\u4e4b\u95f4\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\uff1f \u7b2c\u4e8c\uff0c\u5f53\u4e0e\u76ee\u6807\u6846\u6709\u91cd\u53e0\u751a\u81f3\u5305\u542b\u65f6\uff0c\u5982\u4f55\u4f7f\u56de\u5f52\u66f4\u51c6\u786e\u3001\u66f4\u5feb\uff1f DIoU loss Distance-IoU \u635f\u5931\uff1a\u66f4\u5feb\u66f4\u597d\u7684\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931,\u4e00\u822c\u6765\u8bf4, \\(IoU-based\\) \u635f\u5931\u53ef\u4ee5\u5b9a\u4e49\u4e3a \\(\\mathcal{L}=1-I o U+\\mathcal{R}\\left(B, B^{g t}\\right),\\) (5) \u5176\u4e2d \\(\\large\\mathcal{R}\\left(B, B^{g t}\\right)\\) \u662f \u9884\u6d4b\u6846 B \u548c\u76ee\u6807\u6846 \\(B^{g t}\\) \u7684\u60e9\u7f5a\u9879\u3002 \u901a\u8fc7\u8bbe\u8ba1\u9002\u5f53\u7684\u60e9\u7f5a\u9879, \u5728\u672c\u8282\u4e2d, \u6211\u4eec\u63d0\u51fa\u4e86 DIoU \u635f\u5931\u548cCIoU\u635f\u5931\u6765\u89e3\u7b54\u4e0a\u8ff0\u4e24\u4e2a\u95ee\u9898\u3002 \u4e3a\u4e86\u56de\u7b54\u7b2c\u4e00\u4e2a\u95ee\u9898, \u6211\u4eec\u63d0\u51fa\u5c06\u4e24\u4e2a\u8fb9\u754c\u6846\u7684\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u6807\u51c6\u5316\u8ddd\u79bb\u6700\u5c0f\u5316\uff0c\u60e9\u7f5a\u9879\u53ef\u4ee5\u5b9a\u4e49\u4e3a \\(\\large\\mathcal{R}_{D I o U}=\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}},\\) (6) \u5176\u4e2d \\(\\mathbf{b}\\) \u548c \\(\\mathbf{b}^{g t}\\) \u5206\u522b\u4ee3\u8868 B \u548c \\(B^{g t}\\) \u7684\u4e2d\u5fc3\u70b9\u3002 \\(\\rho(\\cdot)\\) \u4e3a\u6b27\u6c0f\u8ddd\u79bb, \\(\\mathrm{C}\\) \u662f\u8986\u76d6\u4e24\u4e2a\u76d2\u6846\u7684\u6700\u5c0f\u5c01\u95ed\u6846\u7684\u5bf9\u89d2\u7ebf\u957f\u5ea6\u3002 \\(DIoU\\) \u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a: \\(\\large\\mathcal{L}_{D I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}} .\\) (7) \u5982\u56fe5\u6240\u793a, \\(DIoU\\) \u635f\u5931\u7684\u60e9\u7f5a\u9879\u76f4\u63a5\u4f7f\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u6700\u5c0f\u5316, \u800c \\(\\mathrm{GIoU}\\) \u635f\u5931\u7684\u76ee\u7684\u662f\u51cf\u5c11 \\(C-B \\cup B^{g t}\\) \u7684\u9762\u79ef\u3002 DIoU \u548c IoU/GIoU \u635f\u5931\u6bd4\u8f83 \u65b0\u63d0\u51fa\u7684DIoU\u635f\u5931\u7ee7\u627fIoU\u548cGIoU\u635f\u5931\u7684\u4e00\u4e9b\u5c5e\u6027 DIoU\u635f\u5931\u5bf9\u56de\u5f52\u95ee\u9898\u7684\u5c3a\u5ea6\u4ecd\u7136\u662f\u4e0d\u53d8\u7684 \u4e0eGIoU\u635f\u5931\u7c7b\u4f3c, DIoU\u635f\u5931\u53ef\u4ee5\u5728\u4e0e\u76ee\u6807\u6846\u4e0d\u91cd\u53e0\u65f6\u4e3a\u8fb9\u754c\u6846\u63d0\u4f9b\u79fb\u52a8\u65b9\u5411\u3002 \u5f53\u4e24\u4e2a\u8fb9\u754c\u6846\u5b8c\u7f8e\u5339\u914d\u65f6, \\(\\mathcal{L}_{I o U}=\\mathcal{L}_{G I o U}=\\mathcal{L}_{D I o U}=0 .\\) \u5f53\u4e24\u4e2a\u6846\u90fd\u5f88\u8fdc\u65f6, \\(\\mathcal{L}_{G I o U}=\\mathcal{L}_{D I o U} \\rightarrow 2 .\\) DIoU\u635f\u5931\u6bd4IoU\u635f\u5931\u548cGIoU\u635f\u5931\u6709\u51e0\u4e2a\u4f18\u70b9, \u53ef\u4ee5\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u8fdb\u884c\u8bc4\u4f30\u3002 1. \u5982\u56fe1\u548c\u56fe3\u6240\u793a, \\(DIoU\u635f\u5931\\) \u53ef\u4ee5\u76f4\u63a5\u6700\u5c0f\u5316\u4e24\u4e2a\u6846\u7684\u8ddd\u79bb, \u56e0\u6b64\u6536\u655b\u901f\u5ea6\u6bd4 \\(GIoU\u635f\u5931\\) \u8981\u5feb\u5f97\u591a\u3002 2. \u5bf9\u4e8e\u4e24\u4e2a\u6846\u662f\u5305\u542b\u5173\u7cfb\u7684\u60c5\u51b5(\u56fe2), \u6216\u5728\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u60c5\u51b5(\u56fe6)\u4e0b, \\(DIoU\u635f\u77e2\\) \u53ef\u4ee5\u56de\u5f52\u975e\u5e38\u5feb, \u800c \\(\\mathrm{GIoU}\\) \u635f\u5931\u51e0\u4e4e\u9000\u5316\u4e3a \\(\\mathrm{IoU}\u635f\u5931\\) , \u5373 \\(|C-A \\cup B| \\rightarrow 0 .\\) Complete IoU Loss \u63a5\u7740\u6211\u4eec\u56de\u7b54\u4e86\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u8fb9\u754c\u6846\u56de\u5f52\u7684\u826f\u597d \u635f\u5931\u5e94\u8be5\u8981\u8003\u8651\u4e09\u4e2a\u91cd\u8981\u7684\u51e0\u4f55\u56e0\u7d20, \u5373 \u91cd\u53e0\u9762\u79ef\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u548c\u957f\u5bbd\u6bd4 \u3002\u901a\u8fc7\u7edf\u4e00\u5750\u6807, \\(IoU\u635f\u5931\\) \u8003\u8651\u4e86\u91cd\u53e0\u533a\u57df, \u800c \\(GIoU\u635f\u5931\\) \u4e25\u91cd\u4f9d\u8d56\u4e8e \\(IoU\u635f\u5931\\) \u3002\u6211\u4eec\u63d0\u51fa\u7684 \\(DIoU\u635f\u5931\\) \u65e8\u5728\u540c\u65f6\u8003\u8651\u8fb9\u754c\u6846\u7684\u91cd\u53e0\u9762\u79ef\u548c\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u3002\u7136\u800c, \u8fb9\u754c\u6846\u7684\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u4e5f\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u51e0\u4f55\u56e0\u7d20\u3002 \u56e0\u6b64\uff0c\u57fa\u4e8e \\(DIoU\u635f\u5931\\) \uff0c\u901a\u8fc7\u6dfb\u52a0\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u6765 \u63d0\u51fa \\(CIoU\u635f\u5931\\) : \\(\\large\\mathcal{R}_{C I o U}=\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v,\\) (8) \u5176\u4e2d \\(\\alpha\\) \u662f\u4e00\u4e2a\u6b63\u7684\u6743\u8861\u53c2\u6570, \\(v\\) \u8861\u91cf\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u3002 \\(\\large{v=\\frac{4}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right)^{2} .}\\) (9) \u5219\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a: \\(\\large\\mathcal{L}_{C I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v\\) (10) \\(\\large\\alpha=\\frac{v}{(1-I o U)+v}\\) (11) \u901a\u8fc7\u91cd\u53e0\u9762\u79ef\u56e0\u5b50\u7ed9\u4e88\u66f4\u9ad8\u7684\u4f18\u5148\u56de\u5f52, \u7279\u522b\u662f\u5bf9\u4e8e\u975e\u91cd\u53e0\u60c5\u51b5\u3002 \u6700\u7ec8, \\(CIoU\u635f\u5931\\) \u7684\u4f18\u5316\u4e0e \\(DIoU\u635f\u5931\\) \u7684\u4f18\u5316\u76f8\u540c, \u9664 \u4e86 \\(v w.r.t. w\\) \u7684\u68af\u5ea6\u5e94\u8be5\u6307\u5b9a \\(\\mathrm{w}\\) \u548c \\(h\\) \u3002 \\(\\large\\begin{array}{l} \\frac{\\partial v}{\\partial w}=\\frac{8}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right) \\times \\frac{h}{w^{2}+h^{2}}, \\\\ \\frac{\\partial v}{\\partial h}=-\\frac{8}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right) \\times \\frac{w}{w^{2}+h^{2}} . \\end{array}\\) (12) \u4e3b\u5bfc\u5668 \\(w^{2}+h^{2}\\) \u901a\u5e38\u662f\u4e00\u4e2a\u5f88\u5c0f\u7684\u503c\u5bf9\u4e8e \\(h\\) \u548c \\(w\\) \u7684\u8303 \u56f4\u5728 [0,1] , \u8fd9\u5f88\u53ef\u80fd\u4f1a\u4ea7\u751f\u68af\u5ea6\u7206\u70b8\u3002\u56e0\u6b64\u5728\u6211\u4eec\u7684\u5b9e\u73b0, \u4e3b\u5bfc\u5668 \\(w^{2}+h^{2}\\) \u88ab\u79fb\u9664, \u5c06\u6b65\u957f \\(\\frac{1} {w^{2}+h^{2}}\\) \u66ff\u6362\u4e3a \\(1\\) , \u68af\u5ea6\u65b9\u5411\u4ecd\u7136\u4e0e\u516c\u5f0f(12)\u4e00\u81f4\u3002 NMS(Non-Maximum Suppression) \u4ecb\u7ecd NMS\u662f\u5927\u591a\u6570\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u6700\u540e\u4e00\u6b65\uff0c\u5176\u4e2d\u5220\u9664\u4e86\u5197\u4f59\u7684\u68c0\u6d4b\u6846\u5f53\u5b83\u4e0e\u6700\u9ad8\u5206\u6846\u7684\u91cd\u53e0\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c\u3002 Soft-NMS (Bodla et al. 2017) \u7528\u8fde\u7eed\u51fd\u6570w.r.t.\u60e9\u7f5a\u76f8\u90bb\u6846\u7684\u68c0\u6d4b\u5206\u6570IoU\uff0c\u4ea7\u751f\u6bd4\u539f\u59cbNMS\u4ea7\u751f\u66f4\u67d4\u548c\u5927\u548c\u66f4\u5f3a\u5927\u7684\u6291\u5236\u3002IoU-Net (Jiang et al. 2018) \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u7f51\u7edc\u5206\u652f\u6765\u9884\u6d4b\u5b9a\u4f4d\u7f6e\u4fe1\u5ea6\u6765\u6307\u5bfcNMS\u3002\u6700\u8fd1\uff0c\u81ea\u9002\u5e94NMS\uff08Liu\uff0cHuang\uff0c\u548cWang 2019\uff09\u548cSofter-NMS\uff08He et al. 2019\uff09\u88ab\u63d0\u51fa\u5206\u522b\u7814\u7a76\u9002\u5f53\u7684\u9608\u503c\u7b56\u7565\u548c\u52a0\u6743\u5e73\u5747\u7b56\u7565\u3002 \u5728\u672c\u5de5\u4f5c\u4e2d\uff0c\u7b80\u5355\u5c06DIoU\u4f5c\u4e3a\u539f\u59cbNMS\u7684\u6807\u51c6, \u5728\u6291\u5236\u5197\u4f59\u6846\u65f6\uff0c\u540c\u65f6\u8003\u8651\u8fb9\u754c\u6846\u7684\u91cd\u53e0\u9762\u79ef\u548c\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002 DioU-NMS Non-Maximum Suppression using DIoU \u5728\u539f\u59cb\u7684NMS\u4e2d, IoU\u6307\u6807\u7528\u4e8e\u6291\u5236\u5415\u4f59\u7684\u68c0\u6d4b\u6846, \u5176 \u4e2d\u91cd\u53e0\u533a\u57df\u662f\u552f\u4e00\u7684\u56e0\u7d20, \u5bf9\u4e8e\u6709\u906e\u6321\u7684\u60c5\u51b5\uff0c\u5f80\u5f80\u4f1a \u4ea7\u751f\u9519\u8bef\u7684\u6291\u5236\u3002 \u6211\u4eec\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\u5efa\u8bae \\(DIoU\\) \u662f \\(NMS\\) \u7684\u66f4\u597d\u6807\u51c6\uff0c\u56e0\u4e3a\u5728\u6291\u5236\u6807\u51c6\u4e2d\u4e0d\u4ec5\u5e94\u8003\u8651\u91cd\u53e0 \\(DIoU-NMS\\) \u88ab\u6b63\u5f0f\u5b9a\u4e49\u4e3a: \\(s_{i}=\\left\\{\\begin{array}{l} s_{i}, I o U-\\mathcal{R}_{D I o U}\\left(\\mathcal{M}, B_{i}\\right)<\\varepsilon, \\\\ 0, \\quad I o U-\\mathcal{R}_{D I o U}\\left(\\mathcal{M}, B_{i}\\right) \\geq \\varepsilon, \\end{array}\\right.\\) (13) \u5176\u4e2d\u6846 \\(B_{i}\\) \u88ab\u53bb\u9664\u901a\u8fc7\u540c\u65f6\u5230\u8003\u8651 \\(IoU\\) \u548c\u4e24\u4e2a\u6846\u4e2d\u5fc3\u70b9 \u7684\u8ddd\u79bb\u3002 \\(s_{i}\\) \u662f\u5206\u7c7b\u5f97\u5206\u548c \\(\\varepsilon\\) \u662f \\(NMS\\) \u9608\u503c\u3002\u6211\u4eec\u8ba4\u4e3a\u4e24 \u4e2a\u4e2d\u5fc3\u70b9\u8f83\u8fdc\u7684\u6846\u53ef\u80fd\u4f1a\u5b9a\u4f4d\u4e0d\u540c\u7684\u7269\u4f53, \u800c\u4e0d\u5e94\u8be5\u88ab \u5220\u9664\u3002\u6b64\u5916 \\(DIoU-NMS\\) \u662f\u975e\u5e38\u7075\u6d3b, \u4ec5\u4ec5\u662f\u51e0\u884c\u7684\u4ee3\u7801\u5c31\u53ef\u4ee5\u96c6\u6210\u5230\u4efb\u4f55\u76ee\u6807\u68c0\u6d4b\u7ba1\u9053\u4e2d\u3002 \u5c0f\u7ed3 \u5728\u672c\u6587\u4e2d\uff0c\u4e3b\u8981\u7684\u4ecb\u7ecd\u7528\u4e8e\u8fb9\u754c\u6846\u56de\u5f52\u7684 \\(DIoU\u635f\u5931\\) \u548c \\(CIoU \u635f\u5931\\) \u548c \u7528\u4e8e\u6291\u5236\u5197\u4f59\u68c0\u6d4b\u6846\u7684 \\(DIoU-NMS\u3002\\) \u901a\u8fc7\u76f4\u63a5\u6700\u5c0f\u5316\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u7684\u5f52\u4e00\u5316\u7684\u8ddd\u79bb\uff0c \\(DIoU \u635f\u5931\\) \u53ef\u4ee5\u6bd4 \\(GIoU \u635f\u5931\\) \u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u3002 \u6b64\u5916 \\(CIoU\u635f\u5931\\) \u8003\u8651\u4e86\u4e09\u4e2a\u51e0\u4f55\u5c5e\u6027(\u5373 \u91cd\u53e0\u533a\u57df\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb \u548c \u957f\u5bbd\u6bd4),\u4fc3\u8fdb\u4e86 \u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u4f18\u7684\u6027\u80fd\u3002 \u53c2\u8003\u6587\u7ae0 https://github.com/Zzh-tju/DIoU/blob/master/README.md#introduction https://github.com/Zzh-tju/DIoU/blob/master/README.md#introduction IoU: https://arxiv.org/pdf/1608.01471.pdf GIoU: https://giou.stanford.edu/GIoU.pdf DIoU: https://arxiv.org/pdf/1911.08287.pdf","title":"5.2 IoU\u6df1\u5165\u89e3\u6790"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_1","text":"\u8fb9\u754c\u6846\u56de\u5f52\u662f\u76ee\u6807\u68c0\u6d4b\u7684\u5173\u952e\u6b65\u9aa4 \uff0c\u5728\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u867d\u7136 \\(\\ell_n\\) -norm loss \u88ab\u5e7f\u6cdb\u7528\u4e8e\u8fb9\u754c\u6846\u56de\u5f52\uff0c\u4f46\u5b83\u4e0d\u662f\u9488\u5bf9\u8bc4\u4f30\u6307\u6807\u91cf\u8eab\u5b9a\u5236\u7684\uff0c\u5373 Intersection over Union (IoU)\u3002\u6700\u8fd1\uff0c\u5df2\u7ecf\u63d0\u51fa\u4e86 IoU \u635f\u5931\u548cgeneralized IoU (GIoU) Loss\u4f5c\u4e3a\u8bc4\u4f30IoU\u7684\u6307\u6807 \uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u6536\u655b\u901f\u5ea6\u6162\u548c\u56de\u5f52\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u7ed3\u5408\u9884\u6d4b\u6846\u548c\u76ee\u6807\u6846\u4e4b\u95f4\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\u6765\u63d0\u51fa\u8ddd\u79bb-IoU (DIoU) Loss\uff0c\u5b83\u5728\u8bad\u7ec3\u4e2d\u7684\u6536\u655b\u901f\u5ea6\u6bd4 IoU \u548c GIoU Loss\u5feb\u5f97\u591a\u3002 \u6b64\u5916\uff0c\u672c\u6587\u603b\u7ed3\u4e86\u8fb9\u754c\u6846\u56de\u5f52\u4e2d\u7684\u4e09\u4e2a\u51e0\u4f55\u56e0\u7d20\uff0c\u5373 \u91cd\u53e0\u9762\u79ef\uff08overlap area\uff09\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb\uff08central point distance\uff09\u548c\u9ad8\u5bbd\u6bd4\uff08aspect ratio\uff09 \uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e86\u5b8c\u5168 \\(IoU (CIoU)\\) \u635f\u5931\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u4f18\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5c06 \\(DIoU \u548c CIoU \u635f\u5931\\) \u7ed3\u5408\u5230\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0c\u4f8b\u5982 YOLO v3\u3001SSD \u548c Faster RCNN\uff0c\u6211\u4eec\u4e0d\u4ec5\u5728 IoU \u6307\u6807\u65b9\u9762\u800c\u4e14\u5728 GIoU \u6307\u6807\u65b9\u9762\u90fd\u83b7\u5f97\u4e86\u663e\u7740\u7684\u6027\u80fd\u63d0\u5347\u3002\u6b64\u5916\uff0cDIoU \u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u7528\u4e8e\u975e\u6700\u5927\u6291\u5236\uff08NMS\uff09\u4f5c\u4e3a\u6807\u51c6\uff0c\u8fdb\u4e00\u6b65\u4fc3\u8fdb\u6027\u80fd\u63d0\u5347\u3002 \u6ce8\u91ca:\u8fd9\u91ccIoU\u6307\u6807\u65b9\u9762\u548cGIoU\u6307\u6807\u65b9\u9762\u6307\u7684\u662f\u5728\uff1a\u76ee\u6807\u68c0\u6d4b\u7cbe\u5ea6\u6d4b\u91cf(mAP\u503c ),IoU\u635f\u5931\u8ba1\u7b97\u7a33\u5b9a\u6027\u7b49\u4e00\u4e9b\u65b9\u9762\u3002 \u76ee\u6807\u68c0\u6d4b\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u95ee\u9898\u4e4b\u4e00 \uff0c\u51e0\u5341 \u5e74\u6765\u4e00\u76f4\u53d7\u5230\u4e86\u5e7f\u6cdb\u7684\u7814\u7a76\u5173\u6ce8 (Redmon et al. 2016; Redmon and Farhadi 2018; Ren et al. 2015; He et al. 2017; Yang et al. 2018; Wang et al. 2019; 2018). \u901a\u5e38\uff0c\u73b0\u6709\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u53ef\u4ee5\u5206\u4e3a\uff1a - \u5355\u9636\u6bb5-\u68c0\u6d4b\uff0c\u5982YOLO\u7cfb\u5217 (Redmon et al. 2016; Red- mon and Farhadi 2017; 2018) \u548cSSD (Liu et al. 2016; Fu et al. 2017), - \u4e24\u9636\u6bb5\u68c0\u6d4b\uff0c\u5982 R-CNN\u7cfb\u5217\u68c0\u6d4b (Girshick et al. 2014; Girshick 2015; Ren et al. 2015; He et al. 2017), - \u751a\u81f3\u662f\u591a\u9636\u6bb5\u7684\u68c0\u6d4b, \u50cfCascade R-CNN (Cai and Vasconcelos 2018). \u5c3d\u7ba1\u5b58\u5728\u8fd9\u4e9b\u4e0d \u540c\u7684\u68c0\u6d4b\u6846\u67b6\uff0c\u4f46\u8fb9\u754c\u6846\u56de\u5f52\u9884\u6d4b\u4e00\u4e2a\u77e9\u5f62\u6846\u6765\u5b9a\u4f4d\u76ee\u6807\u5bf9\u8c61\u4ecd\u7136\u662f\u5176\u4e2d\u5173\u952e\u6b65\u9aa4\u3002","title":"\ud83d\udcd8\u6458\u8981"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_2","text":"\u672c\u6587\u4e3b\u8981\u662f\u7ed3\u5408\u8bba\u6587Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression( https://arxiv.org/pdf/1911.08287.pdf ) \u5bf9 IoU \u7684\u89e3\u6790\u5b66\u4e60\u3002","title":"\u524d\u8a00"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou","text":"","title":"IoU"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou_1","text":"Intersection over Union (IoU) \u5728\u6307\u6807\u8bc4\u4f30\u6982\u8ff0\u7684\u5c0f\u8282\u6709\u4ecb\u7ecd\u8fc7IoU,\u5df2\u7ecf\u5bf9IoU\u6709\u4e86\u521d\u6b65\u7684\u8ba4\u8bc6(\u5176\u5b9e\u5728yolov5\u9879\u76ee\u4e2d\u5e76\u4e0d\u662f\u7b80\u5355\u7684\u4f7f\u7528\uff0c\u800c\u662f\u7528\u7684\u540e\u9762\u4ecb\u7ecd\u7684CIoU ) \u8ba1\u7b97\u516c\u5f0f\uff1a \\(\\Large{I o U=\\frac{\\left|B \\cap B^{g t}\\right|}{\\left|B \\cup B^{g t}\\right|} }\\) (1) \\(B^{g t}=\\left(x^{g t}, y^{g t}, w^{g t}, h^{g t}\\right)\\) \u662f\u771f\u5b9e\u56de\u5f52\u6846(gt:ground-truth), \\(B=(x, y, w, h)\\) \u662f\u9884\u6d4b\u56de\u5f52\u6846\u3002","title":"IoU\u4ecb\u7ecd"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou-loss","text":"\u8ba1\u7b97\u516c\u5f0f: \\(\\Large\\mathcal{L}_{I o U}=1-\\frac{\\left|B \\cap B^{g t}\\right|}{\\left|B \\cup B^{g t}\\right|}\\) (2)","title":"IoU loss"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou-loss_1","text":"\u6709\u660e\u663e\u7684\u7f3a\u9677 IoU loss\u53ea\u5728\u8fb9\u754c\u6846\u6709\u91cd\u53e0\u65f6\u624d\u80fd\u5de5\u4f5c, \u5bf9\u4e8e\u4e0d\u91cd\u53e0\u7684\u60c5\u51b5\u4e0d\u4f1a\u63d0\u4f9b\u4efb\u4f55\u79fb\u52a8\u68af\u5ea6 (\u79fb\u52a8\u4ee3\u8868\u9884\u6d4b\u6846\u671d\u7740\u76ee\u6807\u6846\u91cd\u53e0\u7684\u65b9\u5411\u79fb\u52a8) \u3002\u79fb\u52a8\u68af\u5ea6\u8868\u793a\u65e0\u6cd5\u8861\u91cf\u5b8c\u5168\u4e0d\u76f8\u4ea4\u7684\u4e24\u4e2a\u6846\u6240\u4ea7\u751f\u7684\u7684\u635f\u5931\uff08iou\u56fa\u5b9a\u4e3a0\uff09\uff0c\u548c\u4e24\u4e2a\u4e0d\u540c\u5f62\u72b6\u7684\u9884\u6d4b\u6846\u53ef\u80fd\u4ea7\u751f\u76f8\u540c\u7684loss\uff08\u76f8\u540c\u7684iou\uff09\u5206\u522b\u5982\u4e0b\u56fe\u7684\u5de6\u8fb9\u548c\u53f3\u8fb9\u6240\u793a\u3002","title":"IoU Loss \u4f18\u7f3a\u70b9\u5206\u6790"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#giou","text":"","title":"GIoU"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#giou_1","text":"GIoU\u7684\u8bbe\u8ba1\u521d\u8877\u5c31\u662f\u60f3\u89e3\u51b3IoU Loss\u5b58\u5728\u7684\u95ee\u9898\uff08\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u4e0d\u76f8\u4ea4\u65f6iou\u6052\u5b9a\u4e3a0\uff09\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957Generalized Intersection over Union Loss\u3002\u5728IoU\u7684\u57fa\u7840\u4e0a\uff0cGIoU\u8fd8\u9700\u8981\u627e\u5230\u9884\u6d4b\u6846\u548c\u771f\u5b9e\u6846\u7684\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\uff0c\u7136\u540e\u6c42\u51fa\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u51cf\u53bb\u4e24\u4e2a\u9884\u6d4b\u6846union\u7684\u9762\u79ef\uff0c\u5177\u4f53\u7b97\u6cd5\u6d41\u7a0b\u5982\u4e0b\uff1a","title":"GIoU\u4ecb\u7ecd"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#giou-loss","text":"\u8ba1\u7b97\u516c\u5f0f : \\(\\large\\mathcal{L}_{G I o U}=1-I o U+\\frac{\\left|C-B \\cup B^{g t}\\right|}{|C|}\\) (3) \u5176\u4e2d \\(C\\) \u662f\u8986\u76d6 \\(B\\) \u548c \\(B^{g t}\\) \u7684\u6700\u5c0f\u65b9\u6846 ,\u7531\u4e8e\u5f15\u5165\u4e86 \\(C\\) \uff0c\u5728\u4e0d\u91cd\u53e0\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u6846\u4e5f\u4f1a\u5411\u76ee\u6807\u6846\u79fb\u52a8\u3002","title":"GIoU loss"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#giou_2","text":"GIoU Loss\u89e3\u51b3\u4e86IoU Loss\u5728\u4e0d\u76f8\u4ea4\u60c5\u51b5\u7684\u95ee\u9898\uff0c\u5728\u6240\u6709\u6027\u80fd\u6307\u6807\u4e2d\u90fd\u53ef\u4ee5\u4f5c\u4e3aIoU\u7684\u9002\u5f53\u66ff\u4ee3\u54c1\uff0c\u5728\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\u80fd\u591f\u5f97\u5230\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002 \u7f3a\u70b9\uff1a\u867d\u7136GIoU\u53ef\u4ee5\u7f13\u89e3\u91cd\u53e0\u60c5\u51b5\u4e0b\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898,\u4f46\u5b83\u4ecd\u6709\u4e00\u4e9b\u5c40\u9650\u6027\u3002\u5373\u65e0\u6cd5\u8861\u91cf\u6709\u5305\u542b\u5173\u7cfb\u65f6\u7684\u6846\u56de\u5f52\u635f\u5931\uff0c\u5982\u4e0b\u56fe\uff0c\u4e09\u4e2a\u56de\u5f52\u6846\u5177\u6709\u76f8\u540c\u7684GIoU Loss\uff0c\u4f46\u662f\u663e\u7136\u7b2c\u4e09\u4e2a\u6846\u7684\u56de\u5f52\u6548\u679c\u66f4\u597d\u3002","title":"GIoU \u4f18\u7f3a\u70b9\u5206\u6790"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou-giou","text":"\u9996\u5148\uff0c\u5728\u672c\u6587\u4e0a\u90e8\u5206\u6211\u4eec\u5206\u6790\u4e86\u5173\u4e8e\u539f\u59cb\u7684IoU\u635f\u5931\u548cGIoU \u635f\u5931\u7684\u5c40\u9650\u6027\u3002\u4e0b\u9762\u5c06\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u7ed3\u679c\u5bf9\u8fb9\u754c\u6846\u56de\u5f52\u7684\u8fc7\u7a0b\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684\u89e3\u6790\u3002(\u8865\u5145\u8bf4\u660e: \u4e3a\u4ec0\u4e48\u8981\u8fdb\u884c\u6a21\u578b\u5b9e\u9a8c? \u56e0\u4e3a\u4ec5\u4ec5\u4ece\u68c0\u6d4b\u7ed3\u679c\u6765\u5206\u6790\u8fb9\u754c\u6846\u56de\u5f52\u7684\u8fc7\u7a0b\u5f88\u96be\uff0c\u56e0\u4e3a\u5728\u4e0d\u53d7\u63a7\u5236\u7684\u57fa\u51c6\u4e2d\u7684\u56de\u5f52\u60c5\u51b5\u5f80\u5f80\u4e0d\u5168\u9762\u6bd4\u5982\uff1a\u4e0d\u540c\u7684\u8ddd\u79bb(distances),\u4e0d\u540c\u7684\u5c3a\u5ea6(scales)\u548c\u4e0d\u540c\u7684\u957f\u5bbd\u6bd4(aspect ratios)\u3002 \u76f8\u53cd\uff0c\u8fdb\u884c\u6a21\u62df\u5b9e\u9a8c\uff0c\u5728\u5b9e\u9a8c\u4e2d\u7efc\u5408\u8003\u8651\u56de\u5f52\u60c5\u51b5\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5206\u6790\u7ed9\u5b9a\u635f\u5931\u51fd\u6570\u7684\u95ee\u9898\u3002)","title":"IoU &amp; GIoU \u5206\u6790"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_3","text":"\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d, \u6211\u4eec\u8bd5\u56fe\u901a\u8fc7\u8ddd\u79bb(distances), \u5c3a\u5ea6 (scales)\u548c\u957f\u5bbd\u6bd4(aspect ratios)\u6765\u8986\u76d6\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5927\u90e8\u5206\u5173\u7cfb\uff0c\u5982\u56fe3(a).\u6240\u793a\u3002\u7279\u522b\u662f, \u6211\u4eec\u9009\u62e97\u4e2a\u5355\u4f4d\u6846 (\u5373\u6bcf\u4e2a\u6846\u7684\u9762\u79ef\u4e3a 1) \uff0c\u5177\u6709\u4e0d\u540c\u7684\u957f\u5bbd\u6bd4 (\u5373 \\(1: 4\u30011: 3\u30011: 2\u30011:1\u30012: 1\u30013:1 \u548c 4: 1\\) ) \u4f5c\u4e3a\u76ee\u6807\u6846\u3002\u5728\u4e0d\u5931\u4e00\u822c\u6027\u7684\u60c5\u51b5\u4e0b\uff0c7\u4e2a\u76ee\u6807\u6846\u7684\u4e2d\u5fc3\u70b9\u88ab\u56fa\u5b9a\u5728 \\((10,10)\\) \u3002\u951a\u6846\u5747\u5300\u5730\u5206\u6563\u57285000\u4e2a\u70b9\u4e0a\u3002 \\(({i})\\) \u8ddd\u79bb: \u5728\u4ee5\u534a\u5f84\u4e3a 3 \u7684 \\((10\u300110)\\) \u4e3a\u4e2d\u5fc3\u7684\u5706\u5f62\u533a\u57df\u5185, \u5747\u5300\u9009\u62e95000\u4e2a\u70b9, \u653e\u7f6e7\u4e2a\u5c3a\u5ea6\u30017\u4e2a\u957f\u5bbd\u6bd4\u7684\u951a \u6846\u3002\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\uff0c\u91cd\u53e0\u548c\u4e0d\u91cd\u53e0\u7684\u65b9\u6846\u90fd\u88ab\u5305\u62ec\u3002 \\(({ii})\\) \u5c3a\u5ea6:\u5bf9\u4e8e\u6bcf\u4e2a\u70b9, \u951a\u6846\u7684\u9762\u79ef\u5206\u522b\u8bbe\u7f6e\u4e3a \\(0.5 \u3001 0.67 \u3001 0.75 \u3001 1 \u3001 1.33 \u3001 1.5 \u548c 2\\) \u3002 \\(({iii})\\) \u957f\u5bbd\u6bd4: \u5bf9\u4e8e\u7ed9\u5b9a\u7684\u70b9\u548c\u5c3a\u5ea6, \u91c7\u7528 7 \u4e2a\u957f\u5bbd\u6bd4, \u5373\u4e0e\u76ee\u6807\u6846\u9075\u5faa\u76f8\u540c\u7684\u8bbe\u7f6e (\u5373 \\(1: 4 \u3001 1: 3 \u3001 1: 2 \u3001 1: 1 \u3001 2: 1 \u3001 3: 1 \u548c 4: 1\\) ) \u3002\u6240\u6709 \\(5000 \\times 7 \\times 7\\) \u951a\u7bb1\u90fd\u5bf9\u5e94\u5728\u6bcf\u4e2a\u76ee\u6807\u6846\u3002\u7efc \u4e0a\u6240\u8ff0\uff0c\u603b\u5171\u6709 \\(1,715,000 =7 \\times 7 \\times 7 \\times 5,000\\) \u4e2a\u56de\u5f52\u6848\u4f8b\u3002 \u56fe3: \u4eff\u771f\u5b9e\u9a8c: (a) \u901a\u8fc7\u8003\u8651\u4e0d\u540c\u7684\u8ddd\u79bb\u3001\u5c3a\u5ea6\u548c\u957f\u5bbd\u6bd4, \u91c7\u7528\u4e86171.5\u4e07\u4e2a\u56de\u5f52\u6848\u4f8b\u3002(b)\u56de\u5f52\u8bef\u5dee\u548c\uff08\u5373: \\(\\sum_{n} \\mathbf{E}(t, n)\\) ) \u8fed\u4ee3\u6b21\u6570\u4e3a \\(\\mathrm{t}\\) \u65f6\u4e0d\u540c\u635f\u5931\u51fd\u6570\u7684\u66f2\u7ebf\u3002 \u7136\u540e\u901a\u8fc7\u7ed9\u5b9a\u635f\u5931\u51fd\u6570 \\(\\mathcal{L}\\) , \u6211\u4eec\u53ef\u4ee5\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5 \u6765\u6a21\u62df\u6bcf\u79cd\u60c5\u51b5\u4e0b\u7684\u8fb9\u754c\u6846\u56de\u5f52\u8fc7\u7a0b\u3002\u5bf9\u4e8e\u9884\u6d4b\u6846 \\(B_{i}\\) , \u5f53\u524d\u7684\u9884\u6d4b\u53ef\u4ee5\u901a\u8fc7: \\(B_{i}^{t}=B_{i}^{t-1}+\\eta\\left(2-I o U_{i}^{t-1}\\right) \\nabla B_{i}^{t-1},\\) (4) \u5176\u4e2d \\(B_{i}^{t}\\) \u662f\u8fed\u4ee3 \\(t\\) \u65f6\u7684\u9884\u6d4b\u6846, \\(\\nabla B_{i}^{t-1}\\) \u8868\u793a\u635f\u5931\u7684\u68af\u5ea6\u3002 \\(\\eta\\) \u611f\u89c9\u53ef\u4ee5\u7406\u89e3\u4e3a\u5b66\u4e60\u7387\u3002 \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6211\u4eec\u7684\u5b9e\u73b0\u4e2d\uff0c\u68af\u5ea6\u4e58\u4ee5 \\(2-I o U_{1}^{t-1}\\) \u53bb\u52a0\u901f\u6536\u655b\u3002 \u8fb9\u754c\u6846\u56de\u5f52\u7684\u6027\u80fd\u8bc4\u4f30\u901a\u8fc7\u4f7f\u7528 \\(\\ell_{1} -norm.\\) \u5bf9\u4e8e\u6bcf\u4e2a\u635f\u5931 \u51fd\u6570, \u4eff\u771f\u6a21\u62df\u5b9e\u9a8c\u5f53\u8fbe\u5230\u8fed\u4ee3 \\(T=200\\) \u65f6, \u8bef\u5dee\u66f2\u7ebf\u5982 \\(\u56fe3(b).\\) \u6240\u793a\u3002","title":"\u6a21\u62df\u5b9e\u9a8c"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#iou-giou_1","text":"\u5728\u56fe4\u4e2d\uff0c\u6211\u4eec\u53ef\u89c6\u5316\u8fed\u4ee3T\u65f6\u5bf95000\u4e2a\u5206\u6563\u70b9\u7684\u6700\u7ec8\u56de\u5f52\u8bef\u5dee\u3002 \u4ece\u56fe4(a)\u4e2d\u5f88\u5bb9\u6613\u770b\u51fa\uff0cIoU\u635f\u5931\u53ea\u9002\u7528\u4e8e\u4e0e\u76ee\u6807\u6846\u91cd\u53e0\u7684\u60c5\u51b5\u3002\u7531\u4e8e\u2207B\u603b\u662f0\uff0c\u6ca1\u6709\u91cd\u53e0\u7684\u951a\u6846\u5c06\u4e0d\u4f1a\u79fb\u52a8\u3002\u901a\u8fc7\u6dfb\u52a0\u4e00\u4e2a\u60e9\u7f5a\u9879\u89c1\u516c\u5f0f(3), GIoU \u635f\u5931\u80fd\u591f\u66f4\u597d\u7684\u7f13\u89e3\u975e\u91cd\u53e0 \u6848\u4f8b\u7684\u95ee\u9898\uff0c\u5982\u56fe\u6240\u793a4(b), \u4f46GIoU\u7684\u635f\u5931\u663e\u8457\u6269\u5927\u4e86\u76c6\u5730\uff0c\u5373GIoU\u7684\u5de5\u4f5c\u9762\u79ef\u3002\u4f46\u662f\uff0c\u5728\u6c34\u5e73\u65b9\u5411\u548c\u5782\u76f4\u65b9\u5411\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u7136\u5f88\u53ef\u80fd\u6709\u5f88\u5927\u7684\u8bef\u5dee\u3002\u8fd9\u662f\u56e0\u4e3aGIoU\u635f\u5931\u4e2d\u7684\u60e9\u7f5a\u9879\u662f\u7528\u6765\u6700\u5c0f\u5316|C\u2212A\u222aB|\uff0c\u4f46\u662fC\u2212A\u222aB\u7684\u9762\u79ef\u901a\u5e38\u5f88\u5c0f\u6216\u4e3a0\uff08\u5f53\u4e24\u4e2a\u76d2\u5b50\u6709\u5305\u542b\u5173\u7cfb\u65f6\uff09\uff0c\u7136\u540eGIoU\u51e0\u4e4e\u9000\u5316\u4e3aIoU\u635f\u5931\u3002\u53ea\u8981\u4ee5\u9002\u5f53\u7684\u5b66\u4e60\u901f\u7387\u8fd0\u884c\u8db3\u591f\u7684\u8fed\u4ee3GIoU \u635f\u5931\u80fd\u6536\u655b\u5230\u5f88\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u6536\u655b\u901f\u5ea6\u5374\u662f\u975e\u5e38\u6162\u3002\u4ece\u51e0\u4f55\u4e0a\u6765\u8bf4\uff0c\u4ece\u5982\u56fe1\u6240\u793a\u7684\u56de\u5f52\u6b65\u9aa4\u6765\u770b\uff0cGIoU\u5b9e\u9645\u4e0a\u589e\u5927\u4e86\u9884\u6d4b\u7684\u6846\u5927\u5c0f\uff0c\u7528\u6765\u548c\u76ee\u6807\u6846\u91cd\u53e0\uff0c\u7136\u540eIoU\u9879\u7528\u4e8e\u9884\u6d4b\u6846\u4e0e\u76ee\u6807\u6846\u5339\u914d\uff0c\u4ea7\u751f\u975e\u5e38\u7f13\u6162\u7684\u6536\u655b\u3002 \u7efc\u4e0a\u6240\u8ff0\uff0c\u5728\u975e\u91cd\u53e0\u60c5\u51b5\u4e0b\uff0cIoU\u635f\u5931\u6536\u655b\u662f\u7cdf\u7cd5\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u800cGIoU\u635f\u5931\u6536\u655b\u901f\u5ea6\u8f83\u6162\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u6846\u3002\u5728\u76ee\u6807\u68c0\u6d4b\u6d41\u7a0b\u4e2d\uff0cIoU\u548cGIoU\u7684\u635f\u5931\u90fd\u4e0d\u80fd\u4fdd\u8bc1\u56de\u5f52\u7684\u51c6\u786e\u6027\u3002","title":"IoU \u548c GIoU \u635f\u5931\u7684\u9650\u5236"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#diou-ciou","text":"\u901a\u8fc7\u524d\u9762\u7684IoU\u548cGIoU\u7684\u5206\u6790\u6211\u4eec\u5f88\u81ea\u7136\u4f1a\u95ee\u4ee5\u4e0b\u95ee\u9898\uff1a \u7b2c\u4e00\uff0c\u662f\u5426\u53ef\u4ee5\u76f4\u63a5\u6700\u5c0f\u5316\u9884\u6d4b\u6846\u548c\u76ee\u6807\u6846\u4e4b\u95f4\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\uff1f \u7b2c\u4e8c\uff0c\u5f53\u4e0e\u76ee\u6807\u6846\u6709\u91cd\u53e0\u751a\u81f3\u5305\u542b\u65f6\uff0c\u5982\u4f55\u4f7f\u56de\u5f52\u66f4\u51c6\u786e\u3001\u66f4\u5feb\uff1f","title":"DIoU &amp; CIoU"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#diou-loss","text":"Distance-IoU \u635f\u5931\uff1a\u66f4\u5feb\u66f4\u597d\u7684\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931,\u4e00\u822c\u6765\u8bf4, \\(IoU-based\\) \u635f\u5931\u53ef\u4ee5\u5b9a\u4e49\u4e3a \\(\\mathcal{L}=1-I o U+\\mathcal{R}\\left(B, B^{g t}\\right),\\) (5) \u5176\u4e2d \\(\\large\\mathcal{R}\\left(B, B^{g t}\\right)\\) \u662f \u9884\u6d4b\u6846 B \u548c\u76ee\u6807\u6846 \\(B^{g t}\\) \u7684\u60e9\u7f5a\u9879\u3002 \u901a\u8fc7\u8bbe\u8ba1\u9002\u5f53\u7684\u60e9\u7f5a\u9879, \u5728\u672c\u8282\u4e2d, \u6211\u4eec\u63d0\u51fa\u4e86 DIoU \u635f\u5931\u548cCIoU\u635f\u5931\u6765\u89e3\u7b54\u4e0a\u8ff0\u4e24\u4e2a\u95ee\u9898\u3002 \u4e3a\u4e86\u56de\u7b54\u7b2c\u4e00\u4e2a\u95ee\u9898, \u6211\u4eec\u63d0\u51fa\u5c06\u4e24\u4e2a\u8fb9\u754c\u6846\u7684\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u6807\u51c6\u5316\u8ddd\u79bb\u6700\u5c0f\u5316\uff0c\u60e9\u7f5a\u9879\u53ef\u4ee5\u5b9a\u4e49\u4e3a \\(\\large\\mathcal{R}_{D I o U}=\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}},\\) (6) \u5176\u4e2d \\(\\mathbf{b}\\) \u548c \\(\\mathbf{b}^{g t}\\) \u5206\u522b\u4ee3\u8868 B \u548c \\(B^{g t}\\) \u7684\u4e2d\u5fc3\u70b9\u3002 \\(\\rho(\\cdot)\\) \u4e3a\u6b27\u6c0f\u8ddd\u79bb, \\(\\mathrm{C}\\) \u662f\u8986\u76d6\u4e24\u4e2a\u76d2\u6846\u7684\u6700\u5c0f\u5c01\u95ed\u6846\u7684\u5bf9\u89d2\u7ebf\u957f\u5ea6\u3002 \\(DIoU\\) \u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a: \\(\\large\\mathcal{L}_{D I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}} .\\) (7) \u5982\u56fe5\u6240\u793a, \\(DIoU\\) \u635f\u5931\u7684\u60e9\u7f5a\u9879\u76f4\u63a5\u4f7f\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u6700\u5c0f\u5316, \u800c \\(\\mathrm{GIoU}\\) \u635f\u5931\u7684\u76ee\u7684\u662f\u51cf\u5c11 \\(C-B \\cup B^{g t}\\) \u7684\u9762\u79ef\u3002","title":"DIoU loss"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#diou-iougiou","text":"\u65b0\u63d0\u51fa\u7684DIoU\u635f\u5931\u7ee7\u627fIoU\u548cGIoU\u635f\u5931\u7684\u4e00\u4e9b\u5c5e\u6027 DIoU\u635f\u5931\u5bf9\u56de\u5f52\u95ee\u9898\u7684\u5c3a\u5ea6\u4ecd\u7136\u662f\u4e0d\u53d8\u7684 \u4e0eGIoU\u635f\u5931\u7c7b\u4f3c, DIoU\u635f\u5931\u53ef\u4ee5\u5728\u4e0e\u76ee\u6807\u6846\u4e0d\u91cd\u53e0\u65f6\u4e3a\u8fb9\u754c\u6846\u63d0\u4f9b\u79fb\u52a8\u65b9\u5411\u3002 \u5f53\u4e24\u4e2a\u8fb9\u754c\u6846\u5b8c\u7f8e\u5339\u914d\u65f6, \\(\\mathcal{L}_{I o U}=\\mathcal{L}_{G I o U}=\\mathcal{L}_{D I o U}=0 .\\) \u5f53\u4e24\u4e2a\u6846\u90fd\u5f88\u8fdc\u65f6, \\(\\mathcal{L}_{G I o U}=\\mathcal{L}_{D I o U} \\rightarrow 2 .\\) DIoU\u635f\u5931\u6bd4IoU\u635f\u5931\u548cGIoU\u635f\u5931\u6709\u51e0\u4e2a\u4f18\u70b9, \u53ef\u4ee5\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u8fdb\u884c\u8bc4\u4f30\u3002 1. \u5982\u56fe1\u548c\u56fe3\u6240\u793a, \\(DIoU\u635f\u5931\\) \u53ef\u4ee5\u76f4\u63a5\u6700\u5c0f\u5316\u4e24\u4e2a\u6846\u7684\u8ddd\u79bb, \u56e0\u6b64\u6536\u655b\u901f\u5ea6\u6bd4 \\(GIoU\u635f\u5931\\) \u8981\u5feb\u5f97\u591a\u3002 2. \u5bf9\u4e8e\u4e24\u4e2a\u6846\u662f\u5305\u542b\u5173\u7cfb\u7684\u60c5\u51b5(\u56fe2), \u6216\u5728\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u60c5\u51b5(\u56fe6)\u4e0b, \\(DIoU\u635f\u77e2\\) \u53ef\u4ee5\u56de\u5f52\u975e\u5e38\u5feb, \u800c \\(\\mathrm{GIoU}\\) \u635f\u5931\u51e0\u4e4e\u9000\u5316\u4e3a \\(\\mathrm{IoU}\u635f\u5931\\) , \u5373 \\(|C-A \\cup B| \\rightarrow 0 .\\)","title":"DIoU \u548c IoU/GIoU \u635f\u5931\u6bd4\u8f83"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#complete-iou-loss","text":"\u63a5\u7740\u6211\u4eec\u56de\u7b54\u4e86\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u8fb9\u754c\u6846\u56de\u5f52\u7684\u826f\u597d \u635f\u5931\u5e94\u8be5\u8981\u8003\u8651\u4e09\u4e2a\u91cd\u8981\u7684\u51e0\u4f55\u56e0\u7d20, \u5373 \u91cd\u53e0\u9762\u79ef\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u548c\u957f\u5bbd\u6bd4 \u3002\u901a\u8fc7\u7edf\u4e00\u5750\u6807, \\(IoU\u635f\u5931\\) \u8003\u8651\u4e86\u91cd\u53e0\u533a\u57df, \u800c \\(GIoU\u635f\u5931\\) \u4e25\u91cd\u4f9d\u8d56\u4e8e \\(IoU\u635f\u5931\\) \u3002\u6211\u4eec\u63d0\u51fa\u7684 \\(DIoU\u635f\u5931\\) \u65e8\u5728\u540c\u65f6\u8003\u8651\u8fb9\u754c\u6846\u7684\u91cd\u53e0\u9762\u79ef\u548c\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u3002\u7136\u800c, \u8fb9\u754c\u6846\u7684\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u4e5f\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u51e0\u4f55\u56e0\u7d20\u3002 \u56e0\u6b64\uff0c\u57fa\u4e8e \\(DIoU\u635f\u5931\\) \uff0c\u901a\u8fc7\u6dfb\u52a0\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u6765 \u63d0\u51fa \\(CIoU\u635f\u5931\\) : \\(\\large\\mathcal{R}_{C I o U}=\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v,\\) (8) \u5176\u4e2d \\(\\alpha\\) \u662f\u4e00\u4e2a\u6b63\u7684\u6743\u8861\u53c2\u6570, \\(v\\) \u8861\u91cf\u957f\u5bbd\u6bd4\u7684\u4e00\u81f4\u6027\u3002 \\(\\large{v=\\frac{4}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right)^{2} .}\\) (9) \u5219\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a: \\(\\large\\mathcal{L}_{C I o U}=1-I o U+\\frac{\\rho^{2}\\left(\\mathbf{b}, \\mathbf{b}^{g t}\\right)}{c^{2}}+\\alpha v\\) (10) \\(\\large\\alpha=\\frac{v}{(1-I o U)+v}\\) (11) \u901a\u8fc7\u91cd\u53e0\u9762\u79ef\u56e0\u5b50\u7ed9\u4e88\u66f4\u9ad8\u7684\u4f18\u5148\u56de\u5f52, \u7279\u522b\u662f\u5bf9\u4e8e\u975e\u91cd\u53e0\u60c5\u51b5\u3002 \u6700\u7ec8, \\(CIoU\u635f\u5931\\) \u7684\u4f18\u5316\u4e0e \\(DIoU\u635f\u5931\\) \u7684\u4f18\u5316\u76f8\u540c, \u9664 \u4e86 \\(v w.r.t. w\\) \u7684\u68af\u5ea6\u5e94\u8be5\u6307\u5b9a \\(\\mathrm{w}\\) \u548c \\(h\\) \u3002 \\(\\large\\begin{array}{l} \\frac{\\partial v}{\\partial w}=\\frac{8}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right) \\times \\frac{h}{w^{2}+h^{2}}, \\\\ \\frac{\\partial v}{\\partial h}=-\\frac{8}{\\pi^{2}}\\left(\\arctan \\frac{w^{g t}}{h^{g t}}-\\arctan \\frac{w}{h}\\right) \\times \\frac{w}{w^{2}+h^{2}} . \\end{array}\\) (12) \u4e3b\u5bfc\u5668 \\(w^{2}+h^{2}\\) \u901a\u5e38\u662f\u4e00\u4e2a\u5f88\u5c0f\u7684\u503c\u5bf9\u4e8e \\(h\\) \u548c \\(w\\) \u7684\u8303 \u56f4\u5728 [0,1] , \u8fd9\u5f88\u53ef\u80fd\u4f1a\u4ea7\u751f\u68af\u5ea6\u7206\u70b8\u3002\u56e0\u6b64\u5728\u6211\u4eec\u7684\u5b9e\u73b0, \u4e3b\u5bfc\u5668 \\(w^{2}+h^{2}\\) \u88ab\u79fb\u9664, \u5c06\u6b65\u957f \\(\\frac{1} {w^{2}+h^{2}}\\) \u66ff\u6362\u4e3a \\(1\\) , \u68af\u5ea6\u65b9\u5411\u4ecd\u7136\u4e0e\u516c\u5f0f(12)\u4e00\u81f4\u3002","title":"Complete IoU Loss"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#nmsnon-maximum-suppression","text":"","title":"NMS(Non-Maximum Suppression)"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_4","text":"NMS\u662f\u5927\u591a\u6570\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u6700\u540e\u4e00\u6b65\uff0c\u5176\u4e2d\u5220\u9664\u4e86\u5197\u4f59\u7684\u68c0\u6d4b\u6846\u5f53\u5b83\u4e0e\u6700\u9ad8\u5206\u6846\u7684\u91cd\u53e0\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c\u3002 Soft-NMS (Bodla et al. 2017) \u7528\u8fde\u7eed\u51fd\u6570w.r.t.\u60e9\u7f5a\u76f8\u90bb\u6846\u7684\u68c0\u6d4b\u5206\u6570IoU\uff0c\u4ea7\u751f\u6bd4\u539f\u59cbNMS\u4ea7\u751f\u66f4\u67d4\u548c\u5927\u548c\u66f4\u5f3a\u5927\u7684\u6291\u5236\u3002IoU-Net (Jiang et al. 2018) \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u7f51\u7edc\u5206\u652f\u6765\u9884\u6d4b\u5b9a\u4f4d\u7f6e\u4fe1\u5ea6\u6765\u6307\u5bfcNMS\u3002\u6700\u8fd1\uff0c\u81ea\u9002\u5e94NMS\uff08Liu\uff0cHuang\uff0c\u548cWang 2019\uff09\u548cSofter-NMS\uff08He et al. 2019\uff09\u88ab\u63d0\u51fa\u5206\u522b\u7814\u7a76\u9002\u5f53\u7684\u9608\u503c\u7b56\u7565\u548c\u52a0\u6743\u5e73\u5747\u7b56\u7565\u3002 \u5728\u672c\u5de5\u4f5c\u4e2d\uff0c\u7b80\u5355\u5c06DIoU\u4f5c\u4e3a\u539f\u59cbNMS\u7684\u6807\u51c6, \u5728\u6291\u5236\u5197\u4f59\u6846\u65f6\uff0c\u540c\u65f6\u8003\u8651\u8fb9\u754c\u6846\u7684\u91cd\u53e0\u9762\u79ef\u548c\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002","title":"\u4ecb\u7ecd"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#diou-nms","text":"Non-Maximum Suppression using DIoU \u5728\u539f\u59cb\u7684NMS\u4e2d, IoU\u6307\u6807\u7528\u4e8e\u6291\u5236\u5415\u4f59\u7684\u68c0\u6d4b\u6846, \u5176 \u4e2d\u91cd\u53e0\u533a\u57df\u662f\u552f\u4e00\u7684\u56e0\u7d20, \u5bf9\u4e8e\u6709\u906e\u6321\u7684\u60c5\u51b5\uff0c\u5f80\u5f80\u4f1a \u4ea7\u751f\u9519\u8bef\u7684\u6291\u5236\u3002 \u6211\u4eec\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\u5efa\u8bae \\(DIoU\\) \u662f \\(NMS\\) \u7684\u66f4\u597d\u6807\u51c6\uff0c\u56e0\u4e3a\u5728\u6291\u5236\u6807\u51c6\u4e2d\u4e0d\u4ec5\u5e94\u8003\u8651\u91cd\u53e0 \\(DIoU-NMS\\) \u88ab\u6b63\u5f0f\u5b9a\u4e49\u4e3a: \\(s_{i}=\\left\\{\\begin{array}{l} s_{i}, I o U-\\mathcal{R}_{D I o U}\\left(\\mathcal{M}, B_{i}\\right)<\\varepsilon, \\\\ 0, \\quad I o U-\\mathcal{R}_{D I o U}\\left(\\mathcal{M}, B_{i}\\right) \\geq \\varepsilon, \\end{array}\\right.\\) (13) \u5176\u4e2d\u6846 \\(B_{i}\\) \u88ab\u53bb\u9664\u901a\u8fc7\u540c\u65f6\u5230\u8003\u8651 \\(IoU\\) \u548c\u4e24\u4e2a\u6846\u4e2d\u5fc3\u70b9 \u7684\u8ddd\u79bb\u3002 \\(s_{i}\\) \u662f\u5206\u7c7b\u5f97\u5206\u548c \\(\\varepsilon\\) \u662f \\(NMS\\) \u9608\u503c\u3002\u6211\u4eec\u8ba4\u4e3a\u4e24 \u4e2a\u4e2d\u5fc3\u70b9\u8f83\u8fdc\u7684\u6846\u53ef\u80fd\u4f1a\u5b9a\u4f4d\u4e0d\u540c\u7684\u7269\u4f53, \u800c\u4e0d\u5e94\u8be5\u88ab \u5220\u9664\u3002\u6b64\u5916 \\(DIoU-NMS\\) \u662f\u975e\u5e38\u7075\u6d3b, \u4ec5\u4ec5\u662f\u51e0\u884c\u7684\u4ee3\u7801\u5c31\u53ef\u4ee5\u96c6\u6210\u5230\u4efb\u4f55\u76ee\u6807\u68c0\u6d4b\u7ba1\u9053\u4e2d\u3002","title":"DioU-NMS"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_5","text":"\u5728\u672c\u6587\u4e2d\uff0c\u4e3b\u8981\u7684\u4ecb\u7ecd\u7528\u4e8e\u8fb9\u754c\u6846\u56de\u5f52\u7684 \\(DIoU\u635f\u5931\\) \u548c \\(CIoU \u635f\u5931\\) \u548c \u7528\u4e8e\u6291\u5236\u5197\u4f59\u68c0\u6d4b\u6846\u7684 \\(DIoU-NMS\u3002\\) \u901a\u8fc7\u76f4\u63a5\u6700\u5c0f\u5316\u4e24\u4e2a\u4e2d\u5fc3\u70b9\u7684\u5f52\u4e00\u5316\u7684\u8ddd\u79bb\uff0c \\(DIoU \u635f\u5931\\) \u53ef\u4ee5\u6bd4 \\(GIoU \u635f\u5931\\) \u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u3002 \u6b64\u5916 \\(CIoU\u635f\u5931\\) \u8003\u8651\u4e86\u4e09\u4e2a\u51e0\u4f55\u5c5e\u6027(\u5373 \u91cd\u53e0\u533a\u57df\u3001\u4e2d\u5fc3\u70b9\u8ddd\u79bb \u548c \u957f\u5bbd\u6bd4),\u4fc3\u8fdb\u4e86 \u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u4f18\u7684\u6027\u80fd\u3002","title":"\u5c0f\u7ed3"},{"location":"tutorials/05_chapter/iou_in-depth_analysis.html#_6","text":"https://github.com/Zzh-tju/DIoU/blob/master/README.md#introduction https://github.com/Zzh-tju/DIoU/blob/master/README.md#introduction IoU: https://arxiv.org/pdf/1608.01471.pdf GIoU: https://giou.stanford.edu/GIoU.pdf DIoU: https://arxiv.org/pdf/1911.08287.pdf","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/05_chapter/map_analysis.html","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6307\u6807\u8bc4\u4f30(\u91cd\u8981\u7684\u4e00\u4e9b\u5b9a\u4e49) \ud83d\udcda IOU \\(IOU\\) ( Intersection Over Union ) \u57fa\u4e8e Jaccard \u7d22\u5f15\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e24\u4e2a\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u91cd\u53e0\u7a0b\u5ea6\u3002\u5b83\u9700\u8981\u4e00\u4e2a\u771f\u5b9e\u56de\u5f52\u6846 (a ground truth bounding box) \\(B_{gt}\\) \u548c\u4e00\u4e2a\u9884\u6d4b\u56de\u5f52\u6846(a predicted bounding box) \\(B_{p}\\) \u8ba1\u7b97\u5f97\u5230\u3002\u901a\u8fc7\u5e94\u7528 IOU \u6211\u4eec\u80fd\u591f\u5224\u65ad\u51fa\u9884\u6d4b\u7ed3\u679c\u662f\u6709\u6548(True Positive) \u6216\u8005 \u65e0\u6548(False Positive) \\(IOU\\) \u4e5f\u79f0\u91cd\u53e0\u5ea6 \u8868\u793a\u8ba1\u7b97\u9884\u6d4b\u56de\u5f52\u6846\u548c\u771f\u5b9e\u56de\u5f52\u6846\u7684\u4ea4\u5e76\u6bd4,\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b: \\(\\large{IOU=\\dfrac{area\\left( B_p\\cap B_{g t}\\right) }{area\\left( B_p\\cup B_{g t}\\right) } }\\) \u5176\u4e2d: \\(B_p:\u9884\u6d4b\u56de\u5f52\u6846\\) \uff0c \\(B_{g t}:\u771f\u5b9e\u56de\u5f52\u6846\\) \u4e0b\u56fe\u53ef\u89c6\u5316\u4e86\u771f\u5b9e\u56de\u5f52\u6846\uff08\u7eff\u8272\uff09\u548c \u9884\u6d4b\u56de\u5f52\u6846\uff08\u7ea2\u8272\uff09\u4e4b\u95f4\u7684IOU\u3002 \u56fe1.1 ; \\(IOU\\) \u7684\u8ba1\u7b97\u3002\u7eff\u8272: \\(B_{g t}\\) \uff0c \u7ea2\u8272: \\(B_{p}\\) TP&FP&FN&TN Positive Negative True TP TN False FP FN \u6307\u6807\u7684\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\uff1a TP\uff08True Postives\uff09\uff1a \u5206\u7c7b\u5668\u628a\u6b63\u4f8b\u6b63\u786e\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u6b63\u4f8b\u3002(IOU >= \u9608\u503c ) FN\uff08False Negatives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u6b63\u4f8b\u9519\u8bef\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u8d1f\u4f8b\u3002(IOU < \u9608\u503c ) FP\uff08False Postives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u8d1f\u4f8b\u9519\u8bef\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u6b63\u4f8b TN\uff08True Negatives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u8d1f\u4f8b\u6b63\u786e\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u8d1f\u4f8b\uff08 yolov5\u4e2d\u6ca1\u6709\u5e94\u7528\u5230 \uff09 yolov5\u4e2d\u6ca1\u6709\u5e94\u7528TN\u7684\u539f\u56e0: TN\u4ee3\u8868\u7684\u662f\u6240\u6709\u53ef\u80fd\u7684\u672a\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\u3002\u7136\u800c\u5728yolo\u5728\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u6bcf\u4e2a\u7f51\u683c\u4f1a\u751f\u6210\u5f88\u591a\u7684\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u6709\u8bb8\u591a\u7684\u9884\u6d4b\u8fb9\u754c\u6846\u662f\u6ca1\u6709\u76f8\u5e94\u7684\u771f\u5b9e\u6807\u7b7e\u6846\uff0c\u5bfc\u81f4\u672a\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\u6570\u91cf\u8fdc\u8fdc\u5927\u4e8e\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\uff0c\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u4e0d\u4f7f\u7528TN\u7684\u539f\u56e0\u3002 threshold: depending on the metric, it is usually set to 50%, 75% or 95%. Precision Precision \u5b9a\u4e49\uff1a\u6a21\u578b\u8bc6\u522b\u76f8\u5173\u76ee\u6807\u7684\u80fd\u529b\u3002\u5206\u7c7b\u6b63\u786e\u7684\u6837\u672c\u5728\u6240\u6709\u6837\u672c\u4e2d\u7684\u6570\u91cf\u6bd4\u4f8b\uff0c\u516c\u5f0f\u5982\u4e0b: \\(Precision =\\dfrac{TP}{TP+FP}=\\dfrac{TP}{all \\ detections}\\) Recall Recall \u5b9a\u4e49\uff1a\u662f\u6a21\u578b\u627e\u5230\u771f\u5b9e\u56de\u5f52\u6846( \u5373\u6807\u7b7e\u6807\u6ce8\u7684\u6846 )\u7684\u80fd\u529b\u3002\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a \\(Recall = \\dfrac{TP}{TP+FN}=\\dfrac{TP}{all \\ ground \\ truths}\\) mAP \u591a\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u56fe\u7247\u7684\u6807\u7b7e\u4e0d\u6b62\u4e00\u4e2a\uff0c\u56e0\u6b64\u8bc4\u4ef7\u4e0d\u80fd\u7528\u666e\u901a\u5355\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\u7684\u6807\u51c6\uff0c\u5373mean accuracy\uff0c\u8be5\u4efb\u52a1\u91c7\u7528\u7684\u662f\u548c\u4fe1\u606f\u68c0\u7d22\u4e2d\u7c7b\u4f3c\u7684\u65b9\u6cd5\u2014mAP\uff0c\u867d\u7136\u5176\u5b57\u9762\u610f\u601d\u548cmean average precision\u770b\u8d77\u6765\u5dee\u4e0d\u591a\uff0c\u4f46\u662f\u8ba1\u7b97\u65b9\u6cd5\u8981\u7e41\u7410\u5f97\u591a,mAP \u4f1a\u7edf\u8ba1\u6240\u6709 Confidence \u503c\u4e0b\u7684 PR\u503c\uff0c\u800c\u5b9e\u9645\u4f7f\u7528\u65f6\uff0c \u4f1a\u8bbe\u5b9a\u4e00\u4e2a Confidence \u9608\u503c\uff0c\u4f4e\u4e8e\u8be5\u9608\u503c\u7684\u76ee\u6807\u4f1a\u88ab\u4e22\u5f03\uff0c\u8fd9\u90e8\u5206\u76ee\u6807\u5728\u7edf\u8ba1 mAP \u65f6\u4e5f\u4f1a\u6709\u4e00\u5b9a\u7684\u8d21\u732e \u3002 Confidence (\u7f6e\u4fe1\u5ea6):\u5728\u7edf\u8ba1\u5b66\u4e2d\uff0c\u4e00\u4e2a\u6982\u7387\u6837\u672c\u7684\u7f6e\u4fe1\u533a\u95f4\uff08Confidence interval\uff09\u662f\u5bf9\u8fd9\u4e2a\u6837\u672c\u7684\u67d0\u4e2a\u603b\u4f53\u53c2\u6570\u7684\u533a\u95f4\u4f30\u8ba1\u3002\u7f6e\u4fe1\u533a\u95f4\u5c55\u73b0\u7684\u662f\u8fd9\u4e2a\u53c2\u6570\u7684\u771f\u5b9e\u503c\u6709\u4e00\u5b9a\u6982\u7387\u843d\u5728\u6d4b\u91cf\u7ed3\u679c\u7684\u5468\u56f4\u7684\u7a0b\u5ea6\u3002\u7f6e\u4fe1\u533a\u95f4\u7ed9\u51fa\u7684\u662f\u88ab\u6d4b\u91cf\u53c2\u6570\u6d4b\u91cf\u503c\u7684\u53ef\u4fe1\u7a0b\u5ea6\u8303\u56f4\uff0c\u5373\u524d\u9762\u6240\u8981\u6c42\u7684\u201c\u4e00\u5b9a\u6982\u7387\u201d\u3002\u8fd9\u4e2a\u6982\u7387\u4e5f\u88ab\u79f0\u4e3a\u7f6e\u4fe1\u6c34\u5e73\u3002 (\u7ea2\u8272\u66f2\u7ebf\u4ee3\u8868,\u4eba\u4e3a\u7684\u65b9\u5f0f\u5c06PR\u66f2\u7ebf\u53d8\u6210\u5355\u8c03\u9012\u51cf\uff0c\u4f7f\u5f97\u8ba1\u7b97\u9762\u79ef\u66f4\u5bb9\u6613\u3002) AP\uff08Average Percision\uff09\uff1aAP\u4e3a\u5e73\u5747\u7cbe\u5ea6\uff0c\u6307\u7684\u662f\u6240\u6709\u56fe\u7247\u5185\u7684\u5177\u4f53\u67d0\u4e00\u7c7b\u7684PR\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef(\u6a2a\u8f74\u4e3aRecall\uff0c\u7eb5\u8f74\u4e3aPrecision)\u3002 AP\u8861\u91cf\u7684\u662f\u5bf9\u4e00\u4e2a\u7c7b\u68c0\u6d4b\u597d\u574f\uff0cmAP\u5c31\u662f\u5bf9\u591a\u4e2a\u7c7b\u7684\u68c0\u6d4b\u597d\u574f\u3002\u5728\u591a\u7c7b\u591a\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u8ba1\u7b97\u51fa\u6bcf\u4e2a\u7c7b\u522b\u7684AP\u540e\uff0c\u518d\u9664\u4e8e\u7c7b\u522b\u603b\u6570\uff0c\u5373\u6240\u6709\u7c7b\u522bAP\u7684\u5e73\u5747\u503c\uff0c\u6bd4\u5982\u6709\u4e24\u7c7b\uff0c\u7c7bA\u7684AP\u503c\u662f0.5\uff0c\u7c7bB\u7684AP\u503c\u662f0.2\uff0c\u90a3\u4e48 \\(mAP\\) =\uff080.5+0.2\uff09/2=0.35\u3002 MAP: \u662f\u6307\u6240\u6709\u56fe\u7247\u5185\u7684\u6240\u6709\u7c7b\u522b\u7684AP\u7684\u5e73\u5747\u503c ,map\u8d8a\u9ad8\u4ee3\u8868\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u503c\u8d8a\u9ad8\u3002 \\(mAP@0.5\\) \uff1a \\(mAP\\) \u662f\u7528 \\(Precision\\) \u548c \\(Recall\\) \u4f5c\u4e3a\u4e24\u8f74\u4f5c\u56fe\u540e\u56f4\u6210\u7684\u9762\u79ef\uff0c \\(m\\) \u8868\u793a\u5e73\u5747\uff0c@\u540e\u9762\u7684\u6570\u8868\u793a\u5224\u5b9a\u6b63\u8d1f\u6837\u672c\u7684 \\(IOU\\) \u9608\u503c\uff0c\u5176\u4e2d @0.5\u8868\u793aIOU\u9608\u503c\u53d60.5\u3002 \\(mAP@0.5:0.95\\) \uff1a\u53ea\u4ee5 \\(IOU=0.5\\) \u7684\u9600\u503c\u7684\u65f6\u5019\u4e0d\u4e00\u5b9a\u5c31\u662f\u597d\u7684\u6a21\u578b\uff0c\u53ef\u80fd\u4ec5\u4ec5\u57280.5\u9600\u503c\u8868\u73b0\u7684\u5f88\u597d\uff0c\u57280.6,0.7...\u9600\u503c\u8868\u73b0\u7684\u5f88\u5dee\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u8bc4\u4f30\u6574\u4f53\u6a21\u578b\u7684\u51c6\u786e\u5ea6\uff0c\u56e0\u6b64\u8ba1\u7b97\u4e00\u4e2a\u6a21\u578b\u5728\u5404\u4e2aIOU\u503c\u7684AP(mAP)\u53d6\u5e73\u5747\u503c\u3002 \u65b9\u6cd5\u662f\uff1a\u8ba1\u7b97\u6bcf\u4e2a\u5206\u7c7b\u7684AP\uff0c\u6c42\u548c\u518d\u5e73\u5747\uff0c\u5f97\u5230\u7684\u5c31\u662fmAP,\u5b83\u662f\u76f4\u63a5\u628amAP\u5f53\u6210AP\uff0c\u7136\u540e\u518d\u628aIOU\u503c\u5927\u4e8e0.5\u7684 \\(AP(mAP)\\) \uff0c\u4ee50.05\u7684\u589e\u91cf,\u52300.95\uff0c\u4e5f\u5c31\u662f\u4ee5 \\((0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)\\) \\(IOU\u503c\\) \u7684 \\(AP(mAP)\\) \u7684\u5e73\u5747\u503c\u5f53\u6210 \\(AP(at IoU=.50:.05:.95)\\) \uff0c\u901a\u8fc7 \\(IOU\u589e\u91cf\\) \u7684\u65b9\u5f0f\u5f97\u5230 \\(mAP@0.5:0.95\\) \u7ed3\u679c\u3002 \u76ee\u6807\u68c0\u6d4b\u4e2d\u7684mAP\u8ba1\u7b97 yolov5\u8ba1\u7b97IOU\u6e90\u7801\u89e3\u6790 \u6e90\u4ee3\u7801\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L224-L261 # \u8ba1\u7b97\u4e24\u6846\u7684\u7279\u5b9aiou (DIou, DIou, CIou) def bbox_iou ( box1 , box2 , xywh = True , GIoU = False , DIoU = False , CIoU = False , eps = 1e-7 ): # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4) # Get the coordinates of bounding boxes \u4e0b\u9762\u6761\u4ef6\u8bed\u53e5\u4f5c\u7528\u662f:\u8fdb\u884c\u5750\u6807\u8f6c\u6362\u4ece\u800c\u83b7\u53d6yolo\u683c\u5f0f\u8fb9\u754c\u6846\u7684\u5750\u6807 if xywh : # transform from xywh to xyxy ( x1 , y1 , w1 , h1 ), ( x2 , y2 , w2 , h2 ) = box1 . chunk ( 4 , 1 ), box2 . chunk ( 4 , 1 ) w1_ , h1_ , w2_ , h2_ = w1 / 2 , h1 / 2 , w2 / 2 , h2 / 2 b1_x1 , b1_x2 , b1_y1 , b1_y2 = x1 - w1_ , x1 + w1_ , y1 - h1_ , y1 + h1_ b2_x1 , b2_x2 , b2_y1 , b2_y2 = x2 - w2_ , x2 + w2_ , y2 - h2_ , y2 + h2_ else : # x1, y1, x2, y2 = box1 b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 . chunk ( 4 , 1 ) b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 . chunk ( 4 , 1 ) w1 , h1 = b1_x2 - b1_x1 , b1_y2 - b1_y1 w2 , h2 = b2_x2 - b2_x1 , b2_y2 - b2_y1 # Intersection area \u83b7\u53d6\u4e24\u4e2a\u6846\u76f8\u4ea4\u7684\u9762\u79ef\u3002 \"\"\" left_line = max(b1_x1, b2_x1) reft_line = min(b1_x2, b2_x2) top_line = max(b1_y1, b2_y1) bottom_line = min(b1_y2, b2_y2) intersect = (reight_line - left_line) * (bottom_line - top_line) \"\"\" inter = ( flow . min ( b1_x2 , b2_x2 ) - flow . max ( b1_x1 , b2_x1 )) . clamp ( 0 ) * \\ ( flow . min ( b1_y2 , b2_y2 ) - flow . max ( b1_y1 , b2_y1 )) . clamp ( 0 ) # Union Area \u4e24\u4e2a\u6846\u5e76\u5230\u9762\u79ef union = w1 * h1 + w2 * h2 - inter + eps # IoU iou = inter / union if CIoU or DIoU or GIoU : cw = flow . max ( b1_x2 , b2_x2 ) - flow . min ( b1_x1 , b2_x1 ) # convex (smallest enclosing box) width ch = flow . max ( b1_y2 , b2_y2 ) - flow . min ( b1_y1 , b2_y1 ) # convex height if CIoU or DIoU : # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1 c2 = cw ** 2 + ch ** 2 + eps # convex diagonal squared rho2 = (( b2_x1 + b2_x2 - b1_x1 - b1_x2 ) ** 2 + ( b2_y1 + b2_y2 - b1_y1 - b1_y2 ) ** 2 ) / 4 # center dist ** 2 if CIoU : # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47 v = ( 4 / math . pi ** 2 ) * flow . pow ( flow . atan ( w2 / ( h2 + eps )) - flow . atan ( w1 / ( h1 + eps )), 2 ) with flow . no_grad (): alpha = v / ( v - iou + ( 1 + eps )) return iou - ( rho2 / c2 + v * alpha ) # CIoU return iou - rho2 / c2 # DIoU c_area = cw * ch + eps # convex area return iou - ( c_area - union ) / c_area # GIoU https://arxiv.org/pdf/1902.09630.pdf return iou # IoU yolov5\u8ba1\u7b97AP\u6e90\u7801\u9010\u884c\u89e3\u6790 \u6e90\u4ee3\u7801\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L96-L121 # \u6839\u636ePR\u66f2\u7ebf\u8ba1\u7b97AP def compute_ap ( recall , precision ): \"\"\" Compute the average precision, given the recall and precision curves # Arguments recall: The recall curve (list) precision: The precision curve (list) # Returns Average precision, precision curve, recall curve \"\"\" # Append sentinel values to beginning and end \u5c06\u5f00\u533a\u95f4\u7ed9\u8865\u4e0a\uff0c\u8865\u6210\u95ed\u5408\u7684\u533a\u95f4\u3002 mrec = np . concatenate (([ 0.0 ], recall , [ 1.0 ])) mpre = np . concatenate (([ 1.0 ], precision , [ 0.0 ])) # Compute the precision envelope \"\"\" \u4eba\u4e3a\u7684\u628aPR\u66f2\u7ebf\u53d8\u6210\u5355\u8c03\u9012\u51cf\u7684,\u4f8b\u5982: np.maximum(accumulate(np.array([21, 23, 18, 19, 20, 13, 12, 11]) ) => np.array([23, 23, 20, 20, 20, 13, 12, 11]) \"\"\" mpre = np . flip ( np . maximum . accumulate ( np . flip ( mpre ))) # Integrate area under curve method = 'interp' # methods: 'continuous', 'interp' if method == 'interp' : # \u9ed8\u8ba4\u91c7\u7528 interpolated-precision \u66f2\u7ebf\uff0c x = np . linspace ( 0 , 1 , 101 ) # 101-point interp (COCO) ap = np . trapz ( np . interp ( x , mrec , mpre ), x ) # integrate else : # 'continuous' i = np . where ( mrec [ 1 :] != mrec [: - 1 ])[ 0 ] # points where x axis (recall) changes ap = np . sum (( mrec [ i + 1 ] - mrec [ i ]) * mpre [ i + 1 ]) # area under curve return ap , mpre , mrec \u53c2\u8003\u6587\u7ae0 https://github.com/rafaelpadilla/Object-Detection-Metrics","title":"5.3 \u6a21\u578b\u7cbe\u786e\u5ea6\u8bc4\u4f30"},{"location":"tutorials/05_chapter/map_analysis.html#_1","text":"","title":"\u6307\u6807\u8bc4\u4f30(\u91cd\u8981\u7684\u4e00\u4e9b\u5b9a\u4e49)"},{"location":"tutorials/05_chapter/map_analysis.html#iou","text":"\\(IOU\\) ( Intersection Over Union ) \u57fa\u4e8e Jaccard \u7d22\u5f15\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e24\u4e2a\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u91cd\u53e0\u7a0b\u5ea6\u3002\u5b83\u9700\u8981\u4e00\u4e2a\u771f\u5b9e\u56de\u5f52\u6846 (a ground truth bounding box) \\(B_{gt}\\) \u548c\u4e00\u4e2a\u9884\u6d4b\u56de\u5f52\u6846(a predicted bounding box) \\(B_{p}\\) \u8ba1\u7b97\u5f97\u5230\u3002\u901a\u8fc7\u5e94\u7528 IOU \u6211\u4eec\u80fd\u591f\u5224\u65ad\u51fa\u9884\u6d4b\u7ed3\u679c\u662f\u6709\u6548(True Positive) \u6216\u8005 \u65e0\u6548(False Positive) \\(IOU\\) \u4e5f\u79f0\u91cd\u53e0\u5ea6 \u8868\u793a\u8ba1\u7b97\u9884\u6d4b\u56de\u5f52\u6846\u548c\u771f\u5b9e\u56de\u5f52\u6846\u7684\u4ea4\u5e76\u6bd4,\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b: \\(\\large{IOU=\\dfrac{area\\left( B_p\\cap B_{g t}\\right) }{area\\left( B_p\\cup B_{g t}\\right) } }\\) \u5176\u4e2d: \\(B_p:\u9884\u6d4b\u56de\u5f52\u6846\\) \uff0c \\(B_{g t}:\u771f\u5b9e\u56de\u5f52\u6846\\) \u4e0b\u56fe\u53ef\u89c6\u5316\u4e86\u771f\u5b9e\u56de\u5f52\u6846\uff08\u7eff\u8272\uff09\u548c \u9884\u6d4b\u56de\u5f52\u6846\uff08\u7ea2\u8272\uff09\u4e4b\u95f4\u7684IOU\u3002 \u56fe1.1 ; \\(IOU\\) \u7684\u8ba1\u7b97\u3002\u7eff\u8272: \\(B_{g t}\\) \uff0c \u7ea2\u8272: \\(B_{p}\\)","title":"\ud83d\udcda IOU"},{"location":"tutorials/05_chapter/map_analysis.html#tpfpfntn","text":"Positive Negative True TP TN False FP FN \u6307\u6807\u7684\u4e00\u4e9b\u57fa\u672c\u6982\u5ff5\uff1a TP\uff08True Postives\uff09\uff1a \u5206\u7c7b\u5668\u628a\u6b63\u4f8b\u6b63\u786e\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u6b63\u4f8b\u3002(IOU >= \u9608\u503c ) FN\uff08False Negatives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u6b63\u4f8b\u9519\u8bef\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u8d1f\u4f8b\u3002(IOU < \u9608\u503c ) FP\uff08False Postives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u8d1f\u4f8b\u9519\u8bef\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u6b63\u4f8b TN\uff08True Negatives\uff09\uff1a\u5206\u7c7b\u5668\u628a\u8d1f\u4f8b\u6b63\u786e\u7684\u5206\u7c7b-\u9884\u6d4b\u4e3a\u8d1f\u4f8b\uff08 yolov5\u4e2d\u6ca1\u6709\u5e94\u7528\u5230 \uff09 yolov5\u4e2d\u6ca1\u6709\u5e94\u7528TN\u7684\u539f\u56e0: TN\u4ee3\u8868\u7684\u662f\u6240\u6709\u53ef\u80fd\u7684\u672a\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\u3002\u7136\u800c\u5728yolo\u5728\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u6bcf\u4e2a\u7f51\u683c\u4f1a\u751f\u6210\u5f88\u591a\u7684\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u6709\u8bb8\u591a\u7684\u9884\u6d4b\u8fb9\u754c\u6846\u662f\u6ca1\u6709\u76f8\u5e94\u7684\u771f\u5b9e\u6807\u7b7e\u6846\uff0c\u5bfc\u81f4\u672a\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\u6570\u91cf\u8fdc\u8fdc\u5927\u4e8e\u6b63\u786e\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\uff0c\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u4e0d\u4f7f\u7528TN\u7684\u539f\u56e0\u3002 threshold: depending on the metric, it is usually set to 50%, 75% or 95%.","title":"TP&amp;FP&amp;FN&amp;TN"},{"location":"tutorials/05_chapter/map_analysis.html#precision","text":"Precision \u5b9a\u4e49\uff1a\u6a21\u578b\u8bc6\u522b\u76f8\u5173\u76ee\u6807\u7684\u80fd\u529b\u3002\u5206\u7c7b\u6b63\u786e\u7684\u6837\u672c\u5728\u6240\u6709\u6837\u672c\u4e2d\u7684\u6570\u91cf\u6bd4\u4f8b\uff0c\u516c\u5f0f\u5982\u4e0b: \\(Precision =\\dfrac{TP}{TP+FP}=\\dfrac{TP}{all \\ detections}\\)","title":"Precision"},{"location":"tutorials/05_chapter/map_analysis.html#recall","text":"Recall \u5b9a\u4e49\uff1a\u662f\u6a21\u578b\u627e\u5230\u771f\u5b9e\u56de\u5f52\u6846( \u5373\u6807\u7b7e\u6807\u6ce8\u7684\u6846 )\u7684\u80fd\u529b\u3002\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a \\(Recall = \\dfrac{TP}{TP+FN}=\\dfrac{TP}{all \\ ground \\ truths}\\)","title":"Recall"},{"location":"tutorials/05_chapter/map_analysis.html#map","text":"\u591a\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u56fe\u7247\u7684\u6807\u7b7e\u4e0d\u6b62\u4e00\u4e2a\uff0c\u56e0\u6b64\u8bc4\u4ef7\u4e0d\u80fd\u7528\u666e\u901a\u5355\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\u7684\u6807\u51c6\uff0c\u5373mean accuracy\uff0c\u8be5\u4efb\u52a1\u91c7\u7528\u7684\u662f\u548c\u4fe1\u606f\u68c0\u7d22\u4e2d\u7c7b\u4f3c\u7684\u65b9\u6cd5\u2014mAP\uff0c\u867d\u7136\u5176\u5b57\u9762\u610f\u601d\u548cmean average precision\u770b\u8d77\u6765\u5dee\u4e0d\u591a\uff0c\u4f46\u662f\u8ba1\u7b97\u65b9\u6cd5\u8981\u7e41\u7410\u5f97\u591a,mAP \u4f1a\u7edf\u8ba1\u6240\u6709 Confidence \u503c\u4e0b\u7684 PR\u503c\uff0c\u800c\u5b9e\u9645\u4f7f\u7528\u65f6\uff0c \u4f1a\u8bbe\u5b9a\u4e00\u4e2a Confidence \u9608\u503c\uff0c\u4f4e\u4e8e\u8be5\u9608\u503c\u7684\u76ee\u6807\u4f1a\u88ab\u4e22\u5f03\uff0c\u8fd9\u90e8\u5206\u76ee\u6807\u5728\u7edf\u8ba1 mAP \u65f6\u4e5f\u4f1a\u6709\u4e00\u5b9a\u7684\u8d21\u732e \u3002 Confidence (\u7f6e\u4fe1\u5ea6):\u5728\u7edf\u8ba1\u5b66\u4e2d\uff0c\u4e00\u4e2a\u6982\u7387\u6837\u672c\u7684\u7f6e\u4fe1\u533a\u95f4\uff08Confidence interval\uff09\u662f\u5bf9\u8fd9\u4e2a\u6837\u672c\u7684\u67d0\u4e2a\u603b\u4f53\u53c2\u6570\u7684\u533a\u95f4\u4f30\u8ba1\u3002\u7f6e\u4fe1\u533a\u95f4\u5c55\u73b0\u7684\u662f\u8fd9\u4e2a\u53c2\u6570\u7684\u771f\u5b9e\u503c\u6709\u4e00\u5b9a\u6982\u7387\u843d\u5728\u6d4b\u91cf\u7ed3\u679c\u7684\u5468\u56f4\u7684\u7a0b\u5ea6\u3002\u7f6e\u4fe1\u533a\u95f4\u7ed9\u51fa\u7684\u662f\u88ab\u6d4b\u91cf\u53c2\u6570\u6d4b\u91cf\u503c\u7684\u53ef\u4fe1\u7a0b\u5ea6\u8303\u56f4\uff0c\u5373\u524d\u9762\u6240\u8981\u6c42\u7684\u201c\u4e00\u5b9a\u6982\u7387\u201d\u3002\u8fd9\u4e2a\u6982\u7387\u4e5f\u88ab\u79f0\u4e3a\u7f6e\u4fe1\u6c34\u5e73\u3002 (\u7ea2\u8272\u66f2\u7ebf\u4ee3\u8868,\u4eba\u4e3a\u7684\u65b9\u5f0f\u5c06PR\u66f2\u7ebf\u53d8\u6210\u5355\u8c03\u9012\u51cf\uff0c\u4f7f\u5f97\u8ba1\u7b97\u9762\u79ef\u66f4\u5bb9\u6613\u3002) AP\uff08Average Percision\uff09\uff1aAP\u4e3a\u5e73\u5747\u7cbe\u5ea6\uff0c\u6307\u7684\u662f\u6240\u6709\u56fe\u7247\u5185\u7684\u5177\u4f53\u67d0\u4e00\u7c7b\u7684PR\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef(\u6a2a\u8f74\u4e3aRecall\uff0c\u7eb5\u8f74\u4e3aPrecision)\u3002 AP\u8861\u91cf\u7684\u662f\u5bf9\u4e00\u4e2a\u7c7b\u68c0\u6d4b\u597d\u574f\uff0cmAP\u5c31\u662f\u5bf9\u591a\u4e2a\u7c7b\u7684\u68c0\u6d4b\u597d\u574f\u3002\u5728\u591a\u7c7b\u591a\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u8ba1\u7b97\u51fa\u6bcf\u4e2a\u7c7b\u522b\u7684AP\u540e\uff0c\u518d\u9664\u4e8e\u7c7b\u522b\u603b\u6570\uff0c\u5373\u6240\u6709\u7c7b\u522bAP\u7684\u5e73\u5747\u503c\uff0c\u6bd4\u5982\u6709\u4e24\u7c7b\uff0c\u7c7bA\u7684AP\u503c\u662f0.5\uff0c\u7c7bB\u7684AP\u503c\u662f0.2\uff0c\u90a3\u4e48 \\(mAP\\) =\uff080.5+0.2\uff09/2=0.35\u3002 MAP: \u662f\u6307\u6240\u6709\u56fe\u7247\u5185\u7684\u6240\u6709\u7c7b\u522b\u7684AP\u7684\u5e73\u5747\u503c ,map\u8d8a\u9ad8\u4ee3\u8868\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u503c\u8d8a\u9ad8\u3002 \\(mAP@0.5\\) \uff1a \\(mAP\\) \u662f\u7528 \\(Precision\\) \u548c \\(Recall\\) \u4f5c\u4e3a\u4e24\u8f74\u4f5c\u56fe\u540e\u56f4\u6210\u7684\u9762\u79ef\uff0c \\(m\\) \u8868\u793a\u5e73\u5747\uff0c@\u540e\u9762\u7684\u6570\u8868\u793a\u5224\u5b9a\u6b63\u8d1f\u6837\u672c\u7684 \\(IOU\\) \u9608\u503c\uff0c\u5176\u4e2d @0.5\u8868\u793aIOU\u9608\u503c\u53d60.5\u3002 \\(mAP@0.5:0.95\\) \uff1a\u53ea\u4ee5 \\(IOU=0.5\\) \u7684\u9600\u503c\u7684\u65f6\u5019\u4e0d\u4e00\u5b9a\u5c31\u662f\u597d\u7684\u6a21\u578b\uff0c\u53ef\u80fd\u4ec5\u4ec5\u57280.5\u9600\u503c\u8868\u73b0\u7684\u5f88\u597d\uff0c\u57280.6,0.7...\u9600\u503c\u8868\u73b0\u7684\u5f88\u5dee\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u8bc4\u4f30\u6574\u4f53\u6a21\u578b\u7684\u51c6\u786e\u5ea6\uff0c\u56e0\u6b64\u8ba1\u7b97\u4e00\u4e2a\u6a21\u578b\u5728\u5404\u4e2aIOU\u503c\u7684AP(mAP)\u53d6\u5e73\u5747\u503c\u3002 \u65b9\u6cd5\u662f\uff1a\u8ba1\u7b97\u6bcf\u4e2a\u5206\u7c7b\u7684AP\uff0c\u6c42\u548c\u518d\u5e73\u5747\uff0c\u5f97\u5230\u7684\u5c31\u662fmAP,\u5b83\u662f\u76f4\u63a5\u628amAP\u5f53\u6210AP\uff0c\u7136\u540e\u518d\u628aIOU\u503c\u5927\u4e8e0.5\u7684 \\(AP(mAP)\\) \uff0c\u4ee50.05\u7684\u589e\u91cf,\u52300.95\uff0c\u4e5f\u5c31\u662f\u4ee5 \\((0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)\\) \\(IOU\u503c\\) \u7684 \\(AP(mAP)\\) \u7684\u5e73\u5747\u503c\u5f53\u6210 \\(AP(at IoU=.50:.05:.95)\\) \uff0c\u901a\u8fc7 \\(IOU\u589e\u91cf\\) \u7684\u65b9\u5f0f\u5f97\u5230 \\(mAP@0.5:0.95\\) \u7ed3\u679c\u3002","title":"mAP"},{"location":"tutorials/05_chapter/map_analysis.html#map_1","text":"","title":"\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684mAP\u8ba1\u7b97"},{"location":"tutorials/05_chapter/map_analysis.html#yolov5iou","text":"\u6e90\u4ee3\u7801\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L224-L261 # \u8ba1\u7b97\u4e24\u6846\u7684\u7279\u5b9aiou (DIou, DIou, CIou) def bbox_iou ( box1 , box2 , xywh = True , GIoU = False , DIoU = False , CIoU = False , eps = 1e-7 ): # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4) # Get the coordinates of bounding boxes \u4e0b\u9762\u6761\u4ef6\u8bed\u53e5\u4f5c\u7528\u662f:\u8fdb\u884c\u5750\u6807\u8f6c\u6362\u4ece\u800c\u83b7\u53d6yolo\u683c\u5f0f\u8fb9\u754c\u6846\u7684\u5750\u6807 if xywh : # transform from xywh to xyxy ( x1 , y1 , w1 , h1 ), ( x2 , y2 , w2 , h2 ) = box1 . chunk ( 4 , 1 ), box2 . chunk ( 4 , 1 ) w1_ , h1_ , w2_ , h2_ = w1 / 2 , h1 / 2 , w2 / 2 , h2 / 2 b1_x1 , b1_x2 , b1_y1 , b1_y2 = x1 - w1_ , x1 + w1_ , y1 - h1_ , y1 + h1_ b2_x1 , b2_x2 , b2_y1 , b2_y2 = x2 - w2_ , x2 + w2_ , y2 - h2_ , y2 + h2_ else : # x1, y1, x2, y2 = box1 b1_x1 , b1_y1 , b1_x2 , b1_y2 = box1 . chunk ( 4 , 1 ) b2_x1 , b2_y1 , b2_x2 , b2_y2 = box2 . chunk ( 4 , 1 ) w1 , h1 = b1_x2 - b1_x1 , b1_y2 - b1_y1 w2 , h2 = b2_x2 - b2_x1 , b2_y2 - b2_y1 # Intersection area \u83b7\u53d6\u4e24\u4e2a\u6846\u76f8\u4ea4\u7684\u9762\u79ef\u3002 \"\"\" left_line = max(b1_x1, b2_x1) reft_line = min(b1_x2, b2_x2) top_line = max(b1_y1, b2_y1) bottom_line = min(b1_y2, b2_y2) intersect = (reight_line - left_line) * (bottom_line - top_line) \"\"\" inter = ( flow . min ( b1_x2 , b2_x2 ) - flow . max ( b1_x1 , b2_x1 )) . clamp ( 0 ) * \\ ( flow . min ( b1_y2 , b2_y2 ) - flow . max ( b1_y1 , b2_y1 )) . clamp ( 0 ) # Union Area \u4e24\u4e2a\u6846\u5e76\u5230\u9762\u79ef union = w1 * h1 + w2 * h2 - inter + eps # IoU iou = inter / union if CIoU or DIoU or GIoU : cw = flow . max ( b1_x2 , b2_x2 ) - flow . min ( b1_x1 , b2_x1 ) # convex (smallest enclosing box) width ch = flow . max ( b1_y2 , b2_y2 ) - flow . min ( b1_y1 , b2_y1 ) # convex height if CIoU or DIoU : # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1 c2 = cw ** 2 + ch ** 2 + eps # convex diagonal squared rho2 = (( b2_x1 + b2_x2 - b1_x1 - b1_x2 ) ** 2 + ( b2_y1 + b2_y2 - b1_y1 - b1_y2 ) ** 2 ) / 4 # center dist ** 2 if CIoU : # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47 v = ( 4 / math . pi ** 2 ) * flow . pow ( flow . atan ( w2 / ( h2 + eps )) - flow . atan ( w1 / ( h1 + eps )), 2 ) with flow . no_grad (): alpha = v / ( v - iou + ( 1 + eps )) return iou - ( rho2 / c2 + v * alpha ) # CIoU return iou - rho2 / c2 # DIoU c_area = cw * ch + eps # convex area return iou - ( c_area - union ) / c_area # GIoU https://arxiv.org/pdf/1902.09630.pdf return iou # IoU","title":"yolov5\u8ba1\u7b97IOU\u6e90\u7801\u89e3\u6790"},{"location":"tutorials/05_chapter/map_analysis.html#yolov5ap","text":"\u6e90\u4ee3\u7801\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/metrics.py#L96-L121 # \u6839\u636ePR\u66f2\u7ebf\u8ba1\u7b97AP def compute_ap ( recall , precision ): \"\"\" Compute the average precision, given the recall and precision curves # Arguments recall: The recall curve (list) precision: The precision curve (list) # Returns Average precision, precision curve, recall curve \"\"\" # Append sentinel values to beginning and end \u5c06\u5f00\u533a\u95f4\u7ed9\u8865\u4e0a\uff0c\u8865\u6210\u95ed\u5408\u7684\u533a\u95f4\u3002 mrec = np . concatenate (([ 0.0 ], recall , [ 1.0 ])) mpre = np . concatenate (([ 1.0 ], precision , [ 0.0 ])) # Compute the precision envelope \"\"\" \u4eba\u4e3a\u7684\u628aPR\u66f2\u7ebf\u53d8\u6210\u5355\u8c03\u9012\u51cf\u7684,\u4f8b\u5982: np.maximum(accumulate(np.array([21, 23, 18, 19, 20, 13, 12, 11]) ) => np.array([23, 23, 20, 20, 20, 13, 12, 11]) \"\"\" mpre = np . flip ( np . maximum . accumulate ( np . flip ( mpre ))) # Integrate area under curve method = 'interp' # methods: 'continuous', 'interp' if method == 'interp' : # \u9ed8\u8ba4\u91c7\u7528 interpolated-precision \u66f2\u7ebf\uff0c x = np . linspace ( 0 , 1 , 101 ) # 101-point interp (COCO) ap = np . trapz ( np . interp ( x , mrec , mpre ), x ) # integrate else : # 'continuous' i = np . where ( mrec [ 1 :] != mrec [: - 1 ])[ 0 ] # points where x axis (recall) changes ap = np . sum (( mrec [ i + 1 ] - mrec [ i ]) * mpre [ i + 1 ]) # area under curve return ap , mpre , mrec","title":"yolov5\u8ba1\u7b97AP\u6e90\u7801\u9010\u884c\u89e3\u6790"},{"location":"tutorials/05_chapter/map_analysis.html#_2","text":"https://github.com/rafaelpadilla/Object-Detection-Metrics","title":"\u53c2\u8003\u6587\u7ae0"},{"location":"tutorials/05_chapter/rectangular_reasoning.html","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u77e9\u5f62\u63a8\u7406 \u4ecb\u7ecd \u5f53\u6211\u4eec\u628a\u4e00\u5e45\u56fe\u7247\u9001\u5165\u7f51\u7edc\uff0c\u8fd9\u5e45\u56fe\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e0e\u7f51\u7edc\u9700\u6c42\u7684\u4e0d\u4e00\u81f4\u7684\u65f6\u5019\uff0c\u6211\u4eec\u80af\u5b9a\u9700\u8981\u5bf9\u56fe\u7247\u505a\u51fa\u4e00\u4e9b\u6539\u53d8\u3002 \u4e00\u822c\u6765\u8bf4\u6709\u4e24\u79cd\u5e38\u7528\u7684\u9009\u62e9:(\u5047\u8bbe \u7f51\u7edc\u9700\u6c42\u7684\u56fe\u7247\u5927\u5c0f\u4e3a32\u7684\u500d\u6570,\u4f20\u5165\u7684\u56fe\u7247\u9ad8\u5bbd\u4e3a 200 x 416 ) 1. \u6b63\u65b9\u5f62\u63a8\u7406(square lnference) \u662f\u5c06\u56fe\u7247\u586b\u5145\u4e3a\u6b63\u65b9\u5f62,\u5982\u4e0b\u56fe\u5de6\u8fb9\u6240\u793a\u3002 2. \u77e9\u5f62\u63a8\u7406(Rectangular Inference) \u5982\u4e0b\u56fe\u53f3\u8fb9\u6240\u793a\u3002 \u5206\u6790: \u53ef\u4ee5\u770b\u5230\u4e0a\u56fe\u6b63\u65b9\u5f62\u63a8\u7406\u5b58\u5728\u5927\u91cf\u7684\u5197\u4f59\u90e8\u5206,\u800c\u53f3\u8fb9\u7684\u77e9\u5f62\u63a8\u7406\u660e\u663e\u5197\u4f59\u90e8\u5206\u5c11\u4e8e\u5de6\u8fb9\u5e76\u4e14\u5b9e\u9645\u8868\u73b0\u7684\u76f8\u6bd4\u6b63\u65b9\u5f62\u63a8\u7406\u80fd\u663e\u8457\u7684\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002 \u63a8\u7406\u8fc7\u7a0b\uff1a\u5c06\u8f83\u957f\u8fb9\u8bbe\u5b9a\u4e3a\u76ee\u6807\u5c3a\u5bf8 416,512\u2026 (\u5fc5\u987b\u662f32\u7684\u500d\u6570)\uff0c\u77ed\u8fb9\u6309\u6bd4\u4f8b\u7f29\u653e\uff0c\u518d\u5bf9\u77ed\u8fb9\u8fdb\u884c\u8f83\u5c11\u586b\u5145\u4f7f\u77ed\u8fb9\u6ee1\u8db332\u7684\u500d\u6570\uff0c\u8be6\u7ec6\u8fc7\u7a0b\u8be6\u89c1\u6e90\u7801\u89e3\u6790\u3002 \u62d3\u5c55 \u77e9\u5f62\u63a8\u7406\u6e90\u7801\u89e3\u6790 \u5bf9\u5e94\u4ed3\u5e93\u6587\u4ef6: https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/augmentations.py#L93-L131 # \u56fe\u7247\u7f29\u653e\uff1a\u4fdd\u6301\u56fe\u7247\u7684\u5bbd\u9ad8\u6bd4\u4f8b\uff0c\u5269\u4e0b\u7684\u90e8\u5206\u7528\u7070\u8272\u586b\u5145\u3002 def letterbox ( im , new_shape = ( 640 , 640 ), color = ( 114 , 114 , 114 ), auto = True , scaleFill = False , scaleup = True , stride = 32 ): \"\"\" \u5c06\u56fe\u7247\u7f29\u653e\u8c03\u6574\u5230\u6307\u5b9a\u5927\u5c0f @Param img: \u539f\u56fe @Param new_shape: \u7f29\u653e\u540e\u7684\u56fe\u7247\u5927\u5c0f @Param color: pad\u7684\u989c\u8272 @Param auto: True \u4fdd\u8bc1\u7f29\u653e\u540e\u7684\u56fe\u7247\u4fdd\u6301\u539f\u56fe\u7684\u6bd4\u4f8b \u5373 \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e\uff08\u4e0d\u4f1a\u5931\u771f\uff09 False \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e,\u6700\u540e\u5c06\u8f83\u77ed\u8fb9\u4e24\u8fb9pad\u64cd\u4f5c\u7f29\u653e\u5230\u6700\u957f\u8fb9\u5927\u5c0f\uff08\u4e0d\u4f1a\u5931\u771f\uff09 @Param scale_fill: True \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u539f\u56feresize\u5230\u6307\u5b9a\u7684\u5927\u5c0f \u76f8\u5f53\u4e8e\u5c31\u662fresize \u6ca1\u6709pad\u64cd\u4f5c\uff08\u5931\u771f\uff09 @Param scale_up: True \u5bf9\u4e8e\u5c0f\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5927\u4e8e\u7684\u4e0d\u53d8 False \u5bf9\u4e8e\u5927\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8e\u7684\u4e0d\u53d8 @return: img: letterbox\u540e\u7684\u56fe\u7247 ratio: wh ratios (dw, dh): w\u548ch\u7684pad \"\"\" # Resize and pad image while meeting stride-multiple constraints # \u53d6\u56fe\u7247\u7684\u9ad8\u5bbd shape = im . shape [: 2 ] # current shape [height, width] if isinstance ( new_shape , int ): new_shape = ( new_shape , new_shape ) # Scale ratio (new / old) \u8ba1\u7b97\u7f29\u653e\u56e0\u5b50 r = min ( new_shape [ 0 ] / shape [ 0 ], new_shape [ 1 ] / shape [ 1 ]) \"\"\" \u7f29\u653e(resize)\u5230\u8f93\u5165\u5927\u5c0fimg_size\u7684\u65f6\u5019,\u5982\u679c\u6ca1\u6709\u8bbe\u7f6e\u4e0a\u91c7\u6837\u7684\u8bdd,\u5219\u53ea\u8fdb\u884c\u4e0b\u91c7\u6837 \u56e0\u4e3a\u4e0a\u91c7\u6837\u56fe\u7247\u4f1a\u8ba9\u56fe\u7247\u6a21\u7cca,\u5bf9\u8bad\u7ec3\u4e0d\u53cb\u597d\u4e14\u5f71\u54cd\u6027\u80fd\u3002 \"\"\" if not scaleup : # only scale down, do not scale up (for better val mAP) r = min ( r , 1.0 ) # Compute padding \u8ba1\u7b97\u586b\u5145 ratio = r , r # width, height ratios # \u65b0\u7684\u672a\u586b\u5145\u5927\u5c0f, \u4fdd\u8bc1\u7f29\u653e\u540e\u56fe\u50cf\u6bd4\u4f8b\u4e0d\u53d8 new_unpad = int ( round ( shape [ 1 ] * r )), int ( round ( shape [ 0 ] * r )) dw , dh = new_shape [ 1 ] - new_unpad [ 0 ], new_shape [ 0 ] - new_unpad [ 1 ] # wh padding if auto : # minimum rectangle \u83b7\u53d6\u6700\u5c0f\u77e9\u5f62\u586b\u5145 # \u8fd9\u91cc\u7684\u53d6\u4f59\u64cd\u4f5c\u53ef\u4ee5\u4fdd\u8bc1padding\u540e\u7684\u56fe\u7247\u662f32\u7684\u6574\u6570\u500d(416x416)\uff0c\u5982\u679c\u662f(512x512)\u53ef\u4ee5\u4fdd\u8bc1\u662f64\u7684\u6574\u6570\u500d dw , dh = np . mod ( dw , stride ), np . mod ( dh , stride ) # wh padding # \u5982\u679cscaleFill = True,\u5219\u4e0d\u8fdb\u884c\u586b\u5145\uff0c\u76f4\u63a5resize\u6210img_size,\u4efb\u7531\u56fe\u7247\u8fdb\u884c\u62c9\u4f38\u548c\u538b\u7f29 elif scaleFill : # stretch dw , dh = 0.0 , 0.0 new_unpad = ( new_shape [ 1 ], new_shape [ 0 ]) ratio = new_shape [ 1 ] / shape [ 1 ], new_shape [ 0 ] / shape [ 0 ] # width, height ratios # \u8ba1\u7b97\u4e0a\u4e0b\u5de6\u53f3\u5230\u586b\u5145,\u5373\u5c06padding\u5206\u5230\u4e0a\u4e0b\uff0c\u5de6\u53f3\u4e24\u4fa7 dw /= 2 # divide padding into 2 sides dh /= 2 # \u5c06\u539f\u56feresize\u5230new_unpad if shape [:: - 1 ] != new_unpad : # resize im = cv2 . resize ( im , new_unpad , interpolation = cv2 . INTER_LINEAR ) # \u4e0b\u9762\u4e24\u884c\u8ba1\u7b97\u9700\u8981\u586b\u5145 padding top , bottom = int ( round ( dh - 0.1 )), int ( round ( dh + 0.1 )) # \u8ba1\u7b97\u4e0a\u4e0b\u4e24\u4fa7\u7684padding left , right = int ( round ( dw - 0.1 )), int ( round ( dw + 0.1 )) # \u8ba1\u7b97\u5de6\u53f3\u4e24\u4fa7\u7684padding # \u8c03\u7528cv2.copyMakeBorder\u51fd\u6570\u8fdb\u884c\u80cc\u666f\u586b\u5145\u3002 im = cv2 . copyMakeBorder ( im , top , bottom , left , right , cv2 . BORDER_CONSTANT , value = color ) # add border return im , ratio , ( dw , dh )","title":"5.1 \u77e9\u5f62\u63a8\u7406"},{"location":"tutorials/05_chapter/rectangular_reasoning.html#_1","text":"","title":"\u77e9\u5f62\u63a8\u7406"},{"location":"tutorials/05_chapter/rectangular_reasoning.html#_2","text":"\u5f53\u6211\u4eec\u628a\u4e00\u5e45\u56fe\u7247\u9001\u5165\u7f51\u7edc\uff0c\u8fd9\u5e45\u56fe\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4e0e\u7f51\u7edc\u9700\u6c42\u7684\u4e0d\u4e00\u81f4\u7684\u65f6\u5019\uff0c\u6211\u4eec\u80af\u5b9a\u9700\u8981\u5bf9\u56fe\u7247\u505a\u51fa\u4e00\u4e9b\u6539\u53d8\u3002 \u4e00\u822c\u6765\u8bf4\u6709\u4e24\u79cd\u5e38\u7528\u7684\u9009\u62e9:(\u5047\u8bbe \u7f51\u7edc\u9700\u6c42\u7684\u56fe\u7247\u5927\u5c0f\u4e3a32\u7684\u500d\u6570,\u4f20\u5165\u7684\u56fe\u7247\u9ad8\u5bbd\u4e3a 200 x 416 ) 1. \u6b63\u65b9\u5f62\u63a8\u7406(square lnference) \u662f\u5c06\u56fe\u7247\u586b\u5145\u4e3a\u6b63\u65b9\u5f62,\u5982\u4e0b\u56fe\u5de6\u8fb9\u6240\u793a\u3002 2. \u77e9\u5f62\u63a8\u7406(Rectangular Inference) \u5982\u4e0b\u56fe\u53f3\u8fb9\u6240\u793a\u3002 \u5206\u6790: \u53ef\u4ee5\u770b\u5230\u4e0a\u56fe\u6b63\u65b9\u5f62\u63a8\u7406\u5b58\u5728\u5927\u91cf\u7684\u5197\u4f59\u90e8\u5206,\u800c\u53f3\u8fb9\u7684\u77e9\u5f62\u63a8\u7406\u660e\u663e\u5197\u4f59\u90e8\u5206\u5c11\u4e8e\u5de6\u8fb9\u5e76\u4e14\u5b9e\u9645\u8868\u73b0\u7684\u76f8\u6bd4\u6b63\u65b9\u5f62\u63a8\u7406\u80fd\u663e\u8457\u7684\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002 \u63a8\u7406\u8fc7\u7a0b\uff1a\u5c06\u8f83\u957f\u8fb9\u8bbe\u5b9a\u4e3a\u76ee\u6807\u5c3a\u5bf8 416,512\u2026 (\u5fc5\u987b\u662f32\u7684\u500d\u6570)\uff0c\u77ed\u8fb9\u6309\u6bd4\u4f8b\u7f29\u653e\uff0c\u518d\u5bf9\u77ed\u8fb9\u8fdb\u884c\u8f83\u5c11\u586b\u5145\u4f7f\u77ed\u8fb9\u6ee1\u8db332\u7684\u500d\u6570\uff0c\u8be6\u7ec6\u8fc7\u7a0b\u8be6\u89c1\u6e90\u7801\u89e3\u6790\u3002","title":"\u4ecb\u7ecd"},{"location":"tutorials/05_chapter/rectangular_reasoning.html#_3","text":"","title":"\u62d3\u5c55"},{"location":"tutorials/05_chapter/rectangular_reasoning.html#_4","text":"\u5bf9\u5e94\u4ed3\u5e93\u6587\u4ef6: https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/augmentations.py#L93-L131 # \u56fe\u7247\u7f29\u653e\uff1a\u4fdd\u6301\u56fe\u7247\u7684\u5bbd\u9ad8\u6bd4\u4f8b\uff0c\u5269\u4e0b\u7684\u90e8\u5206\u7528\u7070\u8272\u586b\u5145\u3002 def letterbox ( im , new_shape = ( 640 , 640 ), color = ( 114 , 114 , 114 ), auto = True , scaleFill = False , scaleup = True , stride = 32 ): \"\"\" \u5c06\u56fe\u7247\u7f29\u653e\u8c03\u6574\u5230\u6307\u5b9a\u5927\u5c0f @Param img: \u539f\u56fe @Param new_shape: \u7f29\u653e\u540e\u7684\u56fe\u7247\u5927\u5c0f @Param color: pad\u7684\u989c\u8272 @Param auto: True \u4fdd\u8bc1\u7f29\u653e\u540e\u7684\u56fe\u7247\u4fdd\u6301\u539f\u56fe\u7684\u6bd4\u4f8b \u5373 \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e\uff08\u4e0d\u4f1a\u5931\u771f\uff09 False \u5c06\u539f\u56fe\u6700\u957f\u8fb9\u7f29\u653e\u5230\u6307\u5b9a\u5927\u5c0f\uff0c\u518d\u5c06\u539f\u56fe\u8f83\u77ed\u8fb9\u6309\u539f\u56fe\u6bd4\u4f8b\u7f29\u653e,\u6700\u540e\u5c06\u8f83\u77ed\u8fb9\u4e24\u8fb9pad\u64cd\u4f5c\u7f29\u653e\u5230\u6700\u957f\u8fb9\u5927\u5c0f\uff08\u4e0d\u4f1a\u5931\u771f\uff09 @Param scale_fill: True \u7b80\u5355\u7c97\u66b4\u7684\u5c06\u539f\u56feresize\u5230\u6307\u5b9a\u7684\u5927\u5c0f \u76f8\u5f53\u4e8e\u5c31\u662fresize \u6ca1\u6709pad\u64cd\u4f5c\uff08\u5931\u771f\uff09 @Param scale_up: True \u5bf9\u4e8e\u5c0f\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5927\u4e8e\u7684\u4e0d\u53d8 False \u5bf9\u4e8e\u5927\u4e8enew_shape\u7684\u539f\u56fe\u8fdb\u884c\u7f29\u653e,\u5c0f\u4e8e\u7684\u4e0d\u53d8 @return: img: letterbox\u540e\u7684\u56fe\u7247 ratio: wh ratios (dw, dh): w\u548ch\u7684pad \"\"\" # Resize and pad image while meeting stride-multiple constraints # \u53d6\u56fe\u7247\u7684\u9ad8\u5bbd shape = im . shape [: 2 ] # current shape [height, width] if isinstance ( new_shape , int ): new_shape = ( new_shape , new_shape ) # Scale ratio (new / old) \u8ba1\u7b97\u7f29\u653e\u56e0\u5b50 r = min ( new_shape [ 0 ] / shape [ 0 ], new_shape [ 1 ] / shape [ 1 ]) \"\"\" \u7f29\u653e(resize)\u5230\u8f93\u5165\u5927\u5c0fimg_size\u7684\u65f6\u5019,\u5982\u679c\u6ca1\u6709\u8bbe\u7f6e\u4e0a\u91c7\u6837\u7684\u8bdd,\u5219\u53ea\u8fdb\u884c\u4e0b\u91c7\u6837 \u56e0\u4e3a\u4e0a\u91c7\u6837\u56fe\u7247\u4f1a\u8ba9\u56fe\u7247\u6a21\u7cca,\u5bf9\u8bad\u7ec3\u4e0d\u53cb\u597d\u4e14\u5f71\u54cd\u6027\u80fd\u3002 \"\"\" if not scaleup : # only scale down, do not scale up (for better val mAP) r = min ( r , 1.0 ) # Compute padding \u8ba1\u7b97\u586b\u5145 ratio = r , r # width, height ratios # \u65b0\u7684\u672a\u586b\u5145\u5927\u5c0f, \u4fdd\u8bc1\u7f29\u653e\u540e\u56fe\u50cf\u6bd4\u4f8b\u4e0d\u53d8 new_unpad = int ( round ( shape [ 1 ] * r )), int ( round ( shape [ 0 ] * r )) dw , dh = new_shape [ 1 ] - new_unpad [ 0 ], new_shape [ 0 ] - new_unpad [ 1 ] # wh padding if auto : # minimum rectangle \u83b7\u53d6\u6700\u5c0f\u77e9\u5f62\u586b\u5145 # \u8fd9\u91cc\u7684\u53d6\u4f59\u64cd\u4f5c\u53ef\u4ee5\u4fdd\u8bc1padding\u540e\u7684\u56fe\u7247\u662f32\u7684\u6574\u6570\u500d(416x416)\uff0c\u5982\u679c\u662f(512x512)\u53ef\u4ee5\u4fdd\u8bc1\u662f64\u7684\u6574\u6570\u500d dw , dh = np . mod ( dw , stride ), np . mod ( dh , stride ) # wh padding # \u5982\u679cscaleFill = True,\u5219\u4e0d\u8fdb\u884c\u586b\u5145\uff0c\u76f4\u63a5resize\u6210img_size,\u4efb\u7531\u56fe\u7247\u8fdb\u884c\u62c9\u4f38\u548c\u538b\u7f29 elif scaleFill : # stretch dw , dh = 0.0 , 0.0 new_unpad = ( new_shape [ 1 ], new_shape [ 0 ]) ratio = new_shape [ 1 ] / shape [ 1 ], new_shape [ 0 ] / shape [ 0 ] # width, height ratios # \u8ba1\u7b97\u4e0a\u4e0b\u5de6\u53f3\u5230\u586b\u5145,\u5373\u5c06padding\u5206\u5230\u4e0a\u4e0b\uff0c\u5de6\u53f3\u4e24\u4fa7 dw /= 2 # divide padding into 2 sides dh /= 2 # \u5c06\u539f\u56feresize\u5230new_unpad if shape [:: - 1 ] != new_unpad : # resize im = cv2 . resize ( im , new_unpad , interpolation = cv2 . INTER_LINEAR ) # \u4e0b\u9762\u4e24\u884c\u8ba1\u7b97\u9700\u8981\u586b\u5145 padding top , bottom = int ( round ( dh - 0.1 )), int ( round ( dh + 0.1 )) # \u8ba1\u7b97\u4e0a\u4e0b\u4e24\u4fa7\u7684padding left , right = int ( round ( dw - 0.1 )), int ( round ( dw + 0.1 )) # \u8ba1\u7b97\u5de6\u53f3\u4e24\u4fa7\u7684padding # \u8c03\u7528cv2.copyMakeBorder\u51fd\u6570\u8fdb\u884c\u80cc\u666f\u586b\u5145\u3002 im = cv2 . copyMakeBorder ( im , top , bottom , left , right , cv2 . BORDER_CONSTANT , value = color ) # add border return im , ratio , ( dw , dh )","title":"\u77e9\u5f62\u63a8\u7406\u6e90\u7801\u89e3\u6790"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html","text":"\ud83c\udf89\u4ee3\u7801\u4ed3\u5e93\u5730\u5740\uff1a https://github.com/Oneflow-Inc/one-yolov5 \u6b22\u8fcestar one-yolov5\u9879\u76ee \u83b7\u53d6 \u6700\u65b0\u7684\u52a8\u6001\u3002 \u5982\u679c\u60a8\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u5728\u4ed3\u5e93\u7ed9\u6211\u4eec\u63d0\u51fa\u5b9d\u8d35\u7684\u610f\u89c1\u3002\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f \u5982\u679c\u5bf9\u60a8\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u6765\u7ed9\u6211Star\u5440\ud83d\ude0a~ \u6a21\u578b\u5bfc\u51fa \ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5982\u4f55\u5bfc\u51fa\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684 OneFlow YOLOv5 \u6a21\u578b \ud83d\ude80 \u5230 ONNX . \u5f00\u59cb\u4e4b\u524d \u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install \u683c\u5f0f YOLOv5\u652f\u6301\u591a\u79cd\u6a21\u578b\u683c\u5f0f\u7684\u5bfc\u51fa\uff0c\u5e76\u57fa\u4e8e\u7279\u5b9a\u6a21\u578b\u5bf9\u5e94\u7684\u6846\u67b6\u83b7\u5f97\u63a8\u7406\u52a0\u901f\u3002 Format export.py --include Model OneFlow - yolov5s_oneflow_model/ ONNX onnx yolov5s.onnx OpenVINO openvino yolov5s_openvino_model/ TensorRT engine yolov5s.engine TensorFlow SavedModel saved_model yolov5s_saved_model/ TensorFlow GraphDef pb yolov5s.pb TensorFlow Lite tflite yolov5s.tflite TensorFlow Edge TPU edgetpu yolov5s_edgetpu.tflite TensorFlow.js tfjs yolov5s_web_model/ \u5bfc\u51fa\u8bad\u7ec3\u597d\u7684 YOLOv5 \u6a21\u578b \u4e0b\u9762\u7684\u547d\u4ee4\u628a\u9884\u8bad\u7ec3\u7684 YOLOV5s \u6a21\u578b\u5bfc\u51fa\u4e3a ONNX \u683c\u5f0f\u3002 yolov5s \u662f\u5c0f\u6a21\u578b\uff0c\u662f\u53ef\u7528\u7684\u6a21\u578b\u91cc\u9762\u7b2c\u4e8c\u5c0f\u7684\u3002\u5176\u5b83\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5l \uff0c yolov5x \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u6211\u4eec\u7684 README python export.py --weights ../yolov5s/ --include onnx \ud83d\udca1 \u63d0\u793a: \u6dfb\u52a0 --half \u4ee5 FP16 \u534a\u7cbe\u5ea6\u5bfc\u51fa\u6a21\u578b\u4ee5\u5b9e\u73b0\u66f4\u5c0f\u7684\u6587\u4ef6\u5927\u5c0f\u3002 \u8f93\u51fa\uff1a export: data = data/coco128.yaml, weights =[ '../yolov5s/' ] , imgsz =[ 640 , 640 ] , batch_size = 1 , device = cpu, half = False, inplace = False, train = False, keras = False, optimize = False, int8 = False, dynamic = False, simplify = False, opset = 12 , verbose = False, workspace = 4 , nms = False, agnostic_nms = False, topk_per_class = 100 , topk_all = 100 , iou_thres = 0 .45, conf_thres = 0 .25, include =[ 'onnx' ] YOLOv5 \ud83d\ude80 270ac92 Python-3.8.11 oneflow-0.8.1+cu117.git.0c70a3f6be CPU Fusing layers... YOLOv5s summary: 157 layers, 7225885 parameters, 229245 gradients OneFlow: starting from ../yolov5s with output shape ( 1 , 25200 , 85 ) ( 112 .9 MB ) ONNX: starting export with onnx 1 .12.0... Converting model to onnx.... Using opset <onnx, 12 > Optimizing ONNX model After optimization: Const +17 ( 73 ->90 ) , Identity -1 ( 1 ->0 ) , Unsqueeze -60 ( 60 ->0 ) , output -1 ( 1 ->0 ) , variable -60 ( 127 ->67 ) Succeed converting model, save model to ../yolov5s.onnx <class 'tuple' > Comparing result between oneflow and onnx.... Compare succeed! ONNX: export success, saved as ../yolov5s.onnx ( 28 .0 MB ) Export complete ( 24 .02s ) Results saved to /home/zhangxiaoyu Detect: python detect.py --weights ../yolov5s.onnx Validate: python val.py --weights ../yolov5s.onnx OneFlow Hub: model = flow.hub.load ( 'OneFlow-Inc/one-yolov5' , 'custom' , '../yolov5s.onnx' ) Visualize: https://netron.app \u5bfc\u51fa\u7684 onnx \u6a21\u578b\u4f7f\u7528 Netron Viewer \u8fdb\u884c\u53ef\u89c6\u5316\u7684\u7ed3\u679c\u5982\u4e0b\uff1a \u5bfc\u51fa\u6a21\u578b\u7684\u793a\u4f8b\u7528\u6cd5 detect.py \u53ef\u4ee5\u5bf9\u5bfc\u51fa\u7684\u6a21\u578b\u8fdb\u884c\u63a8\u7406\uff1a python path / to / detect . py -- weights yolov5s / # OneFlow yolov5s . onnx # ONNX Runtime or OpenCV DNN with --dnn yolov5s . xml # OpenVINO yolov5s . engine # TensorRT yolov5s . mlmodel # CoreML (macOS only) yolov5s_saved_model # TensorFlow SavedModel yolov5s . pb # TensorFlow GraphDef yolov5s . tflite # TensorFlow Lite yolov5s_edgetpu . tflite # TensorFlow Edge TPU val.py \u53ef\u4ee5\u5bf9\u5bfc\u51fa\u7684\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\uff1a python path / to / val . py -- weights yolov5s / # OneFlow yolov5s . onnx # ONNX Runtime or OpenCV DNN with --dnn yolov5s . xml # OpenVINO yolov5s . engine # TensorRT yolov5s . mlmodel # CoreML (macOS only) yolov5s_saved_model # TensorFlow SavedModel yolov5s . pb # TensorFlow GraphDef yolov5s . tflite # TensorFlow Lite yolov5s_edgetpu . tflite # TensorFlow Edge TPU ONNX Runtime \u63a8\u7406 \u57fa\u4e8e onnx \u6a21\u578b\u4f7f\u7528 onnxruntime \u8fdb\u884c\u63a8\u7406\uff1a python3 detect.py --weights ../yolov5s/yolov5s.onnx \u8f93\u51fa\uff1a detect: weights=['../yolov5s/yolov5s.onnx'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 270ac92 Python-3.8.11 oneflow-0.8.1+cu117.git.0c70a3f6be Loading ../yolov5s/yolov5s.onnx for ONNX Runtime inference... detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/zhangxiaoyu/one-yolov5/data/images/bus.jpg: 640x640 4 persons, 1 bus, Done. (0.009s) image 2/2 /home/zhangxiaoyu/one-yolov5/data/images/zidane.jpg: 640x640 2 persons, 2 ties, Done. (0.011s) 0.5ms pre-process, 10.4ms inference, 4.8ms NMS per image at shape (1, 3, 640, 640) Results saved to runs/detect/exp14 \u53c2\u8003\u6587\u7ae0 https://github.com/ultralytics/yolov5/issues/251","title":"6.1 \u6a21\u578b\u5bfc\u51fa"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_1","text":"\ud83d\udcda \u8fd9\u4e2a\u6559\u7a0b\u7528\u6765\u89e3\u91ca\u5982\u4f55\u5bfc\u51fa\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684 OneFlow YOLOv5 \u6a21\u578b \ud83d\ude80 \u5230 ONNX .","title":"\u6a21\u578b\u5bfc\u51fa"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_2","text":"\u514b\u9686\u5de5\u7a0b\u5e76\u5728 Python>3.7.0 \u7684\u73af\u5883\u4e2d\u5b89\u88c5 requiresments.txt , OneFlow \u8bf7\u9009\u62e9 nightly \u7248\u672c\u6216\u8005 >0.9 \u7248\u672c \u3002 \u6a21\u578b \u548c \u6570\u636e \u53ef\u4ee5\u4ece\u6e90\u7801\u4e2d\u81ea\u52a8\u4e0b\u8f7d\u3002 git clone https://github.com/Oneflow-Inc/one-yolov5.git cd one-yolov5 pip install -r requirements.txt # install","title":"\u5f00\u59cb\u4e4b\u524d"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_3","text":"YOLOv5\u652f\u6301\u591a\u79cd\u6a21\u578b\u683c\u5f0f\u7684\u5bfc\u51fa\uff0c\u5e76\u57fa\u4e8e\u7279\u5b9a\u6a21\u578b\u5bf9\u5e94\u7684\u6846\u67b6\u83b7\u5f97\u63a8\u7406\u52a0\u901f\u3002 Format export.py --include Model OneFlow - yolov5s_oneflow_model/ ONNX onnx yolov5s.onnx OpenVINO openvino yolov5s_openvino_model/ TensorRT engine yolov5s.engine TensorFlow SavedModel saved_model yolov5s_saved_model/ TensorFlow GraphDef pb yolov5s.pb TensorFlow Lite tflite yolov5s.tflite TensorFlow Edge TPU edgetpu yolov5s_edgetpu.tflite TensorFlow.js tfjs yolov5s_web_model/","title":"\u683c\u5f0f"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#yolov5","text":"\u4e0b\u9762\u7684\u547d\u4ee4\u628a\u9884\u8bad\u7ec3\u7684 YOLOV5s \u6a21\u578b\u5bfc\u51fa\u4e3a ONNX \u683c\u5f0f\u3002 yolov5s \u662f\u5c0f\u6a21\u578b\uff0c\u662f\u53ef\u7528\u7684\u6a21\u578b\u91cc\u9762\u7b2c\u4e8c\u5c0f\u7684\u3002\u5176\u5b83\u9009\u9879\u662f yolov5n \uff0c yolov5m \uff0c yolov5l \uff0c yolov5x \uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684 P6 \u5bf9\u5e94\u9879\u6bd4\u5982 yolov5s6 \uff0c\u6216\u8005\u4f60\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5373 runs/exp/weights/best \u3002\u6709\u5173\u53ef\u7528\u6a21\u578b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u6211\u4eec\u7684 README python export.py --weights ../yolov5s/ --include onnx \ud83d\udca1 \u63d0\u793a: \u6dfb\u52a0 --half \u4ee5 FP16 \u534a\u7cbe\u5ea6\u5bfc\u51fa\u6a21\u578b\u4ee5\u5b9e\u73b0\u66f4\u5c0f\u7684\u6587\u4ef6\u5927\u5c0f\u3002 \u8f93\u51fa\uff1a export: data = data/coco128.yaml, weights =[ '../yolov5s/' ] , imgsz =[ 640 , 640 ] , batch_size = 1 , device = cpu, half = False, inplace = False, train = False, keras = False, optimize = False, int8 = False, dynamic = False, simplify = False, opset = 12 , verbose = False, workspace = 4 , nms = False, agnostic_nms = False, topk_per_class = 100 , topk_all = 100 , iou_thres = 0 .45, conf_thres = 0 .25, include =[ 'onnx' ] YOLOv5 \ud83d\ude80 270ac92 Python-3.8.11 oneflow-0.8.1+cu117.git.0c70a3f6be CPU Fusing layers... YOLOv5s summary: 157 layers, 7225885 parameters, 229245 gradients OneFlow: starting from ../yolov5s with output shape ( 1 , 25200 , 85 ) ( 112 .9 MB ) ONNX: starting export with onnx 1 .12.0... Converting model to onnx.... Using opset <onnx, 12 > Optimizing ONNX model After optimization: Const +17 ( 73 ->90 ) , Identity -1 ( 1 ->0 ) , Unsqueeze -60 ( 60 ->0 ) , output -1 ( 1 ->0 ) , variable -60 ( 127 ->67 ) Succeed converting model, save model to ../yolov5s.onnx <class 'tuple' > Comparing result between oneflow and onnx.... Compare succeed! ONNX: export success, saved as ../yolov5s.onnx ( 28 .0 MB ) Export complete ( 24 .02s ) Results saved to /home/zhangxiaoyu Detect: python detect.py --weights ../yolov5s.onnx Validate: python val.py --weights ../yolov5s.onnx OneFlow Hub: model = flow.hub.load ( 'OneFlow-Inc/one-yolov5' , 'custom' , '../yolov5s.onnx' ) Visualize: https://netron.app \u5bfc\u51fa\u7684 onnx \u6a21\u578b\u4f7f\u7528 Netron Viewer \u8fdb\u884c\u53ef\u89c6\u5316\u7684\u7ed3\u679c\u5982\u4e0b\uff1a","title":"\u5bfc\u51fa\u8bad\u7ec3\u597d\u7684 YOLOv5 \u6a21\u578b"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_4","text":"detect.py \u53ef\u4ee5\u5bf9\u5bfc\u51fa\u7684\u6a21\u578b\u8fdb\u884c\u63a8\u7406\uff1a python path / to / detect . py -- weights yolov5s / # OneFlow yolov5s . onnx # ONNX Runtime or OpenCV DNN with --dnn yolov5s . xml # OpenVINO yolov5s . engine # TensorRT yolov5s . mlmodel # CoreML (macOS only) yolov5s_saved_model # TensorFlow SavedModel yolov5s . pb # TensorFlow GraphDef yolov5s . tflite # TensorFlow Lite yolov5s_edgetpu . tflite # TensorFlow Edge TPU val.py \u53ef\u4ee5\u5bf9\u5bfc\u51fa\u7684\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\uff1a python path / to / val . py -- weights yolov5s / # OneFlow yolov5s . onnx # ONNX Runtime or OpenCV DNN with --dnn yolov5s . xml # OpenVINO yolov5s . engine # TensorRT yolov5s . mlmodel # CoreML (macOS only) yolov5s_saved_model # TensorFlow SavedModel yolov5s . pb # TensorFlow GraphDef yolov5s . tflite # TensorFlow Lite yolov5s_edgetpu . tflite # TensorFlow Edge TPU","title":"\u5bfc\u51fa\u6a21\u578b\u7684\u793a\u4f8b\u7528\u6cd5"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#onnx-runtime","text":"\u57fa\u4e8e onnx \u6a21\u578b\u4f7f\u7528 onnxruntime \u8fdb\u884c\u63a8\u7406\uff1a python3 detect.py --weights ../yolov5s/yolov5s.onnx \u8f93\u51fa\uff1a detect: weights=['../yolov5s/yolov5s.onnx'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False YOLOv5 \ud83d\ude80 270ac92 Python-3.8.11 oneflow-0.8.1+cu117.git.0c70a3f6be Loading ../yolov5s/yolov5s.onnx for ONNX Runtime inference... detect.py:159: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \" # add to string image 1/2 /home/zhangxiaoyu/one-yolov5/data/images/bus.jpg: 640x640 4 persons, 1 bus, Done. (0.009s) image 2/2 /home/zhangxiaoyu/one-yolov5/data/images/zidane.jpg: 640x640 2 persons, 2 ties, Done. (0.011s) 0.5ms pre-process, 10.4ms inference, 4.8ms NMS per image at shape (1, 3, 640, 640) Results saved to runs/detect/exp14","title":"ONNX Runtime \u63a8\u7406"},{"location":"tutorials/06_chapter/export_onnx_tflite_tensorrt.html#_5","text":"https://github.com/ultralytics/yolov5/issues/251","title":"\u53c2\u8003\u6587\u7ae0"}]}