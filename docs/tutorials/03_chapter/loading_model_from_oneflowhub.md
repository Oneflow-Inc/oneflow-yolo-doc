ğŸ“š è¿™ä¸ªæ•™ç¨‹ç”¨æ¥è§£é‡Šå¦‚ä½•ä» OneFlow Hub åŠ è½½ one-yolov5 ã€‚ğŸš€

### å¼€å§‹ä¹‹å‰

åœ¨ [Python>3.7.0](https://www.python.org/) çš„ç¯å¢ƒä¸­å®‰è£… [æ‰€éœ€çš„ä¾èµ–åº“](https://github.com/Oneflow-Inc/one-yolov5/blob/main/requirements.txt) , OneFlow è¯·é€‰æ‹© [nightly ç‰ˆæœ¬æˆ–è€… >0.9 ç‰ˆæœ¬](https://github.com/Oneflow-Inc/oneflow#install-with-pip-package) ã€‚[æ¨¡å‹](https://github.com/Oneflow-Inc/one-yolov5/tree/main/models)å’Œ[æ•°æ®](https://github.com/Oneflow-Inc/one-yolov5/tree/main/data)å¯ä»¥ä»æºç ä¸­è‡ªåŠ¨ä¸‹è½½ã€‚

ğŸ’¡ ä¸“å®¶æç¤ºï¼šä¸éœ€è¦å…‹éš† https://github.com/Oneflow-Inc/one-yolov5 

### ä½¿ç”¨ OneFlow Hub åŠ è½½ one-yolov5 

#### ç®€å•çš„ä¾‹å­

æ­¤ç¤ºä¾‹ä» OneFlow Hub åŠ è½½é¢„è®­ç»ƒçš„ YOLOv5s æ¨¡å‹ä½œä¸º `model` ï¼Œå¹¶ä¼ ä¸€å¼ å›¾åƒè¿›è¡Œæ¨ç†ã€‚ `yolov5s` æ˜¯æœ€è½»ã€æœ€å¿«çš„ YOLOv5 æ¨¡å‹ã€‚ æœ‰å…³æ‰€æœ‰å¯ç”¨æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [README](https://github.com/Oneflow-Inc/one-yolov5#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A3%80%E6%9F%A5%E7%82%B9) ã€‚

```python
import oneflow as flow

# æ¨¡å‹
model = flow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom

# å›¾åƒ
img = 'https://raw.githubusercontent.com/Oneflow-Inc/one-yolov5/main/data/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list

# æ¨ç†
results = model(img)

# ç»“æœ
results.print()  # or .show(), .save(), .crop(), .pandas(), etc.
print(results.pandas().xyxy[0])


         xmin        ymin         xmax        ymax  confidence  class    name
0  743.290649   48.343842  1141.756348  720.000000    0.879861      0  person
1  441.989624  437.336670   496.585083  710.036255    0.675118     27     tie
2  123.051117  193.237976   714.690674  719.771362    0.666694      0  person
3  978.989807  313.579468  1025.302856  415.526184    0.261517     27     tie
```

#### æ›´ç»†èŠ‚çš„ä¾‹å­

è¿™ä¸ªä¾‹å­å±•ç¤ºäº†ä½¿ç”¨ PIL å’Œ OpenCV åˆ†åˆ«ä½œä¸ºå›¾åƒæºçš„æ‰¹é‡æ¨ç†ã€‚`result` å¯ä»¥æ‰“å°åˆ°æ§åˆ¶å°ï¼Œä¿å­˜åˆ° `runs/hub` , åœ¨æ”¯æŒçš„ç¯å¢ƒä¸­æ˜¾ç¤ºåˆ°å±å¹•ä¸Šï¼Œå¹¶ä½œä¸ºå¼ é‡æˆ– pandas æ•°æ®è¿”å›ã€‚

```python
import cv2
import oneflow as flow
from PIL import Image

# Model
model = flow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s')

# Images
for f in 'zidane.jpg', 'bus.jpg':
    flow.hub.download_url_to_file('https://ultralytics.com/images/' + f, f)  # download 2 images
im1 = Image.open('zidane.jpg')  # PIL image
im2 = cv2.imread('bus.jpg')[..., ::-1]  # OpenCV image (BGR to RGB)

# Inference
results = model([im1, im2], size=640) # batch of images

# Results
results.print()  
results.save()  # or .show()

results.xyxy[0]  # im1 predictions (tensor)
print(results.pandas().xyxy[0])  # im1 predictions (pandas)
```

<center class="half">
    <img src="https://user-images.githubusercontent.com/26833433/124915064-62a49e00-dff1-11eb-86b3-a85b97061afb.jpg" width="400"/><img src="https://user-images.githubusercontent.com/26833433/124915055-60424400-dff1-11eb-9055-24585b375a29.jpg" width="200"/><img src="å›¾ç‰‡é“¾æ¥" width="200"/>
</center>

å¯¹äºæ‰€æœ‰æ¨ç†é€‰é¡¹ï¼Œè¯·å‚é˜… [YOLOv5 `AutoShape()` forwardæ–¹æ³•](https://github.com/Oneflow-Inc/one-yolov5/blob/main/models/common.py#L566)ã€‚

#### æ¨ç†è®¾ç½®

YOLOv5 æ¨¡å‹åŒ…å«å„ç§æ¨ç†å±æ€§ï¼Œä¾‹å¦‚ç½®ä¿¡åº¦é˜ˆå€¼ã€IoU é˜ˆå€¼ç­‰ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½®ï¼š

```python
model.conf = 0.25  # NMS confidence threshold
      iou = 0.45  # NMS IoU threshold
      agnostic = False  # NMS class-agnostic
      multi_label = False  # NMS multiple labels per box
      classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs
      max_det = 1000  # maximum number of detections per image
      amp = False  # Automatic Mixed Precision (AMP) inference

results = model(im, size=320)  # custom inference size
```

#### è®¾å¤‡

æ¨¡å‹åˆ›å»ºåå¯ä»¥è¿ç§»åˆ°ä»»æ„è®¾å¤‡ä¸Š

```python
model.cpu()  # CPU
model.cuda()  # GPU
model.to(device)  # i.e. device=flow.device(0)
```

æ¨¡å‹ä¹Ÿå¯ä»¥åœ¨ä»»æ„ `device` ä¸Šç›´æ¥åˆ›å»ºï¼š

```python
model = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s', device='cpu') # load on CPU
```

ğŸ’¡ ä¸“å®¶æç¤ºï¼š åœ¨æ¨ç†ä¹‹å‰ï¼Œè¾“å…¥å›¾åƒä¹Ÿä¼šè‡ªåŠ¨ä¼ è¾“åˆ°æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡ä¸Šã€‚

#### é™éŸ³è¾“å‡º

ä½¿ç”¨ `_verbose=False` ,æ¨¡å‹å¯ä»¥è¢«é™éŸ³çš„åŠ è½½ï¼š

```python
model = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s', _verbose=False)  # load silently
```

#### è¾“å…¥é€šé“

```python
model = flow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s', channels=4)
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹é™¤äº†ç¬¬ä¸€ä¸ªè¾“å…¥å±‚å¤–å°†ç”±é¢„è®­ç»ƒçš„æƒé‡ç»„æˆï¼Œå®ƒä¸å†ä¸é¢„è®­ç»ƒçš„è¾“å…¥å±‚å…·æœ‰ç›¸åŒçš„å½¢çŠ¶ã€‚ è¾“å…¥å±‚å°†ä¿æŒç”±éšæœºæƒé‡åˆå§‹åŒ–ã€‚

#### ç±»åˆ«æ•°

è¦åŠ è½½å…·æœ‰ 10 ä¸ªè¾“å‡ºç±»è€Œä¸æ˜¯é»˜è®¤çš„ 80 ä¸ªè¾“å‡ºç±»çš„é¢„è®­ç»ƒ YOLOv5s æ¨¡å‹ï¼š

```python
model = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s', classes=10)
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹é™¤äº†è¾“å‡ºå±‚å°†ç”±é¢„è®­ç»ƒçš„æƒé‡ç»„æˆï¼Œå®ƒä»¬ä¸å†ä¸é¢„è®­ç»ƒçš„è¾“å‡ºå±‚å…·æœ‰ç›¸åŒçš„å½¢çŠ¶ã€‚ è¾“å‡ºå±‚å°†ä¿æŒç”±éšæœºæƒé‡åˆå§‹åŒ–ã€‚

#### å¼ºåˆ¶é‡æ–°åŠ è½½

å¦‚æœæ‚¨åœ¨ä¸Šè¿°æ­¥éª¤ä¸­é‡åˆ°é—®é¢˜ï¼Œè®¾ç½® `force_reload=True` å¯èƒ½æœ‰åŠ©äºä¸¢å¼ƒç°æœ‰ç¼“å­˜å¹¶å¼ºåˆ¶ä» OneFlow Hub é‡æ–°ä¸‹è½½æœ€æ–°çš„ YOLOv5 ç‰ˆæœ¬ã€‚

#### æˆªå›¾æ¨ç†

è¦åœ¨æ¡Œé¢å±å¹•ä¸Šè¿è¡Œæ¨ç†ï¼š

```python

import oneflow as flow

from PIL import ImageGrab

# Model
model = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s', _verbose=False)

# Image
im = ImageGrab.grab()  # take a screenshot

# Inference
results = model(im)
```

#### å¤š GPU æ¨ç†

YOLOv5 æ¨¡å‹å¯ä»¥åŠ è½½åˆ°å¤šä¸ª GPU å®ç°å¤šçº¿ç¨‹æ¨ç†ï¼š

```python
import oneflow as flow
import threading

def run(model, im):
  results = model(im)
  results.save()

# Models
model0 = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s', device=0)
model1 = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s', device=1)

# Inference
threading.Thread(target=run, args=[model0, 'https://ultralytics.com/images/zidane.jpg'], daemon=True).start()
threading.Thread(target=run, args=[model1, 'https://ultralytics.com/images/bus.jpg'], daemon=True).start()
```

#### è®­ç»ƒ
è¦åŠ è½½ YOLOv5 æ¨¡å‹è¿›è¡Œè®­ç»ƒè€Œä¸æ˜¯æ¨ç†ï¼Œè¯·è®¾ç½® autoshape=Falseã€‚ è¦åŠ è½½å…·æœ‰éšæœºåˆå§‹åŒ–æƒé‡çš„æ¨¡å‹ï¼ˆä»å¤´å¼€å§‹è®­ç»ƒï¼‰ï¼Œè¯·ä½¿ç”¨ pretrained=Falseã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¿…é¡»æä¾›è‡ªå·±çš„è®­ç»ƒè„šæœ¬ã€‚ æˆ–è€…ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„ [YOLOv5 è®­ç»ƒè‡ªå®šä¹‰æ•°æ®æ•™ç¨‹](https://start.oneflow.org/oneflow-yolo-doc/tutorials/03_chapter/model_train.html)è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚

```python
model = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s', autoshape=False)  # load pretrained
model = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'yolov5s', autoshape=False, pretrained=False)  # load scratch
```

#### Base64 ç»“æœ

ç”¨äº API æœåŠ¡ã€‚ æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [#2291](https://github.com/ultralytics/yolov5/pull/2291) å’Œ [Flask REST API](https://github.com/ultralytics/yolov5/tree/master/utils/flask_rest_api) ç¤ºä¾‹ã€‚

```python
results = model(im)  # inference

results.ims # array of original images (as np array) passed to model for inference
results.render()  # updates results.ims with boxes and labels
for im in results.ims:
    buffered = BytesIO()
    im_base64 = Image.fromarray(im)
    im_base64.save(buffered, format="JPEG")
    print(base64.b64encode(buffered.getvalue()).decode('utf-8'))  # base64 encoded image with results
```

#### è£å‰ªç»“æœ

è¿”å›çš„æ£€æµ‹ç»“æœå¯ä»¥è¢«è£å‰ªï¼š

```python
results = model(im)  # inference
crops = results.crop(save=True)  # cropped detections dictionary
```

#### Pandas ç»“æœ

ç»“æœå¯ä»¥ä½œä¸º[Pandas DataFrames](https://pandas.pydata.org/)è¿”å›ï¼š

```python
results = model(im)  # inference
results.pandas().xyxy[0]  # Pandas DataFrame
```

<details>
  <summary>Pandasè¾“å‡ºï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>
  <pre><code> 
    print(results.pandas().xyxy[0])
    xmin        ymin         xmax        ymax  confidence  class    name
    0  743.290649   48.343842  1141.756348  720.000000    0.879861      0  person
    1  441.989624  437.336670   496.585083  710.036255    0.675118     27     tie
    2  123.051117  193.237976   714.690674  719.771362    0.666694      0  person
    3  978.989807  313.579468  1025.302856  415.526184    0.261517     27     tie
  </code></pre>
</details>

#### æ’åºåçš„ç»“æœ

ç»“æœå¯ä»¥æŒ‰åˆ—æ’åºï¼Œä¾‹å¦‚ä»å·¦åˆ°å³ï¼ˆxè½´ï¼‰å¯¹è½¦ç‰Œæ•°å­—æ£€æµ‹ç»“æœè¿›è¡Œæ’åºï¼š

```python
results = model(im)  # inference
results.pandas().xyxy[0].sort_values('xmin')  # sorted left-right
```

#### Box-Cropped ç»“æœ

ç»“æœå¯ä»¥è¿”å›å¹¶ä¿å­˜ä¸º detection cropsï¼š

```python
results = model(im)  # inference
crops = results.crop(save=True)  # cropped detections dictionary
```

#### JSON ç»“æœ

ç»“æœä¸€æ—¦ä½¿ç”¨ `.pandas` è¢«ä¿å­˜ä¸º pandas æ•°æ®æ ¼å¼ï¼Œå°±å¯ä»¥å†ä½¿ç”¨ `.to_json()` æ–¹æ³•ä¿å­˜ä¸º JSON æ ¼å¼ã€‚å¯ä»¥ä½¿ç”¨ `orient` å‚æ•°ä¿®æ”¹ JSON æ ¼å¼ã€‚è¯·æŸ¥çœ‹ pandas çš„ `.to_json()` æ–¹æ³•çš„[æ–‡æ¡£](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html)äº†è§£ç»†èŠ‚ã€‚

```python
results = model(ims)  # inference
results.pandas().xyxy[0].to_json(orient="records")  # JSON img1 predictions
```

<details>
  <summary>Jsonè¾“å‡ºï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>
  <pre><code> 
    [{"xmin":743.2906494141,"ymin":48.3438415527,"xmax":1141.7563476562,"ymax":720.0,"confidence":0.87986058,"class":0,"name":"person"},{"xmin":441.9896240234,"ymin":437.3366699219,"xmax":496.5850830078,"ymax":710.0362548828,"confidence":0.6751183867,"class":27,"name":"tie"},{"xmin":123.0511169434,"ymin":193.2379760742,"xmax":714.6906738281,"ymax":719.7713623047,"confidence":0.6666944027,"class":0,"name":"person"},{"xmin":978.9898071289,"ymin":313.5794677734,"xmax":1025.3028564453,"ymax":415.526184082,"confidence":0.2615173161,"class":27,"name":"tie"}]
  </code></pre>
</details>


#### è‡ªå®šä¹‰æ¨¡å‹

è¿™ä¸ªä¾‹å­å±•ç¤ºä½¿ç”¨ OneFlow Hub åŠ è½½ä¸€ä¸ªè‡ªå®šä¹‰çš„åœ¨VOCæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒçš„20ä¸ªç±»åˆ«çš„ YOLOV5s æ¨¡å‹ `best` ã€‚

```python
model = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'custom', path='path/to/best') # local model
model = oneflow.hub.load('/path/to/one-yolov5', 'custom', path='path/to/best') # local repo
```

#### TensorRT, ONNX å’Œ OpenVINO æ¨¡å‹

OneFlow Hub æ”¯æŒå¯¹å¤§å¤šæ•° YOLOv5 å¯¼å‡ºæ ¼å¼è¿›è¡Œæ¨ç†ï¼ŒåŒ…æ‹¬è‡ªå®šä¹‰è®­ç»ƒæ¨¡å‹ã€‚æŸ¥çœ‹ [TFLite, ONNX, CoreML, TensorRT æ¨¡å‹å¯¼å‡ºæ•™ç¨‹](https://start.oneflow.org/oneflow-yolo-doc/tutorials/06_chapter/export_onnx_tflite_tensorrt.html) æŸ¥çœ‹ç»†èŠ‚ã€‚

- ğŸ’¡ ä¸“å®¶æç¤ºï¼šåœ¨ [GPU benchmarks](https://github.com/ultralytics/yolov5/pull/6963) ä¸Š **TensorRT** å¯èƒ½æ¯”PyTorchå¿«3-5å€ã€‚
- ğŸ’¡ ä¸“å®¶æç¤ºï¼šåœ¨ [CPU benchmarks](https://github.com/ultralytics/yolov5/pull/6613)  ä¸Š **ONNX** å’Œ **OpenVINO** å¯èƒ½æ¯” PyTorch å¿«2-3å€ã€‚

```python
model = oneflow.hub.load('Oneflow-Inc/one-yolov5', 'custom', path='yolov5s/')  # OneFlow
                                                            'yolov5s.onnx')  # ONNX
                                                            'yolov5s_openvino_model/')  # OpenVINO
                                                            'yolov5s.engine')  # TensorRT
                                                            'yolov5s.mlmodel')  # CoreML (macOS-only)
                                                            'yolov5s.tflite')  # TFLite
```


### å‚è€ƒæ–‡ç« 

- https://github.com/ultralytics/yolov5/issues/36
