## å‰è¨€

>ğŸ‰ä»£ç ä»“åº“åœ°å€ï¼š<a href="https://github.com/Oneflow-Inc/one-yolov5" target="blank">https://github.com/Oneflow-Inc/one-yolov5</a>
æ¬¢è¿star [one-yolov5é¡¹ç›®](https://github.com/Oneflow-Inc/one-yolov5) è·å–<a href="https://github.com/Oneflow-Inc/one-yolov5/tags" target="blank" >æœ€æ–°çš„åŠ¨æ€ã€‚</a>
<a href="https://github.com/Oneflow-Inc/one-yolov5/issues/new"  target="blank"  >å¦‚æœæ‚¨æœ‰é—®é¢˜ï¼Œæ¬¢è¿åœ¨ä»“åº“ç»™æˆ‘ä»¬æå‡ºå®è´µçš„æ„è§ã€‚ğŸŒŸğŸŒŸğŸŒŸ</a>
<a href="https://github.com/Oneflow-Inc/one-yolov5" target="blank" >
å¦‚æœå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿æ¥ç»™æˆ‘Starå‘€ğŸ˜Š~  </a>


æºç è§£è¯»ï¼š [detect.py](https://github.com/Oneflow-Inc/one-yolov5/blob/main/detect.py)

> Run inference with a YOLOv5 model on images, videos, directories, streams

## 1. å¯¼å…¥éœ€è¦çš„åŒ…å’ŒåŸºæœ¬é…ç½®


```python
import argparse  # pythonçš„å‘½ä»¤è¡Œè§£æçš„æ ‡å‡†æ¨¡å—  å¯ä»¥è®©æˆ‘ä»¬ç›´æ¥åœ¨å‘½ä»¤è¡Œä¸­å°±å¯ä»¥å‘ç¨‹åºä¸­ä¼ å…¥å‚æ•°å¹¶è®©ç¨‹åºè¿è¡Œ
import os #  osåº“æ˜¯Pythonæ ‡å‡†åº“,åŒ…å«å‡ ç™¾ä¸ªå‡½æ•°,å¸¸ç”¨è·¯å¾„æ“ä½œã€è¿›ç¨‹ç®¡ç†ã€ç¯å¢ƒå‚æ•°ç­‰å‡ ç±»ã€‚
import platform # ç”¨platformæ¨¡å—å¯ä»¥åˆ¤æ–­å½“å‰çš„ç³»ç»Ÿç¯å¢ƒ
import sys  # sysç³»ç»Ÿæ¨¡å— åŒ…å«äº†ä¸Pythonè§£é‡Šå™¨å’Œå®ƒçš„ç¯å¢ƒæœ‰å…³çš„å‡½æ•°
from pathlib import Path # Pathå°†strè½¬æ¢ä¸ºPathå¯¹è±¡ ä½¿å­—ç¬¦ä¸²è·¯å¾„æ˜“äºæ“ä½œçš„æ¨¡å—

import numpy as np # Numpyæ˜¯ä½¿ç”¨Cè¯­è¨€å®ç°çš„ä¸€ä¸ªæ•°æ®è®¡ç®—åº“
import oneflow as flow # OneFlowæ¡†æ¶
import oneflow.backends.cudnn as cudnn

from models.common import DetectMultiBackend
from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams
from utils.general import LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2, increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh
from utils.plots import Annotator, colors, save_one_box
from utils.oneflow_utils import select_device, time_sync

FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]  # YOLOv5 root directory
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # add ROOT to PATH
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative
```

## 2. optå‚æ•°è¯¦è§£


| å‚æ•°           | è§£æ                                             |                                                                                                                           |
|----------------|--------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|
| weights        | model path(s)                                    | æ¨¡å‹çš„æƒé‡åœ°å€                                                                                                            |
| source         | file/dir/URL/glob, 0 for webcam                  | æµ‹è¯•æ•°æ®æ–‡ä»¶(å›¾ç‰‡æˆ–è§†é¢‘)çš„ä¿å­˜è·¯å¾„ é»˜è®¤data/images                                                                        |
| data           | (optional) dataset.yaml path                     | æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„                                                                                                        |
| imgsz          | inference size h,w                               | ç½‘ç»œè¾“å…¥å›¾ç‰‡çš„å¤§å° é»˜è®¤640                                                                                                |
| conf-thres     | confidence threshold                             | objectç½®ä¿¡åº¦é˜ˆå€¼ é»˜è®¤0.25                                                                                                 |
| iou-thres      | NMS IoU threshold                                | åšnmsçš„ioué˜ˆå€¼ é»˜è®¤0.45                                                                                                   |
| max-det        | maximum detections per image                     | æ¯å¼ å›¾ç‰‡æœ€å¤§çš„ç›®æ ‡ä¸ªæ•° é»˜è®¤1000                                                                                           |
| device         | cuda device, i.e. 0 or 0,1,2,3 or cpu            | è®¾ç½®ä»£ç æ‰§è¡Œçš„è®¾å¤‡ cuda device, i.e. 0 or 0,1,2,3 or cpu                                                                  |
| view-img       | show results                                     | æ˜¯å¦å±•ç¤ºé¢„æµ‹ä¹‹åçš„å›¾ç‰‡æˆ–è§†é¢‘ é»˜è®¤False                                                                                    |
| save-txt       | save results to *.txt                            | æ˜¯å¦å°†é¢„æµ‹çš„æ¡†åæ ‡ä»¥txtæ–‡ä»¶æ ¼å¼ä¿å­˜ é»˜è®¤False ä¼šåœ¨runs/detect/expn/labelsä¸‹ç”Ÿæˆæ¯å¼ å›¾ç‰‡é¢„æµ‹çš„txtæ–‡ä»¶                      |
| save-conf      | save confidences in --save-txt labels            | æ˜¯å¦ä¿å­˜é¢„æµ‹æ¯ä¸ªç›®æ ‡çš„ç½®ä¿¡åº¦åˆ°é¢„æµ‹txæ–‡ä»¶ä¸­ é»˜è®¤False                                                                      |
| save-crop      | save cropped prediction boxes                    | æ˜¯å¦éœ€è¦å°†é¢„æµ‹åˆ°çš„ç›®æ ‡ä»åŸå›¾ä¸­æ‰£å‡ºæ¥ å‰ªåˆ‡å¥½ å¹¶ä¿å­˜ ä¼šåœ¨runs/detect/expnä¸‹ç”Ÿæˆcropsæ–‡ä»¶ï¼Œå°†å‰ªåˆ‡çš„å›¾ç‰‡ä¿å­˜åœ¨é‡Œé¢  é»˜è®¤False |
| nosave         | do not save images/videos                        | æ˜¯å¦ä¸è¦ä¿å­˜é¢„æµ‹åçš„å›¾ç‰‡  é»˜è®¤False å°±æ˜¯é»˜è®¤è¦ä¿å­˜é¢„æµ‹åçš„å›¾ç‰‡                                                            |
| classes        | filter by class: --classes 0, or --classes 0 2 3 | åœ¨nmsä¸­æ˜¯å¦æ˜¯åªä¿ç•™æŸäº›ç‰¹å®šçš„ç±» é»˜è®¤æ˜¯None å°±æ˜¯æ‰€æœ‰ç±»åªè¦æ»¡è¶³æ¡ä»¶éƒ½å¯ä»¥ä¿ç•™                                               |
| agnostic-nms   | class-agnostic NMS                               | è¿›è¡Œnmsæ˜¯å¦ä¹Ÿé™¤å»ä¸åŒç±»åˆ«ä¹‹é—´çš„æ¡† é»˜è®¤False                                                                               |
| augment        | augmented inference                              | é¢„æµ‹æ˜¯å¦ä¹Ÿè¦é‡‡ç”¨æ•°æ®å¢å¼º TTA                                                                                              |
| visualize      | visualize features                               | å¯è§†åŒ–ç‰¹å¾                                                                                                                |
| update         | update all models                                | æ˜¯å¦å°†optimizerä»ckptä¸­åˆ é™¤  æ›´æ–°æ¨¡å‹  é»˜è®¤False                                                                          |
| project        | save results to project/name                     | å½“å‰æµ‹è¯•ç»“æœæ”¾åœ¨å“ªä¸ªä¸»æ–‡ä»¶å¤¹ä¸‹ é»˜è®¤runs/detect                                                                            |
| name           | save results to project/name                     | å½“å‰æµ‹è¯•ç»“æœæ”¾åœ¨run/detectä¸‹çš„æ–‡ä»¶å  é»˜è®¤æ˜¯exp                                                                           |
| exist-ok       | existing project/name ok, do not increment       | æ˜¯å¦å­˜åœ¨å½“å‰æ–‡ä»¶ é»˜è®¤False ä¸€èˆ¬æ˜¯ no exist-ok è¿ç”¨  æ‰€ä»¥ä¸€èˆ¬éƒ½è¦é‡æ–°åˆ›å»ºæ–‡ä»¶å¤¹                                            |
| line-thickness | bounding box thickness (pixels)                  | ç”»æ¡†çš„æ¡†æ¡†çš„çº¿å®½  é»˜è®¤æ˜¯ 3                                                                                                |
| hide-labels    | hide labels                                      | ç”»å‡ºçš„æ¡†æ¡†æ˜¯å¦éœ€è¦éšè—labelä¿¡æ¯ é»˜è®¤False                                                                                 |
| hide-conf      | hide confidences                                 | ç”»å‡ºçš„æ¡†æ¡†æ˜¯å¦éœ€è¦éšè—labelä¿¡æ¯ é»˜è®¤False                                                                                 |
| half           | use FP16 half-precision inference                | ç”»å‡ºçš„æ¡†æ¡†æ˜¯å¦éœ€è¦éšè—confä¿¡æ¯ é»˜è®¤False                                                                                  |
| dnn            | use OpenCV DNN for ONNX inference                | æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦ Float16 æ¨ç† å¯ä»¥ç¼©çŸ­æ¨ç†æ—¶é—´ ä½†æ˜¯é»˜è®¤æ˜¯False                                                              |

## 3 mainå‡½æ•°


```python
def main(opt):
    # æ£€æŸ¥åŒ…æ˜¯å¦æ»¡è¶³requirementså¯¹åº”txtæ–‡ä»¶çš„è¦æ±‚
    check_requirements(exclude=('tensorboard', 'thop'))
    # æ‰§è¡Œrun å¼€å§‹æ¨ç†
    run(**vars(opt))
```

## 4 runå‡½æ•°


```python

@flow.no_grad()
def run(
    weights=ROOT / "yolov5s",  # model path(s)
    source=ROOT / "data/images",  # file/dir/URL/glob, 0 for webcam
    data=ROOT / "data/coco128.yaml",  # dataset.yaml path
    imgsz=(640, 640),  # inference size (height, width)
    conf_thres=0.25,  # confidence threshold
    iou_thres=0.45,  # NMS IOU threshold
    max_det=1000,  # maximum detections per image
    device="",  # cuda device, i.e. 0 or 0,1,2,3 or cpu
    view_img=False,  # show results
    save_txt=False,  # save results to *.txt
    save_conf=False,  # save confidences in --save-txt labels
    save_crop=False,  # save cropped prediction boxes
    nosave=False,  # do not save images/videos
    classes=None,  # filter by class: --class 0, or --class 0 2 3
    agnostic_nms=False,  # class-agnostic NMS
    augment=False,  # augmented inference
    visualize=False,  # visualize features
    update=False,  # update all models
    project=ROOT / "runs/detect",  # save results to project/name
    name="exp",  # save results to project/name
    exist_ok=False,  # existing project/name ok, do not increment
    line_thickness=3,  # bounding box thickness (pixels)
    hide_labels=False,  # hide labels
    hide_conf=False,  # hide confidences
    half=False,  # use FP16 half-precision inference
    dnn=False,  # use OpenCV DNN for ONNX inference
):
    source = str(source)
    # æ˜¯å¦ä¿å­˜é¢„æµ‹åçš„å›¾ç‰‡ é»˜è®¤nosave=False æ‰€ä»¥åªè¦ä¼ å…¥çš„æ–‡ä»¶åœ°å€ä¸æ˜¯ä»¥.txtç»“å°¾ å°±éƒ½æ˜¯è¦ä¿å­˜é¢„æµ‹åçš„å›¾ç‰‡çš„
    save_img = not nosave and not source.endswith(".txt")  # save inference images
    # æ–‡ä»¶ç±»å‹
    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)
    # æ˜¯å¦æ˜¯urlç½‘ç»œåœ°å€
    is_url = source.lower().startswith(("rtsp://", "rtmp://", "http://", "https://"))
    # æ˜¯å¦æ˜¯ä½¿ç”¨webcam ç½‘é¡µæ•°æ® ä¸€èˆ¬æ˜¯Fasle  å› ä¸ºæˆ‘ä»¬ä¸€èˆ¬æ˜¯ä½¿ç”¨å›¾ç‰‡æµLoadImages(å¯ä»¥å¤„ç†å›¾ç‰‡/è§†é¢‘æµæ–‡ä»¶)
    webcam = source.isnumeric() or source.endswith(".txt") or (is_url and not is_file)
    if is_url and is_file: 
        source = check_file(source)  # download

    # Directories
    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # å¢é‡è¿è¡Œ
    (save_dir / "labels" if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # åˆ›å»ºæ–‡ä»¶å¤¹ç”¨äºå­˜å‚¨è¾“å‡ºç»“æœ

    # Load model
    device = select_device(device) # è·å–å½“å‰ä¸»æœºå¯ç”¨çš„è®¾å¤‡
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)
    # stride: æ¨¡å‹æœ€å¤§çš„ä¸‹é‡‡æ ·ç‡ [8, 16, 32] æ‰€æœ‰strideä¸€èˆ¬ä¸º32
    # names: å¾—åˆ°æ•°æ®é›†çš„æ‰€æœ‰ç±»çš„ç±»å
    # of : oneflowæ¨¡å‹æƒé‡æ–‡ä»¶
    stride, names, of = model.stride, model.names, model.of
    
    #  ç¡®ä¿è¾“å…¥å›¾ç‰‡çš„å°ºå¯¸imgszèƒ½æ•´é™¤stride  å¦‚æœä¸èƒ½åˆ™è°ƒæ•´ä¸ºèƒ½è¢«æ•´é™¤å¹¶è¿”å›
    imgsz = check_img_size(imgsz, s=stride)  # check image size

    # Dataloader
    if webcam:  # ä¸€èˆ¬ä¸ä¼šä½¿ç”¨webcamæ¨¡å¼ä»ç½‘é¡µä¸­è·å–æ•°æ®
        view_img = check_imshow()
        cudnn.benchmark = True  # è®¾ç½®ä¸ºTrueï¼Œä½¿ç”¨CUDNNä»¥åŠ å¿«æ’å®šå›¾åƒå°ºå¯¸æ¨æ–­çš„é€Ÿåº¦
        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=of)
        bs = len(dataset)  # batch_size
    else: # ä¸€èˆ¬æ˜¯ç›´æ¥ä»sourceæ–‡ä»¶ç›®å½•ä¸‹ç›´æ¥è¯»å–å›¾ç‰‡æˆ–è€…è§†é¢‘æ•°æ®
        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=of)
        bs = 1  # batch_size
    vid_path, vid_writer = [None] * bs, [None] * bs

    # Run inference æ­£å¼æ¨ç†
    model.warmup(imgsz=(1 if of else bs, 3, *imgsz))  # warmup

    seen, windows, dt = 0, [], [0.0, 0.0, 0.0]
    for path, im, im0s, vid_cap, s in dataset:
        t1 = time_sync()
        im = flow.from_numpy(im).to(device)
        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32
        im /= 255  # 0 - 255 to 0.0 - 1.0
        if len(im.shape) == 3:
            im = im[None]  # expand for batch dim
        t2 = time_sync()
        dt[0] += t2 - t1

        # Inference
        visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False
        pred = model(im, augment=augment, visualize=visualize)
        t3 = time_sync()
        dt[1] += t3 - t2

        # NMS å»æ‰detectionä»»åŠ¡é‡å¤çš„æ£€æµ‹æ¡†ã€‚è·Ÿå¤šè¯·å‚é˜… https://blog.csdn.net/yql_617540298/article/details/89474226
        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)
        dt[2] += time_sync() - t3

        # Second-stage classifier (optional)
        # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)

        # Process predictions
        for i, det in enumerate(pred):  # per image  å¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œå¤„ç†  å°†pred(ç›¸å¯¹img_size 640)æ˜ å°„å›åŸå›¾img0 size
            seen += 1
            if webcam:  # batch_size >= 1
                p, im0, frame = path[i], im0s[i].copy(), dataset.count
                s += f"{i}: "
            else:
                p, im0, frame = path, im0s.copy(), getattr(dataset, "frame", 0)

            p = Path(p)  # to Path
            save_path = str(save_dir / p.name)  # im.jpg
            txt_path = str(save_dir / "labels" / p.stem) + ("" if dataset.mode == "image" else f"_{frame}")  # im.txt
            s += "%gx%g " % im.shape[2:]  # print string
            gn = flow.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
            imc = im0.copy() if save_crop else im0  # for save_crop
            annotator = Annotator(im0, line_width=line_thickness, example=str(names))
            if len(det):
                # Rescale boxes from img_size to im0 size
                # å°†é¢„æµ‹ä¿¡æ¯ï¼ˆç›¸å¯¹img_size 640ï¼‰æ˜ å°„å›åŸå›¾ img0 size
                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()

                det = det.detach().cpu().numpy()

                # Print results
                # è¾“å‡ºä¿¡æ¯s + æ£€æµ‹åˆ°çš„å„ä¸ªç±»åˆ«çš„ç›®æ ‡ä¸ªæ•°
                for c in np.unique(det[:, -1]):
                    n = (det[:, -1] == c).sum()  # detections per class
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string

                # Write results
                # ä¿å­˜é¢„æµ‹ä¿¡æ¯: txtã€img0ä¸Šç”»æ¡†ã€crop_img
                for *xyxy, conf, cls in reversed(det):
                    # å°†æ¯ä¸ªå›¾ç‰‡çš„é¢„æµ‹ä¿¡æ¯åˆ†åˆ«å­˜å…¥save_dir/labelsä¸‹çš„xxx.txtä¸­ æ¯è¡Œ: class_id+score+xywh
                    if save_txt:  # Write to file
                        # å°†xyxy(å·¦ä¸Šè§’ + å³ä¸‹è§’)æ ¼å¼è½¬æ¢ä¸ºxywh(ä¸­å¿ƒçš„ + å®½é«˜)æ ¼å¼ å¹¶é™¤ä»¥gn(whwh)åšå½’ä¸€åŒ– è½¬ä¸ºlistå†ä¿å­˜
                        xywh = (xyxy2xywh(flow.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format
                        with open(f"{txt_path}.txt", "a") as f:
                            f.write(("%g " * len(line)).rstrip() % line + "\n")
                    
                    # åœ¨åŸå›¾ä¸Šç”»æ¡† + å°†é¢„æµ‹åˆ°çš„ç›®æ ‡å‰ªåˆ‡å‡ºæ¥ 
                    if save_img or save_crop or view_img:  # Add bbox to image
                        c = int(cls)  # integer class
                        label = None if hide_labels else (names[c] if hide_conf else f"{names[c]} {conf:.2f}")
                        annotator.box_label(xyxy, label, color=colors(c, True))
                    if save_crop:# å¦‚æœéœ€è¦å°±å°†é¢„æµ‹åˆ°çš„ç›®æ ‡å‰ªåˆ‡å‡ºæ¥ ä¿å­˜æˆå›¾ç‰‡ ä¿å­˜åœ¨save_dir/cropsä¸‹
                        save_one_box(
                            xyxy,
                            imc,
                            file=save_dir / "crops" / names[c] / f"{p.stem}.jpg",
                            BGR=True,
                        )

            # Stream results
            im0 = annotator.result()
            if view_img:
                if platform.system() == "Linux" and p not in windows:
                    windows.append(p)
                    cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux)
                    cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])
                cv2.imshow(str(p), im0)
                cv2.waitKey(1)  # 1 millisecond

            # Save results (image with detections)
            if save_img: # æ˜¯å¦éœ€è¦ä¿å­˜å›¾ç‰‡æˆ–è§†é¢‘ï¼ˆæ£€æµ‹åçš„å›¾ç‰‡/è§†é¢‘ é‡Œé¢å·²ç»è¢«æˆ‘ä»¬ç”»å¥½äº†æ¡†çš„ï¼‰ img0
                if dataset.mode == "image":
                    cv2.imwrite(save_path, im0)
                else:  # 'video' or 'stream'
                    if vid_path[i] != save_path:  # new video
                        vid_path[i] = save_path
                        if isinstance(vid_writer[i], cv2.VideoWriter):
                            vid_writer[i].release()  # release previous video writer
                        if vid_cap:  # video
                            fps = vid_cap.get(cv2.CAP_PROP_FPS)
                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                        else:  # stream
                            fps, w, h = 30, im0.shape[1], im0.shape[0]
                        save_path = str(Path(save_path).with_suffix(".mp4"))  # force *.mp4 suffix on results videos
                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))
                    vid_writer[i].write(im0)

        # Print time (inference-only)
        LOGGER.info(f"{s}Done. ({t3 - t2:.3f}s)")

    # Print results
    t = tuple(x / seen * 1e3 for x in dt)  # speeds per image
    LOGGER.info(f"%.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}" % t)
    if save_txt or save_img:
        s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ""
        LOGGER.info(f"Results saved to {colorstr('bold', save_dir)}{s}")
    if update:
        # strip_optimizerå‡½æ•°å°†optimizerä»ckptä¸­åˆ é™¤  æ›´æ–°æ¨¡å‹
        strip_optimizer(weights[0])  # update model (to fix SourceChangeWarning)
```
