## å‰è¨€

>ğŸ‰ä»£ç ä»“åº“åœ°å€ï¼š<a href="https://github.com/Oneflow-Inc/one-yolov5" target="blank">https://github.com/Oneflow-Inc/one-yolov5</a>
æ¬¢è¿star [one-yolov5é¡¹ç›®](https://github.com/Oneflow-Inc/one-yolov5) è·å–<a href="https://github.com/Oneflow-Inc/one-yolov5/tags" target="blank" >æœ€æ–°çš„åŠ¨æ€ã€‚</a>
<a href="https://github.com/Oneflow-Inc/one-yolov5/issues/new"  target="blank"  >å¦‚æœæ‚¨æœ‰é—®é¢˜ï¼Œæ¬¢è¿åœ¨ä»“åº“ç»™æˆ‘ä»¬æå‡ºå®è´µçš„æ„è§ã€‚ğŸŒŸğŸŒŸğŸŒŸ</a>
<a href="https://github.com/Oneflow-Inc/one-yolov5" target="blank" >
å¦‚æœå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿æ¥ç»™æˆ‘Starå‘€ğŸ˜Š~  </a>


æºç è§£è¯»ï¼š [val.py](https://github.com/Oneflow-Inc/one-yolov5/blob/main/val.py)

Ultralytics YOLOv5 å®˜æ–¹ç»™çš„ä»‹ç»:

> Validate a model's accuracy on [COCO](https://cocodataset.org/#home) val or test-dev datasets. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/Oneflow-Inc/one-yolov5/releases). To show results by class use the `--verbose` flag. Note that `pycocotools` metrics may be ~1% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation.



## 1.å¯¼å…¥éœ€è¦çš„åŒ…å’ŒåŸºæœ¬é…ç½®


```python
import argparse # è§£æå‘½ä»¤è¡Œå‚æ•°æ¨¡å—
import json     # å­—å…¸åˆ—è¡¨å’ŒJSONå­—ç¬¦ä¸²ä¹‹é—´çš„ç›¸äº’è§£ææ¨¡å—
import os       # ä¸æ“ä½œç³»ç»Ÿè¿›è¡Œäº¤äº’çš„æ¨¡å— åŒ…å«æ–‡ä»¶è·¯å¾„æ“ä½œå’Œè§£æ
import sys      # sysç³»ç»Ÿæ¨¡å— åŒ…å«äº†ä¸Pythonè§£é‡Šå™¨å’Œå®ƒçš„ç¯å¢ƒæœ‰å…³çš„å‡½æ•°
from pathlib import Path  # Pathå°†strè½¬æ¢ä¸ºPathå¯¹è±¡ ä½¿å­—ç¬¦ä¸²è·¯å¾„æ˜“äºæ“ä½œçš„æ¨¡å—

import numpy as np # NumPyï¼ˆNumerical Pythonï¼‰æ˜¯Pythonçš„ä¸€ç§å¼€æºçš„æ•°å€¼è®¡ç®—æ‰©å±•
import oneflow as flow # OneFlow æ·±åº¦å­¦ä¹ æ¡†æ¶
from tqdm import tqdm # è¿›åº¦æ¡æ¨¡å—
 
from models.common import DetectMultiBackend # ä¸‹é¢éƒ½æ˜¯ one-yolov5 å®šä¹‰çš„æ¨¡å—ï¼Œåœ¨æœ¬ç³»åˆ—çš„å…¶å®ƒæ–‡ç« éƒ½æœ‰æ¶‰åŠ
from utils.callbacks import Callbacks
from utils.dataloaders import create_dataloader
from utils.general import (
    LOGGER,
    check_dataset,
    check_img_size,
    check_requirements,
    check_yaml,
    coco80_to_coco91_class,
    colorstr,
    increment_path,
    non_max_suppression,
    print_args,
    scale_coords,
    xywh2xyxy,
    xyxy2xywh,
)
from utils.metrics import ConfusionMatrix, ap_per_class, box_iou
from utils.oneflow_utils import select_device, time_sync
from utils.plots import output_to_target, plot_images, plot_val_study
```

## 2.optå‚æ•°è¯¦è§£

| å‚æ•°        | è§£æ                                                                                            |                                                                     |
| ----------- | ----------------------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| data        | dataset.yaml path                                                                               | æ•°æ®é›†é…ç½®æ–‡ä»¶åœ°å€ åŒ…å«æ•°æ®é›†çš„è·¯å¾„ã€ç±»åˆ«ä¸ªæ•°ã€ç±»åã€ä¸‹è½½åœ°å€ç­‰ä¿¡æ¯ |
| weights     | model weights path(s)                                                                           | æ¨¡å‹çš„æƒé‡æ–‡ä»¶åœ°å€ weights/yolov5s                                  |
| batch-size  | batch size                                                                                      | è®¡ç®—æ ·æœ¬çš„æ‰¹æ¬¡å¤§å° é»˜è®¤32                                           |
| imgsz       | inference size (pixels)                                                                         | è¾“å…¥ç½‘ç»œçš„å›¾ç‰‡åˆ†è¾¨ç‡    é»˜è®¤640                                     |
| conf-thres  | confidence threshold                                                                            | objectç½®ä¿¡åº¦é˜ˆå€¼ é»˜è®¤0.001                                          |
| iou-thres   | NMS IoU threshold                                                                               | è¿›è¡ŒNMSæ—¶IOUçš„é˜ˆå€¼ é»˜è®¤0.6                                          |
| task        | train, val, test, speed or study                                                                | è®¾ç½®æµ‹è¯•çš„ç±»å‹ æœ‰train, val, test, speed or studyå‡ ç§ é»˜è®¤val       |
| device      | cuda device, i.e. 0 or 0,1,2,3 or cpu                                                           | æµ‹è¯•çš„è®¾å¤‡                                                          |
| workers     | max dataloader workers (per RANK in DDP mode)                                                   | åŠ è½½æ•°æ®ä½¿ç”¨çš„ dataloader workers                                   |
| single-cls  | treat as single-class dataset                                                                   | æ•°æ®é›†æ˜¯å¦åªç”¨ä¸€ä¸ªç±»åˆ« é»˜è®¤False                                    |
| augment     | [augmented inference](https://start.oneflow.org/oneflow-yolo-doc/tutorials/03_chapter/TTA.html) | æµ‹è¯•æ˜¯å¦ä½¿ç”¨TTA Test Time Augment é»˜è®¤False                         |
| verbose     | report mAP by class                                                                             | æ˜¯å¦æ‰“å°å‡ºæ¯ä¸ªç±»åˆ«çš„mAP é»˜è®¤False                                   |
| save-hybrid | save label+prediction hybrid results to *.txt                                                   | ä¿å­˜label+prediction æ‚äº¤ç»“æœåˆ°å¯¹åº”.txt é»˜è®¤False                    |
| save-conf   | save confidences in --save-txt labels                                                           |                                                                     |
| save-json   | save a COCO-JSON results file                                                                   | æ˜¯å¦æŒ‰ç…§cocoçš„jsonæ ¼å¼ä¿å­˜ç»“æœ       é»˜è®¤False                      |
| project     | save to project/name                                                                            | æµ‹è¯•ä¿å­˜çš„æºæ–‡ä»¶ é»˜è®¤`runs/val`                                     |
| name        | save to project/name                                                                            | æµ‹è¯•ä¿å­˜çš„æ–‡ä»¶åœ°å€å é»˜è®¤`exp`  ä¿å­˜åœ¨`runs/val/exp`ä¸‹              |
| exist-ok    | existing project/name ok, do not increment                                                      | æ˜¯å¦ä¿å­˜åœ¨å½“å‰æ–‡ä»¶ï¼Œä¸æ–°å¢ é»˜è®¤False                                            |
| half        | use FP16 half-precision inference                                                               | æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦æ¨ç† é»˜è®¤False                                        |
| dnn         | use OpenCV DNN for ONNX inference                                                               | æ˜¯å¦ä½¿ç”¨ `OpenCV DNN` å¯¹ `ONNX` æ¨¡å‹æ¨ç†                              |

## 3.[mainå‡½æ•°](https://github.com/Oneflow-Inc/one-yolov5/blob/bf8c66e011fcf5b8885068074ffc6b56c113a20c/val.py#L443)

> æ ¹æ®è§£æçš„optå‚æ•°ï¼Œè°ƒç”¨runå‡½æ•°


```python
def main(opt):
    #  æ£€æµ‹requirementsæ–‡ä»¶ä¸­éœ€è¦çš„åŒ…æ˜¯å¦å®‰è£…å¥½äº†
    check_requirements(requirements=ROOT / "requirements.txt", exclude=("tensorboard", "thop"))
    
    if opt.task in ("train", "val", "test"):  # run normally
        if opt.conf_thres > 0.001:  # æ›´å¤šè¯·è§ https://github.com/ultralytics/yolov5/issues/1466
            LOGGER.info(f"WARNING: confidence threshold {opt.conf_thres} > 0.001 produces invalid results")
        run(**vars(opt))

    else:
        weights = opt.weights if isinstance(opt.weights, list) else [opt.weights]
        opt.half = True  # FP16 for fastest results
        if opt.task == "speed":  # speed benchmarks
            # python val.py --task speed --data coco.yaml
            #                --batch 1 --weights yolov5n.pt yolov5s.pt...
            opt.conf_thres, opt.iou_thres, opt.save_json = 0.25, 0.45, False
            for opt.weights in weights:
                run(**vars(opt), plots=False)

        elif opt.task == "study":  # speed vs mAP benchmarks
            # python val.py --task study --data coco.yaml
            #                --iou 0.7 --weights yolov5n.pt yolov5s.pt...
            for opt.weights in weights:
                f = f"study_{Path(opt.data).stem}_{Path(opt.weights).stem}.txt"
                x, y = (
                    list(range(256, 1536 + 128, 128)),
                    [],
                )  # x axis (image sizes), y axis
                # "study": æ¨¡å‹åœ¨å„ä¸ªå°ºåº¦ä¸‹çš„æŒ‡æ ‡å¹¶å¯è§†åŒ–ï¼Œ
                # ä¸Šé¢list(range(256, 1536 + 128, 128)),ä»£è¡¨ img-size çš„å„ä¸ªå°ºåº¦, å…·ä½“ä»£ç å¦‚ä¸‹ï¼š
                for opt.imgsz in x:  # img-size
                    LOGGER.info(f"\nRunning {f} --imgsz {opt.imgsz}...")
                    r, _, t = run(**vars(opt), plots=False)
                    y.append(r + t)  # results and times
                np.savetxt(f, y, fmt="%10.4g")  # save
            os.system("zip -r study.zip study_*.txt")
            # å¯è§†åŒ–å„ä¸ªæŒ‡æ ‡
            plot_val_study(x=x)  # plot
```

## 3. runå‡½æ•°
> https://github.com/Oneflow-Inc/one-yolov5/blob/bf8c66e011fcf5b8885068074ffc6b56c113a20c/val.py#L112-L383

### 3.1 è½½å…¥å‚æ•°


```python
# ä¸å‚ä¸åå‘ä¼ æ’­
@flow.no_grad() 
def run(
    data,
    weights=None,  # model.pt path(s)
    batch_size=32,  # batch size
    imgsz=640,  # inference size (pixels)
    conf_thres=0.001,  # confidence threshold
    iou_thres=0.6,  # NMS IoU threshold
    task="val",  # train, val, test, speed or study
    device="",  # cuda device, i.e. 0 or 0,1,2,3 or cpu
    workers=8,  # max dataloader workers (per RANK in DDP mode)
    single_cls=False,  # treat as single-class dataset
    augment=False,  # augmented inference
    verbose=False,  # verbose output
    save_txt=False,  # save results to *.txt
    save_hybrid=False,  # save label+prediction hybrid results to *.txt
    save_conf=False,  # save confidences in --save-txt labels
    save_json=False,  # save a COCO-JSON results file
    project=ROOT / "runs/val",  # save to project/name
    name="exp",   # save to project/name
    exist_ok=False,  # existing project/name ok, do not increment
    half=True,    # use FP16 half-precision inference
    dnn=False,    # use OpenCV DNN for ONNX inference
    model=None,   # æ¨¡å‹ å¦‚æœæ‰§è¡Œval.pyå°±ä¸ºNone å¦‚æœæ‰§è¡Œtrain.pyå°±ä¼šä¼ å…¥( model=attempt_load(f, device).half() )
    dataloader=None,   # æ•°æ®åŠ è½½å™¨ å¦‚æœæ‰§è¡Œval.pyå°±ä¸ºNone å¦‚æœæ‰§è¡Œtrain.pyå°±ä¼šä¼ å…¥testloader
    save_dir=Path(""), # æ–‡ä»¶ä¿å­˜è·¯å¾„ å¦‚æœæ‰§è¡Œval.pyå°±ä¸ºâ€˜â€™ , å¦‚æœæ‰§è¡Œtrain.pyå°±ä¼šä¼ å…¥save_dir(runs/train/expn)
    plots=True,  # æ˜¯å¦å¯è§†åŒ– è¿è¡Œval.pyä¼ å…¥é»˜è®¤True 
    callbacks=Callbacks(), 
    compute_loss=None, # æŸå¤±å‡½æ•° è¿è¡Œval.pyä¼ å…¥é»˜è®¤None è¿è¡Œtrain.pyåˆ™ä¼ å…¥compute_loss(train)
):
```

### 3.2 Initialize/load model and set deviceï¼ˆåˆå§‹åŒ–/åŠ è½½æ¨¡å‹ä»¥åŠè®¾ç½®è®¾å¤‡ï¼‰


```python
  if training:  # called by train.py é€šè¿‡train.pyè°ƒç”¨çš„runå‡½æ•°
        device, of, engine = (
            next(model.parameters()).device,
            True,
            False,
        )  # get model device, OneFlow model
        half &= device.type != "cpu"  # half precision only supported on CUDA
        model.half() if half else model.float()
    else:  # called directly é€šè¿‡val.py è°ƒç”¨çš„runå‡½æ•°
        device = select_device(device, batch_size=batch_size)

        # Directories  ç”Ÿæˆsave_diræ–‡ä»¶è·¯å¾„  run/test/expn
        save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run
        (save_dir / "labels" if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir

        # Load model åŠ è½½æ¨¡å‹ 
        model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)
        
        stride, of, engine = model.stride, model.of, model.engine
        # æ£€æµ‹è¾“å…¥å›¾ç‰‡çš„åˆ†è¾¨ç‡imgszæ˜¯å¦èƒ½è¢«gsæ•´é™¤ 
        imgsz = check_img_size(imgsz, s=stride)  # check image size
        half = model.fp16  # FP16 supported on limited backends with CUDA
        if engine:
            batch_size = model.batch_size
        else:
            device = model.device
            if not of:
                batch_size = 1  # export.py models default to batch-size 1
                LOGGER.info(f"Forcing --batch-size 1 inference (1,3,{imgsz},{imgsz}) for non-OneFlow models")
        
        # Data
        data = check_dataset(data)  # check
```

### 3.3 Configure


```python
# é…ç½®
model.eval() # å¯åŠ¨æ¨¡å‹éªŒè¯æ¨¡å¼
cuda = device.type != "cpu"
is_coco = isinstance(data.get("val"), str) and data["val"].endswith(f"coco{os.sep}val2017.txt")  # COCO dataset
nc = 1 if single_cls else int(data["nc"])  # number of classes
# iouv: [0.50000, 0.55000, 0.60000, 0.65000, 0.70000, 0.75000, 0.80000, 0.85000, 0.90000, 0.95000]
iouv = flow.linspace(0.5, 0.95, 10, device=device)  # iou vector for mAP@0.5:0.95
niou = iouv.numel() # ç¤ºä¾‹ mAP@0.5:0.95 iouä¸ªæ•°=10ä¸ª
```

### 3.4 Dataloader
> é€šè¿‡train.pyè°ƒç”¨runå‡½æ•°ä¼šä¼ å…¥ä¸€ä¸ªDataloaderï¼Œè€Œé€šè¿‡val.pyéœ€è¦åŠ è½½æµ‹è¯•æ•°æ®é›†


```python
# Dataloader
if not training: # åŠ è½½valæ•°æ®é›†
    if of and not single_cls:  # check --weights are trained on --data
        ncm = model.model.nc
        assert ncm == nc, (
            f"{weights} ({ncm} classes) trained on different --data than what you passed ({nc} " f"classes). Pass correct combination of" f" --weights and --data that are trained together."
        )
    model.warmup(imgsz=(1 if of else batch_size, 3, imgsz, imgsz))  # warmup
    pad = 0.0 if task in ("speed", "benchmark") else 0.5
    rect = False if task == "benchmark" else of  # square inference for benchmarks
    task = task if task in ("train", "val", "test") else "val"  # path to train/val/test images
    # åˆ›å»ºdataloader è¿™é‡Œçš„recté»˜è®¤ä¸ºTrue çŸ©å½¢æ¨ç†ç”¨äºæµ‹è¯•é›† åœ¨ä¸å½±å“mAPçš„æƒ…å†µä¸‹å¯ä»¥å¤§å¤§æå‡æ¨ç†é€Ÿåº¦
    dataloader = create_dataloader(
        data[task],
        imgsz,
        batch_size,
        stride,
        single_cls,
        pad=pad,
        rect=rect,
        workers=workers,
        prefix=colorstr(f"{task}: "),
    )[0]
```

### 3.5 åˆå§‹åŒ–


```python
# åˆå§‹åŒ–éªŒè¯çš„å›¾ç‰‡çš„æ•°é‡
seen = 0
# åˆå§‹åŒ–æ··æ·†çŸ©é˜µ
confusion_matrix = ConfusionMatrix(nc=nc)

#  è·å–æ•°æ®é›†æ‰€æœ‰ç±»åˆ«çš„ç±»å
names = dict(enumerate(model.names if hasattr(model, "names") else model.module.names))

# coco80_to_coco91_class :  converts 80-index (val2014) to 91-index (paper) 
# https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/
class_map = coco80_to_coco91_class() if is_coco else list(range(1000))
# è®¾ç½®è¿›åº¦æ¡æ¨¡å—æ˜¾ç¤ºä¿¡æ¯
s = ("%20s" + "%11s" * 6) % (
    "Class",
    "Images",
    "Labels",
    "P",
    "R",
    "mAP@.5",
    "mAP@.5:.95",
)
# åˆå§‹åŒ–æ—¶é—´dt[t0, t1, t2] å’Œ p, r, f1, mp, mr, map50, mapæŒ‡æ ‡
dt, p, r, f1, mp, mr, map50, map = (
    [0.0, 0.0, 0.0],
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
)
#  åˆå§‹åŒ–éªŒè¯é›†çš„æŸå¤±
loss = flow.zeros(3, device=device)
#  åˆå§‹åŒ–jsonæ–‡ä»¶ä¸­çš„å­—å…¸ ç»Ÿè®¡ä¿¡æ¯ ap ap_class 
jdict, stats, ap, ap_class = [], [], [], []
callbacks.run("on_val_start")
# åˆå§‹åŒ–tqdm è¿›åº¦æ¡æ¨¡å—
pbar = tqdm(dataloader, desc=s, bar_format="{l_bar}{bar:10}{r_bar}{bar:-10b}")
```
<details open>
<summary>ç¤ºä¾‹è¾“å‡º </summary>

```python
val: data=data/coco.yaml, weights=['yolov5x'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, 
    device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, 
    save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False
YOLOv5 ğŸš€ v1.0-8-g94ec5c4 Python-3.8.13 oneflow-0.8.1.dev20221018+cu112 
Fusing layers... 
Model summary: 322 layers, 86705005 parameters, 571965 gradients
val: Scanning '/data/dataset/fengwen/coco/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:55<00:00,  1.36it/
                 all       5000      36335      0.743      0.627      0.685      0.503
Speed: 0.1ms pre-process, 7.5ms inference, 2.1ms NMS per image at shape (32, 3, 640, 640)  # <--- baseline speed

Evaluating pycocotools mAP... saving runs/val/exp3/yolov5x_predictions.json...

...
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505 # <--- baseline mAP
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.689
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.339
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.557
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.382
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677  # <--- baseline mAR
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.826
```
</details>



### 3.6 å¼€å§‹éªŒè¯


```python
for batch_i, (im, targets, paths, shapes) in enumerate(pbar):
""" https://github.com/Oneflow-Inc/one-yolov5/blob/bf8c66e011fcf5b8885068074ffc6b56c113a20c/utils/dataloaders.py#L735
im :  flow.from_numpy(img);
targets : labels_out 
paths: self.im_files[index] 
shapes : shapes
"""
```

#### 3.6.1 éªŒè¯å¼€å§‹å‰çš„é¢„å¤„ç†


```python
callbacks.run("on_val_batch_start")
t1 = time_sync()
if cuda:
    im = im.to(device)
    targets = targets.to(device)
im = im.half() if half else im.float()  # uint8 to fp16/32
im /= 255  # 0 - 255 to 0.0 - 1.0
nb, _, height, width = im.shape  # batch size, channels, height, width
t2 = time_sync()
dt[0] += t2 - t1
```

#### 3.6.2 æ¨ç†


```python
# Inference
out, train_out = model(im) if training else model(im, augment=augment, val=True)  # è¾“å‡ºä¸ºï¼šæ¨ç†ç»“æœã€æŸå¤±å€¼
dt[1] += time_sync() - t2
```

#### 3.6.3 è®¡ç®—æŸå¤±


```python
# Loss
"""
åˆ†ç±»æŸå¤±(cls_loss)ï¼šè¯¥æŸå¤±ç”¨äºåˆ¤æ–­æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿå‡†ç¡®åœ°è¯†åˆ«å‡ºå›¾åƒä¸­çš„å¯¹è±¡ï¼Œå¹¶å°†å…¶åˆ†ç±»åˆ°æ­£ç¡®çš„ç±»åˆ«ä¸­ã€‚

ç½®ä¿¡åº¦æŸå¤±(obj_loss)ï¼šè¯¥æŸå¤±ç”¨äºè¡¡é‡æ¨¡å‹é¢„æµ‹çš„æ¡†ï¼ˆå³åŒ…å«å¯¹è±¡çš„çŸ©å½¢ï¼‰ä¸çœŸå®æ¡†ä¹‹é—´çš„å·®å¼‚ã€‚

è¾¹ç•Œæ¡†æŸå¤±(box_loss)ï¼šè¯¥æŸå¤±ç”¨äºè¡¡é‡æ¨¡å‹é¢„æµ‹çš„è¾¹ç•Œæ¡†ä¸çœŸå®è¾¹ç•Œæ¡†ä¹‹é—´çš„å·®å¼‚ï¼Œè¿™æœ‰åŠ©äºç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®åœ°å®šä½å¯¹è±¡ã€‚
"""
if compute_loss:
    loss += compute_loss([x.float() for x in train_out], targets)[1]  # box, obj, cls
```

#### 3.6.4 Run NMS


```python
# NMS
# å°†çœŸå®æ¡†targetçš„xywh(å› ä¸ºtargetæ˜¯åœ¨labelimgä¸­åšäº†å½’ä¸€åŒ–çš„)æ˜ å°„åˆ°img(test)å°ºå¯¸
targets[:, 2:] *= flow.tensor((width, height, width, height), device=device)  # to pixels
# å¯¹åº”
lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []  # for autolabelling
t3 = time_sync()
"""non_max_suppression (éæœ€å¤§å€¼æŠ‘åˆ¶)
Non-Maximum Suppression (NMS) on inference results to reject overlapping bounding boxes
è¯¥ç®—æ³•çš„åŸç†ï¼š
å…ˆå‡è®¾æœ‰6ä¸ªçŸ©å½¢æ¡†ï¼Œæ ¹æ®åˆ†ç±»å™¨çš„ç±»åˆ«åˆ†ç±»æ¦‚ç‡å¤§å°æ’åºï¼Œå‡è®¾ä»å°åˆ°å¤§å±äºè½¦è¾†(è¢«æ£€æµ‹çš„ç›®æ ‡)çš„æ¦‚ç‡åˆ†åˆ«ä¸ºï¼šAã€Bã€Cã€Dã€Eã€F
ï¼ˆ1ï¼‰ä»æœ€å¤§æ¦‚ç‡ çŸ©å½¢æ¡†Få¼€å§‹ï¼Œåˆ†åˆ«åˆ¤æ–­A~Eä¸Fçš„é‡å åº¦IOUæ˜¯å¦å¤§äºæŸä¸ªæŒ‡å®šçš„é˜€å€¼ï¼›
ï¼ˆ2ï¼‰å‡è®¾Bã€Dä¸Fçš„é‡å åº¦å¤§äºæŒ‡å®šçš„é˜€å€¼ï¼Œåˆ™ä¸¢å¼ƒBã€Dï¼Œå¹¶æ ‡è®°ç¬¬ä¸€ä¸ªçŸ©å½¢æ¡† Fï¼Œä½¿æˆ‘ä»¬è¦ä¿ç•™çš„
ï¼ˆ3ï¼‰ä»å‰©ä¸‹çš„çŸ©å½¢æ¡†Aã€Cã€Eä¸­ï¼Œé€‰æ‹©æœ€å¤§æ¦‚ç‡ï¼Œå‡è®¾ä¸ºEï¼Œç„¶ååˆ¤æ–­Aã€Cä¸Eçš„é‡å åº¦æ˜¯å¦å¤§äºæŒ‡å®šçš„é˜€å€¼ï¼Œ
     å‡å¦‚å¤§äºå°±ä¸¢å¼ƒAã€Cï¼Œå¹¶æ ‡è®°Eï¼Œæ˜¯æˆ‘ä»¬ä¿ç•™ä¸‹æ¥çš„ç¬¬äºŒä¸ªçŸ©å½¢æ¡†
ä¸€ç›´é‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œæ‰¾åˆ°æ‰€æœ‰è¢«ä¿ç•™çš„çŸ©å½¢æ¡†
Returns:
     list of detections, on (n,6) tensor per image [xyxy, conf, cls]
"""
out = non_max_suppression(out, conf_thres, iou_thres, labels=lb, multi_label=True, agnostic=single_cls)
#  è·å–NMSæ—¶é—´
dt[2] += time_sync() - t3
```

#### 3.6.5 ç»Ÿè®¡æ¯å¼ å›¾ç‰‡çš„çœŸå®æ¡†ã€é¢„æµ‹æ¡†ä¿¡æ¯ 


```python
# Metrics
for si, pred in enumerate(out):
    labels = targets[targets[:, 0] == si, 1:]
    nl, npr = labels.shape[0], pred.shape[0]  # number of labels, predictions
    path, shape = Path(paths[si]), shapes[si][0]
    correct = flow.zeros(npr, niou, dtype=flow.bool, device=device)  # init
    seen += 1 # å›¾ç‰‡æ•°é‡ +1

    if npr == 0:# å¦‚æœé¢„æµ‹ä¸ºç©ºï¼Œåˆ™æ·»åŠ ç©ºçš„ä¿¡æ¯åˆ°statsé‡Œ
        if nl:
            stats.append((correct, *flow.zeros((2, 0), device=device), labels[:, 0]))
            if plots:
                confusion_matrix.process_batch(detections=None, labels=labels[:, 0])
        continue
        # Predictions
        if single_cls:
            pred[:, 5] = 0
        predn = pred.clone()
        # å°†é¢„æµ‹åæ ‡æ˜ å°„åˆ°åŸå›¾imgä¸­
        scale_coords(im[si].shape[1:], predn[:, :4], shape, shapes[si][1])  # native-space pred

        # Evaluate
        if nl:
            tbox = xywh2xyxy(labels[:, 1:5])  # target boxes
            scale_coords(im[si].shape[1:], tbox, shape, shapes[si][1])  # native-space labels
            labelsn = flow.cat((labels[:, 0:1], tbox), 1)  # native-space labels
            correct = process_batch(predn, labelsn, iouv)
            if plots:
                confusion_matrix.process_batch(predn, labelsn)
        stats.append((correct, pred[:, 4], pred[:, 5], labels[:, 0]))  # (correct, conf, pcls, tcls)

        # Save/log
        if save_txt:
            save_one_txt(
                predn,
                save_conf,
                shape,
                file=save_dir / "labels" / f"{path.stem}.txt",
            )
        if save_json:
            save_one_json(predn, jdict, path, class_map)  # append to COCO-JSON dictionary
        callbacks.run("on_val_image_end", pred, predn, path, names, im[si])
```

### 3.6.6 ç”»å‡ºå‰ä¸‰ä¸ªbatchå›¾ç‰‡çš„gtå’Œpredæ¡†
> gt : çœŸå®æ¡†ï¼ŒGround truth box, æ˜¯äººå·¥æ ‡æ³¨çš„ä½ç½®ï¼Œå­˜æ”¾åœ¨æ ‡æ³¨æ–‡ä»¶ä¸­

> pred : é¢„æµ‹æ¡†ï¼ŒPrediction boxï¼Œ æ˜¯ç”±ç›®æ ‡æ£€æµ‹æ¨¡å‹è®¡ç®—è¾“å‡ºçš„æ¡†


```python
# Plot images
if plots and batch_i < 3:
    plot_images(im, targets, paths, save_dir / f"val_batch{batch_i}_labels.jpg", names)  # labels
    plot_images(
        im,
        output_to_target(out),
        paths,
        save_dir / f"val_batch{batch_i}_pred.jpg",
        names,
    )  # pred

callbacks.run("on_val_batch_end")
```

### 3.7 è®¡ç®—æŒ‡æ ‡
> æŒ‡æ ‡åå­—åœ¨ä»£ç ä¸­ä½“ç°


```python
# Compute metrics
stats = [flow.cat(x, 0).cpu().numpy() for x in zip(*stats)]  # to numpy
if len(stats) and stats[0].any():
    tp, fp, p, r, f1, ap, ap_class = ap_per_class(*stats, plot=plots, save_dir=save_dir, names=names)
    ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95
    mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()
nt = np.bincount(stats[3].astype(int), minlength=nc)  # number of targets per class
```

### 3.8 æ‰“å°æ—¥å¿—


```python
# Print results per class
if (verbose or (nc < 50 and not training)) and nc > 1 and len(stats):
for i, c in enumerate(ap_class):
    LOGGER.info(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))

# Print speeds
t = tuple(x / seen * 1e3 for x in dt)  # speeds per image
if not training:
shape = (batch_size, 3, imgsz, imgsz)
LOGGER.info(f"Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {shape}" % t)
```

### 3.9ä¿å­˜éªŒè¯ç»“æœ


```python
# Plots
if plots:
    confusion_matrix.plot(save_dir=save_dir, names=list(names.values()))
    callbacks.run("on_val_end")

# Save JSON
if save_json and len(jdict):
    w = Path(weights[0] if isinstance(weights, list) else weights).stem if weights is not None else ""  # weights
    anno_json = str(Path(data.get("path", "../coco")) / "annotations/instances_val2017.json")  # annotations json
    pred_json = str(save_dir / f"{w}_predictions.json")  # predictions json
    LOGGER.info(f"\nEvaluating pycocotools mAP... saving {pred_json}...")
    with open(pred_json, "w") as f:
        json.dump(jdict, f)
    # try-catchï¼Œä¼šæœ‰å“ªäº›error
    """
    pycocotoolsä»‹ç»:
        https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb
    å°è¯•:
        ä½¿ç”¨pycocotoolså·¥å…·è®¡ç®—loss
        COCO API - http://cocodataset.org/
    å¤±è´¥error:
        ç›´æ¥æ‰“å°æŠ›å‡ºçš„å¼‚å¸¸
        1. å¯èƒ½æ²¡æœ‰å®‰è£… pycocotoolsï¼Œä½†æ˜¯ç½‘ç»œæœ‰é—®é¢˜ï¼Œæ— æ³•å®ç°è‡ªåŠ¨ä¸‹è½½ã€‚
        2. pycocotoolsåŒ…ç‰ˆæœ¬æœ‰é—®é¢˜
    """
    try:  # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb
        check_requirements(["pycocotools"])
        from pycocotools.coco import COCO
        from pycocotools.cocoeval import COCOeval

        anno = COCO(anno_json)  # init annotations api
        pred = anno.loadRes(pred_json)  # init predictions api
        eval = COCOeval(anno, pred, "bbox")
        if is_coco:
            eval.params.imgIds = [int(Path(x).stem) for x in dataloader.dataset.im_files]  # image IDs to evaluate
        eval.evaluate()
        eval.accumulate()
        eval.summarize()
        map, map50 = eval.stats[:2]  # update results (mAP@0.5:0.95, mAP@0.5)
    except Exception as e:
        LOGGER.info(f"pycocotools unable to run: {e}")
```

### 3.10 è¿”å›ç»“æœ


```python
# Return results
model.float()  # for training
if not training:
    s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ""
    LOGGER.info(f"Results saved to {colorstr('bold', save_dir)}{s}")
maps = np.zeros(nc) + map
for i, c in enumerate(ap_class):
    maps[c] = ap[i]
return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t
```

##  Reference

- [ã€ä»€ä¹ˆæ˜¯epochã€batchã€batchsizeã€iterationï¼Ÿä»€ä¹ˆæ˜¯çœŸå®æ¡†ã€é¢„æµ‹æ¡†å’Œé”šæ¡†ã€‘](https://blog.csdn.net/qq_29960631/article/details/121945133?spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-121945133-blog-104170604.pc_relevant_multi_platform_whitelistv4&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-121945133-blog-104170604.pc_relevant_multi_platform_whitelistv4&utm_relevant_index=14)


- [ã€YOLOV5-5.x æºç è§£è¯»ã€‘val.py](https://blog.csdn.net/qq_38253797/article/details/119577291)
