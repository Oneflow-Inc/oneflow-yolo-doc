## å‰è¨€

>ğŸ‰ä»£ç ä»“åº“åœ°å€ï¼š<a href="https://github.com/Oneflow-Inc/one-yolov5" target="blank">https://github.com/Oneflow-Inc/one-yolov5</a>
æ¬¢è¿star [one-yolov5é¡¹ç›®](https://github.com/Oneflow-Inc/one-yolov5) è·å–<a href="https://github.com/Oneflow-Inc/one-yolov5/tags" target="blank" >æœ€æ–°çš„åŠ¨æ€ã€‚</a>
<a href="https://github.com/Oneflow-Inc/one-yolov5/issues/new"  target="blank"  >å¦‚æœæ‚¨æœ‰é—®é¢˜ï¼Œæ¬¢è¿åœ¨ä»“åº“ç»™æˆ‘ä»¬æå‡ºå®è´µçš„æ„è§ã€‚ğŸŒŸğŸŒŸğŸŒŸ</a>
<a href="https://github.com/Oneflow-Inc/one-yolov5" target="blank" >
å¦‚æœå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿æ¥ç»™æˆ‘Starå‘€ğŸ˜Š~  </a>


æºç è§£è¯»ï¼š [utils/augmentations.py](https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/augmentations.py)


## 1. random_perspective
&emsp;è¿™ä¸ªå‡½æ•°æ˜¯å¯¹mosaicæ•´åˆåçš„å›¾ç‰‡è¿›è¡Œéšæœºæ—‹è½¬ã€ç¼©æ”¾ã€å¹³ç§»ã€è£å‰ªï¼Œé€è§†å˜æ¢ï¼Œ

å¹¶resizeä¸ºè¾“å…¥å¤§å°img_sizeã€‚


> ä»¿å°„å˜æ¢åŒ…å«ï¼š`å¹³ç§»ã€æ—‹è½¬ã€æ”¾ç¼©ã€å‰ªåˆ‡ã€åå°„`

ä»¿å°„å˜æ¢åŒ…æ‹¬å¦‚ä¸‹æ‰€æœ‰å˜æ¢ï¼Œä»¥åŠè¿™äº›å˜æ¢ä»»æ„æ¬¡åºæ¬¡æ•°çš„ç»„åˆï¼š

![image](https://user-images.githubusercontent.com/109639975/204688876-10105f39-1c95-4597-9323-63c77c9861cd.png)
å›¾ç‰‡æ¥æºäº:[https://www.cnblogs.com/shine-lee/p/10950963.html](https://www.cnblogs.com/shine-lee/p/10950963.html)

`å¹³ç§»`ï¼ˆtranslationï¼‰å’Œ `æ—‹è½¬`ï¼ˆrotationï¼‰é¡¾åæ€ä¹‰ï¼Œä¸¤è€…çš„ç»„åˆç§°ä¹‹ä¸ºæ¬§å¼å˜æ¢ï¼ˆEuclidean transformationï¼‰æˆ–åˆšä½“å˜æ¢ï¼ˆrigid transformationï¼‰ï¼›

`æ”¾ç¼©`ï¼ˆscalingï¼‰å¯è¿›ä¸€æ­¥åˆ†ä¸ºuniform scalingå’Œnon-uniform scalingï¼Œå‰è€…æ¯ä¸ªåæ ‡è½´æ”¾ç¼©ç³»æ•°ç›¸åŒï¼ˆå„å‘åŒæ€§ï¼‰ï¼Œåè€…ä¸åŒï¼›å¦‚æœæ”¾ç¼©ç³»æ•°ä¸ºè´Ÿï¼Œåˆ™ä¼šå åŠ ä¸Šåå°„ï¼ˆreflectionï¼‰â€”â€”reflectionå¯ä»¥çœ‹æˆæ˜¯ç‰¹æ®Šçš„scalingï¼›

`åˆšä½“å˜æ¢+uniform scaling` ç§°ä¹‹ä¸ºï¼Œç›¸ä¼¼å˜æ¢ï¼ˆsimilarity transformationï¼‰ï¼Œå³å¹³ç§»+æ—‹è½¬+å„å‘åŒæ€§çš„æ”¾ç¼©ï¼›

`å‰ªåˆ‡å˜æ¢`ï¼ˆshear mappingï¼‰å°†æ‰€æœ‰ç‚¹æ²¿æŸä¸€æŒ‡å®šæ–¹å‘æˆæ¯”ä¾‹åœ°å¹³ç§»ï¼Œè¯­è¨€æè¿°ä¸å¦‚ä¸Šé¢å›¾ç¤ºç›´è§‚ã€‚

random_perspectiveå‡½æ•°ä»£ç ï¼š


```python
def random_perspective(
    img, 
    targets=(),
    segments=(),
    degrees=10,
    translate=0.1,
    scale=0.1,
    shear=10,
    perspective=0.0,
    border=(0, 0),
):
    """è¿™ä¸ªå‡½æ•°ä¼šç”¨äºload_mosaicä¸­ç”¨åœ¨mosaicæ“ä½œä¹‹å
    éšæœºé€è§†å˜æ¢  å¯¹mosaicæ•´åˆåçš„å›¾ç‰‡è¿›è¡Œéšæœºæ—‹è½¬ã€ç¼©æ”¾ã€å¹³ç§»ã€è£å‰ªï¼Œé€è§†å˜æ¢ï¼Œå¹¶resizeä¸ºè¾“å…¥å¤§å°img_size
    :params img: mosaicæ•´åˆåçš„å›¾ç‰‡img4 [2*img_size, 2*img_size]
    å¦‚æœmosaicåçš„å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢æ ‡ç­¾ segmentsä¸ºç©º 
    å¦‚æœæœ‰ä¸€ä¸ªå¤šè¾¹å½¢æ ‡ç­¾åˆ™ segmentsä¸ä¸ºç©ºã€‚
    :params targets: mosaicæ•´åˆåå›¾ç‰‡çš„æ‰€æœ‰æ­£å¸¸labelæ ‡ç­¾labels4(ä¸æ­£å¸¸çš„ä¼šé€šè¿‡segments2boxeså°†å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºæ­£å¸¸æ ‡ç­¾) [N, cls+xyxy]
    :params segments: mosaicæ•´åˆåå›¾ç‰‡çš„æ‰€æœ‰ä¸æ­£å¸¸labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢ä¹ŸåŒ…å«æ­£å¸¸gt)  [m, x1y1....]
    :params degrees: æ—‹è½¬å’Œç¼©æ”¾çŸ©é˜µå‚æ•°
    :params translate: å¹³ç§»çŸ©é˜µå‚æ•°
    :params scale: ç¼©æ”¾çŸ©é˜µå‚æ•°
    :params shear: å‰ªåˆ‡çŸ©é˜µå‚æ•°
    :params perspective: é€è§†å˜æ¢å‚æ•°
    :params border: ç”¨äºç¡®å®šæœ€åè¾“å‡ºçš„å›¾ç‰‡å¤§å° 
    ä¸€èˆ¬ç­‰äº[-img_size//2, -img_size//2] é‚£ä¹ˆæœ€åè¾“å‡ºçš„å›¾ç‰‡å¤§å°ä¸º [img_size, img_size]
    :return img: é€šè¿‡é€è§†å˜æ¢/ä»¿å°„å˜æ¢åçš„img [img_size, img_size] 
    :return targets: é€šè¿‡é€è§†å˜æ¢/ä»¿å°„å˜æ¢åçš„imgå¯¹åº”çš„æ ‡ç­¾ [n, cls+x1y1x2y2]  (é€šè¿‡ç­›é€‰åçš„)
    OpenCVä¸­çš„åæ ‡ç³»å®šä¹‰ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º:
   (0,0)o_________width______________x
        |                            |
        height                       |
        |                            |
        |                            |
        |                            |
        y____________________________o(w,h)
    """
    # è®¾å®šè¾“å‡ºå›¾ç‰‡çš„ H W
    # border=-s // 2  æ‰€ä»¥æœ€åå›¾ç‰‡çš„å¤§å°ç›´æ¥å‡åŠ [img_size, img_size, 3]
    # å›¾ç‰‡é«˜å®½ï¼ˆåŠ ä¸Šborderè¾¹æ¡†ï¼‰
    height = img.shape[0] + border[0] * 2  # # æœ€ç»ˆè¾“å‡ºå›¾åƒçš„H
    width = img.shape[1] + border[1] * 2  # æœ€ç»ˆè¾“å‡ºå›¾åƒçš„W

    # ============================ å¼€å§‹å˜æ¢ =============================
    # éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå…¶å®opencvæ˜¯å®ç°äº†ä»¿å°„å˜æ¢çš„, ä¸è¿‡æˆ‘ä»¬è¦å…ˆç”Ÿæˆä»¿å°„å˜æ¢çŸ©é˜µM
    # Center è®¡ç®—ä¸­å¿ƒç‚¹
    C = np.eye(3) # ç”Ÿæˆ3*3çš„å¯¹è§’ä¸º1çš„å¯¹è§’çŸ©é˜µ
    # x æ–¹å‘çš„ä¸­å¿ƒ
    C[0, 2] = -img.shape[1] / 2  # x translation (pixels)
    # y æ–¹å‘çš„ä¸­å¿ƒ
    C[1, 2] = -img.shape[0] / 2  # y translation (pixels)

    # Perspective  è®¾ç½®é€è§†å˜æ¢çŸ©é˜µ
    P = np.eye(3) # ç”Ÿæˆ3*3çš„å¯¹è§’ä¸º1çš„å¯¹è§’çŸ©é˜µ
    # éšæœºç”Ÿæˆxï¼Œyæ–¹å‘ä¸Šçš„é€è§†å€¼
    P[2, 0] = random.uniform(-perspective, perspective)  # x perspective (about y)
    P[2, 1] = random.uniform(-perspective, perspective)  # y perspective (about x)

    # Rotation and Scale  
    # æ—‹è½¬å’Œç¼©æ”¾
    R = np.eye(3)  # åˆå§‹åŒ–R = [[1,0,0], [0,1,0], [0,0,1]]    (3, 3)
    # a: éšæœºç”Ÿæˆæ—‹è½¬è§’åº¦ èŒƒå›´åœ¨(-degrees, degrees)
    # a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations
    a = random.uniform(-degrees, degrees)
    # a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations
    # s: éšæœºç”Ÿæˆæ—‹è½¬åå›¾åƒçš„ç¼©æ”¾æ¯”ä¾‹ èŒƒå›´åœ¨(1 - scale, 1 + scale)
    # s = 2 ** random.uniform(-scale, scale)
    # éšæœºç”Ÿæˆç¼©æ”¾æ¯”ä¾‹
    s = random.uniform(1 - scale, 1 + scale)
    # s = 2 ** random.uniform(-scale, scale)
    # cv2.getRotationMatrix2D: äºŒç»´æ—‹è½¬ç¼©æ”¾å‡½æ•°
    # å‚æ•° angle:æ—‹è½¬è§’åº¦  center: æ—‹è½¬ä¸­å¿ƒ(é»˜è®¤å°±æ˜¯å›¾åƒçš„ä¸­å¿ƒ)  scale: æ—‹è½¬åå›¾åƒçš„ç¼©æ”¾æ¯”ä¾‹
    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)

    # Shear  è®¾ç½®å‰ªåˆ‡çŸ©é˜µ
    # å¼¯æ›²è§’åº¦
    S = np.eye(3)  # åˆå§‹åŒ–T = [[1,0,0], [0,1,0], [0,0,1]]
    S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)
    S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)

    # Translation è®¾ç½®å¹³ç§»çŸ©é˜µ
    T = np.eye(3)  # åˆå§‹åŒ–T = [[1,0,0], [0,1,0], [0,0,1]]    (3, 3)
    T[0, 2] = (
        random.uniform(0.5 - translate, 0.5 + translate) * width
    )  # x translation (pixels)
    T[1, 2] = (
        random.uniform(0.5 - translate, 0.5 + translate) * height
    )  # y translation (pixels)

    # Combined rotation matrix  @ è¡¨ç¤ºçŸ©é˜µä¹˜æ³•  ç”Ÿæˆä»¿å°„å˜æ¢çŸ©é˜µM
    M = T @ S @ R @ P @ C  # order of operations (right to left) is IMPORTANT
    # å°†ä»¿å°„å˜æ¢çŸ©é˜µMä½œç”¨åœ¨å›¾ç‰‡ä¸Š
    if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any():  # image changed
        if perspective:
            # é€è§†å˜æ¢å‡½æ•°  å®ç°æ—‹è½¬å¹³ç§»ç¼©æ”¾å˜æ¢åçš„å¹³è¡Œçº¿ä¸å†å¹³è¡Œ
            # å‚æ•°å’Œä¸‹é¢warpAffineç±»ä¼¼
            img = cv2.warpPerspective(
                img, M, dsize=(width, height), borderValue=(114, 114, 114)
            )
        else:
            # ä»¿å°„å˜æ¢å‡½æ•°  å®ç°æ—‹è½¬å¹³ç§»ç¼©æ”¾å˜æ¢åçš„å¹³è¡Œçº¿ä¾æ—§å¹³è¡Œ
            # image changed  img  [1472, 1472, 3] => [736, 736, 3]
            # cv2.warpAffine: opencvå®ç°çš„ä»¿å°„å˜æ¢å‡½æ•°
            # å‚æ•°ï¼š img: éœ€è¦å˜åŒ–çš„å›¾åƒ   M: å˜æ¢çŸ©é˜µ  dsize: è¾“å‡ºå›¾åƒçš„å¤§å°  flags: æ’å€¼æ–¹æ³•çš„ç»„åˆï¼ˆint ç±»å‹ï¼ï¼‰
            #       borderValue: ï¼ˆé‡ç‚¹ï¼ï¼‰è¾¹ç•Œå¡«å……å€¼  é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒä¸º0ã€‚
            img = cv2.warpAffine(
                img, M[:2], dsize=(width, height), borderValue=(114, 114, 114)
            )

    # Visualize å¯è§†åŒ–
    # import matplotlib.pyplot as plt
    # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel()
    # ax[0].imshow(img[:, :, ::-1])  # base
    # ax[1].imshow(img2[:, :, ::-1])  # warped

    # Transform label coordinates
    # åŒæ ·éœ€è¦è°ƒæ•´æ ‡ç­¾ä¿¡æ¯
    n = len(targets)
    if n:
        # åˆ¤æ–­æ˜¯å¦å¯ä»¥ä½¿ç”¨segmentæ ‡ç­¾: åªæœ‰segmentsä¸ä¸ºç©ºæ—¶å³æ•°æ®é›†ä¸­æœ‰å¤šè¾¹å½¢gtä¹Ÿæœ‰æ­£å¸¸gtæ—¶æ‰èƒ½ä½¿ç”¨segmentæ ‡ç­¾ use_segments=True
        #                          å¦åˆ™å¦‚æœåªæœ‰æ­£å¸¸gtæ—¶segmentsä¸ºç©º use_segments=False
        use_segments = any(x.any() for x in segments)
        new = np.zeros((n, 4))  # [n, 0+0+0+0]
        # å¦‚æœä½¿ç”¨çš„æ˜¯segmentsæ ‡ç­¾(æ ‡ç­¾ä¸­å«æœ‰å¤šè¾¹å½¢gt)
        if use_segments:  # warp segments
            # å…ˆå¯¹segmentæ ‡ç­¾è¿›è¡Œé‡é‡‡æ ·
            # æ¯”å¦‚è¯´segmentåæ ‡åªæœ‰100ä¸ªï¼Œé€šè¿‡interpå‡½æ•°å°†å…¶é‡‡æ ·ä¸ºnä¸ª(é»˜è®¤1000)
            # [n, x1y2...x99y100] æ‰©å¢åæ ‡-> [n, 500, 2]
            # ç”±äºæœ‰æ—‹è½¬ï¼Œé€è§†å˜æ¢ç­‰æ“ä½œï¼Œæ‰€ä»¥éœ€è¦å¯¹å¤šè¾¹å½¢æ‰€æœ‰è§’ç‚¹éƒ½è¿›è¡Œå˜æ¢
            segments = resample_segments(segments)
            for i, segment in enumerate(segments):  # segment: [500, 2]  å¤šè¾¹å½¢çš„500ä¸ªç‚¹åæ ‡xy
                xy = np.ones((len(segment), 3))  # [1, 1+1+1]
                xy[:, :2] = segment  # [500, 2]
                # å¯¹è¯¥æ ‡ç­¾å¤šè¾¹å½¢çš„æ‰€æœ‰é¡¶ç‚¹åæ ‡è¿›è¡Œé€è§†å˜æ¢ æˆ– ä»¿å°„å˜æ¢
                xy = xy @ M.T  # transform  @è¡¨ç¤ºçŸ©é˜µä¹˜æ³•è¿ç®—
                xy = (
                    xy[:, :2] / xy[:, 2:3] if perspective else xy[:, :2]
                )  # perspective rescale or affine

                # æ ¹æ®segmentçš„åæ ‡ï¼Œå–xyåæ ‡çš„æœ€å¤§æœ€å°å€¼ï¼Œå¾—åˆ°è¾¹æ¡†çš„åæ ‡  clip
                new[i] = segment2box(xy, width, height)  # xy [500, 2]
        # ä¸ä½¿ç”¨segmentsæ ‡ç­¾ ä½¿ç”¨æ­£å¸¸çš„çŸ©å½¢çš„æ ‡ç­¾targets
        else:  # warp boxes
            # ç›´æ¥å¯¹boxé€è§†å˜æ¢ æˆ– ä»¿å°„å˜æ¢
            # ç”±äºæœ‰æ—‹è½¬ï¼Œé€è§†å˜æ¢ç­‰æ“ä½œï¼Œæ‰€ä»¥éœ€è¦å¯¹å››ä¸ªè§’ç‚¹éƒ½è¿›è¡Œå˜æ¢
            xy = np.ones((n * 4, 3))
            xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2]].reshape(
                n * 4, 2
            )  # x1y1, x2y2, x1y2, x2y1
            xy = xy @ M.T  # transform æ¯ä¸ªè§’ç‚¹çš„åæ ‡
            xy = (xy[:, :2] / xy[:, 2:3] if perspective else xy[:, :2]).reshape(
                n, 8
            )  # perspective rescale or affine

            # create new boxes
            x = xy[:, [0, 2, 4, 6]]
            y = xy[:, [1, 3, 5, 7]]
            new = (
                np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T
            )

            # clip  å»é™¤å¤ªå°çš„target(targetå¤§éƒ¨åˆ†è·‘åˆ°å›¾å¤–å»äº†)
            new[:, [0, 2]] = new[:, [0, 2]].clip(0, width)
            new[:, [1, 3]] = new[:, [1, 3]].clip(0, height)

        # filter candidates  è¿‡æ»¤target ç­›é€‰box
        # è®¡ç®—å€™é€‰æ¡†å¹¶è¿”å›
        # é•¿å’Œå®½å¿…é¡»å¤§äºwh_thrä¸ªåƒç´  è£å‰ªè¿‡å°çš„æ¡†(é¢ç§¯å°äºè£å‰ªå‰çš„area_thr)  é•¿å®½æ¯”èŒƒå›´åœ¨(1/ar_thr, ar_thr)ä¹‹é—´çš„é™åˆ¶
        # ç­›é€‰ç»“æœ [n] å…¨æ˜¯Trueæˆ–False   ä½¿ç”¨æ¯”å¦‚: box1[i]å³å¯å¾—åˆ°iä¸­æ‰€æœ‰ç­‰äºTrueçš„çŸ©å½¢æ¡† Falseçš„çŸ©å½¢æ¡†å…¨éƒ¨åˆ é™¤
        i = box_candidates(
            box1=targets[:, 1:5].T * s,
            box2=new.T,
            area_thr=0.01 if use_segments else 0.10,
        )
        # å¾—åˆ°æ‰€æœ‰æ»¡è¶³æ¡ä»¶çš„targets
        targets = targets[i]
        targets[:, 1:5] = new[i]

    return img, targets

```

è¿™ä¸ªå‡½æ•°ä¼šç”¨äºload_mosaicä¸­çš„mosaicæ“ä½œä¹‹åè¿›è¡Œé€è§†å˜æ¢ æˆ– ä»¿å°„å˜æ¢ï¼š

![image](https://user-images.githubusercontent.com/109639975/199886156-3adfa134-b3c5-425b-b41a-5704b54e6673.png)

è¿™ä¸ªå‡½æ•°çš„å‚æ•°æ¥è‡ª hyp.yaml ä¸­çš„ä¸‹é¢5ä¸ªå‚æ•°ï¼š

![image](https://user-images.githubusercontent.com/109639975/199886270-6a06134b-50dc-4718-8220-e7436d3f86e9.png)

## 2. box_candidates

>  å®˜æ–¹ä½œè€…ä»‹ç»[Question about function box_candidates() in datasets.py](https://github.com/ultralytics/yolov5/issues/2442)

&emsp;è¿™ä¸ªå‡½æ•°ç”¨åœ¨random_perspectiveä¸­ï¼Œæ˜¯å¯¹é€è§†å˜æ¢åçš„å›¾ç‰‡labelè¿›è¡Œç­›é€‰ï¼Œå»é™¤è¢«è£å‰ªè¿‡å°çš„æ¡†(é¢ç§¯å°äºè£å‰ªå‰çš„area_thr) å¹¶ä¸”ä¿ç•™ä¸‹æ¥çš„æ¡†çš„é•¿å®½å¿…é¡»å¤§äºwh_thrä¸ªåƒç´ ï¼Œä¸”é•¿å®½æ¯”èŒƒå›´åœ¨(1/ar_thr, ar_thr)ä¹‹é—´ã€‚

box_candidates å‡½æ•°ä»£ç ï¼š


```python
def box_candidates(box1, box2, wh_thr=2, ar_thr=20, area_thr=0.1, eps=1e-16):
    """box_candidates() is used to filter the labels and reject poor label candidates:
    ç”¨åœ¨random_perspectiveä¸­ å¯¹é€è§†å˜æ¢åçš„å›¾ç‰‡labelè¿›è¡Œç­›é€‰
    å»é™¤è¢«è£å‰ªè¿‡å°çš„æ¡†(é¢ç§¯å°äºè£å‰ªå‰çš„area_thr) è¿˜æœ‰é•¿å’Œå®½å¿…é¡»å¤§äºwh_thrä¸ªåƒç´ ï¼Œä¸”é•¿å®½æ¯”èŒƒå›´åœ¨(1/ar_thr, ar_thr)ä¹‹é—´çš„é™åˆ¶
    Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio
    :params box1: [4, n]
    :params box2: [4, n]
    :params wh_thr: ç­›é€‰æ¡ä»¶ å®½é«˜é˜ˆå€¼
    :params ar_thr: ç­›é€‰æ¡ä»¶ å®½é«˜æ¯”ã€é«˜å®½æ¯”æœ€å¤§å€¼é˜ˆå€¼
    :params area_thr: ç­›é€‰æ¡ä»¶ é¢ç§¯é˜ˆå€¼
    :params eps: 1e-16 æ¥è¿‘0çš„æ•° é˜²æ­¢åˆ†æ¯ä¸º0
    :return i: ç­›é€‰ç»“æœ [n] å…¨æ˜¯Trueæˆ–False   ä½¿ç”¨æ¯”å¦‚: box1[i]å³å¯å¾—åˆ°iä¸­æ‰€æœ‰ç­‰äºTrueçš„çŸ©å½¢æ¡† Falseçš„çŸ©å½¢æ¡†å…¨éƒ¨åˆ é™¤
    """
    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]  # æ±‚å‡ºæ‰€æœ‰box1çŸ©å½¢æ¡†çš„å®½å’Œé«˜  [n] [n]
    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]  # æ±‚å‡ºæ‰€æœ‰box2çŸ©å½¢æ¡†çš„å®½å’Œé«˜  [n] [n]
    ar = np.maximum(w2 / (h2 + eps), h2 / (w2 + eps))  # æ±‚å‡ºæ‰€æœ‰box2çŸ©å½¢æ¡†çš„å®½é«˜æ¯”å’Œé«˜å®½æ¯”çš„è¾ƒå¤§è€…  [n, 1]
    # ç­›é€‰æ¡ä»¶: å¢å¼ºåwã€hè¦å¤§äº2   å¢å¼ºåå›¾åƒä¸å¢å¼ºå‰å›¾åƒé¢ç§¯æ¯”å€¼å¤§äºarea_thr   å®½é«˜æ¯”å¤§äºar_thr
    return (
        (w2 > wh_thr)
        & (h2 > wh_thr)
        & (w2 * h2 / (w1 * h1 + eps) > area_thr)
        & (ar < ar_thr)
    )  # candidates

```

## 3. replicate
&emsp;è¿™ä¸ªå‡½æ•°æ˜¯éšæœºåç§»æ ‡ç­¾ä¸­å¿ƒï¼Œç”Ÿæˆæ–°çš„æ ‡ç­¾ä¸åŸæ ‡ç­¾ç»“åˆã€‚å¯ä»¥ç”¨åœ¨load_mosaicé‡Œçš„mosaicæ“ä½œä¹‹å ä»¥åŠrandom_perspectiveæ“ä½œä¹‹å‰ï¼Œ ä½œè€…é»˜è®¤æ˜¯å…³é—­çš„ï¼Œ è‡ªå·±å¯ä»¥å®éªŒä¸€ä¸‹æ•ˆæœã€‚

replicateæ¨¡å—ä»£ç ï¼š



```python
def replicate(img, labels):
    """å¯ä»¥ç”¨åœ¨load_mosaicé‡Œåœ¨mosaicæ“ä½œä¹‹å random_perspectiveæ“ä½œä¹‹å‰  ä½œè€…é»˜è®¤æ˜¯å…³é—­çš„ è‡ªå·±å¯ä»¥å®éªŒä¸€ä¸‹æ•ˆæœ
    éšæœºåç§»æ ‡ç­¾ä¸­å¿ƒï¼Œç”Ÿæˆæ–°çš„æ ‡ç­¾ä¸åŸæ ‡ç­¾ç»“åˆ  Replicate labels
    :params img: img4 å› ä¸ºæ˜¯ç”¨åœ¨mosaicæ“ä½œä¹‹å æ‰€ä»¥size=[2*img_size, 2*img_size]
    :params labels: mosaicæ•´åˆåå›¾ç‰‡çš„æ‰€æœ‰æ­£å¸¸labelæ ‡ç­¾labels4(ä¸æ­£å¸¸çš„ä¼šé€šè¿‡segments2boxeså°†å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºæ­£å¸¸æ ‡ç­¾) [N, cls+xyxy]
    :return img: img4 size=[2*img_size, 2*img_size] ä¸è¿‡å›¾ç‰‡ä¸­å¤šäº†ä¸€åŠçš„è¾ƒå°gtä¸ªæ•°
    :params labels: labels4 ä¸è¿‡å¦å¤–å¢åŠ äº†ä¸€åŠçš„è¾ƒå°label [3/2N, cls+xyxy]
    """
    h, w = img.shape[:2]  # å¾—åˆ°å›¾ç‰‡çš„é«˜å’Œå®½
    boxes = labels[:, 1:].astype(int)  # å¾—åˆ°æ‰€æœ‰gtæ¡†çš„çŸ©å½¢åæ ‡ xyxy [N, xyxy]
    x1, y1, x2, y2 = boxes.T  # å·¦ä¸Šè§’: x1 y1   å³ä¸‹è§’: x2 y2  [N]
    s = (
        (x2 - x1) + (y2 - y1)
    ) / 2  # side length (pixels)  [N] å¾—åˆ°Nä¸ªgtçš„ (w+h)/2 ç”¨æ¥è¡¡é‡gtæ¡†çš„å¤§å°
    # ç”ŸæˆåŸæ ‡ç­¾ä¸ªæ•°ä¸€åŠçš„æ–°æ ‡ç­¾   s.sizeè¿”å›ndarrayçš„å…ƒç´ æ•°é‡
    for i in s.argsort()[: round(s.size * 0.5)]:  # è¿”å›è¾ƒå°(sè¾ƒå°)çš„ä¸€åŠgtæ¡†çš„indexä¿¡æ¯
        x1b, y1b, x2b, y2b = boxes[i]  # å¾—åˆ°è¿™ä¸€åŠè¾ƒå°gtæ¡†çš„åæ ‡ä¿¡æ¯  å·¦ä¸Šè§’x1b y1b  å³ä¸‹è§’x2b y2b
        bh, bw = y2b - y1b, x2b - x1b  # å¾—åˆ°è¿™ä¸€èˆ¬è¾ƒå°gtæ¡†çš„é«˜å®½ä¿¡æ¯
        # éšæœºåç§»æ ‡ç­¾ä¸­å¿ƒç‚¹  yèŒƒå›´åœ¨[0, å›¾ç‰‡é«˜-gtæ¡†é«˜]  xèŒƒå›´åœ¨[0, å›¾ç‰‡å®½-gtæ¡†å®½]
        yc, xc = int(random.uniform(0, h - bh)), int(
            random.uniform(0, w - bw)
        )  # offset x, y
        # é‡æ–°ç”Ÿæˆè¿™ä¸€åŠçš„gtæ¡†åæ ‡ä¿¡æ¯(åç§»å)
        x1a, y1a, x2a, y2a = [xc, yc, xc + bw, yc + bh]
        # å°†å›¾ç‰‡ä¸­çœŸå®çš„gtæ¡†åç§»åˆ°å¯¹åº”ç”Ÿæˆçš„åæ ‡(ä¸€åŠè¾ƒå°çš„åç§» è¾ƒå¤§çš„ä¸åç§»)
        img[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
        # append åŸæ¥çš„labelsæ ‡ç­¾ + åç§»äº†çš„æ ‡ç­¾
        labels = np.append(labels, [[labels[i, 0], x1a, y1a, x2a, y2a]], axis=0)

    return img, labels

```

ä¼šç”¨åœ¨load_mosaicload_mosaicé‡Œåœ¨mosaicæ“ä½œä¹‹å random_perspectiveæ“ä½œä¹‹å‰ï¼ˆä¸€èˆ¬ä¼šå…³é—­ å…·ä½“è¿˜è¦çœ‹ä¸ªäººå®éªŒï¼‰

## 4. [letterbox](https://start.oneflow.org/oneflow-yolo-doc/tutorials/05_chapter/rectangular_reasoning.html#_4)
> YOLOV5ä¸­çš„è‡ªé€‚åº”å›¾ç‰‡ç¼©æ”¾[letterbox](https://start.oneflow.org/oneflow-yolo-doc/tutorials/05_chapter/rectangular_reasoning.html#_4) ä¿æŒå›¾ç‰‡çš„å®½é«˜æ¯”ä¾‹ï¼Œå‰©ä¸‹çš„éƒ¨åˆ†ç”¨ç°è‰²å¡«å……ã€‚


[letterbox](https://start.oneflow.org/oneflow-yolo-doc/tutorials/05_chapter/rectangular_reasoning.html#_4) çš„imgè½¬æ¢éƒ¨åˆ†

&emsp;æ­¤æ—¶ï¼šauto=Falseï¼ˆéœ€è¦padï¼‰, scale_fill=False, scale_up=Falseã€‚

&emsp;æ˜¾ç„¶ï¼Œè¿™éƒ¨åˆ†éœ€è¦ç¼©æ”¾ï¼Œå› ä¸ºåœ¨è¿™ä¹‹å‰çš„load_imageéƒ¨åˆ†å·²ç»ç¼©æ”¾è¿‡äº†ï¼ˆæœ€é•¿è¾¹ç­‰äºæŒ‡å®šå¤§å°ï¼Œè¾ƒçŸ­è¾¹ç­‰æ¯”ä¾‹ç¼©æ”¾ï¼‰ï¼Œ

é‚£ä¹ˆåœ¨letterboxåªéœ€è¦è®¡ç®—å‡ºè¾ƒå°è¾¹éœ€è¦å¡«å……çš„pad, å†å°†è¾ƒå°è¾¹ä¸¤è¾¹padåˆ°ç›¸åº”å¤§å°ï¼ˆæ¯ä¸ªbatchéœ€è¦æ¯å¼ å›¾ç‰‡çš„å¤§å°ï¼Œè¿™ä¸ª

å¤§å°æ˜¯ä¸ç›¸åŒçš„ï¼‰å³å¯ã€‚

ä¹Ÿå¯ä»¥ç»“åˆä¸‹é¢ç”»çš„æµç¨‹å›¾æ¥ç†è§£ä¸‹é¢çš„letterboxä»£ç ï¼š

![image](https://user-images.githubusercontent.com/109639975/199886935-f1eb92fa-4965-48de-9d2a-e130cd2ae695.png)
å›¾ç‰‡æ¥æºäº: https://blog.csdn.net/qq_38253797/article/details/119904518


```python
def letterbox(
    img,
    new_shape=(640, 640),
    color=(114, 114, 114),
    auto=True,
    scaleFill=False,
    scaleup=True,
    stride=32,
):
    """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•°  åªåœ¨valæ—¶æ‰ä¼šä½¿ç”¨
    å°†å›¾ç‰‡ç¼©æ”¾è°ƒæ•´åˆ°æŒ‡å®šå¤§å°
    Resize and pad image while meeting stride-multiple constraints
    https://github.com/ultralytics/yolov3/issues/232
    :param img: åŸå›¾ hwc (å½¢çŠ¶æ˜¯ (h,w,c)  é«˜ã€å®½ã€é€šé“ï¼ˆRGBï¼‰  åƒç´ å€¼èŒƒå›´æ˜¯0-255 )
    :param new_shape: ç¼©æ”¾åçš„æœ€é•¿è¾¹å¤§å°
    :param color: padçš„é¢œè‰²
    :param auto: True ä¿è¯ç¼©æ”¾åçš„å›¾ç‰‡ä¿æŒåŸå›¾çš„æ¯”ä¾‹ å³ å°†åŸå›¾æœ€é•¿è¾¹ç¼©æ”¾åˆ°æŒ‡å®šå¤§å°ï¼Œå†å°†åŸå›¾è¾ƒçŸ­è¾¹æŒ‰åŸå›¾æ¯”ä¾‹ç¼©æ”¾ï¼ˆä¸ä¼šå¤±çœŸï¼‰
                 False å°†åŸå›¾æœ€é•¿è¾¹ç¼©æ”¾åˆ°æŒ‡å®šå¤§å°ï¼Œå†å°†åŸå›¾è¾ƒçŸ­è¾¹æŒ‰åŸå›¾æ¯”ä¾‹ç¼©æ”¾,æœ€åå°†è¾ƒçŸ­è¾¹ä¸¤è¾¹padæ“ä½œç¼©æ”¾åˆ°æœ€é•¿è¾¹å¤§å°ï¼ˆä¸ä¼šå¤±çœŸï¼‰
    :param scale_fill: True ç®€å•ç²—æš´çš„å°†åŸå›¾resizeåˆ°æŒ‡å®šçš„å¤§å° ç›¸å½“äºå°±æ˜¯resize æ²¡æœ‰padæ“ä½œï¼ˆå¤±çœŸï¼‰
    :param scale_up: True  å¯¹äºå°äºnew_shapeçš„åŸå›¾è¿›è¡Œç¼©æ”¾,å¤§äºçš„ä¸å˜
                     False å¯¹äºå¤§äºnew_shapeçš„åŸå›¾è¿›è¡Œç¼©æ”¾,å°äºçš„ä¸å˜
    :return: img: letterboxåçš„å›¾ç‰‡ hwc
             ratio: wh ratios
             (dw, dh): wå’Œhçš„pad
    """
    shape = img.shape[:2]  # ç¬¬ä¸€å±‚resizeåå›¾ç‰‡å¤§å°[h, w] = [343, 512]
    if isinstance(new_shape, int):
        new_shape = (new_shape, new_shape)  # (512, 512)

    # scale ratio (new / old)   1.024   new_shape=(384, 512)
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  # r=1

    # åªè¿›è¡Œä¸‹é‡‡æ · å› ä¸ºä¸Šé‡‡æ ·ä¼šè®©å›¾ç‰‡æ¨¡ç³Š
    # (for better test mAP) scale_up = False å¯¹äºå¤§äºnew_shapeï¼ˆr<1ï¼‰çš„åŸå›¾è¿›è¡Œç¼©æ”¾,å°äºnew_shapeï¼ˆr>1ï¼‰çš„ä¸å˜
    if not scaleup:  # only scale down, do not scale up (for better test mAP)
        r = min(r, 1.0)

    # Compute padding
    ratio = r, r  # width, height ratios   (1, 1)
    new_unpad = int(round(shape[1] * r)), int(
        round(shape[0] * r)
    )  # wh(512, 343) ä¿è¯ç¼©æ”¾åå›¾åƒæ¯”ä¾‹ä¸å˜
    dw, dh = (
        new_shape[1] - new_unpad[0],
        new_shape[0] - new_unpad[1],
    )  # wh padding  dw=0 dh=41
    if auto:  # minimum rectangle  ä¿è¯åŸå›¾æ¯”ä¾‹ä¸å˜ï¼Œå°†å›¾åƒæœ€å¤§è¾¹ç¼©æ”¾åˆ°æŒ‡å®šå¤§å°
        # è¿™é‡Œçš„å–ä½™æ“ä½œå¯ä»¥ä¿è¯paddingåçš„å›¾ç‰‡æ˜¯32çš„æ•´æ•°å€(416x416)ï¼Œå¦‚æœæ˜¯(512x512)å¯ä»¥ä¿è¯æ˜¯64çš„æ•´æ•°å€
        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding dw=0 dh=0
    elif scaleFill:  # stretch ç®€å•ç²—æš´çš„å°†å›¾ç‰‡ç¼©æ”¾åˆ°æŒ‡å®šå°ºå¯¸
        dw, dh = 0.0, 0.0
        new_unpad = (new_shape[1], new_shape[0])
        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios

    # åœ¨è¾ƒå°è¾¹çš„ä¸¤ä¾§è¿›è¡Œpad, è€Œä¸æ˜¯åœ¨ä¸€ä¾§pad
    dw /= 2  # divide padding into 2 sides  å°†paddingåˆ†åˆ°ä¸Šä¸‹ï¼Œå·¦å³ä¸¤ä¾§  dw=0
    dh /= 2  # dh=20.5

    # shape:[h, w]  new_unpad:[w, h]
    if shape[::-1] != new_unpad:  # resize  å°†åŸå›¾resizeåˆ°new_unpadï¼ˆé•¿è¾¹ç›¸åŒï¼Œæ¯”ä¾‹ç›¸åŒçš„æ–°å›¾ï¼‰
        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
    top, bottom = int(round(dh - 0.1)), int(
        round(dh + 0.1)
    )  # è®¡ç®—ä¸Šä¸‹ä¸¤ä¾§çš„padding  # top=20 bottom=21
    left, right = int(round(dw - 0.1)), int(
        round(dw + 0.1)
    )  # è®¡ç®—å·¦å³ä¸¤ä¾§çš„padding  # left=0 right=0

    # add border/pad
    img = cv2.copyMakeBorder(
        img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color
    )  # add border

    # img: (384, 512, 3) ratio=(1.0,1.0) è¿™é‡Œæ²¡æœ‰ç¼©æ”¾æ“ä½œ  (dw,dh)=(0.0, 20.5)
    return img, ratio, (dw, dh)

```

æ€»ç»“ä¸‹åœ¨val.pyæ•°æ®åŠ è½½éƒ¨åˆ†ä¸»è¦æ˜¯åšäº†ä¸‰ä»¶äº‹ï¼š

1. load_imageå°†å›¾ç‰‡ä»æ–‡ä»¶ä¸­åŠ è½½å‡ºæ¥ï¼Œå¹¶resizeåˆ°ç›¸åº”çš„å°ºå¯¸ï¼ˆæœ€é•¿è¾¹ç­‰äºæˆ‘ä»¬éœ€è¦çš„å°ºå¯¸ï¼Œæœ€çŸ­è¾¹ç­‰æ¯”ä¾‹ç¼©æ”¾ï¼‰ï¼›
2. letterboxå°†ä¹‹å‰resizeåçš„å›¾ç‰‡å†padåˆ°æˆ‘ä»¬æ‰€éœ€è¦çš„æ”¾åˆ°dataloaderä¸­ï¼ˆcollate_fnå‡½æ•°ï¼‰çš„å°ºå¯¸ï¼ˆçŸ©å½¢è®­ç»ƒè¦æ±‚åŒä¸€ä¸ª batchä¸­çš„å›¾ç‰‡çš„å°ºå¯¸å¿…é¡»ä¿æŒä¸€è‡´ï¼‰ï¼›
3. å°†labelä»ç›¸å¯¹åŸå›¾å°ºå¯¸ï¼ˆåŸæ–‡ä»¶ä¸­å›¾ç‰‡å°ºå¯¸ï¼‰ç¼©æ”¾åˆ°ç›¸å¯¹letterbox padåçš„å›¾ç‰‡å°ºå¯¸ã€‚å› ä¸ºå‰ä¸¤éƒ¨åˆ†çš„å›¾ç‰‡å°ºå¯¸å‘ç”Ÿäº†å˜åŒ–ï¼ŒåŒæ ·çš„æˆ‘ä»¬çš„labelä¹Ÿéœ€è¦å‘ç”Ÿç›¸åº”çš„å˜åŒ–ã€‚


## 5. cutout

> å›¾ç‰‡ä¸Šçš„éšæœºè£å‰ªåƒç´ å—

&emsp; cutoutæ•°æ®å¢å¼ºï¼Œç»™å›¾ç‰‡éšæœºæ·»åŠ éšæœºå¤§å°çš„æ–¹å—å™ªå£° ï¼Œç›®çš„æ˜¯æé«˜æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚æºè‡ªè®ºæ–‡ï¼š [Improved Regularization of Convolutional Neural Networks with Cutout](https://arxiv.org/abs/1708.04552) ã€‚

&emsp;æ›´å¤šåŸç†ç»†èŠ‚è¯·å‚é˜…ï¼š[mosaic è§£è¯»](https://start.oneflow.org/oneflow-yolo-doc/tutorials/04_chapter/mosaic.html) , [ã€YOLO v4ã€‘ã€trick 8ã€‘Data augmentation: MixUpã€Random Erasingã€CutOutã€CutMixã€Mosicã€‚](https://blog.csdn.net/qq_38253797/article/details/116668074)


ç¤ºä¾‹:
```python
image_path = "one-yolo/data/images/bus.jpg"
img = cv2.imread(str(image_path))
h, w = img.shape[:2]
labels = np.array([[0, 0, 0, 800, 800]])
print("åŸå›¾å®½é«˜:\nw1={}\nh1={}".format(w, h)) #  810, 1800
lb = cutout(im=img, labels=labels, p=1000.0)
cv2.imwrite("./00.jpg",img)
```

![image](https://user-images.githubusercontent.com/109639975/204717108-5e4cb777-569e-4320-be25-b7102726d745.png)


cutoutæ¨¡å—ä»£ç ï¼š


```python
def cutout(image, labels):
    """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—ä¸­çš„__getitem__å‡½æ•°è¿›è¡Œcutoutå¢å¼º  v5æºç ä½œè€…é»˜è®¤æ˜¯æ²¡ç”¨ç”¨è¿™ä¸ªçš„ æ„Ÿå…´è¶£çš„å¯ä»¥æµ‹è¯•ä¸€ä¸‹
    cutoutæ•°æ®å¢å¼º, ç»™å›¾ç‰‡éšæœºæ·»åŠ éšæœºå¤§å°çš„æ–¹å—å™ªå£°  ç›®çš„æ˜¯æé«˜æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§
    å®ç°ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªå›ºå®šå¤§å°çš„æ­£æ–¹å½¢åŒºåŸŸï¼Œç„¶åé‡‡ç”¨å…¨0å¡«å……å°±OKäº†ï¼Œå½“ç„¶ä¸ºäº†é¿å…å¡«å……0å€¼å¯¹è®­ç»ƒçš„å½±å“ï¼Œåº”è¯¥è¦å¯¹æ•°æ®è¿›è¡Œä¸­å¿ƒå½’ä¸€åŒ–æ“ä½œï¼Œnormåˆ°0ã€‚
    è®ºæ–‡: https://arxiv.org/abs/1708.04552
    :params image: ä¸€å¼ å›¾ç‰‡ [640, 640, 3] numpy
    :params labels: è¿™å¼ å›¾ç‰‡çš„æ ‡ç­¾ [N, 5]=[N, cls+x1y1x2y2]
    :return labels: ç­›é€‰åçš„è¿™å¼ å›¾ç‰‡çš„æ ‡ç­¾ [M, 5]=[M, cls+x1y1x2y2]  M<N
                    ç­›é€‰: å¦‚æœéšæœºç”Ÿæˆçš„å™ªå£°å’ŒåŸå§‹Fçš„gtæ¡†ç›¸äº¤åŒºåŸŸå gtæ¡†å¤ªå¤§ å°±ç­›å‡ºè¿™ä¸ªgtæ¡†label
    """
    h, w = image.shape[:2]  # è·å–å›¾ç‰‡é«˜å’Œå®½

    def bbox_ioa(box1, box2):
        """ç”¨åœ¨cutoutä¸­
        è®¡ç®—box1å’Œbox2ç›¸äº¤é¢ç§¯ä¸box2é¢ç§¯çš„æ¯”ä¾‹
        Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2
        :params box1: ä¼ å…¥éšæœºç”Ÿæˆå™ªå£° box  [4] = [x1y1x2y2]
        :params box2: ä¼ å…¥å›¾ç‰‡åŸå§‹çš„labelä¿¡æ¯ [n, 4] = [n, x1y1x2y2]
        :return [n, 1]  è¿”å›ä¸€ä¸ªç”Ÿæˆçš„å™ªå£°boxä¸nä¸ªåŸå§‹labelçš„ç›¸äº¤é¢ç§¯ä¸båŸå§‹labelçš„æ¯”å€¼
        """
        box2 = box2.transpose()

        # Get the coordinates of bounding boxes
        b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]
        b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]

        # æ±‚box1å’Œbox2çš„ç›¸äº¤é¢ç§¯
        inter_area = (np.minimum(b1_x2, b2_x2) - np.maximum(b1_x1, b2_x1)).clip(0) * \
                     (np.minimum(b1_y2, b2_y2) - np.maximum(b1_y1, b2_y1)).clip(0)

        # boxé¢ç§¯
        box2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1) + 1e-16

        # è¿”å›box1å’Œbox2ç›¸äº¤é¢ç§¯ ä¸ box2é¢ç§¯ä¹‹æ¯”
        return inter_area / box2_area

    # è®¾ç½®cutoutæ·»åŠ å™ªå£°çš„scale   create random masks
    scales = [0.5] * 1 + [0.25] * 2 + [0.125] * 4 + [0.0625] * 8 + [0.03125] * 16  # image size fraction
    for s in scales:
        # éšæœºç”Ÿæˆå™ªå£° å®½é«˜
        mask_h = random.randint(1, int(h * s))
        mask_w = random.randint(1, int(w * s))

        # éšæœºç”Ÿæˆå™ªå£° box
        xmin = max(0, random.randint(0, w) - mask_w // 2)
        ymin = max(0, random.randint(0, h) - mask_h // 2)
        xmax = min(w, xmin + mask_w)
        ymax = min(h, ymin + mask_h)

        # æ·»åŠ éšæœºé¢œè‰²çš„å™ªå£°  apply random color mask
        image[ymin:ymax, xmin:xmax] = [random.randint(64, 191) for _ in range(3)]

        # è¿”å›æ²¡æœ‰å™ªå£°çš„label   return unobscured labels
        if len(labels) and s > 0.03:
            box = np.array([xmin, ymin, xmax, ymax], dtype=np.float32)  # éšæœºç”Ÿæˆçš„å™ªå£°box
            # è®¡ç®—ç”Ÿæˆçš„ä¸€ä¸ªå™ªå£°boxä¸è¿™å¼ å›¾ç‰‡ä¸­æ‰€æœ‰gtçš„boxåšè®¡ç®— inter_area/label_area [n, 1]
            ioa = bbox_ioa(box, labels[:, 1:5])
            # remove>60% obscured labels  ä¸èƒ½åˆ‡çš„å¤ªå¤§  ioa < 0.60    ä¿ç•™cutoutå™ªå£°é®æŒ¡å°äº60%çš„æ ‡ç­¾
            labels = labels[ioa < 0.60]

    return labels

```

æ³¨æ„ï¼š

- åœ¨LoadImagesAndLabelsæ¨¡å—ä¸­çš„__getitem__å‡½æ•°è¿›è¡Œcutoutå¢å¼ºï¼š



## 6. mixup
&emsp;è¿™ä¸ªå‡½æ•°æ˜¯è¿›è¡Œmixupæ•°æ®å¢å¼ºï¼šæŒ‰æ¯”ä¾‹èåˆä¸¤å¼ å›¾ç‰‡ã€‚è®ºæ–‡ï¼š[https://arxiv.org/pdf/1710.09412.pdf](https://arxiv.org/pdf/1710.09412.pdf)ã€‚

&emsp;æ›´å¤šåŸç†ç»†èŠ‚è¯·çœ‹åšå®¢ï¼š[ã€YOLO v4ã€‘ã€trick 8ã€‘Data augmentation: MixUpã€Random Erasingã€CutOutã€CutMixã€Mosic](https://blog.csdn.net/qq_38253797/article/details/116668074)


ç¤ºä¾‹:
```python
img1 = cv2.imread("one-yolo/data/images/bus.jpg")
img2 = cv2.imread("one-yolo/data/images/zidane.jpg")
img2 = cv2.resize(img2,(810,1080))        
labels1 = np.array([[0, 0, 0, 800, 800]])
labels2 = np.array([[0, 800, 800, 1080, 810]])
img, labels = mixup(img1, labels1, img2, labels2)
cv2.imwrite("./00.jpg", img)
```

![image](https://user-images.githubusercontent.com/109639975/204719701-108dddbc-cdd8-4b76-a07d-0c9cab28855b.png)


mixupæ¨¡å—ä»£ç ï¼š


```python
def mixup(im, labels, im2, labels2):
    """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—ä¸­çš„__getitem__å‡½æ•°è¿›è¡Œmixupå¢å¼º
    mixupæ•°æ®å¢å¼º, æŒ‰æ¯”ä¾‹èåˆä¸¤å¼ å›¾ç‰‡  Applies MixUp augmentation
    è®ºæ–‡: https://arxiv.org/pdf/1710.09412.pdf
    :params im:å›¾ç‰‡1  numpy (640, 640, 3)
    :params labels:[N, 5]=[N, cls+x1y1x2y2]
    :params im2:å›¾ç‰‡2  (640, 640, 3)
    :params labels2:[M, 5]=[M, cls+x1y1x2y2]
    :return img: ä¸¤å¼ å›¾ç‰‡mixupå¢å¼ºåçš„å›¾ç‰‡ (640, 640, 3)
    :return labels: ä¸¤å¼ å›¾ç‰‡mixupå¢å¼ºåçš„labelæ ‡ç­¾ [M+N, cls+x1y1x2y2]
    """
    # éšæœºä»betaåˆ†å¸ƒä¸­è·å–æ¯”ä¾‹,range[0, 1]
    r = np.random.beta(32.0, 32.0)  # mixup ratio, alpha=beta=32.0
    # æŒ‰ç…§æ¯”ä¾‹èåˆä¸¤å¼ å›¾ç‰‡
    im = (im * r + im2 * (1 - r)).astype(np.uint8)
    # å°†ä¸¤å¼ å›¾ç‰‡æ ‡ç­¾æ‹¼æ¥åˆ°ä¸€èµ·
    labels = np.concatenate((labels, labels2), 0)
    return im, labels
```

æ³¨æ„:

- åœ¨LoadImagesAndLabelsæ¨¡å—ä¸­çš„__getitem__å‡½æ•°è¿›è¡Œmixupå¢å¼ºã€‚
- mixupå¢å¼ºç”±è¶…å‚hyp[â€˜mixupâ€™]æ§åˆ¶ï¼Œ0åˆ™å…³é—­ é»˜è®¤ä¸º1(è¡¨ç¤º100%æ‰“å¼€)ã€‚


## 7. hist_equalize
&emsp;è¿™ä¸ªå‡½æ•°æ˜¯ç”¨äºå¯¹å›¾ç‰‡è¿›è¡Œç›´æ–¹å›¾å‡è¡¡åŒ–å¤„ç†ï¼Œä½†æ˜¯åœ¨yolov5ä¸­å¹¶æ²¡æœ‰ç”¨åˆ°è¿™ä¸ªå‡½æ•°ï¼Œå­¦ä¹ äº†è§£ä¸‹å°±å¥½ï¼Œä¸æ˜¯é‡ç‚¹ã€‚

hist_equalizeæ¨¡å—ä»£ç :


```python
def hist_equalize(img, clahe=True, bgr=False):
    """yolov5å¹¶æ²¡æœ‰ä½¿ç”¨ç›´æ–¹å›¾å‡è¡¡åŒ–çš„å¢å¼ºæ“ä½œ  å¯ä»¥è‡ªå·±è¯•è¯•
    ç›´æ–¹å›¾å‡è¡¡åŒ–å¢å¼ºæ“ä½œ  Equalize histogram on BGR image 'img' with img.shape(n,m,3) and range 0-255
    :params img: è¦è¿›è¡Œç›´æ–¹å›¾å‡è¡¡åŒ–çš„åŸå›¾
    :params clahe: æ˜¯å¦è¦ç”Ÿæˆè‡ªé€‚åº”å‡è¡¡åŒ–å›¾ç‰‡ é»˜è®¤True å¦‚æœæ˜¯Falseå°±ç”Ÿæˆå…¨å±€å‡è¡¡åŒ–å›¾ç‰‡
    :params bgr: ä¼ å…¥çš„imgå›¾åƒæ˜¯å¦æ˜¯bgrå›¾ç‰‡ é»˜è®¤False
    :return img: å‡è¡¡åŒ–ä¹‹åçš„å›¾ç‰‡ å¤§å°ä¸å˜ æ ¼å¼RGB
    """
    # å›¾ç‰‡BGR/RGBæ ¼å¼ -> YUVæ ¼å¼
    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV if bgr else cv2.COLOR_RGB2YUV)
    if clahe:
        # cv2.createCLAHEç”Ÿæˆè‡ªé€‚åº”å‡è¡¡åŒ–å›¾åƒ
        c = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        yuv[:, :, 0] = c.apply(yuv[:, :, 0])
    else:
        # å…¨å±€å‡è¡¡åŒ–
        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])  # equalize Y channel histogram
    return cv2.cvtColor(
        yuv, cv2.COLOR_YUV2BGR if bgr else cv2.COLOR_YUV2RGB
    )  # convert YUV image to RGB
```

## Reference
- [Question about function box_candidates() in datasets.py](https://github.com/ultralytics/yolov5/issues/2442)
- ã€YOLOV5-5.x æºç è§£è¯»ã€‘[datasets.py](https://blog.csdn.net/qq_38253797/article/details/119904518)
- [yolov5æ•°æ®å¢å¼ºå¼•å‘çš„æ€è€ƒâ€”â€”é€è§†å˜æ¢çŸ©é˜µçš„åˆ›å»º](https://www.cnblogs.com/shuimuqingyang/p/14595210.html)
- [ä»¿å°„å˜æ¢åŠå…¶å˜æ¢çŸ©é˜µçš„ç†è§£](https://www.cnblogs.com/shine-lee/p/10950963.html)
