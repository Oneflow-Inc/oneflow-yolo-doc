## å‰è¨€

>ğŸ‰ä»£ç ä»“åº“åœ°å€ï¼š<a href="https://github.com/Oneflow-Inc/one-yolov5" target="blank">https://github.com/Oneflow-Inc/one-yolov5</a>
æ¬¢è¿star [one-yolov5é¡¹ç›®](https://github.com/Oneflow-Inc/one-yolov5) è·å–<a href="https://github.com/Oneflow-Inc/one-yolov5/tags" target="blank" >æœ€æ–°çš„åŠ¨æ€ã€‚</a>
<a href="https://github.com/Oneflow-Inc/one-yolov5/issues/new"  target="blank"  >å¦‚æœæ‚¨æœ‰é—®é¢˜ï¼Œæ¬¢è¿åœ¨ä»“åº“ç»™æˆ‘ä»¬æå‡ºå®è´µçš„æ„è§ã€‚ğŸŒŸğŸŒŸğŸŒŸ</a>
<a href="https://github.com/Oneflow-Inc/one-yolov5" target="blank" >
å¦‚æœå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿æ¥ç»™æˆ‘Starå‘€ğŸ˜Š~  </a>


æºç è§£è¯»ï¼š [utils/dataloaders.py](https://github.com/Oneflow-Inc/one-yolov5/blob/main/utils/dataloaders.py)



## 1. å¯¼å…¥éœ€è¦çš„åŒ…å’ŒåŸºæœ¬é…ç½®


```python
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Dataloaders and dataset utils
"""

import contextlib
import glob # pythonè‡ªå·±å¸¦çš„ä¸€ä¸ªæ–‡ä»¶æ“ä½œç›¸å…³æ¨¡å— æŸ¥æ‰¾ç¬¦åˆè‡ªå·±ç›®çš„çš„æ–‡ä»¶(å¦‚æ¨¡ç³ŠåŒ¹é…)
import hashlib  # å“ˆå¸Œæ¨¡å— æä¾›äº†å¤šç§å®‰å…¨æ–¹ä¾¿çš„hashæ–¹æ³•
import json  # jsonæ–‡ä»¶æ“ä½œæ¨¡å—
import math  # æ•°å­¦å…¬å¼æ¨¡å—
import  os  # ä¸æ“ä½œç³»ç»Ÿè¿›è¡Œäº¤äº’çš„æ¨¡å— åŒ…å«æ–‡ä»¶è·¯å¾„æ“ä½œå’Œè§£æ
import random  # ç”Ÿæˆéšæœºæ•°æ¨¡å—
import shutil # æ–‡ä»¶å¤¹ã€å‹ç¼©åŒ…å¤„ç†æ¨¡å—
import time  # æ—¶é—´æ¨¡å— æ›´åº•å±‚
from itertools import repeat # å¤åˆ¶æ¨¡å—
from multiprocessing.pool import Pool, ThreadPool  # å¤šçº¿ç¨‹æ¨¡å— çº¿ç¨‹æ± 
from pathlib import Path   # Pathå°†strè½¬æ¢ä¸ºPathå¯¹è±¡ ä½¿å­—ç¬¦ä¸²è·¯å¾„æ˜“äºæ“ä½œçš„æ¨¡å—
from threading import Thread   # å¤šçº¿ç¨‹æ“ä½œæ¨¡å—
from urllib.parse import urlparse
from zipfile import ZipFile

import numpy as np # numpyçŸ©é˜µæ“ä½œæ¨¡å—
import oneflow as flow    # OneFlowæ·±åº¦å­¦ä¹ æ¨¡å—
import oneflow.nn.functional as F     # OneFlowå‡½æ•°æ¥å£ å°è£…äº†å¾ˆå¤šå·ç§¯ã€æ± åŒ–ç­‰å‡½æ•°
import yaml  # yamlæ–‡ä»¶æ“ä½œæ¨¡å—
from oneflow.utils.data import DataLoader, Dataset, dataloader, distributed
from PIL import ExifTags, Image, ImageOps    # å›¾ç‰‡ã€ç›¸æœºæ“ä½œæ¨¡å—
from tqdm import tqdm   # è¿›åº¦æ¡æ¨¡å—

from utils.augmentations import Albumentations, augment_hsv, copy_paste, letterbox, mixup, random_perspective

from utils.general import (
    DATASETS_DIR,
    LOGGER,
    NUM_THREADS,
    check_dataset,
    check_requirements,
    check_yaml,
    clean_str,
    cv2,
    is_colab,
    is_kaggle,
    segments2boxes,
    xyn2xy,
    xywh2xyxy,
    xywhn2xyxy,
    xyxy2xywhn,
)
# from utils.oneflow_utils import oneflow_distributed_zero_first

# Parameters
HELP_URL = "https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data"
IMG_FORMATS = (
    "bmp",
    "dng",
    "jpeg",
    "jpg",
    "mpo",
    "png",
    "tif",
    "tiff",
    "webp",
)  # include image suffixes
VID_FORMATS = (
    "asf",
    "avi",
    "gif",
    "m4v",
    "mkv",
    "mov",
    "mp4",
    "mpeg",
    "mpg",
    "ts",
    "wmv",
)  # include video suffixes
BAR_FORMAT = "{l_bar}{bar:10}{r_bar}{bar:-10b}"  # tqdm bar format
LOCAL_RANK = int(os.getenv("LOCAL_RANK", -1))  # https://pytorch.org/docs/stable/elastic/run.html
RANK = int(os.getenv("RANK", -1))
```

## 2. ç›¸æœºè®¾ç½®
&emsp;è¿™éƒ¨åˆ†æ˜¯ç›¸æœºç›¸å…³è®¾ç½®ï¼Œå½“ä½¿ç”¨ç›¸æœºé‡‡æ ·æ—¶æ‰ä¼šä½¿ç”¨ã€‚


```python
# ç›¸æœºè®¾ç½®
# Get orientation exif tag
# ä¸“é—¨ä¸ºæ•°ç ç›¸æœºçš„ç…§ç‰‡è€Œè®¾å®š  å¯ä»¥è®°å½•æ•°ç ç…§ç‰‡çš„å±æ€§ä¿¡æ¯å’Œæ‹æ‘„æ•°æ®
for orientation in ExifTags.TAGS.keys():
    if ExifTags.TAGS[orientation] == "Orientation":
        break


def get_hash(paths):
    # è¿”å›æ–‡ä»¶åˆ—è¡¨çš„hashå€¼
    # Returns a single hash value of a list of paths (files or dirs)
    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes
    h = hashlib.md5(str(size).encode())  # hash sizes
    h.update("".join(paths).encode())  # hash paths
    return h.hexdigest()  # return hash


def exif_size(img):
    # è·å–æ•°ç ç›¸æœºçš„å›¾ç‰‡å®½é«˜ä¿¡æ¯  å¹¶ä¸”åˆ¤æ–­æ˜¯å¦éœ€è¦æ—‹è½¬ï¼ˆæ•°ç ç›¸æœºå¯ä»¥å¤šè§’åº¦æ‹æ‘„ï¼‰
    # Returns exif-corrected PIL size
    s = img.size  # (width, height)
    with contextlib.suppress(Exception):
        rotation = dict(img._getexif().items())[orientation]
        if rotation in [6, 8]:  # rotation 270 or 90
            s = (s[1], s[0])
    return s


def exif_transpose(image):
    """
    å¦‚æœæœ‰EXIFæ–¹å‘æ ‡è®°ï¼Œåˆ™ç›¸åº”è°ƒæ¢PILå›¾åƒã€‚
    Transpose a PIL image accordingly if it has an EXIF Orientation tag.
    Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose()

    :param image: The image to transpose.
    :return: An image.
    """
    exif = image.getexif()
    orientation = exif.get(0x0112, 1)  # default 1
    if orientation > 1:
        method = {
            2: Image.FLIP_LEFT_RIGHT,
            3: Image.ROTATE_180,
            4: Image.FLIP_TOP_BOTTOM,
            5: Image.TRANSPOSE,
            6: Image.ROTATE_270,
            7: Image.TRANSVERSE,
            8: Image.ROTATE_90,
        }.get(orientation)
        if method is not None:
            image = image.transpose(method)
            del exif[0x0112]
            image.info["exif"] = exif.tobytes()
    return image
```


```python
def seed_worker(worker_id):
    # Set dataloader worker seed https://pyflow.org/docs/stable/notes/randomness.html#dataloader
    worker_seed = flow.initial_seed() % 2 ** 32
    np.random.seed(worker_seed)
    random.seed(worker_seed)


def create_dataloader(
    path, #  path: å›¾ç‰‡æ•°æ®åŠ è½½è·¯å¾„ train/test  å¦‚: ../datasets/coco/images/train2017
    imgsz, #  train/testå›¾ç‰‡å°ºå¯¸ï¼ˆæ•°æ®å¢å¼ºåå¤§å°ï¼‰ 640
    batch_size,#  batch size å¤§å° 8/16/32
    stride, # æ¨¡å‹æœ€å¤§stride=32   [32 16 8]
    single_cls=False, #  æ•°æ®é›†æ˜¯å¦æ˜¯å•ç±»åˆ« é»˜è®¤False
    hyp=None,# è¶…å‚åˆ—è¡¨dict ç½‘ç»œè®­ç»ƒæ—¶çš„ä¸€äº›è¶…å‚æ•°ï¼ŒåŒ…æ‹¬å­¦ä¹ ç‡ç­‰ï¼Œè¿™é‡Œä¸»è¦ç”¨åˆ°é‡Œé¢ä¸€äº›å…³äºæ•°æ®å¢å¼º(æ—‹è½¬ã€å¹³ç§»ç­‰)çš„ç³»æ•°
    augment=False,# æ˜¯å¦è¦è¿›è¡Œæ•°æ®å¢å¼º  True
    cache=False, # æ˜¯å¦cache_images False
    pad=0.0, # è®¾ç½®çŸ©å½¢è®­ç»ƒçš„shapeæ—¶è¿›è¡Œçš„å¡«å…… é»˜è®¤0.0
    rect=False, # æ˜¯å¦å¼€å¯çŸ©å½¢train/test  é»˜è®¤è®­ç»ƒé›†å…³é—­ éªŒè¯é›†å¼€å¯
    rank=-1, # å¤šå¡è®­ç»ƒæ—¶çš„è¿›ç¨‹ç¼–å· rankä¸ºè¿›ç¨‹ç¼–å·  -1ä¸”gpu=1æ—¶ä¸è¿›è¡Œåˆ†å¸ƒå¼  -1ä¸”å¤šå—gpuä½¿ç”¨DataParallelæ¨¡å¼  é»˜è®¤-1
    workers=8,# dataloaderçš„numworks åŠ è½½æ•°æ®æ—¶çš„cpuè¿›ç¨‹æ•°
    image_weights=False, # è®­ç»ƒæ—¶æ˜¯å¦æ ¹æ®å›¾ç‰‡æ ·æœ¬çœŸå®æ¡†åˆ†å¸ƒæƒé‡æ¥é€‰æ‹©å›¾ç‰‡  é»˜è®¤False
    quad=False, # dataloaderå–æ•°æ®æ—¶, æ˜¯å¦ä½¿ç”¨collate_fn4ä»£æ›¿collate_fn  é»˜è®¤False
    prefix="", # æ˜¾ç¤ºä¿¡æ¯   ä¸€ä¸ªæ ‡å¿—ï¼Œå¤šä¸ºtrain/valï¼Œå¤„ç†æ ‡ç­¾æ—¶ä¿å­˜cacheæ–‡ä»¶ä¼šç”¨åˆ°
    shuffle=False,# å¯¹è®­ç»ƒæ•°æ®æ˜¯å¦éšæœºæ‰“ä¹±ã€‚
):  
    """åœ¨train.pyä¸­è¢«è°ƒç”¨ï¼Œç”¨äºç”ŸæˆTrainloader, datasetï¼Œtestloader
    è‡ªå®šä¹‰dataloaderå‡½æ•°: è°ƒç”¨LoadImagesAndLabelsè·å–æ•°æ®é›†(åŒ…æ‹¬æ•°æ®å¢å¼º) + è°ƒç”¨åˆ†å¸ƒå¼é‡‡æ ·å™¨DistributedSampler +
                        è‡ªå®šä¹‰InfiniteDataLoader è¿›è¡Œæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
    """
    if rect and shuffle:
        LOGGER.warning("WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False")
        shuffle = False
    # è½½å…¥æ–‡ä»¶æ•°æ®(å¢å¼ºæ•°æ®é›†)
    dataset = LoadImagesAndLabels(
        path,
        imgsz,
        batch_size,
        augment=augment,  # augmentation
        hyp=hyp,  # hyperparameters
        rect=rect,  # rectangular batches
        cache_images=cache,
        single_cls=single_cls,
        stride=int(stride),
        pad=pad,
        image_weights=image_weights,
        prefix=prefix,
    )

    batch_size = min(batch_size, len(dataset))
    nd = flow.cuda.device_count()  # number of CUDA devices
    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])  # number of workers
    # åˆ†å¸ƒå¼é‡‡æ ·å™¨DistributedSampler
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)
    # ä½¿ç”¨InfiniteDataLoaderå’Œ_RepeatSampleræ¥å¯¹DataLoaderè¿›è¡Œå°è£…, ä»£æ›¿åŸDå…ˆçš„DataLoader, èƒ½å¤Ÿæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
    loader = DataLoader if image_weights else InfiniteDataLoader  # only DataLoader allows for attribute updates
    generator = flow.Generator()
    generator.manual_seed(6148914691236517205 + RANK)
    return (
        loader(
            dataset,
            batch_size=batch_size,
            shuffle=shuffle and sampler is None,
            num_workers=nw,
            sampler=sampler,
            pin_memory=True,
            collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn,
            worker_init_fn=seed_worker,
            generator=generator,
        ),
        dataset,
    )
```

## 3.è‡ªå®šä¹‰DataLoader
&emsp;å½“image_weights=Falseæ—¶ï¼ˆä¸æ ¹æ®å›¾ç‰‡æ ·æœ¬çœŸå®æ¡†åˆ†å¸ƒæƒé‡æ¥é€‰æ‹©å›¾ç‰‡ï¼‰å°±ä¼šè°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•° è¿›è¡Œè‡ªå®šä¹‰DataLoaderï¼Œè¿›è¡ŒæŒç»­æ€§é‡‡æ ·ã€‚åœ¨ä¸Šé¢çš„create_dataloaderæ¨¡å—ä¸­è¢«è°ƒç”¨ã€‚



```python
class InfiniteDataLoader(dataloader.DataLoader):
    """Dataloader that reuses workers
    å½“image_weights=Falseæ—¶å°±ä¼šä½¿ç”¨InfiniteDataLoaderå’Œ_RepeatSamplerè¿™ä¸¤ä¸ªç±»å®ç°è‡ªå®šä¹‰DataLoader
    ä½¿ç”¨InfiniteDataLoaderå’Œ_RepeatSampleræ¥å¯¹DataLoaderè¿›è¡Œå°è£…, ä»£æ›¿åŸå…ˆçš„DataLoader, èƒ½å¤Ÿæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
    Uses same syntax as vanilla DataLoader
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # è°ƒç”¨_RepeatSamplerè¿›è¡ŒæŒç»­é‡‡æ ·
        object.__setattr__(self, "batch_sampler", _RepeatSampler(self.batch_sampler))
        self.iterator = super().__iter__()

    def __len__(self):
        return len(self.batch_sampler.sampler)

    def __iter__(self):
        for _ in range(len(self)):
            yield next(self.iterator)


class _RepeatSampler:
    """Sampler that repeats forever
     è¿™éƒ¨åˆ†æ˜¯è¿›è¡ŒæŒç»­é‡‡æ ·
    Args:
        sampler (Sampler)
    """

    def __init__(self, sampler):
        self.sampler = sampler

    def __iter__(self):
        while True:
            yield from iter(self.sampler)
```

## 4. LoadImagesAndLabels
&emsp;è¿™ä¸ªéƒ¨åˆ†æ˜¯æ•°æ®è½½å…¥ï¼ˆæ•°æ®å¢å¼ºï¼‰éƒ¨åˆ†ï¼Œ

ä¹Ÿå°±æ˜¯è‡ªå®šä¹‰æ•°æ®é›†éƒ¨åˆ†ï¼Œç»§æ‰¿è‡ªDatasetï¼Œéœ€è¦é‡å†™__init__,__getitem()__ç­‰æŠ½è±¡æ–¹æ³•ï¼Œ

å¦å¤–ç›®æ ‡æ£€æµ‹ä¸€èˆ¬è¿˜éœ€è¦é‡å†™collate_fnå‡½æ•°ã€‚æ‰€ä»¥ï¼Œç†è§£è¿™ä¸‰ä¸ªå‡½æ•°æ˜¯ç†è§£æ•°æ®å¢å¼ºï¼ˆæ•°æ®è½½å…¥ï¼‰çš„é‡ä¸­ä¹‹é‡ã€‚

### 4.1 init
è¿™ä¸ªå‡½æ•°çš„å…¥å£æ˜¯ä¸Šé¢çš„create_dataloaderå‡½æ•°ï¼š
<!-- ![image.png](dataladers_imgs/picture_00.png)
![image-2.png](dataladers_imgs/picture_01.png)  -->
![image](https://user-images.githubusercontent.com/109639975/199916141-2ac22f90-abe0-4b0f-8654-282c857d5804.png)
![image](https://user-images.githubusercontent.com/109639975/199916291-e60a796a-2e77-4fa1-aa22-869cafb23969.png)

__init__ ä¸»è¦å¹²äº†ä¸€ä¸‹å‡ ä»¶äº‹ï¼š

1. èµ‹å€¼ä¸€äº›åŸºç¡€çš„selfå˜é‡ ç”¨äºåé¢åœ¨__getitem__ä¸­è°ƒç”¨
2. å¾—åˆ°pathè·¯å¾„ä¸‹çš„æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„self.img_files
3. æ ¹æ®imgsè·¯å¾„æ‰¾åˆ°labelsçš„è·¯å¾„self.label_files
3. cache label
4. Read cache ç”Ÿæˆself.labelsã€self.shapesã€self.img_filesã€self.label_filesã€self.batchã€self.nã€self.indicesç­‰å˜é‡
5. ä¸ºRectangular Trainingä½œå‡†å¤‡: ç”Ÿæˆself.batch_shapes
6. æ˜¯å¦éœ€è¦cache image(ä¸€èˆ¬ä¸éœ€è¦ï¼Œå¤ªå¤§äº†)


__init__å‡½æ•°ä»£ç ï¼š


```python
 class LoadImagesAndLabels(Dataset):
    def __init__(
        self,
        path, 
        img_size=640,
        batch_size=16,
        augment=False,
        hyp=None,
        rect=False,
        image_weights=False,
        cache_images=False,
        single_cls=False,
        stride=32,
        pad=0.0,
        prefix="",
    ):
    """
    åˆå§‹åŒ–è¿‡ç¨‹å¹¶æ²¡æœ‰ä»€ä¹ˆå®è´¨æ€§çš„æ“ä½œ,æ›´å¤šæ˜¯ä¸€ä¸ªå®šä¹‰å‚æ•°çš„è¿‡ç¨‹ï¼ˆselfå‚æ•°ï¼‰,ä»¥ä¾¿åœ¨__getitem()__ä¸­è¿›è¡Œæ•°æ®å¢å¼ºæ“ä½œ,æ‰€ä»¥è¿™éƒ¨åˆ†ä»£ç åªéœ€è¦æŠ“ä½selfä¸­çš„å„ä¸ªå˜é‡çš„å«ä¹‰å°±ç®—å·®ä¸å¤šäº†
    self.img_files: {list: N} å­˜æ”¾ç€æ•´ä¸ªæ•°æ®é›†å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„
    self.label_files: {list: N} å­˜æ”¾ç€æ•´ä¸ªæ•°æ®é›†å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„
    cache label -> verify_image_label
    self.labels: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  labelså­˜å‚¨çš„labelå°±éƒ½æ˜¯åŸå§‹label(éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢label)
                 å¦åˆ™å°†æ‰€æœ‰å›¾ç‰‡æ­£å¸¸gtçš„labelå­˜å…¥labels ä¸æ­£å¸¸gt(å­˜åœ¨ä¸€ä¸ªå¤šè¾¹å½¢)ç»è¿‡segments2boxesè½¬æ¢ä¸ºæ­£å¸¸çš„çŸ©å½¢label
    self.shapes: æ‰€æœ‰å›¾ç‰‡çš„shape
    self.segments: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  self.segments=None
                   å¦åˆ™å­˜å‚¨æ•°æ®é›†ä¸­æ‰€æœ‰å­˜åœ¨å¤šè¾¹å½¢gtçš„å›¾ç‰‡çš„æ‰€æœ‰åŸå§‹label(è‚¯å®šæœ‰å¤šè¾¹å½¢label ä¹Ÿå¯èƒ½æœ‰çŸ©å½¢æ­£å¸¸label æœªçŸ¥æ•°)
    self.batch: è®°è½½ç€æ¯å¼ å›¾ç‰‡å±äºå“ªä¸ªbatch
    self.n: æ•°æ®é›†ä¸­æ‰€æœ‰å›¾ç‰‡çš„æ•°é‡
    self.indices: è®°è½½ç€æ‰€æœ‰å›¾ç‰‡çš„index
    self.rect=Trueæ—¶self.batch_shapesè®°è½½æ¯ä¸ªbatchçš„shape(åŒä¸€ä¸ªbatchçš„å›¾ç‰‡shapeç›¸åŒ)
    """
       # 1ã€èµ‹å€¼ä¸€äº›åŸºç¡€çš„selfå˜é‡ ç”¨äºåé¢åœ¨__getitem__ä¸­è°ƒç”¨
        self.img_size = img_size  # ç»è¿‡æ•°æ®å¢å¼ºåçš„æ•°æ®å›¾ç‰‡çš„å¤§å°
        self.augment = augment    # æ˜¯å¦å¯åŠ¨æ•°æ®å¢å¼º ä¸€èˆ¬è®­ç»ƒæ—¶æ‰“å¼€ éªŒè¯æ—¶å…³é—­
        self.hyp = hyp            # è¶…å‚åˆ—è¡¨
        # å›¾ç‰‡æŒ‰æƒé‡é‡‡æ ·  Trueå°±å¯ä»¥æ ¹æ®ç±»åˆ«é¢‘ç‡(é¢‘ç‡é«˜çš„æƒé‡å°,åæ­£å¤§)æ¥è¿›è¡Œé‡‡æ ·  é»˜è®¤False: ä¸ä½œç±»åˆ«åŒºåˆ†
        self.image_weights = image_weights
        self.rect = False if image_weights else rect  # æ˜¯å¦å¯åŠ¨çŸ©å½¢è®­ç»ƒ ä¸€èˆ¬è®­ç»ƒæ—¶å…³é—­ éªŒè¯æ—¶æ‰“å¼€ å¯ä»¥åŠ é€Ÿ
        self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)
        # mosaicå¢å¼ºçš„è¾¹ç•Œå€¼  [-320, -320]
        self.mosaic_border = [-img_size // 2, -img_size // 2]
        self.stride = stride      # æœ€å¤§ä¸‹é‡‡æ ·ç‡ 32
        self.path = path          # å›¾ç‰‡è·¯å¾„
        self.albumentations = Albumentations() if augment else None
        # 2ã€å¾—åˆ°pathè·¯å¾„ä¸‹çš„æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„self.img_files  è¿™é‡Œéœ€è¦è‡ªå·±debugä¸€ä¸‹ ä¸ä¼šå¤ªéš¾
        try:
            f = []  # image files
            for p in path if isinstance(path, list) else [path]:
                # è·å–æ•°æ®é›†è·¯å¾„pathï¼ŒåŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶æˆ–è€…åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
                # ä½¿ç”¨pathlib.Pathç”Ÿæˆä¸æ“ä½œç³»ç»Ÿæ— å…³çš„è·¯å¾„ï¼Œå› ä¸ºä¸åŒæ“ä½œç³»ç»Ÿè·¯å¾„çš„â€˜/â€™ä¼šæœ‰æ‰€ä¸åŒ
                p = Path(p)  # os-agnostic
                # å¦‚æœè·¯å¾„pathä¸ºåŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
                if p.is_dir():  # dir
                    # glob.glab: è¿”å›æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨  é€’å½’è·å–pè·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶
                    f += glob.glob(str(p / '**' / '*.*'), recursive=True)
                    # f = list(p.rglob('**/*.*'))  # pathlib
                # å¦‚æœè·¯å¾„pathä¸ºåŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶
                elif p.is_file():  # file
                    with open(p, 'r') as t:
                        t = t.read().strip().splitlines()  # è·å–å›¾ç‰‡è·¯å¾„ï¼Œæ›´æ¢ç›¸å¯¹è·¯å¾„
                        # è·å–æ•°æ®é›†è·¯å¾„çš„ä¸Šçº§çˆ¶ç›®å½•  os.sepä¸ºè·¯å¾„é‡Œçš„åˆ†éš”ç¬¦ï¼ˆä¸åŒè·¯å¾„çš„åˆ†éš”ç¬¦ä¸åŒï¼Œos.sepå¯ä»¥æ ¹æ®ç³»ç»Ÿè‡ªé€‚åº”ï¼‰
                        parent = str(p.parent) + os.sep
                        f += [x.replace('./', parent) if x.startswith('./') else x for x in t]  # local to global path
                        # f += [p.parent / x.lstrip(os.sep) for x in t]  # local to global path (pathlib)
                else:
                    raise Exception(f'{prefix}{p} does not exist')
            # ç ´æŠ˜å·æ›¿æ¢ä¸ºos.sepï¼Œos.path.splitext(x)å°†æ–‡ä»¶åä¸æ‰©å±•ååˆ†å¼€å¹¶è¿”å›ä¸€ä¸ªåˆ—è¡¨
            # ç­›é€‰fä¸­æ‰€æœ‰çš„å›¾ç‰‡æ–‡ä»¶
            self.im_files = sorted(x.replace("/", os.sep) for x in f if x.split(".")[-1].lower() in IMG_FORMATS)
            # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib
            assert self.im_files, f"{prefix}No images found"
        except Exception as e:
            raise Exception(f"{prefix}Error loading data from {path}: {e}\nSee {HELP_URL}")

        # Check cache  3æ ¹æ®imgsè·¯å¾„æ‰¾åˆ°labelsçš„è·¯å¾„self.label_files
        self.label_files = img2label_paths(self.im_files)  # labels
        # 4ã€cache label ä¸‹æ¬¡è¿è¡Œè¿™ä¸ªè„šæœ¬çš„æ—¶å€™ç›´æ¥ä»cacheä¸­å–labelè€Œä¸æ˜¯å»æ–‡ä»¶ä¸­å–label é€Ÿåº¦æ›´å¿«
        cache_path = (p if p.is_file() else Path(self.label_files[0]).parent).with_suffix(".cache")
        try:
            # å¦‚æœæœ‰cacheæ–‡ä»¶ï¼Œç›´æ¥åŠ è½½  exists=True: æ˜¯å¦å·²ä»cacheæ–‡ä»¶ä¸­è¯»å‡ºäº†nf, nm, ne, nc, nç­‰ä¿¡æ¯
            cache, exists = np.load(cache_path, allow_pickle=True).item(), True  # load dict
            assert cache["version"] == self.cache_version  # matches current version
            assert cache["hash"] == get_hash(self.label_files + self.im_files)  # identical hash
        except Exception:
            # å¦‚æœå›¾ç‰‡ç‰ˆæœ¬ä¿¡æ¯æˆ–è€…æ–‡ä»¶åˆ—è¡¨çš„hashå€¼å¯¹ä¸ä¸Šå· è¯´æ˜æœ¬åœ°æ•°æ®é›†å›¾ç‰‡å’Œlabelå¯èƒ½å‘ç”Ÿäº†å˜åŒ– å°±é‡æ–°cache labelæ–‡ä»¶
            cache, exists = self.cache_labels(cache_path, prefix), False  # run cache ops

        # Display cache
        # æ‰“å°cacheçš„ç»“æœ nf nm ne nc n = æ‰¾åˆ°çš„æ ‡ç­¾æ•°é‡ï¼Œæ¼æ‰çš„æ ‡ç­¾æ•°é‡ï¼Œç©ºçš„æ ‡ç­¾æ•°é‡ï¼ŒæŸåçš„æ ‡ç­¾æ•°é‡ï¼Œæ€»çš„æ ‡ç­¾æ•°é‡
        nf, nm, ne, nc, n = cache.pop("results")  # found, missing, empty, corrupt, total
        # å¦‚æœå·²ç»ä»cacheæ–‡ä»¶è¯»å‡ºäº†nf nm ne nc nç­‰ä¿¡æ¯ï¼Œç›´æ¥æ˜¾ç¤ºæ ‡ç­¾ä¿¡æ¯  msgsä¿¡æ¯ç­‰
        if exists and LOCAL_RANK in {-1, 0}:
            d = f"Scanning '{cache_path}' images and labels... {nf} found, {nm} missing, {ne} empty, {nc} corrupt"
            tqdm(None, desc=prefix + d, total=n, initial=n, bar_format=BAR_FORMAT)  # display cache results
            if cache["msgs"]:
                LOGGER.info("\n".join(cache["msgs"]))  # display warnings
        # æ•°æ®é›†æ²¡æœ‰æ ‡ç­¾ä¿¡æ¯ å°±å‘å‡ºè­¦å‘Šå¹¶æ˜¾ç¤ºæ ‡ç­¾labelä¸‹è½½åœ°å€help_url
        assert nf > 0 or not augment, f"{prefix}No labels in {cache_path}. Can not train without labels. See {HELP_URL}"

         # 5ã€Read cache  ä»cacheä¸­è¯»å‡ºæœ€æ–°å˜é‡èµ‹ç»™self  æ–¹ä¾¿ç»™forwardä¸­ä½¿ç”¨
        # cacheä¸­çš„é”®å€¼å¯¹æœ€åˆæœ‰: cache[img_file]=[l, shape, segments] cache[hash] cache[results] cache[msg] cache[version]
        # å…ˆä»cacheä¸­å»é™¤cacheæ–‡ä»¶ä¸­å…¶ä»–æ— å…³é”®å€¼å¦‚:'hash', 'version', 'msgs'ç­‰éƒ½åˆ é™¤
        [cache.pop(k) for k in ('hash', 'version', 'msgs')]  # remove items
        # popæ‰resultsã€hashã€versionã€msgsååªå‰©ä¸‹cache[img_file]=[l, shape, segments]
        # cache.values(): å–cacheä¸­æ‰€æœ‰å€¼ å¯¹åº”æ‰€æœ‰l, shape, segments
        # labels: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  labelså­˜å‚¨çš„labelå°±éƒ½æ˜¯åŸå§‹label(éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢label)
        #         å¦åˆ™å°†æ‰€æœ‰å›¾ç‰‡æ­£å¸¸gtçš„labelå­˜å…¥labels ä¸æ­£å¸¸gt(å­˜åœ¨ä¸€ä¸ªå¤šè¾¹å½¢)ç»è¿‡segments2boxesè½¬æ¢ä¸ºæ­£å¸¸çš„çŸ©å½¢label
        # shapes: æ‰€æœ‰å›¾ç‰‡çš„shape
        # self.segments: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  self.segments=None
        #                å¦åˆ™å­˜å‚¨æ•°æ®é›†ä¸­æ‰€æœ‰å­˜åœ¨å¤šè¾¹å½¢gtçš„å›¾ç‰‡çš„æ‰€æœ‰åŸå§‹label(è‚¯å®šæœ‰å¤šè¾¹å½¢label ä¹Ÿå¯èƒ½æœ‰çŸ©å½¢æ­£å¸¸label æœªçŸ¥æ•°)
        # zip æ˜¯å› ä¸ºcacheä¸­æ‰€æœ‰labelsã€shapesã€segmentsä¿¡æ¯éƒ½æ˜¯æŒ‰æ¯å¼ imgåˆ†å¼€å­˜å‚¨çš„, zipæ˜¯å°†æ‰€æœ‰å›¾ç‰‡å¯¹åº”çš„ä¿¡æ¯å åœ¨ä¸€èµ·
        labels, shapes, self.segments = zip(*cache.values())  # segments: éƒ½æ˜¯[]
        self.labels = list(labels)
        self.shapes = np.array(shapes)
        self.im_files = list(cache.keys())  # update
        self.label_files = img2label_paths(cache.keys())  # update  æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„label_filesä¿¡æ¯(å› ä¸ºimg_filesä¿¡æ¯å¯èƒ½å‘ç”Ÿäº†å˜åŒ–)
        n = len(shapes)  # number of images
        bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index
        nb = bi[-1] + 1  # number of batches
        self.batch = bi  # batch index of image æ‰€æœ‰å›¾ç‰‡çš„index
        self.n = n
        self.indices = range(n)

        # Update labels
        
        include_class = []  # filter labels to include only these classes (optional)
        include_class_array = np.array(include_class).reshape(1, -1)
        for i, (label, segment) in enumerate(zip(self.labels, self.segments)):
            if include_class:
                j = (label[:, 0:1] == include_class_array).any(1)
                self.labels[i] = label[j]
                if segment:
                    self.segments[i] = segment[j]
            if single_cls:  # single-class training, merge all classes into 0
                self.labels[i][:, 0] = 0
                if segment:
                    self.segments[i][:, 0] = 0
        
        # Rectangular Training
        # 6ã€ä¸ºRectangular Trainingä½œå‡†å¤‡
        # è¿™é‡Œä¸»è¦æ˜¯æ³¨æ„shapesçš„ç”Ÿæˆ è¿™ä¸€æ­¥å¾ˆé‡è¦ å› ä¸ºå¦‚æœé‡‡æ ·çŸ©å½¢è®­ç»ƒé‚£ä¹ˆæ•´ä¸ªbatchçš„å½¢çŠ¶è¦ä¸€æ · å°±è¦è®¡ç®—è¿™ä¸ªç¬¦åˆæ•´ä¸ªbatchçš„shape
        # è€Œä¸”è¿˜è¦å¯¹æ•°æ®é›†æŒ‰ç…§é«˜å®½æ¯”è¿›è¡Œæ’åº è¿™æ ·æ‰èƒ½ä¿è¯åŒä¸€ä¸ªbatchçš„å›¾ç‰‡çš„å½¢çŠ¶å·®ä¸å¤šç›¸åŒ å†é€‰åˆ™ä¸€ä¸ªå…±åŒçš„shapeä»£ä»·ä¹Ÿæ¯”è¾ƒå°
        if self.rect:
            # Sort by aspect ratio
            s = self.shapes  # wh
            ar = s[:, 1] / s[:, 0]  # aspect ratio
            irect = ar.argsort()  # æ ¹æ®é«˜å®½æ¯”æ’åº
            self.img_files = [self.img_files[i] for i in irect]      # è·å–æ’åºåçš„img_files
            self.label_files = [self.label_files[i] for i in irect]  # è·å–æ’åºåçš„label_files
            self.labels = [self.labels[i] for i in irect]            # è·å–æ’åºåçš„labels
            self.shapes = s[irect]                                   # è·å–æ’åºåçš„wh
            ar = ar[irect]                                           # è·å–æ’åºåçš„aspect ratio

            # è®¡ç®—æ¯ä¸ªbatché‡‡ç”¨çš„ç»Ÿä¸€å°ºåº¦ Set training image shapes
            shapes = [[1, 1]] * nb    # nb: number of batches
            for i in range(nb):
                ari = ar[bi == i]     # bi: batch index
                mini, maxi = ari.min(), ari.max()   # è·å–ç¬¬iä¸ªbatchä¸­ï¼Œæœ€å°å’Œæœ€å¤§é«˜å®½æ¯”
                # å¦‚æœé«˜/å®½å°äº1(w > h)ï¼Œå°†wè®¾ä¸ºimg_sizeï¼ˆä¿è¯åŸå›¾åƒå°ºåº¦ä¸å˜è¿›è¡Œç¼©æ”¾ï¼‰
                if maxi < 1:
                    shapes[i] = [maxi, 1]   # maxi: hç›¸å¯¹æŒ‡å®šå°ºåº¦çš„æ¯”ä¾‹  1: wç›¸å¯¹æŒ‡å®šå°ºåº¦çš„æ¯”ä¾‹
                # å¦‚æœé«˜/å®½å¤§äº1(w < h)ï¼Œå°†hè®¾ç½®ä¸ºimg_sizeï¼ˆä¿è¯åŸå›¾åƒå°ºåº¦ä¸å˜è¿›è¡Œç¼©æ”¾ï¼‰
                elif mini > 1:
                    shapes[i] = [1, 1 / mini]

            # è®¡ç®—æ¯ä¸ªbatchè¾“å…¥ç½‘ç»œçš„shapeå€¼(å‘ä¸Šè®¾ç½®ä¸º32çš„æ•´æ•°å€)
            # è¦æ±‚æ¯ä¸ªbatch_shapesçš„é«˜å®½éƒ½æ˜¯32çš„æ•´æ•°å€ï¼Œæ‰€ä»¥è¦å…ˆé™¤ä»¥32ï¼Œå–æ•´å†ä¹˜ä»¥32ï¼ˆä¸è¿‡img_sizeå¦‚æœæ˜¯32å€æ•°è¿™é‡Œå°±æ²¡å¿…è¦äº†ï¼‰
            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(np.int) * stride
        
        # 7ã€æ˜¯å¦éœ€è¦cache image ä¸€èˆ¬æ˜¯False å› ä¸ºRAMä¼šä¸è¶³  cache labelè¿˜å¯ä»¥ ä½†æ˜¯cache imageå°±å¤ªå¤§äº† æ‰€ä»¥ä¸€èˆ¬ä¸ç”¨
        # Cache images into RAM/disk for faster training (WARNING: large datasets may exceed system resources)
        self.ims = [None] * n
        self.npy_files = [Path(f).with_suffix(".npy") for f in self.im_files]
        if cache_images:
            gb = 0  # Gigabytes of cached images
            self.im_hw0, self.im_hw = [None] * n, [None] * n
            fcn = self.cache_images_to_disk if cache_images == "disk" else self.load_image
            results = ThreadPool(NUM_THREADS).imap(fcn, range(n))
            pbar = tqdm(enumerate(results), total=n, bar_format=BAR_FORMAT, disable=LOCAL_RANK > 0)
            for i, x in pbar:
                if cache_images == "disk":
                    gb += self.npy_files[i].stat().st_size
                else:  # 'ram'
                    (
                        self.ims[i],
                        self.im_hw0[i],
                        self.im_hw[i],
                    ) = x  # im, hw_orig, hw_resized = load_image(self, i)
                    gb += self.ims[i].nbytes
                pbar.desc = f"{prefix}Caching images ({gb / 1E9:.1f}GB {cache_images})"
            pbar.close()
```

### 4.2 cache_labels
è¿™ä¸ªå‡½æ•°ç”¨äºåŠ è½½æ–‡ä»¶è·¯å¾„ä¸­çš„labelä¿¡æ¯ç”Ÿæˆcacheæ–‡ä»¶ã€‚cacheæ–‡ä»¶ä¸­åŒ…æ‹¬çš„ä¿¡æ¯æœ‰ï¼šim_file, l, shape, segments, hash, results, msgs, versionç­‰ï¼Œå…·ä½“çœ‹ä»£ç æ³¨é‡Šã€‚


```python
def cache_labels(self, path=Path('./labels.cache'), prefix=''):
    """ç”¨åœ¨__init__å‡½æ•°ä¸­  cacheæ•°æ®é›†label
    åŠ è½½labelä¿¡æ¯ç”Ÿæˆcacheæ–‡ä»¶   Cache dataset labels, check images and read shapes
    :params path: cacheæ–‡ä»¶ä¿å­˜åœ°å€
    :params prefix: æ—¥å¿—å¤´éƒ¨ä¿¡æ¯(å½©æ‰“é«˜äº®éƒ¨åˆ†)
    :return x: cacheä¸­ä¿å­˜çš„å­—å…¸
           åŒ…æ‹¬çš„ä¿¡æ¯æœ‰: x[im_file] = [l, shape, segments]
                      ä¸€å¼ å›¾ç‰‡ä¸€ä¸ªlabelç›¸å¯¹åº”çš„ä¿å­˜åˆ°x, æœ€ç»ˆxä¼šä¿å­˜æ‰€æœ‰å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„ã€gtæ¡†çš„ä¿¡æ¯ã€å½¢çŠ¶shapeã€æ‰€æœ‰çš„å¤šè¾¹å½¢gtä¿¡æ¯
                          im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
                          l: å½“å‰è¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(ä¸åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, cls+xywh(normalized)]
                          shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
                          segments: å½“å‰è¿™å¼ å›¾ç‰‡æ‰€æœ‰gtçš„labelä¿¡æ¯(åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
                       hash: å½“å‰å›¾ç‰‡å’Œlabelæ–‡ä»¶çš„hashå€¼  1
                       results: æ‰¾åˆ°çš„labelä¸ªæ•°nf, ä¸¢å¤±labelä¸ªæ•°nm, ç©ºlabelä¸ªæ•°ne, ç ´æŸlabelä¸ªæ•°nc, æ€»img/labelä¸ªæ•°len(self.img_files)
                       msgs: æ‰€æœ‰æ•°æ®é›†çš„msgsä¿¡æ¯
                       version: å½“å‰cache version
    """
    x = {}  # åˆå§‹åŒ–æœ€ç»ˆcacheä¸­ä¿å­˜çš„å­—å…¸dict
    # åˆå§‹åŒ–number missing, found, empty, corrupt, messages
    # åˆå§‹åŒ–æ•´ä¸ªæ•°æ®é›†: æ¼æ‰çš„æ ‡ç­¾(label)æ€»æ•°é‡, æ‰¾åˆ°çš„æ ‡ç­¾(label)æ€»æ•°é‡, ç©ºçš„æ ‡ç­¾(label)æ€»æ•°é‡, é”™è¯¯æ ‡ç­¾(label)æ€»æ•°é‡, æ‰€æœ‰é”™è¯¯ä¿¡æ¯
    nm, nf, ne, nc, msgs = 0, 0, 0, 0, []
    desc = f"{prefix}Scanning '{path.parent / path.stem}' images and labels..."  # æ—¥å¿—
    # å¤šè¿›ç¨‹è°ƒç”¨verify_image_labelå‡½æ•°
    with Pool(num_threads) as pool:
        # å®šä¹‰pbarè¿›åº¦æ¡
        # pool.imap_unordered: å¯¹å¤§é‡æ•°æ®éå†å¤šè¿›ç¨‹è®¡ç®— è¿”å›ä¸€ä¸ªè¿­ä»£å™¨
        # æŠŠself.img_files, self.label_files, repeat(prefix) listä¸­çš„å€¼ä½œä¸ºå‚æ•°ä¾æ¬¡é€å…¥(ä¸€æ¬¡é€ä¸€ä¸ª)verify_image_labelå‡½æ•°
        pbar = tqdm(pool.imap_unordered(verify_image_label, zip(self.img_files, self.label_files, repeat(prefix))),
                    desc=desc, total=len(self.img_files))
        # im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
        # l: [gt_num, cls+xywh(normalized)]
        #    å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ lå°±å­˜å‚¨åŸlabel(å…¨éƒ¨æ˜¯æ­£å¸¸çŸ©å½¢æ ‡ç­¾)
        #    å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾  lå°±å­˜å‚¨ç»è¿‡segments2boxeså¤„ç†å¥½çš„æ ‡ç­¾(æ­£å¸¸çŸ©å½¢æ ‡ç­¾ä¸å¤„ç† å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºçŸ©å½¢æ ‡ç­¾)
        # shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
        # segments: å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å­˜å‚¨None
        #           å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å°±æŠŠè¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰labelå­˜å‚¨åˆ°segmentsä¸­(è‹¥å¹²ä¸ªæ­£å¸¸gt è‹¥å¹²ä¸ªå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
        # nm_f(nm): number missing å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦ä¸¢å¤±         ä¸¢å¤±=1    å­˜åœ¨=0
        # nf_f(nf): number found å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦å­˜åœ¨           å­˜åœ¨=1    ä¸¢å¤±=0
        # ne_f(ne): number empty å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦æ˜¯ç©ºçš„         ç©ºçš„=1    æ²¡ç©º=0
        # nc_f(nc): number corrupt å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ–‡ä»¶æ˜¯å¦æ˜¯ç ´æŸçš„  ç ´æŸçš„=1  æ²¡ç ´æŸ=0
        # msg: è¿”å›çš„msgä¿¡æ¯  labelæ–‡ä»¶å®Œå¥½=â€˜â€™  labelæ–‡ä»¶ç ´æŸ=warningä¿¡æ¯
        for im_file, l, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:
            nm += nm_f  # ç´¯åŠ æ€»number missing label
            nf += nf_f  # ç´¯åŠ æ€»number found label
            ne += ne_f  # ç´¯åŠ æ€»number empty label
            nc += nc_f  # ç´¯åŠ æ€»number corrupt label
            if im_file:
                x[im_file] = [l, shape, segments]  # ä¿¡æ¯å­˜å…¥å­—å…¸ key=im_file  value=[l, shape, segments]
            if msg:
                msgs.append(msg)  # å°†msgåŠ å…¥æ€»msg
            pbar.desc = f"{desc}{nf} found, {nm} missing, {ne} empty, {nc} corrupted"  # æ—¥å¿—
    pbar.close()  # å…³é—­è¿›åº¦æ¡
    # æ—¥å¿—æ‰“å°æ‰€æœ‰msgä¿¡æ¯
    if msgs:
        logging.info('\n'.join(msgs))
    # ä¸€å¼ labeléƒ½æ²¡æ‰¾åˆ° æ—¥å¿—æ‰“å°help_urlä¸‹è½½åœ°å€
    if nf == 0:
        logging.info(f'{prefix}WARNING: No labels found in {path}. See {help_url}')
    x['hash'] = get_hash(self.label_files + self.img_files)  # å°†å½“å‰å›¾ç‰‡å’Œlabelæ–‡ä»¶çš„hashå€¼å­˜å…¥æœ€ç»ˆå­—å…¸dist
    x['results'] = nf, nm, ne, nc, len(self.img_files)  # å°†nf, nm, ne, nc, len(self.img_files)å­˜å…¥æœ€ç»ˆå­—å…¸dist
    x['msgs'] = msgs  # å°†æ‰€æœ‰æ•°æ®é›†çš„msgsä¿¡æ¯å­˜å…¥æœ€ç»ˆå­—å…¸dist
    x['version'] = 0.3  # å°†å½“å‰cache versionå­˜å…¥æœ€ç»ˆå­—å…¸dist
    try:
        torch.save(x, path)  # save cache to path
        logging.info(f'{prefix}New cache created: {path}')
    except Exception as e:
        logging.info(f'{prefix}WARNING: Cache directory {path.parent} is not writeable: {e}')  # path not writeable
    return x

```

### 4.3 __getitem__
&emsp;è¿™éƒ¨åˆ†æ˜¯æ•°æ®å¢å¼ºå‡½æ•°ï¼Œä¸€èˆ¬ä¸€æ¬¡æ€§æ‰§è¡Œbatch_sizeæ¬¡ã€‚


```python
    def __getitem__(self, index):
          """
        è¿™éƒ¨åˆ†æ˜¯æ•°æ®å¢å¼ºå‡½æ•°ï¼Œä¸€èˆ¬ä¸€æ¬¡æ€§æ‰§è¡Œbatch_sizeæ¬¡ã€‚
        è®­ç»ƒ æ•°æ®å¢å¼º: mosaic(random_perspective) + hsv + ä¸Šä¸‹å·¦å³ç¿»è½¬
        æµ‹è¯• æ•°æ®å¢å¼º: letterbox
        :return torch.from_numpy(img): è¿™ä¸ªindexçš„å›¾ç‰‡æ•°æ®(å¢å¼ºå) [3, 640, 640]
        :return labels_out: è¿™ä¸ªindexå›¾ç‰‡çš„gt label [6, 6] = [gt_num, 0+class+xywh(normalized)]
        :return self.img_files[index]: è¿™ä¸ªindexå›¾ç‰‡çš„è·¯å¾„åœ°å€
        :return shapes: è¿™ä¸ªbatchçš„å›¾ç‰‡çš„shapes æµ‹è¯•æ—¶(çŸ©å½¢è®­ç»ƒ)æ‰æœ‰  éªŒè¯æ—¶ä¸ºNone   for COCO mAP rescaling
        """
        # è¿™é‡Œå¯ä»¥é€šè¿‡ä¸‰ç§å½¢å¼è·å–è¦è¿›è¡Œæ•°æ®å¢å¼ºçš„å›¾ç‰‡index  linear, shuffled, or image_weights
        index = self.indices[index]  # linear, shuffled, or image_weights

        hyp = self.hyp   # è¶…å‚ åŒ…å«ä¼—å¤šæ•°æ®å¢å¼ºè¶…å‚
        mosaic = self.mosaic and random.random() < hyp["mosaic"]
        # mosaicå¢å¼º å¯¹å›¾åƒè¿›è¡Œ4å¼ å›¾æ‹¼æ¥è®­ç»ƒ  ä¸€èˆ¬è®­ç»ƒæ—¶è¿è¡Œ
        # mosaic + MixUp
        if mosaic:
            # Load mosaic
            img, labels = self.load_mosaic(index)
            shapes = None

            # MixUp augmentation
            if random.random() < hyp["mixup"]:
                img, labels = mixup(img, labels, *self.load_mosaic(random.randint(0, self.n - 1)))

        else:
            # Load image
            # è½½å…¥å›¾ç‰‡  è½½å…¥å›¾ç‰‡åè¿˜ä¼šè¿›è¡Œä¸€æ¬¡resize  å°†å½“å‰å›¾ç‰‡çš„æœ€é•¿è¾¹ç¼©æ”¾åˆ°æŒ‡å®šçš„å¤§å°(512), è¾ƒå°è¾¹åŒæ¯”ä¾‹ç¼©æ”¾
            # load image img=(343, 512, 3)=(h, w, c)  (h0, w0)=(335, 500)  numpy  index=4
            # img: resizeåçš„å›¾ç‰‡   (h0, w0): åŸå§‹å›¾ç‰‡çš„hw  (h, w): resizeåçš„å›¾ç‰‡çš„hw
            # è¿™ä¸€æ­¥æ˜¯å°†(335, 500, 3) resize-> (343, 512, 3)
            img, (h0, w0), (h, w) = self.load_image(index)

            # Letterbox
            # letterboxä¹‹å‰ç¡®å®šè¿™å¼ å½“å‰å›¾ç‰‡letterboxä¹‹åçš„shape  
            # å¦‚æœä¸ç”¨self.rectçŸ©å½¢è®­ç»ƒshapeå°±æ˜¯self.img_size
            # å¦‚æœä½¿ç”¨self.rectçŸ©å½¢è®­ç»ƒshapeå°±æ˜¯å½“å‰batchçš„shape
            # å› ä¸ºçŸ©å½¢è®­ç»ƒçš„è¯æˆ‘ä»¬æ•´ä¸ªbatchçš„shapeå¿…é¡»ç»Ÿä¸€(åœ¨__init__å‡½æ•°ç¬¬6èŠ‚å†…å®¹)
            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape
            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)
            shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling

            labels = self.labels[index].copy()
            if labels.size:  # normalized xywh to pixel xyxy format
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1])

            if self.augment:
                # random_perspectiveå¢å¼º: éšæœºå¯¹å›¾ç‰‡è¿›è¡Œæ—‹è½¬ï¼Œå¹³ç§»ï¼Œç¼©æ”¾ï¼Œè£å‰ªï¼Œé€è§†å˜æ¢
                img, labels = random_perspective(
                    img,
                    labels,
                    degrees=hyp["degrees"],
                    translate=hyp["translate"],
                    scale=hyp["scale"],
                    shear=hyp["shear"],
                    perspective=hyp["perspective"],
                )

        nl = len(labels)  # number of labels
        if nl:
            labels[:, 1:5] = xyxy2xywhn(labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=True, eps=1e-3)

        if self.augment:
            # Albumentations
            img, labels = self.albumentations(img, labels)
            nl = len(labels)  # update after albumentations

            # HSV color-space è‰²åŸŸç©ºé—´å¢å¼ºAugment colorspace
            augment_hsv(img, hgain=hyp["hsv_h"], sgain=hyp["hsv_s"], vgain=hyp["hsv_v"])

            # Flip up-down
            if random.random() < hyp["flipud"]:
                img = np.flipud(img)
                if nl:
                    labels[:, 2] = 1 - labels[:, 2]

            # Flip left-right éšæœºå·¦å³ç¿»è½¬ 
            if random.random() < hyp["fliplr"]:
                img = np.fliplr(img)
                if nl:
                    labels[:, 1] = 1 - labels[:, 1]

            # Cutouts
            # labels = cutout(img, labels, p=0.5)
            # nl = len(labels)  # update after cutout
        
        # 6ä¸ªå€¼çš„tensor åˆå§‹åŒ–æ ‡ç­¾æ¡†å¯¹åº”çš„å›¾ç‰‡åºå·, é…åˆä¸‹é¢çš„collate_fnä½¿ç”¨
        labels_out = flow.zeros((nl, 6))
        if nl:
            labels_out[:, 1:] = flow.from_numpy(labels)
         
        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img) # imgå˜æˆå†…å­˜è¿ç»­çš„æ•°æ®  åŠ å¿«è¿ç®—                                                                                     

        return flow.from_numpy(img), labels_out, self.im_files[index], shapes
```

### 4.4 collate_fn
&emsp;å¾ˆå¤šäººä»¥ä¸ºå†™å®Œ __init__ å’Œ __getitem__ å‡½æ•°æ•°æ®å¢å¼ºå°±åšå®Œäº†ï¼Œæˆ‘ä»¬åœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„ç¡®å†™å®Œè¿™ä¸¤ä¸ªå‡½æ•°å°±å¯ä»¥äº†ï¼Œå› ä¸ºç³»ç»Ÿä¸­æ˜¯ç»™æˆ‘ä»¬å†™å¥½äº†ä¸€ä¸ªcollate_fnå‡½æ•°çš„ï¼Œä½†æ˜¯åœ¨ç›®æ ‡æ£€æµ‹ä¸­æˆ‘ä»¬å´éœ€è¦é‡å†™collate_fnå‡½æ•°ï¼Œä¸‹é¢æˆ‘ä¼šä»”ç»†çš„è®²è§£è¿™æ ·åšçš„åŸå› ï¼ˆä»£ç ä¸­æ³¨é‡Šï¼‰ã€‚

åŒæ ·åœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
<a href="https://github.com/Oneflow-Inc/one-yolov5/blob/640ac163ee26a8b13bb2e94f348fb3752a250886/utils/dataloaders.py#L183-L195
"  target="blank"> 
![image](https://user-images.githubusercontent.com/109639975/199916498-ee01bd46-9bdc-4cf8-90ce-958f483ce257.png)
</a>


```python
    @staticmethod
    def collate_fn4(batch):
        """åŒæ ·åœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
        è¿™é‡Œæ˜¯yolo-v5ä½œè€…å®éªŒæ€§çš„ä¸€ä¸ªä»£ç  quad-collate function å½“train.pyçš„optå‚æ•°quad=True åˆ™è°ƒç”¨collate_fn4ä»£æ›¿collate_fn
        ä½œç”¨:  å¦‚ä¹‹å‰ç”¨collate_fnå¯ä»¥è¿”å›å›¾ç‰‡[16, 3, 640, 640] ç»è¿‡collate_fn4åˆ™è¿”å›å›¾ç‰‡[4, 3, 1280, 1280]
              å°†4å¼ mosaicå›¾ç‰‡[1, 3, 640, 640]åˆæˆä¸€å¼ å¤§çš„mosaicå›¾ç‰‡[1, 3, 1280, 1280]
              å°†ä¸€ä¸ªbatchçš„å›¾ç‰‡æ¯å››å¼ å¤„ç†, 0.5çš„æ¦‚ç‡å°†å››å¼ å›¾ç‰‡æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Šè®­ç»ƒ, 0.5æ¦‚ç‡ç›´æ¥å°†æŸå¼ å›¾ç‰‡ä¸Šé‡‡æ ·ä¸¤å€è®­ç»ƒ
        """
        # img: æ•´ä¸ªbatchçš„å›¾ç‰‡ [16, 3, 640, 640]
        # label: æ•´ä¸ªbatchçš„labelæ ‡ç­¾ [num_target, img_index+class_index+xywh(normalized)]
        # path: æ•´ä¸ªbatchæ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„
        # shapes: (h0, w0), ((h / h0, w / w0), pad)    for COCO mAP rescaling
        img, label, path, shapes = zip(*batch)  # transposed
        n = len(shapes) // 4 # collate_fn4å¤„ç†åè¿™ä¸ªbatchä¸­å›¾ç‰‡çš„ä¸ªæ•°
        im4, label4, path4, shapes4 = [], [], path[:n], shapes[:n] # åˆå§‹åŒ–

        ho = flow.tensor([[0.0, 0, 0, 1, 0, 0]])
        wo = flow.tensor([[0.0, 0, 1, 0, 0, 0]])
        s = flow.tensor([[1, 1, 0.5, 0.5, 0.5, 0.5]])  # scale
        for i in range(n):  # zidane flow.zeros(16,3,720,1280)  # BCHW
            i *= 4 # é‡‡æ · [0, 4, 8, 16]
            if random.random() < 0.5: # éšæœºæ•°å°äº0.5å°±ç›´æ¥å°†æŸå¼ å›¾ç‰‡ä¸Šé‡‡æ ·ä¸¤å€è®­ç»ƒ
                im = F.interpolate(img[i].unsqueeze(0).float(), scale_factor=2.0, mode="bilinear", align_corners=False,)[
                    0
                ].type(img[i].type())
                lb = label[i]
            else:
                # éšæœºæ•°å¤§äº0.5å°±å°†å››å¼ å›¾ç‰‡(mosaicåçš„)æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Šè®­ç»ƒ
                im = flow.cat(
                    (
                        flow.cat((img[i], img[i + 1]), 1),
                        flow.cat((img[i + 2], img[i + 3]), 1),
                    ),
                    2,
                )
                lb = flow.cat((label[i], label[i + 1] + ho, label[i + 2] + wo, label[i + 3] + ho + wo), 0) * s
            im4.append(im)
            label4.append(lb)
        
        # åé¢è¿”å›çš„éƒ¨åˆ†å’Œcollate_fnå°±å·®ä¸å¤šäº† åŸå› å’Œè§£é‡Šéƒ½å†™åœ¨ä¸Šä¸€ä¸ªå‡½æ•°äº† è‡ªå·±debugçœ‹ä¸€ä¸‹å§
        for i, lb in enumerate(label4):
            lb[:, 0] = i  # add target image index for build_targets()

        return flow.stack(im4, 0), flow.cat(label4, 0), path4, shapes4
```

## 5. img2label_paths
&emsp;è¿™ä¸ªæ–‡ä»¶æ˜¯æ ¹æ®æ•°æ®é›†ä¸­æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„æ‰¾åˆ°æ•°æ®é›†ä¸­æ‰€æœ‰labelså¯¹åº”çš„è·¯å¾„ã€‚

ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__init__å‡½æ•°ä¸­ã€‚


```python
def img2label_paths(img_paths):
    """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__init__å‡½æ•°ä¸­
    æ ¹æ®imgså›¾ç‰‡çš„è·¯å¾„æ‰¾åˆ°å¯¹åº”labelsçš„è·¯å¾„
    Define label paths as a function of image paths
    :params img_paths: {list: 50}  æ•´ä¸ªæ•°æ®é›†çš„å›¾ç‰‡ç›¸å¯¹è·¯å¾„  ä¾‹å¦‚: '..\\datasets\\VOC\\images\\train2007\\000012.jpg'
                                                        =>   '..\\datasets\\VOC\\labels\\train2007\\000012.jpg'
    """
    # å› ä¸ºpythonæ˜¯è·¨å¹³å°çš„,åœ¨Windowsä¸Š,æ–‡ä»¶çš„è·¯å¾„åˆ†éš”ç¬¦æ˜¯'\',åœ¨Linuxä¸Šæ˜¯'/'
    # ä¸ºäº†è®©ä»£ç åœ¨ä¸åŒçš„å¹³å°ä¸Šéƒ½èƒ½è¿è¡Œï¼Œé‚£ä¹ˆè·¯å¾„åº”è¯¥å†™'\'è¿˜æ˜¯'/'å‘¢ï¼Ÿ os.sepæ ¹æ®ä½ æ‰€å¤„çš„å¹³å°, è‡ªåŠ¨é‡‡ç”¨ç›¸åº”çš„åˆ†éš”ç¬¦å·
    # sa: '\\images\\'    sb: '\\labels\\'
    sa, sb = os.sep + 'images' + os.sep, os.sep + 'labels' + os.sep  # /images/, /labels/ substrings
    # æŠŠimg_pathsä¸­æ‰€ä»¥å›¾ç‰‡è·¯å¾„ä¸­çš„imagesæ›¿æ¢ä¸ºlabels
    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]
```

## 6. verify_image_label
&emsp;è¿™ä¸ªå‡½æ•°ç”¨äºæ£€æŸ¥æ¯ä¸€å¼ å›¾ç‰‡å’Œæ¯ä¸€å¼ labelæ–‡ä»¶æ˜¯å¦å®Œå¥½ã€‚

&emsp; å›¾ç‰‡æ–‡ä»¶: æ£€æŸ¥å†…å®¹ã€æ ¼å¼ã€å¤§å°ã€å®Œæ•´æ€§

&emsp; labelæ–‡ä»¶: æ£€æŸ¥æ¯ä¸ªgtå¿…é¡»æ˜¯çŸ©å½¢(æ¯è¡Œéƒ½å¾—æ˜¯5ä¸ªæ•° class+xywh) + æ ‡ç­¾æ˜¯å¦å…¨éƒ¨>=0 + æ ‡ç­¾åæ ‡xywhæ˜¯å¦å½’ä¸€åŒ– + æ ‡ç­¾ä¸­æ˜¯å¦æœ‰é‡å¤çš„åæ ‡

verify_image_labelå‡½æ•°ä»£ç ï¼š


```python
def verify_image_label(args):
    """ç”¨åœ¨cache_labelså‡½æ•°ä¸­
    æ£€æµ‹æ•°æ®é›†ä¸­æ¯å¼ å›¾ç‰‡å’Œæ¯å¼ laeblæ˜¯å¦å®Œå¥½
    å›¾ç‰‡æ–‡ä»¶: å†…å®¹ã€æ ¼å¼ã€å¤§å°ã€å®Œæ•´æ€§
    labelæ–‡ä»¶: æ¯ä¸ªgtå¿…é¡»æ˜¯çŸ©å½¢(æ¯è¡Œéƒ½å¾—æ˜¯5ä¸ªæ•° class+xywh) + æ ‡ç­¾æ˜¯å¦å…¨éƒ¨>=0 + æ ‡ç­¾åæ ‡xywhæ˜¯å¦å½’ä¸€åŒ– + æ ‡ç­¾ä¸­æ˜¯å¦æœ‰é‡å¤çš„åæ ‡
    :params im_file: æ•°æ®é›†ä¸­ä¸€å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
    :params lb_file: æ•°æ®é›†ä¸­ä¸€å¼ å›¾ç‰‡çš„labelç›¸å¯¹è·¯å¾„
    :params prefix: æ—¥å¿—å¤´éƒ¨ä¿¡æ¯(å½©æ‰“é«˜äº®éƒ¨åˆ†)
    :return im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
    :return l: [gt_num, cls+xywh(normalized)]
               å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ lå°±å­˜å‚¨åŸlabel(å…¨éƒ¨æ˜¯æ­£å¸¸çŸ©å½¢æ ‡ç­¾)
               å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾  lå°±å­˜å‚¨ç»è¿‡segments2boxeså¤„ç†å¥½çš„æ ‡ç­¾(æ­£å¸¸çŸ©å½¢æ ‡ç­¾ä¸å¤„ç† å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºçŸ©å½¢æ ‡ç­¾)
    :return shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
    :return segments: å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å­˜å‚¨None
                      å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å°±æŠŠè¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰labelå­˜å‚¨åˆ°segmentsä¸­(è‹¥å¹²ä¸ªæ­£å¸¸gt è‹¥å¹²ä¸ªå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
    :return nm: number missing å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦ä¸¢å¤±         ä¸¢å¤±=1    å­˜åœ¨=0
    :return nf: number found å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦å­˜åœ¨           å­˜åœ¨=1    ä¸¢å¤±=0
    :return ne: number empty å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦æ˜¯ç©ºçš„         ç©ºçš„=1    æ²¡ç©º=0
    :return nc: number corrupt å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ–‡ä»¶æ˜¯å¦æ˜¯ç ´æŸçš„  ç ´æŸçš„=1  æ²¡ç ´æŸ=0
    :return msg: è¿”å›çš„msgä¿¡æ¯  labelæ–‡ä»¶å®Œå¥½=â€˜â€™  labelæ–‡ä»¶ç ´æŸ=warningä¿¡æ¯
    """
    # Verify one image-label pair
    im_file, lb_file, prefix = args
    nm, nf, ne, nc, msg, segments = (
        0,
        0,
        0,
        0,
        "",
        [],
    )  # number (missing, found, empty, corrupt), message, segments
    try:
        # verify images   æ£€æŸ¥è¿™å¼ å›¾ç‰‡(å†…å®¹ã€æ ¼å¼ã€å¤§å°ã€å®Œæ•´æ€§) verify images
        im = Image.open(im_file) # æ‰“å¼€å›¾ç‰‡æ–‡ä»¶
        im.verify()  # PIL verify  æ£€æŸ¥å›¾ç‰‡å†…å®¹å’Œæ ¼å¼æ˜¯å¦æ­£å¸¸
        shape = exif_size(im)  # image size å½“å‰å›¾ç‰‡çš„å¤§å° image size
        # å›¾ç‰‡å¤§å°å¿…é¡»å¤§äº9ä¸ªpixels
        assert (shape[0] > 9) & (shape[1] > 9), f"image size {shape} <10 pixels" 
        # å›¾ç‰‡æ ¼å¼å¿…é¡»åœ¨img_formatä¸­
        assert im.format.lower() in IMG_FORMATS, f"invalid image format {im.format}"
        if im.format.lower() in ("jpg", "jpeg"): # æ£€æŸ¥jpgæ ¼å¼æ–‡ä»¶
            with open(im_file, "rb") as f:
                # f.seek: -2 åç§»é‡ å‘æ–‡ä»¶å¤´æ–¹å‘ä¸­ç§»åŠ¨çš„å­—èŠ‚æ•°   2 ç›¸å¯¹ä½ç½® ä»æ–‡ä»¶å°¾å¼€å§‹åç§»
                f.seek(-2, 2) 
                # f.read(): è¯»å–å›¾ç‰‡æ–‡ä»¶  æŒ‡ä»¤: \xff\xd9  æ£€æµ‹æ•´å¼ å›¾ç‰‡æ˜¯å¦å®Œæ•´  å¦‚æœä¸å®Œæ•´å°±è¿”å›corrupted JPEG
                if f.read() != b"\xff\xd9":  # corrupt JPEG
                    ImageOps.exif_transpose(Image.open(im_file)).save(im_file, "JPEG", subsampling=0, quality=100)
                    msg = f"{prefix}WARNING: {im_file}: corrupt JPEG restored and saved"

        # verify labels
        if os.path.isfile(lb_file):
            nf = 1  # label found
            with open(lb_file) as f:
                # è¯»å–å½“å‰labelæ–‡ä»¶çš„æ¯ä¸€è¡Œ: æ¯ä¸€è¡Œéƒ½æ˜¯å½“å‰å›¾ç‰‡çš„ä¸€ä¸ªgt
                lb = [x.split() for x in f.read().strip().splitlines() if len(x)]
                # any() å‡½æ•°ç”¨äºåˆ¤æ–­ç»™å®šçš„å¯è¿­ä»£å‚æ•° æ˜¯å¦å…¨éƒ¨ä¸ºFalse,åˆ™è¿”å› False; å¦‚æœæœ‰ä¸€ä¸ªä¸º True,åˆ™è¿”å›True
                # å¦‚æœå½“å‰å›¾ç‰‡çš„labelæ–‡ä»¶æŸä¸€åˆ—æ•°å¤§äº8, åˆ™è®¤ä¸ºlabelæ˜¯å­˜åœ¨segmentçš„polygonç‚¹(å¤šè¾¹å½¢) 
                # å°±ä¸æ˜¯çŸ©é˜µ åˆ™å°†labelä¿¡æ¯å­˜å…¥segmentä¸­
                if any(len(x) > 6 for x in lb):  # is segment
                    # å½“å‰å›¾ç‰‡ä¸­æ‰€æœ‰gtæ¡†çš„ç±»åˆ«
                    classes = np.array([x[0] for x in lb], dtype=np.float32)
                    # è·å¾—è¿™å¼ å›¾ä¸­æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾)
                    # å› ä¸ºsegmentæ ‡ç­¾å¯ä»¥æ˜¯ä¸åŒé•¿åº¦ï¼Œæ‰€ä»¥è¿™é‡Œsegmentsæ˜¯ä¸€ä¸ªåˆ—è¡¨ [gt_num, xy1...(normalized)]
                    segments = [np.array(x[1:], dtype=np.float32).reshape(-1, 2) for x in lb]  # (cls, xy1...)
                    # è·å¾—è¿™å¼ å›¾ä¸­æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(ä¸åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾)
                    # segments(å¤šè¾¹å½¢) -> bbox(æ­£æ–¹å½¢), å¾—åˆ°æ–°æ ‡ç­¾  [gt_num, cls+xywh(normalized)]
                    lb = np.concatenate((classes.reshape(-1, 1), segments2boxes(segments)), 1)  # (cls, xywh)
                lb = np.array(lb, dtype=np.float32)
            nl = len(lb)
            if nl: 
                # åˆ¤æ–­æ ‡ç­¾æ˜¯å¦æœ‰äº”åˆ—
                assert lb.shape[1] == 5, f"labels require 5 columns, {lb.shape[1]} columns detected"
                # åˆ¤æ–­æ ‡ç­¾æ˜¯å¦å…¨éƒ¨>=0
                assert (lb >= 0).all(), f"negative label values {lb[lb < 0]}"
                # åˆ¤æ–­æ ‡ç­¾ä¸­æ˜¯å¦æœ‰é‡å¤çš„åæ ‡
                assert (lb[:, 1:] <= 1).all(), f"non-normalized or out of bounds coordinates {lb[:, 1:][lb[:, 1:] > 1]}"
                _, i = np.unique(lb, axis=0, return_index=True)
                if len(i) < nl:  # duplicate row check
                    lb = lb[i]  # remove duplicates
                    if segments:
                        segments = segments[i]
                    msg = f"{prefix}WARNING: {im_file}: {nl - len(i)} duplicate labels removed"
            else:
                ne = 1  # label empty  l.shape[0] == 0åˆ™ä¸ºç©ºçš„æ ‡ç­¾ï¼Œne=1
                lb = np.zeros((0, 5), dtype=np.float32) 
        else:
            nm = 1  # label missing
            lb = np.zeros((0, 5), dtype=np.float32)
        return im_file, lb, shape, segments, nm, nf, ne, nc, msg
    except Exception as e:
        nc = 1
        msg = f"{prefix}WARNING: {im_file}: ignoring corrupt image/label: {e}"
        return [None, None, None, None, nm, nf, ne, nc, msg]
```

## 7. load_image
&emsp;è¿™ä¸ªå‡½æ•°æ˜¯æ ¹æ®å›¾ç‰‡indexï¼Œä»selfæˆ–è€…ä»å¯¹åº”å›¾ç‰‡è·¯å¾„ä¸­è½½å…¥å¯¹åº”indexçš„å›¾ç‰‡

å¹¶å°†åŸå›¾ä¸­hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•ã€‚

ä¼šè¢«ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•°å’Œload_mosaicæ¨¡å—ä¸­è½½å…¥å¯¹åº”indexçš„å›¾ç‰‡ï¼š

load_imageå‡½æ•°ä»£ç ï¼š


```python
    def load_image(self, i):
         """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•°å’Œload_mosaicæ¨¡å—ä¸­
        ä»selfæˆ–è€…ä»å¯¹åº”å›¾ç‰‡è·¯å¾„ä¸­è½½å…¥å¯¹åº”indexçš„å›¾ç‰‡ å¹¶å°†åŸå›¾ä¸­hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•
        loads 1 image from dataset, returns img, original hw, resized hw
        :params self: ä¸€èˆ¬æ˜¯å¯¼å…¥LoadImagesAndLabelsä¸­çš„self
        :param index: å½“å‰å›¾ç‰‡çš„index
        :return: img: resizeåçš„å›¾ç‰‡
                (h0, w0): hw_original  åŸå›¾çš„hw
                img.shape[:2]: hw_resized resizeåçš„å›¾ç‰‡hw(hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•)
        """
        im, f, fn = (
            self.ims[i],
            self.im_files[i],
            self.npy_files[i],
        )
        if im is None:  # not cached in RAM
            if fn.exists():  # load npy
                im = np.load(fn)
            else:  # read image
                im = cv2.imread(f)  # BGR
                assert im is not None, f"Image Not Found {f}"
            h0, w0 = im.shape[:2]  # orig hw
            r = self.img_size / max(h0, w0)  # ratio
            if r != 1:  # if sizes are not equal
            # cv2.INTER_AREA: åŸºäºåŒºåŸŸåƒç´ å…³ç³»çš„ä¸€ç§é‡é‡‡æ ·æˆ–è€…æ’å€¼æ–¹å¼.è¯¥æ–¹æ³•æ˜¯å›¾åƒæŠ½å–çš„é¦–é€‰æ–¹æ³•, å®ƒå¯ä»¥äº§ç”Ÿæ›´å°‘çš„æ³¢çº¹
            # cv2.INTER_LINEAR: åŒçº¿æ€§æ’å€¼,é»˜è®¤æƒ…å†µä¸‹ä½¿ç”¨è¯¥æ–¹å¼è¿›è¡Œæ’å€¼   æ ¹æ®ratioé€‰æ‹©ä¸åŒçš„æ’å€¼æ–¹å¼
            # å°†åŸå›¾ä¸­hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•
                interp = cv2.INTER_LINEAR if (self.augment or r > 1) else cv2.INTER_AREA
                im = cv2.resize(im, (int(w0 * r), int(h0 * r)), interpolation=interp)
            return im, (h0, w0), im.shape[:2]  # im, hw_original, hw_resized
        return self.ims[i], self.im_hw0[i], self.im_hw[i]  # im, hw_original, hw_resized
```

## 8. augment_hsv
&emsp;è¿™ä¸ªå‡½æ•°æ˜¯å…³äºå›¾ç‰‡çš„è‰²åŸŸå¢å¼ºæ¨¡å—ï¼Œå›¾ç‰‡å¹¶ä¸å‘ç”Ÿç§»åŠ¨ï¼Œæ‰€æœ‰ä¸éœ€è¦æ”¹å˜labelï¼Œåªéœ€è¦ img å¢å¼ºå³å¯ã€‚

augment_hsvæ¨¡å—ä»£ç ï¼š


```python
def augment_hsv(img, hgain=0.5, sgain=0.5, vgain=0.5):
    """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•°
    hsvè‰²åŸŸå¢å¼º  å¤„ç†å›¾åƒhsvï¼Œä¸å¯¹labelè¿›è¡Œä»»ä½•å¤„ç†
    :param img: å¾…å¤„ç†å›¾ç‰‡  BGR [736, 736]
    :param hgain: hé€šé“è‰²åŸŸå‚æ•° ç”¨äºç”Ÿæˆæ–°çš„hé€šé“
    :param sgain: hé€šé“è‰²åŸŸå‚æ•° ç”¨äºç”Ÿæˆæ–°çš„sé€šé“
    :param vgain: hé€šé“è‰²åŸŸå‚æ•° ç”¨äºç”Ÿæˆæ–°çš„vé€šé“
    :return: è¿”å›hsvå¢å¼ºåçš„å›¾ç‰‡ img
    """
    if hgain or sgain or vgain:
        # éšæœºå–-1åˆ°1ä¸‰ä¸ªå®æ•°ï¼Œä¹˜ä»¥hypä¸­çš„hsvä¸‰é€šé“çš„ç³»æ•°  ç”¨äºç”Ÿæˆæ–°çš„hsvé€šé“
        r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains
        hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))  # å›¾åƒçš„é€šé“æ‹†åˆ† h s v
        dtype = img.dtype  # uint8

        x = np.arange(0, 256, dtype=r.dtype)
        lut_hue = ((x * r[0]) % 180).astype(dtype)         # ç”Ÿæˆæ–°çš„hé€šé“
        lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)  # ç”Ÿæˆæ–°çš„sé€šé“
        lut_val = np.clip(x * r[2], 0, 255).astype(dtype)  # ç”Ÿæˆæ–°çš„vé€šé“

        # å›¾åƒçš„é€šé“åˆå¹¶ img_hsv=h+s+v  éšæœºè°ƒæ•´hsvä¹‹åé‡æ–°ç»„åˆhsvé€šé“
        # cv2.LUT(hue, lut_hue)   é€šé“è‰²åŸŸå˜æ¢ è¾“å…¥å˜æ¢å‰é€šé“hue å’Œå˜æ¢åé€šé“lut_hue
        img_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)))
        # no return needed  dst:è¾“å‡ºå›¾åƒ
        cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)  # no return needed  hsv->bgr
```

è¿˜è¦æ³¨æ„çš„æ˜¯è¿™ä¸ªhsvå¢å¼ºæ˜¯éšæœºç”Ÿæˆå„ä¸ªè‰²åŸŸå‚æ•°çš„ï¼Œæ‰€ä»¥æ¯æ¬¡å¢å¼ºçš„æ•ˆæœéƒ½æ˜¯ä¸åŒçš„ï¼š

è¿™ä¸ªå‡½æ•°ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•°ä¸­ï¼š
<a href="https://github.com/Oneflow-Inc/one-yolov5/blob/640ac163ee26a8b13bb2e94f348fb3752a250886/utils/dataloaders.py#L707" target="blank">

![image](https://user-images.githubusercontent.com/109639975/199916719-8917e8eb-e3c8-4be8-9d5b-f9174a77195f.png)


</a>
    
å¦å¤–ï¼Œè¿™é‡Œæ¶‰åŠåˆ°çš„ä¸‰ä¸ªå˜é‡æ¥è‡ªhyp.yamlè¶…å‚æ–‡ä»¶ï¼š
![image](https://user-images.githubusercontent.com/109639975/199916836-d2277200-0763-47f7-8b4e-65cd7d62ca3b.png)
## 9. load_mosaicã€load_mosaic9
&emsp;è¿™ä¸¤ä¸ªå‡½æ•°éƒ½æ˜¯mosaicæ•°æ®å¢å¼ºï¼Œåªä¸è¿‡load_mosaicå‡½æ•°æ˜¯æ‹¼æ¥å››å¼ å›¾ï¼Œè€Œload_mosaic9å‡½æ•°æ˜¯æ‹¼æ¥ä¹å¼ å›¾ã€‚
æ›´å¤šè¯·å‚é˜…[ã€Šmosaic è§£è¯»ã€‹](https://start.oneflow.org/oneflow-yolo-doc/tutorials/04_chapter/mosaic.html)
### 9.1 load_mosaic
![image](https://user-images.githubusercontent.com/109639975/199916906-07ba8364-148b-4298-b7eb-bd0d52d98f0e.png)
&emsp;è¿™ä¸ªæ¨¡å—å°±æ˜¯å¾ˆæœ‰åçš„mosaicå¢å¼ºæ¨¡å—ï¼Œå‡ ä¹è®­ç»ƒçš„æ—¶å€™éƒ½ä¼šç”¨å®ƒï¼Œå¯ä»¥æ˜¾è‘—çš„æé«˜å°æ ·æœ¬çš„mAPã€‚

ä»£ç æ˜¯æ•°æ®å¢å¼ºé‡Œé¢æœ€éš¾çš„, ä¹Ÿæ˜¯æœ€æœ‰ä»·å€¼çš„ï¼Œmosaicæ˜¯éå¸¸éå¸¸æœ‰ç”¨çš„æ•°æ®å¢å¼ºtrick, ä¸€å®šè¦ç†Ÿç»ƒæŒæ¡ã€‚

load_mosaicæ¨¡å—ä»£ç ï¼š


```python
def load_mosaic(self, index):
    """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•° è¿›è¡Œmosaicæ•°æ®å¢å¼º
    å°†å››å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­  loads images in a 4-mosaic
    :param index: éœ€è¦è·å–çš„å›¾åƒç´¢å¼•
    :return: img4: mosaicå’Œéšæœºé€è§†å˜æ¢åçš„ä¸€å¼ å›¾ç‰‡  numpy(640, 640, 3)
             labels4: img4å¯¹åº”çš„target  [M, cls+x1y1x2y2]
    """
    # labels4: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ4å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(ä¸åŒ…å«segmentså¤šè¾¹å½¢)
    # segments4: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ4å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢)
    labels4, segments4 = [], []
    s = self.img_size  # ä¸€èˆ¬çš„å›¾ç‰‡å¤§å°
    # éšæœºåˆå§‹åŒ–æ‹¼æ¥å›¾åƒçš„ä¸­å¿ƒç‚¹åæ ‡  [0, s*2]ä¹‹é—´éšæœºå–2ä¸ªæ•°ä½œä¸ºæ‹¼æ¥å›¾åƒçš„ä¸­å¿ƒåæ ‡
    yc, xc = [int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border]  # mosaic center x, y
    # ä»datasetä¸­éšæœºå¯»æ‰¾é¢å¤–çš„ä¸‰å¼ å›¾åƒè¿›è¡Œæ‹¼æ¥ [14, 26, 2, 16] å†éšæœºé€‰ä¸‰å¼ å›¾ç‰‡çš„index
    indices = [index] + random.choices(self.indices, k=3)  # 3 additional image indices
    # éå†å››å¼ å›¾åƒè¿›è¡Œæ‹¼æ¥ 4å¼ ä¸åŒå¤§å°çš„å›¾åƒ => 1å¼ [1472, 1472, 3]çš„å›¾åƒ
    for i, index in enumerate(indices):
        # load image   æ¯æ¬¡æ‹¿ä¸€å¼ å›¾ç‰‡ å¹¶å°†è¿™å¼ å›¾ç‰‡resizeåˆ°self.size(h,w)
        img, _, (h, w) = load_image(self, index)

        # place img in img4
        if i == 0:  # top left  åŸå›¾[375, 500, 3] load_image->[552, 736, 3]   hwc
            # åˆ›å»ºé©¬èµ›å…‹å›¾åƒ [1472, 1472, 3]=[h, w, c]
            img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
            # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)   w=736  h = 552  é©¬èµ›å…‹å›¾åƒï¼š(x1a,y1a)å·¦ä¸Šè§’ (x2a,y2a)å³ä¸‹è§’
            x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)
            # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬ä¸€å¼ å›¾åƒçš„å³ä¸‹è§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)  å›¾åƒï¼š(x1b,y1b)å·¦ä¸Šè§’ (x2b,y2b)å³ä¸‹è§’
            x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)
        elif i == 1:  # top right
            # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)
            x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc
            # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬äºŒå¼ å›¾åƒçš„å·¦ä¸‹è§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)
            x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h
        elif i == 2:  # bottom left
            # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)
            x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)
            # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬ä¸‰å¼ å›¾åƒçš„å³ä¸Šè§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)
            x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)
        elif i == 3:  # bottom right
            # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)
            x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)
            # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬å››å¼ å›¾åƒçš„å·¦ä¸Šè§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)
            x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)

        # å°†æˆªå–çš„å›¾åƒåŒºåŸŸå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒçš„ç›¸åº”ä½ç½®   img4[h, w, c]
        # å°†å›¾åƒimgçš„ã€(x1b,y1b)å·¦ä¸Šè§’ (x2b,y2b)å³ä¸‹è§’ã€‘åŒºåŸŸæˆªå–å‡ºæ¥å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒçš„ã€(x1a,y1a)å·¦ä¸Šè§’ (x2a,y2a)å³ä¸‹è§’ã€‘åŒºåŸŸ
        img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
        # è®¡ç®—pad(å½“å‰å›¾åƒè¾¹ç•Œä¸é©¬èµ›å…‹è¾¹ç•Œçš„è·ç¦»ï¼Œè¶Šç•Œçš„æƒ…å†µpadw/padhä¸ºè´Ÿå€¼)  ç”¨äºåé¢çš„labelæ˜ å°„
        padw = x1a - x1b   # å½“å‰å›¾åƒä¸é©¬èµ›å…‹å›¾åƒåœ¨wç»´åº¦ä¸Šç›¸å·®å¤šå°‘
        padh = y1a - y1b   # å½“å‰å›¾åƒä¸é©¬èµ›å…‹å›¾åƒåœ¨hç»´åº¦ä¸Šç›¸å·®å¤šå°‘

        # labels: è·å–å¯¹åº”æ‹¼æ¥å›¾åƒçš„æ‰€æœ‰æ­£å¸¸labelä¿¡æ¯(å¦‚æœæœ‰segmentså¤šè¾¹å½¢ä¼šè¢«è½¬åŒ–ä¸ºçŸ©å½¢label)
        # segments: è·å–å¯¹åº”æ‹¼æ¥å›¾åƒçš„æ‰€æœ‰ä¸æ­£å¸¸labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢ä¹ŸåŒ…å«æ­£å¸¸gt)
        labels, segments = self.labels[index].copy(), self.segments[index].copy()
        if labels.size:
            # normalized xywh normalized to pixel xyxy format
            labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padw, padh)
            segments = [xyn2xy(x, w, h, padw, padh) for x in segments]
        labels4.append(labels)      # æ›´æ–°labels4
        segments4.extend(segments)  # æ›´æ–°segments4

    # Concat/clip labels4 æŠŠlabels4ï¼ˆ[(2, 5), (1, 5), (3, 5), (1, 5)] => (7, 5)ï¼‰å‹ç¼©åˆ°ä¸€èµ·
    labels4 = np.concatenate(labels4, 0)
    # é˜²æ­¢è¶Šç•Œ  label[:, 1:]ä¸­çš„æ‰€æœ‰å…ƒç´ çš„å€¼ï¼ˆä½ç½®ä¿¡æ¯ï¼‰å¿…é¡»åœ¨[0, 2*s]ä¹‹é—´,å°äº0å°±ä»¤å…¶ç­‰äº0,å¤§äº2*så°±ç­‰äº2*s   out: è¿”å›
    for x in (labels4[:, 1:], *segments4):
        np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()

    # æµ‹è¯•ä»£ç   æµ‹è¯•å‰é¢çš„mosaicæ•ˆæœ
    # cv2.imshow("mosaic", img4)
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()
    # print(img4.shape)   # (1280, 1280, 3)

    # éšæœºåç§»æ ‡ç­¾ä¸­å¿ƒï¼Œç”Ÿæˆæ–°çš„æ ‡ç­¾ä¸åŸæ ‡ç­¾ç»“åˆ replicate
    # img4, labels4 = replicate(img4, labels4)
    #
    # # æµ‹è¯•ä»£ç   æµ‹è¯•replicateæ•ˆæœ
    # cv2.imshow("replicate", img4)
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()
    # print(img4.shape)   # (1280, 1280, 3)

    # Augment
    # random_perspective Augment  éšæœºé€è§†å˜æ¢ [1280, 1280, 3] => [640, 640, 3]
    # å¯¹mosaicæ•´åˆåçš„å›¾ç‰‡è¿›è¡Œéšæœºæ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ã€è£å‰ªï¼Œé€è§†å˜æ¢ï¼Œå¹¶resizeä¸ºè¾“å…¥å¤§å°img_size
    img4, labels4 = random_perspective(img4, labels4, segments4,
                                       degrees=self.hyp['degrees'],
                                       translate=self.hyp['translate'],
                                       scale=self.hyp['scale'],
                                       shear=self.hyp['shear'],
                                       perspective=self.hyp['perspective'],
                                       border=self.mosaic_border)  # border to remove

    # æµ‹è¯•ä»£ç  æµ‹è¯•mosaic + random_perspectiveéšæœºä»¿å°„å˜æ¢æ•ˆæœ
    # cv2.imshow("random_perspective", img4)
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()
    # print(img4.shape)   # (640, 640, 3)

    return img4, labels4

```

### 9.2 load_mosaic9
&emsp;è¿™ä¸ªæ¨¡å—æ˜¯ä½œè€…çš„å®éªŒæ¨¡å—ï¼Œå°†ä¹å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­ã€‚æ€»ä½“ä»£ç æµç¨‹å’Œload_mosaic4å‡ ä¹ä¸€æ ·ï¼Œçœ‹æ‡‚äº†load_mosaic4å†çœ‹è¿™ä¸ªå°±å¾ˆç®€å•äº†ã€

load_mosaic9æ¨¡å—ä»£ç ï¼š



```python
def load_mosaic9(self, index):
    """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•° æ›¿æ¢mosaicæ•°æ®å¢å¼º
    å°†ä¹å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­  loads images in a 9-mosaic
    :param self:
    :param index: éœ€è¦è·å–çš„å›¾åƒç´¢å¼•
    :return: img9: mosaicå’Œä»¿å°„å¢å¼ºåçš„ä¸€å¼ å›¾ç‰‡
             labels9: img9å¯¹åº”çš„target
    """
    # labels9: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ9å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(ä¸åŒ…å«segmentså¤šè¾¹å½¢)
    # segments9: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ9å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢)
    labels9, segments9 = [], []
    s = self.img_size  # ä¸€èˆ¬çš„å›¾ç‰‡å¤§å°(ä¹Ÿæ˜¯æœ€ç»ˆè¾“å‡ºçš„å›¾ç‰‡å¤§å°)
    # ä»datasetä¸­éšæœºå¯»æ‰¾é¢å¤–çš„ä¸‰å¼ å›¾åƒè¿›è¡Œæ‹¼æ¥ [14, 26, 2, 16] å†éšæœºé€‰ä¸‰å¼ å›¾ç‰‡çš„index
    indices = [index] + random.choices(self.indices, k=8)  # 8 additional image indices
    for i, index in enumerate(indices):
        # Load image  æ¯æ¬¡æ‹¿ä¸€å¼ å›¾ç‰‡ å¹¶å°†è¿™å¼ å›¾ç‰‡resizeåˆ°self.size(h,w)
        img, _, (h, w) = load_image(self, index)

        # è¿™é‡Œå’Œä¸Šé¢load_mosaicå‡½æ•°çš„æ“ä½œç±»ä¼¼ å°±æ˜¯å°†å–å‡ºçš„imgå›¾ç‰‡åµŒåˆ°img9ä¸­(ä¸æ˜¯çœŸçš„åµŒå…¥ è€Œæ˜¯æ‰¾åˆ°å¯¹åº”çš„ä½ç½®)
        # place img in img9
        if i == 0:  # center
            img9 = np.full((s * 3, s * 3, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
            h0, w0 = h, w
            c = s, s, s + w, s + h  # xmin, ymin, xmax, ymax (base) coordinates
        elif i == 1:  # top
            c = s, s - h, s + w, s
        elif i == 2:  # top right
            c = s + wp, s - h, s + wp + w, s
        elif i == 3:  # right
            c = s + w0, s, s + w0 + w, s + h
        elif i == 4:  # bottom right
            c = s + w0, s + hp, s + w0 + w, s + hp + h
        elif i == 5:  # bottom
            c = s + w0 - w, s + h0, s + w0, s + h0 + h
        elif i == 6:  # bottom left
            c = s + w0 - wp - w, s + h0, s + w0 - wp, s + h0 + h
        elif i == 7:  # left
            c = s - w, s + h0 - h, s, s + h0
        elif i == 8:  # top left
            c = s - w, s + h0 - hp - h, s, s + h0 - hp

        padx, pady = c[:2]
        x1, y1, x2, y2 = [max(x, 0) for x in c]  # allocate coords

        # å’Œä¸Šé¢load_mosaicå‡½æ•°çš„æ“ä½œç±»ä¼¼ æ‰¾åˆ°mosaic9å¢å¼ºåçš„labels9å’Œsegments9
        labels, segments = self.labels[index].copy(), self.segments[index].copy()
        if labels.size:
            labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padx, pady)  # normalized xywh to pixel xyxy format
            segments = [xyn2xy(x, w, h, padx, pady) for x in segments]
        labels9.append(labels)
        segments9.extend(segments)

        # ç”Ÿæˆå¯¹åº”çš„img9å›¾ç‰‡(å°†å¯¹åº”ä½ç½®çš„å›¾ç‰‡åµŒå…¥img9ä¸­)
        img9[y1:y2, x1:x2] = img[y1 - pady:, x1 - padx:]  # img9[ymin:ymax, xmin:xmax]
        hp, wp = h, w  # height, width previous

    # Offset
    yc, xc = [int(random.uniform(0, s)) for _ in self.mosaic_border]  # mosaic center x, y
    img9 = img9[yc:yc + 2 * s, xc:xc + 2 * s]

    # Concat/clip labels
    labels9 = np.concatenate(labels9, 0)
    labels9[:, [1, 3]] -= xc
    labels9[:, [2, 4]] -= yc
    c = np.array([xc, yc])  # centers
    segments9 = [x - c for x in segments9]

    for x in (labels9[:, 1:], *segments9):
        np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
    # img9, labels9 = replicate(img9, labels9)  # replicate

    # Augment åŒæ ·è¿›è¡Œ éšæœºé€è§†å˜æ¢
    img9, labels9 = random_perspective(img9, labels9, segments9,
                                       degrees=self.hyp['degrees'],
                                       translate=self.hyp['translate'],
                                       scale=self.hyp['scale'],
                                       shear=self.hyp['shear'],
                                       perspective=self.hyp['perspective'],
                                       border=self.mosaic_border)  # border to remove

    return img9, labels9
```

ç”¨æ³•å’Œmosaicä¸€æ ·ï¼Œä½¿ç”¨ç›´æ¥å°†class LoadImagesAndLabels(Dataset): ä¸­ __getitem__ çš„load_mosaicç›´æ¥
ç›´æ¥æ›¿æ¢æˆload_mosaic9å³å¯ï¼š

![image](https://user-images.githubusercontent.com/109639975/199917054-2783d335-7ad7-42ce-91b7-73659010d679.png)


## 10. LoadImages & LoadStreams & LoadWebcam
load æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡/è§†é¢‘ + ç”¨åˆ°å¾ˆå°‘ load webç½‘é¡µä¸­çš„æ•°æ®ã€‚
å…¨éƒ¨ä»£ç ï¼š


```python
class LoadImages:  # for inference
    """åœ¨detect.pyä¸­ä½¿ç”¨
    load æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡/è§†é¢‘
    å®šä¹‰è¿­ä»£å™¨ ç”¨äºdetect.py
    """

    def __init__(self, path, img_size=640, stride=32):
        p = str(Path(path).absolute())  # os-agnostic absolute path
        # glob.glab: è¿”å›æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨   files: æå–å›¾ç‰‡æ‰€æœ‰è·¯å¾„
        if "*" in p:
            # å¦‚æœpæ˜¯é‡‡æ ·æ­£åˆ™åŒ–è¡¨è¾¾å¼æå–å›¾ç‰‡/è§†é¢‘, å¯ä»¥ä½¿ç”¨globè·å–æ–‡ä»¶è·¯å¾„
            files = sorted(glob.glob(p, recursive=True))  # glob
        elif os.path.isdir(p):
            # å¦‚æœpæ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œä½¿ç”¨globè·å–å…¨éƒ¨æ–‡ä»¶è·¯å¾„
            files = sorted(glob.glob(os.path.join(p, "*.*")))  # dir
        elif os.path.isfile(p):
            # å¦‚æœpæ˜¯æ–‡ä»¶åˆ™ç›´æ¥è·å–
            files = [p]  # files
        else:
            raise Exception(f"ERROR: {p} does not exist")

        # images: ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡çš„å›¾ç‰‡å  videos: ç›®å½•ä¸‹æ‰€æœ‰è§†é¢‘çš„è§†é¢‘å
        images = [x for x in files if x.split(".")[-1].lower() in img_formats]
        videos = [x for x in files if x.split(".")[-1].lower() in vid_formats]
        # å›¾ç‰‡ä¸è§†é¢‘æ•°é‡
        ni, nv = len(images), len(videos)

        self.img_size = img_size
        self.stride = stride  # æœ€å¤§çš„ä¸‹é‡‡æ ·ç‡
        self.files = images + videos  # æ•´åˆå›¾ç‰‡å’Œè§†é¢‘è·¯å¾„åˆ°ä¸€ä¸ªåˆ—è¡¨
        self.nf = ni + nv  # number of files
        self.video_flag = [False] * ni + [True] * nv  # æ˜¯ä¸æ˜¯video
        self.mode = "image"  # é»˜è®¤æ˜¯è¯»imageæ¨¡å¼
        if any(videos):
            # åˆ¤æ–­æœ‰æ²¡æœ‰videoæ–‡ä»¶  å¦‚æœåŒ…å«videoæ–‡ä»¶ï¼Œåˆ™åˆå§‹åŒ–opencvä¸­çš„è§†é¢‘æ¨¡å—ï¼Œcap=cv2.VideoCaptureç­‰
            self.new_video(videos[0])  # new video
        else:
            self.cap = None
        assert self.nf > 0, (
            f"No images or videos found in {p}. "
            f"Supported formats are:\nimages: {img_formats}\nvideos: {vid_formats}"
        )

    def __iter__(self):
        """è¿­ä»£å™¨"""
        self.count = 0
        return self

    def __next__(self):
        """ä¸iterä¸€èµ·ç”¨ï¼Ÿ"""
        if self.count == self.nf:  # æ•°æ®è¯»å®Œäº†
            raise StopIteration
        path = self.files[self.count]  # è¯»å–å½“å‰æ–‡ä»¶è·¯å¾„

        if self.video_flag[self.count]:  # åˆ¤æ–­å½“å‰æ–‡ä»¶æ˜¯å¦æ˜¯è§†é¢‘
            # Read video
            self.mode = "video"
            # è·å–å½“å‰å¸§ç”»é¢ï¼Œret_valä¸ºä¸€ä¸ªboolå˜é‡ï¼Œç›´åˆ°è§†é¢‘è¯»å–å®Œæ¯•ä¹‹å‰éƒ½ä¸ºTrue
            ret_val, img0 = self.cap.read()
            # å¦‚æœå½“å‰è§†é¢‘è¯»å–ç»“æŸï¼Œåˆ™è¯»å–ä¸‹ä¸€ä¸ªè§†é¢‘
            if not ret_val:
                self.count += 1
                self.cap.release()
                # self.count == self.nfè¡¨ç¤ºè§†é¢‘å·²ç»è¯»å–å®Œäº†
                if self.count == self.nf:  # last video
                    raise StopIteration
                else:
                    path = self.files[self.count]
                    self.new_video(path)
                    ret_val, img0 = self.cap.read()

            self.frame += 1  # å½“å‰è¯»å–è§†é¢‘çš„å¸§æ•°
            print(
                f"video {self.count + 1}/{self.nf} ({self.frame}/{self.frames}) {path}: ",
                end="",
            )

        else:
            # Read image
            self.count += 1
            img0 = cv2.imread(path)  # BGR
            assert img0 is not None, "Image Not Found " + path
            print(f"image {self.count}/{self.nf} {path}: ", end="")

        # Padded resize
        img = letterbox(img0, self.img_size, stride=self.stride)[0]

        # Convert
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB and HWC to CHW
        img = np.ascontiguousarray(img)

        # è¿”å›è·¯å¾„, resize+padçš„å›¾ç‰‡, åŸå§‹å›¾ç‰‡, è§†é¢‘å¯¹è±¡
        return path, img, img0, self.cap

    def new_video(self, path):
        # è®°å½•å¸§æ•°
        self.frame = 0
        # åˆå§‹åŒ–è§†é¢‘å¯¹è±¡
        self.cap = cv2.VideoCapture(path)
        # å¾—åˆ°è§†é¢‘æ–‡ä»¶ä¸­çš„æ€»å¸§æ•°
        self.frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

    def __len__(self):
        return self.nf  # number of files


class LoadStreams:
    """
    load æ–‡ä»¶å¤¹ä¸­è§†é¢‘æµ
    multiple IP or RTSP cameras
    å®šä¹‰è¿­ä»£å™¨ ç”¨äºdetect.py
    """

    def __init__(self, sources="streams.txt", img_size=640, stride=32):
        self.mode = "stream"  # åˆå§‹åŒ–modeä¸ºimages
        self.img_size = img_size
        self.stride = stride  # æœ€å¤§ä¸‹é‡‡æ ·æ­¥é•¿

        # å¦‚æœsourcesä¸ºä¸€ä¸ªä¿å­˜äº†å¤šä¸ªè§†é¢‘æµçš„æ–‡ä»¶  è·å–æ¯ä¸€ä¸ªè§†é¢‘æµï¼Œä¿å­˜ä¸ºä¸€ä¸ªåˆ—è¡¨
        if os.path.isfile(sources):
            with open(sources, "r") as f:
                sources = [
                    x.strip() for x in f.read().strip().splitlines() if len(x.strip())
                ]
        else:
            # åä¹‹ï¼Œåªæœ‰ä¸€ä¸ªè§†é¢‘æµæ–‡ä»¶å°±ç›´æ¥ä¿å­˜
            sources = [sources]

        n = len(sources)  # è§†é¢‘æµä¸ªæ•°
        # åˆå§‹åŒ–å›¾ç‰‡ fps æ€»å¸§æ•° çº¿ç¨‹æ•°
        self.imgs, self.fps, self.frames, self.threads = (
            [None] * n,
            [0] * n,
            [0] * n,
            [None] * n,
        )
        self.sources = [clean_str(x) for x in sources]  # clean source names for later

        # éå†æ¯ä¸€ä¸ªè§†é¢‘æµ
        for i, s in enumerate(sources):  # index, source
            # Start thread to read frames from video stream
            # æ‰“å°å½“å‰è§†é¢‘index/æ€»è§†é¢‘æ•°/è§†é¢‘æµåœ°å€
            print(f"{i + 1}/{n}: {s}... ", end="")
            if "youtube.com/" in s or "youtu.be/" in s:  # if source is YouTube video
                check_requirements(("pafy", "youtube_dl"))
                import pafy

                s = pafy.new(s).getbest(preftype="mp4").url  # YouTube URL
            s = eval(s) if s.isnumeric() else s  # i.e. s = '0' local webcam æœ¬åœ°æ‘„åƒå¤´
            # s='0'æ‰“å¼€æœ¬åœ°æ‘„åƒå¤´ï¼Œå¦åˆ™æ‰“å¼€è§†é¢‘æµåœ°å€
            cap = cv2.VideoCapture(s)
            assert cap.isOpened(), f"Failed to open {s}"
            # è·å–è§†é¢‘çš„å®½å’Œé•¿
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            # è·å–è§†é¢‘çš„å¸§ç‡
            self.fps[i] = (
                max(cap.get(cv2.CAP_PROP_FPS) % 100, 0) or 30.0
            )  # 30 FPS fallback
            # å¸§æ•°
            self.frames[i] = max(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), 0) or float(
                "inf"
            )  # infinite stream fallback

            # è¯»å–å½“å‰ç”»é¢
            _, self.imgs[i] = cap.read()  # guarantee first frame
            # åˆ›å»ºå¤šçº¿ç¨‹è¯»å–è§†é¢‘æµï¼Œdaemonè¡¨ç¤ºä¸»çº¿ç¨‹ç»“æŸæ—¶å­çº¿ç¨‹ä¹Ÿç»“æŸ
            self.threads[i] = Thread(target=self.update, args=([i, cap]), daemon=True)
            print(
                f" success ({self.frames[i]} frames {w}x{h} at {self.fps[i]:.2f} FPS)"
            )
            self.threads[i].start()
        print("")  # newline

        # check for common shapes
        # è·å–è¿›è¡Œresize+padä¹‹åçš„shapeï¼Œletterboxå‡½æ•°é»˜è®¤(å‚æ•°auto=True)æ˜¯æŒ‰ç…§çŸ©å½¢æ¨ç†è¿›è¡Œå¡«å……
        s = np.stack(
            [
                letterbox(x, self.img_size, stride=self.stride)[0].shape
                for x in self.imgs
            ],
            0,
        )  # shapes
        self.rect = (
            np.unique(s, axis=0).shape[0] == 1
        )  # rect inference if all shapes equal
        if not self.rect:
            print(
                "WARNING: Different stream shapes detected. For optimal performance supply similarly-shaped streams."
            )

    def update(self, i, cap):
        # Read stream `i` frames in daemon thread
        n, f = 0, self.frames[i]
        while cap.isOpened() and n < f:
            n += 1
            # _, self.imgs[index] = cap.read()
            cap.grab()
            # æ¯4å¸§è¯»å–ä¸€æ¬¡
            if n % 4:  # read every 4th frame
                success, im = cap.retrieve()
                self.imgs[i] = im if success else self.imgs[i] * 0
            time.sleep(1 / self.fps[i])  # wait time

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        if not all(x.is_alive() for x in self.threads) or cv2.waitKey(1) == ord(
            "q"
        ):  # q to quit
            cv2.destroyAllWindows()
            raise StopIteration

        # Letterbox
        img0 = self.imgs.copy()
        img = [
            letterbox(x, self.img_size, auto=self.rect, stride=self.stride)[0]
            for x in img0
        ]

        # Stack  å°†è¯»å–çš„å›¾ç‰‡æ‹¼æ¥åˆ°ä¸€èµ·
        img = np.stack(img, 0)

        # Convert
        img = img[:, :, :, ::-1].transpose(0, 3, 1, 2)  # BGR to RGB and BHWC to BCHW
        img = np.ascontiguousarray(img)

        return self.sources, img, img0, None

    def __len__(self):
        return 0  # 1E12 frames = 32 streams at 30 FPS for 30 years


class LoadWebcam:  # for inference
    """ç”¨åˆ°å¾ˆå°‘ load webç½‘é¡µä¸­çš„æ•°æ®"""

    def __init__(self, pipe="0", img_size=640, stride=32):
        self.img_size = img_size
        self.stride = stride

        if pipe.isnumeric():
            pipe = eval(pipe)  # local camera
        # pipe = 'rtsp://192.168.1.64/1'  # IP camera
        # pipe = 'rtsp://username:password@192.168.1.64/1'  # IP camera with login
        # pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg'  # IP golf camera

        self.pipe = pipe
        self.cap = cv2.VideoCapture(pipe)  # video capture object
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 3)  # set buffer size

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        if cv2.waitKey(1) == ord("q"):  # q to quit
            self.cap.release()
            cv2.destroyAllWindows()
            raise StopIteration

        # Read frame
        if self.pipe == 0:  # local camera
            ret_val, img0 = self.cap.read()
            img0 = cv2.flip(img0, 1)  # flip left-right
        else:  # IP camera
            n = 0
            while True:
                n += 1
                self.cap.grab()
                if n % 30 == 0:  # skip frames
                    ret_val, img0 = self.cap.retrieve()
                    if ret_val:
                        break

        # Print
        assert ret_val, f"Camera Error {self.pipe}"
        img_path = "webcam.jpg"
        print(f"webcam {self.count}: ", end="")

        # Padded resize
        img = letterbox(img0, self.img_size, stride=self.stride)[0]

        # Convert
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB and HWC to CHW
        img = np.ascontiguousarray(img)

        return img_path, img, img0, None

    def __len__(self):
        return 0
```

## 11. flatten_recursive
è¿™ä¸ªæ¨¡å—æ˜¯å°†ä¸€ä¸ªæ–‡ä»¶è·¯å¾„ä¸­çš„æ‰€æœ‰æ–‡ä»¶å¤åˆ¶åˆ°å¦ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ å³å°†imageæ–‡ä»¶å’Œlabelæ–‡ä»¶æ”¾åˆ°ä¸€ä¸ªæ–°æ–‡ä»¶å¤¹ä¸­ã€‚

flatten_recursiveæ¨¡å—ä»£ç ï¼š


```python
def flatten_recursive(path=DATASETS_DIR / "coco128"):
    # å°†ä¸€ä¸ªæ–‡ä»¶è·¯å¾„ä¸­çš„æ‰€æœ‰æ–‡ä»¶å¤åˆ¶åˆ°å¦ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­  å³å°†imageæ–‡ä»¶å’Œlabelæ–‡ä»¶æ”¾åˆ°ä¸€ä¸ªæ–°æ–‡ä»¶å¤¹ä¸­
    # Flatten a recursive directory by bringing all files to top level
    new_path = Path(f"{str(path)}_flat")
    if os.path.exists(new_path):
        shutil.rmtree(new_path)  # delete output folder
    os.makedirs(new_path)  # make new output folder
    for file in tqdm(glob.glob(f"{str(Path(path))}/**/*.*", recursive=True)):
        # shutil.copyfile: å¤åˆ¶æ–‡ä»¶åˆ°å¦ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­
        shutil.copyfile(file, new_path / Path(file).name)

```

## 12.extract_boxes
&emsp;è¿™ä¸ªæ¨¡å—æ˜¯å°†ç›®æ ‡æ£€æµ‹æ•°æ®é›†è½¬åŒ–ä¸ºåˆ†ç±»æ•°æ®é›† ï¼Œé›†ä½“åšæ³•: æŠŠç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸­çš„æ¯ä¸€ä¸ªgtæ‹†è§£å¼€ åˆ†ç±»åˆ«å­˜å‚¨åˆ°å¯¹åº”çš„æ–‡ä»¶å½“ä¸­ã€‚


```python
def extract_boxes(
    path=DATASETS_DIR / "coco128",
):  # from utils.dataloaders import *; extract_boxes()
    # Convert detection dataset into classification dataset, with one directory per class
    """è‡ªè¡Œä½¿ç”¨ ç”Ÿæˆåˆ†ç±»æ•°æ®é›†
    å°†ç›®æ ‡æ£€æµ‹æ•°æ®é›†è½¬åŒ–ä¸ºåˆ†ç±»æ•°æ®é›† é›†ä½“åšæ³•: æŠŠç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸­çš„æ¯ä¸€ä¸ªgtæ‹†è§£å¼€ åˆ†ç±»åˆ«å­˜å‚¨åˆ°å¯¹åº”çš„æ–‡ä»¶å½“ä¸­
    Convert detection dataset into classification dataset, with one directory per class
    ä½¿ç”¨: from utils.datasets import *; extract_boxes()
    :params path: æ•°æ®é›†åœ°å€
    """
    path = Path(path)  # images dir æ•°æ®é›†æ–‡ä»¶ç›®å½• é»˜è®¤'..\datasets\coco128'
    shutil.rmtree(path / "classifier") if (path / "classifier").is_dir() else None  # remove existing
    files = list(path.rglob("*.*"))
    n = len(files)  # number of files
    for im_file in tqdm(files, total=n):
        if im_file.suffix[1:] in IMG_FORMATS: # å¿…é¡»å¾—æ˜¯å›¾ç‰‡æ–‡ä»¶
            # image
            im = cv2.imread(str(im_file))[..., ::-1]  # BGR to RGB
            h, w = im.shape[:2]  # å¾—åˆ°è¿™å¼ å›¾ç‰‡h w

            # labels æ ¹æ®è¿™å¼ å›¾ç‰‡çš„è·¯å¾„æ‰¾åˆ°è¿™å¼ å›¾ç‰‡çš„labelè·¯å¾„
            lb_file = Path(img2label_paths([str(im_file)])[0])
            if Path(lb_file).exists():
                with open(lb_file) as f:
                    lb = np.array([x.split() for x in f.read().strip().splitlines()], dtype=np.float32)  # labels è¯»å–labelçš„å„è¡Œ: å¯¹åº”å„ä¸ªgtåæ ‡

                for j, x in enumerate(lb): # éå†æ¯ä¸€ä¸ªgt
                    c = int(x[0])  # class
                    # ç”Ÿæˆæ–°'file_name path\classifier\class_index\image_name'
                    # å¦‚: 'F:\yolo_v5\datasets\coco128\images\train2017\classifier\45\train2017_000000000009_0.jpg'
                    f = (path / "classifier") / f"{c}" / f"{path.stem}_{im_file.stem}_{j}.jpg"  # new filename
                    if not f.parent.is_dir():
                        # æ¯ä¸€ä¸ªç±»åˆ«çš„ç¬¬ä¸€å¼ ç…§ç‰‡å­˜è¿›å»ä¹‹å‰ å…ˆåˆ›å»ºå¯¹åº”ç±»çš„æ–‡ä»¶å¤¹
                        f.parent.mkdir(parents=True)

                    b = x[1:] * [w, h, w, h]  # box normalized to æ­£å¸¸å¤§å°
                    # b[2:] = b[2:].max()  # rectangle to square
                    b[2:] = b[2:] * 1.2 + 3  # pad
                    b = xywh2xyxy(b.reshape(-1, 4)).ravel().astype(np.int)

                    b[[0, 2]] = np.clip(b[[0, 2]], 0, w)  # clip boxes outside of image é˜²æ­¢å‡ºç•Œ 
                    b[[1, 3]] = np.clip(b[[1, 3]], 0, h)
                    assert cv2.imwrite(str(f), im[b[1] : b[3], b[0] : b[2]]), f"box failure in {f}"
```

## 13. autosplit
&emsp;è¿™ä¸ªæ¨¡å—æ˜¯è¿›è¡Œè‡ªåŠ¨åˆ’åˆ†æ•°æ®é›†ã€‚å½“ä½¿ç”¨è‡ªå·±æ•°æ®é›†æ—¶ï¼Œå¯ä»¥ç”¨è¿™ä¸ªæ¨¡å—è¿›è¡Œè‡ªè¡Œåˆ’åˆ†æ•°æ®é›†ã€‚

autosplitæ¨¡å—ä»£ç ï¼š


```python
def autosplit(path=DATASETS_DIR / "coco128/images", weights=(0.9, 0.1, 0.0), annotated_only=False):
    """Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files
    Usage: from utils.dataloaders import *; autosplit()
    Arguments
        path:            Path to images directory
        weights:         Train, val, test weights (list, tuple)
        annotated_only:  Only use images with an annotated txt file
    """
    path = Path(path)  # images dir
    # è·å–imagesä¸­æ‰€æœ‰çš„å›¾ç‰‡ image files only
    files = sorted(x for x in path.rglob("*.*") if x.suffix[1:].lower() in IMG_FORMATS)  # image files only
    n = len(files)  # number of files
    # éšæœºæ•°ç§å­
    random.seed(0)  # for reproducibility
    # assign each image to a split æ ¹æ®(train, val, test)æƒé‡åˆ’åˆ†åŸå§‹å›¾ç‰‡æ•°æ®é›†
    # indices: [n]   0, 1, 2   åˆ†åˆ«è¡¨ç¤ºæ•°æ®é›†ä¸­æ¯ä¸€å¼ å›¾ç‰‡å±äºå“ªä¸ªæ•°æ®é›† åˆ†åˆ«å¯¹åº”ç€(train, val, test)
    indices = random.choices([0, 1, 2], weights=weights, k=n)  # assign each image to a split

    txt = ["autosplit_train.txt", "autosplit_val.txt", "autosplit_test.txt"]  # 3 txt files
    [(path.parent / x).unlink(missing_ok=True) for x in txt]  # remove existing

    print(f"Autosplitting images from {path}" + ", using *.txt labeled images only" * annotated_only)
    for i, img in tqdm(zip(indices, files), total=n):
        if not annotated_only or Path(img2label_paths([str(img)])[0]).exists():  # check label
            with open(path.parent / txt[i], "a") as f:
                f.write(f"./{img.relative_to(path.parent).as_posix()}" + "\n")  # add image to txt file
                
```

## Reference
- ã€YOLOV5-5.x æºç è§£è¯»ã€‘[atasets.py](https://blog.csdn.net/qq_38253797/article/details/119904518)
